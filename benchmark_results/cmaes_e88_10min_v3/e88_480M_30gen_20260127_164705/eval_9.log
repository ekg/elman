Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_9/levelE88_100m_20260127_165750
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 484,069,192 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 3.9206 | lr 3.00e-04 | grad 11.81 | tok/s 5482
step     20 | loss 2.6553 | lr 3.00e-04 | grad 5.25 | tok/s 14203
step     30 | loss 2.4661 | lr 3.00e-04 | grad 3.41 | tok/s 14364
step     40 | loss 2.3587 | lr 3.00e-04 | grad 3.03 | tok/s 13686
step     50 | loss 2.9095 | lr 3.00e-04 | grad 10.81 | tok/s 13868
step     60 | loss 2.0613 | lr 3.00e-04 | grad 7.97 | tok/s 14286
step     70 | loss 1.9069 | lr 3.00e-04 | grad 4.00 | tok/s 14403
step     80 | loss 5.3962 | lr 3.00e-04 | grad 46.75 | tok/s 14532
step     90 | loss 4.7399 | lr 3.00e-04 | grad 7.25 | tok/s 14685
step    100 | loss 3.7809 | lr 3.00e-04 | grad 6.03 | tok/s 14654
step    110 | loss 3.2526 | lr 3.00e-04 | grad 11.69 | tok/s 14692
step    120 | loss 2.9546 | lr 3.00e-04 | grad 7.47 | tok/s 14629
step    130 | loss 2.7419 | lr 3.00e-04 | grad 9.50 | tok/s 14607
step    140 | loss 2.6058 | lr 3.00e-04 | grad 7.59 | tok/s 14588
step    150 | loss 2.5007 | lr 3.00e-04 | grad 6.75 | tok/s 14578
step    160 | loss 2.1913 | lr 3.00e-04 | grad 5.81 | tok/s 14532
step    170 | loss 2.3373 | lr 3.00e-04 | grad 9.00 | tok/s 14519
step    180 | loss 2.0577 | lr 3.00e-04 | grad 4.88 | tok/s 14497
step    190 | loss 2.2743 | lr 3.00e-04 | grad 14.19 | tok/s 14499
step    200 | loss 1.9573 | lr 3.00e-04 | grad 3.58 | tok/s 14469
step    210 | loss 2.0156 | lr 3.00e-04 | grad 6.09 | tok/s 14450
step    220 | loss 2.1108 | lr 3.00e-04 | grad 2.86 | tok/s 14298
step    230 | loss 2.0249 | lr 3.00e-04 | grad 3.61 | tok/s 14051
step    240 | loss 2.2719 | lr 3.00e-04 | grad 3.91 | tok/s 13325
step    250 | loss 2.0817 | lr 3.00e-04 | grad 2.16 | tok/s 13733
step    260 | loss 1.5542 | lr 3.00e-04 | grad 2.41 | tok/s 14183
step    270 | loss 2.0520 | lr 3.00e-04 | grad 2.38 | tok/s 13947
step    280 | loss 2.2343 | lr 3.00e-04 | grad 5.47 | tok/s 13733
step    290 | loss 1.3289 | lr 3.00e-04 | grad 2.45 | tok/s 14426
step    300 | loss 0.5408 | lr 3.00e-04 | grad 1.72 | tok/s 14433
step    310 | loss 2.3722 | lr 3.00e-04 | grad 3.27 | tok/s 14165
step    320 | loss 1.9175 | lr 3.00e-04 | grad 4.38 | tok/s 13855
step    330 | loss 1.9222 | lr 3.00e-04 | grad 2.44 | tok/s 13348
step    340 | loss 2.2426 | lr 3.00e-04 | grad 2.23 | tok/s 13637
step    350 | loss 1.8523 | lr 3.00e-04 | grad 3.16 | tok/s 13998
step    360 | loss 1.1851 | lr 3.00e-04 | grad 7.09 | tok/s 14309
step    370 | loss 1.7931 | lr 3.00e-04 | grad 2.11 | tok/s 12964
step    380 | loss 1.7544 | lr 3.00e-04 | grad 2.14 | tok/s 13830
step    390 | loss 1.5268 | lr 3.00e-04 | grad 1.64 | tok/s 14418
step    400 | loss 1.4799 | lr 3.00e-04 | grad 2.08 | tok/s 14281
step    410 | loss 1.2690 | lr 3.00e-04 | grad 1.70 | tok/s 13976
step    420 | loss 1.7875 | lr 3.00e-04 | grad 3.64 | tok/s 13372
step    430 | loss 2.1370 | lr 3.00e-04 | grad 2.45 | tok/s 14228
step    440 | loss 2.1292 | lr 3.00e-04 | grad 3.39 | tok/s 13389
step    450 | loss 1.9599 | lr 3.00e-04 | grad 2.20 | tok/s 13900
step    460 | loss 1.6972 | lr 3.00e-04 | grad 2.50 | tok/s 13616
step    470 | loss 1.8044 | lr 3.00e-04 | grad 1.92 | tok/s 14026
step    480 | loss 2.1915 | lr 3.00e-04 | grad 5.53 | tok/s 14042
step    490 | loss 1.7744 | lr 3.00e-04 | grad 2.03 | tok/s 13281
step    500 | loss 1.6681 | lr 3.00e-04 | grad 2.78 | tok/s 14140
step    510 | loss 1.6927 | lr 3.00e-04 | grad 2.00 | tok/s 14348
step    520 | loss 1.6504 | lr 3.00e-04 | grad 1.73 | tok/s 14323
step    530 | loss 1.8869 | lr 3.00e-04 | grad 2.09 | tok/s 13763
step    540 | loss 1.7212 | lr 3.00e-04 | grad 1.80 | tok/s 13756
step    550 | loss 1.5569 | lr 3.00e-04 | grad 2.39 | tok/s 11976
step    560 | loss 1.7050 | lr 3.00e-04 | grad 2.16 | tok/s 13143
step    570 | loss 1.6423 | lr 3.00e-04 | grad 2.92 | tok/s 13466
step    580 | loss 1.5278 | lr 3.00e-04 | grad 1.82 | tok/s 13417
step    590 | loss 1.8253 | lr 3.00e-04 | grad 2.64 | tok/s 13766
step    600 | loss 1.8041 | lr 3.00e-04 | grad 1.88 | tok/s 13289
step    610 | loss 1.6110 | lr 3.00e-04 | grad 1.96 | tok/s 13951
step    620 | loss 1.5262 | lr 3.00e-04 | grad 2.00 | tok/s 13236
step    630 | loss 1.6510 | lr 3.00e-04 | grad 3.62 | tok/s 13367
step    640 | loss 1.7891 | lr 3.00e-04 | grad 2.05 | tok/s 13713
step    650 | loss 1.6519 | lr 3.00e-04 | grad 2.11 | tok/s 13775
step    660 | loss 1.6844 | lr 3.00e-04 | grad 1.88 | tok/s 13838
step    670 | loss 1.8727 | lr 3.00e-04 | grad 2.77 | tok/s 13917
step    680 | loss 1.7171 | lr 3.00e-04 | grad 2.03 | tok/s 13678
step    690 | loss 1.7957 | lr 3.00e-04 | grad 2.69 | tok/s 14119
step    700 | loss 1.4167 | lr 3.00e-04 | grad 2.50 | tok/s 14430
step    710 | loss 1.5728 | lr 3.00e-04 | grad 2.00 | tok/s 13501
step    720 | loss 1.4577 | lr 3.00e-04 | grad 3.08 | tok/s 13262
step    730 | loss 1.2859 | lr 3.00e-04 | grad 2.33 | tok/s 14370
step    740 | loss 1.4840 | lr 3.00e-04 | grad 1.96 | tok/s 14192
step    750 | loss 1.1907 | lr 3.00e-04 | grad 2.08 | tok/s 14391
step    760 | loss 1.0984 | lr 3.00e-04 | grad 1.93 | tok/s 14404
step    770 | loss 1.0475 | lr 3.00e-04 | grad 1.70 | tok/s 14374
step    780 | loss 0.9801 | lr 3.00e-04 | grad 1.76 | tok/s 14389
step    790 | loss 1.1123 | lr 3.00e-04 | grad 2.80 | tok/s 13929
step    800 | loss 1.7853 | lr 3.00e-04 | grad 4.69 | tok/s 13892
step    810 | loss 1.6829 | lr 3.00e-04 | grad 1.80 | tok/s 13852
step    820 | loss 1.6836 | lr 3.00e-04 | grad 3.19 | tok/s 13312
step    830 | loss 1.4731 | lr 3.00e-04 | grad 2.11 | tok/s 14265
step    840 | loss 1.3604 | lr 3.00e-04 | grad 1.95 | tok/s 14396
step    850 | loss 1.5515 | lr 3.00e-04 | grad 1.75 | tok/s 14302
step    860 | loss 1.4551 | lr 3.00e-04 | grad 3.17 | tok/s 14122
step    870 | loss 1.4832 | lr 3.00e-04 | grad 2.20 | tok/s 13648
step    880 | loss 1.6534 | lr 3.00e-04 | grad 2.09 | tok/s 13697
step    890 | loss 1.6648 | lr 3.00e-04 | grad 2.52 | tok/s 13901
step    900 | loss 1.5453 | lr 3.00e-04 | grad 2.17 | tok/s 12317
step    910 | loss 1.4101 | lr 3.00e-04 | grad 3.25 | tok/s 13623
step    920 | loss 1.5056 | lr 3.00e-04 | grad 3.22 | tok/s 14161
step    930 | loss 1.5854 | lr 3.00e-04 | grad 2.92 | tok/s 13513
step    940 | loss 1.3758 | lr 3.00e-04 | grad 1.61 | tok/s 14254
step    950 | loss 1.4602 | lr 3.00e-04 | grad 2.44 | tok/s 14356
step    960 | loss 1.2993 | lr 3.00e-04 | grad 2.12 | tok/s 14336
step    970 | loss 1.7131 | lr 3.00e-04 | grad 3.03 | tok/s 13482
step    980 | loss 1.6200 | lr 3.00e-04 | grad 1.98 | tok/s 13845
step    990 | loss 1.4339 | lr 3.00e-04 | grad 1.79 | tok/s 14088
step   1000 | loss 1.8156 | lr 3.00e-04 | grad 7.91 | tok/s 13514
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8156.pt
step   1010 | loss 1.6220 | lr 3.00e-04 | grad 2.56 | tok/s 4371
step   1020 | loss 1.5895 | lr 3.00e-04 | grad 2.08 | tok/s 13251
step   1030 | loss 1.3809 | lr 3.00e-04 | grad 1.85 | tok/s 14163
step   1040 | loss 1.4912 | lr 3.00e-04 | grad 2.02 | tok/s 13885
step   1050 | loss 1.6201 | lr 3.00e-04 | grad 2.05 | tok/s 13779
step   1060 | loss 1.6785 | lr 3.00e-04 | grad 2.53 | tok/s 14196
step   1070 | loss 1.6132 | lr 3.00e-04 | grad 2.83 | tok/s 13785
step   1080 | loss 1.3770 | lr 3.00e-04 | grad 2.09 | tok/s 13159
step   1090 | loss 1.0094 | lr 3.00e-04 | grad 2.23 | tok/s 14137
step   1100 | loss 1.5485 | lr 3.00e-04 | grad 2.36 | tok/s 13667
step   1110 | loss 1.3611 | lr 3.00e-04 | grad 1.63 | tok/s 14102
step   1120 | loss 1.3164 | lr 3.00e-04 | grad 1.73 | tok/s 14493
step   1130 | loss 1.2589 | lr 3.00e-04 | grad 1.53 | tok/s 14415
step   1140 | loss 1.2756 | lr 3.00e-04 | grad 1.66 | tok/s 14444
step   1150 | loss 1.2676 | lr 3.00e-04 | grad 1.53 | tok/s 11939
step   1160 | loss 1.1871 | lr 3.00e-04 | grad 1.61 | tok/s 14433
step   1170 | loss 1.2878 | lr 3.00e-04 | grad 1.75 | tok/s 14464
step   1180 | loss 1.2705 | lr 3.00e-04 | grad 1.83 | tok/s 14390
step   1190 | loss 1.1850 | lr 3.00e-04 | grad 1.56 | tok/s 13485
step   1200 | loss 1.2242 | lr 3.00e-04 | grad 1.59 | tok/s 14263
step   1210 | loss 1.2584 | lr 3.00e-04 | grad 1.69 | tok/s 12732
step   1220 | loss 1.2398 | lr 3.00e-04 | grad 1.46 | tok/s 14413
step   1230 | loss 1.2370 | lr 3.00e-04 | grad 1.54 | tok/s 14406
step   1240 | loss 1.3603 | lr 3.00e-04 | grad 2.22 | tok/s 13955
step   1250 | loss 1.6836 | lr 3.00e-04 | grad 2.12 | tok/s 13671
step   1260 | loss 1.4284 | lr 3.00e-04 | grad 5.25 | tok/s 13569
step   1270 | loss 1.6055 | lr 3.00e-04 | grad 2.59 | tok/s 13291
step   1280 | loss 1.5749 | lr 3.00e-04 | grad 3.31 | tok/s 14198
step   1290 | loss 1.4536 | lr 3.00e-04 | grad 1.85 | tok/s 12348
step   1300 | loss 1.4957 | lr 3.00e-04 | grad 1.87 | tok/s 10348
step   1310 | loss 1.4355 | lr 3.00e-04 | grad 1.84 | tok/s 12560
step   1320 | loss 1.6774 | lr 3.00e-04 | grad 3.61 | tok/s 14235
step   1330 | loss 1.3407 | lr 3.00e-04 | grad 2.86 | tok/s 13948
step   1340 | loss 1.6234 | lr 3.00e-04 | grad 4.81 | tok/s 11870
step   1350 | loss 1.7202 | lr 3.00e-04 | grad 2.86 | tok/s 13357
step   1360 | loss 1.3790 | lr 3.00e-04 | grad 1.91 | tok/s 13714
step   1370 | loss 1.5453 | lr 3.00e-04 | grad 2.70 | tok/s 13986
step   1380 | loss 1.5312 | lr 3.00e-04 | grad 2.20 | tok/s 12154
step   1390 | loss 1.3871 | lr 3.00e-04 | grad 1.78 | tok/s 12628
step   1400 | loss 1.3866 | lr 3.00e-04 | grad 1.92 | tok/s 13791
step   1410 | loss 1.5321 | lr 3.00e-04 | grad 2.02 | tok/s 13426
step   1420 | loss 1.5676 | lr 3.00e-04 | grad 2.03 | tok/s 13535
step   1430 | loss 1.2770 | lr 3.00e-04 | grad 1.54 | tok/s 13653
step   1440 | loss 1.1206 | lr 3.00e-04 | grad 1.53 | tok/s 14392
step   1450 | loss 1.3215 | lr 3.00e-04 | grad 3.95 | tok/s 14171
step   1460 | loss 1.5821 | lr 3.00e-04 | grad 2.09 | tok/s 13268
step   1470 | loss 1.4236 | lr 3.00e-04 | grad 1.80 | tok/s 14192
step   1480 | loss 1.8055 | lr 3.00e-04 | grad 4.66 | tok/s 14323
step   1490 | loss 1.4908 | lr 3.00e-04 | grad 1.91 | tok/s 13569
step   1500 | loss 1.2228 | lr 3.00e-04 | grad 1.59 | tok/s 13226
step   1510 | loss 1.5563 | lr 3.00e-04 | grad 2.16 | tok/s 13990
step   1520 | loss 1.4460 | lr 3.00e-04 | grad 2.22 | tok/s 13950
step   1530 | loss 1.3693 | lr 3.00e-04 | grad 1.84 | tok/s 13911
step   1540 | loss 1.6129 | lr 3.00e-04 | grad 1.93 | tok/s 13828
step   1550 | loss 1.1816 | lr 3.00e-04 | grad 1.56 | tok/s 14228
step   1560 | loss 1.6121 | lr 3.00e-04 | grad 1.59 | tok/s 13682
step   1570 | loss 1.3463 | lr 3.00e-04 | grad 2.30 | tok/s 14282
step   1580 | loss 1.6257 | lr 3.00e-04 | grad 2.88 | tok/s 14139
step   1590 | loss 1.4688 | lr 3.00e-04 | grad 1.53 | tok/s 13613
step   1600 | loss 0.7733 | lr 3.00e-04 | grad 1.04 | tok/s 14514
step   1610 | loss 1.2762 | lr 3.00e-04 | grad 1.62 | tok/s 13298
step   1620 | loss 1.3382 | lr 3.00e-04 | grad 3.47 | tok/s 13702
step   1630 | loss 1.2923 | lr 3.00e-04 | grad 1.79 | tok/s 14056
step   1640 | loss 1.4917 | lr 3.00e-04 | grad 4.53 | tok/s 13607
step   1650 | loss 1.5049 | lr 3.00e-04 | grad 1.95 | tok/s 12850
step   1660 | loss 1.1946 | lr 3.00e-04 | grad 1.59 | tok/s 14390
step   1670 | loss 1.5960 | lr 3.00e-04 | grad 2.31 | tok/s 13559
step   1680 | loss 1.5175 | lr 3.00e-04 | grad 1.81 | tok/s 13362
step   1690 | loss 1.4208 | lr 3.00e-04 | grad 3.56 | tok/s 14195
step   1700 | loss 1.4991 | lr 3.00e-04 | grad 2.47 | tok/s 13427
step   1710 | loss 1.4083 | lr 3.00e-04 | grad 1.98 | tok/s 13573
step   1720 | loss 1.4598 | lr 3.00e-04 | grad 2.61 | tok/s 13654
step   1730 | loss 1.1372 | lr 3.00e-04 | grad 2.14 | tok/s 14455
step   1740 | loss 1.3956 | lr 3.00e-04 | grad 2.17 | tok/s 13791
step   1750 | loss 1.5122 | lr 3.00e-04 | grad 2.31 | tok/s 13986
step   1760 | loss 1.5384 | lr 3.00e-04 | grad 1.64 | tok/s 11571
step   1770 | loss 1.4170 | lr 3.00e-04 | grad 1.91 | tok/s 13737
step   1780 | loss 1.4726 | lr 3.00e-04 | grad 2.33 | tok/s 14009
step   1790 | loss 1.4150 | lr 3.00e-04 | grad 2.25 | tok/s 13855
step   1800 | loss 1.5883 | lr 3.00e-04 | grad 3.12 | tok/s 13166
step   1810 | loss 1.3378 | lr 3.00e-04 | grad 2.44 | tok/s 12010
step   1820 | loss 1.4744 | lr 3.00e-04 | grad 3.28 | tok/s 12710
step   1830 | loss 1.4356 | lr 3.00e-04 | grad 2.19 | tok/s 13560
step   1840 | loss 1.4183 | lr 3.00e-04 | grad 2.27 | tok/s 13487
step   1850 | loss 1.2727 | lr 3.00e-04 | grad 2.09 | tok/s 14372
step   1860 | loss 1.3931 | lr 3.00e-04 | grad 3.20 | tok/s 13416
step   1870 | loss 1.2065 | lr 3.00e-04 | grad 1.61 | tok/s 14280
step   1880 | loss 1.3615 | lr 3.00e-04 | grad 4.44 | tok/s 12831
step   1890 | loss 1.4646 | lr 3.00e-04 | grad 1.56 | tok/s 13555
step   1900 | loss 1.3671 | lr 3.00e-04 | grad 2.66 | tok/s 13707
step   1910 | loss 1.4466 | lr 3.00e-04 | grad 1.55 | tok/s 13388
step   1920 | loss 1.3535 | lr 3.00e-04 | grad 1.84 | tok/s 14271
step   1930 | loss 1.4420 | lr 3.00e-04 | grad 1.81 | tok/s 13479
step   1940 | loss 1.5701 | lr 3.00e-04 | grad 6.03 | tok/s 14175
step   1950 | loss 1.6438 | lr 3.00e-04 | grad 2.91 | tok/s 14412
step   1960 | loss 1.4380 | lr 3.00e-04 | grad 2.50 | tok/s 14300
step   1970 | loss 1.5473 | lr 3.00e-04 | grad 4.22 | tok/s 13947
step   1980 | loss 1.3915 | lr 3.00e-04 | grad 1.38 | tok/s 13700
step   1990 | loss 1.6094 | lr 3.00e-04 | grad 2.80 | tok/s 13590
step   2000 | loss 1.4576 | lr 3.00e-04 | grad 1.80 | tok/s 13940
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4576.pt
step   2010 | loss 1.1419 | lr 3.00e-04 | grad 2.12 | tok/s 6264
step   2020 | loss 1.2986 | lr 3.00e-04 | grad 2.31 | tok/s 14166

Training complete! Final step: 2020
