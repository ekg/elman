Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_32/levelE88_100m_20260127_171845
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 473,574,264 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.3293 | lr 3.00e-04 | grad 47.00 | tok/s 8972
step     20 | loss 3.3699 | lr 3.00e-04 | grad 18.50 | tok/s 18849
step     30 | loss 3.3456 | lr 3.00e-04 | grad 7.62 | tok/s 20023
step     40 | loss 5.2730 | lr 3.00e-04 | grad 40.75 | tok/s 20163
step     50 | loss 4.0584 | lr 3.00e-04 | grad 9.88 | tok/s 20320
step     60 | loss 3.4309 | lr 3.00e-04 | grad 9.69 | tok/s 20196
step     70 | loss 2.8861 | lr 3.00e-04 | grad 9.19 | tok/s 20098
step     80 | loss 2.5138 | lr 3.00e-04 | grad 4.47 | tok/s 20034
step     90 | loss 2.5653 | lr 3.00e-04 | grad 6.91 | tok/s 20007
step    100 | loss 2.3013 | lr 3.00e-04 | grad 5.12 | tok/s 19944
step    110 | loss 2.5128 | lr 3.00e-04 | grad 16.75 | tok/s 19576
step    120 | loss 2.4970 | lr 3.00e-04 | grad 4.97 | tok/s 18626
step    130 | loss 2.0929 | lr 3.00e-04 | grad 4.03 | tok/s 19138
step    140 | loss 2.3697 | lr 3.00e-04 | grad 9.06 | tok/s 19322
step    150 | loss 1.4686 | lr 3.00e-04 | grad 5.12 | tok/s 19601
step    160 | loss 2.2579 | lr 3.00e-04 | grad 3.91 | tok/s 18773
step    170 | loss 2.3199 | lr 3.00e-04 | grad 3.22 | tok/s 18819
step    180 | loss 1.8068 | lr 3.00e-04 | grad 3.66 | tok/s 18864
step    190 | loss 1.8565 | lr 3.00e-04 | grad 3.94 | tok/s 18978
step    200 | loss 1.6050 | lr 3.00e-04 | grad 2.77 | tok/s 19603
step    210 | loss 1.9485 | lr 3.00e-04 | grad 2.73 | tok/s 18551
step    220 | loss 2.3164 | lr 3.00e-04 | grad 14.62 | tok/s 18802
step    230 | loss 1.9610 | lr 3.00e-04 | grad 4.84 | tok/s 18600
step    240 | loss 2.2163 | lr 3.00e-04 | grad 2.84 | tok/s 19020
step    250 | loss 1.7862 | lr 3.00e-04 | grad 4.00 | tok/s 19024
step    260 | loss 1.9030 | lr 3.00e-04 | grad 3.75 | tok/s 19408
step    270 | loss 1.7660 | lr 3.00e-04 | grad 2.66 | tok/s 18797
step    280 | loss 1.7726 | lr 3.00e-04 | grad 2.27 | tok/s 17982
step    290 | loss 1.6560 | lr 3.00e-04 | grad 2.83 | tok/s 18319
step    300 | loss 2.0310 | lr 3.00e-04 | grad 2.81 | tok/s 18673
step    310 | loss 1.6738 | lr 3.00e-04 | grad 3.61 | tok/s 18357
step    320 | loss 1.8561 | lr 3.00e-04 | grad 3.45 | tok/s 18710
step    330 | loss 1.7274 | lr 3.00e-04 | grad 2.67 | tok/s 18855
step    340 | loss 2.0693 | lr 3.00e-04 | grad 3.41 | tok/s 18915
step    350 | loss 1.6713 | lr 3.00e-04 | grad 2.83 | tok/s 19409
step    360 | loss 1.5525 | lr 3.00e-04 | grad 1.91 | tok/s 18491
step    370 | loss 1.4592 | lr 3.00e-04 | grad 2.09 | tok/s 19522
step    380 | loss 1.1941 | lr 3.00e-04 | grad 2.38 | tok/s 19695
step    390 | loss 1.0960 | lr 3.00e-04 | grad 2.22 | tok/s 19694
step    400 | loss 1.8368 | lr 3.00e-04 | grad 3.06 | tok/s 18651
step    410 | loss 1.7712 | lr 3.00e-04 | grad 2.73 | tok/s 18817
step    420 | loss 1.5881 | lr 3.00e-04 | grad 10.38 | tok/s 19630
step    430 | loss 1.6007 | lr 3.00e-04 | grad 2.98 | tok/s 19145
step    440 | loss 1.7226 | lr 3.00e-04 | grad 3.73 | tok/s 18829
step    450 | loss 1.6245 | lr 3.00e-04 | grad 3.83 | tok/s 18826
step    460 | loss 1.6058 | lr 3.00e-04 | grad 2.22 | tok/s 19060
step    470 | loss 1.6178 | lr 3.00e-04 | grad 3.58 | tok/s 19266
step    480 | loss 1.5790 | lr 3.00e-04 | grad 3.56 | tok/s 19250
step    490 | loss 1.6995 | lr 3.00e-04 | grad 2.44 | tok/s 18917
step    500 | loss 1.8605 | lr 3.00e-04 | grad 3.59 | tok/s 18901
step    510 | loss 1.6616 | lr 3.00e-04 | grad 2.78 | tok/s 17996
step    520 | loss 1.5224 | lr 3.00e-04 | grad 2.45 | tok/s 18959
step    530 | loss 1.7464 | lr 3.00e-04 | grad 2.50 | tok/s 18924
step    540 | loss 1.5830 | lr 3.00e-04 | grad 2.62 | tok/s 18258
step    550 | loss 1.4074 | lr 3.00e-04 | grad 2.41 | tok/s 18673
step    560 | loss 1.4247 | lr 3.00e-04 | grad 2.59 | tok/s 19676
step    570 | loss 1.3427 | lr 3.00e-04 | grad 2.09 | tok/s 19675
step    580 | loss 1.2925 | lr 3.00e-04 | grad 2.42 | tok/s 19674
step    590 | loss 1.3485 | lr 3.00e-04 | grad 2.73 | tok/s 19682
step    600 | loss 1.2750 | lr 3.00e-04 | grad 2.34 | tok/s 19670
step    610 | loss 1.3041 | lr 3.00e-04 | grad 2.11 | tok/s 19689
step    620 | loss 1.3969 | lr 3.00e-04 | grad 5.28 | tok/s 19392
step    630 | loss 1.7110 | lr 3.00e-04 | grad 4.03 | tok/s 18625
step    640 | loss 1.7037 | lr 3.00e-04 | grad 2.84 | tok/s 18751
step    650 | loss 1.5605 | lr 3.00e-04 | grad 3.41 | tok/s 18784
step    660 | loss 1.6682 | lr 3.00e-04 | grad 5.00 | tok/s 19427
step    670 | loss 1.6047 | lr 3.00e-04 | grad 3.97 | tok/s 18589
step    680 | loss 1.6368 | lr 3.00e-04 | grad 1.84 | tok/s 18497
step    690 | loss 1.6457 | lr 3.00e-04 | grad 4.06 | tok/s 18631
step    700 | loss 1.4623 | lr 3.00e-04 | grad 1.88 | tok/s 18696
step    710 | loss 1.6814 | lr 3.00e-04 | grad 3.03 | tok/s 18543
step    720 | loss 1.2867 | lr 3.00e-04 | grad 2.52 | tok/s 19208
step    730 | loss 1.5715 | lr 3.00e-04 | grad 4.78 | tok/s 18789
step    740 | loss 1.7809 | lr 3.00e-04 | grad 5.34 | tok/s 19476
step    750 | loss 1.4811 | lr 3.00e-04 | grad 2.42 | tok/s 19632
step    760 | loss 1.6170 | lr 3.00e-04 | grad 3.39 | tok/s 19208
step    770 | loss 1.5898 | lr 3.00e-04 | grad 2.36 | tok/s 18267
step    780 | loss 1.4863 | lr 3.00e-04 | grad 2.23 | tok/s 18191
step    790 | loss 1.6828 | lr 3.00e-04 | grad 3.47 | tok/s 19299
step    800 | loss 1.2090 | lr 3.00e-04 | grad 4.56 | tok/s 19054
step    810 | loss 1.4228 | lr 3.00e-04 | grad 2.61 | tok/s 18179
step    820 | loss 1.4998 | lr 3.00e-04 | grad 5.62 | tok/s 18763
step    830 | loss 1.4513 | lr 3.00e-04 | grad 2.47 | tok/s 18560
step    840 | loss 1.6881 | lr 3.00e-04 | grad 2.59 | tok/s 18275
step    850 | loss 1.5638 | lr 3.00e-04 | grad 2.67 | tok/s 18794
step    860 | loss 1.6258 | lr 3.00e-04 | grad 3.42 | tok/s 19355
step    870 | loss 1.4298 | lr 3.00e-04 | grad 2.91 | tok/s 19198
step    880 | loss 1.6081 | lr 3.00e-04 | grad 2.14 | tok/s 18582
step    890 | loss 1.5215 | lr 3.00e-04 | grad 2.88 | tok/s 18822
step    900 | loss 1.5940 | lr 3.00e-04 | grad 2.64 | tok/s 15206
step    910 | loss 1.5127 | lr 3.00e-04 | grad 2.67 | tok/s 19028
step    920 | loss 1.5490 | lr 3.00e-04 | grad 2.09 | tok/s 18719
step    930 | loss 1.4128 | lr 3.00e-04 | grad 2.34 | tok/s 18692
step    940 | loss 1.3926 | lr 3.00e-04 | grad 2.19 | tok/s 18247
step    950 | loss 1.4778 | lr 3.00e-04 | grad 2.11 | tok/s 18500
step    960 | loss 1.4666 | lr 3.00e-04 | grad 2.58 | tok/s 18940
step    970 | loss 1.7052 | lr 3.00e-04 | grad 6.53 | tok/s 18915
step    980 | loss 1.8256 | lr 3.00e-04 | grad 4.53 | tok/s 19264
step    990 | loss 1.5301 | lr 3.00e-04 | grad 2.64 | tok/s 18687
step   1000 | loss 1.6250 | lr 3.00e-04 | grad 2.75 | tok/s 18819
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6250.pt
step   1010 | loss 1.2294 | lr 3.00e-04 | grad 2.59 | tok/s 6238
step   1020 | loss 1.4828 | lr 3.00e-04 | grad 2.62 | tok/s 10571
step   1030 | loss 2.1914 | lr 3.00e-04 | grad 7.00 | tok/s 19397
step   1040 | loss 1.6038 | lr 3.00e-04 | grad 2.06 | tok/s 19649
step   1050 | loss 1.2699 | lr 3.00e-04 | grad 1.59 | tok/s 18040
step   1060 | loss 1.4065 | lr 3.00e-04 | grad 2.70 | tok/s 17827
step   1070 | loss 1.3226 | lr 3.00e-04 | grad 2.31 | tok/s 6679
step   1080 | loss 1.2669 | lr 3.00e-04 | grad 2.45 | tok/s 18606
step   1090 | loss 1.2001 | lr 3.00e-04 | grad 1.87 | tok/s 18211
step   1100 | loss 1.3586 | lr 3.00e-04 | grad 2.06 | tok/s 18932
step   1110 | loss 1.6030 | lr 3.00e-04 | grad 4.12 | tok/s 16732
step   1120 | loss 1.8659 | lr 3.00e-04 | grad 1.97 | tok/s 19213
step   1130 | loss 1.6400 | lr 3.00e-04 | grad 6.97 | tok/s 19227
step   1140 | loss 1.5572 | lr 3.00e-04 | grad 4.34 | tok/s 18943
step   1150 | loss 1.6975 | lr 3.00e-04 | grad 2.34 | tok/s 13820
step   1160 | loss 1.4830 | lr 3.00e-04 | grad 1.81 | tok/s 14253
step   1170 | loss 1.5948 | lr 3.00e-04 | grad 3.09 | tok/s 19454
step   1180 | loss 1.2211 | lr 3.00e-04 | grad 1.95 | tok/s 19637
step   1190 | loss 1.3318 | lr 3.00e-04 | grad 3.45 | tok/s 18735
step   1200 | loss 1.3896 | lr 3.00e-04 | grad 3.69 | tok/s 18984
step   1210 | loss 1.4863 | lr 3.00e-04 | grad 2.73 | tok/s 19072
step   1220 | loss 1.2490 | lr 3.00e-04 | grad 2.44 | tok/s 18469
step   1230 | loss 1.5181 | lr 3.00e-04 | grad 4.06 | tok/s 18860
step   1240 | loss 1.4479 | lr 3.00e-04 | grad 3.97 | tok/s 19417
step   1250 | loss 1.4416 | lr 3.00e-04 | grad 4.09 | tok/s 18788
step   1260 | loss 1.3860 | lr 3.00e-04 | grad 7.84 | tok/s 18976
step   1270 | loss 1.4255 | lr 3.00e-04 | grad 2.45 | tok/s 18504
step   1280 | loss 1.5131 | lr 3.00e-04 | grad 4.47 | tok/s 18547
step   1290 | loss 1.6391 | lr 3.00e-04 | grad 2.56 | tok/s 19190
step   1300 | loss 1.4859 | lr 3.00e-04 | grad 1.95 | tok/s 19229
step   1310 | loss 1.5363 | lr 3.00e-04 | grad 1.84 | tok/s 19354
step   1320 | loss 1.5969 | lr 3.00e-04 | grad 8.25 | tok/s 18466
step   1330 | loss 1.4505 | lr 3.00e-04 | grad 3.59 | tok/s 19254
step   1340 | loss 1.5261 | lr 3.00e-04 | grad 2.22 | tok/s 18303
step   1350 | loss 1.5099 | lr 3.00e-04 | grad 7.56 | tok/s 19162

Training complete! Final step: 1357
