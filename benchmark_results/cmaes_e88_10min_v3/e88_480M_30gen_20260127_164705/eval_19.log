Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_19/levelE88_100m_20260127_170817
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 480,245,200 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2299 | lr 3.00e-04 | grad 19.25 | tok/s 5965
step     20 | loss 3.1300 | lr 3.00e-04 | grad 10.88 | tok/s 18627
step     30 | loss 2.7461 | lr 3.00e-04 | grad 7.19 | tok/s 18827
step     40 | loss 2.4348 | lr 3.00e-04 | grad 6.00 | tok/s 18034
step     50 | loss 3.0654 | lr 3.00e-04 | grad 12.88 | tok/s 18289
step     60 | loss 2.0976 | lr 3.00e-04 | grad 3.62 | tok/s 18833
step     70 | loss 1.8267 | lr 3.00e-04 | grad 5.59 | tok/s 19010
step     80 | loss 6.4250 | lr 3.00e-04 | grad 50.25 | tok/s 19127
step     90 | loss 5.3724 | lr 3.00e-04 | grad 10.38 | tok/s 19425
step    100 | loss 4.1159 | lr 3.00e-04 | grad 7.53 | tok/s 19414
step    110 | loss 3.4258 | lr 3.00e-04 | grad 14.19 | tok/s 19366
step    120 | loss 3.2154 | lr 3.00e-04 | grad 11.88 | tok/s 19357
step    130 | loss 2.9634 | lr 3.00e-04 | grad 13.94 | tok/s 19317
step    140 | loss 2.8226 | lr 3.00e-04 | grad 9.62 | tok/s 19293
step    150 | loss 2.6796 | lr 3.00e-04 | grad 10.88 | tok/s 19236
step    160 | loss 2.4264 | lr 3.00e-04 | grad 12.44 | tok/s 19243
step    170 | loss 2.4739 | lr 3.00e-04 | grad 12.50 | tok/s 19234
step    180 | loss 2.3538 | lr 3.00e-04 | grad 9.69 | tok/s 19185
step    190 | loss 2.4238 | lr 3.00e-04 | grad 12.12 | tok/s 19194
step    200 | loss 2.1149 | lr 3.00e-04 | grad 5.88 | tok/s 19037
step    210 | loss 2.1792 | lr 3.00e-04 | grad 8.44 | tok/s 19006
step    220 | loss 2.1646 | lr 3.00e-04 | grad 4.38 | tok/s 18761
step    230 | loss 2.1531 | lr 3.00e-04 | grad 4.31 | tok/s 18631
step    240 | loss 2.3032 | lr 3.00e-04 | grad 5.91 | tok/s 17628
step    250 | loss 2.0893 | lr 3.00e-04 | grad 3.22 | tok/s 18052
step    260 | loss 1.5105 | lr 3.00e-04 | grad 3.69 | tok/s 18570
step    270 | loss 2.0755 | lr 3.00e-04 | grad 3.80 | tok/s 16103
step    280 | loss 2.2558 | lr 3.00e-04 | grad 5.62 | tok/s 17875
step    290 | loss 1.4208 | lr 3.00e-04 | grad 25.38 | tok/s 19059
step    300 | loss 0.5769 | lr 3.00e-04 | grad 3.38 | tok/s 19037
step    310 | loss 2.4068 | lr 3.00e-04 | grad 4.78 | tok/s 18712
step    320 | loss 1.9068 | lr 3.00e-04 | grad 6.88 | tok/s 18291
step    330 | loss 1.9422 | lr 3.00e-04 | grad 3.52 | tok/s 16006
step    340 | loss 2.2476 | lr 3.00e-04 | grad 3.73 | tok/s 13533
step    350 | loss 1.8585 | lr 3.00e-04 | grad 4.19 | tok/s 18377
step    360 | loss 1.1990 | lr 3.00e-04 | grad 8.38 | tok/s 17753
step    370 | loss 1.7856 | lr 3.00e-04 | grad 3.03 | tok/s 16293
step    380 | loss 1.7446 | lr 3.00e-04 | grad 3.41 | tok/s 17359
step    390 | loss 1.5165 | lr 3.00e-04 | grad 2.73 | tok/s 18806
step    400 | loss 1.4765 | lr 3.00e-04 | grad 3.11 | tok/s 18857
step    410 | loss 1.2626 | lr 3.00e-04 | grad 2.50 | tok/s 18205
step    420 | loss 1.7987 | lr 3.00e-04 | grad 5.19 | tok/s 17314
step    430 | loss 2.1582 | lr 3.00e-04 | grad 3.64 | tok/s 18425
step    440 | loss 2.1542 | lr 3.00e-04 | grad 4.47 | tok/s 17616
step    450 | loss 2.0752 | lr 3.00e-04 | grad 3.08 | tok/s 18248
step    460 | loss 1.7184 | lr 3.00e-04 | grad 3.75 | tok/s 17785
step    470 | loss 1.8346 | lr 3.00e-04 | grad 3.23 | tok/s 18273
step    480 | loss 2.2533 | lr 3.00e-04 | grad 7.34 | tok/s 18287
step    490 | loss 1.7811 | lr 3.00e-04 | grad 2.95 | tok/s 17116
step    500 | loss 1.6661 | lr 3.00e-04 | grad 4.28 | tok/s 18162
step    510 | loss 1.6987 | lr 3.00e-04 | grad 2.91 | tok/s 18774
step    520 | loss 1.6483 | lr 3.00e-04 | grad 2.52 | tok/s 18746
step    530 | loss 1.9099 | lr 3.00e-04 | grad 2.72 | tok/s 16433
step    540 | loss 1.7247 | lr 3.00e-04 | grad 2.94 | tok/s 17899
step    550 | loss 1.5652 | lr 3.00e-04 | grad 3.28 | tok/s 12958
step    560 | loss 1.7290 | lr 3.00e-04 | grad 3.08 | tok/s 17313
step    570 | loss 1.6633 | lr 3.00e-04 | grad 3.89 | tok/s 16849
step    580 | loss 1.5439 | lr 3.00e-04 | grad 2.80 | tok/s 17300
step    590 | loss 1.8577 | lr 3.00e-04 | grad 3.59 | tok/s 17917
step    600 | loss 1.8381 | lr 3.00e-04 | grad 2.55 | tok/s 17465
step    610 | loss 1.6184 | lr 3.00e-04 | grad 2.84 | tok/s 18474
step    620 | loss 1.5466 | lr 3.00e-04 | grad 2.75 | tok/s 17441
step    630 | loss 1.6571 | lr 3.00e-04 | grad 5.19 | tok/s 17406
step    640 | loss 1.8192 | lr 3.00e-04 | grad 2.81 | tok/s 17430
step    650 | loss 1.6722 | lr 3.00e-04 | grad 3.27 | tok/s 17565
step    660 | loss 1.6924 | lr 3.00e-04 | grad 2.66 | tok/s 18122
step    670 | loss 1.9231 | lr 3.00e-04 | grad 12.00 | tok/s 18305
step    680 | loss 1.7264 | lr 3.00e-04 | grad 2.73 | tok/s 17905
step    690 | loss 1.8315 | lr 3.00e-04 | grad 3.98 | tok/s 17415
step    700 | loss 1.4040 | lr 3.00e-04 | grad 3.34 | tok/s 18691
step    710 | loss 1.5910 | lr 3.00e-04 | grad 2.83 | tok/s 17457
step    720 | loss 1.4731 | lr 3.00e-04 | grad 3.56 | tok/s 17243
step    730 | loss 1.2830 | lr 3.00e-04 | grad 3.28 | tok/s 18747
step    740 | loss 1.4971 | lr 3.00e-04 | grad 2.67 | tok/s 18155
step    750 | loss 1.2007 | lr 3.00e-04 | grad 2.89 | tok/s 18870
step    760 | loss 1.1070 | lr 3.00e-04 | grad 2.28 | tok/s 18852
step    770 | loss 1.0591 | lr 3.00e-04 | grad 2.38 | tok/s 17520
step    780 | loss 1.0009 | lr 3.00e-04 | grad 2.34 | tok/s 12175
step    790 | loss 1.1318 | lr 3.00e-04 | grad 3.75 | tok/s 17303
step    800 | loss 1.8214 | lr 3.00e-04 | grad 6.09 | tok/s 18155
step    810 | loss 1.7119 | lr 3.00e-04 | grad 2.58 | tok/s 18140
step    820 | loss 1.7182 | lr 3.00e-04 | grad 4.59 | tok/s 17378
step    830 | loss 1.4915 | lr 3.00e-04 | grad 2.52 | tok/s 18560
step    840 | loss 1.3394 | lr 3.00e-04 | grad 2.44 | tok/s 18628
step    850 | loss 1.5868 | lr 3.00e-04 | grad 2.59 | tok/s 18566
step    860 | loss 1.4670 | lr 3.00e-04 | grad 4.59 | tok/s 16546
step    870 | loss 1.5007 | lr 3.00e-04 | grad 3.12 | tok/s 15787
step    880 | loss 1.6842 | lr 3.00e-04 | grad 2.75 | tok/s 16958
step    890 | loss 1.6937 | lr 3.00e-04 | grad 3.42 | tok/s 16340
step    900 | loss 1.5705 | lr 3.00e-04 | grad 2.95 | tok/s 18275
step    910 | loss 1.4487 | lr 3.00e-04 | grad 2.73 | tok/s 12215
step    920 | loss 1.5644 | lr 3.00e-04 | grad 4.09 | tok/s 15974
step    930 | loss 1.5540 | lr 3.00e-04 | grad 2.33 | tok/s 17209
step    940 | loss 1.3703 | lr 3.00e-04 | grad 2.45 | tok/s 18548
step    950 | loss 1.5562 | lr 3.00e-04 | grad 3.08 | tok/s 18762
step    960 | loss 1.3665 | lr 3.00e-04 | grad 2.77 | tok/s 17208
step    970 | loss 1.8275 | lr 3.00e-04 | grad 4.22 | tok/s 16000
step    980 | loss 1.5796 | lr 3.00e-04 | grad 2.69 | tok/s 17571
step    990 | loss 1.4752 | lr 3.00e-04 | grad 2.41 | tok/s 18021
step   1000 | loss 1.8771 | lr 3.00e-04 | grad 5.78 | tok/s 17831
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8771.pt
step   1010 | loss 1.7115 | lr 3.00e-04 | grad 3.09 | tok/s 3280
step   1020 | loss 1.4510 | lr 3.00e-04 | grad 2.83 | tok/s 12172
step   1030 | loss 1.4716 | lr 3.00e-04 | grad 3.48 | tok/s 16135
step   1040 | loss 1.4908 | lr 3.00e-04 | grad 2.73 | tok/s 17321
step   1050 | loss 1.7224 | lr 3.00e-04 | grad 3.39 | tok/s 9784
step   1060 | loss 1.7164 | lr 3.00e-04 | grad 3.23 | tok/s 9319
step   1070 | loss 1.5165 | lr 3.00e-04 | grad 2.91 | tok/s 13319
step   1080 | loss 1.3084 | lr 3.00e-04 | grad 2.03 | tok/s 17600
step   1090 | loss 1.1561 | lr 3.00e-04 | grad 3.28 | tok/s 18725
step   1100 | loss 1.5394 | lr 3.00e-04 | grad 2.56 | tok/s 15651
step   1110 | loss 1.3527 | lr 3.00e-04 | grad 2.42 | tok/s 10140
step   1120 | loss 1.3160 | lr 3.00e-04 | grad 2.45 | tok/s 12862
step   1130 | loss 1.2558 | lr 3.00e-04 | grad 2.14 | tok/s 15961
step   1140 | loss 1.3226 | lr 3.00e-04 | grad 2.28 | tok/s 16833
step   1150 | loss 1.2226 | lr 3.00e-04 | grad 2.20 | tok/s 11788
step   1160 | loss 1.2271 | lr 3.00e-04 | grad 2.02 | tok/s 13999
step   1170 | loss 1.3399 | lr 3.00e-04 | grad 2.67 | tok/s 19027
step   1180 | loss 1.2346 | lr 3.00e-04 | grad 2.53 | tok/s 19045
step   1190 | loss 1.1900 | lr 3.00e-04 | grad 2.33 | tok/s 18340
step   1200 | loss 1.2612 | lr 3.00e-04 | grad 2.16 | tok/s 17803
step   1210 | loss 1.3011 | lr 3.00e-04 | grad 2.30 | tok/s 18126
step   1220 | loss 1.2361 | lr 3.00e-04 | grad 2.50 | tok/s 18969
step   1230 | loss 1.2572 | lr 3.00e-04 | grad 2.34 | tok/s 19062
step   1240 | loss 1.7183 | lr 3.00e-04 | grad 3.75 | tok/s 18426
step   1250 | loss 1.6381 | lr 3.00e-04 | grad 2.89 | tok/s 16954
step   1260 | loss 1.3973 | lr 3.00e-04 | grad 2.56 | tok/s 18035
step   1270 | loss 1.7617 | lr 3.00e-04 | grad 2.64 | tok/s 17346
step   1280 | loss 1.4748 | lr 3.00e-04 | grad 2.62 | tok/s 18021
step   1290 | loss 1.5128 | lr 3.00e-04 | grad 5.41 | tok/s 14660
step   1300 | loss 1.4361 | lr 3.00e-04 | grad 2.50 | tok/s 17072
step   1310 | loss 1.5645 | lr 3.00e-04 | grad 2.39 | tok/s 18667
step   1320 | loss 1.7526 | lr 3.00e-04 | grad 9.38 | tok/s 18894
step   1330 | loss 1.2563 | lr 3.00e-04 | grad 3.12 | tok/s 9798
step   1340 | loss 1.8091 | lr 3.00e-04 | grad 4.50 | tok/s 8520
step   1350 | loss 1.5815 | lr 3.00e-04 | grad 2.95 | tok/s 13270
step   1360 | loss 1.4378 | lr 3.00e-04 | grad 2.89 | tok/s 17757
step   1370 | loss 1.6474 | lr 3.00e-04 | grad 2.86 | tok/s 16271
step   1380 | loss 1.5349 | lr 3.00e-04 | grad 2.31 | tok/s 13454
step   1390 | loss 1.4973 | lr 3.00e-04 | grad 3.47 | tok/s 16553
step   1400 | loss 1.3642 | lr 3.00e-04 | grad 2.58 | tok/s 18154
step   1410 | loss 1.6683 | lr 3.00e-04 | grad 8.31 | tok/s 17621
step   1420 | loss 1.4112 | lr 3.00e-04 | grad 2.30 | tok/s 18457
step   1430 | loss 1.2616 | lr 3.00e-04 | grad 2.34 | tok/s 18318
step   1440 | loss 1.1142 | lr 3.00e-04 | grad 2.05 | tok/s 15820
step   1450 | loss 1.5989 | lr 3.00e-04 | grad 3.09 | tok/s 14963
step   1460 | loss 1.5705 | lr 3.00e-04 | grad 2.27 | tok/s 11828
step   1470 | loss 1.6558 | lr 3.00e-04 | grad 4.78 | tok/s 17515
step   1480 | loss 1.7472 | lr 3.00e-04 | grad 3.39 | tok/s 18992
step   1490 | loss 1.3645 | lr 3.00e-04 | grad 2.28 | tok/s 19100
step   1500 | loss 1.5016 | lr 3.00e-04 | grad 3.20 | tok/s 16256
step   1510 | loss 1.4210 | lr 3.00e-04 | grad 2.23 | tok/s 12993
step   1520 | loss 1.5011 | lr 3.00e-04 | grad 2.03 | tok/s 9267
step   1530 | loss 1.5477 | lr 3.00e-04 | grad 2.70 | tok/s 14120
step   1540 | loss 1.4215 | lr 3.00e-04 | grad 2.48 | tok/s 17963
step   1550 | loss 1.4986 | lr 3.00e-04 | grad 7.81 | tok/s 18052
step   1560 | loss 1.3698 | lr 3.00e-04 | grad 2.03 | tok/s 16552
step   1570 | loss 1.5320 | lr 3.00e-04 | grad 4.09 | tok/s 17073
step   1580 | loss 1.6592 | lr 3.00e-04 | grad 2.97 | tok/s 16309
step   1590 | loss 1.2437 | lr 3.00e-04 | grad 2.16 | tok/s 17762
step   1600 | loss 0.8889 | lr 3.00e-04 | grad 2.64 | tok/s 18250
step   1610 | loss 1.3660 | lr 3.00e-04 | grad 3.86 | tok/s 17036
step   1620 | loss 1.4521 | lr 3.00e-04 | grad 3.41 | tok/s 18617
step   1630 | loss 1.2317 | lr 3.00e-04 | grad 2.44 | tok/s 18800
step   1640 | loss 1.5776 | lr 3.00e-04 | grad 3.17 | tok/s 16890
step   1650 | loss 1.4788 | lr 3.00e-04 | grad 2.14 | tok/s 17598
step   1660 | loss 1.2116 | lr 3.00e-04 | grad 3.28 | tok/s 18139
step   1670 | loss 1.8528 | lr 3.00e-04 | grad 3.86 | tok/s 17396
step   1680 | loss 1.4711 | lr 3.00e-04 | grad 3.70 | tok/s 17780
step   1690 | loss 1.4768 | lr 3.00e-04 | grad 3.06 | tok/s 18078
step   1700 | loss 1.4108 | lr 3.00e-04 | grad 4.47 | tok/s 17438
step   1710 | loss 1.5754 | lr 3.00e-04 | grad 4.12 | tok/s 12678
step   1720 | loss 1.3092 | lr 3.00e-04 | grad 4.22 | tok/s 14527
step   1730 | loss 1.1704 | lr 3.00e-04 | grad 2.89 | tok/s 14190
step   1740 | loss 1.5613 | lr 3.00e-04 | grad 4.78 | tok/s 17031
step   1750 | loss 1.5507 | lr 3.00e-04 | grad 4.00 | tok/s 6925
step   1760 | loss 1.5767 | lr 3.00e-04 | grad 2.36 | tok/s 15095
step   1770 | loss 1.4822 | lr 3.00e-04 | grad 2.69 | tok/s 13104
step   1780 | loss 1.4759 | lr 3.00e-04 | grad 2.81 | tok/s 17606
step   1790 | loss 1.4363 | lr 3.00e-04 | grad 2.80 | tok/s 14338
step   1800 | loss 1.5683 | lr 3.00e-04 | grad 2.42 | tok/s 17766
step   1810 | loss 1.4574 | lr 3.00e-04 | grad 2.23 | tok/s 17735
step   1820 | loss 1.5017 | lr 3.00e-04 | grad 4.78 | tok/s 18584
step   1830 | loss 1.5868 | lr 3.00e-04 | grad 2.23 | tok/s 17869
step   1840 | loss 1.3837 | lr 3.00e-04 | grad 2.39 | tok/s 18509
step   1850 | loss 1.2552 | lr 3.00e-04 | grad 2.34 | tok/s 18656
step   1860 | loss 1.4594 | lr 3.00e-04 | grad 2.67 | tok/s 17322
step   1870 | loss 1.1727 | lr 3.00e-04 | grad 2.55 | tok/s 17601
step   1880 | loss 1.5145 | lr 3.00e-04 | grad 3.27 | tok/s 14715
step   1890 | loss 1.4470 | lr 3.00e-04 | grad 2.25 | tok/s 12561
step   1900 | loss 1.4480 | lr 3.00e-04 | grad 3.11 | tok/s 12555
step   1910 | loss 1.4383 | lr 3.00e-04 | grad 2.20 | tok/s 15305
step   1920 | loss 1.4102 | lr 3.00e-04 | grad 2.67 | tok/s 13363
step   1930 | loss 1.4552 | lr 3.00e-04 | grad 2.48 | tok/s 15662
step   1940 | loss 1.8801 | lr 3.00e-04 | grad 5.12 | tok/s 18433
step   1950 | loss 1.5042 | lr 3.00e-04 | grad 3.72 | tok/s 14781
step   1960 | loss 1.5175 | lr 3.00e-04 | grad 3.16 | tok/s 12089
step   1970 | loss 1.5267 | lr 3.00e-04 | grad 3.52 | tok/s 14380
step   1980 | loss 1.4114 | lr 3.00e-04 | grad 3.77 | tok/s 15967
step   1990 | loss 1.7121 | lr 3.00e-04 | grad 2.91 | tok/s 17627
step   2000 | loss 1.3401 | lr 3.00e-04 | grad 6.97 | tok/s 16869
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3401.pt
step   2010 | loss 1.2465 | lr 3.00e-04 | grad 2.55 | tok/s 4750
step   2020 | loss 1.0950 | lr 3.00e-04 | grad 1.02 | tok/s 12400
step   2030 | loss 1.2324 | lr 3.00e-04 | grad 2.38 | tok/s 9282
step   2040 | loss 1.1990 | lr 3.00e-04 | grad 2.72 | tok/s 14613
step   2050 | loss 1.5766 | lr 3.00e-04 | grad 2.66 | tok/s 13080
step   2060 | loss 1.6794 | lr 3.00e-04 | grad 3.36 | tok/s 14815
step   2070 | loss 2.2772 | lr 3.00e-04 | grad 5.53 | tok/s 15057
step   2080 | loss 1.7264 | lr 3.00e-04 | grad 4.50 | tok/s 8237
step   2090 | loss 1.3994 | lr 3.00e-04 | grad 3.08 | tok/s 13765
step   2100 | loss 1.5517 | lr 3.00e-04 | grad 25.88 | tok/s 13854
step   2110 | loss 0.9403 | lr 3.00e-04 | grad 2.48 | tok/s 18728
step   2120 | loss 1.0580 | lr 3.00e-04 | grad 4.25 | tok/s 18896
step   2130 | loss 1.5699 | lr 3.00e-04 | grad 2.53 | tok/s 14658
step   2140 | loss 1.3011 | lr 3.00e-04 | grad 2.59 | tok/s 18884
step   2150 | loss 1.1981 | lr 3.00e-04 | grad 2.00 | tok/s 18897
step   2160 | loss 1.2476 | lr 3.00e-04 | grad 1.85 | tok/s 19059
step   2170 | loss 1.1968 | lr 3.00e-04 | grad 2.45 | tok/s 19054
step   2180 | loss 1.2133 | lr 3.00e-04 | grad 2.34 | tok/s 19119
step   2190 | loss 1.1999 | lr 3.00e-04 | grad 2.20 | tok/s 18895
step   2200 | loss 1.1495 | lr 3.00e-04 | grad 1.94 | tok/s 17938
step   2210 | loss 1.1456 | lr 3.00e-04 | grad 2.14 | tok/s 18435
step   2220 | loss 1.3656 | lr 3.00e-04 | grad 2.31 | tok/s 18557
step   2230 | loss 1.3296 | lr 3.00e-04 | grad 2.39 | tok/s 18705
step   2240 | loss 1.5530 | lr 3.00e-04 | grad 3.47 | tok/s 18207
step   2250 | loss 1.5984 | lr 3.00e-04 | grad 2.73 | tok/s 18458
step   2260 | loss 1.9466 | lr 3.00e-04 | grad 3.39 | tok/s 18512
step   2270 | loss 1.4800 | lr 3.00e-04 | grad 2.84 | tok/s 18678
step   2280 | loss 1.2801 | lr 3.00e-04 | grad 3.27 | tok/s 18250
step   2290 | loss 1.6783 | lr 3.00e-04 | grad 6.72 | tok/s 18621
step   2300 | loss 1.4118 | lr 3.00e-04 | grad 2.16 | tok/s 17700
step   2310 | loss 1.6372 | lr 3.00e-04 | grad 6.16 | tok/s 17668
step   2320 | loss 1.8449 | lr 3.00e-04 | grad 2.97 | tok/s 18083
step   2330 | loss 1.4614 | lr 3.00e-04 | grad 7.03 | tok/s 17619
step   2340 | loss 1.3485 | lr 3.00e-04 | grad 5.31 | tok/s 18405
step   2350 | loss 1.3130 | lr 3.00e-04 | grad 2.80 | tok/s 18495
step   2360 | loss 1.4768 | lr 3.00e-04 | grad 4.19 | tok/s 18422
step   2370 | loss 1.4932 | lr 3.00e-04 | grad 2.67 | tok/s 18792

Training complete! Final step: 2378
