Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_22/levelE88_100m_20260127_170817
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 486,501,416 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2859 | lr 3.00e-04 | grad 19.38 | tok/s 5911
step     20 | loss 3.1640 | lr 3.00e-04 | grad 12.25 | tok/s 18030
step     30 | loss 2.7670 | lr 3.00e-04 | grad 9.06 | tok/s 18219
step     40 | loss 2.5891 | lr 3.00e-04 | grad 7.09 | tok/s 17449
step     50 | loss 3.1895 | lr 3.00e-04 | grad 17.12 | tok/s 17666
step     60 | loss 2.1574 | lr 3.00e-04 | grad 5.31 | tok/s 18136
step     70 | loss 1.8636 | lr 3.00e-04 | grad 5.72 | tok/s 18435
step     80 | loss 6.4379 | lr 3.00e-04 | grad 57.75 | tok/s 18560
step     90 | loss 5.4143 | lr 3.00e-04 | grad 8.88 | tok/s 18864
step    100 | loss 4.1391 | lr 3.00e-04 | grad 6.81 | tok/s 18810
step    110 | loss 3.4561 | lr 3.00e-04 | grad 17.50 | tok/s 18771
step    120 | loss 3.1582 | lr 3.00e-04 | grad 10.31 | tok/s 18752
step    130 | loss 3.0897 | lr 3.00e-04 | grad 15.12 | tok/s 18726
step    140 | loss 2.7735 | lr 3.00e-04 | grad 10.62 | tok/s 18740
step    150 | loss 2.8092 | lr 3.00e-04 | grad 12.44 | tok/s 18712
step    160 | loss 2.5448 | lr 3.00e-04 | grad 12.81 | tok/s 18680
step    170 | loss 2.6007 | lr 3.00e-04 | grad 15.19 | tok/s 18672
step    180 | loss 2.3924 | lr 3.00e-04 | grad 11.56 | tok/s 18650
step    190 | loss 2.5451 | lr 3.00e-04 | grad 16.50 | tok/s 18637
step    200 | loss 2.1769 | lr 3.00e-04 | grad 5.56 | tok/s 18487
step    210 | loss 2.2612 | lr 3.00e-04 | grad 8.62 | tok/s 18492
step    220 | loss 2.2161 | lr 3.00e-04 | grad 4.75 | tok/s 18332
step    230 | loss 2.0822 | lr 3.00e-04 | grad 4.97 | tok/s 18054
step    240 | loss 2.3156 | lr 3.00e-04 | grad 5.53 | tok/s 17149
step    250 | loss 2.1033 | lr 3.00e-04 | grad 3.27 | tok/s 17624
step    260 | loss 1.5282 | lr 3.00e-04 | grad 3.56 | tok/s 18028
step    270 | loss 2.0880 | lr 3.00e-04 | grad 3.30 | tok/s 17712
step    280 | loss 2.2592 | lr 3.00e-04 | grad 7.09 | tok/s 17634
step    290 | loss 1.4297 | lr 3.00e-04 | grad 4.03 | tok/s 18550
step    300 | loss 0.5951 | lr 3.00e-04 | grad 3.41 | tok/s 18526
step    310 | loss 2.4152 | lr 3.00e-04 | grad 4.66 | tok/s 18167
step    320 | loss 1.9130 | lr 3.00e-04 | grad 6.56 | tok/s 17738
step    330 | loss 1.9383 | lr 3.00e-04 | grad 3.41 | tok/s 17074
step    340 | loss 2.2831 | lr 3.00e-04 | grad 3.48 | tok/s 17357
step    350 | loss 1.8328 | lr 3.00e-04 | grad 4.62 | tok/s 18000
step    360 | loss 1.1797 | lr 3.00e-04 | grad 9.56 | tok/s 18075
step    370 | loss 1.7916 | lr 3.00e-04 | grad 2.97 | tok/s 16412
step    380 | loss 1.7461 | lr 3.00e-04 | grad 3.22 | tok/s 17547
step    390 | loss 1.5213 | lr 3.00e-04 | grad 2.78 | tok/s 18487
step    400 | loss 1.4793 | lr 3.00e-04 | grad 3.50 | tok/s 18319
step    410 | loss 1.2554 | lr 3.00e-04 | grad 2.42 | tok/s 17769
step    420 | loss 1.8132 | lr 3.00e-04 | grad 5.12 | tok/s 16936
step    430 | loss 2.1616 | lr 3.00e-04 | grad 3.67 | tok/s 18176
step    440 | loss 2.1517 | lr 3.00e-04 | grad 4.47 | tok/s 17229
step    450 | loss 2.0535 | lr 3.00e-04 | grad 3.03 | tok/s 17818
step    460 | loss 1.7188 | lr 3.00e-04 | grad 3.70 | tok/s 17291
step    470 | loss 1.8290 | lr 3.00e-04 | grad 3.27 | tok/s 17919
step    480 | loss 2.2237 | lr 3.00e-04 | grad 7.19 | tok/s 17893
step    490 | loss 1.7954 | lr 3.00e-04 | grad 2.88 | tok/s 16746
step    500 | loss 1.6724 | lr 3.00e-04 | grad 4.41 | tok/s 18139
step    510 | loss 1.7050 | lr 3.00e-04 | grad 3.12 | tok/s 18415
step    520 | loss 1.6505 | lr 3.00e-04 | grad 2.67 | tok/s 18333
step    530 | loss 1.8992 | lr 3.00e-04 | grad 2.69 | tok/s 17602
step    540 | loss 1.7361 | lr 3.00e-04 | grad 2.91 | tok/s 17526
step    550 | loss 1.5676 | lr 3.00e-04 | grad 3.38 | tok/s 12921
step    560 | loss 1.7149 | lr 3.00e-04 | grad 3.17 | tok/s 16888
step    570 | loss 1.6584 | lr 3.00e-04 | grad 4.06 | tok/s 17198
step    580 | loss 1.5426 | lr 3.00e-04 | grad 2.78 | tok/s 17168
step    590 | loss 1.8553 | lr 3.00e-04 | grad 3.48 | tok/s 17608
step    600 | loss 1.8244 | lr 3.00e-04 | grad 2.62 | tok/s 17121
step    610 | loss 1.6177 | lr 3.00e-04 | grad 2.92 | tok/s 17994
step    620 | loss 1.5454 | lr 3.00e-04 | grad 2.84 | tok/s 16889
step    630 | loss 1.6463 | lr 3.00e-04 | grad 5.00 | tok/s 17062
step    640 | loss 1.8065 | lr 3.00e-04 | grad 2.72 | tok/s 17499
step    650 | loss 1.6798 | lr 3.00e-04 | grad 3.19 | tok/s 17604
step    660 | loss 1.6964 | lr 3.00e-04 | grad 2.38 | tok/s 17832
step    670 | loss 1.8947 | lr 3.00e-04 | grad 3.58 | tok/s 17943
step    680 | loss 1.7324 | lr 3.00e-04 | grad 2.98 | tok/s 17393
step    690 | loss 1.8198 | lr 3.00e-04 | grad 4.06 | tok/s 17949
step    700 | loss 1.4057 | lr 3.00e-04 | grad 3.41 | tok/s 18305
step    710 | loss 1.5893 | lr 3.00e-04 | grad 2.89 | tok/s 17077
step    720 | loss 1.4787 | lr 3.00e-04 | grad 4.25 | tok/s 16900
step    730 | loss 1.2831 | lr 3.00e-04 | grad 3.27 | tok/s 18262
step    740 | loss 1.4909 | lr 3.00e-04 | grad 2.73 | tok/s 18214
step    750 | loss 1.1907 | lr 3.00e-04 | grad 2.92 | tok/s 18473
step    760 | loss 1.0952 | lr 3.00e-04 | grad 2.44 | tok/s 8938
step    770 | loss 1.0433 | lr 3.00e-04 | grad 2.55 | tok/s 6610
step    780 | loss 0.9896 | lr 3.00e-04 | grad 2.25 | tok/s 18422
step    790 | loss 1.1228 | lr 3.00e-04 | grad 3.86 | tok/s 17418
step    800 | loss 1.8202 | lr 3.00e-04 | grad 6.22 | tok/s 17766
step    810 | loss 1.7083 | lr 3.00e-04 | grad 2.66 | tok/s 13460
step    820 | loss 1.7202 | lr 3.00e-04 | grad 4.75 | tok/s 10576
step    830 | loss 1.4937 | lr 3.00e-04 | grad 2.56 | tok/s 15697
step    840 | loss 1.3420 | lr 3.00e-04 | grad 2.45 | tok/s 18237
step    850 | loss 1.5890 | lr 3.00e-04 | grad 2.55 | tok/s 15994
step    860 | loss 1.4643 | lr 3.00e-04 | grad 4.50 | tok/s 18128
step    870 | loss 1.5003 | lr 3.00e-04 | grad 3.05 | tok/s 17430
step    880 | loss 1.6795 | lr 3.00e-04 | grad 3.14 | tok/s 7473
step    890 | loss 1.6593 | lr 3.00e-04 | grad 2.61 | tok/s 10015
step    900 | loss 1.5678 | lr 3.00e-04 | grad 2.23 | tok/s 12063
step    910 | loss 1.4243 | lr 3.00e-04 | grad 3.09 | tok/s 9019
step    920 | loss 1.6102 | lr 3.00e-04 | grad 3.61 | tok/s 16112
step    930 | loss 1.5228 | lr 3.00e-04 | grad 3.86 | tok/s 16613
step    940 | loss 1.3110 | lr 3.00e-04 | grad 2.05 | tok/s 16839
step    950 | loss 1.5475 | lr 3.00e-04 | grad 2.12 | tok/s 15711
step    960 | loss 1.4261 | lr 3.00e-04 | grad 3.70 | tok/s 17664
step    970 | loss 1.8261 | lr 3.00e-04 | grad 3.73 | tok/s 11654
step    980 | loss 1.5670 | lr 3.00e-04 | grad 3.39 | tok/s 8815
step    990 | loss 1.5550 | lr 3.00e-04 | grad 4.88 | tok/s 18159
step   1000 | loss 1.7670 | lr 3.00e-04 | grad 3.61 | tok/s 17781
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7670.pt
step   1010 | loss 1.6621 | lr 3.00e-04 | grad 3.11 | tok/s 3133
step   1020 | loss 1.4536 | lr 3.00e-04 | grad 2.42 | tok/s 18010
step   1030 | loss 1.4726 | lr 3.00e-04 | grad 2.34 | tok/s 18529
step   1040 | loss 1.5712 | lr 3.00e-04 | grad 5.12 | tok/s 14948
step   1050 | loss 1.7325 | lr 3.00e-04 | grad 4.09 | tok/s 14266
step   1060 | loss 1.6632 | lr 3.00e-04 | grad 3.64 | tok/s 17420
step   1070 | loss 1.4428 | lr 3.00e-04 | grad 3.09 | tok/s 16941
step   1080 | loss 1.1854 | lr 3.00e-04 | grad 2.05 | tok/s 17670
step   1090 | loss 1.3019 | lr 3.00e-04 | grad 2.44 | tok/s 17457
step   1100 | loss 1.5249 | lr 3.00e-04 | grad 3.08 | tok/s 18436
step   1110 | loss 1.3460 | lr 3.00e-04 | grad 2.31 | tok/s 18246
step   1120 | loss 1.2888 | lr 3.00e-04 | grad 2.34 | tok/s 18605
step   1130 | loss 1.2779 | lr 3.00e-04 | grad 2.80 | tok/s 18539
step   1140 | loss 1.3051 | lr 3.00e-04 | grad 2.36 | tok/s 16591
step   1150 | loss 1.2022 | lr 3.00e-04 | grad 2.52 | tok/s 9980
step   1160 | loss 1.2298 | lr 3.00e-04 | grad 2.67 | tok/s 11417
step   1170 | loss 1.3292 | lr 3.00e-04 | grad 1.93 | tok/s 18627
step   1180 | loss 1.2071 | lr 3.00e-04 | grad 2.84 | tok/s 18693
step   1190 | loss 1.2072 | lr 3.00e-04 | grad 2.52 | tok/s 16004
step   1200 | loss 1.2623 | lr 3.00e-04 | grad 2.67 | tok/s 18184
step   1210 | loss 1.2878 | lr 3.00e-04 | grad 2.59 | tok/s 15705
step   1220 | loss 1.2503 | lr 3.00e-04 | grad 2.39 | tok/s 18036
step   1230 | loss 1.2183 | lr 3.00e-04 | grad 1.83 | tok/s 17261
step   1240 | loss 1.7984 | lr 3.00e-04 | grad 4.25 | tok/s 17424
step   1250 | loss 1.3872 | lr 3.00e-04 | grad 3.50 | tok/s 15562
step   1260 | loss 1.6679 | lr 3.00e-04 | grad 6.62 | tok/s 16118
step   1270 | loss 1.6226 | lr 3.00e-04 | grad 2.03 | tok/s 17577
step   1280 | loss 1.4802 | lr 3.00e-04 | grad 2.59 | tok/s 14049
step   1290 | loss 1.5159 | lr 3.00e-04 | grad 2.77 | tok/s 12201
step   1300 | loss 1.4595 | lr 3.00e-04 | grad 3.19 | tok/s 17920
step   1310 | loss 1.5883 | lr 3.00e-04 | grad 2.72 | tok/s 17976
step   1320 | loss 1.6112 | lr 3.00e-04 | grad 3.19 | tok/s 15322
step   1330 | loss 1.4731 | lr 3.00e-04 | grad 10.25 | tok/s 17213
step   1340 | loss 1.7288 | lr 3.00e-04 | grad 3.16 | tok/s 16840
step   1350 | loss 1.4853 | lr 3.00e-04 | grad 3.22 | tok/s 17851
step   1360 | loss 1.4191 | lr 3.00e-04 | grad 2.08 | tok/s 17642
step   1370 | loss 1.6730 | lr 3.00e-04 | grad 2.59 | tok/s 17001
step   1380 | loss 1.5255 | lr 3.00e-04 | grad 2.34 | tok/s 17695
step   1390 | loss 1.4040 | lr 3.00e-04 | grad 1.97 | tok/s 16843
step   1400 | loss 1.4596 | lr 3.00e-04 | grad 3.77 | tok/s 17041
step   1410 | loss 1.6826 | lr 3.00e-04 | grad 5.00 | tok/s 11702
step   1420 | loss 1.3430 | lr 3.00e-04 | grad 2.23 | tok/s 16839
step   1430 | loss 1.1434 | lr 3.00e-04 | grad 2.84 | tok/s 18374
step   1440 | loss 1.1601 | lr 3.00e-04 | grad 5.53 | tok/s 18519
step   1450 | loss 1.6751 | lr 3.00e-04 | grad 2.72 | tok/s 16275
step   1460 | loss 1.5324 | lr 3.00e-04 | grad 2.25 | tok/s 15465
step   1470 | loss 1.8244 | lr 3.00e-04 | grad 4.81 | tok/s 14440
step   1480 | loss 1.5709 | lr 3.00e-04 | grad 2.20 | tok/s 12655
step   1490 | loss 1.3414 | lr 3.00e-04 | grad 2.34 | tok/s 18336
step   1500 | loss 1.5071 | lr 3.00e-04 | grad 2.62 | tok/s 18071
step   1510 | loss 1.4306 | lr 3.00e-04 | grad 5.28 | tok/s 17770
step   1520 | loss 1.4606 | lr 3.00e-04 | grad 2.58 | tok/s 12009
step   1530 | loss 1.6125 | lr 3.00e-04 | grad 2.92 | tok/s 7932
step   1540 | loss 1.2880 | lr 3.00e-04 | grad 2.92 | tok/s 11893
step   1550 | loss 1.5842 | lr 3.00e-04 | grad 3.30 | tok/s 17521
step   1560 | loss 1.2789 | lr 3.00e-04 | grad 3.00 | tok/s 18667
step   1570 | loss 1.6989 | lr 3.00e-04 | grad 4.31 | tok/s 18148
step   1580 | loss 1.5952 | lr 3.00e-04 | grad 2.89 | tok/s 16855
step   1590 | loss 1.0005 | lr 3.00e-04 | grad 1.84 | tok/s 18300
step   1600 | loss 1.0357 | lr 3.00e-04 | grad 3.03 | tok/s 17641
step   1610 | loss 1.3974 | lr 3.00e-04 | grad 3.02 | tok/s 16640
step   1620 | loss 1.3511 | lr 3.00e-04 | grad 3.12 | tok/s 16221
step   1630 | loss 1.3292 | lr 3.00e-04 | grad 2.75 | tok/s 15473
step   1640 | loss 1.5326 | lr 3.00e-04 | grad 2.72 | tok/s 15876
step   1650 | loss 1.3842 | lr 3.00e-04 | grad 2.02 | tok/s 6182
step   1660 | loss 1.3513 | lr 3.00e-04 | grad 6.97 | tok/s 10173
step   1670 | loss 1.7297 | lr 3.00e-04 | grad 2.50 | tok/s 8880
step   1680 | loss 1.4933 | lr 3.00e-04 | grad 4.62 | tok/s 16150
step   1690 | loss 1.5004 | lr 3.00e-04 | grad 2.64 | tok/s 18037
step   1700 | loss 1.4219 | lr 3.00e-04 | grad 2.56 | tok/s 17728
step   1710 | loss 1.5215 | lr 3.00e-04 | grad 3.38 | tok/s 17028
step   1720 | loss 1.2025 | lr 3.00e-04 | grad 3.30 | tok/s 17354
step   1730 | loss 1.3244 | lr 3.00e-04 | grad 2.89 | tok/s 17699
step   1740 | loss 1.5899 | lr 3.00e-04 | grad 3.25 | tok/s 17665
step   1750 | loss 1.5405 | lr 3.00e-04 | grad 2.75 | tok/s 17504
step   1760 | loss 1.4378 | lr 3.00e-04 | grad 3.00 | tok/s 14178
step   1770 | loss 1.5105 | lr 3.00e-04 | grad 2.48 | tok/s 15002
step   1780 | loss 1.3998 | lr 3.00e-04 | grad 2.20 | tok/s 9676
step   1790 | loss 1.6144 | lr 3.00e-04 | grad 2.53 | tok/s 17520
step   1800 | loss 1.4368 | lr 3.00e-04 | grad 2.53 | tok/s 10441
step   1810 | loss 1.4808 | lr 3.00e-04 | grad 6.72 | tok/s 11798
step   1820 | loss 1.4323 | lr 3.00e-04 | grad 2.69 | tok/s 13988
step   1830 | loss 1.5384 | lr 3.00e-04 | grad 3.23 | tok/s 12326
step   1840 | loss 1.2797 | lr 3.00e-04 | grad 2.20 | tok/s 16206
step   1850 | loss 1.3308 | lr 3.00e-04 | grad 2.98 | tok/s 17644
step   1860 | loss 1.4143 | lr 3.00e-04 | grad 3.61 | tok/s 17620
step   1870 | loss 1.2358 | lr 3.00e-04 | grad 2.45 | tok/s 12748
step   1880 | loss 1.5213 | lr 3.00e-04 | grad 2.61 | tok/s 13734
step   1890 | loss 1.3959 | lr 3.00e-04 | grad 3.09 | tok/s 15448
step   1900 | loss 1.4818 | lr 3.00e-04 | grad 3.20 | tok/s 16613
step   1910 | loss 1.3966 | lr 3.00e-04 | grad 2.50 | tok/s 15116
step   1920 | loss 1.4586 | lr 3.00e-04 | grad 2.73 | tok/s 17032
step   1930 | loss 1.4445 | lr 3.00e-04 | grad 2.59 | tok/s 18028
step   1940 | loss 1.8355 | lr 3.00e-04 | grad 4.44 | tok/s 18324
step   1950 | loss 1.4402 | lr 3.00e-04 | grad 4.97 | tok/s 18329
step   1960 | loss 1.5141 | lr 3.00e-04 | grad 2.94 | tok/s 17301
step   1970 | loss 1.5455 | lr 3.00e-04 | grad 2.78 | tok/s 7541
step   1980 | loss 1.6043 | lr 3.00e-04 | grad 3.19 | tok/s 12990
step   1990 | loss 1.5036 | lr 3.00e-04 | grad 3.03 | tok/s 12728
step   2000 | loss 1.0280 | lr 3.00e-04 | grad 3.84 | tok/s 12259
  >>> saved checkpoint: checkpoint_step_002000_loss_1.0280.pt
step   2010 | loss 1.0298 | lr 3.00e-04 | grad 3.11 | tok/s 2247
step   2020 | loss 1.2077 | lr 3.00e-04 | grad 2.27 | tok/s 17008
step   2030 | loss 1.3557 | lr 3.00e-04 | grad 3.44 | tok/s 12887
step   2040 | loss 1.6657 | lr 3.00e-04 | grad 2.89 | tok/s 17659
step   2050 | loss 1.9842 | lr 3.00e-04 | grad 6.53 | tok/s 17850
step   2060 | loss 2.0645 | lr 3.00e-04 | grad 4.50 | tok/s 18701
step   2070 | loss 1.5816 | lr 3.00e-04 | grad 5.06 | tok/s 17683
step   2080 | loss 1.2726 | lr 3.00e-04 | grad 2.48 | tok/s 18320
step   2090 | loss 1.4878 | lr 3.00e-04 | grad 2.19 | tok/s 17284
step   2100 | loss 0.7246 | lr 3.00e-04 | grad 1.70 | tok/s 18774
step   2110 | loss 1.4376 | lr 3.00e-04 | grad 2.75 | tok/s 17633
step   2120 | loss 1.4324 | lr 3.00e-04 | grad 2.88 | tok/s 14682
step   2130 | loss 1.2736 | lr 3.00e-04 | grad 2.30 | tok/s 18549
step   2140 | loss 1.2092 | lr 3.00e-04 | grad 2.27 | tok/s 18495
step   2150 | loss 1.1987 | lr 3.00e-04 | grad 2.20 | tok/s 18567
step   2160 | loss 1.2033 | lr 3.00e-04 | grad 2.34 | tok/s 18555
step   2170 | loss 1.2254 | lr 3.00e-04 | grad 2.05 | tok/s 18532
step   2180 | loss 1.1560 | lr 3.00e-04 | grad 2.05 | tok/s 17736
step   2190 | loss 1.1359 | lr 3.00e-04 | grad 1.98 | tok/s 18088
step   2200 | loss 1.1198 | lr 3.00e-04 | grad 2.00 | tok/s 18310
step   2210 | loss 1.4546 | lr 3.00e-04 | grad 2.56 | tok/s 18143
step   2220 | loss 1.3639 | lr 3.00e-04 | grad 3.48 | tok/s 17727
step   2230 | loss 1.4904 | lr 3.00e-04 | grad 3.62 | tok/s 18405
step   2240 | loss 1.6059 | lr 3.00e-04 | grad 2.30 | tok/s 17897
step   2250 | loss 1.9491 | lr 3.00e-04 | grad 2.59 | tok/s 18187

Training complete! Final step: 2250
