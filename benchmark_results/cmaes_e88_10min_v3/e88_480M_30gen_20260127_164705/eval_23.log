Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_23/levelE88_100m_20260127_170817
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 493,883,008 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 3.9624 | lr 3.00e-04 | grad 10.31 | tok/s 5601
step     20 | loss 2.5976 | lr 3.00e-04 | grad 4.97 | tok/s 14046
step     30 | loss 2.4698 | lr 3.00e-04 | grad 3.42 | tok/s 14138
step     40 | loss 2.3551 | lr 3.00e-04 | grad 3.39 | tok/s 13533
step     50 | loss 2.9025 | lr 3.00e-04 | grad 11.00 | tok/s 13774
step     60 | loss 2.0243 | lr 3.00e-04 | grad 2.67 | tok/s 14140
step     70 | loss 1.8700 | lr 3.00e-04 | grad 4.03 | tok/s 14288
step     80 | loss 5.7735 | lr 3.00e-04 | grad 52.75 | tok/s 14409
step     90 | loss 5.0457 | lr 3.00e-04 | grad 8.00 | tok/s 14580
step    100 | loss 3.9529 | lr 3.00e-04 | grad 6.28 | tok/s 14567
step    110 | loss 3.3266 | lr 3.00e-04 | grad 10.75 | tok/s 14520
step    120 | loss 3.0375 | lr 3.00e-04 | grad 9.19 | tok/s 14467
step    130 | loss 2.8540 | lr 3.00e-04 | grad 11.31 | tok/s 14465
step    140 | loss 2.6267 | lr 3.00e-04 | grad 8.06 | tok/s 14443
step    150 | loss 2.6107 | lr 3.00e-04 | grad 11.44 | tok/s 14415
step    160 | loss 2.2249 | lr 3.00e-04 | grad 7.28 | tok/s 14280
step    170 | loss 2.3237 | lr 3.00e-04 | grad 9.38 | tok/s 14343
step    180 | loss 2.1431 | lr 3.00e-04 | grad 3.91 | tok/s 14272
step    190 | loss 2.2484 | lr 3.00e-04 | grad 6.28 | tok/s 14251
step    200 | loss 1.9702 | lr 3.00e-04 | grad 4.06 | tok/s 14246
step    210 | loss 1.9957 | lr 3.00e-04 | grad 5.19 | tok/s 12901
step    220 | loss 2.1089 | lr 3.00e-04 | grad 2.81 | tok/s 14085
step    230 | loss 2.0175 | lr 3.00e-04 | grad 3.08 | tok/s 13905
step    240 | loss 2.2621 | lr 3.00e-04 | grad 3.92 | tok/s 12679
step    250 | loss 2.0839 | lr 3.00e-04 | grad 2.14 | tok/s 13451
step    260 | loss 1.5403 | lr 3.00e-04 | grad 2.42 | tok/s 12937
step    270 | loss 2.0540 | lr 3.00e-04 | grad 2.30 | tok/s 13824
step    280 | loss 2.2416 | lr 3.00e-04 | grad 4.88 | tok/s 13094
step    290 | loss 1.3606 | lr 3.00e-04 | grad 3.09 | tok/s 14138
step    300 | loss 0.5499 | lr 3.00e-04 | grad 1.89 | tok/s 14214
step    310 | loss 2.4030 | lr 3.00e-04 | grad 3.19 | tok/s 12076
step    320 | loss 1.9721 | lr 3.00e-04 | grad 3.12 | tok/s 9876
step    330 | loss 1.9424 | lr 3.00e-04 | grad 2.34 | tok/s 13346
step    340 | loss 2.2365 | lr 3.00e-04 | grad 2.27 | tok/s 13554
step    350 | loss 1.7890 | lr 3.00e-04 | grad 4.62 | tok/s 13777
step    360 | loss 1.2569 | lr 3.00e-04 | grad 3.84 | tok/s 14140
step    370 | loss 1.7747 | lr 3.00e-04 | grad 2.27 | tok/s 12637
step    380 | loss 1.7433 | lr 3.00e-04 | grad 2.33 | tok/s 13786
step    390 | loss 1.5105 | lr 3.00e-04 | grad 1.93 | tok/s 14251
step    400 | loss 1.4883 | lr 3.00e-04 | grad 2.70 | tok/s 14066
step    410 | loss 1.2869 | lr 3.00e-04 | grad 2.66 | tok/s 13672
step    420 | loss 1.9197 | lr 3.00e-04 | grad 11.56 | tok/s 13185
step    430 | loss 1.9820 | lr 3.00e-04 | grad 1.91 | tok/s 13874
step    440 | loss 2.1559 | lr 3.00e-04 | grad 4.78 | tok/s 13274
step    450 | loss 1.9082 | lr 3.00e-04 | grad 1.80 | tok/s 13522
step    460 | loss 1.6455 | lr 3.00e-04 | grad 2.70 | tok/s 13484
step    470 | loss 1.8542 | lr 3.00e-04 | grad 2.52 | tok/s 13681
step    480 | loss 2.2668 | lr 3.00e-04 | grad 3.84 | tok/s 13787
step    490 | loss 1.7149 | lr 3.00e-04 | grad 1.95 | tok/s 12964
step    500 | loss 1.6940 | lr 3.00e-04 | grad 2.33 | tok/s 13834
step    510 | loss 1.6587 | lr 3.00e-04 | grad 1.98 | tok/s 14071
step    520 | loss 1.6456 | lr 3.00e-04 | grad 1.93 | tok/s 13815
step    530 | loss 1.8942 | lr 3.00e-04 | grad 1.84 | tok/s 13551
step    540 | loss 1.7031 | lr 3.00e-04 | grad 2.03 | tok/s 12573
step    550 | loss 1.5660 | lr 3.00e-04 | grad 2.28 | tok/s 12870
step    560 | loss 1.7051 | lr 3.00e-04 | grad 3.06 | tok/s 12845
step    570 | loss 1.6019 | lr 3.00e-04 | grad 3.69 | tok/s 11246
step    580 | loss 1.5327 | lr 3.00e-04 | grad 1.81 | tok/s 13067
step    590 | loss 1.9068 | lr 3.00e-04 | grad 6.78 | tok/s 5698
step    600 | loss 1.7210 | lr 3.00e-04 | grad 2.27 | tok/s 8600
step    610 | loss 1.5806 | lr 3.00e-04 | grad 2.33 | tok/s 13462
step    620 | loss 1.5895 | lr 3.00e-04 | grad 2.64 | tok/s 12199
step    630 | loss 1.5928 | lr 3.00e-04 | grad 6.47 | tok/s 12771
step    640 | loss 1.9270 | lr 3.00e-04 | grad 2.34 | tok/s 12864
step    650 | loss 1.6224 | lr 3.00e-04 | grad 1.98 | tok/s 13472
step    660 | loss 1.5966 | lr 3.00e-04 | grad 1.88 | tok/s 13397
step    670 | loss 1.9576 | lr 3.00e-04 | grad 2.53 | tok/s 12515
step    680 | loss 1.8020 | lr 3.00e-04 | grad 3.34 | tok/s 9615
step    690 | loss 1.5881 | lr 3.00e-04 | grad 1.77 | tok/s 6259
step    700 | loss 1.5544 | lr 3.00e-04 | grad 2.00 | tok/s 13611
step    710 | loss 1.4380 | lr 3.00e-04 | grad 2.14 | tok/s 9634
step    720 | loss 1.4311 | lr 3.00e-04 | grad 1.45 | tok/s 14162
step    730 | loss 1.4326 | lr 3.00e-04 | grad 1.91 | tok/s 14169
step    740 | loss 1.2398 | lr 3.00e-04 | grad 1.77 | tok/s 13819
step    750 | loss 1.1443 | lr 3.00e-04 | grad 1.79 | tok/s 13595
step    760 | loss 1.0747 | lr 3.00e-04 | grad 1.52 | tok/s 10199
step    770 | loss 1.0144 | lr 3.00e-04 | grad 1.88 | tok/s 7053
step    780 | loss 0.9624 | lr 3.00e-04 | grad 1.68 | tok/s 13330
step    790 | loss 1.5975 | lr 3.00e-04 | grad 3.52 | tok/s 9857
step    800 | loss 1.7839 | lr 3.00e-04 | grad 2.16 | tok/s 10847
step    810 | loss 1.6626 | lr 3.00e-04 | grad 4.53 | tok/s 10054
step    820 | loss 1.5885 | lr 3.00e-04 | grad 2.52 | tok/s 13921
step    830 | loss 1.3468 | lr 3.00e-04 | grad 2.27 | tok/s 13633
step    840 | loss 1.5875 | lr 3.00e-04 | grad 18.50 | tok/s 10966
step    850 | loss 1.4635 | lr 3.00e-04 | grad 2.17 | tok/s 9155
step    860 | loss 1.4963 | lr 3.00e-04 | grad 1.84 | tok/s 13649
step    870 | loss 1.5544 | lr 3.00e-04 | grad 4.47 | tok/s 13438
step    880 | loss 1.6717 | lr 3.00e-04 | grad 2.20 | tok/s 13733
step    890 | loss 1.6152 | lr 3.00e-04 | grad 1.77 | tok/s 13899
step    900 | loss 1.4219 | lr 3.00e-04 | grad 2.30 | tok/s 13544
step    910 | loss 1.4963 | lr 3.00e-04 | grad 2.55 | tok/s 14155
step    920 | loss 1.5160 | lr 3.00e-04 | grad 1.91 | tok/s 13563
step    930 | loss 1.5541 | lr 3.00e-04 | grad 2.31 | tok/s 13782
step    940 | loss 1.4235 | lr 3.00e-04 | grad 2.22 | tok/s 14246
step    950 | loss 1.2663 | lr 3.00e-04 | grad 2.28 | tok/s 14369
step    960 | loss 1.5633 | lr 3.00e-04 | grad 2.05 | tok/s 13258
step    970 | loss 1.7427 | lr 3.00e-04 | grad 1.85 | tok/s 13428
step    980 | loss 1.4433 | lr 3.00e-04 | grad 1.66 | tok/s 12516
step    990 | loss 1.6180 | lr 3.00e-04 | grad 1.99 | tok/s 13481
step   1000 | loss 1.7649 | lr 3.00e-04 | grad 5.62 | tok/s 13879
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7649.pt
step   1010 | loss 1.6266 | lr 3.00e-04 | grad 1.98 | tok/s 3647
step   1020 | loss 1.4453 | lr 3.00e-04 | grad 1.56 | tok/s 11459
step   1030 | loss 1.4571 | lr 3.00e-04 | grad 1.66 | tok/s 14269
step   1040 | loss 1.5515 | lr 3.00e-04 | grad 3.97 | tok/s 13153
step   1050 | loss 1.7006 | lr 3.00e-04 | grad 2.94 | tok/s 13714
step   1060 | loss 1.6633 | lr 3.00e-04 | grad 2.86 | tok/s 14158
step   1070 | loss 1.3945 | lr 3.00e-04 | grad 1.73 | tok/s 10015
step   1080 | loss 1.1018 | lr 3.00e-04 | grad 1.12 | tok/s 14134
step   1090 | loss 1.4196 | lr 3.00e-04 | grad 3.00 | tok/s 13276
step   1100 | loss 1.4449 | lr 3.00e-04 | grad 1.78 | tok/s 12144
step   1110 | loss 1.3186 | lr 3.00e-04 | grad 1.85 | tok/s 11184
step   1120 | loss 1.2728 | lr 3.00e-04 | grad 1.68 | tok/s 13862
step   1130 | loss 1.2651 | lr 3.00e-04 | grad 1.84 | tok/s 14395
step   1140 | loss 1.2790 | lr 3.00e-04 | grad 1.61 | tok/s 14277
step   1150 | loss 1.1978 | lr 3.00e-04 | grad 1.56 | tok/s 13419
step   1160 | loss 1.2216 | lr 3.00e-04 | grad 1.85 | tok/s 9326
step   1170 | loss 1.3188 | lr 3.00e-04 | grad 1.44 | tok/s 7464
step   1180 | loss 1.1987 | lr 3.00e-04 | grad 1.89 | tok/s 14327
step   1190 | loss 1.1981 | lr 3.00e-04 | grad 1.77 | tok/s 13892
step   1200 | loss 1.2494 | lr 3.00e-04 | grad 1.80 | tok/s 13453
step   1210 | loss 1.2703 | lr 3.00e-04 | grad 1.76 | tok/s 13610
step   1220 | loss 1.2358 | lr 3.00e-04 | grad 1.61 | tok/s 14219
step   1230 | loss 1.2000 | lr 3.00e-04 | grad 1.38 | tok/s 14377
step   1240 | loss 1.7394 | lr 3.00e-04 | grad 3.09 | tok/s 13632
step   1250 | loss 1.3918 | lr 3.00e-04 | grad 6.75 | tok/s 13369
step   1260 | loss 1.6364 | lr 3.00e-04 | grad 4.31 | tok/s 13178
step   1270 | loss 1.5841 | lr 3.00e-04 | grad 1.63 | tok/s 13398
step   1280 | loss 1.4561 | lr 3.00e-04 | grad 1.72 | tok/s 10120
step   1290 | loss 1.5011 | lr 3.00e-04 | grad 2.17 | tok/s 13706
step   1300 | loss 1.4376 | lr 3.00e-04 | grad 2.06 | tok/s 10740
step   1310 | loss 1.5576 | lr 3.00e-04 | grad 1.97 | tok/s 12184
step   1320 | loss 1.5696 | lr 3.00e-04 | grad 2.16 | tok/s 12319
step   1330 | loss 1.4693 | lr 3.00e-04 | grad 7.97 | tok/s 11542
step   1340 | loss 1.6962 | lr 3.00e-04 | grad 2.16 | tok/s 9159
step   1350 | loss 1.4711 | lr 3.00e-04 | grad 2.12 | tok/s 13386
step   1360 | loss 1.3946 | lr 3.00e-04 | grad 1.42 | tok/s 13253
step   1370 | loss 1.6080 | lr 3.00e-04 | grad 2.05 | tok/s 12752
step   1380 | loss 1.5009 | lr 3.00e-04 | grad 1.55 | tok/s 13813
step   1390 | loss 1.3826 | lr 3.00e-04 | grad 1.57 | tok/s 13370
step   1400 | loss 1.4298 | lr 3.00e-04 | grad 2.62 | tok/s 13392
step   1410 | loss 1.6338 | lr 3.00e-04 | grad 3.75 | tok/s 13333
step   1420 | loss 1.3295 | lr 3.00e-04 | grad 1.79 | tok/s 13729
step   1430 | loss 1.1229 | lr 3.00e-04 | grad 1.68 | tok/s 9850
step   1440 | loss 1.1452 | lr 3.00e-04 | grad 3.81 | tok/s 8045
step   1450 | loss 1.6226 | lr 3.00e-04 | grad 1.83 | tok/s 8336
step   1460 | loss 1.4962 | lr 3.00e-04 | grad 1.64 | tok/s 10675
step   1470 | loss 1.7771 | lr 3.00e-04 | grad 3.61 | tok/s 13976
step   1480 | loss 1.5327 | lr 3.00e-04 | grad 1.53 | tok/s 12634
step   1490 | loss 1.3203 | lr 3.00e-04 | grad 1.56 | tok/s 11631
step   1500 | loss 1.4868 | lr 3.00e-04 | grad 1.75 | tok/s 9417
step   1510 | loss 1.4071 | lr 3.00e-04 | grad 3.20 | tok/s 9928
step   1520 | loss 1.4241 | lr 3.00e-04 | grad 1.62 | tok/s 10210
step   1530 | loss 1.5895 | lr 3.00e-04 | grad 2.11 | tok/s 9940
step   1540 | loss 1.2712 | lr 3.00e-04 | grad 2.06 | tok/s 12717
step   1550 | loss 1.5542 | lr 3.00e-04 | grad 2.34 | tok/s 12697
step   1560 | loss 1.2616 | lr 3.00e-04 | grad 2.02 | tok/s 9496
step   1570 | loss 1.6683 | lr 3.00e-04 | grad 3.66 | tok/s 7401
step   1580 | loss 1.5657 | lr 3.00e-04 | grad 2.12 | tok/s 6677
step   1590 | loss 0.9736 | lr 3.00e-04 | grad 1.38 | tok/s 5772
step   1600 | loss 1.1709 | lr 3.00e-04 | grad 1.62 | tok/s 11317
step   1610 | loss 1.3202 | lr 3.00e-04 | grad 2.28 | tok/s 12396
step   1620 | loss 1.3502 | lr 3.00e-04 | grad 1.80 | tok/s 13934
step   1630 | loss 1.4344 | lr 3.00e-04 | grad 3.83 | tok/s 13577
step   1640 | loss 1.5422 | lr 3.00e-04 | grad 3.45 | tok/s 12768
step   1650 | loss 1.2224 | lr 3.00e-04 | grad 1.44 | tok/s 14359
step   1660 | loss 1.5708 | lr 3.00e-04 | grad 6.50 | tok/s 11624
step   1670 | loss 1.5255 | lr 3.00e-04 | grad 2.16 | tok/s 13407
step   1680 | loss 1.4273 | lr 3.00e-04 | grad 5.00 | tok/s 13792
step   1690 | loss 1.4850 | lr 3.00e-04 | grad 1.83 | tok/s 13151
step   1700 | loss 1.4172 | lr 3.00e-04 | grad 2.00 | tok/s 13146
step   1710 | loss 1.4668 | lr 3.00e-04 | grad 2.48 | tok/s 13869
step   1720 | loss 1.1606 | lr 3.00e-04 | grad 3.06 | tok/s 9677
step   1730 | loss 1.3691 | lr 3.00e-04 | grad 2.08 | tok/s 11097
step   1740 | loss 1.4925 | lr 3.00e-04 | grad 1.95 | tok/s 13495
step   1750 | loss 1.5679 | lr 3.00e-04 | grad 2.06 | tok/s 12730
step   1760 | loss 1.4127 | lr 3.00e-04 | grad 1.58 | tok/s 9684
step   1770 | loss 1.4669 | lr 3.00e-04 | grad 2.41 | tok/s 12719
step   1780 | loss 1.3989 | lr 3.00e-04 | grad 1.66 | tok/s 10293
step   1790 | loss 1.5345 | lr 3.00e-04 | grad 1.95 | tok/s 12906

Training complete! Final step: 1797
