Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_14/levelE88_100m_20260127_165750
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 481,351,656 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0772 | lr 3.00e-04 | grad 18.00 | tok/s 5253
step     20 | loss 3.0829 | lr 3.00e-04 | grad 15.31 | tok/s 16615
step     30 | loss 2.7896 | lr 3.00e-04 | grad 7.31 | tok/s 16592
step     40 | loss 2.5622 | lr 3.00e-04 | grad 26.12 | tok/s 15791
step     50 | loss 3.1807 | lr 3.00e-04 | grad 14.12 | tok/s 16314
step     60 | loss 2.0417 | lr 3.00e-04 | grad 5.75 | tok/s 16743
step     70 | loss 1.8668 | lr 3.00e-04 | grad 3.55 | tok/s 11628
step     80 | loss 7.0820 | lr 3.00e-04 | grad 128.00 | tok/s 13425
step     90 | loss 5.8386 | lr 3.00e-04 | grad 28.88 | tok/s 17070
step    100 | loss 4.6027 | lr 3.00e-04 | grad 40.50 | tok/s 16848
step    110 | loss 3.8842 | lr 3.00e-04 | grad 33.00 | tok/s 17217
step    120 | loss 3.3031 | lr 3.00e-04 | grad 19.62 | tok/s 15064
step    130 | loss 3.1222 | lr 3.00e-04 | grad 6.66 | tok/s 16772
step    140 | loss 2.8060 | lr 3.00e-04 | grad 17.00 | tok/s 17240
step    150 | loss 2.9203 | lr 3.00e-04 | grad 8.38 | tok/s 17457
step    160 | loss 2.3862 | lr 3.00e-04 | grad 9.06 | tok/s 11822
step    170 | loss 2.5308 | lr 3.00e-04 | grad 12.25 | tok/s 14377
step    180 | loss 2.2901 | lr 3.00e-04 | grad 6.06 | tok/s 13778
step    190 | loss 2.3757 | lr 3.00e-04 | grad 8.06 | tok/s 16812
step    200 | loss 2.1753 | lr 3.00e-04 | grad 10.19 | tok/s 16881
step    210 | loss 2.1374 | lr 3.00e-04 | grad 5.78 | tok/s 17323
step    220 | loss 2.1656 | lr 3.00e-04 | grad 3.86 | tok/s 17105
step    230 | loss 2.1597 | lr 3.00e-04 | grad 3.30 | tok/s 14812
step    240 | loss 2.3277 | lr 3.00e-04 | grad 4.09 | tok/s 16291
step    250 | loss 2.0664 | lr 3.00e-04 | grad 2.77 | tok/s 14841
step    260 | loss 1.5734 | lr 3.00e-04 | grad 3.39 | tok/s 16985
step    270 | loss 2.0838 | lr 3.00e-04 | grad 2.50 | tok/s 16591
step    280 | loss 2.4692 | lr 3.00e-04 | grad 14.38 | tok/s 16545
step    290 | loss 1.1632 | lr 3.00e-04 | grad 2.92 | tok/s 17315
step    300 | loss 0.7606 | lr 3.00e-04 | grad 4.91 | tok/s 17128
step    310 | loss 2.3870 | lr 3.00e-04 | grad 3.84 | tok/s 17263
step    320 | loss 1.9440 | lr 3.00e-04 | grad 3.97 | tok/s 14868
step    330 | loss 1.9798 | lr 3.00e-04 | grad 3.12 | tok/s 13867
step    340 | loss 2.2862 | lr 3.00e-04 | grad 3.17 | tok/s 16155
step    350 | loss 1.7844 | lr 3.00e-04 | grad 5.81 | tok/s 16585
step    360 | loss 1.2839 | lr 3.00e-04 | grad 4.94 | tok/s 17065
step    370 | loss 1.7961 | lr 3.00e-04 | grad 3.09 | tok/s 15381
step    380 | loss 1.7730 | lr 3.00e-04 | grad 3.23 | tok/s 16833
step    390 | loss 1.5312 | lr 3.00e-04 | grad 2.61 | tok/s 17360
step    400 | loss 1.5106 | lr 3.00e-04 | grad 3.64 | tok/s 17227
step    410 | loss 1.3067 | lr 3.00e-04 | grad 3.47 | tok/s 16831
step    420 | loss 1.9526 | lr 3.00e-04 | grad 11.19 | tok/s 14584
step    430 | loss 2.0190 | lr 3.00e-04 | grad 2.47 | tok/s 16975
step    440 | loss 2.1941 | lr 3.00e-04 | grad 6.16 | tok/s 16380
step    450 | loss 2.0108 | lr 3.00e-04 | grad 2.34 | tok/s 16649
step    460 | loss 1.6809 | lr 3.00e-04 | grad 4.38 | tok/s 16538
step    470 | loss 1.8977 | lr 3.00e-04 | grad 3.19 | tok/s 16833
step    480 | loss 2.3313 | lr 3.00e-04 | grad 4.84 | tok/s 16995
step    490 | loss 1.7460 | lr 3.00e-04 | grad 2.52 | tok/s 15705
step    500 | loss 1.7209 | lr 3.00e-04 | grad 2.95 | tok/s 16997
step    510 | loss 1.6861 | lr 3.00e-04 | grad 2.70 | tok/s 17278
step    520 | loss 1.6657 | lr 3.00e-04 | grad 2.56 | tok/s 16965
step    530 | loss 1.9378 | lr 3.00e-04 | grad 2.34 | tok/s 16876
step    540 | loss 1.7323 | lr 3.00e-04 | grad 2.72 | tok/s 16770
step    550 | loss 1.5985 | lr 3.00e-04 | grad 2.89 | tok/s 16054
step    560 | loss 1.7531 | lr 3.00e-04 | grad 4.12 | tok/s 14872
step    570 | loss 1.6440 | lr 3.00e-04 | grad 3.73 | tok/s 16548
step    580 | loss 1.5646 | lr 3.00e-04 | grad 2.41 | tok/s 16123
step    590 | loss 1.8773 | lr 3.00e-04 | grad 3.12 | tok/s 16725
step    600 | loss 1.8198 | lr 3.00e-04 | grad 2.19 | tok/s 16169
step    610 | loss 1.6177 | lr 3.00e-04 | grad 2.58 | tok/s 16490
step    620 | loss 1.6021 | lr 3.00e-04 | grad 2.45 | tok/s 16475
step    630 | loss 1.6327 | lr 3.00e-04 | grad 2.94 | tok/s 16257
step    640 | loss 1.9054 | lr 3.00e-04 | grad 6.91 | tok/s 16430
step    650 | loss 1.6284 | lr 3.00e-04 | grad 3.19 | tok/s 16848
step    660 | loss 1.7127 | lr 3.00e-04 | grad 3.38 | tok/s 16947
step    670 | loss 1.9725 | lr 3.00e-04 | grad 3.61 | tok/s 16905
step    680 | loss 1.7201 | lr 3.00e-04 | grad 3.31 | tok/s 16387
step    690 | loss 1.7765 | lr 3.00e-04 | grad 2.97 | tok/s 17300
step    700 | loss 1.4054 | lr 3.00e-04 | grad 2.70 | tok/s 17438
step    710 | loss 1.6288 | lr 3.00e-04 | grad 3.95 | tok/s 16007
step    720 | loss 1.5110 | lr 3.00e-04 | grad 3.03 | tok/s 16356
step    730 | loss 1.2838 | lr 3.00e-04 | grad 3.33 | tok/s 17414
step    740 | loss 1.4558 | lr 3.00e-04 | grad 2.48 | tok/s 17182
step    750 | loss 1.2128 | lr 3.00e-04 | grad 2.08 | tok/s 17432
step    760 | loss 1.1069 | lr 3.00e-04 | grad 1.88 | tok/s 17372
step    770 | loss 1.0711 | lr 3.00e-04 | grad 2.20 | tok/s 17433
step    780 | loss 0.9762 | lr 3.00e-04 | grad 2.09 | tok/s 17392
step    790 | loss 1.1896 | lr 3.00e-04 | grad 2.91 | tok/s 16706
step    800 | loss 1.9052 | lr 3.00e-04 | grad 5.66 | tok/s 17041
step    810 | loss 1.6715 | lr 3.00e-04 | grad 5.50 | tok/s 16474
step    820 | loss 1.7008 | lr 3.00e-04 | grad 10.81 | tok/s 16319
step    830 | loss 1.4464 | lr 3.00e-04 | grad 2.50 | tok/s 17233
step    840 | loss 1.4258 | lr 3.00e-04 | grad 4.28 | tok/s 17389
step    850 | loss 1.5815 | lr 3.00e-04 | grad 4.19 | tok/s 17131
step    860 | loss 1.4691 | lr 3.00e-04 | grad 2.81 | tok/s 17069
step    870 | loss 1.5163 | lr 3.00e-04 | grad 2.42 | tok/s 16745
step    880 | loss 1.7259 | lr 3.00e-04 | grad 2.98 | tok/s 16629
step    890 | loss 1.6423 | lr 3.00e-04 | grad 2.16 | tok/s 16674
step    900 | loss 1.5865 | lr 3.00e-04 | grad 2.05 | tok/s 16683
step    910 | loss 1.4443 | lr 3.00e-04 | grad 2.73 | tok/s 16815
step    920 | loss 1.5815 | lr 3.00e-04 | grad 3.95 | tok/s 17128
step    930 | loss 1.5594 | lr 3.00e-04 | grad 2.03 | tok/s 16179
step    940 | loss 1.3798 | lr 3.00e-04 | grad 2.27 | tok/s 17409
step    950 | loss 1.5236 | lr 3.00e-04 | grad 2.62 | tok/s 17323
step    960 | loss 1.3405 | lr 3.00e-04 | grad 2.39 | tok/s 17205
step    970 | loss 1.8409 | lr 3.00e-04 | grad 3.83 | tok/s 16414
step    980 | loss 1.5863 | lr 3.00e-04 | grad 2.62 | tok/s 16645
step    990 | loss 1.4790 | lr 3.00e-04 | grad 2.16 | tok/s 16128
step   1000 | loss 1.8857 | lr 3.00e-04 | grad 6.81 | tok/s 16534
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8857.pt
step   1010 | loss 1.7227 | lr 3.00e-04 | grad 2.53 | tok/s 6903
step   1020 | loss 1.6919 | lr 3.00e-04 | grad 2.80 | tok/s 16026
step   1030 | loss 1.4203 | lr 3.00e-04 | grad 1.92 | tok/s 16697
step   1040 | loss 1.5384 | lr 3.00e-04 | grad 4.31 | tok/s 17006
step   1050 | loss 1.6200 | lr 3.00e-04 | grad 2.44 | tok/s 16031
step   1060 | loss 1.7123 | lr 3.00e-04 | grad 2.48 | tok/s 17141
step   1070 | loss 1.6588 | lr 3.00e-04 | grad 3.56 | tok/s 16882
step   1080 | loss 1.4138 | lr 3.00e-04 | grad 2.64 | tok/s 14834
step   1090 | loss 1.0100 | lr 3.00e-04 | grad 2.05 | tok/s 16805
step   1100 | loss 1.5832 | lr 3.00e-04 | grad 3.00 | tok/s 16554
step   1110 | loss 1.4309 | lr 3.00e-04 | grad 2.22 | tok/s 17098
step   1120 | loss 1.3397 | lr 3.00e-04 | grad 2.36 | tok/s 17177
step   1130 | loss 1.2867 | lr 3.00e-04 | grad 2.27 | tok/s 16884
step   1140 | loss 1.2946 | lr 3.00e-04 | grad 2.05 | tok/s 17267
step   1150 | loss 1.2971 | lr 3.00e-04 | grad 2.16 | tok/s 17398
step   1160 | loss 1.2141 | lr 3.00e-04 | grad 2.16 | tok/s 17202
step   1170 | loss 1.2587 | lr 3.00e-04 | grad 2.28 | tok/s 17113
step   1180 | loss 1.3146 | lr 3.00e-04 | grad 1.87 | tok/s 17016
step   1190 | loss 1.2193 | lr 3.00e-04 | grad 2.41 | tok/s 15044
step   1200 | loss 1.2221 | lr 3.00e-04 | grad 2.03 | tok/s 16213
step   1210 | loss 1.2624 | lr 3.00e-04 | grad 1.80 | tok/s 16174
step   1220 | loss 1.2850 | lr 3.00e-04 | grad 1.99 | tok/s 17121
step   1230 | loss 1.2587 | lr 3.00e-04 | grad 1.79 | tok/s 17077
step   1240 | loss 1.2661 | lr 3.00e-04 | grad 2.94 | tok/s 16742
step   1250 | loss 1.8140 | lr 3.00e-04 | grad 2.61 | tok/s 16234
step   1260 | loss 1.3344 | lr 3.00e-04 | grad 3.58 | tok/s 16191
step   1270 | loss 1.7728 | lr 3.00e-04 | grad 2.92 | tok/s 16270
step   1280 | loss 1.5865 | lr 3.00e-04 | grad 2.66 | tok/s 16933
step   1290 | loss 1.5012 | lr 3.00e-04 | grad 2.86 | tok/s 16574
step   1300 | loss 1.5224 | lr 3.00e-04 | grad 2.28 | tok/s 16533
step   1310 | loss 1.4647 | lr 3.00e-04 | grad 2.08 | tok/s 17280
step   1320 | loss 1.5972 | lr 3.00e-04 | grad 2.52 | tok/s 17124
step   1330 | loss 1.5357 | lr 3.00e-04 | grad 2.31 | tok/s 17144
step   1340 | loss 1.5878 | lr 3.00e-04 | grad 3.48 | tok/s 16176
step   1350 | loss 1.7350 | lr 3.00e-04 | grad 2.52 | tok/s 16039
step   1360 | loss 1.4857 | lr 3.00e-04 | grad 1.94 | tok/s 16818
step   1370 | loss 1.5264 | lr 3.00e-04 | grad 7.25 | tok/s 16517
step   1380 | loss 1.6048 | lr 3.00e-04 | grad 3.23 | tok/s 15971
step   1390 | loss 1.4999 | lr 3.00e-04 | grad 5.19 | tok/s 16870
step   1400 | loss 1.3848 | lr 3.00e-04 | grad 1.84 | tok/s 16471
step   1410 | loss 1.5453 | lr 3.00e-04 | grad 8.44 | tok/s 16435
step   1420 | loss 1.6493 | lr 3.00e-04 | grad 2.33 | tok/s 14579
step   1430 | loss 1.3433 | lr 3.00e-04 | grad 2.41 | tok/s 16541
step   1440 | loss 1.1430 | lr 3.00e-04 | grad 2.20 | tok/s 17508
step   1450 | loss 1.1704 | lr 3.00e-04 | grad 2.53 | tok/s 17247
step   1460 | loss 1.7027 | lr 3.00e-04 | grad 2.44 | tok/s 16331
step   1470 | loss 1.5264 | lr 3.00e-04 | grad 2.22 | tok/s 17333
step   1480 | loss 1.8444 | lr 3.00e-04 | grad 3.72 | tok/s 17142
step   1490 | loss 1.5809 | lr 3.00e-04 | grad 2.84 | tok/s 17374
step   1500 | loss 1.3111 | lr 3.00e-04 | grad 2.22 | tok/s 17422
step   1510 | loss 1.5612 | lr 3.00e-04 | grad 2.94 | tok/s 17219
step   1520 | loss 1.4413 | lr 3.00e-04 | grad 2.97 | tok/s 16873
step   1530 | loss 1.4507 | lr 3.00e-04 | grad 3.19 | tok/s 17277
step   1540 | loss 1.6460 | lr 3.00e-04 | grad 2.77 | tok/s 16223
step   1550 | loss 1.2778 | lr 3.00e-04 | grad 2.84 | tok/s 17341
step   1560 | loss 1.6051 | lr 3.00e-04 | grad 2.09 | tok/s 16411
step   1570 | loss 1.2774 | lr 3.00e-04 | grad 2.31 | tok/s 17269
step   1580 | loss 1.7386 | lr 3.00e-04 | grad 4.72 | tok/s 17222
step   1590 | loss 1.5980 | lr 3.00e-04 | grad 2.38 | tok/s 16377
step   1600 | loss 0.9193 | lr 3.00e-04 | grad 1.71 | tok/s 17436
step   1610 | loss 1.1079 | lr 3.00e-04 | grad 2.03 | tok/s 16469
step   1620 | loss 1.3989 | lr 3.00e-04 | grad 3.66 | tok/s 16211
step   1630 | loss 1.3680 | lr 3.00e-04 | grad 2.03 | tok/s 16938
step   1640 | loss 1.3635 | lr 3.00e-04 | grad 2.23 | tok/s 16397
step   1650 | loss 1.5618 | lr 3.00e-04 | grad 2.78 | tok/s 15548
step   1660 | loss 1.3309 | lr 3.00e-04 | grad 1.80 | tok/s 17414
step   1670 | loss 1.4378 | lr 3.00e-04 | grad 3.81 | tok/s 16735
step   1680 | loss 1.6925 | lr 3.00e-04 | grad 1.95 | tok/s 15002
step   1690 | loss 1.5016 | lr 3.00e-04 | grad 3.66 | tok/s 16814
step   1700 | loss 1.5209 | lr 3.00e-04 | grad 2.08 | tok/s 16592
step   1710 | loss 1.4414 | lr 3.00e-04 | grad 2.22 | tok/s 16517
step   1720 | loss 1.5288 | lr 3.00e-04 | grad 3.12 | tok/s 17368
step   1730 | loss 1.2111 | lr 3.00e-04 | grad 2.66 | tok/s 17426
step   1740 | loss 1.4063 | lr 3.00e-04 | grad 2.66 | tok/s 16890
step   1750 | loss 1.5543 | lr 3.00e-04 | grad 2.92 | tok/s 16818
step   1760 | loss 1.5800 | lr 3.00e-04 | grad 2.30 | tok/s 16765
step   1770 | loss 1.4539 | lr 3.00e-04 | grad 2.48 | tok/s 16466
step   1780 | loss 1.4975 | lr 3.00e-04 | grad 2.08 | tok/s 16993
step   1790 | loss 1.4380 | lr 3.00e-04 | grad 3.12 | tok/s 16831
step   1800 | loss 1.5897 | lr 3.00e-04 | grad 2.14 | tok/s 16550
step   1810 | loss 1.4844 | lr 3.00e-04 | grad 3.62 | tok/s 16215
step   1820 | loss 1.4781 | lr 3.00e-04 | grad 5.94 | tok/s 16732
step   1830 | loss 1.4605 | lr 3.00e-04 | grad 3.94 | tok/s 17105
step   1840 | loss 1.4894 | lr 3.00e-04 | grad 1.96 | tok/s 16254
step   1850 | loss 1.2802 | lr 3.00e-04 | grad 2.09 | tok/s 17296
step   1860 | loss 1.3754 | lr 3.00e-04 | grad 2.77 | tok/s 16462
step   1870 | loss 1.3777 | lr 3.00e-04 | grad 1.87 | tok/s 16120
step   1880 | loss 1.2824 | lr 3.00e-04 | grad 2.88 | tok/s 16147
step   1890 | loss 1.5355 | lr 3.00e-04 | grad 2.16 | tok/s 15553
step   1900 | loss 1.3991 | lr 3.00e-04 | grad 2.33 | tok/s 16701
step   1910 | loss 1.4903 | lr 3.00e-04 | grad 2.23 | tok/s 15894
step   1920 | loss 1.3850 | lr 3.00e-04 | grad 2.05 | tok/s 17355
step   1930 | loss 1.4654 | lr 3.00e-04 | grad 3.55 | tok/s 15945
step   1940 | loss 1.4608 | lr 3.00e-04 | grad 2.36 | tok/s 17277
step   1950 | loss 1.8592 | lr 3.00e-04 | grad 3.58 | tok/s 17164
step   1960 | loss 1.4531 | lr 3.00e-04 | grad 4.44 | tok/s 17404
step   1970 | loss 1.5030 | lr 3.00e-04 | grad 2.44 | tok/s 16931
step   1980 | loss 1.5711 | lr 3.00e-04 | grad 2.47 | tok/s 16111
step   1990 | loss 1.6352 | lr 3.00e-04 | grad 2.62 | tok/s 16440
step   2000 | loss 1.5123 | lr 3.00e-04 | grad 2.61 | tok/s 16710
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5123.pt
step   2010 | loss 1.1717 | lr 3.00e-04 | grad 2.22 | tok/s 5548
step   2020 | loss 1.3257 | lr 3.00e-04 | grad 2.97 | tok/s 17070
step   2030 | loss 0.9606 | lr 3.00e-04 | grad 5.31 | tok/s 17609
step   2040 | loss 1.3342 | lr 3.00e-04 | grad 2.59 | tok/s 17499
step   2050 | loss 1.2524 | lr 3.00e-04 | grad 2.25 | tok/s 16901
step   2060 | loss 1.6373 | lr 3.00e-04 | grad 2.44 | tok/s 16454
step   2070 | loss 1.8409 | lr 3.00e-04 | grad 7.12 | tok/s 16567
step   2080 | loss 2.1766 | lr 3.00e-04 | grad 4.81 | tok/s 17506
step   2090 | loss 1.6424 | lr 3.00e-04 | grad 2.75 | tok/s 17119
step   2100 | loss 1.3977 | lr 3.00e-04 | grad 2.69 | tok/s 17121
step   2110 | loss 1.4812 | lr 3.00e-04 | grad 2.28 | tok/s 16009
step   2120 | loss 0.8759 | lr 3.00e-04 | grad 1.96 | tok/s 17452
step   2130 | loss 1.2788 | lr 3.00e-04 | grad 4.06 | tok/s 16790
step   2140 | loss 1.4627 | lr 3.00e-04 | grad 1.94 | tok/s 16920
step   2150 | loss 1.2987 | lr 3.00e-04 | grad 2.17 | tok/s 17379
step   2160 | loss 1.1811 | lr 3.00e-04 | grad 2.30 | tok/s 17456
step   2170 | loss 1.2487 | lr 3.00e-04 | grad 1.73 | tok/s 16736
step   2180 | loss 1.1914 | lr 3.00e-04 | grad 1.83 | tok/s 17255
step   2190 | loss 1.2149 | lr 3.00e-04 | grad 2.17 | tok/s 17461
step   2200 | loss 1.1776 | lr 3.00e-04 | grad 1.73 | tok/s 17413
step   2210 | loss 1.1441 | lr 3.00e-04 | grad 2.16 | tok/s 17415
step   2220 | loss 1.1390 | lr 3.00e-04 | grad 1.87 | tok/s 17433
step   2230 | loss 1.4052 | lr 3.00e-04 | grad 2.62 | tok/s 16980
step   2240 | loss 1.3172 | lr 3.00e-04 | grad 2.19 | tok/s 16728
step   2250 | loss 1.6251 | lr 3.00e-04 | grad 8.19 | tok/s 17384
step   2260 | loss 1.5947 | lr 3.00e-04 | grad 2.36 | tok/s 16500
step   2270 | loss 1.9425 | lr 3.00e-04 | grad 2.52 | tok/s 17204
step   2280 | loss 1.4336 | lr 3.00e-04 | grad 2.59 | tok/s 17420
step   2290 | loss 1.4689 | lr 3.00e-04 | grad 6.53 | tok/s 16737
step   2300 | loss 1.4559 | lr 3.00e-04 | grad 3.42 | tok/s 17017
step   2310 | loss 1.4385 | lr 3.00e-04 | grad 2.73 | tok/s 16377
step   2320 | loss 1.8683 | lr 3.00e-04 | grad 3.55 | tok/s 16305
step   2330 | loss 1.5930 | lr 3.00e-04 | grad 3.73 | tok/s 16434
step   2340 | loss 1.4572 | lr 3.00e-04 | grad 2.72 | tok/s 16250
step   2350 | loss 1.3904 | lr 3.00e-04 | grad 2.97 | tok/s 16974
step   2360 | loss 1.2625 | lr 3.00e-04 | grad 1.80 | tok/s 17441
step   2370 | loss 1.5736 | lr 3.00e-04 | grad 3.95 | tok/s 17067
step   2380 | loss 1.4347 | lr 3.00e-04 | grad 2.62 | tok/s 17462
step   2390 | loss 1.1304 | lr 3.00e-04 | grad 2.11 | tok/s 17419
step   2400 | loss 1.0698 | lr 3.00e-04 | grad 1.91 | tok/s 17441
step   2410 | loss 1.2087 | lr 3.00e-04 | grad 1.85 | tok/s 16694
step   2420 | loss 1.4984 | lr 3.00e-04 | grad 2.59 | tok/s 16056

Training complete! Final step: 2424
