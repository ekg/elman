Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_5/levelE88_100m_20260127_164715
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 466,084,884 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.1121 | lr 3.00e-04 | grad 8.62 | tok/s 7649
step     20 | loss 2.7172 | lr 3.00e-04 | grad 2.97 | tok/s 12816
step     30 | loss 2.9607 | lr 3.00e-04 | grad 5.25 | tok/s 13532
step     40 | loss 4.3151 | lr 3.00e-04 | grad 32.50 | tok/s 13691
step     50 | loss 4.4296 | lr 3.00e-04 | grad 13.19 | tok/s 13822
step     60 | loss 3.4680 | lr 3.00e-04 | grad 9.00 | tok/s 13759
step     70 | loss 2.7479 | lr 3.00e-04 | grad 5.50 | tok/s 13655
step     80 | loss 2.4645 | lr 3.00e-04 | grad 4.47 | tok/s 13530
step     90 | loss 2.3348 | lr 3.00e-04 | grad 3.50 | tok/s 13503
step    100 | loss 2.1294 | lr 3.00e-04 | grad 2.61 | tok/s 13401
step    110 | loss 2.1873 | lr 3.00e-04 | grad 2.66 | tok/s 13251
step    120 | loss 2.7123 | lr 3.00e-04 | grad 1.62 | tok/s 12600
step    130 | loss 2.1083 | lr 3.00e-04 | grad 4.59 | tok/s 12848
step    140 | loss 2.3675 | lr 3.00e-04 | grad 6.47 | tok/s 12883
step    150 | loss 1.3820 | lr 3.00e-04 | grad 4.66 | tok/s 13087
step    160 | loss 2.3296 | lr 3.00e-04 | grad 2.00 | tok/s 12626
step    170 | loss 2.2779 | lr 3.00e-04 | grad 1.55 | tok/s 12477
step    180 | loss 1.8516 | lr 3.00e-04 | grad 2.64 | tok/s 12733
step    190 | loss 1.9213 | lr 3.00e-04 | grad 1.80 | tok/s 12548
step    200 | loss 1.6675 | lr 3.00e-04 | grad 1.60 | tok/s 13079
step    210 | loss 1.8897 | lr 3.00e-04 | grad 4.25 | tok/s 12408
step    220 | loss 2.2012 | lr 3.00e-04 | grad 2.69 | tok/s 12562
step    230 | loss 1.9436 | lr 3.00e-04 | grad 2.36 | tok/s 12518
step    240 | loss 2.2507 | lr 3.00e-04 | grad 4.56 | tok/s 12704
step    250 | loss 1.7657 | lr 3.00e-04 | grad 1.48 | tok/s 12619
step    260 | loss 1.8965 | lr 3.00e-04 | grad 2.86 | tok/s 12945
step    270 | loss 1.8272 | lr 3.00e-04 | grad 1.70 | tok/s 12669
step    280 | loss 1.7745 | lr 3.00e-04 | grad 1.62 | tok/s 11885
step    290 | loss 1.6720 | lr 3.00e-04 | grad 1.91 | tok/s 12252
step    300 | loss 1.9672 | lr 3.00e-04 | grad 1.91 | tok/s 12355
step    310 | loss 1.6643 | lr 3.00e-04 | grad 1.61 | tok/s 12316
step    320 | loss 1.8729 | lr 3.00e-04 | grad 2.73 | tok/s 12442
step    330 | loss 1.7196 | lr 3.00e-04 | grad 1.60 | tok/s 12576
step    340 | loss 2.0345 | lr 3.00e-04 | grad 1.75 | tok/s 12489
step    350 | loss 1.7229 | lr 3.00e-04 | grad 1.73 | tok/s 12858
step    360 | loss 1.5812 | lr 3.00e-04 | grad 1.70 | tok/s 12344
step    370 | loss 1.4908 | lr 3.00e-04 | grad 1.45 | tok/s 12975
step    380 | loss 1.2312 | lr 3.00e-04 | grad 1.48 | tok/s 13086
step    390 | loss 1.1279 | lr 3.00e-04 | grad 1.43 | tok/s 13068
step    400 | loss 1.7450 | lr 3.00e-04 | grad 1.62 | tok/s 12428
step    410 | loss 1.7519 | lr 3.00e-04 | grad 2.12 | tok/s 12543
step    420 | loss 1.6266 | lr 3.00e-04 | grad 2.67 | tok/s 13067
step    430 | loss 1.6190 | lr 3.00e-04 | grad 1.66 | tok/s 12856
step    440 | loss 1.6944 | lr 3.00e-04 | grad 2.03 | tok/s 12483
step    450 | loss 1.6266 | lr 3.00e-04 | grad 1.38 | tok/s 12612
step    460 | loss 1.5911 | lr 3.00e-04 | grad 1.83 | tok/s 12789
step    470 | loss 1.5617 | lr 3.00e-04 | grad 2.91 | tok/s 12720
step    480 | loss 1.5667 | lr 3.00e-04 | grad 2.48 | tok/s 12970
step    490 | loss 1.7033 | lr 3.00e-04 | grad 2.14 | tok/s 12437
step    500 | loss 1.8057 | lr 3.00e-04 | grad 1.55 | tok/s 12633
step    510 | loss 1.6729 | lr 3.00e-04 | grad 1.38 | tok/s 12097
step    520 | loss 1.5355 | lr 3.00e-04 | grad 1.84 | tok/s 12698
step    530 | loss 1.7100 | lr 3.00e-04 | grad 1.80 | tok/s 12469
step    540 | loss 1.5830 | lr 3.00e-04 | grad 1.67 | tok/s 11301
step    550 | loss 1.3786 | lr 3.00e-04 | grad 1.60 | tok/s 12784
step    560 | loss 1.4152 | lr 3.00e-04 | grad 1.60 | tok/s 13094
step    570 | loss 1.3390 | lr 3.00e-04 | grad 1.30 | tok/s 13088
step    580 | loss 1.2909 | lr 3.00e-04 | grad 1.23 | tok/s 13092
step    590 | loss 1.3502 | lr 3.00e-04 | grad 1.63 | tok/s 13095
step    600 | loss 1.2749 | lr 3.00e-04 | grad 1.34 | tok/s 13096
step    610 | loss 1.2991 | lr 3.00e-04 | grad 1.19 | tok/s 13100
step    620 | loss 1.3785 | lr 3.00e-04 | grad 3.53 | tok/s 12917
step    630 | loss 1.6652 | lr 3.00e-04 | grad 2.66 | tok/s 12404
step    640 | loss 1.6881 | lr 3.00e-04 | grad 1.77 | tok/s 12532
step    650 | loss 1.5489 | lr 3.00e-04 | grad 2.20 | tok/s 12567
step    660 | loss 1.6502 | lr 3.00e-04 | grad 2.53 | tok/s 12962
step    670 | loss 1.5678 | lr 3.00e-04 | grad 2.50 | tok/s 12379
step    680 | loss 1.6064 | lr 3.00e-04 | grad 1.20 | tok/s 12313
step    690 | loss 1.6075 | lr 3.00e-04 | grad 2.23 | tok/s 12373
step    700 | loss 1.4456 | lr 3.00e-04 | grad 1.30 | tok/s 12432
step    710 | loss 1.6487 | lr 3.00e-04 | grad 1.91 | tok/s 12358
step    720 | loss 1.2761 | lr 3.00e-04 | grad 1.27 | tok/s 12822
step    730 | loss 1.5409 | lr 3.00e-04 | grad 3.47 | tok/s 12534
step    740 | loss 1.7624 | lr 3.00e-04 | grad 3.31 | tok/s 13012
step    750 | loss 1.4661 | lr 3.00e-04 | grad 1.23 | tok/s 13103
step    760 | loss 1.5829 | lr 3.00e-04 | grad 2.03 | tok/s 12849
step    770 | loss 1.5645 | lr 3.00e-04 | grad 1.67 | tok/s 12590
step    780 | loss 1.4668 | lr 3.00e-04 | grad 1.38 | tok/s 12700
step    790 | loss 1.6745 | lr 3.00e-04 | grad 2.45 | tok/s 12973
step    800 | loss 1.1853 | lr 3.00e-04 | grad 1.11 | tok/s 12781
step    810 | loss 1.4108 | lr 3.00e-04 | grad 2.08 | tok/s 12282
step    820 | loss 1.4754 | lr 3.00e-04 | grad 3.52 | tok/s 12536
step    830 | loss 1.4277 | lr 3.00e-04 | grad 1.23 | tok/s 12364
step    840 | loss 1.6410 | lr 3.00e-04 | grad 1.52 | tok/s 12168
step    850 | loss 1.5424 | lr 3.00e-04 | grad 1.85 | tok/s 12568
step    860 | loss 1.5888 | lr 3.00e-04 | grad 2.41 | tok/s 12898
step    870 | loss 1.4127 | lr 3.00e-04 | grad 1.81 | tok/s 12793
step    880 | loss 1.5812 | lr 3.00e-04 | grad 1.30 | tok/s 12580
step    890 | loss 1.4958 | lr 3.00e-04 | grad 1.84 | tok/s 12583
step    900 | loss 1.5585 | lr 3.00e-04 | grad 1.80 | tok/s 12442
step    910 | loss 1.4940 | lr 3.00e-04 | grad 2.45 | tok/s 12569
step    920 | loss 1.4681 | lr 3.00e-04 | grad 1.62 | tok/s 12492
step    930 | loss 1.4094 | lr 3.00e-04 | grad 1.84 | tok/s 12565
step    940 | loss 1.3639 | lr 3.00e-04 | grad 2.97 | tok/s 12311
step    950 | loss 1.4613 | lr 3.00e-04 | grad 1.62 | tok/s 12365

Training complete! Final step: 953
