Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_59/levelE88_100m_20260127_180040
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 486,289,200 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0671 | lr 3.00e-04 | grad 16.38 | tok/s 5613
step     20 | loss 3.1190 | lr 3.00e-04 | grad 11.38 | tok/s 16729
step     30 | loss 2.7282 | lr 3.00e-04 | grad 7.69 | tok/s 16389
step     40 | loss 2.5049 | lr 3.00e-04 | grad 19.50 | tok/s 16041
step     50 | loss 3.0682 | lr 3.00e-04 | grad 13.25 | tok/s 16785
step     60 | loss 2.0088 | lr 3.00e-04 | grad 5.94 | tok/s 16909
step     70 | loss 1.8158 | lr 3.00e-04 | grad 3.72 | tok/s 17050
step     80 | loss 6.9904 | lr 3.00e-04 | grad 86.50 | tok/s 17629
step     90 | loss 5.0895 | lr 3.00e-04 | grad 19.12 | tok/s 17733
step    100 | loss 4.0985 | lr 3.00e-04 | grad 23.75 | tok/s 17496
step    110 | loss 3.6413 | lr 3.00e-04 | grad 21.62 | tok/s 17434
step    120 | loss 3.0688 | lr 3.00e-04 | grad 22.50 | tok/s 17421
step    130 | loss 3.0169 | lr 3.00e-04 | grad 10.44 | tok/s 17469
step    140 | loss 2.7304 | lr 3.00e-04 | grad 19.38 | tok/s 17147
step    150 | loss 2.6727 | lr 3.00e-04 | grad 7.97 | tok/s 17088
step    160 | loss 2.4298 | lr 3.00e-04 | grad 6.66 | tok/s 17210
step    170 | loss 2.5292 | lr 3.00e-04 | grad 8.38 | tok/s 17248
step    180 | loss 2.2554 | lr 3.00e-04 | grad 5.75 | tok/s 17424
step    190 | loss 2.4168 | lr 3.00e-04 | grad 8.75 | tok/s 17208
step    200 | loss 2.1626 | lr 3.00e-04 | grad 6.41 | tok/s 17072
step    210 | loss 2.1780 | lr 3.00e-04 | grad 5.38 | tok/s 17142
step    220 | loss 2.1279 | lr 3.00e-04 | grad 3.92 | tok/s 17022
step    230 | loss 2.1251 | lr 3.00e-04 | grad 3.52 | tok/s 13946
step    240 | loss 2.3272 | lr 3.00e-04 | grad 4.12 | tok/s 14255
step    250 | loss 2.0460 | lr 3.00e-04 | grad 2.86 | tok/s 16403
step    260 | loss 1.5477 | lr 3.00e-04 | grad 3.64 | tok/s 16978
step    270 | loss 2.0498 | lr 3.00e-04 | grad 2.66 | tok/s 16622
step    280 | loss 2.4551 | lr 3.00e-04 | grad 14.25 | tok/s 16542
step    290 | loss 1.1280 | lr 3.00e-04 | grad 7.41 | tok/s 17195
step    300 | loss 0.7569 | lr 3.00e-04 | grad 4.91 | tok/s 16870
step    310 | loss 2.3664 | lr 3.00e-04 | grad 3.77 | tok/s 17155
step    320 | loss 1.9198 | lr 3.00e-04 | grad 4.19 | tok/s 16364
step    330 | loss 1.9603 | lr 3.00e-04 | grad 3.45 | tok/s 15677
step    340 | loss 2.2842 | lr 3.00e-04 | grad 3.12 | tok/s 16215
step    350 | loss 1.7699 | lr 3.00e-04 | grad 5.72 | tok/s 16548
step    360 | loss 1.2438 | lr 3.00e-04 | grad 5.00 | tok/s 17085
step    370 | loss 1.7972 | lr 3.00e-04 | grad 3.19 | tok/s 13550
step    380 | loss 1.7443 | lr 3.00e-04 | grad 3.61 | tok/s 13684
step    390 | loss 1.5187 | lr 3.00e-04 | grad 2.92 | tok/s 16712
step    400 | loss 1.4976 | lr 3.00e-04 | grad 3.70 | tok/s 17114
step    410 | loss 1.2942 | lr 3.00e-04 | grad 3.42 | tok/s 16716
step    420 | loss 1.9436 | lr 3.00e-04 | grad 13.56 | tok/s 15227
step    430 | loss 1.9929 | lr 3.00e-04 | grad 2.44 | tok/s 15610
step    440 | loss 2.1818 | lr 3.00e-04 | grad 6.16 | tok/s 16009
step    450 | loss 2.0257 | lr 3.00e-04 | grad 2.41 | tok/s 16502
step    460 | loss 1.6662 | lr 3.00e-04 | grad 3.91 | tok/s 16420
step    470 | loss 1.8851 | lr 3.00e-04 | grad 3.25 | tok/s 15423
step    480 | loss 2.3051 | lr 3.00e-04 | grad 5.09 | tok/s 14348
step    490 | loss 1.7435 | lr 3.00e-04 | grad 2.50 | tok/s 11716
step    500 | loss 1.7094 | lr 3.00e-04 | grad 3.00 | tok/s 14630
step    510 | loss 1.6740 | lr 3.00e-04 | grad 2.91 | tok/s 17098
step    520 | loss 1.6451 | lr 3.00e-04 | grad 2.64 | tok/s 15923
step    530 | loss 1.9100 | lr 3.00e-04 | grad 2.42 | tok/s 15099
step    540 | loss 1.7220 | lr 3.00e-04 | grad 3.12 | tok/s 13684
step    550 | loss 1.6218 | lr 3.00e-04 | grad 3.62 | tok/s 10584
step    560 | loss 1.7169 | lr 3.00e-04 | grad 3.44 | tok/s 15511
step    570 | loss 1.5977 | lr 3.00e-04 | grad 2.19 | tok/s 16454
step    580 | loss 1.5776 | lr 3.00e-04 | grad 3.20 | tok/s 15902
step    590 | loss 1.9373 | lr 3.00e-04 | grad 10.62 | tok/s 16189
step    600 | loss 1.7518 | lr 3.00e-04 | grad 2.97 | tok/s 16178
step    610 | loss 1.6039 | lr 3.00e-04 | grad 4.25 | tok/s 16375
step    620 | loss 1.6003 | lr 3.00e-04 | grad 2.84 | tok/s 16088
step    630 | loss 1.5554 | lr 3.00e-04 | grad 2.58 | tok/s 16297
step    640 | loss 1.9885 | lr 3.00e-04 | grad 6.03 | tok/s 16225
step    650 | loss 1.6311 | lr 3.00e-04 | grad 2.89 | tok/s 16578
step    660 | loss 1.6464 | lr 3.00e-04 | grad 2.33 | tok/s 16766
step    670 | loss 1.9594 | lr 3.00e-04 | grad 3.11 | tok/s 16643
step    680 | loss 1.8032 | lr 3.00e-04 | grad 7.16 | tok/s 16365
step    690 | loss 1.6648 | lr 3.00e-04 | grad 3.52 | tok/s 17114
step    700 | loss 1.4487 | lr 3.00e-04 | grad 13.06 | tok/s 17208
step    710 | loss 1.5515 | lr 3.00e-04 | grad 3.02 | tok/s 15864
step    720 | loss 1.5055 | lr 3.00e-04 | grad 2.73 | tok/s 16210
step    730 | loss 1.2867 | lr 3.00e-04 | grad 2.80 | tok/s 17291
step    740 | loss 1.3829 | lr 3.00e-04 | grad 2.30 | tok/s 17043
step    750 | loss 1.1926 | lr 3.00e-04 | grad 2.47 | tok/s 17297
step    760 | loss 1.0852 | lr 3.00e-04 | grad 2.34 | tok/s 17291
step    770 | loss 1.0398 | lr 3.00e-04 | grad 2.20 | tok/s 17256
step    780 | loss 0.9764 | lr 3.00e-04 | grad 2.14 | tok/s 17307
step    790 | loss 1.2471 | lr 3.00e-04 | grad 3.36 | tok/s 16432
step    800 | loss 1.9009 | lr 3.00e-04 | grad 2.89 | tok/s 16639
step    810 | loss 1.6738 | lr 3.00e-04 | grad 3.33 | tok/s 16559
step    820 | loss 1.6147 | lr 3.00e-04 | grad 5.97 | tok/s 16380
step    830 | loss 1.4810 | lr 3.00e-04 | grad 2.94 | tok/s 17030
step    840 | loss 1.4597 | lr 3.00e-04 | grad 2.72 | tok/s 17131
step    850 | loss 1.5558 | lr 3.00e-04 | grad 3.84 | tok/s 17131
step    860 | loss 1.4466 | lr 3.00e-04 | grad 3.09 | tok/s 17015
step    870 | loss 1.4972 | lr 3.00e-04 | grad 3.28 | tok/s 16453
step    880 | loss 1.7023 | lr 3.00e-04 | grad 2.30 | tok/s 16676
step    890 | loss 1.6891 | lr 3.00e-04 | grad 6.69 | tok/s 16498
step    900 | loss 1.5190 | lr 3.00e-04 | grad 2.34 | tok/s 15428
step    910 | loss 1.4309 | lr 3.00e-04 | grad 3.06 | tok/s 16748
step    920 | loss 1.6086 | lr 3.00e-04 | grad 3.27 | tok/s 16995
step    930 | loss 1.5295 | lr 3.00e-04 | grad 3.80 | tok/s 16130
step    940 | loss 1.3299 | lr 3.00e-04 | grad 1.96 | tok/s 17231
step    950 | loss 1.5202 | lr 3.00e-04 | grad 2.05 | tok/s 17324
step    960 | loss 1.4243 | lr 3.00e-04 | grad 3.44 | tok/s 17116
step    970 | loss 1.8295 | lr 3.00e-04 | grad 3.58 | tok/s 16289
step    980 | loss 1.5662 | lr 3.00e-04 | grad 3.02 | tok/s 16452
step    990 | loss 1.5540 | lr 3.00e-04 | grad 4.50 | tok/s 16929
step   1000 | loss 1.7816 | lr 3.00e-04 | grad 3.27 | tok/s 16559
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7816.pt
step   1010 | loss 1.6063 | lr 3.00e-04 | grad 3.16 | tok/s 6066
step   1020 | loss 1.6179 | lr 3.00e-04 | grad 2.53 | tok/s 15851
step   1030 | loss 1.3920 | lr 3.00e-04 | grad 2.48 | tok/s 16989
step   1040 | loss 1.5069 | lr 3.00e-04 | grad 2.50 | tok/s 16654
step   1050 | loss 1.6432 | lr 3.00e-04 | grad 2.80 | tok/s 16527
step   1060 | loss 1.6944 | lr 3.00e-04 | grad 3.22 | tok/s 16999
step   1070 | loss 1.6229 | lr 3.00e-04 | grad 3.34 | tok/s 16514
step   1080 | loss 1.3950 | lr 3.00e-04 | grad 2.59 | tok/s 15769
step   1090 | loss 1.0384 | lr 3.00e-04 | grad 3.02 | tok/s 17003
step   1100 | loss 1.5811 | lr 3.00e-04 | grad 3.45 | tok/s 16860
step   1110 | loss 1.3797 | lr 3.00e-04 | grad 2.30 | tok/s 17345
step   1120 | loss 1.3319 | lr 3.00e-04 | grad 2.44 | tok/s 17360
step   1130 | loss 1.2729 | lr 3.00e-04 | grad 2.20 | tok/s 17416
step   1140 | loss 1.2884 | lr 3.00e-04 | grad 2.20 | tok/s 16061
step   1150 | loss 1.2726 | lr 3.00e-04 | grad 1.95 | tok/s 17535
step   1160 | loss 1.1985 | lr 3.00e-04 | grad 2.20 | tok/s 17513
step   1170 | loss 1.3008 | lr 3.00e-04 | grad 2.27 | tok/s 17509
step   1180 | loss 1.2802 | lr 3.00e-04 | grad 2.19 | tok/s 17421
step   1190 | loss 1.1954 | lr 3.00e-04 | grad 1.95 | tok/s 17283
step   1200 | loss 1.2329 | lr 3.00e-04 | grad 1.93 | tok/s 17304
step   1210 | loss 1.2713 | lr 3.00e-04 | grad 2.09 | tok/s 17185
step   1220 | loss 1.2537 | lr 3.00e-04 | grad 1.90 | tok/s 17243
step   1230 | loss 1.2558 | lr 3.00e-04 | grad 2.12 | tok/s 17256
step   1240 | loss 1.4024 | lr 3.00e-04 | grad 2.81 | tok/s 16700
step   1250 | loss 1.7158 | lr 3.00e-04 | grad 2.52 | tok/s 16392
step   1260 | loss 1.4406 | lr 3.00e-04 | grad 6.72 | tok/s 16324
step   1270 | loss 1.6272 | lr 3.00e-04 | grad 3.34 | tok/s 15799
step   1280 | loss 1.6092 | lr 3.00e-04 | grad 4.38 | tok/s 16877
step   1290 | loss 1.4776 | lr 3.00e-04 | grad 2.45 | tok/s 16478
step   1300 | loss 1.5164 | lr 3.00e-04 | grad 2.39 | tok/s 16278
step   1310 | loss 1.4553 | lr 3.00e-04 | grad 2.39 | tok/s 17117
step   1320 | loss 1.7057 | lr 3.00e-04 | grad 4.75 | tok/s 16978
step   1330 | loss 1.3705 | lr 3.00e-04 | grad 3.81 | tok/s 16683
step   1340 | loss 1.6533 | lr 3.00e-04 | grad 6.78 | tok/s 15804
step   1350 | loss 1.7606 | lr 3.00e-04 | grad 3.70 | tok/s 16130
step   1360 | loss 1.3914 | lr 3.00e-04 | grad 2.45 | tok/s 16462
step   1370 | loss 1.5982 | lr 3.00e-04 | grad 3.53 | tok/s 16603
step   1380 | loss 1.5653 | lr 3.00e-04 | grad 3.20 | tok/s 15867
step   1390 | loss 1.4133 | lr 3.00e-04 | grad 2.50 | tok/s 16181
step   1400 | loss 1.4097 | lr 3.00e-04 | grad 2.30 | tok/s 16614
step   1410 | loss 1.5823 | lr 3.00e-04 | grad 2.58 | tok/s 16068
step   1420 | loss 1.5951 | lr 3.00e-04 | grad 2.48 | tok/s 16252
step   1430 | loss 1.2843 | lr 3.00e-04 | grad 1.98 | tok/s 16507
step   1440 | loss 1.1300 | lr 3.00e-04 | grad 1.97 | tok/s 17184
step   1450 | loss 1.3572 | lr 3.00e-04 | grad 6.56 | tok/s 16852
step   1460 | loss 1.6188 | lr 3.00e-04 | grad 2.80 | tok/s 15879
step   1470 | loss 1.4407 | lr 3.00e-04 | grad 2.28 | tok/s 17083
step   1480 | loss 1.8687 | lr 3.00e-04 | grad 5.88 | tok/s 17033
step   1490 | loss 1.5374 | lr 3.00e-04 | grad 2.36 | tok/s 16413
step   1500 | loss 1.2339 | lr 3.00e-04 | grad 2.34 | tok/s 16580
step   1510 | loss 1.5974 | lr 3.00e-04 | grad 2.73 | tok/s 12888
step   1520 | loss 1.4673 | lr 3.00e-04 | grad 2.83 | tok/s 15624
step   1530 | loss 1.3985 | lr 3.00e-04 | grad 2.45 | tok/s 11923
step   1540 | loss 1.6467 | lr 3.00e-04 | grad 2.36 | tok/s 7677
step   1550 | loss 1.1936 | lr 3.00e-04 | grad 1.92 | tok/s 7139
step   1560 | loss 1.6372 | lr 3.00e-04 | grad 2.12 | tok/s 7012
step   1570 | loss 1.3578 | lr 3.00e-04 | grad 2.91 | tok/s 7146
step   1580 | loss 1.6446 | lr 3.00e-04 | grad 3.33 | tok/s 6965
step   1590 | loss 1.4942 | lr 3.00e-04 | grad 2.06 | tok/s 6994
step   1600 | loss 0.7727 | lr 3.00e-04 | grad 1.01 | tok/s 7218
step   1610 | loss 1.3011 | lr 3.00e-04 | grad 2.19 | tok/s 6611
step   1620 | loss 1.3692 | lr 3.00e-04 | grad 4.34 | tok/s 7086
step   1630 | loss 1.3123 | lr 3.00e-04 | grad 2.12 | tok/s 7104
step   1640 | loss 1.5235 | lr 3.00e-04 | grad 5.56 | tok/s 6833
step   1650 | loss 1.5355 | lr 3.00e-04 | grad 2.48 | tok/s 6755
step   1660 | loss 1.2084 | lr 3.00e-04 | grad 2.05 | tok/s 7338
step   1670 | loss 1.6314 | lr 3.00e-04 | grad 2.91 | tok/s 6936
step   1680 | loss 1.5467 | lr 3.00e-04 | grad 2.50 | tok/s 6906
step   1690 | loss 1.4393 | lr 3.00e-04 | grad 3.70 | tok/s 7210
step   1700 | loss 1.5328 | lr 3.00e-04 | grad 3.16 | tok/s 6714
step   1710 | loss 1.4351 | lr 3.00e-04 | grad 2.41 | tok/s 7040
step   1720 | loss 1.4853 | lr 3.00e-04 | grad 3.22 | tok/s 7489
step   1730 | loss 1.1534 | lr 3.00e-04 | grad 2.50 | tok/s 7193
step   1740 | loss 1.4239 | lr 3.00e-04 | grad 2.77 | tok/s 6838
step   1750 | loss 1.5436 | lr 3.00e-04 | grad 3.52 | tok/s 7037
step   1760 | loss 1.5507 | lr 3.00e-04 | grad 2.45 | tok/s 6439
step   1770 | loss 1.4359 | lr 3.00e-04 | grad 2.52 | tok/s 6800
step   1780 | loss 1.4872 | lr 3.00e-04 | grad 2.61 | tok/s 6946
step   1790 | loss 1.4464 | lr 3.00e-04 | grad 2.72 | tok/s 6941
step   1800 | loss 1.6271 | lr 3.00e-04 | grad 3.06 | tok/s 6979
step   1810 | loss 1.3670 | lr 3.00e-04 | grad 2.34 | tok/s 6905
step   1820 | loss 1.5118 | lr 3.00e-04 | grad 3.64 | tok/s 6843
step   1830 | loss 1.4836 | lr 3.00e-04 | grad 3.53 | tok/s 6836
step   1840 | loss 1.4674 | lr 3.00e-04 | grad 2.89 | tok/s 6655
step   1850 | loss 1.2229 | lr 3.00e-04 | grad 2.78 | tok/s 6943
step   1860 | loss 1.4732 | lr 3.00e-04 | grad 3.06 | tok/s 6601
step   1870 | loss 1.1674 | lr 3.00e-04 | grad 1.74 | tok/s 7062
step   1880 | loss 1.4653 | lr 3.00e-04 | grad 3.94 | tok/s 6322
step   1890 | loss 1.4606 | lr 3.00e-04 | grad 2.17 | tok/s 6962
step   1900 | loss 1.3807 | lr 3.00e-04 | grad 2.05 | tok/s 6723

Training complete! Final step: 1906
