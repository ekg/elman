Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v3/e88_480M_30gen_20260127_164705/eval_24/levelE88_100m_20260127_170817
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,075,024 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1225 | lr 3.00e-04 | grad 19.25 | tok/s 6014
step     20 | loss 2.9672 | lr 3.00e-04 | grad 11.44 | tok/s 18021
step     30 | loss 2.7321 | lr 3.00e-04 | grad 8.62 | tok/s 18258
step     40 | loss 2.4820 | lr 3.00e-04 | grad 5.34 | tok/s 17442
step     50 | loss 2.9973 | lr 3.00e-04 | grad 15.38 | tok/s 17744
step     60 | loss 2.1193 | lr 3.00e-04 | grad 4.06 | tok/s 18266
step     70 | loss 1.8685 | lr 3.00e-04 | grad 5.50 | tok/s 18529
step     80 | loss 6.6636 | lr 3.00e-04 | grad 69.50 | tok/s 18593
step     90 | loss 5.7127 | lr 3.00e-04 | grad 10.38 | tok/s 18911
step    100 | loss 4.1540 | lr 3.00e-04 | grad 8.56 | tok/s 18917
step    110 | loss 3.4025 | lr 3.00e-04 | grad 12.50 | tok/s 18874
step    120 | loss 3.2172 | lr 3.00e-04 | grad 13.25 | tok/s 18916
step    130 | loss 2.9626 | lr 3.00e-04 | grad 15.56 | tok/s 18824
step    140 | loss 2.7821 | lr 3.00e-04 | grad 9.19 | tok/s 18851
step    150 | loss 2.6683 | lr 3.00e-04 | grad 11.69 | tok/s 18814
step    160 | loss 2.4146 | lr 3.00e-04 | grad 11.12 | tok/s 18810
step    170 | loss 2.4325 | lr 3.00e-04 | grad 13.81 | tok/s 18736
step    180 | loss 2.3154 | lr 3.00e-04 | grad 8.12 | tok/s 18737
step    190 | loss 2.4182 | lr 3.00e-04 | grad 12.12 | tok/s 18731
step    200 | loss 2.1384 | lr 3.00e-04 | grad 5.81 | tok/s 18588
step    210 | loss 2.1742 | lr 3.00e-04 | grad 8.88 | tok/s 18561
step    220 | loss 2.1642 | lr 3.00e-04 | grad 4.31 | tok/s 18334
step    230 | loss 2.0596 | lr 3.00e-04 | grad 4.28 | tok/s 18172
step    240 | loss 2.3123 | lr 3.00e-04 | grad 5.50 | tok/s 17240
step    250 | loss 2.1130 | lr 3.00e-04 | grad 2.95 | tok/s 17706
step    260 | loss 1.5431 | lr 3.00e-04 | grad 3.45 | tok/s 18020
step    270 | loss 2.0849 | lr 3.00e-04 | grad 3.22 | tok/s 17229
step    280 | loss 2.2659 | lr 3.00e-04 | grad 5.34 | tok/s 17318
step    290 | loss 1.3713 | lr 3.00e-04 | grad 3.70 | tok/s 18572
step    300 | loss 0.5749 | lr 3.00e-04 | grad 3.33 | tok/s 18391
step    310 | loss 2.4210 | lr 3.00e-04 | grad 4.50 | tok/s 18098
step    320 | loss 1.9209 | lr 3.00e-04 | grad 6.22 | tok/s 17646
step    330 | loss 1.9513 | lr 3.00e-04 | grad 3.31 | tok/s 16058
step    340 | loss 2.2682 | lr 3.00e-04 | grad 3.31 | tok/s 16744
step    350 | loss 1.8402 | lr 3.00e-04 | grad 3.83 | tok/s 18162
step    360 | loss 1.1486 | lr 3.00e-04 | grad 9.19 | tok/s 18232
step    370 | loss 1.8023 | lr 3.00e-04 | grad 2.88 | tok/s 14379
step    380 | loss 1.7680 | lr 3.00e-04 | grad 3.16 | tok/s 17268
step    390 | loss 1.5334 | lr 3.00e-04 | grad 2.58 | tok/s 18562
step    400 | loss 1.4880 | lr 3.00e-04 | grad 3.11 | tok/s 18279
step    410 | loss 1.2614 | lr 3.00e-04 | grad 2.28 | tok/s 17804
step    420 | loss 1.8142 | lr 3.00e-04 | grad 5.06 | tok/s 17064
step    430 | loss 2.1502 | lr 3.00e-04 | grad 3.39 | tok/s 18176
step    440 | loss 2.1587 | lr 3.00e-04 | grad 4.31 | tok/s 17373
step    450 | loss 2.0754 | lr 3.00e-04 | grad 2.91 | tok/s 17948
step    460 | loss 1.7213 | lr 3.00e-04 | grad 3.27 | tok/s 17342
step    470 | loss 1.8308 | lr 3.00e-04 | grad 3.08 | tok/s 18070
step    480 | loss 2.2663 | lr 3.00e-04 | grad 7.22 | tok/s 18030
step    490 | loss 1.7916 | lr 3.00e-04 | grad 2.78 | tok/s 16980
step    500 | loss 1.6729 | lr 3.00e-04 | grad 4.03 | tok/s 18249
step    510 | loss 1.7125 | lr 3.00e-04 | grad 2.89 | tok/s 18535
step    520 | loss 1.6566 | lr 3.00e-04 | grad 2.52 | tok/s 18426
step    530 | loss 1.9014 | lr 3.00e-04 | grad 2.64 | tok/s 17610
step    540 | loss 1.7405 | lr 3.00e-04 | grad 2.61 | tok/s 17492
step    550 | loss 1.5806 | lr 3.00e-04 | grad 3.03 | tok/s 12512
step    560 | loss 1.7254 | lr 3.00e-04 | grad 4.09 | tok/s 16979
step    570 | loss 1.6354 | lr 3.00e-04 | grad 3.81 | tok/s 17571
step    580 | loss 1.5576 | lr 3.00e-04 | grad 2.45 | tok/s 17093
step    590 | loss 1.8741 | lr 3.00e-04 | grad 3.55 | tok/s 17845
step    600 | loss 1.8147 | lr 3.00e-04 | grad 2.25 | tok/s 17357
step    610 | loss 1.6008 | lr 3.00e-04 | grad 2.78 | tok/s 17636
step    620 | loss 1.5879 | lr 3.00e-04 | grad 2.50 | tok/s 17263
step    630 | loss 1.6178 | lr 3.00e-04 | grad 3.02 | tok/s 16984
step    640 | loss 1.9010 | lr 3.00e-04 | grad 6.84 | tok/s 17248
step    650 | loss 1.6330 | lr 3.00e-04 | grad 3.23 | tok/s 17808
step    660 | loss 1.6975 | lr 3.00e-04 | grad 3.70 | tok/s 18099
step    670 | loss 1.9482 | lr 3.00e-04 | grad 3.66 | tok/s 18126
step    680 | loss 1.7217 | lr 3.00e-04 | grad 3.72 | tok/s 17296
step    690 | loss 1.7669 | lr 3.00e-04 | grad 2.94 | tok/s 18091
step    700 | loss 1.3820 | lr 3.00e-04 | grad 2.53 | tok/s 15599
step    710 | loss 1.6164 | lr 3.00e-04 | grad 3.92 | tok/s 16813
step    720 | loss 1.4967 | lr 3.00e-04 | grad 3.30 | tok/s 17264
step    730 | loss 1.2743 | lr 3.00e-04 | grad 3.52 | tok/s 18525
step    740 | loss 1.4338 | lr 3.00e-04 | grad 2.50 | tok/s 18213
step    750 | loss 1.1933 | lr 3.00e-04 | grad 2.06 | tok/s 18453
step    760 | loss 1.0835 | lr 3.00e-04 | grad 1.88 | tok/s 12566
step    770 | loss 1.0557 | lr 3.00e-04 | grad 2.28 | tok/s 6292
step    780 | loss 0.9635 | lr 3.00e-04 | grad 2.00 | tok/s 11900
step    790 | loss 1.1799 | lr 3.00e-04 | grad 2.91 | tok/s 16155
step    800 | loss 1.9094 | lr 3.00e-04 | grad 5.88 | tok/s 17532
step    810 | loss 1.6695 | lr 3.00e-04 | grad 5.47 | tok/s 16899
step    820 | loss 1.6807 | lr 3.00e-04 | grad 9.38 | tok/s 13958
step    830 | loss 1.4356 | lr 3.00e-04 | grad 2.47 | tok/s 17831
step    840 | loss 1.4133 | lr 3.00e-04 | grad 4.50 | tok/s 18246
step    850 | loss 1.5381 | lr 3.00e-04 | grad 4.62 | tok/s 15613
step    860 | loss 1.4561 | lr 3.00e-04 | grad 2.98 | tok/s 18130
step    870 | loss 1.5006 | lr 3.00e-04 | grad 2.62 | tok/s 17656
step    880 | loss 1.7068 | lr 3.00e-04 | grad 3.14 | tok/s 17437
step    890 | loss 1.6262 | lr 3.00e-04 | grad 2.31 | tok/s 13096
step    900 | loss 1.5747 | lr 3.00e-04 | grad 2.41 | tok/s 9505
step    910 | loss 1.4252 | lr 3.00e-04 | grad 3.03 | tok/s 16931
step    920 | loss 1.6067 | lr 3.00e-04 | grad 3.20 | tok/s 16843
step    930 | loss 1.5183 | lr 3.00e-04 | grad 3.70 | tok/s 16803
step    940 | loss 1.3228 | lr 3.00e-04 | grad 2.47 | tok/s 17546
step    950 | loss 1.5599 | lr 3.00e-04 | grad 2.00 | tok/s 18031
step    960 | loss 1.4369 | lr 3.00e-04 | grad 3.42 | tok/s 18286
step    970 | loss 1.8292 | lr 3.00e-04 | grad 3.61 | tok/s 13614
step    980 | loss 1.5639 | lr 3.00e-04 | grad 3.12 | tok/s 9610
step    990 | loss 1.5565 | lr 3.00e-04 | grad 4.44 | tok/s 14541
step   1000 | loss 1.7633 | lr 3.00e-04 | grad 3.25 | tok/s 11280
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7633.pt
step   1010 | loss 1.6590 | lr 3.00e-04 | grad 2.73 | tok/s 2872
step   1020 | loss 1.4518 | lr 3.00e-04 | grad 2.19 | tok/s 15955
step   1030 | loss 1.4717 | lr 3.00e-04 | grad 2.22 | tok/s 18073
step   1040 | loss 1.5763 | lr 3.00e-04 | grad 5.00 | tok/s 17268
step   1050 | loss 1.7316 | lr 3.00e-04 | grad 3.84 | tok/s 18076
step   1060 | loss 1.6660 | lr 3.00e-04 | grad 3.56 | tok/s 15136
step   1070 | loss 1.4465 | lr 3.00e-04 | grad 2.95 | tok/s 7690
step   1080 | loss 1.1852 | lr 3.00e-04 | grad 1.92 | tok/s 13496
step   1090 | loss 1.2940 | lr 3.00e-04 | grad 2.38 | tok/s 15137
step   1100 | loss 1.5196 | lr 3.00e-04 | grad 2.67 | tok/s 13935
step   1110 | loss 1.3422 | lr 3.00e-04 | grad 2.17 | tok/s 17830
step   1120 | loss 1.2881 | lr 3.00e-04 | grad 2.17 | tok/s 18795
step   1130 | loss 1.2783 | lr 3.00e-04 | grad 2.48 | tok/s 18712
step   1140 | loss 1.3033 | lr 3.00e-04 | grad 2.11 | tok/s 18479
step   1150 | loss 1.2017 | lr 3.00e-04 | grad 2.33 | tok/s 13032
step   1160 | loss 1.2247 | lr 3.00e-04 | grad 2.08 | tok/s 13080
step   1170 | loss 1.3534 | lr 3.00e-04 | grad 2.23 | tok/s 18090
step   1180 | loss 1.2097 | lr 3.00e-04 | grad 2.41 | tok/s 18738
step   1190 | loss 1.2054 | lr 3.00e-04 | grad 2.25 | tok/s 18855
step   1200 | loss 1.2514 | lr 3.00e-04 | grad 2.62 | tok/s 14158
step   1210 | loss 1.2979 | lr 3.00e-04 | grad 2.17 | tok/s 18157
step   1220 | loss 1.2517 | lr 3.00e-04 | grad 2.33 | tok/s 18222
step   1230 | loss 1.2113 | lr 3.00e-04 | grad 1.95 | tok/s 18545
step   1240 | loss 1.7304 | lr 3.00e-04 | grad 2.30 | tok/s 17885
step   1250 | loss 1.5205 | lr 3.00e-04 | grad 5.16 | tok/s 17303
step   1260 | loss 1.4448 | lr 3.00e-04 | grad 2.47 | tok/s 17612
step   1270 | loss 1.7601 | lr 3.00e-04 | grad 2.80 | tok/s 17782
step   1280 | loss 1.4861 | lr 3.00e-04 | grad 2.89 | tok/s 17528
step   1290 | loss 1.4861 | lr 3.00e-04 | grad 2.83 | tok/s 17807
step   1300 | loss 1.4548 | lr 3.00e-04 | grad 2.89 | tok/s 17642
step   1310 | loss 1.6087 | lr 3.00e-04 | grad 2.64 | tok/s 18096
step   1320 | loss 1.6544 | lr 3.00e-04 | grad 2.73 | tok/s 18366
step   1330 | loss 1.3431 | lr 3.00e-04 | grad 3.33 | tok/s 17356
step   1340 | loss 1.8154 | lr 3.00e-04 | grad 2.58 | tok/s 16815
step   1350 | loss 1.5013 | lr 3.00e-04 | grad 2.61 | tok/s 17821
step   1360 | loss 1.4503 | lr 3.00e-04 | grad 2.59 | tok/s 18017
step   1370 | loss 1.6466 | lr 3.00e-04 | grad 3.03 | tok/s 16960
step   1380 | loss 1.5323 | lr 3.00e-04 | grad 2.50 | tok/s 17782
step   1390 | loss 1.4459 | lr 3.00e-04 | grad 2.27 | tok/s 17295
step   1400 | loss 1.3977 | lr 3.00e-04 | grad 2.53 | tok/s 14928
step   1410 | loss 1.7134 | lr 3.00e-04 | grad 6.00 | tok/s 9909
step   1420 | loss 1.3411 | lr 3.00e-04 | grad 2.56 | tok/s 9217
step   1430 | loss 1.1728 | lr 3.00e-04 | grad 2.53 | tok/s 13961
step   1440 | loss 1.1029 | lr 3.00e-04 | grad 1.96 | tok/s 18602
step   1450 | loss 1.6931 | lr 3.00e-04 | grad 3.41 | tok/s 15709
step   1460 | loss 1.5244 | lr 3.00e-04 | grad 2.25 | tok/s 14398
step   1470 | loss 1.7965 | lr 3.00e-04 | grad 6.38 | tok/s 7986
step   1480 | loss 1.5954 | lr 3.00e-04 | grad 2.41 | tok/s 10348
step   1490 | loss 1.3418 | lr 3.00e-04 | grad 2.69 | tok/s 17913
step   1500 | loss 1.5250 | lr 3.00e-04 | grad 2.45 | tok/s 17860
step   1510 | loss 1.3875 | lr 3.00e-04 | grad 2.25 | tok/s 10397
step   1520 | loss 1.4838 | lr 3.00e-04 | grad 2.44 | tok/s 6825
step   1530 | loss 1.5602 | lr 3.00e-04 | grad 2.59 | tok/s 11676
step   1540 | loss 1.3542 | lr 3.00e-04 | grad 2.77 | tok/s 18494
step   1550 | loss 1.5580 | lr 3.00e-04 | grad 2.73 | tok/s 17832
step   1560 | loss 1.2914 | lr 3.00e-04 | grad 1.87 | tok/s 16501
step   1570 | loss 1.6844 | lr 3.00e-04 | grad 4.69 | tok/s 11607
step   1580 | loss 1.6032 | lr 3.00e-04 | grad 2.58 | tok/s 17380
step   1590 | loss 1.0918 | lr 3.00e-04 | grad 5.62 | tok/s 17142
step   1600 | loss 0.9612 | lr 3.00e-04 | grad 2.53 | tok/s 10212
step   1610 | loss 1.4237 | lr 3.00e-04 | grad 4.44 | tok/s 10435
step   1620 | loss 1.3531 | lr 3.00e-04 | grad 2.50 | tok/s 6573
step   1630 | loss 1.3064 | lr 3.00e-04 | grad 4.72 | tok/s 4789
step   1640 | loss 1.5688 | lr 3.00e-04 | grad 4.28 | tok/s 10415
step   1650 | loss 1.2290 | lr 3.00e-04 | grad 1.91 | tok/s 18455
step   1660 | loss 1.6025 | lr 3.00e-04 | grad 8.25 | tok/s 17734
step   1670 | loss 1.5584 | lr 3.00e-04 | grad 2.80 | tok/s 16433
step   1680 | loss 1.4625 | lr 3.00e-04 | grad 8.25 | tok/s 18339
step   1690 | loss 1.5247 | lr 3.00e-04 | grad 2.39 | tok/s 17762
step   1700 | loss 1.4516 | lr 3.00e-04 | grad 2.52 | tok/s 17701
step   1710 | loss 1.4983 | lr 3.00e-04 | grad 3.25 | tok/s 18641
step   1720 | loss 1.1706 | lr 3.00e-04 | grad 3.92 | tok/s 17561
step   1730 | loss 1.4123 | lr 3.00e-04 | grad 2.78 | tok/s 17909
step   1740 | loss 1.5179 | lr 3.00e-04 | grad 2.69 | tok/s 15745
step   1750 | loss 1.5967 | lr 3.00e-04 | grad 3.05 | tok/s 15866
step   1760 | loss 1.4380 | lr 3.00e-04 | grad 2.11 | tok/s 14244
step   1770 | loss 1.4961 | lr 3.00e-04 | grad 3.06 | tok/s 13467
step   1780 | loss 1.4278 | lr 3.00e-04 | grad 2.31 | tok/s 13367
step   1790 | loss 1.5649 | lr 3.00e-04 | grad 2.58 | tok/s 11693
step   1800 | loss 1.4740 | lr 3.00e-04 | grad 3.20 | tok/s 12477
step   1810 | loss 1.4847 | lr 3.00e-04 | grad 6.66 | tok/s 16607
step   1820 | loss 1.4522 | lr 3.00e-04 | grad 2.59 | tok/s 13601
step   1830 | loss 1.4414 | lr 3.00e-04 | grad 1.81 | tok/s 12015
step   1840 | loss 1.2837 | lr 3.00e-04 | grad 2.11 | tok/s 8897
step   1850 | loss 1.3663 | lr 3.00e-04 | grad 2.44 | tok/s 16052
step   1860 | loss 1.3368 | lr 3.00e-04 | grad 1.61 | tok/s 18231
step   1870 | loss 1.3177 | lr 3.00e-04 | grad 2.69 | tok/s 16164
step   1880 | loss 1.5645 | lr 3.00e-04 | grad 2.20 | tok/s 15271
step   1890 | loss 1.3700 | lr 3.00e-04 | grad 2.11 | tok/s 14305
step   1900 | loss 1.5016 | lr 3.00e-04 | grad 2.09 | tok/s 17165
step   1910 | loss 1.3636 | lr 3.00e-04 | grad 2.22 | tok/s 17505
step   1920 | loss 1.4850 | lr 3.00e-04 | grad 2.30 | tok/s 12357
step   1930 | loss 1.4775 | lr 3.00e-04 | grad 3.33 | tok/s 10265
step   1940 | loss 1.8276 | lr 3.00e-04 | grad 3.73 | tok/s 11005
step   1950 | loss 1.4472 | lr 3.00e-04 | grad 3.95 | tok/s 9086
step   1960 | loss 1.5412 | lr 3.00e-04 | grad 5.47 | tok/s 18129
step   1970 | loss 1.4961 | lr 3.00e-04 | grad 2.03 | tok/s 16388
step   1980 | loss 1.6411 | lr 3.00e-04 | grad 2.20 | tok/s 12955
step   1990 | loss 1.5071 | lr 3.00e-04 | grad 2.48 | tok/s 15615
step   2000 | loss 1.0015 | lr 3.00e-04 | grad 1.83 | tok/s 16796
  >>> saved checkpoint: checkpoint_step_002000_loss_1.0015.pt
step   2010 | loss 1.0262 | lr 3.00e-04 | grad 5.22 | tok/s 2554
step   2020 | loss 1.3188 | lr 3.00e-04 | grad 2.78 | tok/s 19057
step   2030 | loss 1.2460 | lr 3.00e-04 | grad 2.33 | tok/s 15220
step   2040 | loss 1.6329 | lr 3.00e-04 | grad 2.34 | tok/s 13533
step   2050 | loss 1.8309 | lr 3.00e-04 | grad 8.44 | tok/s 12026
step   2060 | loss 2.1554 | lr 3.00e-04 | grad 4.53 | tok/s 18648
step   2070 | loss 1.5844 | lr 3.00e-04 | grad 2.47 | tok/s 18502
step   2080 | loss 1.3704 | lr 3.00e-04 | grad 3.66 | tok/s 17533
step   2090 | loss 1.4597 | lr 3.00e-04 | grad 2.36 | tok/s 12770
step   2100 | loss 0.8085 | lr 3.00e-04 | grad 2.00 | tok/s 16933
step   2110 | loss 1.3329 | lr 3.00e-04 | grad 2.64 | tok/s 16656
step   2120 | loss 1.4505 | lr 3.00e-04 | grad 2.11 | tok/s 18002
step   2130 | loss 1.2863 | lr 3.00e-04 | grad 2.58 | tok/s 18255
step   2140 | loss 1.1867 | lr 3.00e-04 | grad 2.11 | tok/s 18294
step   2150 | loss 1.2216 | lr 3.00e-04 | grad 2.14 | tok/s 18607
step   2160 | loss 1.1889 | lr 3.00e-04 | grad 2.00 | tok/s 18717
step   2170 | loss 1.2250 | lr 3.00e-04 | grad 2.14 | tok/s 18510
step   2180 | loss 1.1576 | lr 3.00e-04 | grad 2.05 | tok/s 18583
step   2190 | loss 1.1502 | lr 3.00e-04 | grad 2.11 | tok/s 18514
step   2200 | loss 1.1187 | lr 3.00e-04 | grad 2.06 | tok/s 18458

Training complete! Final step: 2200
