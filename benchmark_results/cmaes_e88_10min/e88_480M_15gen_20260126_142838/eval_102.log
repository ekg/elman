Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_102/levelE88_100m_20260126_163223
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 484,004,408 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0312 | lr 3.00e-04 | grad 11.38 | tok/s 5662
step     20 | loss 2.6073 | lr 3.00e-04 | grad 4.28 | tok/s 13554
step     30 | loss 2.5084 | lr 3.00e-04 | grad 3.20 | tok/s 13715
step     40 | loss 2.3417 | lr 3.00e-04 | grad 2.98 | tok/s 13112
step     50 | loss 2.9259 | lr 3.00e-04 | grad 11.25 | tok/s 13328
step     60 | loss 2.0338 | lr 3.00e-04 | grad 6.56 | tok/s 13767
step     70 | loss 1.8990 | lr 3.00e-04 | grad 3.97 | tok/s 13869
step     80 | loss 5.6291 | lr 3.00e-04 | grad 53.75 | tok/s 13956
step     90 | loss 5.1279 | lr 3.00e-04 | grad 8.38 | tok/s 14202
step    100 | loss 4.0225 | lr 3.00e-04 | grad 7.22 | tok/s 14170
step    110 | loss 3.4488 | lr 3.00e-04 | grad 12.25 | tok/s 14160
step    120 | loss 3.1540 | lr 3.00e-04 | grad 10.81 | tok/s 14127
step    130 | loss 2.8834 | lr 3.00e-04 | grad 12.62 | tok/s 14148
step    140 | loss 2.5319 | lr 3.00e-04 | grad 7.66 | tok/s 14118
step    150 | loss 2.6256 | lr 3.00e-04 | grad 8.50 | tok/s 14088
step    160 | loss 2.2047 | lr 3.00e-04 | grad 6.81 | tok/s 14147
step    170 | loss 2.3410 | lr 3.00e-04 | grad 9.06 | tok/s 14166
step    180 | loss 2.1632 | lr 3.00e-04 | grad 5.41 | tok/s 14119
step    190 | loss 2.2688 | lr 3.00e-04 | grad 3.62 | tok/s 14114
step    200 | loss 1.9736 | lr 3.00e-04 | grad 4.34 | tok/s 14088
step    210 | loss 2.0124 | lr 3.00e-04 | grad 4.56 | tok/s 14104
step    220 | loss 2.1223 | lr 3.00e-04 | grad 2.67 | tok/s 13915
step    230 | loss 2.0173 | lr 3.00e-04 | grad 2.53 | tok/s 13761
step    240 | loss 2.2661 | lr 3.00e-04 | grad 3.91 | tok/s 13073
step    250 | loss 2.0799 | lr 3.00e-04 | grad 2.03 | tok/s 13419
step    260 | loss 1.5568 | lr 3.00e-04 | grad 2.27 | tok/s 13860
step    270 | loss 2.0786 | lr 3.00e-04 | grad 2.14 | tok/s 13664
step    280 | loss 2.2459 | lr 3.00e-04 | grad 4.22 | tok/s 13436
step    290 | loss 1.3536 | lr 3.00e-04 | grad 2.72 | tok/s 14161
step    300 | loss 0.5564 | lr 3.00e-04 | grad 2.45 | tok/s 14108
step    310 | loss 2.3843 | lr 3.00e-04 | grad 3.05 | tok/s 13879
step    320 | loss 1.9389 | lr 3.00e-04 | grad 4.41 | tok/s 13569
step    330 | loss 1.9339 | lr 3.00e-04 | grad 2.34 | tok/s 13076
step    340 | loss 2.2577 | lr 3.00e-04 | grad 2.28 | tok/s 13314
step    350 | loss 1.8853 | lr 3.00e-04 | grad 3.95 | tok/s 13664
step    360 | loss 1.2372 | lr 3.00e-04 | grad 5.94 | tok/s 13968
step    370 | loss 1.7999 | lr 3.00e-04 | grad 2.14 | tok/s 12689
step    380 | loss 1.7642 | lr 3.00e-04 | grad 2.05 | tok/s 13499
step    390 | loss 1.5328 | lr 3.00e-04 | grad 1.67 | tok/s 14082
step    400 | loss 1.4871 | lr 3.00e-04 | grad 1.99 | tok/s 13951
step    410 | loss 1.2800 | lr 3.00e-04 | grad 1.60 | tok/s 13636
step    420 | loss 1.8047 | lr 3.00e-04 | grad 3.44 | tok/s 13043
step    430 | loss 2.1521 | lr 3.00e-04 | grad 2.39 | tok/s 13883
step    440 | loss 2.1292 | lr 3.00e-04 | grad 3.38 | tok/s 13098
step    450 | loss 1.9332 | lr 3.00e-04 | grad 2.17 | tok/s 13578
step    460 | loss 1.7124 | lr 3.00e-04 | grad 2.30 | tok/s 13277
step    470 | loss 1.8207 | lr 3.00e-04 | grad 1.88 | tok/s 13699
step    480 | loss 2.2438 | lr 3.00e-04 | grad 5.50 | tok/s 13712
step    490 | loss 1.7728 | lr 3.00e-04 | grad 1.98 | tok/s 12954
step    500 | loss 1.6727 | lr 3.00e-04 | grad 2.69 | tok/s 13835
step    510 | loss 1.6981 | lr 3.00e-04 | grad 1.96 | tok/s 14015
step    520 | loss 1.6602 | lr 3.00e-04 | grad 1.66 | tok/s 14013
step    530 | loss 1.9028 | lr 3.00e-04 | grad 1.99 | tok/s 12337
step    540 | loss 1.7261 | lr 3.00e-04 | grad 1.74 | tok/s 13443
step    550 | loss 1.5603 | lr 3.00e-04 | grad 2.30 | tok/s 13151
step    560 | loss 1.7109 | lr 3.00e-04 | grad 2.11 | tok/s 12815
step    570 | loss 1.6464 | lr 3.00e-04 | grad 3.03 | tok/s 13172
step    580 | loss 1.5353 | lr 3.00e-04 | grad 1.77 | tok/s 13139
step    590 | loss 1.8519 | lr 3.00e-04 | grad 2.53 | tok/s 13479
step    600 | loss 1.8070 | lr 3.00e-04 | grad 1.85 | tok/s 13010
step    610 | loss 1.6179 | lr 3.00e-04 | grad 1.93 | tok/s 13710
step    620 | loss 1.5362 | lr 3.00e-04 | grad 2.02 | tok/s 12954
step    630 | loss 1.6597 | lr 3.00e-04 | grad 3.62 | tok/s 13069
step    640 | loss 1.7945 | lr 3.00e-04 | grad 1.95 | tok/s 13409
step    650 | loss 1.6513 | lr 3.00e-04 | grad 2.12 | tok/s 13482
step    660 | loss 1.6877 | lr 3.00e-04 | grad 1.73 | tok/s 13522
step    670 | loss 1.8958 | lr 3.00e-04 | grad 3.30 | tok/s 13630
step    680 | loss 1.7221 | lr 3.00e-04 | grad 1.98 | tok/s 13359
step    690 | loss 1.8064 | lr 3.00e-04 | grad 2.64 | tok/s 13812
step    700 | loss 1.4301 | lr 3.00e-04 | grad 2.55 | tok/s 14056
step    710 | loss 1.5798 | lr 3.00e-04 | grad 1.93 | tok/s 13166
step    720 | loss 1.4595 | lr 3.00e-04 | grad 3.30 | tok/s 12966
step    730 | loss 1.2978 | lr 3.00e-04 | grad 2.25 | tok/s 14048
step    740 | loss 1.5026 | lr 3.00e-04 | grad 1.92 | tok/s 13881
step    750 | loss 1.2091 | lr 3.00e-04 | grad 2.09 | tok/s 14094
step    760 | loss 1.1139 | lr 3.00e-04 | grad 1.84 | tok/s 14087
step    770 | loss 1.0580 | lr 3.00e-04 | grad 1.69 | tok/s 14065
step    780 | loss 0.9977 | lr 3.00e-04 | grad 1.76 | tok/s 14089
step    790 | loss 1.1268 | lr 3.00e-04 | grad 2.75 | tok/s 13666
step    800 | loss 1.8017 | lr 3.00e-04 | grad 4.69 | tok/s 13600
step    810 | loss 1.6883 | lr 3.00e-04 | grad 1.75 | tok/s 13525
step    820 | loss 1.6939 | lr 3.00e-04 | grad 3.23 | tok/s 12983
step    830 | loss 1.4954 | lr 3.00e-04 | grad 1.95 | tok/s 13946
step    840 | loss 1.3722 | lr 3.00e-04 | grad 1.86 | tok/s 14070
step    850 | loss 1.5893 | lr 3.00e-04 | grad 1.71 | tok/s 14029
step    860 | loss 1.4727 | lr 3.00e-04 | grad 2.94 | tok/s 13849
step    870 | loss 1.4924 | lr 3.00e-04 | grad 2.23 | tok/s 13352
step    880 | loss 1.6643 | lr 3.00e-04 | grad 2.25 | tok/s 12370
step    890 | loss 1.6634 | lr 3.00e-04 | grad 2.42 | tok/s 13619
step    900 | loss 1.5518 | lr 3.00e-04 | grad 2.09 | tok/s 13606
step    910 | loss 1.4057 | lr 3.00e-04 | grad 3.22 | tok/s 13305
step    920 | loss 1.5099 | lr 3.00e-04 | grad 3.00 | tok/s 13812
step    930 | loss 1.5852 | lr 3.00e-04 | grad 2.98 | tok/s 13227
step    940 | loss 1.3847 | lr 3.00e-04 | grad 1.55 | tok/s 13931
step    950 | loss 1.4713 | lr 3.00e-04 | grad 2.36 | tok/s 14022
step    960 | loss 1.3198 | lr 3.00e-04 | grad 2.08 | tok/s 13998
step    970 | loss 1.7242 | lr 3.00e-04 | grad 3.00 | tok/s 13197
step    980 | loss 1.6303 | lr 3.00e-04 | grad 2.00 | tok/s 13562
step    990 | loss 1.4410 | lr 3.00e-04 | grad 1.74 | tok/s 13746
step   1000 | loss 1.8149 | lr 3.00e-04 | grad 6.81 | tok/s 13226
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8149.pt
step   1010 | loss 1.7020 | lr 3.00e-04 | grad 2.02 | tok/s 5815
step   1020 | loss 1.6694 | lr 3.00e-04 | grad 2.09 | tok/s 13012
step   1030 | loss 1.4060 | lr 3.00e-04 | grad 1.47 | tok/s 13576
step   1040 | loss 1.5109 | lr 3.00e-04 | grad 3.33 | tok/s 13820
step   1050 | loss 1.5888 | lr 3.00e-04 | grad 1.92 | tok/s 13026
step   1060 | loss 1.6907 | lr 3.00e-04 | grad 1.91 | tok/s 13916
step   1070 | loss 1.6482 | lr 3.00e-04 | grad 2.80 | tok/s 13662
step   1080 | loss 1.3920 | lr 3.00e-04 | grad 2.12 | tok/s 12646
step   1090 | loss 0.9960 | lr 3.00e-04 | grad 1.02 | tok/s 14029
step   1100 | loss 1.5477 | lr 3.00e-04 | grad 2.38 | tok/s 13465
step   1110 | loss 1.4103 | lr 3.00e-04 | grad 1.56 | tok/s 14138
step   1120 | loss 1.3236 | lr 3.00e-04 | grad 1.85 | tok/s 14129
step   1130 | loss 1.2754 | lr 3.00e-04 | grad 1.68 | tok/s 14128
step   1140 | loss 1.2770 | lr 3.00e-04 | grad 1.55 | tok/s 14137
step   1150 | loss 1.2833 | lr 3.00e-04 | grad 1.65 | tok/s 14136
step   1160 | loss 1.2077 | lr 3.00e-04 | grad 1.61 | tok/s 14105
step   1170 | loss 1.2457 | lr 3.00e-04 | grad 1.71 | tok/s 13042
step   1180 | loss 1.3064 | lr 3.00e-04 | grad 1.42 | tok/s 14222
step   1190 | loss 1.2084 | lr 3.00e-04 | grad 1.69 | tok/s 14115
step   1200 | loss 1.2142 | lr 3.00e-04 | grad 1.58 | tok/s 14099
step   1210 | loss 1.2498 | lr 3.00e-04 | grad 1.45 | tok/s 14101
step   1220 | loss 1.2695 | lr 3.00e-04 | grad 1.40 | tok/s 14088
step   1230 | loss 1.2476 | lr 3.00e-04 | grad 1.40 | tok/s 14092
step   1240 | loss 1.2502 | lr 3.00e-04 | grad 2.48 | tok/s 13974
step   1250 | loss 1.7502 | lr 3.00e-04 | grad 2.08 | tok/s 13342
step   1260 | loss 1.3545 | lr 3.00e-04 | grad 2.80 | tok/s 13136
step   1270 | loss 1.7467 | lr 3.00e-04 | grad 2.53 | tok/s 13151
step   1280 | loss 1.5536 | lr 3.00e-04 | grad 1.91 | tok/s 13752
step   1290 | loss 1.4726 | lr 3.00e-04 | grad 2.23 | tok/s 13470
step   1300 | loss 1.5043 | lr 3.00e-04 | grad 1.84 | tok/s 13368
step   1310 | loss 1.4457 | lr 3.00e-04 | grad 1.66 | tok/s 14005
step   1320 | loss 1.5755 | lr 3.00e-04 | grad 1.95 | tok/s 13851
step   1330 | loss 1.5038 | lr 3.00e-04 | grad 1.84 | tok/s 13870
step   1340 | loss 1.5673 | lr 3.00e-04 | grad 2.81 | tok/s 13095
step   1350 | loss 1.6886 | lr 3.00e-04 | grad 1.95 | tok/s 12936
step   1360 | loss 1.4665 | lr 3.00e-04 | grad 1.54 | tok/s 13561
step   1370 | loss 1.4863 | lr 3.00e-04 | grad 5.50 | tok/s 13400
step   1380 | loss 1.5672 | lr 3.00e-04 | grad 2.50 | tok/s 12883
step   1390 | loss 1.4684 | lr 3.00e-04 | grad 3.05 | tok/s 13628
step   1400 | loss 1.3566 | lr 3.00e-04 | grad 1.37 | tok/s 13281
step   1410 | loss 1.5062 | lr 3.00e-04 | grad 5.97 | tok/s 13251
step   1420 | loss 1.6117 | lr 3.00e-04 | grad 1.95 | tok/s 12038
step   1430 | loss 1.3314 | lr 3.00e-04 | grad 1.84 | tok/s 13405
step   1440 | loss 1.1242 | lr 3.00e-04 | grad 1.69 | tok/s 14104
step   1450 | loss 1.1511 | lr 3.00e-04 | grad 2.06 | tok/s 13913
step   1460 | loss 1.6643 | lr 3.00e-04 | grad 1.91 | tok/s 13152
step   1470 | loss 1.5002 | lr 3.00e-04 | grad 1.68 | tok/s 13984
step   1480 | loss 1.8008 | lr 3.00e-04 | grad 2.84 | tok/s 13817
step   1490 | loss 1.5332 | lr 3.00e-04 | grad 2.23 | tok/s 14043
step   1500 | loss 1.2934 | lr 3.00e-04 | grad 1.72 | tok/s 14094
step   1510 | loss 1.5227 | lr 3.00e-04 | grad 2.34 | tok/s 13888
step   1520 | loss 1.4217 | lr 3.00e-04 | grad 2.25 | tok/s 13645
step   1530 | loss 1.4268 | lr 3.00e-04 | grad 2.33 | tok/s 13970
step   1540 | loss 1.5957 | lr 3.00e-04 | grad 2.16 | tok/s 13123
step   1550 | loss 1.2579 | lr 3.00e-04 | grad 2.12 | tok/s 14002
step   1560 | loss 1.5754 | lr 3.00e-04 | grad 1.70 | tok/s 13268
step   1570 | loss 1.2614 | lr 3.00e-04 | grad 1.86 | tok/s 13958
step   1580 | loss 1.6912 | lr 3.00e-04 | grad 3.83 | tok/s 13888
step   1590 | loss 1.5687 | lr 3.00e-04 | grad 1.89 | tok/s 13214
step   1600 | loss 0.9073 | lr 3.00e-04 | grad 0.96 | tok/s 14089
step   1610 | loss 1.0910 | lr 3.00e-04 | grad 1.55 | tok/s 13319
step   1620 | loss 1.3813 | lr 3.00e-04 | grad 2.62 | tok/s 13066
step   1630 | loss 1.3374 | lr 3.00e-04 | grad 1.49 | tok/s 13667
step   1640 | loss 1.3466 | lr 3.00e-04 | grad 1.73 | tok/s 13261
step   1650 | loss 1.5259 | lr 3.00e-04 | grad 2.30 | tok/s 12547
step   1660 | loss 1.3214 | lr 3.00e-04 | grad 1.42 | tok/s 14036
step   1670 | loss 1.4159 | lr 3.00e-04 | grad 2.92 | tok/s 13533
step   1680 | loss 1.6515 | lr 3.00e-04 | grad 1.45 | tok/s 12940
step   1690 | loss 1.4747 | lr 3.00e-04 | grad 3.19 | tok/s 13538
step   1700 | loss 1.4986 | lr 3.00e-04 | grad 1.71 | tok/s 13448
step   1710 | loss 1.4036 | lr 3.00e-04 | grad 1.80 | tok/s 13429
step   1720 | loss 1.5083 | lr 3.00e-04 | grad 2.50 | tok/s 14043
step   1730 | loss 1.1741 | lr 3.00e-04 | grad 2.19 | tok/s 14068
step   1740 | loss 1.3723 | lr 3.00e-04 | grad 2.23 | tok/s 13567
step   1750 | loss 1.5301 | lr 3.00e-04 | grad 2.16 | tok/s 13585
step   1760 | loss 1.5455 | lr 3.00e-04 | grad 1.76 | tok/s 13529
step   1770 | loss 1.4264 | lr 3.00e-04 | grad 1.88 | tok/s 13313
step   1780 | loss 1.4696 | lr 3.00e-04 | grad 1.62 | tok/s 13735
step   1790 | loss 1.4081 | lr 3.00e-04 | grad 2.39 | tok/s 13574
step   1800 | loss 1.5554 | lr 3.00e-04 | grad 1.62 | tok/s 13320
step   1810 | loss 1.4349 | lr 3.00e-04 | grad 2.91 | tok/s 13124
step   1820 | loss 1.4471 | lr 3.00e-04 | grad 5.31 | tok/s 13527
step   1830 | loss 1.4335 | lr 3.00e-04 | grad 3.00 | tok/s 13812
step   1840 | loss 1.4638 | lr 3.00e-04 | grad 1.49 | tok/s 13113
step   1850 | loss 1.2669 | lr 3.00e-04 | grad 1.53 | tok/s 14004
step   1860 | loss 1.3430 | lr 3.00e-04 | grad 2.33 | tok/s 13278
step   1870 | loss 1.3523 | lr 3.00e-04 | grad 1.48 | tok/s 13596
step   1880 | loss 1.2557 | lr 3.00e-04 | grad 2.36 | tok/s 13065
step   1890 | loss 1.5024 | lr 3.00e-04 | grad 1.68 | tok/s 12659
step   1900 | loss 1.3808 | lr 3.00e-04 | grad 1.77 | tok/s 13581
step   1910 | loss 1.4573 | lr 3.00e-04 | grad 1.80 | tok/s 12861
step   1920 | loss 1.3673 | lr 3.00e-04 | grad 1.53 | tok/s 14093
step   1930 | loss 1.4373 | lr 3.00e-04 | grad 2.84 | tok/s 12979
step   1940 | loss 1.4341 | lr 3.00e-04 | grad 1.82 | tok/s 13988
step   1950 | loss 1.8479 | lr 3.00e-04 | grad 2.77 | tok/s 13958
step   1960 | loss 1.4459 | lr 3.00e-04 | grad 3.56 | tok/s 14075
step   1970 | loss 1.4720 | lr 3.00e-04 | grad 2.09 | tok/s 13729
step   1980 | loss 1.5365 | lr 3.00e-04 | grad 1.82 | tok/s 13148
step   1990 | loss 1.5605 | lr 3.00e-04 | grad 1.98 | tok/s 13362
step   2000 | loss 1.4824 | lr 3.00e-04 | grad 2.12 | tok/s 13562
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4824.pt

Training complete! Final step: 2000
