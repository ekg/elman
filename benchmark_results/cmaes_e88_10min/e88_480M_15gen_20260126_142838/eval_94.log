Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_94/levelE88_100m_20260126_162204
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 489,128,128 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0962 | lr 3.00e-04 | grad 12.81 | tok/s 5420
step     20 | loss 2.6408 | lr 3.00e-04 | grad 4.97 | tok/s 11725
step     30 | loss 2.5159 | lr 3.00e-04 | grad 2.81 | tok/s 11865
step     40 | loss 2.3597 | lr 3.00e-04 | grad 2.78 | tok/s 11376
step     50 | loss 2.9648 | lr 3.00e-04 | grad 10.25 | tok/s 11528
step     60 | loss 2.0437 | lr 3.00e-04 | grad 2.72 | tok/s 11917
step     70 | loss 1.9014 | lr 3.00e-04 | grad 3.88 | tok/s 12065
step     80 | loss 5.5175 | lr 3.00e-04 | grad 59.75 | tok/s 12169
step     90 | loss 5.1600 | lr 3.00e-04 | grad 8.44 | tok/s 12371
step    100 | loss 4.1634 | lr 3.00e-04 | grad 8.00 | tok/s 12357
step    110 | loss 3.6148 | lr 3.00e-04 | grad 13.31 | tok/s 12342
step    120 | loss 3.2629 | lr 3.00e-04 | grad 10.88 | tok/s 12334
step    130 | loss 2.9241 | lr 3.00e-04 | grad 12.69 | tok/s 12345
step    140 | loss 2.6209 | lr 3.00e-04 | grad 7.72 | tok/s 12330
step    150 | loss 2.7384 | lr 3.00e-04 | grad 8.44 | tok/s 12319
step    160 | loss 2.2862 | lr 3.00e-04 | grad 7.34 | tok/s 12326
step    170 | loss 2.3636 | lr 3.00e-04 | grad 8.12 | tok/s 12321
step    180 | loss 2.1554 | lr 3.00e-04 | grad 4.69 | tok/s 12318
step    190 | loss 2.2631 | lr 3.00e-04 | grad 3.67 | tok/s 12306
step    200 | loss 1.9887 | lr 3.00e-04 | grad 3.97 | tok/s 12302
step    210 | loss 1.9906 | lr 3.00e-04 | grad 4.00 | tok/s 12314
step    220 | loss 2.1199 | lr 3.00e-04 | grad 2.45 | tok/s 12145
step    230 | loss 1.9843 | lr 3.00e-04 | grad 2.53 | tok/s 11209
step    240 | loss 2.2540 | lr 3.00e-04 | grad 3.47 | tok/s 11406
step    250 | loss 2.0878 | lr 3.00e-04 | grad 1.91 | tok/s 11701
step    260 | loss 1.5670 | lr 3.00e-04 | grad 2.16 | tok/s 12061
step    270 | loss 2.0772 | lr 3.00e-04 | grad 2.06 | tok/s 11888
step    280 | loss 2.2579 | lr 3.00e-04 | grad 4.41 | tok/s 11679
step    290 | loss 1.3784 | lr 3.00e-04 | grad 2.48 | tok/s 12297
step    300 | loss 0.5619 | lr 3.00e-04 | grad 2.50 | tok/s 12288
step    310 | loss 2.3947 | lr 3.00e-04 | grad 2.94 | tok/s 12082
step    320 | loss 1.9448 | lr 3.00e-04 | grad 4.16 | tok/s 11906
step    330 | loss 1.9246 | lr 3.00e-04 | grad 2.19 | tok/s 11460
step    340 | loss 2.2496 | lr 3.00e-04 | grad 2.09 | tok/s 11666
step    350 | loss 1.8898 | lr 3.00e-04 | grad 2.88 | tok/s 11893
step    360 | loss 1.2102 | lr 3.00e-04 | grad 6.59 | tok/s 12246
step    370 | loss 1.8044 | lr 3.00e-04 | grad 1.97 | tok/s 11046
step    380 | loss 1.7732 | lr 3.00e-04 | grad 1.85 | tok/s 11778
step    390 | loss 1.5326 | lr 3.00e-04 | grad 1.52 | tok/s 12301
step    400 | loss 1.4894 | lr 3.00e-04 | grad 1.93 | tok/s 12219
step    410 | loss 1.2816 | lr 3.00e-04 | grad 1.50 | tok/s 11918
step    420 | loss 1.8019 | lr 3.00e-04 | grad 3.34 | tok/s 10683
step    430 | loss 2.1538 | lr 3.00e-04 | grad 2.27 | tok/s 12124
step    440 | loss 2.1281 | lr 3.00e-04 | grad 3.27 | tok/s 11467
step    450 | loss 1.9027 | lr 3.00e-04 | grad 2.06 | tok/s 11816
step    460 | loss 1.7184 | lr 3.00e-04 | grad 2.30 | tok/s 11567
step    470 | loss 1.8167 | lr 3.00e-04 | grad 1.78 | tok/s 11938
step    480 | loss 2.2370 | lr 3.00e-04 | grad 5.31 | tok/s 11969
step    490 | loss 1.7740 | lr 3.00e-04 | grad 1.84 | tok/s 11280
step    500 | loss 1.6715 | lr 3.00e-04 | grad 2.58 | tok/s 12051
step    510 | loss 1.6942 | lr 3.00e-04 | grad 1.77 | tok/s 12249
step    520 | loss 1.6585 | lr 3.00e-04 | grad 1.57 | tok/s 12234
step    530 | loss 1.8997 | lr 3.00e-04 | grad 1.98 | tok/s 11710
step    540 | loss 1.7237 | lr 3.00e-04 | grad 1.66 | tok/s 11741
step    550 | loss 1.5630 | lr 3.00e-04 | grad 2.22 | tok/s 11453
step    560 | loss 1.7108 | lr 3.00e-04 | grad 2.02 | tok/s 10368
step    570 | loss 1.6523 | lr 3.00e-04 | grad 2.86 | tok/s 11484
step    580 | loss 1.5332 | lr 3.00e-04 | grad 1.68 | tok/s 11533
step    590 | loss 1.8520 | lr 3.00e-04 | grad 2.39 | tok/s 11759
step    600 | loss 1.8096 | lr 3.00e-04 | grad 1.80 | tok/s 11382
step    610 | loss 1.6117 | lr 3.00e-04 | grad 1.80 | tok/s 11961
step    620 | loss 1.5353 | lr 3.00e-04 | grad 1.88 | tok/s 11349
step    630 | loss 1.6501 | lr 3.00e-04 | grad 3.42 | tok/s 11411
step    640 | loss 1.7919 | lr 3.00e-04 | grad 1.92 | tok/s 11733
step    650 | loss 1.6490 | lr 3.00e-04 | grad 1.99 | tok/s 11805
step    660 | loss 1.6828 | lr 3.00e-04 | grad 1.68 | tok/s 11809
step    670 | loss 1.8908 | lr 3.00e-04 | grad 6.00 | tok/s 11957
step    680 | loss 1.7095 | lr 3.00e-04 | grad 1.91 | tok/s 11662
step    690 | loss 1.8152 | lr 3.00e-04 | grad 2.50 | tok/s 12086
step    700 | loss 1.4252 | lr 3.00e-04 | grad 2.36 | tok/s 12314
step    710 | loss 1.5668 | lr 3.00e-04 | grad 1.83 | tok/s 11544
step    720 | loss 1.4502 | lr 3.00e-04 | grad 2.83 | tok/s 11299
step    730 | loss 1.2921 | lr 3.00e-04 | grad 2.16 | tok/s 12358
step    740 | loss 1.4885 | lr 3.00e-04 | grad 1.84 | tok/s 12139
step    750 | loss 1.2017 | lr 3.00e-04 | grad 2.00 | tok/s 12323
step    760 | loss 1.1041 | lr 3.00e-04 | grad 1.71 | tok/s 12298
step    770 | loss 1.0527 | lr 3.00e-04 | grad 1.58 | tok/s 12371
step    780 | loss 0.9873 | lr 3.00e-04 | grad 1.54 | tok/s 12312
step    790 | loss 1.1126 | lr 3.00e-04 | grad 2.58 | tok/s 11934
step    800 | loss 1.8020 | lr 3.00e-04 | grad 4.38 | tok/s 11837
step    810 | loss 1.6865 | lr 3.00e-04 | grad 1.67 | tok/s 11798
step    820 | loss 1.6929 | lr 3.00e-04 | grad 3.05 | tok/s 11351
step    830 | loss 1.5000 | lr 3.00e-04 | grad 1.91 | tok/s 12203
step    840 | loss 1.3725 | lr 3.00e-04 | grad 1.82 | tok/s 12349
step    850 | loss 1.5926 | lr 3.00e-04 | grad 1.61 | tok/s 12263
step    860 | loss 1.4708 | lr 3.00e-04 | grad 2.95 | tok/s 12124
step    870 | loss 1.4906 | lr 3.00e-04 | grad 2.14 | tok/s 11687
step    880 | loss 1.6571 | lr 3.00e-04 | grad 2.17 | tok/s 11722
step    890 | loss 1.6633 | lr 3.00e-04 | grad 2.38 | tok/s 11925
step    900 | loss 1.5531 | lr 3.00e-04 | grad 2.03 | tok/s 11889
step    910 | loss 1.4094 | lr 3.00e-04 | grad 3.05 | tok/s 11677
step    920 | loss 1.5078 | lr 3.00e-04 | grad 2.81 | tok/s 12116
step    930 | loss 1.5810 | lr 3.00e-04 | grad 2.89 | tok/s 11584
step    940 | loss 1.3808 | lr 3.00e-04 | grad 1.46 | tok/s 12197
step    950 | loss 1.4759 | lr 3.00e-04 | grad 2.72 | tok/s 12253
step    960 | loss 1.3184 | lr 3.00e-04 | grad 2.00 | tok/s 12279
step    970 | loss 1.7186 | lr 3.00e-04 | grad 2.95 | tok/s 11563
step    980 | loss 1.6238 | lr 3.00e-04 | grad 1.91 | tok/s 11844
step    990 | loss 1.4364 | lr 3.00e-04 | grad 1.69 | tok/s 12052
step   1000 | loss 1.8068 | lr 3.00e-04 | grad 6.31 | tok/s 10900
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8068.pt
step   1010 | loss 1.6936 | lr 3.00e-04 | grad 1.92 | tok/s 5262
step   1020 | loss 1.6609 | lr 3.00e-04 | grad 2.05 | tok/s 11310
step   1030 | loss 1.4041 | lr 3.00e-04 | grad 1.44 | tok/s 11806
step   1040 | loss 1.5085 | lr 3.00e-04 | grad 3.20 | tok/s 12023
step   1050 | loss 1.5837 | lr 3.00e-04 | grad 1.84 | tok/s 11319
step   1060 | loss 1.6824 | lr 3.00e-04 | grad 1.84 | tok/s 12104
step   1070 | loss 1.6427 | lr 3.00e-04 | grad 2.73 | tok/s 11910
step   1080 | loss 1.3889 | lr 3.00e-04 | grad 2.05 | tok/s 11009
step   1090 | loss 0.9885 | lr 3.00e-04 | grad 0.92 | tok/s 12193
step   1100 | loss 1.5429 | lr 3.00e-04 | grad 2.28 | tok/s 11700
step   1110 | loss 1.4090 | lr 3.00e-04 | grad 1.46 | tok/s 12307
step   1120 | loss 1.3260 | lr 3.00e-04 | grad 1.76 | tok/s 12292
step   1130 | loss 1.2685 | lr 3.00e-04 | grad 1.60 | tok/s 12309
step   1140 | loss 1.2727 | lr 3.00e-04 | grad 1.48 | tok/s 12308
step   1150 | loss 1.2830 | lr 3.00e-04 | grad 1.52 | tok/s 12292
step   1160 | loss 1.2053 | lr 3.00e-04 | grad 1.52 | tok/s 12309
step   1170 | loss 1.2427 | lr 3.00e-04 | grad 1.66 | tok/s 12333
step   1180 | loss 1.3034 | lr 3.00e-04 | grad 1.38 | tok/s 12290
step   1190 | loss 1.2037 | lr 3.00e-04 | grad 1.66 | tok/s 12365
step   1200 | loss 1.2097 | lr 3.00e-04 | grad 1.52 | tok/s 12373
step   1210 | loss 1.2485 | lr 3.00e-04 | grad 1.39 | tok/s 12308
step   1220 | loss 1.2665 | lr 3.00e-04 | grad 1.32 | tok/s 12303
step   1230 | loss 1.2423 | lr 3.00e-04 | grad 1.33 | tok/s 12367
step   1240 | loss 1.2469 | lr 3.00e-04 | grad 2.42 | tok/s 12240
step   1250 | loss 1.7458 | lr 3.00e-04 | grad 2.09 | tok/s 11668
step   1260 | loss 1.3353 | lr 3.00e-04 | grad 2.62 | tok/s 11493
step   1270 | loss 1.7409 | lr 3.00e-04 | grad 2.55 | tok/s 11485
step   1280 | loss 1.5565 | lr 3.00e-04 | grad 1.80 | tok/s 11997
step   1290 | loss 1.4717 | lr 3.00e-04 | grad 2.20 | tok/s 11789
step   1300 | loss 1.4980 | lr 3.00e-04 | grad 1.79 | tok/s 11683
step   1310 | loss 1.4407 | lr 3.00e-04 | grad 1.60 | tok/s 12259
step   1320 | loss 1.5705 | lr 3.00e-04 | grad 1.96 | tok/s 12113
step   1330 | loss 1.4959 | lr 3.00e-04 | grad 1.65 | tok/s 12097
step   1340 | loss 1.5724 | lr 3.00e-04 | grad 2.78 | tok/s 11447
step   1350 | loss 1.6819 | lr 3.00e-04 | grad 1.88 | tok/s 11324
step   1360 | loss 1.4642 | lr 3.00e-04 | grad 1.52 | tok/s 11898
step   1370 | loss 1.4790 | lr 3.00e-04 | grad 5.50 | tok/s 11754
step   1380 | loss 1.5590 | lr 3.00e-04 | grad 2.31 | tok/s 11260
step   1390 | loss 1.4576 | lr 3.00e-04 | grad 3.16 | tok/s 11896
step   1400 | loss 1.3560 | lr 3.00e-04 | grad 1.33 | tok/s 11603
step   1410 | loss 1.4944 | lr 3.00e-04 | grad 5.59 | tok/s 11619
step   1420 | loss 1.6005 | lr 3.00e-04 | grad 1.87 | tok/s 11568
step   1430 | loss 1.3238 | lr 3.00e-04 | grad 1.74 | tok/s 11722
step   1440 | loss 1.1247 | lr 3.00e-04 | grad 1.59 | tok/s 12327
step   1450 | loss 1.1504 | lr 3.00e-04 | grad 2.05 | tok/s 11437
step   1460 | loss 1.6529 | lr 3.00e-04 | grad 1.84 | tok/s 11482
step   1470 | loss 1.4978 | lr 3.00e-04 | grad 1.66 | tok/s 12265
step   1480 | loss 1.7962 | lr 3.00e-04 | grad 2.77 | tok/s 12123
step   1490 | loss 1.5254 | lr 3.00e-04 | grad 2.19 | tok/s 12281
step   1500 | loss 1.2852 | lr 3.00e-04 | grad 1.68 | tok/s 12345
step   1510 | loss 1.5155 | lr 3.00e-04 | grad 2.25 | tok/s 12141
step   1520 | loss 1.4162 | lr 3.00e-04 | grad 2.12 | tok/s 11946
step   1530 | loss 1.4125 | lr 3.00e-04 | grad 2.22 | tok/s 12241
step   1540 | loss 1.5910 | lr 3.00e-04 | grad 2.06 | tok/s 11435
step   1550 | loss 1.2551 | lr 3.00e-04 | grad 2.08 | tok/s 12207
step   1560 | loss 1.5700 | lr 3.00e-04 | grad 1.64 | tok/s 11574
step   1570 | loss 1.2618 | lr 3.00e-04 | grad 1.82 | tok/s 12211
step   1580 | loss 1.6841 | lr 3.00e-04 | grad 4.03 | tok/s 12162
step   1590 | loss 1.5683 | lr 3.00e-04 | grad 1.85 | tok/s 11579
step   1600 | loss 0.9062 | lr 3.00e-04 | grad 1.38 | tok/s 12320
step   1610 | loss 1.0870 | lr 3.00e-04 | grad 1.48 | tok/s 11658
step   1620 | loss 1.3728 | lr 3.00e-04 | grad 2.69 | tok/s 11432
step   1630 | loss 1.3442 | lr 3.00e-04 | grad 1.45 | tok/s 11984
step   1640 | loss 1.3415 | lr 3.00e-04 | grad 1.62 | tok/s 11592
step   1650 | loss 1.5207 | lr 3.00e-04 | grad 2.33 | tok/s 10971
step   1660 | loss 1.3210 | lr 3.00e-04 | grad 1.40 | tok/s 12319
step   1670 | loss 1.4007 | lr 3.00e-04 | grad 2.81 | tok/s 11860
step   1680 | loss 1.6498 | lr 3.00e-04 | grad 1.42 | tok/s 11348
step   1690 | loss 1.4663 | lr 3.00e-04 | grad 3.47 | tok/s 11868
step   1700 | loss 1.4849 | lr 3.00e-04 | grad 1.63 | tok/s 11185
step   1710 | loss 1.3883 | lr 3.00e-04 | grad 1.74 | tok/s 11780
step   1720 | loss 1.4933 | lr 3.00e-04 | grad 2.27 | tok/s 12300
step   1730 | loss 1.1700 | lr 3.00e-04 | grad 2.27 | tok/s 12319
step   1740 | loss 1.3740 | lr 3.00e-04 | grad 2.16 | tok/s 11922
step   1750 | loss 1.5312 | lr 3.00e-04 | grad 2.06 | tok/s 11903

Training complete! Final step: 1759
