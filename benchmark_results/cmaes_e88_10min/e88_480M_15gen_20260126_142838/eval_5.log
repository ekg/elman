Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_5/levelE88_100m_20260126_142845
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 494,142,560 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.4398 | lr 3.00e-04 | grad 24.12 | tok/s 5904
step     20 | loss 2.7255 | lr 3.00e-04 | grad 11.00 | tok/s 14246
step     30 | loss 2.6040 | lr 3.00e-04 | grad 5.81 | tok/s 14455
step     40 | loss 2.4362 | lr 3.00e-04 | grad 4.62 | tok/s 13804
step     50 | loss 3.1280 | lr 3.00e-04 | grad 17.38 | tok/s 14049
step     60 | loss 2.1211 | lr 3.00e-04 | grad 4.78 | tok/s 14448
step     70 | loss 1.9517 | lr 3.00e-04 | grad 6.06 | tok/s 14625
step     80 | loss 6.1320 | lr 3.00e-04 | grad 182.00 | tok/s 14693
step     90 | loss 6.2424 | lr 3.00e-04 | grad 18.25 | tok/s 14935
step    100 | loss 5.0959 | lr 3.00e-04 | grad 16.75 | tok/s 14872
step    110 | loss 4.6288 | lr 3.00e-04 | grad 33.00 | tok/s 14915
step    120 | loss 4.0339 | lr 3.00e-04 | grad 37.25 | tok/s 14858
step    130 | loss 3.6647 | lr 3.00e-04 | grad 37.25 | tok/s 13874
step    140 | loss 2.9252 | lr 3.00e-04 | grad 21.50 | tok/s 14792
step    150 | loss 3.4507 | lr 3.00e-04 | grad 28.12 | tok/s 14762
step    160 | loss 2.5847 | lr 3.00e-04 | grad 27.50 | tok/s 14792
step    170 | loss 2.6819 | lr 3.00e-04 | grad 22.50 | tok/s 14714
step    180 | loss 2.4076 | lr 3.00e-04 | grad 7.28 | tok/s 14686
step    190 | loss 2.7451 | lr 3.00e-04 | grad 12.00 | tok/s 14659
step    200 | loss 2.3276 | lr 3.00e-04 | grad 13.94 | tok/s 14623
step    210 | loss 2.3291 | lr 3.00e-04 | grad 11.62 | tok/s 14622
step    220 | loss 2.3434 | lr 3.00e-04 | grad 3.53 | tok/s 14379
step    230 | loss 2.1076 | lr 3.00e-04 | grad 5.00 | tok/s 14199
step    240 | loss 2.3108 | lr 3.00e-04 | grad 4.97 | tok/s 13452
step    250 | loss 2.1386 | lr 3.00e-04 | grad 2.44 | tok/s 13791
step    260 | loss 1.5925 | lr 3.00e-04 | grad 2.89 | tok/s 14229
step    270 | loss 2.1357 | lr 3.00e-04 | grad 2.61 | tok/s 13232
step    280 | loss 2.2871 | lr 3.00e-04 | grad 4.88 | tok/s 13845
step    290 | loss 1.5289 | lr 3.00e-04 | grad 4.12 | tok/s 14472
step    300 | loss 0.6192 | lr 3.00e-04 | grad 2.53 | tok/s 14437
step    310 | loss 2.4156 | lr 3.00e-04 | grad 3.36 | tok/s 14171
step    320 | loss 1.9648 | lr 3.00e-04 | grad 5.75 | tok/s 13900
step    330 | loss 1.9832 | lr 3.00e-04 | grad 2.86 | tok/s 13415
step    340 | loss 2.3165 | lr 3.00e-04 | grad 2.70 | tok/s 13595
step    350 | loss 1.9156 | lr 3.00e-04 | grad 4.78 | tok/s 13894
step    360 | loss 1.2433 | lr 3.00e-04 | grad 6.44 | tok/s 14179
step    370 | loss 1.8378 | lr 3.00e-04 | grad 2.47 | tok/s 12851
step    380 | loss 1.8057 | lr 3.00e-04 | grad 2.36 | tok/s 13698
step    390 | loss 1.5698 | lr 3.00e-04 | grad 1.95 | tok/s 14305
step    400 | loss 1.5169 | lr 3.00e-04 | grad 2.41 | tok/s 14158
step    410 | loss 1.3009 | lr 3.00e-04 | grad 1.97 | tok/s 13835
step    420 | loss 1.8475 | lr 3.00e-04 | grad 4.22 | tok/s 12535
step    430 | loss 2.1863 | lr 3.00e-04 | grad 2.81 | tok/s 14076
step    440 | loss 2.1886 | lr 3.00e-04 | grad 3.94 | tok/s 13236
step    450 | loss 1.9636 | lr 3.00e-04 | grad 2.67 | tok/s 13705
step    460 | loss 1.7482 | lr 3.00e-04 | grad 2.67 | tok/s 13416
step    470 | loss 1.8605 | lr 3.00e-04 | grad 2.23 | tok/s 13786
step    480 | loss 2.2923 | lr 3.00e-04 | grad 6.31 | tok/s 13837
step    490 | loss 1.8096 | lr 3.00e-04 | grad 2.45 | tok/s 13074
step    500 | loss 1.7153 | lr 3.00e-04 | grad 3.14 | tok/s 13918
step    510 | loss 1.7356 | lr 3.00e-04 | grad 2.23 | tok/s 14098
step    520 | loss 1.6902 | lr 3.00e-04 | grad 1.94 | tok/s 14062
step    530 | loss 1.9455 | lr 3.00e-04 | grad 2.42 | tok/s 13571
step    540 | loss 1.7668 | lr 3.00e-04 | grad 2.11 | tok/s 13542
step    550 | loss 1.5912 | lr 3.00e-04 | grad 2.83 | tok/s 13282
step    560 | loss 1.7473 | lr 3.00e-04 | grad 2.41 | tok/s 12492
step    570 | loss 1.6969 | lr 3.00e-04 | grad 3.38 | tok/s 13294
step    580 | loss 1.5678 | lr 3.00e-04 | grad 2.02 | tok/s 13230
step    590 | loss 1.8978 | lr 3.00e-04 | grad 2.94 | tok/s 13544
step    600 | loss 1.8462 | lr 3.00e-04 | grad 2.14 | tok/s 13061
step    610 | loss 1.6470 | lr 3.00e-04 | grad 2.19 | tok/s 13774
step    620 | loss 1.5641 | lr 3.00e-04 | grad 2.34 | tok/s 13043
step    630 | loss 1.6838 | lr 3.00e-04 | grad 4.12 | tok/s 13151
step    640 | loss 1.8351 | lr 3.00e-04 | grad 2.34 | tok/s 13495
step    650 | loss 1.6837 | lr 3.00e-04 | grad 2.41 | tok/s 13536
step    660 | loss 1.7198 | lr 3.00e-04 | grad 1.95 | tok/s 13610
step    670 | loss 1.9476 | lr 3.00e-04 | grad 2.97 | tok/s 13710
step    680 | loss 1.7531 | lr 3.00e-04 | grad 2.25 | tok/s 13455
step    690 | loss 1.8739 | lr 3.00e-04 | grad 3.09 | tok/s 13852
step    700 | loss 1.4648 | lr 3.00e-04 | grad 2.89 | tok/s 14145
step    710 | loss 1.6124 | lr 3.00e-04 | grad 2.25 | tok/s 12646
step    720 | loss 1.4882 | lr 3.00e-04 | grad 3.12 | tok/s 13012
step    730 | loss 1.3133 | lr 3.00e-04 | grad 2.58 | tok/s 14105
step    740 | loss 1.5155 | lr 3.00e-04 | grad 2.22 | tok/s 13952
step    750 | loss 1.2180 | lr 3.00e-04 | grad 2.44 | tok/s 14141
step    760 | loss 1.1259 | lr 3.00e-04 | grad 2.06 | tok/s 14125
step    770 | loss 1.0715 | lr 3.00e-04 | grad 1.98 | tok/s 14176
step    780 | loss 1.0060 | lr 3.00e-04 | grad 1.95 | tok/s 14154
step    790 | loss 1.1378 | lr 3.00e-04 | grad 3.05 | tok/s 13693
step    800 | loss 1.8464 | lr 3.00e-04 | grad 5.06 | tok/s 13685
step    810 | loss 1.7238 | lr 3.00e-04 | grad 2.00 | tok/s 13567
step    820 | loss 1.7312 | lr 3.00e-04 | grad 3.64 | tok/s 13026
step    830 | loss 1.5025 | lr 3.00e-04 | grad 2.19 | tok/s 13990
step    840 | loss 1.3823 | lr 3.00e-04 | grad 2.11 | tok/s 14135
step    850 | loss 1.6053 | lr 3.00e-04 | grad 1.91 | tok/s 13618
step    860 | loss 1.4926 | lr 3.00e-04 | grad 3.25 | tok/s 13928
step    870 | loss 1.5150 | lr 3.00e-04 | grad 2.47 | tok/s 13441
step    880 | loss 1.7025 | lr 3.00e-04 | grad 2.47 | tok/s 13488
step    890 | loss 1.7026 | lr 3.00e-04 | grad 2.80 | tok/s 13655
step    900 | loss 1.5827 | lr 3.00e-04 | grad 2.42 | tok/s 13678
step    910 | loss 1.4377 | lr 3.00e-04 | grad 3.70 | tok/s 13387
step    920 | loss 1.5440 | lr 3.00e-04 | grad 3.48 | tok/s 13899
step    930 | loss 1.6170 | lr 3.00e-04 | grad 3.45 | tok/s 13320
step    940 | loss 1.4006 | lr 3.00e-04 | grad 1.76 | tok/s 14017
step    950 | loss 1.4969 | lr 3.00e-04 | grad 2.69 | tok/s 14078
step    960 | loss 1.3383 | lr 3.00e-04 | grad 2.38 | tok/s 14126
step    970 | loss 1.7550 | lr 3.00e-04 | grad 3.42 | tok/s 13306
step    980 | loss 1.6649 | lr 3.00e-04 | grad 2.33 | tok/s 13639
step    990 | loss 1.4634 | lr 3.00e-04 | grad 1.96 | tok/s 13357
step   1000 | loss 1.8569 | lr 3.00e-04 | grad 7.34 | tok/s 13304
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8569.pt
step   1010 | loss 1.6606 | lr 3.00e-04 | grad 3.20 | tok/s 6205
step   1020 | loss 1.6670 | lr 3.00e-04 | grad 1.88 | tok/s 13008
step   1030 | loss 1.4724 | lr 3.00e-04 | grad 1.99 | tok/s 13527
step   1040 | loss 1.4926 | lr 3.00e-04 | grad 2.08 | tok/s 13966
step   1050 | loss 1.6437 | lr 3.00e-04 | grad 3.16 | tok/s 12920
step   1060 | loss 1.7465 | lr 3.00e-04 | grad 3.27 | tok/s 13964
step   1070 | loss 1.6573 | lr 3.00e-04 | grad 2.55 | tok/s 13919
step   1080 | loss 1.4156 | lr 3.00e-04 | grad 1.84 | tok/s 12615
step   1090 | loss 1.1246 | lr 3.00e-04 | grad 1.09 | tok/s 13921
step   1100 | loss 1.4553 | lr 3.00e-04 | grad 3.11 | tok/s 13506
step   1110 | loss 1.4742 | lr 3.00e-04 | grad 1.88 | tok/s 14177
step   1120 | loss 1.3441 | lr 3.00e-04 | grad 1.95 | tok/s 14214
step   1130 | loss 1.2979 | lr 3.00e-04 | grad 1.84 | tok/s 14182
step   1140 | loss 1.2884 | lr 3.00e-04 | grad 1.99 | tok/s 13687
step   1150 | loss 1.3048 | lr 3.00e-04 | grad 1.70 | tok/s 14186
step   1160 | loss 1.2198 | lr 3.00e-04 | grad 1.72 | tok/s 14207
step   1170 | loss 1.2495 | lr 3.00e-04 | grad 1.99 | tok/s 14185
step   1180 | loss 1.3470 | lr 3.00e-04 | grad 1.61 | tok/s 14181
step   1190 | loss 1.2263 | lr 3.00e-04 | grad 2.03 | tok/s 14183
step   1200 | loss 1.2237 | lr 3.00e-04 | grad 1.96 | tok/s 14143
step   1210 | loss 1.2742 | lr 3.00e-04 | grad 1.95 | tok/s 14129
step   1220 | loss 1.2957 | lr 3.00e-04 | grad 1.88 | tok/s 14118
step   1230 | loss 1.2661 | lr 3.00e-04 | grad 1.69 | tok/s 14205
step   1240 | loss 1.2289 | lr 3.00e-04 | grad 1.49 | tok/s 14115
step   1250 | loss 1.8284 | lr 3.00e-04 | grad 3.50 | tok/s 13382
step   1260 | loss 1.4096 | lr 3.00e-04 | grad 2.69 | tok/s 13281
step   1270 | loss 1.6757 | lr 3.00e-04 | grad 4.53 | tok/s 13194
step   1280 | loss 1.6358 | lr 3.00e-04 | grad 1.76 | tok/s 13096
step   1290 | loss 1.4867 | lr 3.00e-04 | grad 2.00 | tok/s 13544
step   1300 | loss 1.5318 | lr 3.00e-04 | grad 2.42 | tok/s 13608
step   1310 | loss 1.4717 | lr 3.00e-04 | grad 2.23 | tok/s 13818
step   1320 | loss 1.6018 | lr 3.00e-04 | grad 2.11 | tok/s 13931
step   1330 | loss 1.6222 | lr 3.00e-04 | grad 2.28 | tok/s 13927
step   1340 | loss 1.5018 | lr 3.00e-04 | grad 9.19 | tok/s 13274
step   1350 | loss 1.7405 | lr 3.00e-04 | grad 2.31 | tok/s 12878
step   1360 | loss 1.4997 | lr 3.00e-04 | grad 2.20 | tok/s 13645
step   1370 | loss 1.4195 | lr 3.00e-04 | grad 1.55 | tok/s 13486
step   1380 | loss 1.6709 | lr 3.00e-04 | grad 2.25 | tok/s 12917
step   1390 | loss 1.5301 | lr 3.00e-04 | grad 1.68 | tok/s 13766
step   1400 | loss 1.4193 | lr 3.00e-04 | grad 1.68 | tok/s 13247
step   1410 | loss 1.4708 | lr 3.00e-04 | grad 2.91 | tok/s 13271
step   1420 | loss 1.6989 | lr 3.00e-04 | grad 3.73 | tok/s 12872
step   1430 | loss 1.3589 | lr 3.00e-04 | grad 1.89 | tok/s 13580
step   1440 | loss 1.1578 | lr 3.00e-04 | grad 1.80 | tok/s 14035
step   1450 | loss 1.1754 | lr 3.00e-04 | grad 4.16 | tok/s 14070
step   1460 | loss 1.6788 | lr 3.00e-04 | grad 1.99 | tok/s 13290
step   1470 | loss 1.5334 | lr 3.00e-04 | grad 1.80 | tok/s 13773
step   1480 | loss 1.8398 | lr 3.00e-04 | grad 3.84 | tok/s 13862
step   1490 | loss 1.5776 | lr 3.00e-04 | grad 1.68 | tok/s 14070
step   1500 | loss 1.3485 | lr 3.00e-04 | grad 1.73 | tok/s 14186
step   1510 | loss 1.5330 | lr 3.00e-04 | grad 1.91 | tok/s 13953
step   1520 | loss 1.4380 | lr 3.00e-04 | grad 3.17 | tok/s 13680
step   1530 | loss 1.4521 | lr 3.00e-04 | grad 1.62 | tok/s 14034
step   1540 | loss 1.6493 | lr 3.00e-04 | grad 2.27 | tok/s 13141
step   1550 | loss 1.3020 | lr 3.00e-04 | grad 2.17 | tok/s 14045
step   1560 | loss 1.5939 | lr 3.00e-04 | grad 2.53 | tok/s 13338
step   1570 | loss 1.2915 | lr 3.00e-04 | grad 2.06 | tok/s 13638
step   1580 | loss 1.7391 | lr 3.00e-04 | grad 3.88 | tok/s 13786
step   1590 | loss 1.6163 | lr 3.00e-04 | grad 2.28 | tok/s 13264
step   1600 | loss 1.0120 | lr 3.00e-04 | grad 1.46 | tok/s 14204
step   1610 | loss 1.0391 | lr 3.00e-04 | grad 2.36 | tok/s 13705
step   1620 | loss 1.4336 | lr 3.00e-04 | grad 2.81 | tok/s 12835
step   1630 | loss 1.3577 | lr 3.00e-04 | grad 2.20 | tok/s 13784
step   1640 | loss 1.3474 | lr 3.00e-04 | grad 2.16 | tok/s 13465
step   1650 | loss 1.5396 | lr 3.00e-04 | grad 2.44 | tok/s 12909
step   1660 | loss 1.4032 | lr 3.00e-04 | grad 1.69 | tok/s 13780
step   1670 | loss 1.3681 | lr 3.00e-04 | grad 5.06 | tok/s 13751
step   1680 | loss 1.7370 | lr 3.00e-04 | grad 1.86 | tok/s 13149
step   1690 | loss 1.5077 | lr 3.00e-04 | grad 4.12 | tok/s 13433
step   1700 | loss 1.5219 | lr 3.00e-04 | grad 2.23 | tok/s 13726
step   1710 | loss 1.4292 | lr 3.00e-04 | grad 2.14 | tok/s 12967
step   1720 | loss 1.5421 | lr 3.00e-04 | grad 2.75 | tok/s 14037
step   1730 | loss 1.2364 | lr 3.00e-04 | grad 2.75 | tok/s 14184
step   1740 | loss 1.3534 | lr 3.00e-04 | grad 2.59 | tok/s 13820
step   1750 | loss 1.5897 | lr 3.00e-04 | grad 2.42 | tok/s 13536
step   1760 | loss 1.5563 | lr 3.00e-04 | grad 2.25 | tok/s 13607
step   1770 | loss 1.4474 | lr 3.00e-04 | grad 2.20 | tok/s 13407
step   1780 | loss 1.5212 | lr 3.00e-04 | grad 1.74 | tok/s 13876
step   1790 | loss 1.4113 | lr 3.00e-04 | grad 1.59 | tok/s 13546
step   1800 | loss 1.6360 | lr 3.00e-04 | grad 2.70 | tok/s 13665
step   1810 | loss 1.4780 | lr 3.00e-04 | grad 1.96 | tok/s 13147
step   1820 | loss 1.4878 | lr 3.00e-04 | grad 4.53 | tok/s 13348
step   1830 | loss 1.4152 | lr 3.00e-04 | grad 2.22 | tok/s 13931
step   1840 | loss 1.5530 | lr 3.00e-04 | grad 2.56 | tok/s 13332
step   1850 | loss 1.3043 | lr 3.00e-04 | grad 1.71 | tok/s 13928
step   1860 | loss 1.3334 | lr 3.00e-04 | grad 2.17 | tok/s 12988
step   1870 | loss 1.4283 | lr 3.00e-04 | grad 2.91 | tok/s 13519
step   1880 | loss 1.2471 | lr 3.00e-04 | grad 2.16 | tok/s 13286
step   1890 | loss 1.5273 | lr 3.00e-04 | grad 1.77 | tok/s 12609
step   1900 | loss 1.4063 | lr 3.00e-04 | grad 2.38 | tok/s 13601
step   1910 | loss 1.4871 | lr 3.00e-04 | grad 2.67 | tok/s 12940
step   1920 | loss 1.4064 | lr 3.00e-04 | grad 1.89 | tok/s 14204
step   1930 | loss 1.4661 | lr 3.00e-04 | grad 2.34 | tok/s 13331
step   1940 | loss 1.4554 | lr 3.00e-04 | grad 1.90 | tok/s 13842
step   1950 | loss 1.9012 | lr 3.00e-04 | grad 3.56 | tok/s 14009
step   1960 | loss 1.4825 | lr 3.00e-04 | grad 4.06 | tok/s 14157
step   1970 | loss 1.5485 | lr 3.00e-04 | grad 2.38 | tok/s 13814
step   1980 | loss 1.5600 | lr 3.00e-04 | grad 1.99 | tok/s 13231
step   1990 | loss 1.6569 | lr 3.00e-04 | grad 14.06 | tok/s 13435
step   2000 | loss 1.5008 | lr 3.00e-04 | grad 1.94 | tok/s 13116
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5008.pt
step   2010 | loss 1.1012 | lr 3.00e-04 | grad 1.62 | tok/s 6668
step   2020 | loss 1.3137 | lr 3.00e-04 | grad 1.96 | tok/s 13558

Training complete! Final step: 2022
