Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_11/levelE88_100m_20260126_143906
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 480,572,936 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2663 | lr 3.00e-04 | grad 24.00 | tok/s 5821
step     20 | loss 2.7431 | lr 3.00e-04 | grad 11.00 | tok/s 14227
step     30 | loss 2.5841 | lr 3.00e-04 | grad 6.03 | tok/s 14433
step     40 | loss 2.4402 | lr 3.00e-04 | grad 4.50 | tok/s 13787
step     50 | loss 3.1013 | lr 3.00e-04 | grad 15.62 | tok/s 13973
step     60 | loss 2.0995 | lr 3.00e-04 | grad 4.78 | tok/s 14416
step     70 | loss 1.9528 | lr 3.00e-04 | grad 5.44 | tok/s 14573
step     80 | loss 6.2764 | lr 3.00e-04 | grad 156.00 | tok/s 14665
step     90 | loss 6.2481 | lr 3.00e-04 | grad 15.50 | tok/s 14900
step    100 | loss 5.0054 | lr 3.00e-04 | grad 17.25 | tok/s 14841
step    110 | loss 4.4955 | lr 3.00e-04 | grad 29.38 | tok/s 14814
step    120 | loss 3.9043 | lr 3.00e-04 | grad 29.88 | tok/s 14815
step    130 | loss 3.5238 | lr 3.00e-04 | grad 37.75 | tok/s 13932
step    140 | loss 2.9863 | lr 3.00e-04 | grad 24.62 | tok/s 14801
step    150 | loss 3.3361 | lr 3.00e-04 | grad 27.75 | tok/s 14821
step    160 | loss 2.5873 | lr 3.00e-04 | grad 24.62 | tok/s 14815
step    170 | loss 2.6247 | lr 3.00e-04 | grad 23.00 | tok/s 14826
step    180 | loss 2.4384 | lr 3.00e-04 | grad 7.59 | tok/s 14818
step    190 | loss 2.6582 | lr 3.00e-04 | grad 7.25 | tok/s 14817
step    200 | loss 2.3191 | lr 3.00e-04 | grad 14.38 | tok/s 14822
step    210 | loss 2.2975 | lr 3.00e-04 | grad 10.88 | tok/s 14805
step    220 | loss 2.3159 | lr 3.00e-04 | grad 3.58 | tok/s 14617
step    230 | loss 2.1331 | lr 3.00e-04 | grad 3.75 | tok/s 14402
step    240 | loss 2.3117 | lr 3.00e-04 | grad 4.94 | tok/s 13722
step    250 | loss 2.1374 | lr 3.00e-04 | grad 2.59 | tok/s 14073
step    260 | loss 1.5951 | lr 3.00e-04 | grad 2.94 | tok/s 14521
step    270 | loss 2.1300 | lr 3.00e-04 | grad 2.69 | tok/s 13555
step    280 | loss 2.3008 | lr 3.00e-04 | grad 4.97 | tok/s 14037
step    290 | loss 1.4257 | lr 3.00e-04 | grad 3.50 | tok/s 14821
step    300 | loss 0.5872 | lr 3.00e-04 | grad 3.66 | tok/s 14753
step    310 | loss 2.4155 | lr 3.00e-04 | grad 3.45 | tok/s 14556
step    320 | loss 1.9723 | lr 3.00e-04 | grad 5.81 | tok/s 14239
step    330 | loss 1.9835 | lr 3.00e-04 | grad 2.98 | tok/s 13746
step    340 | loss 2.3216 | lr 3.00e-04 | grad 2.78 | tok/s 14005
step    350 | loss 1.9269 | lr 3.00e-04 | grad 5.25 | tok/s 14316
step    360 | loss 1.2311 | lr 3.00e-04 | grad 7.06 | tok/s 14616
step    370 | loss 1.8316 | lr 3.00e-04 | grad 2.53 | tok/s 13242
step    380 | loss 1.7989 | lr 3.00e-04 | grad 2.50 | tok/s 14156
step    390 | loss 1.5713 | lr 3.00e-04 | grad 2.03 | tok/s 14745
step    400 | loss 1.5207 | lr 3.00e-04 | grad 2.44 | tok/s 14601
step    410 | loss 1.2997 | lr 3.00e-04 | grad 1.97 | tok/s 14304
step    420 | loss 1.8471 | lr 3.00e-04 | grad 4.41 | tok/s 13053
step    430 | loss 2.1917 | lr 3.00e-04 | grad 2.84 | tok/s 14487
step    440 | loss 2.1825 | lr 3.00e-04 | grad 3.97 | tok/s 13708
step    450 | loss 1.9484 | lr 3.00e-04 | grad 2.72 | tok/s 14183
step    460 | loss 1.7446 | lr 3.00e-04 | grad 2.86 | tok/s 13898
step    470 | loss 1.8602 | lr 3.00e-04 | grad 2.25 | tok/s 14314
step    480 | loss 2.2790 | lr 3.00e-04 | grad 6.53 | tok/s 14326
step    490 | loss 1.8100 | lr 3.00e-04 | grad 2.38 | tok/s 13519
step    500 | loss 1.7108 | lr 3.00e-04 | grad 3.25 | tok/s 14436
step    510 | loss 1.7363 | lr 3.00e-04 | grad 2.31 | tok/s 14642
step    520 | loss 1.6906 | lr 3.00e-04 | grad 1.98 | tok/s 14618
step    530 | loss 1.9340 | lr 3.00e-04 | grad 2.38 | tok/s 14083
step    540 | loss 1.7626 | lr 3.00e-04 | grad 2.09 | tok/s 14048
step    550 | loss 1.5886 | lr 3.00e-04 | grad 2.84 | tok/s 13757
step    560 | loss 1.7516 | lr 3.00e-04 | grad 2.48 | tok/s 12847
step    570 | loss 1.6925 | lr 3.00e-04 | grad 3.70 | tok/s 13813
step    580 | loss 1.5690 | lr 3.00e-04 | grad 2.08 | tok/s 13723
step    590 | loss 1.8819 | lr 3.00e-04 | grad 2.97 | tok/s 14091
step    600 | loss 1.8421 | lr 3.00e-04 | grad 2.23 | tok/s 13619
step    610 | loss 1.6455 | lr 3.00e-04 | grad 2.25 | tok/s 14298
step    620 | loss 1.5641 | lr 3.00e-04 | grad 2.39 | tok/s 13556
step    630 | loss 1.6818 | lr 3.00e-04 | grad 4.19 | tok/s 13659
step    640 | loss 1.8340 | lr 3.00e-04 | grad 2.34 | tok/s 14030
step    650 | loss 1.6919 | lr 3.00e-04 | grad 2.47 | tok/s 14085
step    660 | loss 1.7168 | lr 3.00e-04 | grad 2.02 | tok/s 14152
step    670 | loss 1.9529 | lr 3.00e-04 | grad 3.09 | tok/s 14239
step    680 | loss 1.7507 | lr 3.00e-04 | grad 2.34 | tok/s 13976
step    690 | loss 1.8492 | lr 3.00e-04 | grad 3.09 | tok/s 14471
step    700 | loss 1.4531 | lr 3.00e-04 | grad 2.94 | tok/s 14127
step    710 | loss 1.6096 | lr 3.00e-04 | grad 2.27 | tok/s 13834
step    720 | loss 1.4849 | lr 3.00e-04 | grad 3.34 | tok/s 13575
step    730 | loss 1.3078 | lr 3.00e-04 | grad 2.64 | tok/s 14720
step    740 | loss 1.5226 | lr 3.00e-04 | grad 2.27 | tok/s 14496
step    750 | loss 1.2234 | lr 3.00e-04 | grad 2.42 | tok/s 14715
step    760 | loss 1.1305 | lr 3.00e-04 | grad 2.16 | tok/s 14764
step    770 | loss 1.0806 | lr 3.00e-04 | grad 1.97 | tok/s 14750
step    780 | loss 1.0115 | lr 3.00e-04 | grad 1.98 | tok/s 14737
step    790 | loss 1.1486 | lr 3.00e-04 | grad 3.22 | tok/s 14269
step    800 | loss 1.8331 | lr 3.00e-04 | grad 5.25 | tok/s 14204
step    810 | loss 1.7254 | lr 3.00e-04 | grad 2.00 | tok/s 14158
step    820 | loss 1.7323 | lr 3.00e-04 | grad 3.72 | tok/s 13580
step    830 | loss 1.5111 | lr 3.00e-04 | grad 2.25 | tok/s 14569
step    840 | loss 1.3846 | lr 3.00e-04 | grad 2.19 | tok/s 14713
step    850 | loss 1.6026 | lr 3.00e-04 | grad 2.03 | tok/s 13993
step    860 | loss 1.4950 | lr 3.00e-04 | grad 3.34 | tok/s 14515
step    870 | loss 1.5224 | lr 3.00e-04 | grad 2.69 | tok/s 13961
step    880 | loss 1.7064 | lr 3.00e-04 | grad 2.75 | tok/s 14018
step    890 | loss 1.7038 | lr 3.00e-04 | grad 2.84 | tok/s 14216
step    900 | loss 1.5871 | lr 3.00e-04 | grad 2.52 | tok/s 14239
step    910 | loss 1.4345 | lr 3.00e-04 | grad 3.69 | tok/s 13938
step    920 | loss 1.5385 | lr 3.00e-04 | grad 3.47 | tok/s 14472
step    930 | loss 1.6209 | lr 3.00e-04 | grad 3.45 | tok/s 13833
step    940 | loss 1.4071 | lr 3.00e-04 | grad 1.84 | tok/s 14584
step    950 | loss 1.5083 | lr 3.00e-04 | grad 2.97 | tok/s 14661
step    960 | loss 1.3449 | lr 3.00e-04 | grad 2.45 | tok/s 14672
step    970 | loss 1.7634 | lr 3.00e-04 | grad 3.52 | tok/s 13806
step    980 | loss 1.6649 | lr 3.00e-04 | grad 2.39 | tok/s 14168
step    990 | loss 1.4685 | lr 3.00e-04 | grad 2.05 | tok/s 13809
step   1000 | loss 1.8473 | lr 3.00e-04 | grad 6.94 | tok/s 13823
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8473.pt
step   1010 | loss 1.6580 | lr 3.00e-04 | grad 3.30 | tok/s 6029
step   1020 | loss 1.6667 | lr 3.00e-04 | grad 1.88 | tok/s 13576
step   1030 | loss 1.4728 | lr 3.00e-04 | grad 2.02 | tok/s 14150
step   1040 | loss 1.4962 | lr 3.00e-04 | grad 2.11 | tok/s 14604
step   1050 | loss 1.6414 | lr 3.00e-04 | grad 3.11 | tok/s 13482
step   1060 | loss 1.7490 | lr 3.00e-04 | grad 3.28 | tok/s 14590
step   1070 | loss 1.6619 | lr 3.00e-04 | grad 2.64 | tok/s 14482
step   1080 | loss 1.4136 | lr 3.00e-04 | grad 1.90 | tok/s 13172
step   1090 | loss 1.1322 | lr 3.00e-04 | grad 1.16 | tok/s 14500
step   1100 | loss 1.4561 | lr 3.00e-04 | grad 3.23 | tok/s 14148
step   1110 | loss 1.4804 | lr 3.00e-04 | grad 2.00 | tok/s 14827
step   1120 | loss 1.3462 | lr 3.00e-04 | grad 2.00 | tok/s 14831
step   1130 | loss 1.3026 | lr 3.00e-04 | grad 1.86 | tok/s 14204
step   1140 | loss 1.2935 | lr 3.00e-04 | grad 2.08 | tok/s 14826
step   1150 | loss 1.3070 | lr 3.00e-04 | grad 1.73 | tok/s 14824
step   1160 | loss 1.2242 | lr 3.00e-04 | grad 1.79 | tok/s 14826
step   1170 | loss 1.2497 | lr 3.00e-04 | grad 2.05 | tok/s 14800
step   1180 | loss 1.3489 | lr 3.00e-04 | grad 1.66 | tok/s 14798
step   1190 | loss 1.2309 | lr 3.00e-04 | grad 2.16 | tok/s 14771
step   1200 | loss 1.2250 | lr 3.00e-04 | grad 1.96 | tok/s 14799
step   1210 | loss 1.2763 | lr 3.00e-04 | grad 2.05 | tok/s 14798
step   1220 | loss 1.2971 | lr 3.00e-04 | grad 1.92 | tok/s 14774
step   1230 | loss 1.2662 | lr 3.00e-04 | grad 1.75 | tok/s 14810
step   1240 | loss 1.2264 | lr 3.00e-04 | grad 1.56 | tok/s 14791
step   1250 | loss 1.8197 | lr 3.00e-04 | grad 3.67 | tok/s 13976
step   1260 | loss 1.4000 | lr 3.00e-04 | grad 2.34 | tok/s 13833
step   1270 | loss 1.6701 | lr 3.00e-04 | grad 4.75 | tok/s 13844
step   1280 | loss 1.6403 | lr 3.00e-04 | grad 1.84 | tok/s 13474
step   1290 | loss 1.4909 | lr 3.00e-04 | grad 2.05 | tok/s 14171
step   1300 | loss 1.5323 | lr 3.00e-04 | grad 2.47 | tok/s 14268
step   1310 | loss 1.4722 | lr 3.00e-04 | grad 2.28 | tok/s 14523
step   1320 | loss 1.5998 | lr 3.00e-04 | grad 2.23 | tok/s 14557
step   1330 | loss 1.6240 | lr 3.00e-04 | grad 2.31 | tok/s 14583
step   1340 | loss 1.4990 | lr 3.00e-04 | grad 9.00 | tok/s 13924
step   1350 | loss 1.7437 | lr 3.00e-04 | grad 2.41 | tok/s 13441
step   1360 | loss 1.5043 | lr 3.00e-04 | grad 2.31 | tok/s 14271
step   1370 | loss 1.4253 | lr 3.00e-04 | grad 1.59 | tok/s 14119
step   1380 | loss 1.6776 | lr 3.00e-04 | grad 2.31 | tok/s 13561
step   1390 | loss 1.5364 | lr 3.00e-04 | grad 1.67 | tok/s 14388
step   1400 | loss 1.4211 | lr 3.00e-04 | grad 1.76 | tok/s 13864
step   1410 | loss 1.4740 | lr 3.00e-04 | grad 3.03 | tok/s 13918
step   1420 | loss 1.6894 | lr 3.00e-04 | grad 3.80 | tok/s 13492
step   1430 | loss 1.3574 | lr 3.00e-04 | grad 1.95 | tok/s 14202
step   1440 | loss 1.1578 | lr 3.00e-04 | grad 1.84 | tok/s 14671
step   1450 | loss 1.1725 | lr 3.00e-04 | grad 4.28 | tok/s 14767
step   1460 | loss 1.6801 | lr 3.00e-04 | grad 2.05 | tok/s 13911
step   1470 | loss 1.5348 | lr 3.00e-04 | grad 1.84 | tok/s 14434
step   1480 | loss 1.8266 | lr 3.00e-04 | grad 3.92 | tok/s 14540
step   1490 | loss 1.5769 | lr 3.00e-04 | grad 1.76 | tok/s 14751
step   1500 | loss 1.3491 | lr 3.00e-04 | grad 1.77 | tok/s 14776
step   1510 | loss 1.5349 | lr 3.00e-04 | grad 1.95 | tok/s 14616
step   1520 | loss 1.4443 | lr 3.00e-04 | grad 3.41 | tok/s 14320
step   1530 | loss 1.4618 | lr 3.00e-04 | grad 1.66 | tok/s 14653
step   1540 | loss 1.6480 | lr 3.00e-04 | grad 2.34 | tok/s 13758
step   1550 | loss 1.2962 | lr 3.00e-04 | grad 2.34 | tok/s 14669
step   1560 | loss 1.5933 | lr 3.00e-04 | grad 2.58 | tok/s 13358
step   1570 | loss 1.2989 | lr 3.00e-04 | grad 2.19 | tok/s 14801
step   1580 | loss 1.7372 | lr 3.00e-04 | grad 4.06 | tok/s 14470
step   1590 | loss 1.6116 | lr 3.00e-04 | grad 2.38 | tok/s 13885
step   1600 | loss 1.0127 | lr 3.00e-04 | grad 1.51 | tok/s 14816
step   1610 | loss 1.0393 | lr 3.00e-04 | grad 2.44 | tok/s 14340
step   1620 | loss 1.4260 | lr 3.00e-04 | grad 3.27 | tok/s 13450
step   1630 | loss 1.3629 | lr 3.00e-04 | grad 2.11 | tok/s 14379
step   1640 | loss 1.3578 | lr 3.00e-04 | grad 2.45 | tok/s 14046
step   1650 | loss 1.5425 | lr 3.00e-04 | grad 2.48 | tok/s 13466
step   1660 | loss 1.4026 | lr 3.00e-04 | grad 1.74 | tok/s 14348
step   1670 | loss 1.3691 | lr 3.00e-04 | grad 6.22 | tok/s 14333
step   1680 | loss 1.7417 | lr 3.00e-04 | grad 1.97 | tok/s 13758
step   1690 | loss 1.5072 | lr 3.00e-04 | grad 4.22 | tok/s 13996
step   1700 | loss 1.5242 | lr 3.00e-04 | grad 2.28 | tok/s 13837
step   1710 | loss 1.4409 | lr 3.00e-04 | grad 2.25 | tok/s 14021
step   1720 | loss 1.5412 | lr 3.00e-04 | grad 2.77 | tok/s 14645
step   1730 | loss 1.2367 | lr 3.00e-04 | grad 2.64 | tok/s 14791
step   1740 | loss 1.3467 | lr 3.00e-04 | grad 2.66 | tok/s 14402
step   1750 | loss 1.6002 | lr 3.00e-04 | grad 2.53 | tok/s 14169
step   1760 | loss 1.5568 | lr 3.00e-04 | grad 2.33 | tok/s 14230
step   1770 | loss 1.4495 | lr 3.00e-04 | grad 2.27 | tok/s 13949
step   1780 | loss 1.5202 | lr 3.00e-04 | grad 1.80 | tok/s 14531
step   1790 | loss 1.4132 | lr 3.00e-04 | grad 1.69 | tok/s 14164
step   1800 | loss 1.6388 | lr 3.00e-04 | grad 2.62 | tok/s 14270
step   1810 | loss 1.4752 | lr 3.00e-04 | grad 2.00 | tok/s 13731
step   1820 | loss 1.4960 | lr 3.00e-04 | grad 4.81 | tok/s 13959
step   1830 | loss 1.4246 | lr 3.00e-04 | grad 2.38 | tok/s 14553
step   1840 | loss 1.5540 | lr 3.00e-04 | grad 2.58 | tok/s 13923
step   1850 | loss 1.3100 | lr 3.00e-04 | grad 1.77 | tok/s 14052
step   1860 | loss 1.3365 | lr 3.00e-04 | grad 2.23 | tok/s 14179
step   1870 | loss 1.4322 | lr 3.00e-04 | grad 3.08 | tok/s 14140
step   1880 | loss 1.2470 | lr 3.00e-04 | grad 2.22 | tok/s 13846
step   1890 | loss 1.5314 | lr 3.00e-04 | grad 1.84 | tok/s 13166
step   1900 | loss 1.4067 | lr 3.00e-04 | grad 2.59 | tok/s 14194
step   1910 | loss 1.4799 | lr 3.00e-04 | grad 2.80 | tok/s 13488
step   1920 | loss 1.4072 | lr 3.00e-04 | grad 1.97 | tok/s 14784
step   1930 | loss 1.4732 | lr 3.00e-04 | grad 2.44 | tok/s 13846
step   1940 | loss 1.4548 | lr 3.00e-04 | grad 2.02 | tok/s 14450
step   1950 | loss 1.8706 | lr 3.00e-04 | grad 3.47 | tok/s 14667
step   1960 | loss 1.4742 | lr 3.00e-04 | grad 4.12 | tok/s 14799
step   1970 | loss 1.5468 | lr 3.00e-04 | grad 2.42 | tok/s 14428
step   1980 | loss 1.5643 | lr 3.00e-04 | grad 2.09 | tok/s 13782
step   1990 | loss 1.6604 | lr 3.00e-04 | grad 11.94 | tok/s 13594
step   2000 | loss 1.5065 | lr 3.00e-04 | grad 1.98 | tok/s 14262
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5065.pt
step   2010 | loss 1.0911 | lr 3.00e-04 | grad 1.69 | tok/s 6523
step   2020 | loss 1.3163 | lr 3.00e-04 | grad 2.06 | tok/s 14169
step   2030 | loss 1.1047 | lr 3.00e-04 | grad 0.88 | tok/s 14862
step   2040 | loss 1.2479 | lr 3.00e-04 | grad 2.06 | tok/s 14873
step   2050 | loss 1.2088 | lr 3.00e-04 | grad 2.19 | tok/s 14522
step   2060 | loss 1.5794 | lr 3.00e-04 | grad 2.17 | tok/s 13682
step   2070 | loss 1.6804 | lr 3.00e-04 | grad 2.23 | tok/s 14209
step   2080 | loss 2.2769 | lr 3.00e-04 | grad 4.09 | tok/s 14673
step   2090 | loss 1.7166 | lr 3.00e-04 | grad 4.28 | tok/s 14727

Training complete! Final step: 2094
