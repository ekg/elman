Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_111/levelE88_100m_20260126_164244
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,400,910 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0514 | lr 3.00e-04 | grad 11.12 | tok/s 5679
step     20 | loss 2.6093 | lr 3.00e-04 | grad 5.41 | tok/s 12492
step     30 | loss 2.4690 | lr 3.00e-04 | grad 2.84 | tok/s 12639
step     40 | loss 2.3280 | lr 3.00e-04 | grad 3.05 | tok/s 12100
step     50 | loss 2.8582 | lr 3.00e-04 | grad 8.12 | tok/s 12252
step     60 | loss 2.0378 | lr 3.00e-04 | grad 6.41 | tok/s 12626
step     70 | loss 1.8750 | lr 3.00e-04 | grad 3.86 | tok/s 12798
step     80 | loss 5.5082 | lr 3.00e-04 | grad 47.75 | tok/s 12826
step     90 | loss 5.0101 | lr 3.00e-04 | grad 7.97 | tok/s 13061
step    100 | loss 4.0011 | lr 3.00e-04 | grad 7.06 | tok/s 13041
step    110 | loss 3.4176 | lr 3.00e-04 | grad 10.56 | tok/s 12995
step    120 | loss 3.0652 | lr 3.00e-04 | grad 9.38 | tok/s 13002
step    130 | loss 2.8514 | lr 3.00e-04 | grad 10.62 | tok/s 12959
step    140 | loss 2.5549 | lr 3.00e-04 | grad 7.09 | tok/s 12954
step    150 | loss 2.5740 | lr 3.00e-04 | grad 7.31 | tok/s 12956
step    160 | loss 2.1880 | lr 3.00e-04 | grad 7.00 | tok/s 12964
step    170 | loss 2.3002 | lr 3.00e-04 | grad 9.12 | tok/s 12941
step    180 | loss 2.0953 | lr 3.00e-04 | grad 5.78 | tok/s 12953
step    190 | loss 2.2483 | lr 3.00e-04 | grad 10.38 | tok/s 12952
step    200 | loss 1.9813 | lr 3.00e-04 | grad 3.73 | tok/s 12906
step    210 | loss 1.9730 | lr 3.00e-04 | grad 4.25 | tok/s 12925
step    220 | loss 2.0850 | lr 3.00e-04 | grad 2.62 | tok/s 12766
step    230 | loss 1.9522 | lr 3.00e-04 | grad 2.47 | tok/s 12589
step    240 | loss 2.2658 | lr 3.00e-04 | grad 3.59 | tok/s 11976
step    250 | loss 2.0687 | lr 3.00e-04 | grad 1.97 | tok/s 12278
step    260 | loss 1.5310 | lr 3.00e-04 | grad 2.27 | tok/s 12665
step    270 | loss 2.0448 | lr 3.00e-04 | grad 2.14 | tok/s 12499
step    280 | loss 2.2299 | lr 3.00e-04 | grad 4.56 | tok/s 12253
step    290 | loss 1.3360 | lr 3.00e-04 | grad 2.31 | tok/s 12916
step    300 | loss 0.5632 | lr 3.00e-04 | grad 2.33 | tok/s 12903
step    310 | loss 2.3844 | lr 3.00e-04 | grad 2.95 | tok/s 12681
step    320 | loss 1.9287 | lr 3.00e-04 | grad 4.34 | tok/s 12423
step    330 | loss 1.9221 | lr 3.00e-04 | grad 2.36 | tok/s 11982
step    340 | loss 2.2493 | lr 3.00e-04 | grad 2.16 | tok/s 12252
step    350 | loss 1.8583 | lr 3.00e-04 | grad 3.38 | tok/s 12533
step    360 | loss 1.2064 | lr 3.00e-04 | grad 4.94 | tok/s 12786
step    370 | loss 1.7789 | lr 3.00e-04 | grad 2.14 | tok/s 11619
step    380 | loss 1.7403 | lr 3.00e-04 | grad 1.98 | tok/s 12351
step    390 | loss 1.5159 | lr 3.00e-04 | grad 1.60 | tok/s 12908
step    400 | loss 1.4770 | lr 3.00e-04 | grad 1.98 | tok/s 12798
step    410 | loss 1.2654 | lr 3.00e-04 | grad 1.60 | tok/s 12522
step    420 | loss 1.7947 | lr 3.00e-04 | grad 3.41 | tok/s 11912
step    430 | loss 2.1363 | lr 3.00e-04 | grad 2.36 | tok/s 12668
step    440 | loss 2.1302 | lr 3.00e-04 | grad 3.42 | tok/s 11987
step    450 | loss 1.9088 | lr 3.00e-04 | grad 2.20 | tok/s 12406
step    460 | loss 1.7183 | lr 3.00e-04 | grad 2.50 | tok/s 12187
step    470 | loss 1.8264 | lr 3.00e-04 | grad 1.88 | tok/s 12500
step    480 | loss 2.2248 | lr 3.00e-04 | grad 5.25 | tok/s 12506
step    490 | loss 1.7732 | lr 3.00e-04 | grad 2.11 | tok/s 11796
step    500 | loss 1.6602 | lr 3.00e-04 | grad 2.67 | tok/s 12624
step    510 | loss 1.6945 | lr 3.00e-04 | grad 1.87 | tok/s 12800
step    520 | loss 1.6431 | lr 3.00e-04 | grad 1.69 | tok/s 12765
step    530 | loss 1.9058 | lr 3.00e-04 | grad 2.06 | tok/s 12268
step    540 | loss 1.7175 | lr 3.00e-04 | grad 1.74 | tok/s 11697
step    550 | loss 1.5558 | lr 3.00e-04 | grad 2.38 | tok/s 12031
step    560 | loss 1.7055 | lr 3.00e-04 | grad 2.16 | tok/s 11719
step    570 | loss 1.6482 | lr 3.00e-04 | grad 3.09 | tok/s 12041
step    580 | loss 1.5298 | lr 3.00e-04 | grad 1.75 | tok/s 11973
step    590 | loss 1.8437 | lr 3.00e-04 | grad 2.58 | tok/s 12291
step    600 | loss 1.8088 | lr 3.00e-04 | grad 1.85 | tok/s 11868
step    610 | loss 1.6061 | lr 3.00e-04 | grad 1.98 | tok/s 12487
step    620 | loss 1.5325 | lr 3.00e-04 | grad 1.98 | tok/s 11830
step    630 | loss 1.6465 | lr 3.00e-04 | grad 3.64 | tok/s 11916
step    640 | loss 1.7891 | lr 3.00e-04 | grad 2.05 | tok/s 12237
step    650 | loss 1.6453 | lr 3.00e-04 | grad 2.08 | tok/s 12293
step    660 | loss 1.6768 | lr 3.00e-04 | grad 1.68 | tok/s 12326
step    670 | loss 1.8860 | lr 3.00e-04 | grad 2.59 | tok/s 12453
step    680 | loss 1.7138 | lr 3.00e-04 | grad 2.03 | tok/s 12183
step    690 | loss 1.8027 | lr 3.00e-04 | grad 2.70 | tok/s 12604
step    700 | loss 1.4266 | lr 3.00e-04 | grad 2.53 | tok/s 12836
step    710 | loss 1.5679 | lr 3.00e-04 | grad 1.93 | tok/s 12007
step    720 | loss 1.4535 | lr 3.00e-04 | grad 3.06 | tok/s 11800
step    730 | loss 1.2930 | lr 3.00e-04 | grad 2.30 | tok/s 12790
step    740 | loss 1.4863 | lr 3.00e-04 | grad 1.98 | tok/s 12654
step    750 | loss 1.1979 | lr 3.00e-04 | grad 2.11 | tok/s 12837
step    760 | loss 1.1044 | lr 3.00e-04 | grad 1.88 | tok/s 12853
step    770 | loss 1.0505 | lr 3.00e-04 | grad 1.65 | tok/s 12858
step    780 | loss 0.9866 | lr 3.00e-04 | grad 1.77 | tok/s 12850
step    790 | loss 1.1154 | lr 3.00e-04 | grad 2.73 | tok/s 12440
step    800 | loss 1.7952 | lr 3.00e-04 | grad 4.72 | tok/s 12442
step    810 | loss 1.6845 | lr 3.00e-04 | grad 1.74 | tok/s 12346
step    820 | loss 1.6904 | lr 3.00e-04 | grad 3.30 | tok/s 11854
step    830 | loss 1.4686 | lr 3.00e-04 | grad 1.93 | tok/s 12685
step    840 | loss 1.3622 | lr 3.00e-04 | grad 1.88 | tok/s 12838
step    850 | loss 1.5623 | lr 3.00e-04 | grad 1.66 | tok/s 12784
step    860 | loss 1.4662 | lr 3.00e-04 | grad 2.98 | tok/s 12660
step    870 | loss 1.4785 | lr 3.00e-04 | grad 2.19 | tok/s 12206
step    880 | loss 1.6597 | lr 3.00e-04 | grad 2.14 | tok/s 12238
step    890 | loss 1.6650 | lr 3.00e-04 | grad 2.47 | tok/s 12042
step    900 | loss 1.5495 | lr 3.00e-04 | grad 2.11 | tok/s 12440
step    910 | loss 1.4100 | lr 3.00e-04 | grad 3.19 | tok/s 12164
step    920 | loss 1.5035 | lr 3.00e-04 | grad 3.12 | tok/s 12642
step    930 | loss 1.5759 | lr 3.00e-04 | grad 2.91 | tok/s 12059
step    940 | loss 1.3693 | lr 3.00e-04 | grad 1.54 | tok/s 12723
step    950 | loss 1.4672 | lr 3.00e-04 | grad 2.25 | tok/s 12752
step    960 | loss 1.3124 | lr 3.00e-04 | grad 2.05 | tok/s 12811
step    970 | loss 1.7236 | lr 3.00e-04 | grad 3.03 | tok/s 12055
step    980 | loss 1.6266 | lr 3.00e-04 | grad 1.96 | tok/s 12382
step    990 | loss 1.4322 | lr 3.00e-04 | grad 1.73 | tok/s 12584
step   1000 | loss 1.8103 | lr 3.00e-04 | grad 7.28 | tok/s 12087
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8103.pt
step   1010 | loss 1.6277 | lr 3.00e-04 | grad 2.78 | tok/s 5688
step   1020 | loss 1.6288 | lr 3.00e-04 | grad 1.66 | tok/s 11839
step   1030 | loss 1.4470 | lr 3.00e-04 | grad 1.73 | tok/s 12334
step   1040 | loss 1.4612 | lr 3.00e-04 | grad 1.79 | tok/s 12743
step   1050 | loss 1.5974 | lr 3.00e-04 | grad 2.73 | tok/s 11769
step   1060 | loss 1.7102 | lr 3.00e-04 | grad 2.70 | tok/s 12736
step   1070 | loss 1.6240 | lr 3.00e-04 | grad 2.22 | tok/s 12685
step   1080 | loss 1.3801 | lr 3.00e-04 | grad 1.61 | tok/s 11513
step   1090 | loss 1.1034 | lr 3.00e-04 | grad 1.09 | tok/s 12669
step   1100 | loss 1.4172 | lr 3.00e-04 | grad 2.81 | tok/s 12301
step   1110 | loss 1.4490 | lr 3.00e-04 | grad 1.66 | tok/s 12952
step   1120 | loss 1.3233 | lr 3.00e-04 | grad 1.71 | tok/s 12958
step   1130 | loss 1.2781 | lr 3.00e-04 | grad 1.59 | tok/s 12949
step   1140 | loss 1.2658 | lr 3.00e-04 | grad 1.73 | tok/s 12896
step   1150 | loss 1.2828 | lr 3.00e-04 | grad 1.48 | tok/s 12923
step   1160 | loss 1.1981 | lr 3.00e-04 | grad 1.49 | tok/s 12910
step   1170 | loss 1.2260 | lr 3.00e-04 | grad 1.74 | tok/s 12937
step   1180 | loss 1.3245 | lr 3.00e-04 | grad 1.40 | tok/s 12921
step   1190 | loss 1.2052 | lr 3.00e-04 | grad 1.82 | tok/s 12413
step   1200 | loss 1.2009 | lr 3.00e-04 | grad 1.68 | tok/s 12900
step   1210 | loss 1.2540 | lr 3.00e-04 | grad 1.72 | tok/s 12902
step   1220 | loss 1.2727 | lr 3.00e-04 | grad 1.70 | tok/s 12929
step   1230 | loss 1.2375 | lr 3.00e-04 | grad 1.51 | tok/s 12892
step   1240 | loss 1.2067 | lr 3.00e-04 | grad 1.30 | tok/s 12922
step   1250 | loss 1.7514 | lr 3.00e-04 | grad 3.00 | tok/s 12197
step   1260 | loss 1.3524 | lr 3.00e-04 | grad 3.30 | tok/s 12083
step   1270 | loss 1.6388 | lr 3.00e-04 | grad 4.19 | tok/s 12058
step   1280 | loss 1.6024 | lr 3.00e-04 | grad 1.56 | tok/s 12418
step   1290 | loss 1.4517 | lr 3.00e-04 | grad 1.73 | tok/s 12324
step   1300 | loss 1.5047 | lr 3.00e-04 | grad 2.11 | tok/s 12418
step   1310 | loss 1.4424 | lr 3.00e-04 | grad 2.00 | tok/s 12662
step   1320 | loss 1.5601 | lr 3.00e-04 | grad 1.88 | tok/s 12671
step   1330 | loss 1.5808 | lr 3.00e-04 | grad 2.02 | tok/s 12691
step   1340 | loss 1.4651 | lr 3.00e-04 | grad 7.75 | tok/s 12155
step   1350 | loss 1.6884 | lr 3.00e-04 | grad 2.08 | tok/s 11703
step   1360 | loss 1.4713 | lr 3.00e-04 | grad 1.99 | tok/s 12417
step   1370 | loss 1.3943 | lr 3.00e-04 | grad 1.34 | tok/s 12279
step   1380 | loss 1.6155 | lr 3.00e-04 | grad 1.99 | tok/s 11786
step   1390 | loss 1.4987 | lr 3.00e-04 | grad 1.43 | tok/s 12543
step   1400 | loss 1.3813 | lr 3.00e-04 | grad 1.49 | tok/s 12064
step   1410 | loss 1.4377 | lr 3.00e-04 | grad 2.64 | tok/s 12112
step   1420 | loss 1.6464 | lr 3.00e-04 | grad 4.16 | tok/s 12154
step   1430 | loss 1.3307 | lr 3.00e-04 | grad 1.67 | tok/s 12346
step   1440 | loss 1.1301 | lr 3.00e-04 | grad 1.59 | tok/s 12062
step   1450 | loss 1.1474 | lr 3.00e-04 | grad 3.66 | tok/s 12851
step   1460 | loss 1.6355 | lr 3.00e-04 | grad 1.75 | tok/s 12126
step   1470 | loss 1.4956 | lr 3.00e-04 | grad 1.58 | tok/s 12564
step   1480 | loss 1.7761 | lr 3.00e-04 | grad 3.33 | tok/s 12636
step   1490 | loss 1.5402 | lr 3.00e-04 | grad 1.48 | tok/s 12826
step   1500 | loss 1.3264 | lr 3.00e-04 | grad 1.49 | tok/s 12890
step   1510 | loss 1.4878 | lr 3.00e-04 | grad 1.66 | tok/s 12707
step   1520 | loss 1.4079 | lr 3.00e-04 | grad 3.11 | tok/s 12451
step   1530 | loss 1.4118 | lr 3.00e-04 | grad 1.42 | tok/s 12748
step   1540 | loss 1.5847 | lr 3.00e-04 | grad 2.06 | tok/s 12001
step   1550 | loss 1.2750 | lr 3.00e-04 | grad 1.97 | tok/s 12783
step   1560 | loss 1.5548 | lr 3.00e-04 | grad 2.23 | tok/s 12123
step   1570 | loss 1.2679 | lr 3.00e-04 | grad 1.88 | tok/s 12873
step   1580 | loss 1.6750 | lr 3.00e-04 | grad 3.53 | tok/s 12581
step   1590 | loss 1.5652 | lr 3.00e-04 | grad 2.02 | tok/s 12121
step   1600 | loss 0.9899 | lr 3.00e-04 | grad 1.37 | tok/s 12904
step   1610 | loss 1.0124 | lr 3.00e-04 | grad 2.14 | tok/s 12482
step   1620 | loss 1.3816 | lr 3.00e-04 | grad 2.56 | tok/s 11706
step   1630 | loss 1.3305 | lr 3.00e-04 | grad 1.84 | tok/s 12527
step   1640 | loss 1.3103 | lr 3.00e-04 | grad 1.77 | tok/s 12244
step   1650 | loss 1.4962 | lr 3.00e-04 | grad 2.14 | tok/s 11719
step   1660 | loss 1.3690 | lr 3.00e-04 | grad 1.49 | tok/s 12515
step   1670 | loss 1.3592 | lr 3.00e-04 | grad 6.88 | tok/s 12508
step   1680 | loss 1.6874 | lr 3.00e-04 | grad 1.68 | tok/s 11991
step   1690 | loss 1.4580 | lr 3.00e-04 | grad 3.70 | tok/s 12235
step   1700 | loss 1.4792 | lr 3.00e-04 | grad 1.96 | tok/s 12468
step   1710 | loss 1.3862 | lr 3.00e-04 | grad 1.85 | tok/s 12231
step   1720 | loss 1.4889 | lr 3.00e-04 | grad 2.30 | tok/s 12751
step   1730 | loss 1.2101 | lr 3.00e-04 | grad 2.42 | tok/s 12878
step   1740 | loss 1.3106 | lr 3.00e-04 | grad 2.25 | tok/s 12572
step   1750 | loss 1.5473 | lr 3.00e-04 | grad 2.06 | tok/s 12333
step   1760 | loss 1.5192 | lr 3.00e-04 | grad 1.95 | tok/s 12398
step   1770 | loss 1.4116 | lr 3.00e-04 | grad 1.95 | tok/s 12171
step   1780 | loss 1.4844 | lr 3.00e-04 | grad 1.54 | tok/s 12670
step   1790 | loss 1.3746 | lr 3.00e-04 | grad 1.40 | tok/s 12338
step   1800 | loss 1.5852 | lr 3.00e-04 | grad 2.05 | tok/s 12430
step   1810 | loss 1.4017 | lr 3.00e-04 | grad 1.80 | tok/s 11985
step   1820 | loss 1.4575 | lr 3.00e-04 | grad 4.72 | tok/s 12151
step   1830 | loss 1.3860 | lr 3.00e-04 | grad 1.97 | tok/s 12653
step   1840 | loss 1.5002 | lr 3.00e-04 | grad 2.28 | tok/s 12123

Training complete! Final step: 1844
