Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_17/levelE88_100m_20260126_144924
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 480,916,682 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3806 | lr 3.00e-04 | grad 22.50 | tok/s 5841
step     20 | loss 2.7583 | lr 3.00e-04 | grad 9.19 | tok/s 14079
step     30 | loss 2.5614 | lr 3.00e-04 | grad 5.12 | tok/s 14203
step     40 | loss 2.4084 | lr 3.00e-04 | grad 4.84 | tok/s 13576
step     50 | loss 3.0423 | lr 3.00e-04 | grad 13.00 | tok/s 13790
step     60 | loss 2.0821 | lr 3.00e-04 | grad 5.00 | tok/s 14205
step     70 | loss 1.9289 | lr 3.00e-04 | grad 5.31 | tok/s 14352
step     80 | loss 5.9882 | lr 3.00e-04 | grad 130.00 | tok/s 14468
step     90 | loss 5.9744 | lr 3.00e-04 | grad 14.75 | tok/s 14698
step    100 | loss 4.8245 | lr 3.00e-04 | grad 14.19 | tok/s 14668
step    110 | loss 4.3337 | lr 3.00e-04 | grad 23.25 | tok/s 14701
step    120 | loss 3.7653 | lr 3.00e-04 | grad 23.50 | tok/s 14624
step    130 | loss 3.4258 | lr 3.00e-04 | grad 27.88 | tok/s 13877
step    140 | loss 2.8705 | lr 3.00e-04 | grad 16.00 | tok/s 14608
step    150 | loss 3.1655 | lr 3.00e-04 | grad 18.75 | tok/s 14596
step    160 | loss 2.5081 | lr 3.00e-04 | grad 18.88 | tok/s 14586
step    170 | loss 2.5832 | lr 3.00e-04 | grad 15.44 | tok/s 14575
step    180 | loss 2.4142 | lr 3.00e-04 | grad 7.41 | tok/s 14541
step    190 | loss 2.5555 | lr 3.00e-04 | grad 6.62 | tok/s 14549
step    200 | loss 2.2118 | lr 3.00e-04 | grad 9.06 | tok/s 14542
step    210 | loss 2.2472 | lr 3.00e-04 | grad 9.25 | tok/s 14527
step    220 | loss 2.2599 | lr 3.00e-04 | grad 3.25 | tok/s 14362
step    230 | loss 2.0468 | lr 3.00e-04 | grad 4.28 | tok/s 14198
step    240 | loss 2.3041 | lr 3.00e-04 | grad 4.75 | tok/s 13469
step    250 | loss 2.1200 | lr 3.00e-04 | grad 2.50 | tok/s 13838
step    260 | loss 1.5725 | lr 3.00e-04 | grad 2.75 | tok/s 14288
step    270 | loss 2.1123 | lr 3.00e-04 | grad 2.61 | tok/s 14109
step    280 | loss 2.2766 | lr 3.00e-04 | grad 4.97 | tok/s 13028
step    290 | loss 1.5060 | lr 3.00e-04 | grad 25.12 | tok/s 14556
step    300 | loss 0.5938 | lr 3.00e-04 | grad 2.44 | tok/s 14546
step    310 | loss 2.4052 | lr 3.00e-04 | grad 3.31 | tok/s 14295
step    320 | loss 1.9538 | lr 3.00e-04 | grad 5.53 | tok/s 13994
step    330 | loss 1.9762 | lr 3.00e-04 | grad 2.73 | tok/s 13520
step    340 | loss 2.3056 | lr 3.00e-04 | grad 2.75 | tok/s 13725
step    350 | loss 1.9027 | lr 3.00e-04 | grad 4.66 | tok/s 14054
step    360 | loss 1.2444 | lr 3.00e-04 | grad 7.16 | tok/s 14373
step    370 | loss 1.8291 | lr 3.00e-04 | grad 2.47 | tok/s 13030
step    380 | loss 1.7953 | lr 3.00e-04 | grad 2.39 | tok/s 13872
step    390 | loss 1.5558 | lr 3.00e-04 | grad 1.90 | tok/s 14484
step    400 | loss 1.5062 | lr 3.00e-04 | grad 2.41 | tok/s 14353
step    410 | loss 1.2978 | lr 3.00e-04 | grad 1.95 | tok/s 14047
step    420 | loss 1.8352 | lr 3.00e-04 | grad 4.09 | tok/s 12776
step    430 | loss 2.1778 | lr 3.00e-04 | grad 2.75 | tok/s 14277
step    440 | loss 2.1716 | lr 3.00e-04 | grad 3.94 | tok/s 13499
step    450 | loss 1.9432 | lr 3.00e-04 | grad 2.64 | tok/s 13985
step    460 | loss 1.7454 | lr 3.00e-04 | grad 2.66 | tok/s 13698
step    470 | loss 1.8563 | lr 3.00e-04 | grad 2.17 | tok/s 14118
step    480 | loss 2.2812 | lr 3.00e-04 | grad 6.44 | tok/s 14101
step    490 | loss 1.8072 | lr 3.00e-04 | grad 2.28 | tok/s 13311
step    500 | loss 1.6987 | lr 3.00e-04 | grad 3.06 | tok/s 14214
step    510 | loss 1.7247 | lr 3.00e-04 | grad 2.17 | tok/s 14414
step    520 | loss 1.6804 | lr 3.00e-04 | grad 1.93 | tok/s 14405
step    530 | loss 1.9351 | lr 3.00e-04 | grad 2.33 | tok/s 13841
step    540 | loss 1.7522 | lr 3.00e-04 | grad 2.05 | tok/s 13842
step    550 | loss 1.5835 | lr 3.00e-04 | grad 2.88 | tok/s 13554
step    560 | loss 1.7449 | lr 3.00e-04 | grad 2.42 | tok/s 13199
step    570 | loss 1.6742 | lr 3.00e-04 | grad 3.38 | tok/s 12890
step    580 | loss 1.5543 | lr 3.00e-04 | grad 2.02 | tok/s 13502
step    590 | loss 1.8857 | lr 3.00e-04 | grad 2.89 | tok/s 13853
step    600 | loss 1.8354 | lr 3.00e-04 | grad 2.17 | tok/s 13365
step    610 | loss 1.6414 | lr 3.00e-04 | grad 2.20 | tok/s 14041
step    620 | loss 1.5577 | lr 3.00e-04 | grad 2.30 | tok/s 13306
step    630 | loss 1.6734 | lr 3.00e-04 | grad 4.09 | tok/s 13419
step    640 | loss 1.8288 | lr 3.00e-04 | grad 2.33 | tok/s 13820
step    650 | loss 1.6818 | lr 3.00e-04 | grad 2.42 | tok/s 13862
step    660 | loss 1.7115 | lr 3.00e-04 | grad 1.92 | tok/s 13906
step    670 | loss 1.9538 | lr 3.00e-04 | grad 6.53 | tok/s 14013
step    680 | loss 1.7369 | lr 3.00e-04 | grad 2.25 | tok/s 13740
step    690 | loss 1.8538 | lr 3.00e-04 | grad 3.09 | tok/s 14204
step    700 | loss 1.4569 | lr 3.00e-04 | grad 2.84 | tok/s 14475
step    710 | loss 1.5912 | lr 3.00e-04 | grad 2.22 | tok/s 13007
step    720 | loss 1.4756 | lr 3.00e-04 | grad 3.28 | tok/s 13320
step    730 | loss 1.3092 | lr 3.00e-04 | grad 2.55 | tok/s 14461
step    740 | loss 1.5170 | lr 3.00e-04 | grad 2.23 | tok/s 14281
step    750 | loss 1.2176 | lr 3.00e-04 | grad 2.38 | tok/s 14469
step    760 | loss 1.1273 | lr 3.00e-04 | grad 2.14 | tok/s 14480
step    770 | loss 1.0721 | lr 3.00e-04 | grad 1.95 | tok/s 14467
step    780 | loss 1.0050 | lr 3.00e-04 | grad 2.02 | tok/s 14470
step    790 | loss 1.1426 | lr 3.00e-04 | grad 3.09 | tok/s 14034
step    800 | loss 1.8331 | lr 3.00e-04 | grad 5.22 | tok/s 14003
step    810 | loss 1.7153 | lr 3.00e-04 | grad 1.95 | tok/s 13896
step    820 | loss 1.7216 | lr 3.00e-04 | grad 3.66 | tok/s 13374
step    830 | loss 1.4983 | lr 3.00e-04 | grad 2.19 | tok/s 14349
step    840 | loss 1.3798 | lr 3.00e-04 | grad 2.12 | tok/s 14473
step    850 | loss 1.5915 | lr 3.00e-04 | grad 1.92 | tok/s 13761
step    860 | loss 1.4906 | lr 3.00e-04 | grad 3.27 | tok/s 14273
step    870 | loss 1.5136 | lr 3.00e-04 | grad 2.55 | tok/s 13727
step    880 | loss 1.6943 | lr 3.00e-04 | grad 2.47 | tok/s 13793
step    890 | loss 1.6959 | lr 3.00e-04 | grad 2.73 | tok/s 13991
step    900 | loss 1.5730 | lr 3.00e-04 | grad 2.42 | tok/s 14011
step    910 | loss 1.4319 | lr 3.00e-04 | grad 3.59 | tok/s 13711
step    920 | loss 1.5252 | lr 3.00e-04 | grad 3.31 | tok/s 14234
step    930 | loss 1.6167 | lr 3.00e-04 | grad 3.39 | tok/s 13620
step    940 | loss 1.4005 | lr 3.00e-04 | grad 1.77 | tok/s 14364
step    950 | loss 1.4921 | lr 3.00e-04 | grad 2.41 | tok/s 14445
step    960 | loss 1.3304 | lr 3.00e-04 | grad 2.38 | tok/s 14459
step    970 | loss 1.7530 | lr 3.00e-04 | grad 3.38 | tok/s 13578
step    980 | loss 1.6578 | lr 3.00e-04 | grad 2.30 | tok/s 13925
step    990 | loss 1.4585 | lr 3.00e-04 | grad 2.00 | tok/s 14162
step   1000 | loss 1.8436 | lr 3.00e-04 | grad 6.91 | tok/s 12936
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8436.pt
step   1010 | loss 1.6338 | lr 3.00e-04 | grad 3.14 | tok/s 6829
step   1020 | loss 1.6613 | lr 3.00e-04 | grad 1.83 | tok/s 13362
step   1030 | loss 1.4748 | lr 3.00e-04 | grad 1.99 | tok/s 13905
step   1040 | loss 1.4845 | lr 3.00e-04 | grad 2.08 | tok/s 14332
step   1050 | loss 1.6427 | lr 3.00e-04 | grad 3.06 | tok/s 13255
step   1060 | loss 1.7428 | lr 3.00e-04 | grad 3.17 | tok/s 14305
step   1070 | loss 1.6564 | lr 3.00e-04 | grad 2.56 | tok/s 14233
step   1080 | loss 1.4085 | lr 3.00e-04 | grad 1.84 | tok/s 12931
step   1090 | loss 1.1202 | lr 3.00e-04 | grad 1.20 | tok/s 14218
step   1100 | loss 1.4520 | lr 3.00e-04 | grad 3.16 | tok/s 13820
step   1110 | loss 1.4764 | lr 3.00e-04 | grad 1.91 | tok/s 14535
step   1120 | loss 1.3455 | lr 3.00e-04 | grad 1.94 | tok/s 14515
step   1130 | loss 1.2970 | lr 3.00e-04 | grad 1.82 | tok/s 14510
step   1140 | loss 1.2869 | lr 3.00e-04 | grad 2.00 | tok/s 13723
step   1150 | loss 1.3023 | lr 3.00e-04 | grad 1.70 | tok/s 14533
step   1160 | loss 1.2181 | lr 3.00e-04 | grad 1.73 | tok/s 14516
step   1170 | loss 1.2460 | lr 3.00e-04 | grad 1.99 | tok/s 14529
step   1180 | loss 1.3464 | lr 3.00e-04 | grad 1.60 | tok/s 14494
step   1190 | loss 1.2256 | lr 3.00e-04 | grad 2.05 | tok/s 14511
step   1200 | loss 1.2189 | lr 3.00e-04 | grad 1.88 | tok/s 14495
step   1210 | loss 1.2718 | lr 3.00e-04 | grad 1.95 | tok/s 14486
step   1220 | loss 1.2942 | lr 3.00e-04 | grad 1.80 | tok/s 14504
step   1230 | loss 1.2607 | lr 3.00e-04 | grad 1.72 | tok/s 14493
step   1240 | loss 1.2239 | lr 3.00e-04 | grad 1.52 | tok/s 14497
step   1250 | loss 1.8100 | lr 3.00e-04 | grad 3.44 | tok/s 13713
step   1260 | loss 1.3825 | lr 3.00e-04 | grad 2.80 | tok/s 13593
step   1270 | loss 1.6724 | lr 3.00e-04 | grad 4.69 | tok/s 13570
step   1280 | loss 1.6270 | lr 3.00e-04 | grad 1.73 | tok/s 13351
step   1290 | loss 1.4839 | lr 3.00e-04 | grad 1.95 | tok/s 13880
step   1300 | loss 1.5263 | lr 3.00e-04 | grad 2.39 | tok/s 13962
step   1310 | loss 1.4672 | lr 3.00e-04 | grad 2.22 | tok/s 14205
step   1320 | loss 1.5949 | lr 3.00e-04 | grad 2.16 | tok/s 14257
step   1330 | loss 1.6141 | lr 3.00e-04 | grad 2.25 | tok/s 14270
step   1340 | loss 1.5030 | lr 3.00e-04 | grad 9.44 | tok/s 13624
step   1350 | loss 1.7404 | lr 3.00e-04 | grad 2.33 | tok/s 13162
step   1360 | loss 1.4949 | lr 3.00e-04 | grad 2.22 | tok/s 13952
step   1370 | loss 1.4152 | lr 3.00e-04 | grad 1.53 | tok/s 13794
step   1380 | loss 1.6612 | lr 3.00e-04 | grad 2.25 | tok/s 13272
step   1390 | loss 1.5320 | lr 3.00e-04 | grad 1.66 | tok/s 14063
step   1400 | loss 1.4118 | lr 3.00e-04 | grad 1.70 | tok/s 13560
step   1410 | loss 1.4667 | lr 3.00e-04 | grad 2.92 | tok/s 13641
step   1420 | loss 1.6908 | lr 3.00e-04 | grad 3.73 | tok/s 13666
step   1430 | loss 1.3542 | lr 3.00e-04 | grad 1.91 | tok/s 13244
step   1440 | loss 1.1528 | lr 3.00e-04 | grad 1.79 | tok/s 14348
step   1450 | loss 1.1697 | lr 3.00e-04 | grad 4.03 | tok/s 14445
step   1460 | loss 1.6741 | lr 3.00e-04 | grad 1.98 | tok/s 13635
step   1470 | loss 1.5315 | lr 3.00e-04 | grad 1.77 | tok/s 14122
step   1480 | loss 1.8272 | lr 3.00e-04 | grad 3.81 | tok/s 14205
step   1490 | loss 1.5674 | lr 3.00e-04 | grad 1.66 | tok/s 14428
step   1500 | loss 1.3510 | lr 3.00e-04 | grad 1.70 | tok/s 14490
step   1510 | loss 1.5239 | lr 3.00e-04 | grad 1.90 | tok/s 14314
step   1520 | loss 1.4377 | lr 3.00e-04 | grad 3.19 | tok/s 14018
step   1530 | loss 1.4608 | lr 3.00e-04 | grad 1.66 | tok/s 14347
step   1540 | loss 1.6380 | lr 3.00e-04 | grad 2.27 | tok/s 13498
step   1550 | loss 1.2958 | lr 3.00e-04 | grad 2.19 | tok/s 14397
step   1560 | loss 1.5882 | lr 3.00e-04 | grad 2.50 | tok/s 13619
step   1570 | loss 1.2876 | lr 3.00e-04 | grad 2.09 | tok/s 13856
step   1580 | loss 1.7256 | lr 3.00e-04 | grad 3.58 | tok/s 14126
step   1590 | loss 1.6044 | lr 3.00e-04 | grad 2.39 | tok/s 13608
step   1600 | loss 1.0084 | lr 3.00e-04 | grad 1.42 | tok/s 14506
step   1610 | loss 1.0328 | lr 3.00e-04 | grad 2.36 | tok/s 14006
step   1620 | loss 1.4178 | lr 3.00e-04 | grad 2.83 | tok/s 13155
step   1630 | loss 1.3511 | lr 3.00e-04 | grad 2.12 | tok/s 14072
step   1640 | loss 1.3370 | lr 3.00e-04 | grad 2.17 | tok/s 13763
step   1650 | loss 1.5366 | lr 3.00e-04 | grad 2.44 | tok/s 13155
step   1660 | loss 1.3966 | lr 3.00e-04 | grad 1.71 | tok/s 14074
step   1670 | loss 1.3813 | lr 3.00e-04 | grad 6.91 | tok/s 14023
step   1680 | loss 1.7308 | lr 3.00e-04 | grad 1.90 | tok/s 13470
step   1690 | loss 1.4951 | lr 3.00e-04 | grad 3.95 | tok/s 13734
step   1700 | loss 1.5094 | lr 3.00e-04 | grad 2.23 | tok/s 14029
step   1710 | loss 1.4325 | lr 3.00e-04 | grad 2.12 | tok/s 13753
step   1720 | loss 1.5397 | lr 3.00e-04 | grad 2.78 | tok/s 13745
step   1730 | loss 1.2382 | lr 3.00e-04 | grad 2.64 | tok/s 14499
step   1740 | loss 1.3404 | lr 3.00e-04 | grad 2.58 | tok/s 14118
step   1750 | loss 1.5792 | lr 3.00e-04 | grad 2.39 | tok/s 13899
step   1760 | loss 1.5515 | lr 3.00e-04 | grad 2.23 | tok/s 13939
step   1770 | loss 1.4460 | lr 3.00e-04 | grad 2.23 | tok/s 13718
step   1780 | loss 1.5155 | lr 3.00e-04 | grad 1.71 | tok/s 14271
step   1790 | loss 1.4113 | lr 3.00e-04 | grad 1.61 | tok/s 13894
step   1800 | loss 1.6296 | lr 3.00e-04 | grad 2.61 | tok/s 14008
step   1810 | loss 1.4631 | lr 3.00e-04 | grad 1.95 | tok/s 13506
step   1820 | loss 1.4838 | lr 3.00e-04 | grad 4.50 | tok/s 13714
step   1830 | loss 1.4173 | lr 3.00e-04 | grad 2.22 | tok/s 14241
step   1840 | loss 1.5475 | lr 3.00e-04 | grad 2.53 | tok/s 13661
step   1850 | loss 1.3046 | lr 3.00e-04 | grad 1.67 | tok/s 14305
step   1860 | loss 1.3276 | lr 3.00e-04 | grad 2.17 | tok/s 13206
step   1870 | loss 1.4225 | lr 3.00e-04 | grad 2.66 | tok/s 13868
step   1880 | loss 1.2411 | lr 3.00e-04 | grad 2.14 | tok/s 13580
step   1890 | loss 1.5138 | lr 3.00e-04 | grad 1.81 | tok/s 12948
step   1900 | loss 1.4058 | lr 3.00e-04 | grad 2.42 | tok/s 14002
step   1910 | loss 1.4821 | lr 3.00e-04 | grad 2.69 | tok/s 13252
step   1920 | loss 1.4030 | lr 3.00e-04 | grad 1.89 | tok/s 14537
step   1930 | loss 1.4667 | lr 3.00e-04 | grad 2.41 | tok/s 13633
step   1940 | loss 1.4497 | lr 3.00e-04 | grad 1.95 | tok/s 14146
step   1950 | loss 1.8795 | lr 3.00e-04 | grad 3.39 | tok/s 14371
step   1960 | loss 1.4650 | lr 3.00e-04 | grad 4.06 | tok/s 14515
step   1970 | loss 1.5330 | lr 3.00e-04 | grad 2.36 | tok/s 14170
step   1980 | loss 1.5511 | lr 3.00e-04 | grad 2.05 | tok/s 13543
step   1990 | loss 1.6255 | lr 3.00e-04 | grad 10.19 | tok/s 13815
step   2000 | loss 1.4996 | lr 3.00e-04 | grad 1.94 | tok/s 13995
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4996.pt
step   2010 | loss 1.0706 | lr 3.00e-04 | grad 1.62 | tok/s 7133
step   2020 | loss 1.3097 | lr 3.00e-04 | grad 1.98 | tok/s 13935
step   2030 | loss 1.0989 | lr 3.00e-04 | grad 0.90 | tok/s 14645
step   2040 | loss 1.2366 | lr 3.00e-04 | grad 2.02 | tok/s 14581
step   2050 | loss 1.2015 | lr 3.00e-04 | grad 2.12 | tok/s 14286
step   2060 | loss 1.5747 | lr 3.00e-04 | grad 2.16 | tok/s 13454

Training complete! Final step: 2061
