Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_46/levelE88_100m_20260126_152013
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 489,144,920 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3418 | lr 3.00e-04 | grad 14.88 | tok/s 5268
step     20 | loss 2.6009 | lr 3.00e-04 | grad 5.09 | tok/s 10387
step     30 | loss 2.5383 | lr 3.00e-04 | grad 3.08 | tok/s 10501
step     40 | loss 2.3747 | lr 3.00e-04 | grad 2.86 | tok/s 10142
step     50 | loss 3.0208 | lr 3.00e-04 | grad 11.69 | tok/s 10166
step     60 | loss 2.0983 | lr 3.00e-04 | grad 3.44 | tok/s 10518
step     70 | loss 1.9802 | lr 3.00e-04 | grad 4.34 | tok/s 10627
step     80 | loss 5.5059 | lr 3.00e-04 | grad 91.00 | tok/s 10739
step     90 | loss 5.3956 | lr 3.00e-04 | grad 9.69 | tok/s 10895
step    100 | loss 4.5660 | lr 3.00e-04 | grad 11.88 | tok/s 10881
step    110 | loss 4.1539 | lr 3.00e-04 | grad 18.25 | tok/s 10855
step    120 | loss 3.6823 | lr 3.00e-04 | grad 17.75 | tok/s 10865
step    130 | loss 3.3191 | lr 3.00e-04 | grad 20.75 | tok/s 10846
step    140 | loss 2.7253 | lr 3.00e-04 | grad 11.81 | tok/s 10912
step    150 | loss 3.0013 | lr 3.00e-04 | grad 15.06 | tok/s 10871
step    160 | loss 2.3642 | lr 3.00e-04 | grad 12.44 | tok/s 10899
step    170 | loss 2.4969 | lr 3.00e-04 | grad 11.31 | tok/s 10862
step    180 | loss 2.2443 | lr 3.00e-04 | grad 4.19 | tok/s 10810
step    190 | loss 2.4418 | lr 3.00e-04 | grad 4.91 | tok/s 10807
step    200 | loss 2.1643 | lr 3.00e-04 | grad 6.78 | tok/s 10851
step    210 | loss 2.1005 | lr 3.00e-04 | grad 5.69 | tok/s 10847
step    220 | loss 2.2412 | lr 3.00e-04 | grad 2.38 | tok/s 10658
step    230 | loss 2.0496 | lr 3.00e-04 | grad 2.59 | tok/s 10535
step    240 | loss 2.2767 | lr 3.00e-04 | grad 3.48 | tok/s 10064
step    250 | loss 2.1089 | lr 3.00e-04 | grad 1.86 | tok/s 10280
step    260 | loss 1.6127 | lr 3.00e-04 | grad 2.08 | tok/s 10651
step    270 | loss 2.0938 | lr 3.00e-04 | grad 1.88 | tok/s 10506
step    280 | loss 2.2721 | lr 3.00e-04 | grad 3.73 | tok/s 10288
step    290 | loss 1.4946 | lr 3.00e-04 | grad 3.34 | tok/s 10824
step    300 | loss 0.6143 | lr 3.00e-04 | grad 2.20 | tok/s 10886
step    310 | loss 2.4298 | lr 3.00e-04 | grad 3.09 | tok/s 10630
step    320 | loss 1.9939 | lr 3.00e-04 | grad 4.19 | tok/s 10458
step    330 | loss 1.9590 | lr 3.00e-04 | grad 2.09 | tok/s 10059
step    340 | loss 2.2741 | lr 3.00e-04 | grad 2.09 | tok/s 10263
step    350 | loss 1.9240 | lr 3.00e-04 | grad 3.47 | tok/s 10475
step    360 | loss 1.2580 | lr 3.00e-04 | grad 5.62 | tok/s 10723
step    370 | loss 1.8356 | lr 3.00e-04 | grad 1.93 | tok/s 9715
step    380 | loss 1.7989 | lr 3.00e-04 | grad 1.87 | tok/s 9677
step    390 | loss 1.5581 | lr 3.00e-04 | grad 1.46 | tok/s 10824
step    400 | loss 1.5134 | lr 3.00e-04 | grad 1.88 | tok/s 10723
step    410 | loss 1.3170 | lr 3.00e-04 | grad 1.49 | tok/s 10486
step    420 | loss 1.8266 | lr 3.00e-04 | grad 3.17 | tok/s 10018
step    430 | loss 2.1708 | lr 3.00e-04 | grad 2.17 | tok/s 10667
step    440 | loss 2.1617 | lr 3.00e-04 | grad 3.05 | tok/s 10083
step    450 | loss 1.9259 | lr 3.00e-04 | grad 2.06 | tok/s 10442
step    460 | loss 1.7254 | lr 3.00e-04 | grad 1.98 | tok/s 10214
step    470 | loss 1.8355 | lr 3.00e-04 | grad 1.70 | tok/s 10534
step    480 | loss 2.2750 | lr 3.00e-04 | grad 5.16 | tok/s 10535
step    490 | loss 1.7979 | lr 3.00e-04 | grad 1.82 | tok/s 9958
step    500 | loss 1.7005 | lr 3.00e-04 | grad 2.48 | tok/s 10649
step    510 | loss 1.7243 | lr 3.00e-04 | grad 1.66 | tok/s 10782
step    520 | loss 1.6850 | lr 3.00e-04 | grad 1.51 | tok/s 10767
step    530 | loss 1.9198 | lr 3.00e-04 | grad 1.89 | tok/s 10344
step    540 | loss 1.7450 | lr 3.00e-04 | grad 1.62 | tok/s 10373
step    550 | loss 1.5789 | lr 3.00e-04 | grad 2.20 | tok/s 10132
step    560 | loss 1.7290 | lr 3.00e-04 | grad 2.00 | tok/s 9887
step    570 | loss 1.6748 | lr 3.00e-04 | grad 2.91 | tok/s 10142
step    580 | loss 1.5530 | lr 3.00e-04 | grad 1.57 | tok/s 10122
step    590 | loss 1.8766 | lr 3.00e-04 | grad 2.36 | tok/s 10370
step    600 | loss 1.8177 | lr 3.00e-04 | grad 1.72 | tok/s 10032
step    610 | loss 1.6332 | lr 3.00e-04 | grad 1.69 | tok/s 10536
step    620 | loss 1.5527 | lr 3.00e-04 | grad 1.80 | tok/s 9995
step    630 | loss 1.6706 | lr 3.00e-04 | grad 3.25 | tok/s 10063
step    640 | loss 1.8159 | lr 3.00e-04 | grad 1.91 | tok/s 10355
step    650 | loss 1.6654 | lr 3.00e-04 | grad 1.89 | tok/s 10399
step    660 | loss 1.7038 | lr 3.00e-04 | grad 1.60 | tok/s 10443
step    670 | loss 1.9254 | lr 3.00e-04 | grad 5.19 | tok/s 10526
step    680 | loss 1.7317 | lr 3.00e-04 | grad 1.82 | tok/s 10313
step    690 | loss 1.8385 | lr 3.00e-04 | grad 2.45 | tok/s 10650
step    700 | loss 1.4662 | lr 3.00e-04 | grad 2.33 | tok/s 10875
step    710 | loss 1.5850 | lr 3.00e-04 | grad 1.77 | tok/s 10152
step    720 | loss 1.4652 | lr 3.00e-04 | grad 2.66 | tok/s 9980
step    730 | loss 1.3150 | lr 3.00e-04 | grad 2.11 | tok/s 10862
step    740 | loss 1.5164 | lr 3.00e-04 | grad 1.83 | tok/s 10685
step    750 | loss 1.2314 | lr 3.00e-04 | grad 1.92 | tok/s 10871
step    760 | loss 1.1280 | lr 3.00e-04 | grad 1.72 | tok/s 10853
step    770 | loss 1.0771 | lr 3.00e-04 | grad 1.54 | tok/s 10873
step    780 | loss 1.0053 | lr 3.00e-04 | grad 1.54 | tok/s 10861
step    790 | loss 1.1287 | lr 3.00e-04 | grad 2.58 | tok/s 10531
step    800 | loss 1.8230 | lr 3.00e-04 | grad 4.41 | tok/s 10503
step    810 | loss 1.7029 | lr 3.00e-04 | grad 1.67 | tok/s 10005
step    820 | loss 1.7090 | lr 3.00e-04 | grad 3.05 | tok/s 10040
step    830 | loss 1.5054 | lr 3.00e-04 | grad 1.84 | tok/s 10770
step    840 | loss 1.3938 | lr 3.00e-04 | grad 1.79 | tok/s 10878
step    850 | loss 1.5861 | lr 3.00e-04 | grad 1.64 | tok/s 10824
step    860 | loss 1.4914 | lr 3.00e-04 | grad 2.81 | tok/s 10692
step    870 | loss 1.5034 | lr 3.00e-04 | grad 2.14 | tok/s 10301
step    880 | loss 1.6727 | lr 3.00e-04 | grad 2.09 | tok/s 10330
step    890 | loss 1.6766 | lr 3.00e-04 | grad 2.33 | tok/s 10495
step    900 | loss 1.5568 | lr 3.00e-04 | grad 2.03 | tok/s 10504
step    910 | loss 1.4291 | lr 3.00e-04 | grad 2.97 | tok/s 10272
step    920 | loss 1.5253 | lr 3.00e-04 | grad 2.89 | tok/s 10689
step    930 | loss 1.5983 | lr 3.00e-04 | grad 2.83 | tok/s 10196
step    940 | loss 1.4007 | lr 3.00e-04 | grad 1.45 | tok/s 10773
step    950 | loss 1.4920 | lr 3.00e-04 | grad 2.36 | tok/s 10826
step    960 | loss 1.3355 | lr 3.00e-04 | grad 1.98 | tok/s 10841
step    970 | loss 1.7305 | lr 3.00e-04 | grad 2.86 | tok/s 10176
step    980 | loss 1.6471 | lr 3.00e-04 | grad 1.90 | tok/s 10457
step    990 | loss 1.4537 | lr 3.00e-04 | grad 1.68 | tok/s 10640
step   1000 | loss 1.8199 | lr 3.00e-04 | grad 6.00 | tok/s 10201
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8199.pt
step   1010 | loss 1.6234 | lr 3.00e-04 | grad 2.66 | tok/s 5492
step   1020 | loss 1.6422 | lr 3.00e-04 | grad 1.51 | tok/s 9954
step   1030 | loss 1.4540 | lr 3.00e-04 | grad 1.58 | tok/s 10414
step   1040 | loss 1.4811 | lr 3.00e-04 | grad 1.75 | tok/s 10725
step   1050 | loss 1.6124 | lr 3.00e-04 | grad 2.56 | tok/s 9902
step   1060 | loss 1.7226 | lr 3.00e-04 | grad 2.75 | tok/s 10707
step   1070 | loss 1.6576 | lr 3.00e-04 | grad 2.19 | tok/s 10661
step   1080 | loss 1.3923 | lr 3.00e-04 | grad 1.55 | tok/s 9238
step   1090 | loss 1.1093 | lr 3.00e-04 | grad 1.02 | tok/s 10645
step   1100 | loss 1.4266 | lr 3.00e-04 | grad 2.66 | tok/s 10344
step   1110 | loss 1.4617 | lr 3.00e-04 | grad 1.55 | tok/s 10890
step   1120 | loss 1.3383 | lr 3.00e-04 | grad 1.60 | tok/s 10895
step   1130 | loss 1.2913 | lr 3.00e-04 | grad 1.48 | tok/s 10892
step   1140 | loss 1.2778 | lr 3.00e-04 | grad 1.72 | tok/s 10882
step   1150 | loss 1.2975 | lr 3.00e-04 | grad 1.39 | tok/s 10879
step   1160 | loss 1.2120 | lr 3.00e-04 | grad 1.41 | tok/s 10892
step   1170 | loss 1.2415 | lr 3.00e-04 | grad 1.65 | tok/s 10894
step   1180 | loss 1.3411 | lr 3.00e-04 | grad 1.36 | tok/s 10892
step   1190 | loss 1.2202 | lr 3.00e-04 | grad 1.74 | tok/s 10858
step   1200 | loss 1.2161 | lr 3.00e-04 | grad 1.62 | tok/s 10875
step   1210 | loss 1.2651 | lr 3.00e-04 | grad 1.65 | tok/s 10857
step   1220 | loss 1.2842 | lr 3.00e-04 | grad 1.57 | tok/s 10876
step   1230 | loss 1.2527 | lr 3.00e-04 | grad 1.38 | tok/s 10860
step   1240 | loss 1.2169 | lr 3.00e-04 | grad 1.27 | tok/s 10882
step   1250 | loss 1.7624 | lr 3.00e-04 | grad 2.86 | tok/s 10295
step   1260 | loss 1.3994 | lr 3.00e-04 | grad 16.50 | tok/s 9812
step   1270 | loss 1.6474 | lr 3.00e-04 | grad 3.77 | tok/s 10167
step   1280 | loss 1.6055 | lr 3.00e-04 | grad 1.47 | tok/s 10466
step   1290 | loss 1.4676 | lr 3.00e-04 | grad 1.61 | tok/s 10387
step   1300 | loss 1.5116 | lr 3.00e-04 | grad 1.96 | tok/s 10468
step   1310 | loss 1.4579 | lr 3.00e-04 | grad 1.84 | tok/s 10651
step   1320 | loss 1.5705 | lr 3.00e-04 | grad 1.77 | tok/s 10684
step   1330 | loss 1.5900 | lr 3.00e-04 | grad 1.88 | tok/s 10693
step   1340 | loss 1.4733 | lr 3.00e-04 | grad 7.44 | tok/s 10210
step   1350 | loss 1.7077 | lr 3.00e-04 | grad 1.91 | tok/s 9866
step   1360 | loss 1.4927 | lr 3.00e-04 | grad 1.86 | tok/s 10476
step   1370 | loss 1.4023 | lr 3.00e-04 | grad 1.25 | tok/s 10330
step   1380 | loss 1.6198 | lr 3.00e-04 | grad 1.94 | tok/s 9949
step   1390 | loss 1.5089 | lr 3.00e-04 | grad 1.44 | tok/s 10542
step   1400 | loss 1.3958 | lr 3.00e-04 | grad 1.43 | tok/s 10180
step   1410 | loss 1.4448 | lr 3.00e-04 | grad 2.48 | tok/s 10205
step   1420 | loss 1.6638 | lr 3.00e-04 | grad 3.61 | tok/s 10228
step   1430 | loss 1.3486 | lr 3.00e-04 | grad 1.64 | tok/s 10401
step   1440 | loss 1.1395 | lr 3.00e-04 | grad 1.45 | tok/s 10763
step   1450 | loss 1.1570 | lr 3.00e-04 | grad 3.56 | tok/s 10816
step   1460 | loss 1.6311 | lr 3.00e-04 | grad 1.69 | tok/s 10214
step   1470 | loss 1.5119 | lr 3.00e-04 | grad 1.49 | tok/s 10579
step   1480 | loss 1.8043 | lr 3.00e-04 | grad 3.08 | tok/s 10663
step   1490 | loss 1.5474 | lr 3.00e-04 | grad 1.41 | tok/s 10811
step   1500 | loss 1.3442 | lr 3.00e-04 | grad 1.42 | tok/s 10872
step   1510 | loss 1.4966 | lr 3.00e-04 | grad 1.59 | tok/s 10518
step   1520 | loss 1.4191 | lr 3.00e-04 | grad 2.92 | tok/s 10485
step   1530 | loss 1.4286 | lr 3.00e-04 | grad 1.35 | tok/s 10764
step   1540 | loss 1.5994 | lr 3.00e-04 | grad 1.98 | tok/s 10089
step   1550 | loss 1.2824 | lr 3.00e-04 | grad 1.84 | tok/s 10790

Training complete! Final step: 1556
