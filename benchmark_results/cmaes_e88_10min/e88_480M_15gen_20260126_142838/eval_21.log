Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_21/levelE88_100m_20260126_144924
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 472,844,568 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.5407 | lr 3.00e-04 | grad 7.41 | tok/s 6231
step     20 | loss 2.7558 | lr 3.00e-04 | grad 2.05 | tok/s 8515
step     30 | loss 3.1213 | lr 3.00e-04 | grad 6.09 | tok/s 8988
step     40 | loss 4.1335 | lr 3.00e-04 | grad 41.00 | tok/s 9121
step     50 | loss 4.7867 | lr 3.00e-04 | grad 22.25 | tok/s 9194
step     60 | loss 4.1106 | lr 3.00e-04 | grad 18.38 | tok/s 9127
step     70 | loss 3.3594 | lr 3.00e-04 | grad 11.44 | tok/s 9066
step     80 | loss 2.9229 | lr 3.00e-04 | grad 8.06 | tok/s 9046
step     90 | loss 2.5887 | lr 3.00e-04 | grad 4.94 | tok/s 9005
step    100 | loss 2.3781 | lr 3.00e-04 | grad 1.98 | tok/s 8983
step    110 | loss 2.3944 | lr 3.00e-04 | grad 2.03 | tok/s 8879
step    120 | loss 2.7629 | lr 3.00e-04 | grad 1.16 | tok/s 8421
step    130 | loss 2.2063 | lr 3.00e-04 | grad 3.81 | tok/s 8610
step    140 | loss 2.4092 | lr 3.00e-04 | grad 6.16 | tok/s 8476
step    150 | loss 1.5738 | lr 3.00e-04 | grad 2.34 | tok/s 8795
step    160 | loss 2.3143 | lr 3.00e-04 | grad 1.21 | tok/s 8426
step    170 | loss 2.3287 | lr 3.00e-04 | grad 1.33 | tok/s 8425
step    180 | loss 2.0680 | lr 3.00e-04 | grad 1.95 | tok/s 8471
step    190 | loss 1.9377 | lr 3.00e-04 | grad 1.48 | tok/s 8511
step    200 | loss 1.7354 | lr 3.00e-04 | grad 1.29 | tok/s 8771
step    210 | loss 2.0118 | lr 3.00e-04 | grad 1.52 | tok/s 8288
step    220 | loss 2.2465 | lr 3.00e-04 | grad 3.94 | tok/s 8408
step    230 | loss 2.0070 | lr 3.00e-04 | grad 2.55 | tok/s 8305
step    240 | loss 2.2353 | lr 3.00e-04 | grad 1.30 | tok/s 8483
step    250 | loss 1.8500 | lr 3.00e-04 | grad 1.59 | tok/s 8481
step    260 | loss 1.9694 | lr 3.00e-04 | grad 2.02 | tok/s 8646
step    270 | loss 1.8048 | lr 3.00e-04 | grad 1.32 | tok/s 8380
step    280 | loss 1.8142 | lr 3.00e-04 | grad 1.20 | tok/s 8024
step    290 | loss 1.6939 | lr 3.00e-04 | grad 1.48 | tok/s 8169
step    300 | loss 2.0091 | lr 3.00e-04 | grad 1.47 | tok/s 8311
step    310 | loss 1.7006 | lr 3.00e-04 | grad 1.73 | tok/s 8188
step    320 | loss 1.8672 | lr 3.00e-04 | grad 1.37 | tok/s 8335
step    330 | loss 1.7463 | lr 3.00e-04 | grad 1.34 | tok/s 8408
step    340 | loss 2.0581 | lr 3.00e-04 | grad 1.66 | tok/s 8422
step    350 | loss 1.7600 | lr 3.00e-04 | grad 1.22 | tok/s 8657
step    360 | loss 1.5793 | lr 3.00e-04 | grad 1.07 | tok/s 8241
step    370 | loss 1.5103 | lr 3.00e-04 | grad 1.30 | tok/s 8689
step    380 | loss 1.2707 | lr 3.00e-04 | grad 1.34 | tok/s 8771
step    390 | loss 1.1478 | lr 3.00e-04 | grad 1.19 | tok/s 8775
step    400 | loss 1.8394 | lr 3.00e-04 | grad 1.55 | tok/s 8306
step    410 | loss 1.7502 | lr 3.00e-04 | grad 1.55 | tok/s 8377
step    420 | loss 1.6872 | lr 3.00e-04 | grad 3.62 | tok/s 8643
step    430 | loss 1.6035 | lr 3.00e-04 | grad 1.39 | tok/s 8467
step    440 | loss 1.7493 | lr 3.00e-04 | grad 1.38 | tok/s 8418
step    450 | loss 1.5727 | lr 3.00e-04 | grad 3.27 | tok/s 8356
step    460 | loss 1.6547 | lr 3.00e-04 | grad 1.77 | tok/s 8449
step    470 | loss 1.5831 | lr 3.00e-04 | grad 1.43 | tok/s 8682
step    480 | loss 1.5887 | lr 3.00e-04 | grad 1.45 | tok/s 8487
step    490 | loss 1.6720 | lr 3.00e-04 | grad 1.10 | tok/s 8518
step    500 | loss 1.8558 | lr 3.00e-04 | grad 3.22 | tok/s 8382
step    510 | loss 1.6605 | lr 3.00e-04 | grad 2.50 | tok/s 7982
step    520 | loss 1.4919 | lr 3.00e-04 | grad 1.30 | tok/s 8341
step    530 | loss 1.7908 | lr 3.00e-04 | grad 1.90 | tok/s 8593
step    540 | loss 1.5354 | lr 3.00e-04 | grad 1.16 | tok/s 8132
step    550 | loss 1.3847 | lr 3.00e-04 | grad 1.15 | tok/s 8553
step    560 | loss 1.4208 | lr 3.00e-04 | grad 1.15 | tok/s 8781
step    570 | loss 1.3493 | lr 3.00e-04 | grad 1.04 | tok/s 8780
step    580 | loss 1.3017 | lr 3.00e-04 | grad 1.09 | tok/s 8782
step    590 | loss 1.3576 | lr 3.00e-04 | grad 1.20 | tok/s 8740
step    600 | loss 1.2891 | lr 3.00e-04 | grad 1.04 | tok/s 8769
step    610 | loss 1.3066 | lr 3.00e-04 | grad 1.12 | tok/s 8760
step    620 | loss 1.5010 | lr 3.00e-04 | grad 4.38 | tok/s 8624
step    630 | loss 1.5561 | lr 3.00e-04 | grad 1.52 | tok/s 8323
step    640 | loss 1.6608 | lr 3.00e-04 | grad 1.09 | tok/s 8308

Training complete! Final step: 641
