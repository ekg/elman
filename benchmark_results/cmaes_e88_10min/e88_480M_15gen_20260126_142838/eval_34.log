Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_34/levelE88_100m_20260126_150957
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 491,957,378 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2199 | lr 3.00e-04 | grad 17.25 | tok/s 6148
step     20 | loss 2.7451 | lr 3.00e-04 | grad 8.94 | tok/s 15619
step     30 | loss 2.5908 | lr 3.00e-04 | grad 5.06 | tok/s 15777
step     40 | loss 2.4059 | lr 3.00e-04 | grad 4.25 | tok/s 15100
step     50 | loss 3.1084 | lr 3.00e-04 | grad 15.50 | tok/s 15331
step     60 | loss 2.0797 | lr 3.00e-04 | grad 4.09 | tok/s 15803
step     70 | loss 1.9191 | lr 3.00e-04 | grad 5.38 | tok/s 15978
step     80 | loss 6.0337 | lr 3.00e-04 | grad 102.00 | tok/s 16066
step     90 | loss 5.7907 | lr 3.00e-04 | grad 13.69 | tok/s 16331
step    100 | loss 4.5092 | lr 3.00e-04 | grad 12.06 | tok/s 16307
step    110 | loss 3.9196 | lr 3.00e-04 | grad 25.12 | tok/s 16296
step    120 | loss 3.4972 | lr 3.00e-04 | grad 17.88 | tok/s 16256
step    130 | loss 3.2547 | lr 3.00e-04 | grad 22.12 | tok/s 15049
step    140 | loss 2.8409 | lr 3.00e-04 | grad 12.62 | tok/s 16122
step    150 | loss 2.9938 | lr 3.00e-04 | grad 19.12 | tok/s 16113
step    160 | loss 2.4356 | lr 3.00e-04 | grad 14.25 | tok/s 16106
step    170 | loss 2.5366 | lr 3.00e-04 | grad 15.81 | tok/s 16098
step    180 | loss 2.3436 | lr 3.00e-04 | grad 7.56 | tok/s 16097
step    190 | loss 2.5091 | lr 3.00e-04 | grad 6.91 | tok/s 16095
step    200 | loss 2.1977 | lr 3.00e-04 | grad 9.06 | tok/s 16072
step    210 | loss 2.1671 | lr 3.00e-04 | grad 7.19 | tok/s 16071
step    220 | loss 2.2492 | lr 3.00e-04 | grad 3.44 | tok/s 15823
step    230 | loss 2.1117 | lr 3.00e-04 | grad 3.58 | tok/s 15690
step    240 | loss 2.2966 | lr 3.00e-04 | grad 4.75 | tok/s 14821
step    250 | loss 2.1163 | lr 3.00e-04 | grad 2.55 | tok/s 15229
step    260 | loss 1.5689 | lr 3.00e-04 | grad 2.98 | tok/s 15716
step    270 | loss 2.1014 | lr 3.00e-04 | grad 2.73 | tok/s 14802
step    280 | loss 2.2735 | lr 3.00e-04 | grad 5.06 | tok/s 15234
step    290 | loss 1.4413 | lr 3.00e-04 | grad 3.50 | tok/s 16004
step    300 | loss 0.5845 | lr 3.00e-04 | grad 2.70 | tok/s 15997
step    310 | loss 2.3962 | lr 3.00e-04 | grad 3.66 | tok/s 15730
step    320 | loss 1.9476 | lr 3.00e-04 | grad 5.72 | tok/s 15396
step    330 | loss 1.9587 | lr 3.00e-04 | grad 2.84 | tok/s 14873
step    340 | loss 2.2886 | lr 3.00e-04 | grad 2.75 | tok/s 15109
step    350 | loss 1.8864 | lr 3.00e-04 | grad 4.25 | tok/s 15487
step    360 | loss 1.2161 | lr 3.00e-04 | grad 7.16 | tok/s 15840
step    370 | loss 1.8138 | lr 3.00e-04 | grad 2.55 | tok/s 14368
step    380 | loss 1.7760 | lr 3.00e-04 | grad 2.47 | tok/s 15282
step    390 | loss 1.5486 | lr 3.00e-04 | grad 2.08 | tok/s 15991
step    400 | loss 1.5026 | lr 3.00e-04 | grad 2.58 | tok/s 15862
step    410 | loss 1.2876 | lr 3.00e-04 | grad 2.03 | tok/s 14693
step    420 | loss 1.8279 | lr 3.00e-04 | grad 4.41 | tok/s 14858
step    430 | loss 2.1726 | lr 3.00e-04 | grad 2.89 | tok/s 15766
step    440 | loss 2.1673 | lr 3.00e-04 | grad 4.09 | tok/s 14906
step    450 | loss 1.9834 | lr 3.00e-04 | grad 2.69 | tok/s 15460
step    460 | loss 1.7334 | lr 3.00e-04 | grad 2.80 | tok/s 15073
step    470 | loss 1.8455 | lr 3.00e-04 | grad 2.31 | tok/s 15536
step    480 | loss 2.2490 | lr 3.00e-04 | grad 6.50 | tok/s 15541
step    490 | loss 1.7951 | lr 3.00e-04 | grad 2.38 | tok/s 14748
step    500 | loss 1.6892 | lr 3.00e-04 | grad 3.22 | tok/s 15713
step    510 | loss 1.7150 | lr 3.00e-04 | grad 2.25 | tok/s 15913
step    520 | loss 1.6709 | lr 3.00e-04 | grad 2.05 | tok/s 15937
step    530 | loss 1.9238 | lr 3.00e-04 | grad 2.39 | tok/s 15277
step    540 | loss 1.7484 | lr 3.00e-04 | grad 2.19 | tok/s 15260
step    550 | loss 1.5796 | lr 3.00e-04 | grad 2.84 | tok/s 14299
step    560 | loss 1.7352 | lr 3.00e-04 | grad 2.56 | tok/s 14702
step    570 | loss 1.6773 | lr 3.00e-04 | grad 3.47 | tok/s 15088
step    580 | loss 1.5569 | lr 3.00e-04 | grad 2.08 | tok/s 15030
step    590 | loss 1.8723 | lr 3.00e-04 | grad 2.98 | tok/s 15416
step    600 | loss 1.8257 | lr 3.00e-04 | grad 2.27 | tok/s 14876
step    610 | loss 1.6329 | lr 3.00e-04 | grad 2.34 | tok/s 15653
step    620 | loss 1.5598 | lr 3.00e-04 | grad 2.34 | tok/s 14824
step    630 | loss 1.6664 | lr 3.00e-04 | grad 4.19 | tok/s 14941
step    640 | loss 1.8178 | lr 3.00e-04 | grad 2.41 | tok/s 15335
step    650 | loss 1.6873 | lr 3.00e-04 | grad 2.45 | tok/s 15425
step    660 | loss 1.7063 | lr 3.00e-04 | grad 2.05 | tok/s 15479
step    670 | loss 1.9339 | lr 3.00e-04 | grad 3.09 | tok/s 15594
step    680 | loss 1.7351 | lr 3.00e-04 | grad 2.36 | tok/s 15293
step    690 | loss 1.8438 | lr 3.00e-04 | grad 3.14 | tok/s 14930
step    700 | loss 1.4443 | lr 3.00e-04 | grad 2.98 | tok/s 16045
step    710 | loss 1.5982 | lr 3.00e-04 | grad 2.27 | tok/s 14983
step    720 | loss 1.4793 | lr 3.00e-04 | grad 3.38 | tok/s 14776
step    730 | loss 1.2936 | lr 3.00e-04 | grad 2.91 | tok/s 15967
step    740 | loss 1.5067 | lr 3.00e-04 | grad 2.25 | tok/s 15756
step    750 | loss 1.2033 | lr 3.00e-04 | grad 2.47 | tok/s 15990
step    760 | loss 1.1095 | lr 3.00e-04 | grad 2.19 | tok/s 16014
step    770 | loss 1.0560 | lr 3.00e-04 | grad 2.03 | tok/s 16063
step    780 | loss 0.9895 | lr 3.00e-04 | grad 2.06 | tok/s 16008
step    790 | loss 1.1311 | lr 3.00e-04 | grad 3.17 | tok/s 15576
step    800 | loss 1.8260 | lr 3.00e-04 | grad 5.38 | tok/s 15484
step    810 | loss 1.7151 | lr 3.00e-04 | grad 2.02 | tok/s 15413
step    820 | loss 1.7228 | lr 3.00e-04 | grad 3.80 | tok/s 14754
step    830 | loss 1.4923 | lr 3.00e-04 | grad 2.25 | tok/s 15270
step    840 | loss 1.3688 | lr 3.00e-04 | grad 2.19 | tok/s 16035
step    850 | loss 1.6019 | lr 3.00e-04 | grad 2.00 | tok/s 15929
step    860 | loss 1.4911 | lr 3.00e-04 | grad 3.47 | tok/s 15822
step    870 | loss 1.5080 | lr 3.00e-04 | grad 2.58 | tok/s 15180
step    880 | loss 1.6913 | lr 3.00e-04 | grad 2.61 | tok/s 15303
step    890 | loss 1.6879 | lr 3.00e-04 | grad 2.84 | tok/s 15453
step    900 | loss 1.5783 | lr 3.00e-04 | grad 2.48 | tok/s 15526
step    910 | loss 1.4331 | lr 3.00e-04 | grad 3.78 | tok/s 15155
step    920 | loss 1.5306 | lr 3.00e-04 | grad 3.39 | tok/s 15805
step    930 | loss 1.6071 | lr 3.00e-04 | grad 3.39 | tok/s 15079
step    940 | loss 1.3946 | lr 3.00e-04 | grad 1.81 | tok/s 15885
step    950 | loss 1.4885 | lr 3.00e-04 | grad 2.56 | tok/s 15990
step    960 | loss 1.3255 | lr 3.00e-04 | grad 2.44 | tok/s 16006
step    970 | loss 1.7568 | lr 3.00e-04 | grad 3.47 | tok/s 14456
step    980 | loss 1.6518 | lr 3.00e-04 | grad 2.30 | tok/s 15454
step    990 | loss 1.4567 | lr 3.00e-04 | grad 2.05 | tok/s 15713
step   1000 | loss 1.8488 | lr 3.00e-04 | grad 7.53 | tok/s 15100
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8488.pt
step   1010 | loss 1.6438 | lr 3.00e-04 | grad 3.30 | tok/s 7222
step   1020 | loss 1.6603 | lr 3.00e-04 | grad 1.90 | tok/s 14780
step   1030 | loss 1.4652 | lr 3.00e-04 | grad 2.03 | tok/s 15388
step   1040 | loss 1.4884 | lr 3.00e-04 | grad 2.16 | tok/s 15867
step   1050 | loss 1.6301 | lr 3.00e-04 | grad 3.12 | tok/s 14660
step   1060 | loss 1.7347 | lr 3.00e-04 | grad 3.33 | tok/s 15902
step   1070 | loss 1.6492 | lr 3.00e-04 | grad 2.59 | tok/s 15797
step   1080 | loss 1.4097 | lr 3.00e-04 | grad 1.90 | tok/s 14353
step   1090 | loss 1.1204 | lr 3.00e-04 | grad 1.12 | tok/s 15796
step   1100 | loss 1.4493 | lr 3.00e-04 | grad 3.27 | tok/s 15320
step   1110 | loss 1.4709 | lr 3.00e-04 | grad 2.11 | tok/s 15511
step   1120 | loss 1.3415 | lr 3.00e-04 | grad 2.05 | tok/s 16165
step   1130 | loss 1.2933 | lr 3.00e-04 | grad 1.88 | tok/s 16141
step   1140 | loss 1.2845 | lr 3.00e-04 | grad 2.02 | tok/s 16125
step   1150 | loss 1.2983 | lr 3.00e-04 | grad 1.77 | tok/s 16141
step   1160 | loss 1.2126 | lr 3.00e-04 | grad 1.73 | tok/s 16125
step   1170 | loss 1.2433 | lr 3.00e-04 | grad 2.09 | tok/s 16118
step   1180 | loss 1.3426 | lr 3.00e-04 | grad 1.68 | tok/s 16112
step   1190 | loss 1.2186 | lr 3.00e-04 | grad 2.14 | tok/s 16123
step   1200 | loss 1.2149 | lr 3.00e-04 | grad 1.97 | tok/s 16127
step   1210 | loss 1.2690 | lr 3.00e-04 | grad 2.05 | tok/s 16126
step   1220 | loss 1.2896 | lr 3.00e-04 | grad 1.88 | tok/s 16145
step   1230 | loss 1.2581 | lr 3.00e-04 | grad 1.77 | tok/s 16143
step   1240 | loss 1.2214 | lr 3.00e-04 | grad 1.55 | tok/s 16123
step   1250 | loss 1.8050 | lr 3.00e-04 | grad 3.58 | tok/s 15286
step   1260 | loss 1.3897 | lr 3.00e-04 | grad 3.84 | tok/s 14272
step   1270 | loss 1.6716 | lr 3.00e-04 | grad 4.84 | tok/s 15207
step   1280 | loss 1.6256 | lr 3.00e-04 | grad 1.77 | tok/s 15631
step   1290 | loss 1.4853 | lr 3.00e-04 | grad 2.03 | tok/s 15530
step   1300 | loss 1.5227 | lr 3.00e-04 | grad 2.47 | tok/s 15646
step   1310 | loss 1.4650 | lr 3.00e-04 | grad 2.33 | tok/s 15901
step   1320 | loss 1.5927 | lr 3.00e-04 | grad 2.20 | tok/s 15948
step   1330 | loss 1.6088 | lr 3.00e-04 | grad 2.34 | tok/s 15968
step   1340 | loss 1.4833 | lr 3.00e-04 | grad 8.88 | tok/s 15211
step   1350 | loss 1.7339 | lr 3.00e-04 | grad 2.47 | tok/s 14708
step   1360 | loss 1.4962 | lr 3.00e-04 | grad 2.34 | tok/s 15631
step   1370 | loss 1.4139 | lr 3.00e-04 | grad 1.59 | tok/s 15429
step   1380 | loss 1.6770 | lr 3.00e-04 | grad 2.30 | tok/s 14843
step   1390 | loss 1.5293 | lr 3.00e-04 | grad 1.72 | tok/s 15764
step   1400 | loss 1.4108 | lr 3.00e-04 | grad 1.77 | tok/s 14525
step   1410 | loss 1.4648 | lr 3.00e-04 | grad 3.11 | tok/s 15146
step   1420 | loss 1.6933 | lr 3.00e-04 | grad 3.80 | tok/s 15177
step   1430 | loss 1.3442 | lr 3.00e-04 | grad 1.94 | tok/s 15438
step   1440 | loss 1.1512 | lr 3.00e-04 | grad 1.95 | tok/s 15954
step   1450 | loss 1.1661 | lr 3.00e-04 | grad 4.19 | tok/s 16058
step   1460 | loss 1.6845 | lr 3.00e-04 | grad 2.03 | tok/s 15154
step   1470 | loss 1.5219 | lr 3.00e-04 | grad 1.84 | tok/s 15689
step   1480 | loss 1.8262 | lr 3.00e-04 | grad 4.16 | tok/s 15801
step   1490 | loss 1.5641 | lr 3.00e-04 | grad 1.70 | tok/s 16043
step   1500 | loss 1.3486 | lr 3.00e-04 | grad 1.78 | tok/s 16104
step   1510 | loss 1.5253 | lr 3.00e-04 | grad 1.98 | tok/s 15881
step   1520 | loss 1.4274 | lr 3.00e-04 | grad 3.47 | tok/s 15577
step   1530 | loss 1.4461 | lr 3.00e-04 | grad 1.73 | tok/s 15951
step   1540 | loss 1.6243 | lr 3.00e-04 | grad 2.33 | tok/s 14478
step   1550 | loss 1.2919 | lr 3.00e-04 | grad 2.27 | tok/s 16018
step   1560 | loss 1.5901 | lr 3.00e-04 | grad 2.55 | tok/s 15192
step   1570 | loss 1.2851 | lr 3.00e-04 | grad 2.16 | tok/s 16128
step   1580 | loss 1.7389 | lr 3.00e-04 | grad 4.03 | tok/s 15756
step   1590 | loss 1.5936 | lr 3.00e-04 | grad 2.38 | tok/s 15156
step   1600 | loss 1.0062 | lr 3.00e-04 | grad 1.45 | tok/s 16183
step   1610 | loss 1.0305 | lr 3.00e-04 | grad 2.47 | tok/s 15626
step   1620 | loss 1.4134 | lr 3.00e-04 | grad 2.84 | tok/s 14677
step   1630 | loss 1.3503 | lr 3.00e-04 | grad 2.16 | tok/s 15729
step   1640 | loss 1.3380 | lr 3.00e-04 | grad 2.39 | tok/s 15330
step   1650 | loss 1.5411 | lr 3.00e-04 | grad 2.45 | tok/s 14691
step   1660 | loss 1.3918 | lr 3.00e-04 | grad 1.72 | tok/s 15696
step   1670 | loss 1.3636 | lr 3.00e-04 | grad 6.12 | tok/s 15652
step   1680 | loss 1.7335 | lr 3.00e-04 | grad 1.95 | tok/s 14467
step   1690 | loss 1.4997 | lr 3.00e-04 | grad 4.12 | tok/s 15308
step   1700 | loss 1.5116 | lr 3.00e-04 | grad 2.31 | tok/s 15644
step   1710 | loss 1.4326 | lr 3.00e-04 | grad 2.16 | tok/s 15337
step   1720 | loss 1.5322 | lr 3.00e-04 | grad 2.67 | tok/s 16001
step   1730 | loss 1.2414 | lr 3.00e-04 | grad 2.78 | tok/s 16146
step   1740 | loss 1.3409 | lr 3.00e-04 | grad 2.58 | tok/s 15741
step   1750 | loss 1.5839 | lr 3.00e-04 | grad 2.53 | tok/s 15486
step   1760 | loss 1.5460 | lr 3.00e-04 | grad 2.23 | tok/s 15505
step   1770 | loss 1.4438 | lr 3.00e-04 | grad 2.28 | tok/s 15235
step   1780 | loss 1.5162 | lr 3.00e-04 | grad 1.80 | tok/s 15869
step   1790 | loss 1.4050 | lr 3.00e-04 | grad 1.69 | tok/s 15446
step   1800 | loss 1.6259 | lr 3.00e-04 | grad 2.48 | tok/s 15563
step   1810 | loss 1.4526 | lr 3.00e-04 | grad 2.03 | tok/s 15013
step   1820 | loss 1.4808 | lr 3.00e-04 | grad 4.69 | tok/s 14613
step   1830 | loss 1.4242 | lr 3.00e-04 | grad 2.34 | tok/s 15864
step   1840 | loss 1.5432 | lr 3.00e-04 | grad 2.62 | tok/s 15210
step   1850 | loss 1.2901 | lr 3.00e-04 | grad 1.75 | tok/s 15929
step   1860 | loss 1.3300 | lr 3.00e-04 | grad 2.30 | tok/s 15399
step   1870 | loss 1.4203 | lr 3.00e-04 | grad 2.84 | tok/s 15467
step   1880 | loss 1.2394 | lr 3.00e-04 | grad 2.19 | tok/s 15115
step   1890 | loss 1.5192 | lr 3.00e-04 | grad 1.82 | tok/s 14378
step   1900 | loss 1.4009 | lr 3.00e-04 | grad 2.48 | tok/s 15548
step   1910 | loss 1.4812 | lr 3.00e-04 | grad 2.75 | tok/s 14747
step   1920 | loss 1.4008 | lr 3.00e-04 | grad 1.94 | tok/s 16141
step   1930 | loss 1.4656 | lr 3.00e-04 | grad 2.44 | tok/s 15166
step   1940 | loss 1.4466 | lr 3.00e-04 | grad 2.06 | tok/s 15746
step   1950 | loss 1.8553 | lr 3.00e-04 | grad 3.69 | tok/s 15989
step   1960 | loss 1.4462 | lr 3.00e-04 | grad 4.31 | tok/s 15534
step   1970 | loss 1.5320 | lr 3.00e-04 | grad 2.42 | tok/s 15766
step   1980 | loss 1.5530 | lr 3.00e-04 | grad 2.06 | tok/s 15073
step   1990 | loss 1.6114 | lr 3.00e-04 | grad 8.38 | tok/s 15362
step   2000 | loss 1.4983 | lr 3.00e-04 | grad 2.00 | tok/s 15582
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4983.pt
step   2010 | loss 1.0912 | lr 3.00e-04 | grad 1.65 | tok/s 7740
step   2020 | loss 1.3105 | lr 3.00e-04 | grad 2.09 | tok/s 15458
step   2030 | loss 1.0997 | lr 3.00e-04 | grad 0.90 | tok/s 16220
step   2040 | loss 1.2306 | lr 3.00e-04 | grad 2.11 | tok/s 16190
step   2050 | loss 1.1996 | lr 3.00e-04 | grad 2.20 | tok/s 15881
step   2060 | loss 1.5758 | lr 3.00e-04 | grad 2.17 | tok/s 14969
step   2070 | loss 1.6713 | lr 3.00e-04 | grad 2.28 | tok/s 15528
step   2080 | loss 2.2713 | lr 3.00e-04 | grad 4.16 | tok/s 16054
step   2090 | loss 1.7231 | lr 3.00e-04 | grad 4.44 | tok/s 16064
step   2100 | loss 1.3952 | lr 3.00e-04 | grad 2.61 | tok/s 15675
step   2110 | loss 1.5276 | lr 3.00e-04 | grad 21.50 | tok/s 15367
step   2120 | loss 0.9356 | lr 3.00e-04 | grad 1.67 | tok/s 15904
step   2130 | loss 1.0470 | lr 3.00e-04 | grad 3.12 | tok/s 15856
step   2140 | loss 1.5628 | lr 3.00e-04 | grad 1.80 | tok/s 15404
step   2150 | loss 1.2949 | lr 3.00e-04 | grad 1.97 | tok/s 16173
step   2160 | loss 1.1907 | lr 3.00e-04 | grad 1.63 | tok/s 16162
step   2170 | loss 1.2424 | lr 3.00e-04 | grad 1.56 | tok/s 16160
step   2180 | loss 1.1929 | lr 3.00e-04 | grad 1.88 | tok/s 16182
step   2190 | loss 1.2089 | lr 3.00e-04 | grad 1.61 | tok/s 16168
step   2200 | loss 1.1949 | lr 3.00e-04 | grad 1.70 | tok/s 16186
step   2210 | loss 1.1438 | lr 3.00e-04 | grad 1.55 | tok/s 16174
step   2220 | loss 1.1422 | lr 3.00e-04 | grad 1.56 | tok/s 16196
step   2230 | loss 1.3575 | lr 3.00e-04 | grad 1.98 | tok/s 15896
step   2240 | loss 1.3317 | lr 3.00e-04 | grad 1.77 | tok/s 16164
step   2250 | loss 1.5566 | lr 3.00e-04 | grad 3.11 | tok/s 15613
step   2260 | loss 1.6084 | lr 3.00e-04 | grad 2.11 | tok/s 15773
step   2270 | loss 1.9178 | lr 3.00e-04 | grad 2.91 | tok/s 16003
step   2280 | loss 1.4669 | lr 3.00e-04 | grad 2.38 | tok/s 15965

Training complete! Final step: 2287
