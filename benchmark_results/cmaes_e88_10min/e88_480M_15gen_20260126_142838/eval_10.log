Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_10/levelE88_100m_20260126_143906
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 492,277,544 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3889 | lr 3.00e-04 | grad 20.75 | tok/s 5985
step     20 | loss 2.6747 | lr 3.00e-04 | grad 10.50 | tok/s 14647
step     30 | loss 2.6011 | lr 3.00e-04 | grad 4.84 | tok/s 14828
step     40 | loss 2.3878 | lr 3.00e-04 | grad 3.97 | tok/s 14190
step     50 | loss 3.1468 | lr 3.00e-04 | grad 18.00 | tok/s 14404
step     60 | loss 2.1021 | lr 3.00e-04 | grad 4.47 | tok/s 14898
step     70 | loss 1.9179 | lr 3.00e-04 | grad 5.28 | tok/s 15073
step     80 | loss 5.8277 | lr 3.00e-04 | grad 152.00 | tok/s 15153
step     90 | loss 5.8422 | lr 3.00e-04 | grad 15.62 | tok/s 15399
step    100 | loss 4.8722 | lr 3.00e-04 | grad 15.62 | tok/s 15391
step    110 | loss 4.4068 | lr 3.00e-04 | grad 30.50 | tok/s 15354
step    120 | loss 3.9159 | lr 3.00e-04 | grad 27.50 | tok/s 15342
step    130 | loss 3.5764 | lr 3.00e-04 | grad 32.00 | tok/s 14268
step    140 | loss 2.9730 | lr 3.00e-04 | grad 17.12 | tok/s 15287
step    150 | loss 3.3155 | lr 3.00e-04 | grad 27.62 | tok/s 15276
step    160 | loss 2.5337 | lr 3.00e-04 | grad 21.38 | tok/s 15281
step    170 | loss 2.6372 | lr 3.00e-04 | grad 20.25 | tok/s 15280
step    180 | loss 2.4094 | lr 3.00e-04 | grad 6.69 | tok/s 15241
step    190 | loss 2.6320 | lr 3.00e-04 | grad 6.19 | tok/s 15220
step    200 | loss 2.2725 | lr 3.00e-04 | grad 12.94 | tok/s 15199
step    210 | loss 2.2550 | lr 3.00e-04 | grad 9.56 | tok/s 15192
step    220 | loss 2.2906 | lr 3.00e-04 | grad 3.05 | tok/s 14982
step    230 | loss 2.1173 | lr 3.00e-04 | grad 3.31 | tok/s 14809
step    240 | loss 2.2857 | lr 3.00e-04 | grad 4.62 | tok/s 14056
step    250 | loss 2.1178 | lr 3.00e-04 | grad 2.30 | tok/s 14448
step    260 | loss 1.5741 | lr 3.00e-04 | grad 2.64 | tok/s 14880
step    270 | loss 2.0994 | lr 3.00e-04 | grad 2.42 | tok/s 13839
step    280 | loss 2.2735 | lr 3.00e-04 | grad 4.62 | tok/s 14387
step    290 | loss 1.4755 | lr 3.00e-04 | grad 3.72 | tok/s 15136
step    300 | loss 0.6258 | lr 3.00e-04 | grad 9.44 | tok/s 15123
step    310 | loss 2.4110 | lr 3.00e-04 | grad 3.45 | tok/s 14882
step    320 | loss 1.9597 | lr 3.00e-04 | grad 5.34 | tok/s 14563
step    330 | loss 1.9721 | lr 3.00e-04 | grad 2.78 | tok/s 14064
step    340 | loss 2.3035 | lr 3.00e-04 | grad 2.64 | tok/s 14271
step    350 | loss 1.9162 | lr 3.00e-04 | grad 4.62 | tok/s 14628
step    360 | loss 1.2404 | lr 3.00e-04 | grad 6.41 | tok/s 14939
step    370 | loss 1.8258 | lr 3.00e-04 | grad 2.39 | tok/s 13539
step    380 | loss 1.8023 | lr 3.00e-04 | grad 2.33 | tok/s 14424
step    390 | loss 1.5616 | lr 3.00e-04 | grad 1.86 | tok/s 15043
step    400 | loss 1.5074 | lr 3.00e-04 | grad 2.31 | tok/s 14907
step    410 | loss 1.2955 | lr 3.00e-04 | grad 1.84 | tok/s 14553
step    420 | loss 1.8373 | lr 3.00e-04 | grad 4.03 | tok/s 13034
step    430 | loss 2.1839 | lr 3.00e-04 | grad 2.69 | tok/s 14817
step    440 | loss 2.1718 | lr 3.00e-04 | grad 3.86 | tok/s 13972
step    450 | loss 1.9275 | lr 3.00e-04 | grad 2.58 | tok/s 14467
step    460 | loss 1.7346 | lr 3.00e-04 | grad 2.45 | tok/s 14153
step    470 | loss 1.8624 | lr 3.00e-04 | grad 2.11 | tok/s 14633
step    480 | loss 2.2925 | lr 3.00e-04 | grad 6.47 | tok/s 14627
step    490 | loss 1.8085 | lr 3.00e-04 | grad 2.38 | tok/s 13798
step    500 | loss 1.7038 | lr 3.00e-04 | grad 3.05 | tok/s 14752
step    510 | loss 1.7255 | lr 3.00e-04 | grad 2.14 | tok/s 14944
step    520 | loss 1.6773 | lr 3.00e-04 | grad 1.88 | tok/s 14907
step    530 | loss 1.9285 | lr 3.00e-04 | grad 2.25 | tok/s 14324
step    540 | loss 1.7554 | lr 3.00e-04 | grad 1.98 | tok/s 14338
step    550 | loss 1.5832 | lr 3.00e-04 | grad 2.69 | tok/s 14037
step    560 | loss 1.7393 | lr 3.00e-04 | grad 2.30 | tok/s 13140
step    570 | loss 1.6866 | lr 3.00e-04 | grad 3.20 | tok/s 14041
step    580 | loss 1.5599 | lr 3.00e-04 | grad 1.91 | tok/s 13969
step    590 | loss 1.8894 | lr 3.00e-04 | grad 2.78 | tok/s 14347
step    600 | loss 1.8252 | lr 3.00e-04 | grad 2.06 | tok/s 13861
step    610 | loss 1.6333 | lr 3.00e-04 | grad 2.14 | tok/s 14568
step    620 | loss 1.5581 | lr 3.00e-04 | grad 2.22 | tok/s 13784
step    630 | loss 1.6711 | lr 3.00e-04 | grad 3.97 | tok/s 13925
step    640 | loss 1.8202 | lr 3.00e-04 | grad 2.23 | tok/s 14298
step    650 | loss 1.6861 | lr 3.00e-04 | grad 2.30 | tok/s 14351
step    660 | loss 1.7066 | lr 3.00e-04 | grad 1.88 | tok/s 14415
step    670 | loss 1.9528 | lr 3.00e-04 | grad 2.92 | tok/s 14509
step    680 | loss 1.7434 | lr 3.00e-04 | grad 2.22 | tok/s 14212
step    690 | loss 1.8483 | lr 3.00e-04 | grad 3.00 | tok/s 14730
step    700 | loss 1.4643 | lr 3.00e-04 | grad 2.86 | tok/s 14120
step    710 | loss 1.6060 | lr 3.00e-04 | grad 2.12 | tok/s 14006
step    720 | loss 1.4812 | lr 3.00e-04 | grad 3.08 | tok/s 13794
step    730 | loss 1.3062 | lr 3.00e-04 | grad 2.45 | tok/s 14963
step    740 | loss 1.5171 | lr 3.00e-04 | grad 2.17 | tok/s 14769
step    750 | loss 1.2245 | lr 3.00e-04 | grad 2.28 | tok/s 15009
step    760 | loss 1.1238 | lr 3.00e-04 | grad 1.98 | tok/s 15005
step    770 | loss 1.0769 | lr 3.00e-04 | grad 1.88 | tok/s 14994
step    780 | loss 1.0076 | lr 3.00e-04 | grad 1.88 | tok/s 15001
step    790 | loss 1.1416 | lr 3.00e-04 | grad 3.05 | tok/s 14531
step    800 | loss 1.8269 | lr 3.00e-04 | grad 5.09 | tok/s 14473
step    810 | loss 1.7180 | lr 3.00e-04 | grad 1.91 | tok/s 14417
step    820 | loss 1.7270 | lr 3.00e-04 | grad 3.61 | tok/s 13827
step    830 | loss 1.5041 | lr 3.00e-04 | grad 2.09 | tok/s 14840
step    840 | loss 1.3821 | lr 3.00e-04 | grad 2.08 | tok/s 15000
step    850 | loss 1.5910 | lr 3.00e-04 | grad 1.85 | tok/s 14156
step    860 | loss 1.4963 | lr 3.00e-04 | grad 3.19 | tok/s 14760
step    870 | loss 1.5127 | lr 3.00e-04 | grad 2.53 | tok/s 14222
step    880 | loss 1.6929 | lr 3.00e-04 | grad 2.34 | tok/s 14284
step    890 | loss 1.6946 | lr 3.00e-04 | grad 2.66 | tok/s 14466
step    900 | loss 1.5724 | lr 3.00e-04 | grad 2.33 | tok/s 14493
step    910 | loss 1.4417 | lr 3.00e-04 | grad 3.56 | tok/s 14187
step    920 | loss 1.5377 | lr 3.00e-04 | grad 3.42 | tok/s 14759
step    930 | loss 1.6144 | lr 3.00e-04 | grad 3.14 | tok/s 14085
step    940 | loss 1.4018 | lr 3.00e-04 | grad 1.70 | tok/s 14848
step    950 | loss 1.5046 | lr 3.00e-04 | grad 2.31 | tok/s 14911
step    960 | loss 1.3418 | lr 3.00e-04 | grad 2.30 | tok/s 14934
step    970 | loss 1.7564 | lr 3.00e-04 | grad 3.36 | tok/s 14043
step    980 | loss 1.6577 | lr 3.00e-04 | grad 2.25 | tok/s 14455
step    990 | loss 1.4599 | lr 3.00e-04 | grad 1.95 | tok/s 13968
step   1000 | loss 1.8459 | lr 3.00e-04 | grad 6.81 | tok/s 14082
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8459.pt
step   1010 | loss 1.6410 | lr 3.00e-04 | grad 3.12 | tok/s 6006
step   1020 | loss 1.6562 | lr 3.00e-04 | grad 1.78 | tok/s 13781
step   1030 | loss 1.4678 | lr 3.00e-04 | grad 1.87 | tok/s 14333
step   1040 | loss 1.4868 | lr 3.00e-04 | grad 2.06 | tok/s 14832
step   1050 | loss 1.6382 | lr 3.00e-04 | grad 3.02 | tok/s 13690
step   1060 | loss 1.7485 | lr 3.00e-04 | grad 3.22 | tok/s 14806
step   1070 | loss 1.6610 | lr 3.00e-04 | grad 2.52 | tok/s 14746
step   1080 | loss 1.4090 | lr 3.00e-04 | grad 1.80 | tok/s 13366
step   1090 | loss 1.1208 | lr 3.00e-04 | grad 1.10 | tok/s 14710
step   1100 | loss 1.4485 | lr 3.00e-04 | grad 3.08 | tok/s 14296
step   1110 | loss 1.4725 | lr 3.00e-04 | grad 1.84 | tok/s 15034
step   1120 | loss 1.3414 | lr 3.00e-04 | grad 1.89 | tok/s 15027
step   1130 | loss 1.2974 | lr 3.00e-04 | grad 1.77 | tok/s 14160
step   1140 | loss 1.2869 | lr 3.00e-04 | grad 1.89 | tok/s 14987
step   1150 | loss 1.3041 | lr 3.00e-04 | grad 1.62 | tok/s 14991
step   1160 | loss 1.2198 | lr 3.00e-04 | grad 1.64 | tok/s 15031
step   1170 | loss 1.2452 | lr 3.00e-04 | grad 1.96 | tok/s 14987
step   1180 | loss 1.3453 | lr 3.00e-04 | grad 1.55 | tok/s 14981
step   1190 | loss 1.2231 | lr 3.00e-04 | grad 1.99 | tok/s 14986
step   1200 | loss 1.2210 | lr 3.00e-04 | grad 1.86 | tok/s 14981
step   1210 | loss 1.2729 | lr 3.00e-04 | grad 1.86 | tok/s 14977
step   1220 | loss 1.2912 | lr 3.00e-04 | grad 1.77 | tok/s 14971
step   1230 | loss 1.2602 | lr 3.00e-04 | grad 1.62 | tok/s 14984
step   1240 | loss 1.2241 | lr 3.00e-04 | grad 1.47 | tok/s 14984
step   1250 | loss 1.8078 | lr 3.00e-04 | grad 3.45 | tok/s 14183
step   1260 | loss 1.4230 | lr 3.00e-04 | grad 6.16 | tok/s 13998
step   1270 | loss 1.6737 | lr 3.00e-04 | grad 4.59 | tok/s 13990
step   1280 | loss 1.6327 | lr 3.00e-04 | grad 1.71 | tok/s 13475
step   1290 | loss 1.4859 | lr 3.00e-04 | grad 1.89 | tok/s 14326
step   1300 | loss 1.5345 | lr 3.00e-04 | grad 2.36 | tok/s 14425
step   1310 | loss 1.4648 | lr 3.00e-04 | grad 2.16 | tok/s 14679
step   1320 | loss 1.5961 | lr 3.00e-04 | grad 2.08 | tok/s 14725
step   1330 | loss 1.6126 | lr 3.00e-04 | grad 2.19 | tok/s 14723
step   1340 | loss 1.5002 | lr 3.00e-04 | grad 8.94 | tok/s 14070
step   1350 | loss 1.7336 | lr 3.00e-04 | grad 2.23 | tok/s 13608
step   1360 | loss 1.4956 | lr 3.00e-04 | grad 2.17 | tok/s 14462
step   1370 | loss 1.4183 | lr 3.00e-04 | grad 1.48 | tok/s 14254
step   1380 | loss 1.6638 | lr 3.00e-04 | grad 2.22 | tok/s 13696
step   1390 | loss 1.5299 | lr 3.00e-04 | grad 1.64 | tok/s 14535
step   1400 | loss 1.4176 | lr 3.00e-04 | grad 1.64 | tok/s 14035
step   1410 | loss 1.4672 | lr 3.00e-04 | grad 2.92 | tok/s 14068
step   1420 | loss 1.6963 | lr 3.00e-04 | grad 3.52 | tok/s 13602
step   1430 | loss 1.3447 | lr 3.00e-04 | grad 1.83 | tok/s 14344
step   1440 | loss 1.1524 | lr 3.00e-04 | grad 1.70 | tok/s 14812
step   1450 | loss 1.1698 | lr 3.00e-04 | grad 3.94 | tok/s 14934
step   1460 | loss 1.6716 | lr 3.00e-04 | grad 1.92 | tok/s 14095
step   1470 | loss 1.5324 | lr 3.00e-04 | grad 1.76 | tok/s 14586
step   1480 | loss 1.8311 | lr 3.00e-04 | grad 3.73 | tok/s 14690
step   1490 | loss 1.5666 | lr 3.00e-04 | grad 1.63 | tok/s 14920
step   1500 | loss 1.3464 | lr 3.00e-04 | grad 1.66 | tok/s 14960
step   1510 | loss 1.5219 | lr 3.00e-04 | grad 1.83 | tok/s 14769
step   1520 | loss 1.4340 | lr 3.00e-04 | grad 3.14 | tok/s 14464
step   1530 | loss 1.4597 | lr 3.00e-04 | grad 1.58 | tok/s 14810
step   1540 | loss 1.6401 | lr 3.00e-04 | grad 2.23 | tok/s 13911
step   1550 | loss 1.2915 | lr 3.00e-04 | grad 2.17 | tok/s 14868
step   1560 | loss 1.5927 | lr 3.00e-04 | grad 2.38 | tok/s 13507
step   1570 | loss 1.2898 | lr 3.00e-04 | grad 2.05 | tok/s 14967
step   1580 | loss 1.7322 | lr 3.00e-04 | grad 3.89 | tok/s 14605
step   1590 | loss 1.6067 | lr 3.00e-04 | grad 2.25 | tok/s 14029
step   1600 | loss 1.0071 | lr 3.00e-04 | grad 1.43 | tok/s 14979
step   1610 | loss 1.0348 | lr 3.00e-04 | grad 2.31 | tok/s 14458
step   1620 | loss 1.4223 | lr 3.00e-04 | grad 2.84 | tok/s 13618
step   1630 | loss 1.3578 | lr 3.00e-04 | grad 2.05 | tok/s 14611
step   1640 | loss 1.3348 | lr 3.00e-04 | grad 2.22 | tok/s 14236
step   1650 | loss 1.5338 | lr 3.00e-04 | grad 2.33 | tok/s 13641
step   1660 | loss 1.3982 | lr 3.00e-04 | grad 1.65 | tok/s 14561
step   1670 | loss 1.3665 | lr 3.00e-04 | grad 5.59 | tok/s 14515
step   1680 | loss 1.7406 | lr 3.00e-04 | grad 1.85 | tok/s 13915
step   1690 | loss 1.4963 | lr 3.00e-04 | grad 3.78 | tok/s 14190
step   1700 | loss 1.5050 | lr 3.00e-04 | grad 2.20 | tok/s 13603
step   1710 | loss 1.4309 | lr 3.00e-04 | grad 2.08 | tok/s 14225
step   1720 | loss 1.5360 | lr 3.00e-04 | grad 2.72 | tok/s 14851
step   1730 | loss 1.2326 | lr 3.00e-04 | grad 2.67 | tok/s 14985
step   1740 | loss 1.3467 | lr 3.00e-04 | grad 2.52 | tok/s 14607
step   1750 | loss 1.5837 | lr 3.00e-04 | grad 2.33 | tok/s 14333
step   1760 | loss 1.5514 | lr 3.00e-04 | grad 2.14 | tok/s 14425
step   1770 | loss 1.4430 | lr 3.00e-04 | grad 2.14 | tok/s 14159
step   1780 | loss 1.5147 | lr 3.00e-04 | grad 1.68 | tok/s 14739
step   1790 | loss 1.4071 | lr 3.00e-04 | grad 1.56 | tok/s 14357
step   1800 | loss 1.6291 | lr 3.00e-04 | grad 2.47 | tok/s 14522
step   1810 | loss 1.4619 | lr 3.00e-04 | grad 1.92 | tok/s 13929
step   1820 | loss 1.4813 | lr 3.00e-04 | grad 4.50 | tok/s 14149
step   1830 | loss 1.4226 | lr 3.00e-04 | grad 2.19 | tok/s 14713
step   1840 | loss 1.5448 | lr 3.00e-04 | grad 2.47 | tok/s 14092
step   1850 | loss 1.3016 | lr 3.00e-04 | grad 1.62 | tok/s 14028
step   1860 | loss 1.3311 | lr 3.00e-04 | grad 2.09 | tok/s 14308
step   1870 | loss 1.4286 | lr 3.00e-04 | grad 2.86 | tok/s 14334
step   1880 | loss 1.2431 | lr 3.00e-04 | grad 2.09 | tok/s 14024
step   1890 | loss 1.5201 | lr 3.00e-04 | grad 1.73 | tok/s 13343
step   1900 | loss 1.4024 | lr 3.00e-04 | grad 2.28 | tok/s 14438
step   1910 | loss 1.4796 | lr 3.00e-04 | grad 2.66 | tok/s 13679
step   1920 | loss 1.4029 | lr 3.00e-04 | grad 1.80 | tok/s 14998
step   1930 | loss 1.4670 | lr 3.00e-04 | grad 2.36 | tok/s 14052
step   1940 | loss 1.4516 | lr 3.00e-04 | grad 1.87 | tok/s 14633
step   1950 | loss 1.8676 | lr 3.00e-04 | grad 3.09 | tok/s 14840
step   1960 | loss 1.4735 | lr 3.00e-04 | grad 3.91 | tok/s 15018
step   1970 | loss 1.5326 | lr 3.00e-04 | grad 2.36 | tok/s 14631
step   1980 | loss 1.5538 | lr 3.00e-04 | grad 1.94 | tok/s 13985
step   1990 | loss 1.6345 | lr 3.00e-04 | grad 11.31 | tok/s 13747
step   2000 | loss 1.4972 | lr 3.00e-04 | grad 1.88 | tok/s 14441
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4972.pt
step   2010 | loss 1.0790 | lr 3.00e-04 | grad 1.56 | tok/s 6429
step   2020 | loss 1.3130 | lr 3.00e-04 | grad 1.91 | tok/s 14379
step   2030 | loss 1.1012 | lr 3.00e-04 | grad 0.81 | tok/s 15119
step   2040 | loss 1.2397 | lr 3.00e-04 | grad 1.95 | tok/s 15042
step   2050 | loss 1.2040 | lr 3.00e-04 | grad 2.08 | tok/s 14738
step   2060 | loss 1.5740 | lr 3.00e-04 | grad 2.05 | tok/s 13900
step   2070 | loss 1.6745 | lr 3.00e-04 | grad 2.14 | tok/s 14415
step   2080 | loss 2.2699 | lr 3.00e-04 | grad 3.52 | tok/s 14908
step   2090 | loss 1.7120 | lr 3.00e-04 | grad 4.38 | tok/s 14948
step   2100 | loss 1.4008 | lr 3.00e-04 | grad 2.53 | tok/s 14558
step   2110 | loss 1.5398 | lr 3.00e-04 | grad 17.75 | tok/s 14293
step   2120 | loss 0.9261 | lr 3.00e-04 | grad 1.44 | tok/s 14744

Training complete! Final step: 2127
