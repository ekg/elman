Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_20/levelE88_100m_20260126_144923
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 492,277,544 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3817 | lr 3.00e-04 | grad 21.12 | tok/s 5890
step     20 | loss 2.6782 | lr 3.00e-04 | grad 8.50 | tok/s 14116
step     30 | loss 2.5478 | lr 3.00e-04 | grad 5.22 | tok/s 14269
step     40 | loss 2.3779 | lr 3.00e-04 | grad 4.31 | tok/s 13662
step     50 | loss 3.1492 | lr 3.00e-04 | grad 17.00 | tok/s 13877
step     60 | loss 2.1061 | lr 3.00e-04 | grad 4.69 | tok/s 14294
step     70 | loss 1.9230 | lr 3.00e-04 | grad 5.28 | tok/s 14463
step     80 | loss 5.7866 | lr 3.00e-04 | grad 136.00 | tok/s 14575
step     90 | loss 5.7748 | lr 3.00e-04 | grad 15.69 | tok/s 14823
step    100 | loss 4.8099 | lr 3.00e-04 | grad 16.62 | tok/s 14831
step    110 | loss 4.3513 | lr 3.00e-04 | grad 27.38 | tok/s 14825
step    120 | loss 3.8754 | lr 3.00e-04 | grad 24.50 | tok/s 14794
step    130 | loss 3.5157 | lr 3.00e-04 | grad 32.50 | tok/s 13858
step    140 | loss 2.9275 | lr 3.00e-04 | grad 19.50 | tok/s 14800
step    150 | loss 3.2708 | lr 3.00e-04 | grad 22.12 | tok/s 14828
step    160 | loss 2.5422 | lr 3.00e-04 | grad 20.88 | tok/s 14807
step    170 | loss 2.6274 | lr 3.00e-04 | grad 19.38 | tok/s 14747
step    180 | loss 2.3453 | lr 3.00e-04 | grad 7.12 | tok/s 14763
step    190 | loss 2.7383 | lr 3.00e-04 | grad 14.94 | tok/s 14734
step    200 | loss 2.2996 | lr 3.00e-04 | grad 12.69 | tok/s 14772
step    210 | loss 2.2564 | lr 3.00e-04 | grad 9.50 | tok/s 14741
step    220 | loss 2.2998 | lr 3.00e-04 | grad 3.08 | tok/s 14572
step    230 | loss 2.1499 | lr 3.00e-04 | grad 3.42 | tok/s 14423
step    240 | loss 2.2961 | lr 3.00e-04 | grad 4.50 | tok/s 13647
step    250 | loss 2.1151 | lr 3.00e-04 | grad 2.36 | tok/s 14049
step    260 | loss 1.5769 | lr 3.00e-04 | grad 2.81 | tok/s 14479
step    270 | loss 2.1224 | lr 3.00e-04 | grad 2.53 | tok/s 13695
step    280 | loss 2.2913 | lr 3.00e-04 | grad 5.50 | tok/s 14043
step    290 | loss 1.4668 | lr 3.00e-04 | grad 24.75 | tok/s 14767
step    300 | loss 0.6041 | lr 3.00e-04 | grad 2.38 | tok/s 14733
step    310 | loss 2.4148 | lr 3.00e-04 | grad 3.14 | tok/s 14501
step    320 | loss 1.9625 | lr 3.00e-04 | grad 5.38 | tok/s 14194
step    330 | loss 1.9660 | lr 3.00e-04 | grad 2.72 | tok/s 13722
step    340 | loss 2.3021 | lr 3.00e-04 | grad 2.73 | tok/s 13975
step    350 | loss 1.8975 | lr 3.00e-04 | grad 4.00 | tok/s 14280
step    360 | loss 1.2333 | lr 3.00e-04 | grad 6.50 | tok/s 14601
step    370 | loss 1.8312 | lr 3.00e-04 | grad 2.39 | tok/s 13274
step    380 | loss 1.7980 | lr 3.00e-04 | grad 2.30 | tok/s 14110
step    390 | loss 1.5575 | lr 3.00e-04 | grad 1.95 | tok/s 14708
step    400 | loss 1.5117 | lr 3.00e-04 | grad 2.34 | tok/s 14583
step    410 | loss 1.2968 | lr 3.00e-04 | grad 1.88 | tok/s 14250
step    420 | loss 1.8382 | lr 3.00e-04 | grad 4.00 | tok/s 13217
step    430 | loss 2.1825 | lr 3.00e-04 | grad 2.72 | tok/s 14515
step    440 | loss 2.1749 | lr 3.00e-04 | grad 3.88 | tok/s 13736
step    450 | loss 1.9176 | lr 3.00e-04 | grad 2.61 | tok/s 14205
step    460 | loss 1.7431 | lr 3.00e-04 | grad 2.48 | tok/s 13903
step    470 | loss 1.8510 | lr 3.00e-04 | grad 2.11 | tok/s 14346
step    480 | loss 2.2801 | lr 3.00e-04 | grad 6.28 | tok/s 14329
step    490 | loss 1.8049 | lr 3.00e-04 | grad 2.33 | tok/s 13521
step    500 | loss 1.7013 | lr 3.00e-04 | grad 3.02 | tok/s 14425
step    510 | loss 1.7297 | lr 3.00e-04 | grad 2.20 | tok/s 14644
step    520 | loss 1.6827 | lr 3.00e-04 | grad 1.91 | tok/s 14637
step    530 | loss 1.9346 | lr 3.00e-04 | grad 2.31 | tok/s 14092
step    540 | loss 1.7541 | lr 3.00e-04 | grad 2.02 | tok/s 14061
step    550 | loss 1.5823 | lr 3.00e-04 | grad 2.73 | tok/s 13755
step    560 | loss 1.7411 | lr 3.00e-04 | grad 2.33 | tok/s 12881
step    570 | loss 1.6825 | lr 3.00e-04 | grad 3.38 | tok/s 13754
step    580 | loss 1.5588 | lr 3.00e-04 | grad 1.97 | tok/s 13717
step    590 | loss 1.8783 | lr 3.00e-04 | grad 2.83 | tok/s 14076
step    600 | loss 1.8378 | lr 3.00e-04 | grad 2.11 | tok/s 13582
step    610 | loss 1.6399 | lr 3.00e-04 | grad 2.20 | tok/s 14289
step    620 | loss 1.5621 | lr 3.00e-04 | grad 2.25 | tok/s 13533
step    630 | loss 1.6811 | lr 3.00e-04 | grad 3.83 | tok/s 13657
step    640 | loss 1.8272 | lr 3.00e-04 | grad 2.28 | tok/s 14029
step    650 | loss 1.6845 | lr 3.00e-04 | grad 2.31 | tok/s 14139
step    660 | loss 1.7099 | lr 3.00e-04 | grad 1.93 | tok/s 14163
step    670 | loss 1.9494 | lr 3.00e-04 | grad 2.91 | tok/s 14243
step    680 | loss 1.7414 | lr 3.00e-04 | grad 2.22 | tok/s 13962
step    690 | loss 1.8524 | lr 3.00e-04 | grad 3.05 | tok/s 14439
step    700 | loss 1.4593 | lr 3.00e-04 | grad 2.89 | tok/s 14154
step    710 | loss 1.6009 | lr 3.00e-04 | grad 2.14 | tok/s 13776
step    720 | loss 1.4811 | lr 3.00e-04 | grad 3.23 | tok/s 13577
step    730 | loss 1.3059 | lr 3.00e-04 | grad 2.48 | tok/s 14709
step    740 | loss 1.5141 | lr 3.00e-04 | grad 2.16 | tok/s 14519
step    750 | loss 1.2238 | lr 3.00e-04 | grad 2.38 | tok/s 14718
step    760 | loss 1.1248 | lr 3.00e-04 | grad 2.05 | tok/s 14716
step    770 | loss 1.0749 | lr 3.00e-04 | grad 1.86 | tok/s 14728
step    780 | loss 1.0065 | lr 3.00e-04 | grad 2.00 | tok/s 14767
step    790 | loss 1.1432 | lr 3.00e-04 | grad 3.06 | tok/s 14289
step    800 | loss 1.8357 | lr 3.00e-04 | grad 5.12 | tok/s 14274
step    810 | loss 1.7177 | lr 3.00e-04 | grad 1.94 | tok/s 14156
step    820 | loss 1.7226 | lr 3.00e-04 | grad 3.59 | tok/s 13614
step    830 | loss 1.4988 | lr 3.00e-04 | grad 2.09 | tok/s 14603
step    840 | loss 1.3837 | lr 3.00e-04 | grad 2.06 | tok/s 14755
step    850 | loss 1.6140 | lr 3.00e-04 | grad 1.90 | tok/s 14244
step    860 | loss 1.4955 | lr 3.00e-04 | grad 3.25 | tok/s 14512
step    870 | loss 1.5164 | lr 3.00e-04 | grad 2.52 | tok/s 13961
step    880 | loss 1.6892 | lr 3.00e-04 | grad 2.47 | tok/s 14020
step    890 | loss 1.6952 | lr 3.00e-04 | grad 2.69 | tok/s 14227
step    900 | loss 1.5832 | lr 3.00e-04 | grad 2.36 | tok/s 14241
step    910 | loss 1.4350 | lr 3.00e-04 | grad 3.78 | tok/s 13922
step    920 | loss 1.5352 | lr 3.00e-04 | grad 3.28 | tok/s 14491
step    930 | loss 1.6112 | lr 3.00e-04 | grad 3.31 | tok/s 13862
step    940 | loss 1.4033 | lr 3.00e-04 | grad 1.75 | tok/s 14597
step    950 | loss 1.5113 | lr 3.00e-04 | grad 2.69 | tok/s 14661
step    960 | loss 1.3438 | lr 3.00e-04 | grad 2.33 | tok/s 14675
step    970 | loss 1.7551 | lr 3.00e-04 | grad 3.23 | tok/s 13813
step    980 | loss 1.6657 | lr 3.00e-04 | grad 2.19 | tok/s 14163
step    990 | loss 1.4616 | lr 3.00e-04 | grad 1.96 | tok/s 13858
step   1000 | loss 1.8537 | lr 3.00e-04 | grad 6.72 | tok/s 13835
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8537.pt
step   1010 | loss 1.6426 | lr 3.00e-04 | grad 3.06 | tok/s 6720
step   1020 | loss 1.6627 | lr 3.00e-04 | grad 1.82 | tok/s 13550
step   1030 | loss 1.4666 | lr 3.00e-04 | grad 1.91 | tok/s 14107
step   1040 | loss 1.4909 | lr 3.00e-04 | grad 2.06 | tok/s 14555
step   1050 | loss 1.6349 | lr 3.00e-04 | grad 3.02 | tok/s 13440
step   1060 | loss 1.7420 | lr 3.00e-04 | grad 3.12 | tok/s 14538
step   1070 | loss 1.6563 | lr 3.00e-04 | grad 2.48 | tok/s 14486
step   1080 | loss 1.4120 | lr 3.00e-04 | grad 1.80 | tok/s 13121
step   1090 | loss 1.1178 | lr 3.00e-04 | grad 1.19 | tok/s 14465
step   1100 | loss 1.4502 | lr 3.00e-04 | grad 3.08 | tok/s 14076
step   1110 | loss 1.4747 | lr 3.00e-04 | grad 1.91 | tok/s 14788
step   1120 | loss 1.3438 | lr 3.00e-04 | grad 1.88 | tok/s 14761
step   1130 | loss 1.2956 | lr 3.00e-04 | grad 1.76 | tok/s 14281
step   1140 | loss 1.2885 | lr 3.00e-04 | grad 1.97 | tok/s 14756
step   1150 | loss 1.3057 | lr 3.00e-04 | grad 1.63 | tok/s 14740
step   1160 | loss 1.2180 | lr 3.00e-04 | grad 1.65 | tok/s 14739
step   1170 | loss 1.2455 | lr 3.00e-04 | grad 1.95 | tok/s 14745
step   1180 | loss 1.3440 | lr 3.00e-04 | grad 1.55 | tok/s 14761
step   1190 | loss 1.2269 | lr 3.00e-04 | grad 2.03 | tok/s 14746
step   1200 | loss 1.2224 | lr 3.00e-04 | grad 1.88 | tok/s 14738
step   1210 | loss 1.2741 | lr 3.00e-04 | grad 1.88 | tok/s 14777
step   1220 | loss 1.2937 | lr 3.00e-04 | grad 1.77 | tok/s 14755
step   1230 | loss 1.2654 | lr 3.00e-04 | grad 1.63 | tok/s 14770
step   1240 | loss 1.2224 | lr 3.00e-04 | grad 1.48 | tok/s 14794
step   1250 | loss 1.8173 | lr 3.00e-04 | grad 3.36 | tok/s 13978
step   1260 | loss 1.4006 | lr 3.00e-04 | grad 2.42 | tok/s 13792
step   1270 | loss 1.6758 | lr 3.00e-04 | grad 4.66 | tok/s 13762
step   1280 | loss 1.6341 | lr 3.00e-04 | grad 1.73 | tok/s 13497
step   1290 | loss 1.4895 | lr 3.00e-04 | grad 1.90 | tok/s 14157
step   1300 | loss 1.5312 | lr 3.00e-04 | grad 2.34 | tok/s 14204
step   1310 | loss 1.4702 | lr 3.00e-04 | grad 2.22 | tok/s 14456
step   1320 | loss 1.5916 | lr 3.00e-04 | grad 2.08 | tok/s 14506
step   1330 | loss 1.6192 | lr 3.00e-04 | grad 2.14 | tok/s 14511
step   1340 | loss 1.4913 | lr 3.00e-04 | grad 8.75 | tok/s 13879
step   1350 | loss 1.7342 | lr 3.00e-04 | grad 2.27 | tok/s 13375
step   1360 | loss 1.5023 | lr 3.00e-04 | grad 2.17 | tok/s 14212
step   1370 | loss 1.4174 | lr 3.00e-04 | grad 1.52 | tok/s 14043
step   1380 | loss 1.6664 | lr 3.00e-04 | grad 2.22 | tok/s 13481
step   1390 | loss 1.5260 | lr 3.00e-04 | grad 1.59 | tok/s 14312
step   1400 | loss 1.4127 | lr 3.00e-04 | grad 1.66 | tok/s 13818
step   1410 | loss 1.4735 | lr 3.00e-04 | grad 2.86 | tok/s 13865
step   1420 | loss 1.6817 | lr 3.00e-04 | grad 3.58 | tok/s 13429
step   1430 | loss 1.3462 | lr 3.00e-04 | grad 1.85 | tok/s 14186
step   1440 | loss 1.1537 | lr 3.00e-04 | grad 1.71 | tok/s 14598
step   1450 | loss 1.1732 | lr 3.00e-04 | grad 4.16 | tok/s 14683
step   1460 | loss 1.6703 | lr 3.00e-04 | grad 1.95 | tok/s 13894
step   1470 | loss 1.5301 | lr 3.00e-04 | grad 1.77 | tok/s 14376
step   1480 | loss 1.8240 | lr 3.00e-04 | grad 3.73 | tok/s 14499
step   1490 | loss 1.5658 | lr 3.00e-04 | grad 1.61 | tok/s 14681
step   1500 | loss 1.3599 | lr 3.00e-04 | grad 1.65 | tok/s 14737
step   1510 | loss 1.5263 | lr 3.00e-04 | grad 1.81 | tok/s 14585
step   1520 | loss 1.4372 | lr 3.00e-04 | grad 3.11 | tok/s 14249
step   1530 | loss 1.4565 | lr 3.00e-04 | grad 1.62 | tok/s 14597
step   1540 | loss 1.6379 | lr 3.00e-04 | grad 2.25 | tok/s 13707
step   1550 | loss 1.2954 | lr 3.00e-04 | grad 2.16 | tok/s 14645
step   1560 | loss 1.5900 | lr 3.00e-04 | grad 2.42 | tok/s 13540
step   1570 | loss 1.2870 | lr 3.00e-04 | grad 2.09 | tok/s 14735
step   1580 | loss 1.7252 | lr 3.00e-04 | grad 3.86 | tok/s 14397
step   1590 | loss 1.5992 | lr 3.00e-04 | grad 2.23 | tok/s 13827
step   1600 | loss 1.0081 | lr 3.00e-04 | grad 1.49 | tok/s 14737
step   1610 | loss 1.0347 | lr 3.00e-04 | grad 2.30 | tok/s 14269
step   1620 | loss 1.4229 | lr 3.00e-04 | grad 2.77 | tok/s 13395
step   1630 | loss 1.3605 | lr 3.00e-04 | grad 1.98 | tok/s 14326
step   1640 | loss 1.3352 | lr 3.00e-04 | grad 2.16 | tok/s 13995
step   1650 | loss 1.5340 | lr 3.00e-04 | grad 2.39 | tok/s 13418
step   1660 | loss 1.3972 | lr 3.00e-04 | grad 1.67 | tok/s 14316
step   1670 | loss 1.3549 | lr 3.00e-04 | grad 5.16 | tok/s 14273
step   1680 | loss 1.7379 | lr 3.00e-04 | grad 1.83 | tok/s 13678
step   1690 | loss 1.4993 | lr 3.00e-04 | grad 3.91 | tok/s 13940
step   1700 | loss 1.5169 | lr 3.00e-04 | grad 2.19 | tok/s 13753
step   1710 | loss 1.4311 | lr 3.00e-04 | grad 2.09 | tok/s 13976
step   1720 | loss 1.5319 | lr 3.00e-04 | grad 2.67 | tok/s 14569
step   1730 | loss 1.2382 | lr 3.00e-04 | grad 2.70 | tok/s 14759
step   1740 | loss 1.3437 | lr 3.00e-04 | grad 2.50 | tok/s 14353
step   1750 | loss 1.5842 | lr 3.00e-04 | grad 2.34 | tok/s 14098
step   1760 | loss 1.5478 | lr 3.00e-04 | grad 2.27 | tok/s 14150
step   1770 | loss 1.4464 | lr 3.00e-04 | grad 2.16 | tok/s 13927
step   1780 | loss 1.5190 | lr 3.00e-04 | grad 1.71 | tok/s 14465
step   1790 | loss 1.4073 | lr 3.00e-04 | grad 1.56 | tok/s 14089
step   1800 | loss 1.6315 | lr 3.00e-04 | grad 2.58 | tok/s 14203
step   1810 | loss 1.4730 | lr 3.00e-04 | grad 1.93 | tok/s 13727
step   1820 | loss 1.4829 | lr 3.00e-04 | grad 4.53 | tok/s 13893
step   1830 | loss 1.4201 | lr 3.00e-04 | grad 2.17 | tok/s 14459
step   1840 | loss 1.5483 | lr 3.00e-04 | grad 2.53 | tok/s 13838
step   1850 | loss 1.3019 | lr 3.00e-04 | grad 1.65 | tok/s 14022
step   1860 | loss 1.3320 | lr 3.00e-04 | grad 2.09 | tok/s 14036
step   1870 | loss 1.4270 | lr 3.00e-04 | grad 2.86 | tok/s 14061
step   1880 | loss 1.2450 | lr 3.00e-04 | grad 2.08 | tok/s 13775
step   1890 | loss 1.5181 | lr 3.00e-04 | grad 1.73 | tok/s 13119
step   1900 | loss 1.4053 | lr 3.00e-04 | grad 2.31 | tok/s 14189
step   1910 | loss 1.4789 | lr 3.00e-04 | grad 2.64 | tok/s 13427
step   1920 | loss 1.4062 | lr 3.00e-04 | grad 1.83 | tok/s 14711
step   1930 | loss 1.4669 | lr 3.00e-04 | grad 2.38 | tok/s 13819
step   1940 | loss 1.4501 | lr 3.00e-04 | grad 1.90 | tok/s 14361
step   1950 | loss 1.8622 | lr 3.00e-04 | grad 3.05 | tok/s 14570
step   1960 | loss 1.4725 | lr 3.00e-04 | grad 3.84 | tok/s 14736
step   1970 | loss 1.5303 | lr 3.00e-04 | grad 2.36 | tok/s 14356
step   1980 | loss 1.5610 | lr 3.00e-04 | grad 1.98 | tok/s 13720
step   1990 | loss 1.6458 | lr 3.00e-04 | grad 12.62 | tok/s 13459
step   2000 | loss 1.4981 | lr 3.00e-04 | grad 1.88 | tok/s 14180
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4981.pt
step   2010 | loss 1.0856 | lr 3.00e-04 | grad 1.59 | tok/s 7369
step   2020 | loss 1.3118 | lr 3.00e-04 | grad 1.95 | tok/s 14059
step   2030 | loss 1.1019 | lr 3.00e-04 | grad 0.85 | tok/s 14805
step   2040 | loss 1.2421 | lr 3.00e-04 | grad 1.98 | tok/s 14779
step   2050 | loss 1.2046 | lr 3.00e-04 | grad 2.09 | tok/s 14474
step   2060 | loss 1.5701 | lr 3.00e-04 | grad 2.08 | tok/s 13662
step   2070 | loss 1.6744 | lr 3.00e-04 | grad 2.12 | tok/s 14183
step   2080 | loss 2.2620 | lr 3.00e-04 | grad 3.81 | tok/s 14647
step   2090 | loss 1.7097 | lr 3.00e-04 | grad 4.03 | tok/s 14694

Training complete! Final step: 2094
