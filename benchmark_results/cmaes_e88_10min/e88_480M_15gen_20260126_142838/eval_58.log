Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_58/levelE88_100m_20260126_154048
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,604,984 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1570 | lr 3.00e-04 | grad 22.12 | tok/s 6031
step     20 | loss 2.7567 | lr 3.00e-04 | grad 10.94 | tok/s 15557
step     30 | loss 2.6135 | lr 3.00e-04 | grad 6.34 | tok/s 15753
step     40 | loss 2.4522 | lr 3.00e-04 | grad 4.88 | tok/s 15117
step     50 | loss 3.0730 | lr 3.00e-04 | grad 12.81 | tok/s 15298
step     60 | loss 2.0883 | lr 3.00e-04 | grad 4.38 | tok/s 15816
step     70 | loss 1.9206 | lr 3.00e-04 | grad 5.66 | tok/s 16029
step     80 | loss 6.3281 | lr 3.00e-04 | grad 117.00 | tok/s 16123
step     90 | loss 6.1327 | lr 3.00e-04 | grad 13.25 | tok/s 16385
step    100 | loss 4.7611 | lr 3.00e-04 | grad 15.25 | tok/s 16365
step    110 | loss 4.2363 | lr 3.00e-04 | grad 32.50 | tok/s 16400
step    120 | loss 3.6437 | lr 3.00e-04 | grad 22.75 | tok/s 16336
step    130 | loss 3.2690 | lr 3.00e-04 | grad 24.75 | tok/s 16323
step    140 | loss 2.7921 | lr 3.00e-04 | grad 14.00 | tok/s 16313
step    150 | loss 3.0544 | lr 3.00e-04 | grad 21.75 | tok/s 16324
step    160 | loss 2.4275 | lr 3.00e-04 | grad 14.38 | tok/s 16307
step    170 | loss 2.5146 | lr 3.00e-04 | grad 17.12 | tok/s 16366
step    180 | loss 2.3476 | lr 3.00e-04 | grad 6.78 | tok/s 16318
step    190 | loss 2.5380 | lr 3.00e-04 | grad 9.19 | tok/s 16297
step    200 | loss 2.2093 | lr 3.00e-04 | grad 9.88 | tok/s 16299
step    210 | loss 2.1954 | lr 3.00e-04 | grad 7.69 | tok/s 16292
step    220 | loss 2.2648 | lr 3.00e-04 | grad 3.66 | tok/s 16097
step    230 | loss 2.0864 | lr 3.00e-04 | grad 4.19 | tok/s 15897
step    240 | loss 2.3079 | lr 3.00e-04 | grad 4.88 | tok/s 15107
step    250 | loss 2.1338 | lr 3.00e-04 | grad 2.67 | tok/s 15515
step    260 | loss 1.5755 | lr 3.00e-04 | grad 2.95 | tok/s 16017
step    270 | loss 2.1141 | lr 3.00e-04 | grad 2.83 | tok/s 15788
step    280 | loss 2.2811 | lr 3.00e-04 | grad 5.28 | tok/s 15509
step    290 | loss 1.4472 | lr 3.00e-04 | grad 3.59 | tok/s 16315
step    300 | loss 0.5969 | lr 3.00e-04 | grad 3.02 | tok/s 16312
step    310 | loss 2.4158 | lr 3.00e-04 | grad 3.86 | tok/s 16020
step    320 | loss 1.9586 | lr 3.00e-04 | grad 5.94 | tok/s 15714
step    330 | loss 1.9666 | lr 3.00e-04 | grad 2.98 | tok/s 15155
step    340 | loss 2.3032 | lr 3.00e-04 | grad 2.84 | tok/s 15384
step    350 | loss 1.8927 | lr 3.00e-04 | grad 5.47 | tok/s 15804
step    360 | loss 1.2351 | lr 3.00e-04 | grad 7.44 | tok/s 16132
step    370 | loss 1.8193 | lr 3.00e-04 | grad 2.58 | tok/s 14638
step    380 | loss 1.7815 | lr 3.00e-04 | grad 2.62 | tok/s 14510
step    390 | loss 1.5525 | lr 3.00e-04 | grad 2.09 | tok/s 16281
step    400 | loss 1.5065 | lr 3.00e-04 | grad 2.59 | tok/s 16165
step    410 | loss 1.2880 | lr 3.00e-04 | grad 2.05 | tok/s 15783
step    420 | loss 1.8373 | lr 3.00e-04 | grad 4.41 | tok/s 15082
step    430 | loss 2.1772 | lr 3.00e-04 | grad 3.03 | tok/s 16051
step    440 | loss 2.1643 | lr 3.00e-04 | grad 4.09 | tok/s 15158
step    450 | loss 1.9593 | lr 3.00e-04 | grad 2.75 | tok/s 15669
step    460 | loss 1.7276 | lr 3.00e-04 | grad 2.92 | tok/s 15363
step    470 | loss 1.8423 | lr 3.00e-04 | grad 2.44 | tok/s 15798
step    480 | loss 2.2802 | lr 3.00e-04 | grad 6.75 | tok/s 15831
step    490 | loss 1.8070 | lr 3.00e-04 | grad 2.52 | tok/s 14956
step    500 | loss 1.6927 | lr 3.00e-04 | grad 3.36 | tok/s 15980
step    510 | loss 1.7235 | lr 3.00e-04 | grad 2.41 | tok/s 16182
step    520 | loss 1.6753 | lr 3.00e-04 | grad 2.09 | tok/s 15233
step    530 | loss 1.9284 | lr 3.00e-04 | grad 2.44 | tok/s 15538
step    540 | loss 1.7513 | lr 3.00e-04 | grad 2.25 | tok/s 15540
step    550 | loss 1.5828 | lr 3.00e-04 | grad 2.92 | tok/s 15227
step    560 | loss 1.7419 | lr 3.00e-04 | grad 2.58 | tok/s 14815
step    570 | loss 1.6849 | lr 3.00e-04 | grad 3.59 | tok/s 15222
step    580 | loss 1.5556 | lr 3.00e-04 | grad 2.14 | tok/s 15154
step    590 | loss 1.8818 | lr 3.00e-04 | grad 3.06 | tok/s 15557
step    600 | loss 1.8313 | lr 3.00e-04 | grad 2.30 | tok/s 15024
step    610 | loss 1.6339 | lr 3.00e-04 | grad 2.47 | tok/s 15801
step    620 | loss 1.5600 | lr 3.00e-04 | grad 2.42 | tok/s 14982
step    630 | loss 1.6679 | lr 3.00e-04 | grad 4.34 | tok/s 15090
step    640 | loss 1.8139 | lr 3.00e-04 | grad 2.44 | tok/s 15501
step    650 | loss 1.6851 | lr 3.00e-04 | grad 2.56 | tok/s 15576
step    660 | loss 1.7120 | lr 3.00e-04 | grad 2.00 | tok/s 15644
step    670 | loss 1.9446 | lr 3.00e-04 | grad 3.14 | tok/s 15740
step    680 | loss 1.7384 | lr 3.00e-04 | grad 2.41 | tok/s 15432
step    690 | loss 1.8547 | lr 3.00e-04 | grad 3.41 | tok/s 15963
step    700 | loss 1.4458 | lr 3.00e-04 | grad 3.02 | tok/s 16282
step    710 | loss 1.5976 | lr 3.00e-04 | grad 2.33 | tok/s 14461
step    720 | loss 1.4837 | lr 3.00e-04 | grad 3.72 | tok/s 14974
step    730 | loss 1.2999 | lr 3.00e-04 | grad 2.70 | tok/s 16242
step    740 | loss 1.5144 | lr 3.00e-04 | grad 2.36 | tok/s 16031
step    750 | loss 1.2131 | lr 3.00e-04 | grad 2.45 | tok/s 16289
step    760 | loss 1.1200 | lr 3.00e-04 | grad 2.28 | tok/s 16272
step    770 | loss 1.0711 | lr 3.00e-04 | grad 2.09 | tok/s 16284
step    780 | loss 1.0031 | lr 3.00e-04 | grad 2.16 | tok/s 16284
step    790 | loss 1.1391 | lr 3.00e-04 | grad 3.23 | tok/s 15768
step    800 | loss 1.8300 | lr 3.00e-04 | grad 5.38 | tok/s 15715
step    810 | loss 1.7118 | lr 3.00e-04 | grad 2.11 | tok/s 15644
step    820 | loss 1.7227 | lr 3.00e-04 | grad 3.88 | tok/s 14997
step    830 | loss 1.5027 | lr 3.00e-04 | grad 2.30 | tok/s 16111
step    840 | loss 1.3718 | lr 3.00e-04 | grad 2.19 | tok/s 16279
step    850 | loss 1.5977 | lr 3.00e-04 | grad 2.02 | tok/s 16179
step    860 | loss 1.4872 | lr 3.00e-04 | grad 3.47 | tok/s 16010
step    870 | loss 1.5165 | lr 3.00e-04 | grad 2.64 | tok/s 15444
step    880 | loss 1.6971 | lr 3.00e-04 | grad 2.64 | tok/s 15486
step    890 | loss 1.6970 | lr 3.00e-04 | grad 2.97 | tok/s 14956
step    900 | loss 1.5804 | lr 3.00e-04 | grad 2.53 | tok/s 15788
step    910 | loss 1.4382 | lr 3.00e-04 | grad 3.97 | tok/s 15460
step    920 | loss 1.5443 | lr 3.00e-04 | grad 3.77 | tok/s 16057
step    930 | loss 1.6152 | lr 3.00e-04 | grad 3.70 | tok/s 15331
step    940 | loss 1.3996 | lr 3.00e-04 | grad 1.88 | tok/s 16164
step    950 | loss 1.5088 | lr 3.00e-04 | grad 2.78 | tok/s 16239
step    960 | loss 1.3361 | lr 3.00e-04 | grad 2.48 | tok/s 16247
step    970 | loss 1.7588 | lr 3.00e-04 | grad 3.56 | tok/s 15293
step    980 | loss 1.6609 | lr 3.00e-04 | grad 2.38 | tok/s 15693
step    990 | loss 1.4621 | lr 3.00e-04 | grad 2.14 | tok/s 15957
step   1000 | loss 1.8629 | lr 3.00e-04 | grad 8.12 | tok/s 15317
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8629.pt
step   1010 | loss 1.6543 | lr 3.00e-04 | grad 3.41 | tok/s 6360
step   1020 | loss 1.6628 | lr 3.00e-04 | grad 1.95 | tok/s 14978
step   1030 | loss 1.4673 | lr 3.00e-04 | grad 2.09 | tok/s 15538
step   1040 | loss 1.4925 | lr 3.00e-04 | grad 2.31 | tok/s 16058
step   1050 | loss 1.6358 | lr 3.00e-04 | grad 3.28 | tok/s 14854
step   1060 | loss 1.7443 | lr 3.00e-04 | grad 3.38 | tok/s 16026
step   1070 | loss 1.6500 | lr 3.00e-04 | grad 2.62 | tok/s 15970
step   1080 | loss 1.4074 | lr 3.00e-04 | grad 1.94 | tok/s 14494
step   1090 | loss 1.1267 | lr 3.00e-04 | grad 1.25 | tok/s 16006
step   1100 | loss 1.4570 | lr 3.00e-04 | grad 3.33 | tok/s 14748
step   1110 | loss 1.4737 | lr 3.00e-04 | grad 2.08 | tok/s 16295
step   1120 | loss 1.3435 | lr 3.00e-04 | grad 2.08 | tok/s 16304
step   1130 | loss 1.2993 | lr 3.00e-04 | grad 1.94 | tok/s 16283
step   1140 | loss 1.2883 | lr 3.00e-04 | grad 2.11 | tok/s 16303
step   1150 | loss 1.3020 | lr 3.00e-04 | grad 1.84 | tok/s 16274
step   1160 | loss 1.2164 | lr 3.00e-04 | grad 1.83 | tok/s 16262
step   1170 | loss 1.2446 | lr 3.00e-04 | grad 2.14 | tok/s 16292
step   1180 | loss 1.3447 | lr 3.00e-04 | grad 1.70 | tok/s 16266
step   1190 | loss 1.2242 | lr 3.00e-04 | grad 2.23 | tok/s 16267
step   1200 | loss 1.2203 | lr 3.00e-04 | grad 2.05 | tok/s 16299
step   1210 | loss 1.2729 | lr 3.00e-04 | grad 2.12 | tok/s 16275
step   1220 | loss 1.2939 | lr 3.00e-04 | grad 1.94 | tok/s 16296
step   1230 | loss 1.2616 | lr 3.00e-04 | grad 1.82 | tok/s 16306
step   1240 | loss 1.2250 | lr 3.00e-04 | grad 1.59 | tok/s 16299
step   1250 | loss 1.8098 | lr 3.00e-04 | grad 3.59 | tok/s 15437
step   1260 | loss 1.4061 | lr 3.00e-04 | grad 3.12 | tok/s 15268
step   1270 | loss 1.6715 | lr 3.00e-04 | grad 4.94 | tok/s 15224
step   1280 | loss 1.6392 | lr 3.00e-04 | grad 1.86 | tok/s 15682
step   1290 | loss 1.4875 | lr 3.00e-04 | grad 2.11 | tok/s 15554
step   1300 | loss 1.5290 | lr 3.00e-04 | grad 2.52 | tok/s 15675
step   1310 | loss 1.4675 | lr 3.00e-04 | grad 2.34 | tok/s 15934
step   1320 | loss 1.5972 | lr 3.00e-04 | grad 2.28 | tok/s 15997
step   1330 | loss 1.6270 | lr 3.00e-04 | grad 2.42 | tok/s 16020
step   1340 | loss 1.4878 | lr 3.00e-04 | grad 8.94 | tok/s 15273
step   1350 | loss 1.7375 | lr 3.00e-04 | grad 2.45 | tok/s 14758
step   1360 | loss 1.4981 | lr 3.00e-04 | grad 2.41 | tok/s 15682
step   1370 | loss 1.4192 | lr 3.00e-04 | grad 1.66 | tok/s 15486
step   1380 | loss 1.6750 | lr 3.00e-04 | grad 2.33 | tok/s 14880
step   1390 | loss 1.5320 | lr 3.00e-04 | grad 1.74 | tok/s 15791
step   1400 | loss 1.4158 | lr 3.00e-04 | grad 1.75 | tok/s 15245
step   1410 | loss 1.4671 | lr 3.00e-04 | grad 3.06 | tok/s 15277
step   1420 | loss 1.6980 | lr 3.00e-04 | grad 3.91 | tok/s 15323
step   1430 | loss 1.3528 | lr 3.00e-04 | grad 1.98 | tok/s 15607
step   1440 | loss 1.1566 | lr 3.00e-04 | grad 1.98 | tok/s 16097
step   1450 | loss 1.1737 | lr 3.00e-04 | grad 4.53 | tok/s 16216
step   1460 | loss 1.6827 | lr 3.00e-04 | grad 2.09 | tok/s 15292
step   1470 | loss 1.5316 | lr 3.00e-04 | grad 1.92 | tok/s 15854
step   1480 | loss 1.8307 | lr 3.00e-04 | grad 4.16 | tok/s 15941
step   1490 | loss 1.5753 | lr 3.00e-04 | grad 1.78 | tok/s 16192
step   1500 | loss 1.3469 | lr 3.00e-04 | grad 1.87 | tok/s 16264
step   1510 | loss 1.5225 | lr 3.00e-04 | grad 1.99 | tok/s 16054
step   1520 | loss 1.4371 | lr 3.00e-04 | grad 3.44 | tok/s 15706
step   1530 | loss 1.4612 | lr 3.00e-04 | grad 1.79 | tok/s 15249
step   1540 | loss 1.6312 | lr 3.00e-04 | grad 2.41 | tok/s 15166
step   1550 | loss 1.2991 | lr 3.00e-04 | grad 2.39 | tok/s 16184
step   1560 | loss 1.5930 | lr 3.00e-04 | grad 2.66 | tok/s 15350
step   1570 | loss 1.2956 | lr 3.00e-04 | grad 2.25 | tok/s 16305
step   1580 | loss 1.7320 | lr 3.00e-04 | grad 4.16 | tok/s 15923
step   1590 | loss 1.6069 | lr 3.00e-04 | grad 2.41 | tok/s 15306
step   1600 | loss 1.0086 | lr 3.00e-04 | grad 1.56 | tok/s 16345
step   1610 | loss 1.0349 | lr 3.00e-04 | grad 2.50 | tok/s 15797
step   1620 | loss 1.4237 | lr 3.00e-04 | grad 2.92 | tok/s 14822
step   1630 | loss 1.3613 | lr 3.00e-04 | grad 2.44 | tok/s 15865
step   1640 | loss 1.3427 | lr 3.00e-04 | grad 2.38 | tok/s 15495
step   1650 | loss 1.5478 | lr 3.00e-04 | grad 2.50 | tok/s 14845
step   1660 | loss 1.3987 | lr 3.00e-04 | grad 1.77 | tok/s 15849
step   1670 | loss 1.3696 | lr 3.00e-04 | grad 6.31 | tok/s 14862
step   1680 | loss 1.7436 | lr 3.00e-04 | grad 1.99 | tok/s 15128
step   1690 | loss 1.5069 | lr 3.00e-04 | grad 4.19 | tok/s 15400
step   1700 | loss 1.5217 | lr 3.00e-04 | grad 2.33 | tok/s 15769
step   1710 | loss 1.4392 | lr 3.00e-04 | grad 2.25 | tok/s 15455
step   1720 | loss 1.5369 | lr 3.00e-04 | grad 2.94 | tok/s 16129
step   1730 | loss 1.2442 | lr 3.00e-04 | grad 2.78 | tok/s 16290
step   1740 | loss 1.3398 | lr 3.00e-04 | grad 2.64 | tok/s 15895
step   1750 | loss 1.5871 | lr 3.00e-04 | grad 2.50 | tok/s 15590
step   1760 | loss 1.5562 | lr 3.00e-04 | grad 2.36 | tok/s 15684
step   1770 | loss 1.4480 | lr 3.00e-04 | grad 2.42 | tok/s 15400
step   1780 | loss 1.5195 | lr 3.00e-04 | grad 1.85 | tok/s 15993
step   1790 | loss 1.4080 | lr 3.00e-04 | grad 1.75 | tok/s 15585
step   1800 | loss 1.6315 | lr 3.00e-04 | grad 2.55 | tok/s 15699
step   1810 | loss 1.4596 | lr 3.00e-04 | grad 2.05 | tok/s 15136
step   1820 | loss 1.4955 | lr 3.00e-04 | grad 5.00 | tok/s 15330
step   1830 | loss 1.4344 | lr 3.00e-04 | grad 2.39 | tok/s 15977
step   1840 | loss 1.5478 | lr 3.00e-04 | grad 2.67 | tok/s 15316
step   1850 | loss 1.3022 | lr 3.00e-04 | grad 1.78 | tok/s 15200
step   1860 | loss 1.3335 | lr 3.00e-04 | grad 2.33 | tok/s 15452
step   1870 | loss 1.4282 | lr 3.00e-04 | grad 2.97 | tok/s 15512
step   1880 | loss 1.2441 | lr 3.00e-04 | grad 2.28 | tok/s 15228
step   1890 | loss 1.5270 | lr 3.00e-04 | grad 1.91 | tok/s 14473
step   1900 | loss 1.4052 | lr 3.00e-04 | grad 2.55 | tok/s 15661
step   1910 | loss 1.4818 | lr 3.00e-04 | grad 2.80 | tok/s 14815
step   1920 | loss 1.4053 | lr 3.00e-04 | grad 2.06 | tok/s 16231
step   1930 | loss 1.4668 | lr 3.00e-04 | grad 2.53 | tok/s 15229
step   1940 | loss 1.4548 | lr 3.00e-04 | grad 2.06 | tok/s 15837
step   1950 | loss 1.8713 | lr 3.00e-04 | grad 3.62 | tok/s 16071
step   1960 | loss 1.4606 | lr 3.00e-04 | grad 4.25 | tok/s 16238
step   1970 | loss 1.5430 | lr 3.00e-04 | grad 2.50 | tok/s 15846
step   1980 | loss 1.5564 | lr 3.00e-04 | grad 2.12 | tok/s 15162
step   1990 | loss 1.6234 | lr 3.00e-04 | grad 9.50 | tok/s 15451
step   2000 | loss 1.5026 | lr 3.00e-04 | grad 2.12 | tok/s 15656
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5026.pt
step   2010 | loss 1.0871 | lr 3.00e-04 | grad 1.70 | tok/s 6979
step   2020 | loss 1.3124 | lr 3.00e-04 | grad 2.16 | tok/s 15559
step   2030 | loss 1.1048 | lr 3.00e-04 | grad 0.89 | tok/s 15498
step   2040 | loss 1.2386 | lr 3.00e-04 | grad 2.09 | tok/s 16292
step   2050 | loss 1.2063 | lr 3.00e-04 | grad 2.27 | tok/s 15961
step   2060 | loss 1.5786 | lr 3.00e-04 | grad 2.25 | tok/s 15068
step   2070 | loss 1.6745 | lr 3.00e-04 | grad 2.38 | tok/s 15626
step   2080 | loss 2.2719 | lr 3.00e-04 | grad 4.09 | tok/s 16144
step   2090 | loss 1.7128 | lr 3.00e-04 | grad 4.50 | tok/s 16191
step   2100 | loss 1.4011 | lr 3.00e-04 | grad 2.67 | tok/s 15766
step   2110 | loss 1.5465 | lr 3.00e-04 | grad 25.38 | tok/s 15463
step   2120 | loss 0.9381 | lr 3.00e-04 | grad 1.80 | tok/s 16017
step   2130 | loss 1.0500 | lr 3.00e-04 | grad 3.17 | tok/s 15999
step   2140 | loss 1.5677 | lr 3.00e-04 | grad 1.95 | tok/s 15498
step   2150 | loss 1.2994 | lr 3.00e-04 | grad 1.99 | tok/s 16271
step   2160 | loss 1.1954 | lr 3.00e-04 | grad 1.65 | tok/s 16273
step   2170 | loss 1.2474 | lr 3.00e-04 | grad 1.61 | tok/s 16258
step   2180 | loss 1.1945 | lr 3.00e-04 | grad 1.92 | tok/s 16249
step   2190 | loss 1.2139 | lr 3.00e-04 | grad 1.62 | tok/s 16274
step   2200 | loss 1.1988 | lr 3.00e-04 | grad 1.76 | tok/s 16274
step   2210 | loss 1.1471 | lr 3.00e-04 | grad 1.59 | tok/s 16269
step   2220 | loss 1.1471 | lr 3.00e-04 | grad 1.62 | tok/s 15265
step   2230 | loss 1.3618 | lr 3.00e-04 | grad 2.02 | tok/s 15977
step   2240 | loss 1.3334 | lr 3.00e-04 | grad 1.81 | tok/s 16233
step   2250 | loss 1.5630 | lr 3.00e-04 | grad 3.17 | tok/s 15679
step   2260 | loss 1.6163 | lr 3.00e-04 | grad 2.22 | tok/s 15869
step   2270 | loss 1.9326 | lr 3.00e-04 | grad 3.03 | tok/s 16108
step   2280 | loss 1.4905 | lr 3.00e-04 | grad 2.39 | tok/s 16081
step   2290 | loss 1.2954 | lr 3.00e-04 | grad 2.80 | tok/s 15683
step   2300 | loss 1.6543 | lr 3.00e-04 | grad 3.12 | tok/s 16025

Training complete! Final step: 2305
