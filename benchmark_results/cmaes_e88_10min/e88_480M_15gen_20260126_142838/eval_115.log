Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_115/levelE88_100m_20260126_165303
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,286,128 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1756 | lr 3.00e-04 | grad 17.25 | tok/s 6006
step     20 | loss 2.8372 | lr 3.00e-04 | grad 8.25 | tok/s 15388
step     30 | loss 2.5839 | lr 3.00e-04 | grad 5.81 | tok/s 15542
step     40 | loss 2.3783 | lr 3.00e-04 | grad 4.56 | tok/s 14903
step     50 | loss 2.9406 | lr 3.00e-04 | grad 12.62 | tok/s 15104
step     60 | loss 2.0661 | lr 3.00e-04 | grad 3.94 | tok/s 15565
step     70 | loss 1.8655 | lr 3.00e-04 | grad 5.22 | tok/s 15715
step     80 | loss 6.0395 | lr 3.00e-04 | grad 74.00 | tok/s 15808
step     90 | loss 5.5276 | lr 3.00e-04 | grad 10.12 | tok/s 16025
step    100 | loss 4.2634 | lr 3.00e-04 | grad 8.19 | tok/s 16038
step    110 | loss 3.5650 | lr 3.00e-04 | grad 16.50 | tok/s 15996
step    120 | loss 3.1873 | lr 3.00e-04 | grad 12.31 | tok/s 15981
step    130 | loss 2.9632 | lr 3.00e-04 | grad 13.94 | tok/s 15986
step    140 | loss 2.6996 | lr 3.00e-04 | grad 10.56 | tok/s 15983
step    150 | loss 2.7376 | lr 3.00e-04 | grad 11.75 | tok/s 15980
step    160 | loss 2.3290 | lr 3.00e-04 | grad 10.62 | tok/s 15972
step    170 | loss 2.4475 | lr 3.00e-04 | grad 12.94 | tok/s 15970
step    180 | loss 2.2299 | lr 3.00e-04 | grad 6.56 | tok/s 15980
step    190 | loss 2.3586 | lr 3.00e-04 | grad 6.50 | tok/s 15979
step    200 | loss 2.1022 | lr 3.00e-04 | grad 5.84 | tok/s 15967
step    210 | loss 2.1394 | lr 3.00e-04 | grad 7.31 | tok/s 15988
step    220 | loss 2.1292 | lr 3.00e-04 | grad 3.42 | tok/s 15760
step    230 | loss 2.0063 | lr 3.00e-04 | grad 4.44 | tok/s 14658
step    240 | loss 2.2774 | lr 3.00e-04 | grad 4.81 | tok/s 14765
step    250 | loss 2.0946 | lr 3.00e-04 | grad 2.66 | tok/s 15213
step    260 | loss 1.5306 | lr 3.00e-04 | grad 3.03 | tok/s 15616
step    270 | loss 2.0801 | lr 3.00e-04 | grad 2.81 | tok/s 15491
step    280 | loss 2.2309 | lr 3.00e-04 | grad 4.94 | tok/s 15121
step    290 | loss 1.3845 | lr 3.00e-04 | grad 3.70 | tok/s 15982
step    300 | loss 0.5694 | lr 3.00e-04 | grad 2.28 | tok/s 15908
step    310 | loss 2.3721 | lr 3.00e-04 | grad 3.67 | tok/s 15634
step    320 | loss 1.9025 | lr 3.00e-04 | grad 5.75 | tok/s 15304
step    330 | loss 1.9413 | lr 3.00e-04 | grad 2.95 | tok/s 14760
step    340 | loss 2.2665 | lr 3.00e-04 | grad 2.86 | tok/s 15002
step    350 | loss 1.8558 | lr 3.00e-04 | grad 4.53 | tok/s 15375
step    360 | loss 1.1932 | lr 3.00e-04 | grad 7.72 | tok/s 15706
step    370 | loss 1.7912 | lr 3.00e-04 | grad 2.62 | tok/s 14238
step    380 | loss 1.7509 | lr 3.00e-04 | grad 2.72 | tok/s 15173
step    390 | loss 1.5290 | lr 3.00e-04 | grad 2.14 | tok/s 15817
step    400 | loss 1.4799 | lr 3.00e-04 | grad 2.55 | tok/s 15684
step    410 | loss 1.2645 | lr 3.00e-04 | grad 2.05 | tok/s 15318
step    420 | loss 1.8131 | lr 3.00e-04 | grad 4.38 | tok/s 13699
step    430 | loss 2.1499 | lr 3.00e-04 | grad 2.92 | tok/s 15587
step    440 | loss 2.1384 | lr 3.00e-04 | grad 4.09 | tok/s 14737
step    450 | loss 1.9663 | lr 3.00e-04 | grad 2.69 | tok/s 15217
step    460 | loss 1.7210 | lr 3.00e-04 | grad 2.95 | tok/s 14959
step    470 | loss 1.8332 | lr 3.00e-04 | grad 2.42 | tok/s 15368
step    480 | loss 2.2407 | lr 3.00e-04 | grad 7.03 | tok/s 15482
step    490 | loss 1.7915 | lr 3.00e-04 | grad 2.45 | tok/s 14554
step    500 | loss 1.6652 | lr 3.00e-04 | grad 3.33 | tok/s 15542
step    510 | loss 1.6978 | lr 3.00e-04 | grad 2.38 | tok/s 15771
step    520 | loss 1.6520 | lr 3.00e-04 | grad 2.09 | tok/s 15698
step    530 | loss 1.9123 | lr 3.00e-04 | grad 2.44 | tok/s 15124
step    540 | loss 1.7335 | lr 3.00e-04 | grad 2.23 | tok/s 15060
step    550 | loss 1.5649 | lr 3.00e-04 | grad 2.95 | tok/s 14801
step    560 | loss 1.7208 | lr 3.00e-04 | grad 2.59 | tok/s 12831
step    570 | loss 1.6625 | lr 3.00e-04 | grad 3.50 | tok/s 14802
step    580 | loss 1.5468 | lr 3.00e-04 | grad 2.16 | tok/s 14755
step    590 | loss 1.8616 | lr 3.00e-04 | grad 3.14 | tok/s 15126
step    600 | loss 1.8137 | lr 3.00e-04 | grad 2.22 | tok/s 14635
step    610 | loss 1.6183 | lr 3.00e-04 | grad 2.38 | tok/s 15376
step    620 | loss 1.5445 | lr 3.00e-04 | grad 2.36 | tok/s 14524
step    630 | loss 1.6562 | lr 3.00e-04 | grad 4.31 | tok/s 14703
step    640 | loss 1.8078 | lr 3.00e-04 | grad 2.38 | tok/s 15086
step    650 | loss 1.6790 | lr 3.00e-04 | grad 2.50 | tok/s 15169
step    660 | loss 1.6952 | lr 3.00e-04 | grad 2.12 | tok/s 15255
step    670 | loss 1.9283 | lr 3.00e-04 | grad 3.11 | tok/s 15337
step    680 | loss 1.7304 | lr 3.00e-04 | grad 2.36 | tok/s 15003
step    690 | loss 1.8283 | lr 3.00e-04 | grad 3.05 | tok/s 15542
step    700 | loss 1.4268 | lr 3.00e-04 | grad 3.08 | tok/s 15793
step    710 | loss 1.5954 | lr 3.00e-04 | grad 2.34 | tok/s 14786
step    720 | loss 1.4716 | lr 3.00e-04 | grad 3.31 | tok/s 14564
step    730 | loss 1.2882 | lr 3.00e-04 | grad 2.77 | tok/s 15780
step    740 | loss 1.4936 | lr 3.00e-04 | grad 2.33 | tok/s 15659
step    750 | loss 1.2056 | lr 3.00e-04 | grad 2.47 | tok/s 15843
step    760 | loss 1.1104 | lr 3.00e-04 | grad 2.19 | tok/s 15803
step    770 | loss 1.0605 | lr 3.00e-04 | grad 2.09 | tok/s 15844
step    780 | loss 0.9982 | lr 3.00e-04 | grad 2.12 | tok/s 15837
step    790 | loss 1.1325 | lr 3.00e-04 | grad 3.17 | tok/s 15334
step    800 | loss 1.8200 | lr 3.00e-04 | grad 5.34 | tok/s 15235
step    810 | loss 1.7066 | lr 3.00e-04 | grad 2.09 | tok/s 15183
step    820 | loss 1.7110 | lr 3.00e-04 | grad 3.81 | tok/s 14600
step    830 | loss 1.4913 | lr 3.00e-04 | grad 2.23 | tok/s 15696
step    840 | loss 1.3513 | lr 3.00e-04 | grad 2.20 | tok/s 15825
step    850 | loss 1.5917 | lr 3.00e-04 | grad 2.00 | tok/s 15781
step    860 | loss 1.4876 | lr 3.00e-04 | grad 3.44 | tok/s 15611
step    870 | loss 1.4993 | lr 3.00e-04 | grad 2.47 | tok/s 15028
step    880 | loss 1.6845 | lr 3.00e-04 | grad 2.47 | tok/s 15074
step    890 | loss 1.6847 | lr 3.00e-04 | grad 2.89 | tok/s 15290
step    900 | loss 1.5701 | lr 3.00e-04 | grad 2.48 | tok/s 15328
step    910 | loss 1.4416 | lr 3.00e-04 | grad 3.94 | tok/s 14982
step    920 | loss 1.5268 | lr 3.00e-04 | grad 3.47 | tok/s 15540
step    930 | loss 1.6056 | lr 3.00e-04 | grad 3.45 | tok/s 14892
step    940 | loss 1.3827 | lr 3.00e-04 | grad 1.88 | tok/s 15726
step    950 | loss 1.4903 | lr 3.00e-04 | grad 2.59 | tok/s 15757
step    960 | loss 1.3364 | lr 3.00e-04 | grad 2.55 | tok/s 15780
step    970 | loss 1.7558 | lr 3.00e-04 | grad 3.55 | tok/s 14790
step    980 | loss 1.6525 | lr 3.00e-04 | grad 2.45 | tok/s 15206
step    990 | loss 1.4513 | lr 3.00e-04 | grad 2.11 | tok/s 15466
step   1000 | loss 1.8541 | lr 3.00e-04 | grad 7.88 | tok/s 14857
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8541.pt
step   1010 | loss 1.7314 | lr 3.00e-04 | grad 2.38 | tok/s 5869
step   1020 | loss 1.6870 | lr 3.00e-04 | grad 2.50 | tok/s 14616
step   1030 | loss 1.4157 | lr 3.00e-04 | grad 1.76 | tok/s 15248
step   1040 | loss 1.5328 | lr 3.00e-04 | grad 4.06 | tok/s 15576
step   1050 | loss 1.6165 | lr 3.00e-04 | grad 2.28 | tok/s 14652
step   1060 | loss 1.7073 | lr 3.00e-04 | grad 2.31 | tok/s 15676
step   1070 | loss 1.6554 | lr 3.00e-04 | grad 3.38 | tok/s 15417
step   1080 | loss 1.4085 | lr 3.00e-04 | grad 2.44 | tok/s 14268
step   1090 | loss 1.0031 | lr 3.00e-04 | grad 2.08 | tok/s 15825
step   1100 | loss 1.5802 | lr 3.00e-04 | grad 2.77 | tok/s 15151
step   1110 | loss 1.4272 | lr 3.00e-04 | grad 1.94 | tok/s 15928
step   1120 | loss 1.3348 | lr 3.00e-04 | grad 2.19 | tok/s 15885
step   1130 | loss 1.2833 | lr 3.00e-04 | grad 2.05 | tok/s 15884
step   1140 | loss 1.2899 | lr 3.00e-04 | grad 1.88 | tok/s 15944
step   1150 | loss 1.2916 | lr 3.00e-04 | grad 2.00 | tok/s 15876
step   1160 | loss 1.2107 | lr 3.00e-04 | grad 1.94 | tok/s 15880
step   1170 | loss 1.2579 | lr 3.00e-04 | grad 2.09 | tok/s 15907
step   1180 | loss 1.3131 | lr 3.00e-04 | grad 1.72 | tok/s 15907
step   1190 | loss 1.2191 | lr 3.00e-04 | grad 2.09 | tok/s 13985
step   1200 | loss 1.2222 | lr 3.00e-04 | grad 1.80 | tok/s 15884
step   1210 | loss 1.2594 | lr 3.00e-04 | grad 1.66 | tok/s 15856
step   1220 | loss 1.2846 | lr 3.00e-04 | grad 1.80 | tok/s 15868
step   1230 | loss 1.2567 | lr 3.00e-04 | grad 1.66 | tok/s 15848
step   1240 | loss 1.2642 | lr 3.00e-04 | grad 2.81 | tok/s 15732
step   1250 | loss 1.7943 | lr 3.00e-04 | grad 2.42 | tok/s 15079
step   1260 | loss 1.3281 | lr 3.00e-04 | grad 3.20 | tok/s 14818
step   1270 | loss 1.7623 | lr 3.00e-04 | grad 2.92 | tok/s 14856
step   1280 | loss 1.5846 | lr 3.00e-04 | grad 2.56 | tok/s 15453
step   1290 | loss 1.4939 | lr 3.00e-04 | grad 2.67 | tok/s 15168
step   1300 | loss 1.5169 | lr 3.00e-04 | grad 2.14 | tok/s 15017
step   1310 | loss 1.4518 | lr 3.00e-04 | grad 1.94 | tok/s 15710
step   1320 | loss 1.5953 | lr 3.00e-04 | grad 2.39 | tok/s 15566
step   1330 | loss 1.5302 | lr 3.00e-04 | grad 2.05 | tok/s 15621
step   1340 | loss 1.5887 | lr 3.00e-04 | grad 3.30 | tok/s 13401
step   1350 | loss 1.7346 | lr 3.00e-04 | grad 2.33 | tok/s 14566
step   1360 | loss 1.4773 | lr 3.00e-04 | grad 1.81 | tok/s 15270
step   1370 | loss 1.5186 | lr 3.00e-04 | grad 6.69 | tok/s 15095
step   1380 | loss 1.5934 | lr 3.00e-04 | grad 3.05 | tok/s 14578
step   1390 | loss 1.4904 | lr 3.00e-04 | grad 4.41 | tok/s 15310
step   1400 | loss 1.3743 | lr 3.00e-04 | grad 1.64 | tok/s 14945
step   1410 | loss 1.5293 | lr 3.00e-04 | grad 7.03 | tok/s 14896
step   1420 | loss 1.6423 | lr 3.00e-04 | grad 2.23 | tok/s 14864
step   1430 | loss 1.3388 | lr 3.00e-04 | grad 2.23 | tok/s 15106
step   1440 | loss 1.1412 | lr 3.00e-04 | grad 1.98 | tok/s 15831
step   1450 | loss 1.1645 | lr 3.00e-04 | grad 2.48 | tok/s 15616
step   1460 | loss 1.7069 | lr 3.00e-04 | grad 2.25 | tok/s 14793
step   1470 | loss 1.5215 | lr 3.00e-04 | grad 2.03 | tok/s 15709
step   1480 | loss 1.8330 | lr 3.00e-04 | grad 3.30 | tok/s 15512
step   1490 | loss 1.5664 | lr 3.00e-04 | grad 2.66 | tok/s 15804
step   1500 | loss 1.2974 | lr 3.00e-04 | grad 1.94 | tok/s 15891
step   1510 | loss 1.5420 | lr 3.00e-04 | grad 2.62 | tok/s 15583
step   1520 | loss 1.4359 | lr 3.00e-04 | grad 2.80 | tok/s 15313
step   1530 | loss 1.4391 | lr 3.00e-04 | grad 2.97 | tok/s 15733
step   1540 | loss 1.6269 | lr 3.00e-04 | grad 2.52 | tok/s 14717
step   1550 | loss 1.2692 | lr 3.00e-04 | grad 2.64 | tok/s 15694
step   1560 | loss 1.5988 | lr 3.00e-04 | grad 1.93 | tok/s 14915
step   1570 | loss 1.2804 | lr 3.00e-04 | grad 2.20 | tok/s 15673
step   1580 | loss 1.7284 | lr 3.00e-04 | grad 4.12 | tok/s 15570
step   1590 | loss 1.5874 | lr 3.00e-04 | grad 2.20 | tok/s 14865
step   1600 | loss 0.9141 | lr 3.00e-04 | grad 1.70 | tok/s 15855
step   1610 | loss 1.1063 | lr 3.00e-04 | grad 1.86 | tok/s 14972
step   1620 | loss 1.4033 | lr 3.00e-04 | grad 3.16 | tok/s 14707
step   1630 | loss 1.3603 | lr 3.00e-04 | grad 1.80 | tok/s 15448
step   1640 | loss 1.3655 | lr 3.00e-04 | grad 2.03 | tok/s 14922
step   1650 | loss 1.5606 | lr 3.00e-04 | grad 2.72 | tok/s 14112
step   1660 | loss 1.3322 | lr 3.00e-04 | grad 1.67 | tok/s 15790
step   1670 | loss 1.4469 | lr 3.00e-04 | grad 3.70 | tok/s 15278
step   1680 | loss 1.6863 | lr 3.00e-04 | grad 1.75 | tok/s 14544
step   1690 | loss 1.4915 | lr 3.00e-04 | grad 3.14 | tok/s 15269
step   1700 | loss 1.5215 | lr 3.00e-04 | grad 1.96 | tok/s 15073
step   1710 | loss 1.4224 | lr 3.00e-04 | grad 2.08 | tok/s 15147
step   1720 | loss 1.5261 | lr 3.00e-04 | grad 2.86 | tok/s 15785
step   1730 | loss 1.1938 | lr 3.00e-04 | grad 2.59 | tok/s 15809
step   1740 | loss 1.3999 | lr 3.00e-04 | grad 2.50 | tok/s 15258
step   1750 | loss 1.5537 | lr 3.00e-04 | grad 2.58 | tok/s 15305
step   1760 | loss 1.5703 | lr 3.00e-04 | grad 2.16 | tok/s 15301
step   1770 | loss 1.4527 | lr 3.00e-04 | grad 2.28 | tok/s 14922
step   1780 | loss 1.4922 | lr 3.00e-04 | grad 1.92 | tok/s 15428
step   1790 | loss 1.4340 | lr 3.00e-04 | grad 2.92 | tok/s 15257
step   1800 | loss 1.5829 | lr 3.00e-04 | grad 1.97 | tok/s 13571
step   1810 | loss 1.4599 | lr 3.00e-04 | grad 3.50 | tok/s 14767
step   1820 | loss 1.4865 | lr 3.00e-04 | grad 6.75 | tok/s 15208
step   1830 | loss 1.4541 | lr 3.00e-04 | grad 3.81 | tok/s 15521
step   1840 | loss 1.4892 | lr 3.00e-04 | grad 1.86 | tok/s 14770
step   1850 | loss 1.2779 | lr 3.00e-04 | grad 1.81 | tok/s 15787
step   1860 | loss 1.3700 | lr 3.00e-04 | grad 2.58 | tok/s 14947
step   1870 | loss 1.3705 | lr 3.00e-04 | grad 1.71 | tok/s 15289
step   1880 | loss 1.2785 | lr 3.00e-04 | grad 2.81 | tok/s 14706
step   1890 | loss 1.5336 | lr 3.00e-04 | grad 2.03 | tok/s 14299
step   1900 | loss 1.3969 | lr 3.00e-04 | grad 2.19 | tok/s 15262
step   1910 | loss 1.4949 | lr 3.00e-04 | grad 2.14 | tok/s 14466
step   1920 | loss 1.3818 | lr 3.00e-04 | grad 1.86 | tok/s 15845
step   1930 | loss 1.4634 | lr 3.00e-04 | grad 3.31 | tok/s 14540
step   1940 | loss 1.4576 | lr 3.00e-04 | grad 2.11 | tok/s 15675
step   1950 | loss 1.8756 | lr 3.00e-04 | grad 3.28 | tok/s 15679
step   1960 | loss 1.4472 | lr 3.00e-04 | grad 4.28 | tok/s 15840
step   1970 | loss 1.4891 | lr 3.00e-04 | grad 2.38 | tok/s 15447
step   1980 | loss 1.5654 | lr 3.00e-04 | grad 2.19 | tok/s 14771
step   1990 | loss 1.6075 | lr 3.00e-04 | grad 2.48 | tok/s 15073
step   2000 | loss 1.5080 | lr 3.00e-04 | grad 2.50 | tok/s 15297
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5080.pt
step   2010 | loss 1.1096 | lr 3.00e-04 | grad 2.42 | tok/s 7114
step   2020 | loss 1.3196 | lr 3.00e-04 | grad 2.81 | tok/s 15399
step   2030 | loss 1.0021 | lr 3.00e-04 | grad 1.66 | tok/s 16009
step   2040 | loss 1.2959 | lr 3.00e-04 | grad 2.08 | tok/s 15163
step   2050 | loss 1.2337 | lr 3.00e-04 | grad 2.39 | tok/s 15546
step   2060 | loss 1.5869 | lr 3.00e-04 | grad 3.38 | tok/s 14808
step   2070 | loss 1.7511 | lr 3.00e-04 | grad 5.94 | tok/s 15156
step   2080 | loss 2.2107 | lr 3.00e-04 | grad 3.44 | tok/s 15973
step   2090 | loss 1.6745 | lr 3.00e-04 | grad 2.19 | tok/s 15635
step   2100 | loss 1.4061 | lr 3.00e-04 | grad 2.03 | tok/s 15697
step   2110 | loss 1.5023 | lr 3.00e-04 | grad 2.75 | tok/s 14879
step   2120 | loss 0.8902 | lr 3.00e-04 | grad 6.12 | tok/s 16008
step   2130 | loss 1.1731 | lr 3.00e-04 | grad 4.25 | tok/s 15378
step   2140 | loss 1.5125 | lr 3.00e-04 | grad 2.03 | tok/s 15468
step   2150 | loss 1.2997 | lr 3.00e-04 | grad 2.08 | tok/s 15984
step   2160 | loss 1.1750 | lr 3.00e-04 | grad 1.59 | tok/s 15982
step   2170 | loss 1.2488 | lr 3.00e-04 | grad 1.76 | tok/s 15991
step   2180 | loss 1.1938 | lr 3.00e-04 | grad 1.63 | tok/s 15112
step   2190 | loss 1.1981 | lr 3.00e-04 | grad 1.61 | tok/s 15912
step   2200 | loss 1.1986 | lr 3.00e-04 | grad 1.74 | tok/s 15982
step   2210 | loss 1.1411 | lr 3.00e-04 | grad 1.77 | tok/s 15968
step   2220 | loss 1.1439 | lr 3.00e-04 | grad 1.59 | tok/s 15989
step   2230 | loss 1.3837 | lr 3.00e-04 | grad 1.73 | tok/s 15675
step   2240 | loss 1.3381 | lr 3.00e-04 | grad 2.30 | tok/s 15910

Training complete! Final step: 2247
