Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_92/levelE88_100m_20260126_162205
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 486,656,932 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1582 | lr 3.00e-04 | grad 24.88 | tok/s 6084
step     20 | loss 2.8160 | lr 3.00e-04 | grad 11.44 | tok/s 16133
step     30 | loss 2.6239 | lr 3.00e-04 | grad 6.59 | tok/s 16315
step     40 | loss 2.4646 | lr 3.00e-04 | grad 5.28 | tok/s 15590
step     50 | loss 3.1206 | lr 3.00e-04 | grad 17.00 | tok/s 15838
step     60 | loss 2.0954 | lr 3.00e-04 | grad 5.16 | tok/s 16320
step     70 | loss 1.9165 | lr 3.00e-04 | grad 6.19 | tok/s 16517
step     80 | loss 6.4009 | lr 3.00e-04 | grad 153.00 | tok/s 16602
step     90 | loss 6.3190 | lr 3.00e-04 | grad 18.12 | tok/s 16862
step    100 | loss 5.0971 | lr 3.00e-04 | grad 16.25 | tok/s 16851
step    110 | loss 4.4437 | lr 3.00e-04 | grad 27.38 | tok/s 16846
step    120 | loss 3.8049 | lr 3.00e-04 | grad 29.75 | tok/s 16814
step    130 | loss 3.4686 | lr 3.00e-04 | grad 39.75 | tok/s 14855
step    140 | loss 2.9569 | lr 3.00e-04 | grad 21.88 | tok/s 16926
step    150 | loss 3.2345 | lr 3.00e-04 | grad 31.25 | tok/s 16777
step    160 | loss 2.5308 | lr 3.00e-04 | grad 26.38 | tok/s 16747
step    170 | loss 2.6243 | lr 3.00e-04 | grad 25.25 | tok/s 16757
step    180 | loss 2.4343 | lr 3.00e-04 | grad 8.38 | tok/s 16732
step    190 | loss 2.6932 | lr 3.00e-04 | grad 20.38 | tok/s 16740
step    200 | loss 2.3199 | lr 3.00e-04 | grad 16.25 | tok/s 16738
step    210 | loss 2.3123 | lr 3.00e-04 | grad 11.00 | tok/s 16735
step    220 | loss 2.3169 | lr 3.00e-04 | grad 3.80 | tok/s 16498
step    230 | loss 2.1187 | lr 3.00e-04 | grad 4.22 | tok/s 16322
step    240 | loss 2.3122 | lr 3.00e-04 | grad 5.25 | tok/s 15488
step    250 | loss 2.1300 | lr 3.00e-04 | grad 2.80 | tok/s 15909
step    260 | loss 1.5692 | lr 3.00e-04 | grad 3.08 | tok/s 16398
step    270 | loss 2.1215 | lr 3.00e-04 | grad 2.86 | tok/s 15256
step    280 | loss 2.3019 | lr 3.00e-04 | grad 5.03 | tok/s 15868
step    290 | loss 1.4169 | lr 3.00e-04 | grad 4.09 | tok/s 16752
step    300 | loss 0.5869 | lr 3.00e-04 | grad 2.56 | tok/s 16752
step    310 | loss 2.4189 | lr 3.00e-04 | grad 3.70 | tok/s 16471
step    320 | loss 1.9497 | lr 3.00e-04 | grad 6.03 | tok/s 16116
step    330 | loss 1.9729 | lr 3.00e-04 | grad 3.05 | tok/s 15570
step    340 | loss 2.3025 | lr 3.00e-04 | grad 2.91 | tok/s 15822
step    350 | loss 1.8915 | lr 3.00e-04 | grad 4.66 | tok/s 16198
step    360 | loss 1.1976 | lr 3.00e-04 | grad 7.00 | tok/s 16570
step    370 | loss 1.8321 | lr 3.00e-04 | grad 2.67 | tok/s 14978
step    380 | loss 1.7917 | lr 3.00e-04 | grad 2.55 | tok/s 15985
step    390 | loss 1.5489 | lr 3.00e-04 | grad 2.11 | tok/s 16693
step    400 | loss 1.5082 | lr 3.00e-04 | grad 2.67 | tok/s 16552
step    410 | loss 1.2970 | lr 3.00e-04 | grad 2.09 | tok/s 16128
step    420 | loss 1.8424 | lr 3.00e-04 | grad 4.59 | tok/s 14734
step    430 | loss 2.1807 | lr 3.00e-04 | grad 3.02 | tok/s 16444
step    440 | loss 2.1828 | lr 3.00e-04 | grad 4.19 | tok/s 15529
step    450 | loss 1.9661 | lr 3.00e-04 | grad 2.83 | tok/s 16066
step    460 | loss 1.7541 | lr 3.00e-04 | grad 2.91 | tok/s 15725
step    470 | loss 1.8542 | lr 3.00e-04 | grad 2.48 | tok/s 16207
step    480 | loss 2.2967 | lr 3.00e-04 | grad 6.94 | tok/s 16211
step    490 | loss 1.8170 | lr 3.00e-04 | grad 2.58 | tok/s 15314
step    500 | loss 1.7019 | lr 3.00e-04 | grad 3.36 | tok/s 16375
step    510 | loss 1.7291 | lr 3.00e-04 | grad 2.39 | tok/s 16592
step    520 | loss 1.6789 | lr 3.00e-04 | grad 2.12 | tok/s 16546
step    530 | loss 1.9333 | lr 3.00e-04 | grad 2.50 | tok/s 15916
step    540 | loss 1.7540 | lr 3.00e-04 | grad 2.36 | tok/s 15932
step    550 | loss 1.5840 | lr 3.00e-04 | grad 3.25 | tok/s 15589
step    560 | loss 1.7532 | lr 3.00e-04 | grad 2.69 | tok/s 14633
step    570 | loss 1.6882 | lr 3.00e-04 | grad 3.83 | tok/s 15602
step    580 | loss 1.5594 | lr 3.00e-04 | grad 2.20 | tok/s 15553
step    590 | loss 1.8923 | lr 3.00e-04 | grad 3.11 | tok/s 15952
step    600 | loss 1.8347 | lr 3.00e-04 | grad 2.33 | tok/s 15407
step    610 | loss 1.6449 | lr 3.00e-04 | grad 2.44 | tok/s 16211
step    620 | loss 1.5685 | lr 3.00e-04 | grad 2.50 | tok/s 15350
step    630 | loss 1.6801 | lr 3.00e-04 | grad 4.38 | tok/s 15472
step    640 | loss 1.8347 | lr 3.00e-04 | grad 2.48 | tok/s 15895
step    650 | loss 1.6851 | lr 3.00e-04 | grad 2.61 | tok/s 15963
step    660 | loss 1.7160 | lr 3.00e-04 | grad 2.19 | tok/s 16046
step    670 | loss 1.9542 | lr 3.00e-04 | grad 3.34 | tok/s 16143
step    680 | loss 1.7423 | lr 3.00e-04 | grad 2.45 | tok/s 15827
step    690 | loss 1.8542 | lr 3.00e-04 | grad 3.09 | tok/s 16354
step    700 | loss 1.4452 | lr 3.00e-04 | grad 3.14 | tok/s 16004
step    710 | loss 1.5936 | lr 3.00e-04 | grad 2.39 | tok/s 15592
step    720 | loss 1.4783 | lr 3.00e-04 | grad 3.22 | tok/s 15359
step    730 | loss 1.3092 | lr 3.00e-04 | grad 2.86 | tok/s 16642
step    740 | loss 1.5222 | lr 3.00e-04 | grad 2.38 | tok/s 16445
step    750 | loss 1.2247 | lr 3.00e-04 | grad 2.56 | tok/s 16683
step    760 | loss 1.1313 | lr 3.00e-04 | grad 2.23 | tok/s 16691
step    770 | loss 1.0816 | lr 3.00e-04 | grad 2.08 | tok/s 16711
step    780 | loss 1.0150 | lr 3.00e-04 | grad 2.11 | tok/s 16707
step    790 | loss 1.1464 | lr 3.00e-04 | grad 3.27 | tok/s 16170
step    800 | loss 1.8373 | lr 3.00e-04 | grad 5.56 | tok/s 16111
step    810 | loss 1.7203 | lr 3.00e-04 | grad 2.08 | tok/s 16033
step    820 | loss 1.7338 | lr 3.00e-04 | grad 3.94 | tok/s 15405
step    830 | loss 1.5051 | lr 3.00e-04 | grad 2.27 | tok/s 16517
step    840 | loss 1.3778 | lr 3.00e-04 | grad 2.30 | tok/s 15849
step    850 | loss 1.5998 | lr 3.00e-04 | grad 2.14 | tok/s 16600
step    860 | loss 1.4946 | lr 3.00e-04 | grad 3.55 | tok/s 16435
step    870 | loss 1.5182 | lr 3.00e-04 | grad 2.73 | tok/s 15810
step    880 | loss 1.7042 | lr 3.00e-04 | grad 2.70 | tok/s 15889
step    890 | loss 1.7059 | lr 3.00e-04 | grad 2.95 | tok/s 16108
step    900 | loss 1.5849 | lr 3.00e-04 | grad 2.58 | tok/s 16147
step    910 | loss 1.4466 | lr 3.00e-04 | grad 4.25 | tok/s 15805
step    920 | loss 1.5500 | lr 3.00e-04 | grad 3.64 | tok/s 16414
step    930 | loss 1.6209 | lr 3.00e-04 | grad 3.59 | tok/s 15662
step    940 | loss 1.4081 | lr 3.00e-04 | grad 1.91 | tok/s 16527
step    950 | loss 1.5024 | lr 3.00e-04 | grad 2.94 | tok/s 16581
step    960 | loss 1.3417 | lr 3.00e-04 | grad 2.50 | tok/s 16603
step    970 | loss 1.7708 | lr 3.00e-04 | grad 3.56 | tok/s 15639
step    980 | loss 1.6686 | lr 3.00e-04 | grad 2.41 | tok/s 16069
step    990 | loss 1.4668 | lr 3.00e-04 | grad 2.12 | tok/s 15442
step   1000 | loss 1.8640 | lr 3.00e-04 | grad 7.78 | tok/s 15825
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8640.pt
step   1010 | loss 1.6684 | lr 3.00e-04 | grad 3.39 | tok/s 7220
step   1020 | loss 1.6745 | lr 3.00e-04 | grad 1.95 | tok/s 15344
step   1030 | loss 1.4770 | lr 3.00e-04 | grad 2.12 | tok/s 15969
step   1040 | loss 1.4977 | lr 3.00e-04 | grad 2.28 | tok/s 16488
step   1050 | loss 1.6481 | lr 3.00e-04 | grad 3.31 | tok/s 15243
step   1060 | loss 1.7497 | lr 3.00e-04 | grad 3.47 | tok/s 16474
step   1070 | loss 1.6638 | lr 3.00e-04 | grad 2.72 | tok/s 16400
step   1080 | loss 1.4165 | lr 3.00e-04 | grad 2.00 | tok/s 14893
step   1090 | loss 1.1328 | lr 3.00e-04 | grad 1.14 | tok/s 16399
step   1100 | loss 1.4580 | lr 3.00e-04 | grad 3.39 | tok/s 15924
step   1110 | loss 1.4787 | lr 3.00e-04 | grad 2.11 | tok/s 16717
step   1120 | loss 1.3490 | lr 3.00e-04 | grad 2.12 | tok/s 16720
step   1130 | loss 1.3008 | lr 3.00e-04 | grad 1.94 | tok/s 15810
step   1140 | loss 1.2933 | lr 3.00e-04 | grad 2.16 | tok/s 16710
step   1150 | loss 1.3116 | lr 3.00e-04 | grad 1.81 | tok/s 16744
step   1160 | loss 1.2233 | lr 3.00e-04 | grad 1.89 | tok/s 16749
step   1170 | loss 1.2522 | lr 3.00e-04 | grad 2.12 | tok/s 16707
step   1180 | loss 1.3523 | lr 3.00e-04 | grad 1.71 | tok/s 16697
step   1190 | loss 1.2320 | lr 3.00e-04 | grad 2.22 | tok/s 16722
step   1200 | loss 1.2278 | lr 3.00e-04 | grad 2.05 | tok/s 16695
step   1210 | loss 1.2817 | lr 3.00e-04 | grad 2.11 | tok/s 16722
step   1220 | loss 1.3003 | lr 3.00e-04 | grad 1.98 | tok/s 16729
step   1230 | loss 1.2678 | lr 3.00e-04 | grad 1.84 | tok/s 16695
step   1240 | loss 1.2310 | lr 3.00e-04 | grad 1.61 | tok/s 16706
step   1250 | loss 1.8232 | lr 3.00e-04 | grad 3.72 | tok/s 15822
step   1260 | loss 1.4346 | lr 3.00e-04 | grad 2.86 | tok/s 15648
step   1270 | loss 1.6712 | lr 3.00e-04 | grad 4.94 | tok/s 14667
step   1280 | loss 1.6506 | lr 3.00e-04 | grad 1.80 | tok/s 16097
step   1290 | loss 1.4909 | lr 3.00e-04 | grad 2.12 | tok/s 15998
step   1300 | loss 1.5358 | lr 3.00e-04 | grad 2.55 | tok/s 16101
step   1310 | loss 1.4719 | lr 3.00e-04 | grad 2.44 | tok/s 16364
step   1320 | loss 1.6046 | lr 3.00e-04 | grad 2.28 | tok/s 16423
step   1330 | loss 1.6287 | lr 3.00e-04 | grad 2.48 | tok/s 16427
step   1340 | loss 1.5068 | lr 3.00e-04 | grad 9.19 | tok/s 15687
step   1350 | loss 1.7514 | lr 3.00e-04 | grad 2.52 | tok/s 15160
step   1360 | loss 1.5094 | lr 3.00e-04 | grad 2.42 | tok/s 16094
step   1370 | loss 1.4218 | lr 3.00e-04 | grad 1.66 | tok/s 15906
step   1380 | loss 1.6963 | lr 3.00e-04 | grad 2.34 | tok/s 15294
step   1390 | loss 1.5415 | lr 3.00e-04 | grad 1.79 | tok/s 16235
step   1400 | loss 1.4211 | lr 3.00e-04 | grad 1.77 | tok/s 15634
step   1410 | loss 1.4774 | lr 3.00e-04 | grad 3.12 | tok/s 15082
step   1420 | loss 1.7030 | lr 3.00e-04 | grad 3.98 | tok/s 15719
step   1430 | loss 1.3564 | lr 3.00e-04 | grad 2.00 | tok/s 16000
step   1440 | loss 1.1606 | lr 3.00e-04 | grad 2.00 | tok/s 16522
step   1450 | loss 1.1753 | lr 3.00e-04 | grad 4.50 | tok/s 16637
step   1460 | loss 1.6948 | lr 3.00e-04 | grad 2.16 | tok/s 15711
step   1470 | loss 1.5378 | lr 3.00e-04 | grad 1.90 | tok/s 16262
step   1480 | loss 1.8454 | lr 3.00e-04 | grad 4.22 | tok/s 16327
step   1490 | loss 1.5865 | lr 3.00e-04 | grad 1.81 | tok/s 16624
step   1500 | loss 1.3533 | lr 3.00e-04 | grad 1.89 | tok/s 16678
step   1510 | loss 1.5438 | lr 3.00e-04 | grad 2.08 | tok/s 16441
step   1520 | loss 1.4441 | lr 3.00e-04 | grad 3.55 | tok/s 16117
step   1530 | loss 1.4722 | lr 3.00e-04 | grad 1.79 | tok/s 16495
step   1540 | loss 1.6478 | lr 3.00e-04 | grad 2.41 | tok/s 15530
step   1550 | loss 1.3050 | lr 3.00e-04 | grad 2.36 | tok/s 16554
step   1560 | loss 1.6028 | lr 3.00e-04 | grad 2.67 | tok/s 14919
step   1570 | loss 1.2994 | lr 3.00e-04 | grad 2.19 | tok/s 16689
step   1580 | loss 1.7443 | lr 3.00e-04 | grad 4.25 | tok/s 16301
step   1590 | loss 1.6098 | lr 3.00e-04 | grad 2.50 | tok/s 15676
step   1600 | loss 1.0175 | lr 3.00e-04 | grad 1.60 | tok/s 16702
step   1610 | loss 1.0435 | lr 3.00e-04 | grad 2.50 | tok/s 16158
step   1620 | loss 1.4277 | lr 3.00e-04 | grad 2.88 | tok/s 15166
step   1630 | loss 1.3613 | lr 3.00e-04 | grad 2.20 | tok/s 16224
step   1640 | loss 1.3484 | lr 3.00e-04 | grad 2.31 | tok/s 15836
step   1650 | loss 1.5521 | lr 3.00e-04 | grad 2.56 | tok/s 15179
step   1660 | loss 1.4118 | lr 3.00e-04 | grad 1.78 | tok/s 16201
step   1670 | loss 1.3915 | lr 3.00e-04 | grad 6.12 | tok/s 16150
step   1680 | loss 1.7535 | lr 3.00e-04 | grad 2.03 | tok/s 15514
step   1690 | loss 1.5112 | lr 3.00e-04 | grad 4.34 | tok/s 15781
step   1700 | loss 1.5325 | lr 3.00e-04 | grad 2.36 | tok/s 15478
step   1710 | loss 1.4485 | lr 3.00e-04 | grad 2.27 | tok/s 15837
step   1720 | loss 1.5376 | lr 3.00e-04 | grad 2.78 | tok/s 16513
step   1730 | loss 1.2497 | lr 3.00e-04 | grad 2.84 | tok/s 16669
step   1740 | loss 1.3500 | lr 3.00e-04 | grad 2.72 | tok/s 16270
step   1750 | loss 1.5977 | lr 3.00e-04 | grad 2.62 | tok/s 15965
step   1760 | loss 1.5644 | lr 3.00e-04 | grad 2.31 | tok/s 16058
step   1770 | loss 1.4543 | lr 3.00e-04 | grad 2.44 | tok/s 15770
step   1780 | loss 1.5320 | lr 3.00e-04 | grad 1.88 | tok/s 16385
step   1790 | loss 1.4166 | lr 3.00e-04 | grad 1.74 | tok/s 15987
step   1800 | loss 1.6474 | lr 3.00e-04 | grad 2.89 | tok/s 16098
step   1810 | loss 1.4827 | lr 3.00e-04 | grad 2.09 | tok/s 15519
step   1820 | loss 1.5034 | lr 3.00e-04 | grad 5.09 | tok/s 15729
step   1830 | loss 1.4379 | lr 3.00e-04 | grad 2.39 | tok/s 16384
step   1840 | loss 1.5651 | lr 3.00e-04 | grad 2.73 | tok/s 15684
step   1850 | loss 1.3085 | lr 3.00e-04 | grad 1.83 | tok/s 15517
step   1860 | loss 1.3410 | lr 3.00e-04 | grad 2.39 | tok/s 15879
step   1870 | loss 1.4363 | lr 3.00e-04 | grad 3.19 | tok/s 15942
step   1880 | loss 1.2570 | lr 3.00e-04 | grad 2.25 | tok/s 15631
step   1890 | loss 1.5247 | lr 3.00e-04 | grad 1.96 | tok/s 14861
step   1900 | loss 1.4094 | lr 3.00e-04 | grad 2.56 | tok/s 16058
step   1910 | loss 1.4910 | lr 3.00e-04 | grad 2.78 | tok/s 15215
step   1920 | loss 1.4110 | lr 3.00e-04 | grad 2.03 | tok/s 16663
step   1930 | loss 1.4738 | lr 3.00e-04 | grad 2.50 | tok/s 15640
step   1940 | loss 1.4557 | lr 3.00e-04 | grad 2.08 | tok/s 16260
step   1950 | loss 1.8959 | lr 3.00e-04 | grad 3.89 | tok/s 16500
step   1960 | loss 1.4734 | lr 3.00e-04 | grad 4.44 | tok/s 16669
step   1970 | loss 1.5540 | lr 3.00e-04 | grad 2.53 | tok/s 16257
step   1980 | loss 1.5719 | lr 3.00e-04 | grad 2.14 | tok/s 15543
step   1990 | loss 1.6606 | lr 3.00e-04 | grad 13.75 | tok/s 15267
step   2000 | loss 1.5126 | lr 3.00e-04 | grad 2.09 | tok/s 16071
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5126.pt
step   2010 | loss 1.0960 | lr 3.00e-04 | grad 1.75 | tok/s 7564
step   2020 | loss 1.3230 | lr 3.00e-04 | grad 2.19 | tok/s 15992
step   2030 | loss 1.1192 | lr 3.00e-04 | grad 0.93 | tok/s 16809
step   2040 | loss 1.2480 | lr 3.00e-04 | grad 2.11 | tok/s 16773
step   2050 | loss 1.2100 | lr 3.00e-04 | grad 2.30 | tok/s 16418
step   2060 | loss 1.5819 | lr 3.00e-04 | grad 2.28 | tok/s 15497
step   2070 | loss 1.6868 | lr 3.00e-04 | grad 2.38 | tok/s 16054
step   2080 | loss 2.2816 | lr 3.00e-04 | grad 4.38 | tok/s 16592
step   2090 | loss 1.7310 | lr 3.00e-04 | grad 4.31 | tok/s 16627
step   2100 | loss 1.4162 | lr 3.00e-04 | grad 2.69 | tok/s 16220
step   2110 | loss 1.5625 | lr 3.00e-04 | grad 23.75 | tok/s 15891
step   2120 | loss 0.9515 | lr 3.00e-04 | grad 1.54 | tok/s 16444
step   2130 | loss 1.0681 | lr 3.00e-04 | grad 3.25 | tok/s 15830
step   2140 | loss 1.5798 | lr 3.00e-04 | grad 1.88 | tok/s 15917
step   2150 | loss 1.3031 | lr 3.00e-04 | grad 1.98 | tok/s 16704
step   2160 | loss 1.2024 | lr 3.00e-04 | grad 1.66 | tok/s 16727
step   2170 | loss 1.2491 | lr 3.00e-04 | grad 1.65 | tok/s 16703
step   2180 | loss 1.2021 | lr 3.00e-04 | grad 1.91 | tok/s 16706
step   2190 | loss 1.2156 | lr 3.00e-04 | grad 1.60 | tok/s 16694
step   2200 | loss 1.2032 | lr 3.00e-04 | grad 1.79 | tok/s 16690
step   2210 | loss 1.1535 | lr 3.00e-04 | grad 1.62 | tok/s 16697
step   2220 | loss 1.1526 | lr 3.00e-04 | grad 1.64 | tok/s 16731
step   2230 | loss 1.3679 | lr 3.00e-04 | grad 2.03 | tok/s 16440
step   2240 | loss 1.3356 | lr 3.00e-04 | grad 1.80 | tok/s 16688
step   2250 | loss 1.5908 | lr 3.00e-04 | grad 3.34 | tok/s 16127
step   2260 | loss 1.6426 | lr 3.00e-04 | grad 2.25 | tok/s 16309
step   2270 | loss 1.9493 | lr 3.00e-04 | grad 2.98 | tok/s 16580
step   2280 | loss 1.4871 | lr 3.00e-04 | grad 2.42 | tok/s 15994
step   2290 | loss 1.2995 | lr 3.00e-04 | grad 2.80 | tok/s 16135
step   2300 | loss 1.6556 | lr 3.00e-04 | grad 4.62 | tok/s 16475
step   2310 | loss 1.4052 | lr 3.00e-04 | grad 1.76 | tok/s 15657
step   2320 | loss 1.6497 | lr 3.00e-04 | grad 4.28 | tok/s 15708
step   2330 | loss 1.8451 | lr 3.00e-04 | grad 2.14 | tok/s 16008
step   2340 | loss 1.4492 | lr 3.00e-04 | grad 6.00 | tok/s 15560
step   2350 | loss 1.3595 | lr 3.00e-04 | grad 4.72 | tok/s 16334
step   2360 | loss 1.3315 | lr 3.00e-04 | grad 2.39 | tok/s 16544

Training complete! Final step: 2367
