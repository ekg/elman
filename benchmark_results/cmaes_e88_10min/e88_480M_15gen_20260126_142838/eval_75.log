Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_75/levelE88_100m_20260126_160128
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 486,304,560 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1195 | lr 3.00e-04 | grad 20.50 | tok/s 5872
step     20 | loss 2.9917 | lr 3.00e-04 | grad 12.25 | tok/s 17393
step     30 | loss 2.7109 | lr 3.00e-04 | grad 7.56 | tok/s 17600
step     40 | loss 2.4866 | lr 3.00e-04 | grad 4.97 | tok/s 16779
step     50 | loss 3.0709 | lr 3.00e-04 | grad 15.56 | tok/s 17062
step     60 | loss 2.0933 | lr 3.00e-04 | grad 4.53 | tok/s 17607
step     70 | loss 1.9091 | lr 3.00e-04 | grad 5.75 | tok/s 17768
step     80 | loss 6.9652 | lr 3.00e-04 | grad 70.50 | tok/s 17864
step     90 | loss 6.5409 | lr 3.00e-04 | grad 10.31 | tok/s 18167
step    100 | loss 4.3061 | lr 3.00e-04 | grad 10.44 | tok/s 18162
step    110 | loss 3.7157 | lr 3.00e-04 | grad 32.25 | tok/s 18140
step    120 | loss 3.2348 | lr 3.00e-04 | grad 16.50 | tok/s 18130
step    130 | loss 2.9935 | lr 3.00e-04 | grad 19.75 | tok/s 18096
step    140 | loss 2.8087 | lr 3.00e-04 | grad 13.19 | tok/s 18086
step    150 | loss 2.8239 | lr 3.00e-04 | grad 22.50 | tok/s 18053
step    160 | loss 2.4162 | lr 3.00e-04 | grad 10.75 | tok/s 18015
step    170 | loss 2.5177 | lr 3.00e-04 | grad 13.12 | tok/s 17991
step    180 | loss 2.3532 | lr 3.00e-04 | grad 10.50 | tok/s 17996
step    190 | loss 2.5804 | lr 3.00e-04 | grad 17.50 | tok/s 18012
step    200 | loss 2.1449 | lr 3.00e-04 | grad 6.69 | tok/s 18009
step    210 | loss 2.2052 | lr 3.00e-04 | grad 9.94 | tok/s 17986
step    220 | loss 2.2195 | lr 3.00e-04 | grad 4.72 | tok/s 16435
step    230 | loss 2.1193 | lr 3.00e-04 | grad 4.44 | tok/s 17576
step    240 | loss 2.3222 | lr 3.00e-04 | grad 6.06 | tok/s 16677
step    250 | loss 2.1291 | lr 3.00e-04 | grad 3.02 | tok/s 17167
step    260 | loss 1.5634 | lr 3.00e-04 | grad 3.55 | tok/s 17673
step    270 | loss 2.1084 | lr 3.00e-04 | grad 3.44 | tok/s 17444
step    280 | loss 2.2558 | lr 3.00e-04 | grad 6.62 | tok/s 17118
step    290 | loss 1.4518 | lr 3.00e-04 | grad 4.03 | tok/s 17984
step    300 | loss 0.5677 | lr 3.00e-04 | grad 3.38 | tok/s 17974
step    310 | loss 2.4437 | lr 3.00e-04 | grad 4.69 | tok/s 17696
step    320 | loss 1.9599 | lr 3.00e-04 | grad 6.81 | tok/s 17340
step    330 | loss 1.9669 | lr 3.00e-04 | grad 3.16 | tok/s 16728
step    340 | loss 2.3080 | lr 3.00e-04 | grad 3.45 | tok/s 17005
step    350 | loss 1.8616 | lr 3.00e-04 | grad 4.53 | tok/s 17410
step    360 | loss 1.2173 | lr 3.00e-04 | grad 7.84 | tok/s 17821
step    370 | loss 1.8187 | lr 3.00e-04 | grad 2.98 | tok/s 16154
step    380 | loss 1.7647 | lr 3.00e-04 | grad 3.05 | tok/s 17209
step    390 | loss 1.5376 | lr 3.00e-04 | grad 2.61 | tok/s 17955
step    400 | loss 1.4951 | lr 3.00e-04 | grad 3.17 | tok/s 17788
step    410 | loss 1.2787 | lr 3.00e-04 | grad 2.31 | tok/s 17389
step    420 | loss 1.8227 | lr 3.00e-04 | grad 5.00 | tok/s 16603
step    430 | loss 2.1607 | lr 3.00e-04 | grad 3.44 | tok/s 17644
step    440 | loss 2.1711 | lr 3.00e-04 | grad 4.34 | tok/s 16663
step    450 | loss 2.1180 | lr 3.00e-04 | grad 2.97 | tok/s 17257
step    460 | loss 1.7220 | lr 3.00e-04 | grad 3.33 | tok/s 16895
step    470 | loss 1.8366 | lr 3.00e-04 | grad 3.08 | tok/s 17396
step    480 | loss 2.2529 | lr 3.00e-04 | grad 6.78 | tok/s 17393
step    490 | loss 1.8031 | lr 3.00e-04 | grad 2.75 | tok/s 16459
step    500 | loss 1.6808 | lr 3.00e-04 | grad 4.12 | tok/s 17574
step    510 | loss 1.7164 | lr 3.00e-04 | grad 3.02 | tok/s 17808
step    520 | loss 1.6653 | lr 3.00e-04 | grad 2.47 | tok/s 17788
step    530 | loss 1.9106 | lr 3.00e-04 | grad 2.67 | tok/s 17111
step    540 | loss 1.7442 | lr 3.00e-04 | grad 2.77 | tok/s 17113
step    550 | loss 1.5786 | lr 3.00e-04 | grad 3.09 | tok/s 16756
step    560 | loss 1.7382 | lr 3.00e-04 | grad 2.92 | tok/s 16314
step    570 | loss 1.6625 | lr 3.00e-04 | grad 4.03 | tok/s 16752
step    580 | loss 1.5530 | lr 3.00e-04 | grad 2.59 | tok/s 16712
step    590 | loss 1.8518 | lr 3.00e-04 | grad 3.33 | tok/s 17128
step    600 | loss 1.8334 | lr 3.00e-04 | grad 2.52 | tok/s 16534
step    610 | loss 1.6327 | lr 3.00e-04 | grad 2.75 | tok/s 17391
step    620 | loss 1.5528 | lr 3.00e-04 | grad 2.67 | tok/s 16463
step    630 | loss 1.6599 | lr 3.00e-04 | grad 4.78 | tok/s 16623
step    640 | loss 1.8328 | lr 3.00e-04 | grad 2.69 | tok/s 17064
step    650 | loss 1.6793 | lr 3.00e-04 | grad 2.91 | tok/s 17154
step    660 | loss 1.7039 | lr 3.00e-04 | grad 2.20 | tok/s 17212
step    670 | loss 1.9316 | lr 3.00e-04 | grad 4.47 | tok/s 17353
step    680 | loss 1.7384 | lr 3.00e-04 | grad 2.69 | tok/s 17015
step    690 | loss 1.8347 | lr 3.00e-04 | grad 3.66 | tok/s 17581
step    700 | loss 1.4171 | lr 3.00e-04 | grad 3.28 | tok/s 17930
step    710 | loss 1.5947 | lr 3.00e-04 | grad 2.75 | tok/s 16732
step    720 | loss 1.4728 | lr 3.00e-04 | grad 3.73 | tok/s 16480
step    730 | loss 1.2917 | lr 3.00e-04 | grad 3.09 | tok/s 17886
step    740 | loss 1.5019 | lr 3.00e-04 | grad 2.59 | tok/s 17645
step    750 | loss 1.2008 | lr 3.00e-04 | grad 2.80 | tok/s 17910
step    760 | loss 1.1133 | lr 3.00e-04 | grad 2.33 | tok/s 17912
step    770 | loss 1.0616 | lr 3.00e-04 | grad 2.36 | tok/s 17928
step    780 | loss 0.9998 | lr 3.00e-04 | grad 2.12 | tok/s 17900
step    790 | loss 1.1339 | lr 3.00e-04 | grad 3.69 | tok/s 17354
step    800 | loss 1.8246 | lr 3.00e-04 | grad 5.97 | tok/s 17302
step    810 | loss 1.7015 | lr 3.00e-04 | grad 2.34 | tok/s 16194
step    820 | loss 1.7249 | lr 3.00e-04 | grad 4.34 | tok/s 16537
step    830 | loss 1.5054 | lr 3.00e-04 | grad 2.62 | tok/s 17745
step    840 | loss 1.3563 | lr 3.00e-04 | grad 2.45 | tok/s 17918
step    850 | loss 1.5796 | lr 3.00e-04 | grad 2.34 | tok/s 17813
step    860 | loss 1.4775 | lr 3.00e-04 | grad 4.38 | tok/s 17655
step    870 | loss 1.5137 | lr 3.00e-04 | grad 2.86 | tok/s 17026
step    880 | loss 1.6974 | lr 3.00e-04 | grad 2.92 | tok/s 17072
step    890 | loss 1.6940 | lr 3.00e-04 | grad 3.34 | tok/s 17309
step    900 | loss 1.5774 | lr 3.00e-04 | grad 2.84 | tok/s 17320
step    910 | loss 1.4316 | lr 3.00e-04 | grad 4.25 | tok/s 16971
step    920 | loss 1.5401 | lr 3.00e-04 | grad 3.78 | tok/s 17639
step    930 | loss 1.6125 | lr 3.00e-04 | grad 3.75 | tok/s 16825
step    940 | loss 1.3841 | lr 3.00e-04 | grad 2.17 | tok/s 17745
step    950 | loss 1.5195 | lr 3.00e-04 | grad 2.95 | tok/s 17828
step    960 | loss 1.3382 | lr 3.00e-04 | grad 2.88 | tok/s 17865
step    970 | loss 1.7689 | lr 3.00e-04 | grad 4.09 | tok/s 16800
step    980 | loss 1.6611 | lr 3.00e-04 | grad 2.69 | tok/s 17257
step    990 | loss 1.4590 | lr 3.00e-04 | grad 2.42 | tok/s 17557
step   1000 | loss 1.8658 | lr 3.00e-04 | grad 10.25 | tok/s 16854
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8658.pt
step   1010 | loss 1.6567 | lr 3.00e-04 | grad 3.78 | tok/s 6731
step   1020 | loss 1.6640 | lr 3.00e-04 | grad 2.27 | tok/s 16543
step   1030 | loss 1.4555 | lr 3.00e-04 | grad 2.39 | tok/s 17178
step   1040 | loss 1.4869 | lr 3.00e-04 | grad 2.55 | tok/s 17704
step   1050 | loss 1.6310 | lr 3.00e-04 | grad 3.70 | tok/s 16391
step   1060 | loss 1.7357 | lr 3.00e-04 | grad 3.48 | tok/s 17729
step   1070 | loss 1.6355 | lr 3.00e-04 | grad 3.00 | tok/s 17654
step   1080 | loss 1.4104 | lr 3.00e-04 | grad 2.22 | tok/s 16045
step   1090 | loss 1.1068 | lr 3.00e-04 | grad 1.55 | tok/s 17660
step   1100 | loss 1.4511 | lr 3.00e-04 | grad 4.16 | tok/s 17158
step   1110 | loss 1.4748 | lr 3.00e-04 | grad 2.48 | tok/s 17987
step   1120 | loss 1.3357 | lr 3.00e-04 | grad 2.64 | tok/s 17980
step   1130 | loss 1.2933 | lr 3.00e-04 | grad 2.27 | tok/s 17987
step   1140 | loss 1.2850 | lr 3.00e-04 | grad 2.45 | tok/s 17989
step   1150 | loss 1.2999 | lr 3.00e-04 | grad 2.16 | tok/s 17973
step   1160 | loss 1.2123 | lr 3.00e-04 | grad 2.12 | tok/s 17992
step   1170 | loss 1.2400 | lr 3.00e-04 | grad 2.50 | tok/s 17992
step   1180 | loss 1.3394 | lr 3.00e-04 | grad 1.87 | tok/s 17979
step   1190 | loss 1.2165 | lr 3.00e-04 | grad 2.62 | tok/s 17979
step   1200 | loss 1.2108 | lr 3.00e-04 | grad 2.33 | tok/s 17964
step   1210 | loss 1.2681 | lr 3.00e-04 | grad 2.33 | tok/s 17968
step   1220 | loss 1.2924 | lr 3.00e-04 | grad 2.25 | tok/s 17941
step   1230 | loss 1.2578 | lr 3.00e-04 | grad 2.20 | tok/s 17978
step   1240 | loss 1.2216 | lr 3.00e-04 | grad 1.77 | tok/s 17944
step   1250 | loss 1.8140 | lr 3.00e-04 | grad 3.95 | tok/s 17017
step   1260 | loss 1.3916 | lr 3.00e-04 | grad 4.06 | tok/s 15910
step   1270 | loss 1.6729 | lr 3.00e-04 | grad 5.94 | tok/s 16791
step   1280 | loss 1.6315 | lr 3.00e-04 | grad 2.12 | tok/s 17281
step   1290 | loss 1.4846 | lr 3.00e-04 | grad 2.47 | tok/s 17168
step   1300 | loss 1.5308 | lr 3.00e-04 | grad 2.66 | tok/s 17310
step   1310 | loss 1.4657 | lr 3.00e-04 | grad 2.86 | tok/s 17581
step   1320 | loss 1.5878 | lr 3.00e-04 | grad 2.58 | tok/s 17643
step   1330 | loss 1.6163 | lr 3.00e-04 | grad 2.70 | tok/s 17651
step   1340 | loss 1.4883 | lr 3.00e-04 | grad 9.75 | tok/s 16866
step   1350 | loss 1.7497 | lr 3.00e-04 | grad 2.91 | tok/s 16295
step   1360 | loss 1.5005 | lr 3.00e-04 | grad 2.84 | tok/s 17309
step   1370 | loss 1.4198 | lr 3.00e-04 | grad 1.98 | tok/s 17070
step   1380 | loss 1.6769 | lr 3.00e-04 | grad 2.52 | tok/s 16409
step   1390 | loss 1.5319 | lr 3.00e-04 | grad 2.14 | tok/s 17422
step   1400 | loss 1.4100 | lr 3.00e-04 | grad 1.90 | tok/s 16819
step   1410 | loss 1.4638 | lr 3.00e-04 | grad 3.50 | tok/s 16888
step   1420 | loss 1.6976 | lr 3.00e-04 | grad 4.88 | tok/s 16894
step   1430 | loss 1.3443 | lr 3.00e-04 | grad 2.12 | tok/s 17158
step   1440 | loss 1.1501 | lr 3.00e-04 | grad 2.64 | tok/s 17765
step   1450 | loss 1.1696 | lr 3.00e-04 | grad 5.09 | tok/s 17895
step   1460 | loss 1.6802 | lr 3.00e-04 | grad 2.47 | tok/s 16889
step   1470 | loss 1.5346 | lr 3.00e-04 | grad 2.11 | tok/s 17512
step   1480 | loss 1.8216 | lr 3.00e-04 | grad 4.84 | tok/s 17578
step   1490 | loss 1.5676 | lr 3.00e-04 | grad 2.00 | tok/s 17875
step   1500 | loss 1.3389 | lr 3.00e-04 | grad 2.22 | tok/s 17936
step   1510 | loss 1.5295 | lr 3.00e-04 | grad 2.44 | tok/s 17673
step   1520 | loss 1.4324 | lr 3.00e-04 | grad 4.38 | tok/s 17312
step   1530 | loss 1.4642 | lr 3.00e-04 | grad 2.25 | tok/s 17739
step   1540 | loss 1.6339 | lr 3.00e-04 | grad 2.66 | tok/s 16700
step   1550 | loss 1.2929 | lr 3.00e-04 | grad 2.67 | tok/s 17822
step   1560 | loss 1.5935 | lr 3.00e-04 | grad 3.14 | tok/s 16867
step   1570 | loss 1.2792 | lr 3.00e-04 | grad 2.62 | tok/s 17926
step   1580 | loss 1.7056 | lr 3.00e-04 | grad 4.16 | tok/s 17531
step   1590 | loss 1.5966 | lr 3.00e-04 | grad 2.78 | tok/s 16844
step   1600 | loss 1.0105 | lr 3.00e-04 | grad 1.85 | tok/s 17967
step   1610 | loss 1.0389 | lr 3.00e-04 | grad 2.92 | tok/s 16766
step   1620 | loss 1.4104 | lr 3.00e-04 | grad 3.02 | tok/s 16313
step   1630 | loss 1.3558 | lr 3.00e-04 | grad 2.67 | tok/s 17444
step   1640 | loss 1.3355 | lr 3.00e-04 | grad 2.67 | tok/s 17036
step   1650 | loss 1.5360 | lr 3.00e-04 | grad 2.70 | tok/s 16340
step   1660 | loss 1.3921 | lr 3.00e-04 | grad 1.95 | tok/s 17422
step   1670 | loss 1.3573 | lr 3.00e-04 | grad 6.06 | tok/s 17386
step   1680 | loss 1.7427 | lr 3.00e-04 | grad 2.33 | tok/s 16696
step   1690 | loss 1.4943 | lr 3.00e-04 | grad 4.31 | tok/s 17018
step   1700 | loss 1.5041 | lr 3.00e-04 | grad 2.61 | tok/s 17358
step   1710 | loss 1.4350 | lr 3.00e-04 | grad 2.45 | tok/s 17022
step   1720 | loss 1.5381 | lr 3.00e-04 | grad 3.14 | tok/s 17758
step   1730 | loss 1.2132 | lr 3.00e-04 | grad 3.06 | tok/s 17941
step   1740 | loss 1.3262 | lr 3.00e-04 | grad 2.88 | tok/s 17487
step   1750 | loss 1.5879 | lr 3.00e-04 | grad 3.11 | tok/s 17181
step   1760 | loss 1.5550 | lr 3.00e-04 | grad 2.52 | tok/s 17251
step   1770 | loss 1.4436 | lr 3.00e-04 | grad 2.73 | tok/s 16940
step   1780 | loss 1.5141 | lr 3.00e-04 | grad 2.20 | tok/s 17640
step   1790 | loss 1.4114 | lr 3.00e-04 | grad 2.02 | tok/s 17160
step   1800 | loss 1.6284 | lr 3.00e-04 | grad 2.64 | tok/s 17321
step   1810 | loss 1.4456 | lr 3.00e-04 | grad 2.42 | tok/s 16667
step   1820 | loss 1.5015 | lr 3.00e-04 | grad 6.38 | tok/s 16897
step   1830 | loss 1.4291 | lr 3.00e-04 | grad 2.58 | tok/s 17619
step   1840 | loss 1.5530 | lr 3.00e-04 | grad 3.20 | tok/s 16875
step   1850 | loss 1.2937 | lr 3.00e-04 | grad 2.16 | tok/s 17648
step   1860 | loss 1.3360 | lr 3.00e-04 | grad 2.72 | tok/s 16324
step   1870 | loss 1.4229 | lr 3.00e-04 | grad 3.23 | tok/s 17161
step   1880 | loss 1.2411 | lr 3.00e-04 | grad 2.34 | tok/s 16794
step   1890 | loss 1.5238 | lr 3.00e-04 | grad 2.38 | tok/s 15957
step   1900 | loss 1.4059 | lr 3.00e-04 | grad 2.89 | tok/s 17278
step   1910 | loss 1.4858 | lr 3.00e-04 | grad 3.08 | tok/s 16386
step   1920 | loss 1.4028 | lr 3.00e-04 | grad 2.31 | tok/s 17913
step   1930 | loss 1.4641 | lr 3.00e-04 | grad 2.55 | tok/s 16834
step   1940 | loss 1.4512 | lr 3.00e-04 | grad 2.36 | tok/s 17519
step   1950 | loss 1.8785 | lr 3.00e-04 | grad 4.09 | tok/s 17764
step   1960 | loss 1.4519 | lr 3.00e-04 | grad 4.78 | tok/s 17919
step   1970 | loss 1.5212 | lr 3.00e-04 | grad 2.73 | tok/s 17504
step   1980 | loss 1.5549 | lr 3.00e-04 | grad 2.36 | tok/s 16724
step   1990 | loss 1.6229 | lr 3.00e-04 | grad 8.50 | tok/s 17056
step   2000 | loss 1.4979 | lr 3.00e-04 | grad 2.31 | tok/s 17278
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4979.pt
step   2010 | loss 1.1471 | lr 3.00e-04 | grad 1.98 | tok/s 6962
step   2020 | loss 1.3104 | lr 3.00e-04 | grad 2.38 | tok/s 17234
step   2030 | loss 1.1029 | lr 3.00e-04 | grad 1.03 | tok/s 18134
step   2040 | loss 1.2306 | lr 3.00e-04 | grad 2.30 | tok/s 18030
step   2050 | loss 1.2023 | lr 3.00e-04 | grad 2.53 | tok/s 17655
step   2060 | loss 1.5730 | lr 3.00e-04 | grad 2.62 | tok/s 16684
step   2070 | loss 1.6767 | lr 3.00e-04 | grad 2.94 | tok/s 17294
step   2080 | loss 2.2896 | lr 3.00e-04 | grad 6.12 | tok/s 17845
step   2090 | loss 1.7324 | lr 3.00e-04 | grad 5.62 | tok/s 17915
step   2100 | loss 1.4068 | lr 3.00e-04 | grad 3.00 | tok/s 17451
step   2110 | loss 1.5480 | lr 3.00e-04 | grad 25.62 | tok/s 17110
step   2120 | loss 0.9369 | lr 3.00e-04 | grad 2.27 | tok/s 17679
step   2130 | loss 1.0497 | lr 3.00e-04 | grad 3.77 | tok/s 17683
step   2140 | loss 1.5689 | lr 3.00e-04 | grad 2.33 | tok/s 17110
step   2150 | loss 1.2966 | lr 3.00e-04 | grad 2.50 | tok/s 17979
step   2160 | loss 1.1924 | lr 3.00e-04 | grad 1.92 | tok/s 17988
step   2170 | loss 1.2437 | lr 3.00e-04 | grad 1.80 | tok/s 17984
step   2180 | loss 1.1927 | lr 3.00e-04 | grad 2.44 | tok/s 17981
step   2190 | loss 1.2081 | lr 3.00e-04 | grad 2.06 | tok/s 17988
step   2200 | loss 1.1937 | lr 3.00e-04 | grad 1.97 | tok/s 17990
step   2210 | loss 1.1452 | lr 3.00e-04 | grad 1.88 | tok/s 17966
step   2220 | loss 1.1400 | lr 3.00e-04 | grad 1.84 | tok/s 17971
step   2230 | loss 1.3574 | lr 3.00e-04 | grad 2.20 | tok/s 17654
step   2240 | loss 1.3262 | lr 3.00e-04 | grad 2.17 | tok/s 17941
step   2250 | loss 1.5394 | lr 3.00e-04 | grad 3.67 | tok/s 17315
step   2260 | loss 1.5958 | lr 3.00e-04 | grad 2.55 | tok/s 17502
step   2270 | loss 1.9302 | lr 3.00e-04 | grad 3.38 | tok/s 17784
step   2280 | loss 1.4753 | lr 3.00e-04 | grad 2.61 | tok/s 17741
step   2290 | loss 1.2861 | lr 3.00e-04 | grad 2.95 | tok/s 17290
step   2300 | loss 1.7140 | lr 3.00e-04 | grad 4.75 | tok/s 17695
step   2310 | loss 1.4061 | lr 3.00e-04 | grad 1.98 | tok/s 16809
step   2320 | loss 1.6290 | lr 3.00e-04 | grad 5.25 | tok/s 16870
step   2330 | loss 1.8286 | lr 3.00e-04 | grad 2.83 | tok/s 17161
step   2340 | loss 1.4568 | lr 3.00e-04 | grad 6.91 | tok/s 16702
step   2350 | loss 1.3408 | lr 3.00e-04 | grad 4.97 | tok/s 17522
step   2360 | loss 1.3191 | lr 3.00e-04 | grad 2.72 | tok/s 17754
step   2370 | loss 1.4810 | lr 3.00e-04 | grad 4.03 | tok/s 17575
step   2380 | loss 1.4908 | lr 3.00e-04 | grad 2.77 | tok/s 17947
step   2390 | loss 1.1744 | lr 3.00e-04 | grad 2.12 | tok/s 17917
step   2400 | loss 1.1025 | lr 3.00e-04 | grad 1.90 | tok/s 17937
step   2410 | loss 1.1084 | lr 3.00e-04 | grad 2.48 | tok/s 17360
step   2420 | loss 1.4893 | lr 3.00e-04 | grad 4.75 | tok/s 16790
step   2430 | loss 1.4149 | lr 3.00e-04 | grad 2.22 | tok/s 17078
step   2440 | loss 1.2274 | lr 3.00e-04 | grad 4.12 | tok/s 16880
step   2450 | loss 1.4730 | lr 3.00e-04 | grad 2.72 | tok/s 17149
step   2460 | loss 1.3442 | lr 3.00e-04 | grad 2.66 | tok/s 17756
step   2470 | loss 1.1486 | lr 3.00e-04 | grad 2.61 | tok/s 17701
step   2480 | loss 1.2104 | lr 3.00e-04 | grad 1.85 | tok/s 17948
step   2490 | loss 1.3288 | lr 3.00e-04 | grad 2.22 | tok/s 16989
step   2500 | loss 1.5576 | lr 3.00e-04 | grad 2.59 | tok/s 17543
step   2510 | loss 1.1660 | lr 3.00e-04 | grad 3.41 | tok/s 17930
step   2520 | loss 1.3966 | lr 3.00e-04 | grad 5.53 | tok/s 17866
step   2530 | loss 1.3686 | lr 3.00e-04 | grad 2.39 | tok/s 17270
step   2540 | loss 1.4086 | lr 3.00e-04 | grad 3.20 | tok/s 17131

Training complete! Final step: 2540
