Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_26/levelE88_100m_20260126_145940
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 497,528,720 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.6097 | lr 3.00e-04 | grad 8.94 | tok/s 4902
step     20 | loss 2.6425 | lr 3.00e-04 | grad 4.78 | tok/s 9218
step     30 | loss 2.5549 | lr 3.00e-04 | grad 2.25 | tok/s 9323
step     40 | loss 2.3448 | lr 3.00e-04 | grad 2.34 | tok/s 8936
step     50 | loss 3.0890 | lr 3.00e-04 | grad 14.62 | tok/s 9055
step     60 | loss 2.1562 | lr 3.00e-04 | grad 2.88 | tok/s 8994
step     70 | loss 1.9926 | lr 3.00e-04 | grad 3.44 | tok/s 9466
step     80 | loss 4.9531 | lr 3.00e-04 | grad 82.50 | tok/s 9513
step     90 | loss 5.1148 | lr 3.00e-04 | grad 9.50 | tok/s 9667
step    100 | loss 4.5722 | lr 3.00e-04 | grad 12.75 | tok/s 9668
step    110 | loss 4.2381 | lr 3.00e-04 | grad 19.62 | tok/s 9668
step    120 | loss 3.8508 | lr 3.00e-04 | grad 20.62 | tok/s 9654
step    130 | loss 3.5769 | lr 3.00e-04 | grad 25.00 | tok/s 9661
step    140 | loss 2.8918 | lr 3.00e-04 | grad 14.44 | tok/s 9658
step    150 | loss 3.1912 | lr 3.00e-04 | grad 17.25 | tok/s 9656
step    160 | loss 2.4369 | lr 3.00e-04 | grad 13.12 | tok/s 9660
step    170 | loss 2.5602 | lr 3.00e-04 | grad 12.38 | tok/s 9662
step    180 | loss 2.3135 | lr 3.00e-04 | grad 3.02 | tok/s 9671
step    190 | loss 2.4951 | lr 3.00e-04 | grad 3.53 | tok/s 9668
step    200 | loss 2.2216 | lr 3.00e-04 | grad 7.62 | tok/s 9657
step    210 | loss 2.1559 | lr 3.00e-04 | grad 6.06 | tok/s 9664
step    220 | loss 2.2930 | lr 3.00e-04 | grad 1.91 | tok/s 9550
step    230 | loss 2.1519 | lr 3.00e-04 | grad 2.14 | tok/s 9429
step    240 | loss 2.2766 | lr 3.00e-04 | grad 3.00 | tok/s 8958
step    250 | loss 2.1177 | lr 3.00e-04 | grad 1.55 | tok/s 9216
step    260 | loss 1.6500 | lr 3.00e-04 | grad 1.80 | tok/s 9498
step    270 | loss 2.1112 | lr 3.00e-04 | grad 1.68 | tok/s 9367
step    280 | loss 2.2841 | lr 3.00e-04 | grad 3.28 | tok/s 9187
step    290 | loss 1.5425 | lr 3.00e-04 | grad 2.58 | tok/s 9681
step    300 | loss 0.6055 | lr 3.00e-04 | grad 3.34 | tok/s 9674
step    310 | loss 2.4257 | lr 3.00e-04 | grad 2.58 | tok/s 9507
step    320 | loss 2.0247 | lr 3.00e-04 | grad 3.69 | tok/s 9326
step    330 | loss 1.9480 | lr 3.00e-04 | grad 1.81 | tok/s 8995
step    340 | loss 2.2636 | lr 3.00e-04 | grad 1.73 | tok/s 8765
step    350 | loss 1.9380 | lr 3.00e-04 | grad 3.33 | tok/s 9376
step    360 | loss 1.3198 | lr 3.00e-04 | grad 4.69 | tok/s 9591
step    370 | loss 1.8320 | lr 3.00e-04 | grad 1.73 | tok/s 8676
step    380 | loss 1.7980 | lr 3.00e-04 | grad 1.52 | tok/s 9246
step    390 | loss 1.5625 | lr 3.00e-04 | grad 1.23 | tok/s 9652
step    400 | loss 1.5249 | lr 3.00e-04 | grad 1.61 | tok/s 9572
step    410 | loss 1.3345 | lr 3.00e-04 | grad 1.38 | tok/s 9364
step    420 | loss 1.8257 | lr 3.00e-04 | grad 2.81 | tok/s 8946
step    430 | loss 2.1573 | lr 3.00e-04 | grad 1.88 | tok/s 9508
step    440 | loss 2.1598 | lr 3.00e-04 | grad 2.78 | tok/s 8992
step    450 | loss 1.8674 | lr 3.00e-04 | grad 1.80 | tok/s 9309
step    460 | loss 1.7210 | lr 3.00e-04 | grad 1.96 | tok/s 9118
step    470 | loss 1.8378 | lr 3.00e-04 | grad 1.52 | tok/s 9389
step    480 | loss 2.2340 | lr 3.00e-04 | grad 4.44 | tok/s 9400
step    490 | loss 1.7884 | lr 3.00e-04 | grad 1.57 | tok/s 8861
step    500 | loss 1.6972 | lr 3.00e-04 | grad 2.23 | tok/s 9490
step    510 | loss 1.7187 | lr 3.00e-04 | grad 1.45 | tok/s 9332
step    520 | loss 1.6877 | lr 3.00e-04 | grad 1.34 | tok/s 9584
step    530 | loss 1.9133 | lr 3.00e-04 | grad 1.70 | tok/s 9207
step    540 | loss 1.7420 | lr 3.00e-04 | grad 1.40 | tok/s 9216
step    550 | loss 1.5807 | lr 3.00e-04 | grad 2.05 | tok/s 9028
step    560 | loss 1.7249 | lr 3.00e-04 | grad 1.77 | tok/s 8797
step    570 | loss 1.6608 | lr 3.00e-04 | grad 2.58 | tok/s 9029
step    580 | loss 1.5548 | lr 3.00e-04 | grad 1.45 | tok/s 8992
step    590 | loss 1.8667 | lr 3.00e-04 | grad 2.09 | tok/s 9230
step    600 | loss 1.8135 | lr 3.00e-04 | grad 1.53 | tok/s 8915
step    610 | loss 1.6306 | lr 3.00e-04 | grad 1.62 | tok/s 9374
step    620 | loss 1.5503 | lr 3.00e-04 | grad 1.62 | tok/s 8880
step    630 | loss 1.6642 | lr 3.00e-04 | grad 2.86 | tok/s 8804
step    640 | loss 1.8001 | lr 3.00e-04 | grad 1.71 | tok/s 9193
step    650 | loss 1.6528 | lr 3.00e-04 | grad 1.73 | tok/s 9251
step    660 | loss 1.7035 | lr 3.00e-04 | grad 1.41 | tok/s 9286
step    670 | loss 1.9018 | lr 3.00e-04 | grad 2.53 | tok/s 9345
step    680 | loss 1.7316 | lr 3.00e-04 | grad 1.66 | tok/s 9151
step    690 | loss 1.8213 | lr 3.00e-04 | grad 2.28 | tok/s 9470
step    700 | loss 1.4661 | lr 3.00e-04 | grad 2.08 | tok/s 9652
step    710 | loss 1.5819 | lr 3.00e-04 | grad 1.64 | tok/s 9010
step    720 | loss 1.4657 | lr 3.00e-04 | grad 2.69 | tok/s 8710
step    730 | loss 1.3229 | lr 3.00e-04 | grad 1.88 | tok/s 9646
step    740 | loss 1.5109 | lr 3.00e-04 | grad 1.62 | tok/s 9518
step    750 | loss 1.2332 | lr 3.00e-04 | grad 1.80 | tok/s 9663
step    760 | loss 1.1324 | lr 3.00e-04 | grad 1.62 | tok/s 9670
step    770 | loss 1.0769 | lr 3.00e-04 | grad 1.41 | tok/s 9676
step    780 | loss 1.0073 | lr 3.00e-04 | grad 1.45 | tok/s 9672
step    790 | loss 1.1279 | lr 3.00e-04 | grad 2.45 | tok/s 9354
step    800 | loss 1.8097 | lr 3.00e-04 | grad 4.22 | tok/s 9133
step    810 | loss 1.6869 | lr 3.00e-04 | grad 1.51 | tok/s 9281
step    820 | loss 1.6984 | lr 3.00e-04 | grad 2.75 | tok/s 8923
step    830 | loss 1.4902 | lr 3.00e-04 | grad 1.75 | tok/s 9557
step    840 | loss 1.4047 | lr 3.00e-04 | grad 1.63 | tok/s 9663
step    850 | loss 1.5905 | lr 3.00e-04 | grad 1.52 | tok/s 9612
step    860 | loss 1.4860 | lr 3.00e-04 | grad 2.61 | tok/s 9262
step    870 | loss 1.5079 | lr 3.00e-04 | grad 1.98 | tok/s 9164
step    880 | loss 1.6552 | lr 3.00e-04 | grad 1.92 | tok/s 9216
step    890 | loss 1.6688 | lr 3.00e-04 | grad 2.12 | tok/s 9332
step    900 | loss 1.5533 | lr 3.00e-04 | grad 1.84 | tok/s 9334
step    910 | loss 1.4133 | lr 3.00e-04 | grad 2.81 | tok/s 9142
step    920 | loss 1.5262 | lr 3.00e-04 | grad 2.66 | tok/s 9503
step    930 | loss 1.5831 | lr 3.00e-04 | grad 2.53 | tok/s 9085
step    940 | loss 1.3971 | lr 3.00e-04 | grad 1.27 | tok/s 9576
step    950 | loss 1.4821 | lr 3.00e-04 | grad 2.03 | tok/s 9615
step    960 | loss 1.3364 | lr 3.00e-04 | grad 1.84 | tok/s 9626
step    970 | loss 1.7126 | lr 3.00e-04 | grad 2.62 | tok/s 9057
step    980 | loss 1.6276 | lr 3.00e-04 | grad 1.64 | tok/s 9301
step    990 | loss 1.4508 | lr 3.00e-04 | grad 1.47 | tok/s 9469
step   1000 | loss 1.8029 | lr 3.00e-04 | grad 5.59 | tok/s 9087
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8029.pt
step   1010 | loss 1.6302 | lr 3.00e-04 | grad 2.28 | tok/s 4979
step   1020 | loss 1.6289 | lr 3.00e-04 | grad 1.30 | tok/s 8872
step   1030 | loss 1.4484 | lr 3.00e-04 | grad 1.43 | tok/s 9239
step   1040 | loss 1.4765 | lr 3.00e-04 | grad 1.58 | tok/s 9535
step   1050 | loss 1.5947 | lr 3.00e-04 | grad 2.36 | tok/s 8831
step   1060 | loss 1.7173 | lr 3.00e-04 | grad 2.62 | tok/s 9543
step   1070 | loss 1.6538 | lr 3.00e-04 | grad 1.95 | tok/s 9491
step   1080 | loss 1.3827 | lr 3.00e-04 | grad 1.41 | tok/s 8626
step   1090 | loss 1.0958 | lr 3.00e-04 | grad 0.92 | tok/s 9185
step   1100 | loss 1.4183 | lr 3.00e-04 | grad 2.42 | tok/s 9208
step   1110 | loss 1.4494 | lr 3.00e-04 | grad 1.39 | tok/s 9682
step   1120 | loss 1.3310 | lr 3.00e-04 | grad 1.48 | tok/s 9684
step   1130 | loss 1.2852 | lr 3.00e-04 | grad 1.35 | tok/s 9676
step   1140 | loss 1.2742 | lr 3.00e-04 | grad 1.53 | tok/s 9681
step   1150 | loss 1.2941 | lr 3.00e-04 | grad 1.27 | tok/s 9683
step   1160 | loss 1.2094 | lr 3.00e-04 | grad 1.30 | tok/s 9685
step   1170 | loss 1.2359 | lr 3.00e-04 | grad 1.53 | tok/s 9675
step   1180 | loss 1.3354 | lr 3.00e-04 | grad 1.22 | tok/s 9680
step   1190 | loss 1.2100 | lr 3.00e-04 | grad 1.52 | tok/s 9670
step   1200 | loss 1.2124 | lr 3.00e-04 | grad 1.47 | tok/s 9385
step   1210 | loss 1.2613 | lr 3.00e-04 | grad 1.46 | tok/s 9658
step   1220 | loss 1.2779 | lr 3.00e-04 | grad 1.45 | tok/s 9663
step   1230 | loss 1.2464 | lr 3.00e-04 | grad 1.23 | tok/s 9659
step   1240 | loss 1.2086 | lr 3.00e-04 | grad 1.17 | tok/s 9664
step   1250 | loss 1.7622 | lr 3.00e-04 | grad 2.56 | tok/s 9139
step   1260 | loss 1.3512 | lr 3.00e-04 | grad 11.62 | tok/s 9035
step   1270 | loss 1.6351 | lr 3.00e-04 | grad 3.47 | tok/s 9032
step   1280 | loss 1.5906 | lr 3.00e-04 | grad 1.38 | tok/s 9293
step   1290 | loss 1.4636 | lr 3.00e-04 | grad 1.48 | tok/s 9237
step   1300 | loss 1.5123 | lr 3.00e-04 | grad 1.85 | tok/s 9104
step   1310 | loss 1.4490 | lr 3.00e-04 | grad 1.70 | tok/s 9472
step   1320 | loss 1.5673 | lr 3.00e-04 | grad 1.61 | tok/s 9488
step   1330 | loss 1.5743 | lr 3.00e-04 | grad 1.62 | tok/s 9512
step   1340 | loss 1.4681 | lr 3.00e-04 | grad 7.66 | tok/s 9065
step   1350 | loss 1.6931 | lr 3.00e-04 | grad 1.69 | tok/s 8760
step   1360 | loss 1.4832 | lr 3.00e-04 | grad 1.66 | tok/s 9307
step   1370 | loss 1.3952 | lr 3.00e-04 | grad 1.10 | tok/s 9068
step   1380 | loss 1.6030 | lr 3.00e-04 | grad 1.84 | tok/s 8840

Training complete! Final step: 1384
