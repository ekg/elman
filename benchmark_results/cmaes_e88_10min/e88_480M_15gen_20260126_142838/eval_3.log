Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_3/levelE88_100m_20260126_142845
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 467,124,352 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.7542 | lr 3.00e-04 | grad 7.34 | tok/s 5921
step     20 | loss 2.7693 | lr 3.00e-04 | grad 1.85 | tok/s 7801
step     30 | loss 3.1639 | lr 3.00e-04 | grad 7.50 | tok/s 8208
step     40 | loss 4.0376 | lr 3.00e-04 | grad 49.00 | tok/s 8322
step     50 | loss 4.8792 | lr 3.00e-04 | grad 21.25 | tok/s 8366
step     60 | loss 4.3782 | lr 3.00e-04 | grad 12.00 | tok/s 8312
step     70 | loss 3.8454 | lr 3.00e-04 | grad 19.88 | tok/s 8263
step     80 | loss 3.0892 | lr 3.00e-04 | grad 10.75 | tok/s 8192
step     90 | loss 2.7839 | lr 3.00e-04 | grad 2.67 | tok/s 8131
step    100 | loss 2.8071 | lr 3.00e-04 | grad 1.62 | tok/s 7786
step    110 | loss 2.6708 | lr 3.00e-04 | grad 5.34 | tok/s 7843
step    120 | loss 2.4317 | lr 3.00e-04 | grad 1.54 | tok/s 7729
step    130 | loss 2.4899 | lr 3.00e-04 | grad 2.34 | tok/s 7665
step    140 | loss 2.0607 | lr 3.00e-04 | grad 1.57 | tok/s 7818
step    150 | loss 2.3965 | lr 3.00e-04 | grad 4.22 | tok/s 7668
step    160 | loss 2.4486 | lr 3.00e-04 | grad 2.84 | tok/s 7589
step    170 | loss 2.0476 | lr 3.00e-04 | grad 1.11 | tok/s 7732
step    180 | loss 2.0889 | lr 3.00e-04 | grad 1.38 | tok/s 7595
step    190 | loss 2.0571 | lr 3.00e-04 | grad 1.39 | tok/s 7433
step    200 | loss 1.9830 | lr 3.00e-04 | grad 1.60 | tok/s 7594
step    210 | loss 2.0390 | lr 3.00e-04 | grad 1.00 | tok/s 7498
step    220 | loss 2.0618 | lr 3.00e-04 | grad 1.09 | tok/s 7489
step    230 | loss 1.7947 | lr 3.00e-04 | grad 1.33 | tok/s 7890
step    240 | loss 1.5724 | lr 3.00e-04 | grad 1.34 | tok/s 7799
step    250 | loss 2.0554 | lr 3.00e-04 | grad 1.55 | tok/s 7629
step    260 | loss 1.8798 | lr 3.00e-04 | grad 1.16 | tok/s 7748
step    270 | loss 1.8841 | lr 3.00e-04 | grad 1.91 | tok/s 7755
step    280 | loss 1.8402 | lr 3.00e-04 | grad 1.60 | tok/s 7806
step    290 | loss 1.9093 | lr 3.00e-04 | grad 1.53 | tok/s 7725
step    300 | loss 1.9287 | lr 3.00e-04 | grad 1.15 | tok/s 7529
step    310 | loss 1.8700 | lr 3.00e-04 | grad 2.27 | tok/s 7660
step    320 | loss 1.6216 | lr 3.00e-04 | grad 1.38 | tok/s 7512
step    330 | loss 1.5691 | lr 3.00e-04 | grad 1.14 | tok/s 7945
step    340 | loss 1.4983 | lr 3.00e-04 | grad 1.18 | tok/s 7945
step    350 | loss 1.4670 | lr 3.00e-04 | grad 1.36 | tok/s 7941
step    360 | loss 1.6625 | lr 3.00e-04 | grad 1.13 | tok/s 7598
step    370 | loss 1.8305 | lr 3.00e-04 | grad 1.33 | tok/s 7687
step    380 | loss 1.8186 | lr 3.00e-04 | grad 1.34 | tok/s 7528
step    390 | loss 1.7832 | lr 3.00e-04 | grad 1.02 | tok/s 7617
step    400 | loss 1.7094 | lr 3.00e-04 | grad 1.04 | tok/s 7459
step    410 | loss 1.5980 | lr 3.00e-04 | grad 1.18 | tok/s 7719
step    420 | loss 2.0495 | lr 3.00e-04 | grad 1.80 | tok/s 7886
step    430 | loss 1.6896 | lr 3.00e-04 | grad 1.20 | tok/s 7700
step    440 | loss 1.9167 | lr 3.00e-04 | grad 1.75 | tok/s 7826
step    450 | loss 1.4368 | lr 3.00e-04 | grad 1.80 | tok/s 7603
step    460 | loss 1.5766 | lr 3.00e-04 | grad 0.99 | tok/s 7669
step    470 | loss 1.8952 | lr 3.00e-04 | grad 1.60 | tok/s 7497
step    480 | loss 1.7682 | lr 3.00e-04 | grad 1.20 | tok/s 7714
step    490 | loss 1.7415 | lr 3.00e-04 | grad 1.37 | tok/s 7670
step    500 | loss 1.6501 | lr 3.00e-04 | grad 3.05 | tok/s 7558
step    510 | loss 1.6682 | lr 3.00e-04 | grad 0.99 | tok/s 7827
step    520 | loss 1.5515 | lr 3.00e-04 | grad 1.09 | tok/s 7388
step    530 | loss 1.5770 | lr 3.00e-04 | grad 1.20 | tok/s 7633
step    540 | loss 2.0018 | lr 3.00e-04 | grad 2.73 | tok/s 7815
step    550 | loss 1.6624 | lr 3.00e-04 | grad 1.16 | tok/s 7592
step    560 | loss 1.4467 | lr 3.00e-04 | grad 1.50 | tok/s 7891
step    570 | loss 1.9388 | lr 3.00e-04 | grad 2.75 | tok/s 7717
step    580 | loss 1.6127 | lr 3.00e-04 | grad 1.33 | tok/s 7785

Training complete! Final step: 582
