Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min/e88_480M_15gen_20260126_142838/eval_71/levelE88_100m_20260126_155109
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 493,412,960 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1346 | lr 3.00e-04 | grad 11.75 | tok/s 5424
step     20 | loss 2.6041 | lr 3.00e-04 | grad 4.53 | tok/s 11518
step     30 | loss 2.4844 | lr 3.00e-04 | grad 2.81 | tok/s 11693
step     40 | loss 2.3393 | lr 3.00e-04 | grad 2.94 | tok/s 11182
step     50 | loss 2.9579 | lr 3.00e-04 | grad 10.06 | tok/s 11299
step     60 | loss 2.0404 | lr 3.00e-04 | grad 2.61 | tok/s 11663
step     70 | loss 1.8893 | lr 3.00e-04 | grad 3.86 | tok/s 11796
step     80 | loss 5.4539 | lr 3.00e-04 | grad 63.75 | tok/s 11829
step     90 | loss 5.1180 | lr 3.00e-04 | grad 8.88 | tok/s 12043
step    100 | loss 4.1896 | lr 3.00e-04 | grad 8.12 | tok/s 12081
step    110 | loss 3.6021 | lr 3.00e-04 | grad 12.50 | tok/s 12002
step    120 | loss 3.2060 | lr 3.00e-04 | grad 10.38 | tok/s 11984
step    130 | loss 2.8885 | lr 3.00e-04 | grad 12.19 | tok/s 11981
step    140 | loss 2.6737 | lr 3.00e-04 | grad 8.19 | tok/s 11967
step    150 | loss 2.6461 | lr 3.00e-04 | grad 8.25 | tok/s 11949
step    160 | loss 2.2733 | lr 3.00e-04 | grad 6.31 | tok/s 11943
step    170 | loss 2.3238 | lr 3.00e-04 | grad 8.69 | tok/s 11952
step    180 | loss 2.1318 | lr 3.00e-04 | grad 4.94 | tok/s 11951
step    190 | loss 2.2627 | lr 3.00e-04 | grad 8.62 | tok/s 11913
step    200 | loss 2.0065 | lr 3.00e-04 | grad 3.89 | tok/s 11943
step    210 | loss 1.9897 | lr 3.00e-04 | grad 3.92 | tok/s 11944
step    220 | loss 2.1169 | lr 3.00e-04 | grad 2.41 | tok/s 11776
step    230 | loss 2.0241 | lr 3.00e-04 | grad 2.66 | tok/s 11145
step    240 | loss 2.2370 | lr 3.00e-04 | grad 3.30 | tok/s 11078
step    250 | loss 2.0759 | lr 3.00e-04 | grad 1.83 | tok/s 11386
step    260 | loss 1.5539 | lr 3.00e-04 | grad 2.14 | tok/s 11750
step    270 | loss 2.0563 | lr 3.00e-04 | grad 2.05 | tok/s 11602
step    280 | loss 2.2410 | lr 3.00e-04 | grad 3.78 | tok/s 11364
step    290 | loss 1.3394 | lr 3.00e-04 | grad 2.44 | tok/s 11958
step    300 | loss 0.5608 | lr 3.00e-04 | grad 2.33 | tok/s 11964
step    310 | loss 2.3907 | lr 3.00e-04 | grad 2.91 | tok/s 11762
step    320 | loss 1.9303 | lr 3.00e-04 | grad 4.09 | tok/s 11533
step    330 | loss 1.9240 | lr 3.00e-04 | grad 2.12 | tok/s 11134
step    340 | loss 2.2358 | lr 3.00e-04 | grad 1.99 | tok/s 11298
step    350 | loss 1.8724 | lr 3.00e-04 | grad 3.42 | tok/s 11590
step    360 | loss 1.2292 | lr 3.00e-04 | grad 4.72 | tok/s 11838
step    370 | loss 1.7913 | lr 3.00e-04 | grad 1.98 | tok/s 10728
step    380 | loss 1.7546 | lr 3.00e-04 | grad 1.84 | tok/s 11448
step    390 | loss 1.5272 | lr 3.00e-04 | grad 1.49 | tok/s 11918
step    400 | loss 1.4871 | lr 3.00e-04 | grad 1.88 | tok/s 11846
step    410 | loss 1.2823 | lr 3.00e-04 | grad 1.51 | tok/s 11552
step    420 | loss 1.7984 | lr 3.00e-04 | grad 3.27 | tok/s 10755
step    430 | loss 2.1373 | lr 3.00e-04 | grad 2.22 | tok/s 11751
step    440 | loss 2.1322 | lr 3.00e-04 | grad 3.12 | tok/s 11117
step    450 | loss 1.9120 | lr 3.00e-04 | grad 2.03 | tok/s 11498
step    460 | loss 1.7074 | lr 3.00e-04 | grad 2.39 | tok/s 11238
step    470 | loss 1.8165 | lr 3.00e-04 | grad 1.72 | tok/s 11588
step    480 | loss 2.2211 | lr 3.00e-04 | grad 5.06 | tok/s 11595
step    490 | loss 1.7722 | lr 3.00e-04 | grad 1.81 | tok/s 10977
step    500 | loss 1.6701 | lr 3.00e-04 | grad 2.48 | tok/s 11698
step    510 | loss 1.6954 | lr 3.00e-04 | grad 1.71 | tok/s 11855
step    520 | loss 1.6541 | lr 3.00e-04 | grad 1.55 | tok/s 11822
step    530 | loss 1.8922 | lr 3.00e-04 | grad 1.92 | tok/s 11396
step    540 | loss 1.7204 | lr 3.00e-04 | grad 1.62 | tok/s 11381
step    550 | loss 1.5609 | lr 3.00e-04 | grad 2.12 | tok/s 11159
step    560 | loss 1.7055 | lr 3.00e-04 | grad 2.02 | tok/s 10375
step    570 | loss 1.6456 | lr 3.00e-04 | grad 2.91 | tok/s 11193
step    580 | loss 1.5344 | lr 3.00e-04 | grad 1.61 | tok/s 11130
step    590 | loss 1.8403 | lr 3.00e-04 | grad 2.33 | tok/s 11424
step    600 | loss 1.8017 | lr 3.00e-04 | grad 1.76 | tok/s 11033
step    610 | loss 1.6142 | lr 3.00e-04 | grad 1.77 | tok/s 11595
step    620 | loss 1.5354 | lr 3.00e-04 | grad 1.82 | tok/s 10979
step    630 | loss 1.6535 | lr 3.00e-04 | grad 3.44 | tok/s 11083
step    640 | loss 1.7989 | lr 3.00e-04 | grad 1.87 | tok/s 11383
step    650 | loss 1.6490 | lr 3.00e-04 | grad 1.95 | tok/s 11433
step    660 | loss 1.6787 | lr 3.00e-04 | grad 1.59 | tok/s 11482
step    670 | loss 1.8881 | lr 3.00e-04 | grad 2.81 | tok/s 11577
step    680 | loss 1.7110 | lr 3.00e-04 | grad 1.87 | tok/s 11322
step    690 | loss 1.8106 | lr 3.00e-04 | grad 2.52 | tok/s 11697
step    700 | loss 1.4209 | lr 3.00e-04 | grad 2.30 | tok/s 11938
step    710 | loss 1.5627 | lr 3.00e-04 | grad 1.82 | tok/s 11141
step    720 | loss 1.4588 | lr 3.00e-04 | grad 2.84 | tok/s 10990
step    730 | loss 1.2937 | lr 3.00e-04 | grad 2.12 | tok/s 11915
step    740 | loss 1.4899 | lr 3.00e-04 | grad 1.88 | tok/s 11771
step    750 | loss 1.1950 | lr 3.00e-04 | grad 1.96 | tok/s 11943
step    760 | loss 1.1023 | lr 3.00e-04 | grad 1.74 | tok/s 11952
step    770 | loss 1.0486 | lr 3.00e-04 | grad 1.57 | tok/s 11957
step    780 | loss 0.9822 | lr 3.00e-04 | grad 1.63 | tok/s 11942
step    790 | loss 1.1115 | lr 3.00e-04 | grad 2.53 | tok/s 11582
step    800 | loss 1.7920 | lr 3.00e-04 | grad 4.47 | tok/s 11528
step    810 | loss 1.6884 | lr 3.00e-04 | grad 1.65 | tok/s 11453
step    820 | loss 1.6842 | lr 3.00e-04 | grad 2.95 | tok/s 11002
step    830 | loss 1.4710 | lr 3.00e-04 | grad 1.91 | tok/s 11826
step    840 | loss 1.3752 | lr 3.00e-04 | grad 1.75 | tok/s 11944
step    850 | loss 1.5686 | lr 3.00e-04 | grad 1.59 | tok/s 11881
step    860 | loss 1.4632 | lr 3.00e-04 | grad 2.72 | tok/s 11744
step    870 | loss 1.4879 | lr 3.00e-04 | grad 2.06 | tok/s 11321
step    880 | loss 1.6531 | lr 3.00e-04 | grad 2.16 | tok/s 11369
step    890 | loss 1.6597 | lr 3.00e-04 | grad 2.31 | tok/s 11526
step    900 | loss 1.5411 | lr 3.00e-04 | grad 1.96 | tok/s 11538
step    910 | loss 1.4059 | lr 3.00e-04 | grad 2.97 | tok/s 11285
step    920 | loss 1.5106 | lr 3.00e-04 | grad 3.03 | tok/s 11744
step    930 | loss 1.5764 | lr 3.00e-04 | grad 2.81 | tok/s 11208
step    940 | loss 1.3760 | lr 3.00e-04 | grad 1.41 | tok/s 11821
step    950 | loss 1.4628 | lr 3.00e-04 | grad 2.25 | tok/s 11877
step    960 | loss 1.3117 | lr 3.00e-04 | grad 1.97 | tok/s 11895
step    970 | loss 1.7188 | lr 3.00e-04 | grad 2.86 | tok/s 11157
step    980 | loss 1.6190 | lr 3.00e-04 | grad 1.91 | tok/s 11482
step    990 | loss 1.4351 | lr 3.00e-04 | grad 1.67 | tok/s 11708
step   1000 | loss 1.8062 | lr 3.00e-04 | grad 6.69 | tok/s 11202
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8062.pt
step   1010 | loss 1.7048 | lr 3.00e-04 | grad 1.88 | tok/s 4992
step   1020 | loss 1.6591 | lr 3.00e-04 | grad 2.02 | tok/s 11052
step   1030 | loss 1.4045 | lr 3.00e-04 | grad 1.41 | tok/s 11548
step   1040 | loss 1.5070 | lr 3.00e-04 | grad 3.20 | tok/s 11758
step   1050 | loss 1.5789 | lr 3.00e-04 | grad 1.80 | tok/s 11050
step   1060 | loss 1.6815 | lr 3.00e-04 | grad 1.75 | tok/s 11801
step   1070 | loss 1.6419 | lr 3.00e-04 | grad 2.73 | tok/s 11624
step   1080 | loss 1.3836 | lr 3.00e-04 | grad 2.02 | tok/s 10752
step   1090 | loss 0.9856 | lr 3.00e-04 | grad 0.98 | tok/s 11911
step   1100 | loss 1.5384 | lr 3.00e-04 | grad 2.27 | tok/s 11418
step   1110 | loss 1.4053 | lr 3.00e-04 | grad 1.43 | tok/s 12022
step   1120 | loss 1.3229 | lr 3.00e-04 | grad 1.73 | tok/s 12008
step   1130 | loss 1.2698 | lr 3.00e-04 | grad 1.55 | tok/s 12000
step   1140 | loss 1.2764 | lr 3.00e-04 | grad 1.48 | tok/s 11989
step   1150 | loss 1.2795 | lr 3.00e-04 | grad 1.51 | tok/s 11984
step   1160 | loss 1.2040 | lr 3.00e-04 | grad 1.51 | tok/s 11990
step   1170 | loss 1.2404 | lr 3.00e-04 | grad 1.65 | tok/s 11984
step   1180 | loss 1.3046 | lr 3.00e-04 | grad 1.34 | tok/s 11997
step   1190 | loss 1.2006 | lr 3.00e-04 | grad 1.63 | tok/s 11975
step   1200 | loss 1.2104 | lr 3.00e-04 | grad 1.49 | tok/s 11996
step   1210 | loss 1.2431 | lr 3.00e-04 | grad 1.37 | tok/s 11973
step   1220 | loss 1.2667 | lr 3.00e-04 | grad 1.30 | tok/s 11973
step   1230 | loss 1.2398 | lr 3.00e-04 | grad 1.32 | tok/s 11971
step   1240 | loss 1.2429 | lr 3.00e-04 | grad 2.33 | tok/s 11856
step   1250 | loss 1.7409 | lr 3.00e-04 | grad 2.00 | tok/s 11338
step   1260 | loss 1.2969 | lr 3.00e-04 | grad 2.48 | tok/s 10790
step   1270 | loss 1.7401 | lr 3.00e-04 | grad 2.47 | tok/s 11148
step   1280 | loss 1.5466 | lr 3.00e-04 | grad 1.79 | tok/s 11658
step   1290 | loss 1.4666 | lr 3.00e-04 | grad 2.17 | tok/s 11451
step   1300 | loss 1.4995 | lr 3.00e-04 | grad 1.72 | tok/s 11342
step   1310 | loss 1.4395 | lr 3.00e-04 | grad 1.58 | tok/s 11899
step   1320 | loss 1.5617 | lr 3.00e-04 | grad 1.85 | tok/s 11752
step   1330 | loss 1.4993 | lr 3.00e-04 | grad 1.74 | tok/s 11766
step   1340 | loss 1.5558 | lr 3.00e-04 | grad 2.75 | tok/s 11112
step   1350 | loss 1.6787 | lr 3.00e-04 | grad 1.82 | tok/s 10975
step   1360 | loss 1.4613 | lr 3.00e-04 | grad 1.46 | tok/s 11526
step   1370 | loss 1.4687 | lr 3.00e-04 | grad 4.91 | tok/s 11391
step   1380 | loss 1.5527 | lr 3.00e-04 | grad 2.38 | tok/s 10934
step   1390 | loss 1.4635 | lr 3.00e-04 | grad 2.89 | tok/s 11542
step   1400 | loss 1.3490 | lr 3.00e-04 | grad 1.30 | tok/s 11257
step   1410 | loss 1.4836 | lr 3.00e-04 | grad 5.41 | tok/s 11235
step   1420 | loss 1.5990 | lr 3.00e-04 | grad 1.78 | tok/s 11204
step   1430 | loss 1.3275 | lr 3.00e-04 | grad 1.77 | tok/s 11365
step   1440 | loss 1.1196 | lr 3.00e-04 | grad 1.55 | tok/s 11964
step   1450 | loss 1.1492 | lr 3.00e-04 | grad 1.96 | tok/s 11516
step   1460 | loss 1.6462 | lr 3.00e-04 | grad 1.83 | tok/s 11141
step   1470 | loss 1.4909 | lr 3.00e-04 | grad 1.62 | tok/s 11843
step   1480 | loss 1.7805 | lr 3.00e-04 | grad 2.69 | tok/s 11731
step   1490 | loss 1.5198 | lr 3.00e-04 | grad 2.22 | tok/s 11925
step   1500 | loss 1.2905 | lr 3.00e-04 | grad 1.66 | tok/s 11925
step   1510 | loss 1.5206 | lr 3.00e-04 | grad 2.23 | tok/s 11801
step   1520 | loss 1.4113 | lr 3.00e-04 | grad 2.08 | tok/s 11537
step   1530 | loss 1.4074 | lr 3.00e-04 | grad 2.12 | tok/s 11821
step   1540 | loss 1.5890 | lr 3.00e-04 | grad 2.03 | tok/s 11107
step   1550 | loss 1.2516 | lr 3.00e-04 | grad 2.08 | tok/s 11857
step   1560 | loss 1.5640 | lr 3.00e-04 | grad 1.60 | tok/s 11231
step   1570 | loss 1.2547 | lr 3.00e-04 | grad 1.84 | tok/s 11836
step   1580 | loss 1.6642 | lr 3.00e-04 | grad 3.77 | tok/s 11773
step   1590 | loss 1.5522 | lr 3.00e-04 | grad 1.81 | tok/s 10838
step   1600 | loss 0.9013 | lr 3.00e-04 | grad 1.16 | tok/s 11961
step   1610 | loss 1.0856 | lr 3.00e-04 | grad 1.44 | tok/s 11273
step   1620 | loss 1.3630 | lr 3.00e-04 | grad 2.48 | tok/s 11114
step   1630 | loss 1.3315 | lr 3.00e-04 | grad 1.44 | tok/s 11651
step   1640 | loss 1.3320 | lr 3.00e-04 | grad 1.60 | tok/s 11271
step   1650 | loss 1.5252 | lr 3.00e-04 | grad 2.27 | tok/s 10640
step   1660 | loss 1.3127 | lr 3.00e-04 | grad 1.34 | tok/s 11935
step   1670 | loss 1.4177 | lr 3.00e-04 | grad 2.69 | tok/s 11478
step   1680 | loss 1.6343 | lr 3.00e-04 | grad 1.38 | tok/s 10972
step   1690 | loss 1.4662 | lr 3.00e-04 | grad 5.50 | tok/s 11495
step   1700 | loss 1.4791 | lr 3.00e-04 | grad 1.61 | tok/s 11419

Training complete! Final step: 1709
