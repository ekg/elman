Using device: cuda
Output directory: output/level51_100m_20260114_132626
Auto r_h_mode: spectral_norm (level 51 has full W_h)
Created Level 51 model: dim=768, depth=21, params=99,336,192
Model: Level 51, 99,336,192 parameters

Starting training from step 0...
Batch size: 8, Chunk size: 256
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.6301 | lr 9.00e-07 | grad 31.50 | tok/s 3922
step     20 | loss 5.0933 | lr 1.90e-06 | grad 14.51 | tok/s 8982
step     30 | loss 4.3121 | lr 2.90e-06 | grad 6.48 | tok/s 9247
step     40 | loss 3.9394 | lr 3.90e-06 | grad 7.58 | tok/s 8888
step     50 | loss 3.6456 | lr 4.90e-06 | grad 4.01 | tok/s 9230
step     60 | loss 3.6424 | lr 5.90e-06 | grad 3.21 | tok/s 9096
step     70 | loss 3.5350 | lr 6.90e-06 | grad 3.96 | tok/s 8995
step     80 | loss 3.6408 | lr 7.90e-06 | grad 2.73 | tok/s 8841
step     90 | loss 3.2770 | lr 8.90e-06 | grad 2.61 | tok/s 8883
step    100 | loss 4.2457 | lr 9.90e-06 | grad 13.06 | tok/s 8794
step    110 | loss 4.3416 | lr 1.09e-05 | grad 14.30 | tok/s 9106
step    120 | loss 3.7044 | lr 1.19e-05 | grad 2.49 | tok/s 9269
step    130 | loss 3.3239 | lr 1.29e-05 | grad 5.80 | tok/s 8931
step    140 | loss 3.3327 | lr 1.39e-05 | grad 2.71 | tok/s 9267
step    150 | loss 4.1527 | lr 1.49e-05 | grad 4.49 | tok/s 8954
step    160 | loss 5.5904 | lr 1.59e-05 | grad 4.23 | tok/s 9249
step    170 | loss 4.8070 | lr 1.69e-05 | grad 8.65 | tok/s 9247
step    180 | loss 4.7584 | lr 1.79e-05 | grad 10.67 | tok/s 9247
step    190 | loss 4.0365 | lr 1.89e-05 | grad 14.55 | tok/s 9241
step    200 | loss 4.0964 | lr 1.99e-05 | grad 13.36 | tok/s 9227
step    210 | loss 3.7886 | lr 2.09e-05 | grad 15.94 | tok/s 9234
step    220 | loss 3.7354 | lr 2.19e-05 | grad 3.73 | tok/s 9240
step    230 | loss 3.8838 | lr 2.29e-05 | grad 8.94 | tok/s 9229
step    240 | loss 4.0886 | lr 2.39e-05 | grad 10.11 | tok/s 9217
step    250 | loss 3.7570 | lr 2.49e-05 | grad 14.30 | tok/s 9215
step    260 | loss 3.7128 | lr 2.59e-05 | grad 7.23 | tok/s 9227
step    270 | loss 3.6219 | lr 2.69e-05 | grad 5.45 | tok/s 9198
step    280 | loss 3.2194 | lr 2.79e-05 | grad 9.07 | tok/s 9200
step    290 | loss 3.6738 | lr 2.89e-05 | grad 3.28 | tok/s 9199
step    300 | loss 3.9226 | lr 2.99e-05 | grad 6.09 | tok/s 9210
step    310 | loss 3.4641 | lr 3.09e-05 | grad 11.01 | tok/s 9186
step    320 | loss 3.0833 | lr 3.19e-05 | grad 5.59 | tok/s 9186
step    330 | loss 3.4540 | lr 3.29e-05 | grad 3.01 | tok/s 9183
step    340 | loss 3.0353 | lr 3.39e-05 | grad 10.37 | tok/s 9168
step    350 | loss 3.2754 | lr 3.49e-05 | grad 7.93 | tok/s 9173
step    360 | loss 3.3081 | lr 3.59e-05 | grad 4.06 | tok/s 9174
step    370 | loss 3.2655 | lr 3.69e-05 | grad 5.12 | tok/s 9169
step    380 | loss 3.2801 | lr 3.79e-05 | grad 5.94 | tok/s 9162
step    390 | loss 3.1972 | lr 3.89e-05 | grad 5.45 | tok/s 9172
step    400 | loss 2.7721 | lr 3.99e-05 | grad 7.90 | tok/s 9163
step    410 | loss 3.0517 | lr 4.09e-05 | grad 4.46 | tok/s 9161
step    420 | loss 3.1150 | lr 4.19e-05 | grad 10.38 | tok/s 9122
step    430 | loss 3.1669 | lr 4.29e-05 | grad 2.71 | tok/s 9128
step    440 | loss 3.0936 | lr 4.39e-05 | grad 1.65 | tok/s 9074
step    450 | loss 2.9028 | lr 4.49e-05 | grad 1.41 | tok/s 9132
step    460 | loss 3.6951 | lr 4.59e-05 | grad 4.66 | tok/s 9000
step    470 | loss 3.0927 | lr 4.69e-05 | grad 2.74 | tok/s 8791
step    480 | loss 2.9958 | lr 4.79e-05 | grad 2.55 | tok/s 8624
step    490 | loss 2.9937 | lr 4.89e-05 | grad 1.86 | tok/s 8936
step    500 | loss 2.7866 | lr 4.99e-05 | grad 2.00 | tok/s 8763
step    510 | loss 2.5616 | lr 5.09e-05 | grad 1.92 | tok/s 9109
step    520 | loss 2.3841 | lr 5.19e-05 | grad 2.20 | tok/s 9113
step    530 | loss 2.9174 | lr 5.29e-05 | grad 3.19 | tok/s 8772
step    540 | loss 2.7640 | lr 5.39e-05 | grad 2.59 | tok/s 8863
step    550 | loss 2.5897 | lr 5.49e-05 | grad 2.07 | tok/s 8745
step    560 | loss 3.2243 | lr 5.59e-05 | grad 3.00 | tok/s 9031
step    570 | loss 3.2176 | lr 5.69e-05 | grad 4.47 | tok/s 8991
step    580 | loss 1.9673 | lr 5.79e-05 | grad 1.20 | tok/s 9110
step    590 | loss 1.0839 | lr 5.89e-05 | grad 0.81 | tok/s 9105
step    600 | loss 0.7083 | lr 5.99e-05 | grad 0.66 | tok/s 9101
step    610 | loss 2.8776 | lr 6.09e-05 | grad 1.79 | tok/s 8756
step    620 | loss 3.0360 | lr 6.19e-05 | grad 1.87 | tok/s 9121
step    630 | loss 2.6559 | lr 6.29e-05 | grad 1.38 | tok/s 9108
step    640 | loss 2.6062 | lr 6.39e-05 | grad 2.23 | tok/s 8864
step    650 | loss 2.9419 | lr 6.49e-05 | grad 2.05 | tok/s 8679
step    660 | loss 2.6509 | lr 6.59e-05 | grad 1.94 | tok/s 8914
step    670 | loss 3.0090 | lr 6.69e-05 | grad 2.73 | tok/s 8893
step    680 | loss 2.6872 | lr 6.79e-05 | grad 1.30 | tok/s 8526
step    690 | loss 2.4376 | lr 6.89e-05 | grad 1.51 | tok/s 8856
step    700 | loss 2.7355 | lr 6.99e-05 | grad 1.51 | tok/s 9010
step    710 | loss 2.3941 | lr 7.09e-05 | grad 2.08 | tok/s 9113
step    720 | loss 2.4004 | lr 7.19e-05 | grad 9.44 | tok/s 9015
step    730 | loss 2.8253 | lr 7.29e-05 | grad 1.88 | tok/s 8531
step    740 | loss 2.5602 | lr 7.39e-05 | grad 1.85 | tok/s 8853
step    750 | loss 2.6029 | lr 7.49e-05 | grad 1.57 | tok/s 8879
step    760 | loss 2.3368 | lr 7.59e-05 | grad 1.50 | tok/s 9035
step    770 | loss 2.1680 | lr 7.69e-05 | grad 1.55 | tok/s 9106
step    780 | loss 2.0778 | lr 7.79e-05 | grad 1.27 | tok/s 9103
step    790 | loss 2.0656 | lr 7.89e-05 | grad 2.30 | tok/s 8979
step    800 | loss 2.3082 | lr 7.99e-05 | grad 1.75 | tok/s 9109
step    810 | loss 2.0389 | lr 8.09e-05 | grad 1.40 | tok/s 9105
step    820 | loss 2.0936 | lr 8.19e-05 | grad 1.64 | tok/s 8888
step    830 | loss 2.4275 | lr 8.29e-05 | grad 1.44 | tok/s 8457
step    840 | loss 2.6696 | lr 8.39e-05 | grad 1.96 | tok/s 8848
step    850 | loss 2.5870 | lr 8.49e-05 | grad 2.98 | tok/s 8941
step    860 | loss 2.6343 | lr 8.59e-05 | grad 2.94 | tok/s 8854
step    870 | loss 2.8766 | lr 8.69e-05 | grad 1.65 | tok/s 8714
step    880 | loss 2.7446 | lr 8.79e-05 | grad 2.15 | tok/s 8881
step    890 | loss 4.3250 | lr 8.89e-05 | grad 9.82 | tok/s 8609
step    900 | loss 2.5168 | lr 8.99e-05 | grad 1.56 | tok/s 8829
step    910 | loss 2.8519 | lr 9.09e-05 | grad 1.72 | tok/s 8797
step    920 | loss 2.2633 | lr 9.19e-05 | grad 5.87 | tok/s 8911
step    930 | loss 2.7352 | lr 9.29e-05 | grad 1.60 | tok/s 8531
step    940 | loss 2.3021 | lr 9.39e-05 | grad 4.44 | tok/s 8909
step    950 | loss 2.8960 | lr 9.49e-05 | grad 2.93 | tok/s 8773
step    960 | loss 2.9180 | lr 9.59e-05 | grad 2.30 | tok/s 8835
step    970 | loss 2.5097 | lr 9.69e-05 | grad 1.85 | tok/s 8717
step    980 | loss 2.2293 | lr 9.79e-05 | grad 1.00 | tok/s 8863
step    990 | loss 2.2101 | lr 9.89e-05 | grad 1.90 | tok/s 8851
step   1000 | loss 2.3959 | lr 9.99e-05 | grad 1.37 | tok/s 9064
  >>> saved checkpoint: checkpoint_step_001000_loss_2.3959.pt
step   1010 | loss 2.2882 | lr 1.02e-06 | grad 1.40 | tok/s 5742
step   1020 | loss 2.3818 | lr 1.09e-06 | grad 1.23 | tok/s 9071
step   1030 | loss 2.3724 | lr 1.21e-06 | grad 1.27 | tok/s 8899
step   1040 | loss 2.5255 | lr 1.37e-06 | grad 2.33 | tok/s 8948
step   1050 | loss 2.6903 | lr 1.59e-06 | grad 1.54 | tok/s 9050
step   1060 | loss 2.2241 | lr 1.85e-06 | grad 1.14 | tok/s 8820
step   1070 | loss 2.2602 | lr 2.16e-06 | grad 1.56 | tok/s 8762
step   1080 | loss 2.0626 | lr 2.52e-06 | grad 1.04 | tok/s 8994
step   1090 | loss 2.1160 | lr 2.92e-06 | grad 1.19 | tok/s 8796
step   1100 | loss 2.1937 | lr 3.37e-06 | grad 0.76 | tok/s 8362
step   1110 | loss 2.4848 | lr 3.87e-06 | grad 1.25 | tok/s 8818
step   1120 | loss 2.2683 | lr 4.42e-06 | grad 1.12 | tok/s 8641
step   1130 | loss 2.1710 | lr 5.01e-06 | grad 1.03 | tok/s 8628
step   1140 | loss 2.1478 | lr 5.65e-06 | grad 1.01 | tok/s 8791
step   1150 | loss 2.0293 | lr 6.32e-06 | grad 0.91 | tok/s 8553
step   1160 | loss 2.0996 | lr 7.05e-06 | grad 1.04 | tok/s 8526
step   1170 | loss 2.7950 | lr 7.81e-06 | grad 2.39 | tok/s 8972
step   1180 | loss 2.2782 | lr 8.62e-06 | grad 0.95 | tok/s 8572
step   1190 | loss 2.3334 | lr 9.47e-06 | grad 1.20 | tok/s 8652
step   1200 | loss 2.1445 | lr 1.04e-05 | grad 1.37 | tok/s 8779
step   1210 | loss 2.1581 | lr 1.13e-05 | grad 0.96 | tok/s 8902
step   1220 | loss 2.0017 | lr 1.23e-05 | grad 1.02 | tok/s 8579
step   1230 | loss 2.0013 | lr 1.33e-05 | grad 0.87 | tok/s 8434
step   1240 | loss 2.0648 | lr 1.43e-05 | grad 1.00 | tok/s 8262
step   1250 | loss 2.2587 | lr 1.54e-05 | grad 1.87 | tok/s 8650
step   1260 | loss 2.2871 | lr 1.65e-05 | grad 3.63 | tok/s 8733
step   1270 | loss 2.4057 | lr 1.76e-05 | grad 1.34 | tok/s 8760
step   1280 | loss 2.6165 | lr 1.88e-05 | grad 2.11 | tok/s 8877
step   1290 | loss 2.0718 | lr 2.00e-05 | grad 1.46 | tok/s 8904
step   1300 | loss 2.2774 | lr 2.13e-05 | grad 1.00 | tok/s 9057
step   1310 | loss 2.1063 | lr 2.25e-05 | grad 1.25 | tok/s 8578
step   1320 | loss 2.1559 | lr 2.38e-05 | grad 1.16 | tok/s 8900
step   1330 | loss 2.9039 | lr 2.52e-05 | grad 2.14 | tok/s 8840
step   1340 | loss 2.2312 | lr 2.65e-05 | grad 1.23 | tok/s 8936
step   1350 | loss 2.3137 | lr 2.79e-05 | grad 2.50 | tok/s 8657
step   1360 | loss 2.6451 | lr 2.93e-05 | grad 1.58 | tok/s 8882
step   1370 | loss 2.5121 | lr 3.07e-05 | grad 1.15 | tok/s 9077
step   1380 | loss 2.2926 | lr 3.21e-05 | grad 1.15 | tok/s 9077
step   1390 | loss 2.1396 | lr 3.36e-05 | grad 1.15 | tok/s 9066
step   1400 | loss 2.2629 | lr 3.51e-05 | grad 1.16 | tok/s 8921
step   1410 | loss 2.0237 | lr 3.65e-05 | grad 1.21 | tok/s 8399
step   1420 | loss 1.9592 | lr 3.80e-05 | grad 1.96 | tok/s 8479
step   1430 | loss 2.1516 | lr 3.96e-05 | grad 1.22 | tok/s 9066
step   1440 | loss 1.9954 | lr 4.11e-05 | grad 1.12 | tok/s 9078
step   1450 | loss 1.9213 | lr 4.26e-05 | grad 1.32 | tok/s 8995
step   1460 | loss 2.1175 | lr 4.41e-05 | grad 1.33 | tok/s 8918
step   1470 | loss 2.0152 | lr 4.57e-05 | grad 1.23 | tok/s 9084
step   1480 | loss 1.8269 | lr 4.72e-05 | grad 1.19 | tok/s 9082
step   1490 | loss 1.7292 | lr 4.88e-05 | grad 1.28 | tok/s 9079
step   1500 | loss 1.6029 | lr 5.03e-05 | grad 0.93 | tok/s 9081
step   1510 | loss 1.6247 | lr 5.19e-05 | grad 1.10 | tok/s 9076
step   1520 | loss 1.5387 | lr 5.35e-05 | grad 1.05 | tok/s 9082
step   1530 | loss 1.5507 | lr 5.50e-05 | grad 1.38 | tok/s 9074
step   1540 | loss 1.5490 | lr 5.65e-05 | grad 1.52 | tok/s 9078
step   1550 | loss 1.4324 | lr 5.81e-05 | grad 0.96 | tok/s 9073
step   1560 | loss 1.5105 | lr 5.96e-05 | grad 1.64 | tok/s 9084
step   1570 | loss 2.0723 | lr 6.11e-05 | grad 1.61 | tok/s 8605
step   1580 | loss 2.7410 | lr 6.27e-05 | grad 2.33 | tok/s 8907
step   1590 | loss 2.6495 | lr 6.42e-05 | grad 1.38 | tok/s 8824
step   1600 | loss 2.1124 | lr 6.56e-05 | grad 1.46 | tok/s 8905
step   1610 | loss 2.1707 | lr 6.71e-05 | grad 1.38 | tok/s 8820
step   1620 | loss 2.2541 | lr 6.86e-05 | grad 1.69 | tok/s 8734
step   1630 | loss 2.0876 | lr 7.00e-05 | grad 1.32 | tok/s 8807
step   1640 | loss 2.3831 | lr 7.14e-05 | grad 1.23 | tok/s 9083
step   1650 | loss 2.0644 | lr 7.28e-05 | grad 1.32 | tok/s 9081
step   1660 | loss 1.9913 | lr 7.42e-05 | grad 1.49 | tok/s 9086
step   1670 | loss 2.1616 | lr 7.56e-05 | grad 1.48 | tok/s 8905
step   1680 | loss 2.1373 | lr 7.69e-05 | grad 1.59 | tok/s 9081
step   1690 | loss 2.0783 | lr 7.82e-05 | grad 1.50 | tok/s 8988
step   1700 | loss 2.0216 | lr 7.95e-05 | grad 1.09 | tok/s 9070
step   1710 | loss 2.1077 | lr 8.07e-05 | grad 1.21 | tok/s 8828
step   1720 | loss 2.0809 | lr 8.19e-05 | grad 1.41 | tok/s 8647
step   1730 | loss 2.1012 | lr 8.31e-05 | grad 1.42 | tok/s 8814
step   1740 | loss 2.4879 | lr 8.43e-05 | grad 2.13 | tok/s 8843
step   1750 | loss 2.2426 | lr 8.54e-05 | grad 1.51 | tok/s 8921
step   1760 | loss 2.2030 | lr 8.65e-05 | grad 1.40 | tok/s 8824
step   1770 | loss 2.1867 | lr 8.75e-05 | grad 1.96 | tok/s 8728
step   1780 | loss 1.9502 | lr 8.85e-05 | grad 1.64 | tok/s 8893
step   1790 | loss 1.9216 | lr 8.95e-05 | grad 1.35 | tok/s 8820
step   1800 | loss 1.9702 | lr 9.05e-05 | grad 1.76 | tok/s 8785
step   1810 | loss 2.1751 | lr 9.14e-05 | grad 1.49 | tok/s 9065
step   1820 | loss 2.0200 | lr 9.22e-05 | grad 1.66 | tok/s 8971
step   1830 | loss 2.1134 | lr 9.30e-05 | grad 1.51 | tok/s 8868
step   1840 | loss 2.1499 | lr 9.38e-05 | grad 1.58 | tok/s 8370
step   1850 | loss 2.0683 | lr 9.45e-05 | grad 1.47 | tok/s 8882
step   1860 | loss 1.9631 | lr 9.52e-05 | grad 1.20 | tok/s 9072
step   1870 | loss 2.0928 | lr 9.59e-05 | grad 2.49 | tok/s 9038
step   1880 | loss 2.0471 | lr 9.65e-05 | grad 1.40 | tok/s 9090
step   1890 | loss 1.6724 | lr 9.70e-05 | grad 1.47 | tok/s 9085
step   1900 | loss 1.9014 | lr 9.75e-05 | grad 1.75 | tok/s 9054
step   1910 | loss 2.2364 | lr 9.80e-05 | grad 2.32 | tok/s 8618
step   1920 | loss 2.2205 | lr 9.84e-05 | grad 1.92 | tok/s 8585
step   1930 | loss 2.3762 | lr 9.88e-05 | grad 1.79 | tok/s 8768
step   1940 | loss 1.9425 | lr 9.91e-05 | grad 1.37 | tok/s 8864
step   1950 | loss 2.0048 | lr 9.94e-05 | grad 1.22 | tok/s 8663
step   1960 | loss 1.9664 | lr 9.96e-05 | grad 1.26 | tok/s 8998
step   1970 | loss 2.3336 | lr 9.98e-05 | grad 1.39 | tok/s 8807
step   1980 | loss 2.4816 | lr 9.99e-05 | grad 5.56 | tok/s 8674
step   1990 | loss 2.2867 | lr 1.00e-04 | grad 1.45 | tok/s 8749
step   2000 | loss 2.4378 | lr 1.00e-04 | grad 1.93 | tok/s 8716
  >>> saved checkpoint: checkpoint_step_002000_loss_2.4378.pt
step   2010 | loss 2.1085 | lr 1.00e-04 | grad 1.47 | tok/s 5698
step   2020 | loss 2.3107 | lr 9.99e-05 | grad 1.14 | tok/s 8527
step   2030 | loss 1.9312 | lr 9.98e-05 | grad 1.91 | tok/s 8561
step   2040 | loss 1.9945 | lr 9.96e-05 | grad 1.57 | tok/s 8789
step   2050 | loss 1.9112 | lr 9.94e-05 | grad 0.90 | tok/s 9071
step   2060 | loss 2.0536 | lr 9.92e-05 | grad 2.06 | tok/s 8971
step   2070 | loss 1.9956 | lr 9.88e-05 | grad 1.23 | tok/s 8692
step   2080 | loss 2.0381 | lr 9.85e-05 | grad 1.31 | tok/s 8469
step   2090 | loss 2.1258 | lr 9.81e-05 | grad 0.99 | tok/s 9085
step   2100 | loss 2.2328 | lr 9.76e-05 | grad 1.98 | tok/s 8864
step   2110 | loss 2.2947 | lr 9.71e-05 | grad 1.30 | tok/s 9016
step   2120 | loss 2.2646 | lr 9.66e-05 | grad 1.14 | tok/s 9093
step   2130 | loss 2.2443 | lr 9.60e-05 | grad 1.85 | tok/s 8554
step   2140 | loss 1.9480 | lr 9.54e-05 | grad 1.35 | tok/s 8726
step   2150 | loss 1.9317 | lr 9.47e-05 | grad 1.13 | tok/s 8490
step   2160 | loss 1.4285 | lr 9.40e-05 | grad 1.07 | tok/s 9095
step   2170 | loss 1.5092 | lr 9.32e-05 | grad 1.85 | tok/s 8888
step   2180 | loss 1.9656 | lr 9.24e-05 | grad 1.19 | tok/s 8672
step   2190 | loss 2.0750 | lr 9.15e-05 | grad 1.65 | tok/s 9066
step   2200 | loss 1.8522 | lr 9.06e-05 | grad 1.04 | tok/s 9090
step   2210 | loss 1.7193 | lr 8.97e-05 | grad 1.04 | tok/s 9096
step   2220 | loss 1.6994 | lr 8.87e-05 | grad 1.13 | tok/s 9077
step   2230 | loss 1.6843 | lr 8.77e-05 | grad 0.93 | tok/s 9078
step   2240 | loss 1.5969 | lr 8.67e-05 | grad 1.04 | tok/s 9095
step   2250 | loss 1.5868 | lr 8.56e-05 | grad 0.98 | tok/s 9089
step   2260 | loss 1.6059 | lr 8.45e-05 | grad 1.05 | tok/s 9076
step   2270 | loss 1.6227 | lr 8.34e-05 | grad 1.01 | tok/s 9098
step   2280 | loss 1.6141 | lr 8.22e-05 | grad 0.90 | tok/s 9082
step   2290 | loss 1.5305 | lr 8.10e-05 | grad 0.89 | tok/s 9066
step   2300 | loss 1.4451 | lr 7.97e-05 | grad 0.94 | tok/s 9087
step   2310 | loss 1.5078 | lr 7.85e-05 | grad 0.98 | tok/s 9102
step   2320 | loss 1.5091 | lr 7.72e-05 | grad 0.83 | tok/s 9102
step   2330 | loss 1.7035 | lr 7.58e-05 | grad 0.93 | tok/s 9085
step   2340 | loss 1.6612 | lr 7.45e-05 | grad 0.91 | tok/s 9075
step   2350 | loss 1.5593 | lr 7.31e-05 | grad 1.05 | tok/s 9100
step   2360 | loss 1.4830 | lr 7.17e-05 | grad 1.31 | tok/s 9093
step   2370 | loss 1.4639 | lr 7.03e-05 | grad 1.03 | tok/s 9081
step   2380 | loss 1.5219 | lr 6.89e-05 | grad 0.99 | tok/s 9094
step   2390 | loss 1.5426 | lr 6.74e-05 | grad 0.92 | tok/s 9085
step   2400 | loss 1.5224 | lr 6.59e-05 | grad 1.08 | tok/s 9064
step   2410 | loss 1.5902 | lr 6.45e-05 | grad 1.03 | tok/s 9089
step   2420 | loss 1.5296 | lr 6.30e-05 | grad 0.80 | tok/s 9084
step   2430 | loss 1.4381 | lr 6.15e-05 | grad 1.08 | tok/s 9086
step   2440 | loss 1.5881 | lr 5.99e-05 | grad 1.12 | tok/s 9078
step   2450 | loss 1.4404 | lr 5.84e-05 | grad 1.03 | tok/s 9095
step   2460 | loss 1.4707 | lr 5.69e-05 | grad 0.82 | tok/s 9084
step   2470 | loss 2.5474 | lr 5.53e-05 | grad 2.91 | tok/s 8822
step   2480 | loss 2.1104 | lr 5.38e-05 | grad 1.34 | tok/s 8823
step   2490 | loss 2.0385 | lr 5.22e-05 | grad 1.67 | tok/s 8580
step   2500 | loss 1.7287 | lr 5.07e-05 | grad 2.40 | tok/s 8889
step   2510 | loss 2.0642 | lr 4.91e-05 | grad 1.18 | tok/s 8893
step   2520 | loss 2.0493 | lr 4.75e-05 | grad 3.24 | tok/s 8519
step   2530 | loss 2.1755 | lr 4.60e-05 | grad 1.38 | tok/s 8458
step   2540 | loss 1.9932 | lr 4.45e-05 | grad 1.12 | tok/s 9080
step   2550 | loss 1.9212 | lr 4.29e-05 | grad 1.09 | tok/s 8941
step   2560 | loss 1.7980 | lr 4.14e-05 | grad 1.30 | tok/s 8735
step   2570 | loss 2.0121 | lr 3.99e-05 | grad 1.04 | tok/s 9087
step   2580 | loss 1.8368 | lr 3.83e-05 | grad 1.34 | tok/s 8620
step   2590 | loss 1.8510 | lr 3.68e-05 | grad 1.26 | tok/s 9041
step   2600 | loss 1.8102 | lr 3.54e-05 | grad 1.14 | tok/s 8974
step   2610 | loss 1.8818 | lr 3.39e-05 | grad 1.36 | tok/s 8893
step   2620 | loss 2.0418 | lr 3.24e-05 | grad 1.10 | tok/s 9138
step   2630 | loss 2.1738 | lr 3.10e-05 | grad 1.47 | tok/s 9066

Training complete! Final step: 2632
