Using device: cuda
Output directory: benchmark_results/e75mh_100m_20260119_150335/E75h2n48/levelE75h2n48_100m_20260119_150341
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h2n48, 62,358,912 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.8350 | lr 2.70e-06 | grad 78.00 | tok/s 21559
step     20 | loss 5.8168 | lr 5.70e-06 | grad 84.00 | tok/s 62294
step     30 | loss 5.7858 | lr 8.70e-06 | grad 75.00 | tok/s 66434
step     40 | loss 5.7783 | lr 1.17e-05 | grad 77.50 | tok/s 66516
step     50 | loss 5.7526 | lr 1.47e-05 | grad 67.00 | tok/s 66466
step     60 | loss 5.7142 | lr 1.77e-05 | grad 104.50 | tok/s 65074
step     70 | loss 5.5577 | lr 2.07e-05 | grad 90.00 | tok/s 62836
step     80 | loss 5.1653 | lr 2.37e-05 | grad 55.50 | tok/s 65202
step     90 | loss 5.1019 | lr 2.67e-05 | grad 107.00 | tok/s 63037
step    100 | loss 4.7489 | lr 2.97e-05 | grad 36.50 | tok/s 63617
step    110 | loss 4.3517 | lr 3.27e-05 | grad 27.25 | tok/s 62655
step    120 | loss 4.1535 | lr 3.57e-05 | grad 25.75 | tok/s 61716
step    130 | loss 3.9579 | lr 3.87e-05 | grad 14.00 | tok/s 63037
step    140 | loss 3.5808 | lr 4.17e-05 | grad 8.19 | tok/s 63156
step    150 | loss 3.3259 | lr 4.47e-05 | grad 7.44 | tok/s 60288
step    160 | loss 3.1776 | lr 4.77e-05 | grad 5.25 | tok/s 60892
step    170 | loss 3.2783 | lr 5.07e-05 | grad 23.62 | tok/s 63055
step    180 | loss 3.3044 | lr 5.37e-05 | grad 4.16 | tok/s 63260
step    190 | loss 3.0753 | lr 5.67e-05 | grad 5.56 | tok/s 64242
step    200 | loss 2.9520 | lr 5.97e-05 | grad 3.61 | tok/s 65639
step    210 | loss 2.9579 | lr 6.27e-05 | grad 5.22 | tok/s 62873
step    220 | loss 2.9494 | lr 6.57e-05 | grad 2.97 | tok/s 64965
step    230 | loss 2.6807 | lr 6.87e-05 | grad 7.19 | tok/s 62694
step    240 | loss 2.7591 | lr 7.17e-05 | grad 4.25 | tok/s 63891
step    250 | loss 2.6177 | lr 7.47e-05 | grad 4.03 | tok/s 63052
step    260 | loss 2.6093 | lr 7.77e-05 | grad 2.39 | tok/s 60509
step    270 | loss 2.4857 | lr 8.07e-05 | grad 6.03 | tok/s 62771
step    280 | loss 2.4227 | lr 8.37e-05 | grad 4.50 | tok/s 62591
step    290 | loss 2.3426 | lr 8.67e-05 | grad 3.12 | tok/s 66047
step    300 | loss 2.2185 | lr 8.97e-05 | grad 4.06 | tok/s 65966
step    310 | loss 2.1362 | lr 9.27e-05 | grad 3.78 | tok/s 65901
step    320 | loss 2.2889 | lr 9.57e-05 | grad 5.34 | tok/s 63520
step    330 | loss 2.3967 | lr 9.87e-05 | grad 5.28 | tok/s 61897
step    340 | loss 2.3734 | lr 1.02e-04 | grad 5.25 | tok/s 63281
step    350 | loss 2.3609 | lr 1.05e-04 | grad 3.56 | tok/s 61421
step    360 | loss 2.3478 | lr 1.08e-04 | grad 6.53 | tok/s 62206
step    370 | loss 2.1921 | lr 1.11e-04 | grad 3.33 | tok/s 63320
step    380 | loss 2.6987 | lr 1.14e-04 | grad 3.36 | tok/s 64966
step    390 | loss 2.2505 | lr 1.17e-04 | grad 3.11 | tok/s 62543
step    400 | loss 2.3426 | lr 1.20e-04 | grad 6.16 | tok/s 64200
step    410 | loss 2.1122 | lr 1.23e-04 | grad 4.72 | tok/s 62219
step    420 | loss 2.2206 | lr 1.26e-04 | grad 3.23 | tok/s 61842
step    430 | loss 2.3611 | lr 1.29e-04 | grad 3.61 | tok/s 61561
step    440 | loss 2.4651 | lr 1.32e-04 | grad 3.30 | tok/s 64008
step    450 | loss 2.1870 | lr 1.35e-04 | grad 2.75 | tok/s 62289
step    460 | loss 2.1610 | lr 1.38e-04 | grad 2.53 | tok/s 62581
step    470 | loss 2.1397 | lr 1.41e-04 | grad 2.70 | tok/s 63311
step    480 | loss 2.0758 | lr 1.44e-04 | grad 2.02 | tok/s 61046
step    490 | loss 1.9491 | lr 1.47e-04 | grad 1.77 | tok/s 62163
step    500 | loss 2.8307 | lr 1.50e-04 | grad 3.39 | tok/s 64051
step    510 | loss 2.0981 | lr 1.53e-04 | grad 3.25 | tok/s 62616
step    520 | loss 2.0556 | lr 1.56e-04 | grad 2.14 | tok/s 64562
step    530 | loss 2.5491 | lr 1.59e-04 | grad 6.47 | tok/s 63246
step    540 | loss 2.1327 | lr 1.62e-04 | grad 3.95 | tok/s 63207
step    550 | loss 1.9223 | lr 1.65e-04 | grad 1.71 | tok/s 64862
step    560 | loss 1.6796 | lr 1.68e-04 | grad 1.68 | tok/s 65727
step    570 | loss 2.0331 | lr 1.71e-04 | grad 4.12 | tok/s 64244
step    580 | loss 2.3811 | lr 1.74e-04 | grad 3.09 | tok/s 63402
step    590 | loss 2.5734 | lr 1.77e-04 | grad 4.44 | tok/s 62190
step    600 | loss 2.0925 | lr 1.80e-04 | grad 2.55 | tok/s 62336
step    610 | loss 2.1137 | lr 1.83e-04 | grad 2.09 | tok/s 65366
step    620 | loss 2.0059 | lr 1.86e-04 | grad 1.66 | tok/s 62001
step    630 | loss 1.9470 | lr 1.89e-04 | grad 1.84 | tok/s 63973
step    640 | loss 2.3546 | lr 1.92e-04 | grad 1.62 | tok/s 64085
step    650 | loss 1.9870 | lr 1.95e-04 | grad 2.44 | tok/s 62806
step    660 | loss 2.2685 | lr 1.98e-04 | grad 6.41 | tok/s 61978
step    670 | loss 2.1428 | lr 2.01e-04 | grad 2.77 | tok/s 64198
step    680 | loss 2.1154 | lr 2.04e-04 | grad 2.33 | tok/s 61890
step    690 | loss 2.0951 | lr 2.07e-04 | grad 1.99 | tok/s 62439
step    700 | loss 2.1738 | lr 2.10e-04 | grad 1.82 | tok/s 62806
step    710 | loss 2.0860 | lr 2.13e-04 | grad 1.70 | tok/s 63049
step    720 | loss 2.0557 | lr 2.16e-04 | grad 7.09 | tok/s 62797
step    730 | loss 2.2285 | lr 2.19e-04 | grad 1.98 | tok/s 63372
step    740 | loss 2.1574 | lr 2.22e-04 | grad 3.31 | tok/s 62809
step    750 | loss 1.8865 | lr 2.25e-04 | grad 1.81 | tok/s 62120
step    760 | loss 2.3204 | lr 2.28e-04 | grad 1.33 | tok/s 62914
step    770 | loss 1.8937 | lr 2.31e-04 | grad 1.72 | tok/s 62550
step    780 | loss 1.9358 | lr 2.34e-04 | grad 1.66 | tok/s 63303
step    790 | loss 1.8764 | lr 2.37e-04 | grad 1.18 | tok/s 63833
step    800 | loss 1.8278 | lr 2.40e-04 | grad 1.51 | tok/s 63774
step    810 | loss 1.9270 | lr 2.43e-04 | grad 2.50 | tok/s 63200
step    820 | loss 2.5540 | lr 2.46e-04 | grad 2.20 | tok/s 64766
step    830 | loss 2.0163 | lr 2.49e-04 | grad 1.01 | tok/s 65726
step    840 | loss 1.7039 | lr 2.52e-04 | grad 0.91 | tok/s 65803
step    850 | loss 2.2707 | lr 2.55e-04 | grad 1.56 | tok/s 62576
step    860 | loss 1.9771 | lr 2.58e-04 | grad 1.39 | tok/s 61334
step    870 | loss 1.8860 | lr 2.61e-04 | grad 1.12 | tok/s 63164
step    880 | loss 1.9773 | lr 2.64e-04 | grad 1.54 | tok/s 62944
step    890 | loss 1.8344 | lr 2.67e-04 | grad 1.16 | tok/s 62891
step    900 | loss 2.3179 | lr 2.70e-04 | grad 1.10 | tok/s 61118
step    910 | loss 1.8654 | lr 2.73e-04 | grad 1.06 | tok/s 62325
step    920 | loss 1.8244 | lr 2.76e-04 | grad 0.99 | tok/s 62110
step    930 | loss 1.9133 | lr 2.79e-04 | grad 1.73 | tok/s 61961
step    940 | loss 1.8051 | lr 2.82e-04 | grad 1.80 | tok/s 61306
step    950 | loss 1.9110 | lr 2.85e-04 | grad 1.58 | tok/s 62749
step    960 | loss 1.5873 | lr 2.88e-04 | grad 0.74 | tok/s 65824
step    970 | loss 1.4190 | lr 2.91e-04 | grad 0.64 | tok/s 65722
step    980 | loss 1.6254 | lr 2.94e-04 | grad 2.00 | tok/s 63948
step    990 | loss 1.9997 | lr 2.97e-04 | grad 0.97 | tok/s 62360
step   1000 | loss 1.8429 | lr 3.00e-04 | grad 0.79 | tok/s 60807
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8429.pt
step   1010 | loss 2.1356 | lr 1.06e-06 | grad 2.58 | tok/s 50220
step   1020 | loss 1.7868 | lr 1.27e-06 | grad 0.91 | tok/s 58980
step   1030 | loss 2.1626 | lr 1.62e-06 | grad 0.95 | tok/s 57859
step   1040 | loss 1.7664 | lr 2.12e-06 | grad 1.51 | tok/s 59129
step   1050 | loss 1.7971 | lr 2.77e-06 | grad 0.90 | tok/s 59460
step   1060 | loss 2.1567 | lr 3.56e-06 | grad 2.25 | tok/s 59585
step   1070 | loss 2.2234 | lr 4.50e-06 | grad 0.95 | tok/s 59784
step   1080 | loss 2.5131 | lr 5.58e-06 | grad 1.34 | tok/s 58949
step   1090 | loss 2.1926 | lr 6.81e-06 | grad 1.34 | tok/s 59458
step   1100 | loss 1.8341 | lr 8.17e-06 | grad 1.01 | tok/s 59057
step   1110 | loss 1.9198 | lr 9.68e-06 | grad 0.97 | tok/s 59983
step   1120 | loss 2.2721 | lr 1.13e-05 | grad 1.08 | tok/s 60713
step   1130 | loss 1.8566 | lr 1.31e-05 | grad 0.89 | tok/s 57777
step   1140 | loss 1.7424 | lr 1.50e-05 | grad 0.94 | tok/s 59061
step   1150 | loss 2.0223 | lr 1.71e-05 | grad 1.38 | tok/s 59106
step   1160 | loss 1.6775 | lr 1.93e-05 | grad 0.67 | tok/s 58485
step   1170 | loss 2.0557 | lr 2.16e-05 | grad 0.86 | tok/s 59331
step   1180 | loss 1.8048 | lr 2.40e-05 | grad 0.94 | tok/s 62186
step   1190 | loss 1.7608 | lr 2.66e-05 | grad 0.73 | tok/s 62187
step   1200 | loss 1.7023 | lr 2.93e-05 | grad 0.66 | tok/s 62157
step   1210 | loss 1.6733 | lr 3.21e-05 | grad 0.67 | tok/s 62257
step   1220 | loss 1.6752 | lr 3.50e-05 | grad 0.82 | tok/s 61678
step   1230 | loss 1.6101 | lr 3.80e-05 | grad 0.76 | tok/s 59535
step   1240 | loss 1.7406 | lr 4.12e-05 | grad 0.79 | tok/s 58397
step   1250 | loss 1.8676 | lr 4.45e-05 | grad 3.12 | tok/s 60267
step   1260 | loss 1.8789 | lr 4.78e-05 | grad 2.72 | tok/s 60243
step   1270 | loss 1.9492 | lr 5.13e-05 | grad 1.41 | tok/s 59537
step   1280 | loss 1.8241 | lr 5.48e-05 | grad 0.97 | tok/s 58619
step   1290 | loss 1.7342 | lr 5.85e-05 | grad 0.98 | tok/s 58634
step   1300 | loss 1.7810 | lr 6.22e-05 | grad 0.86 | tok/s 58235
step   1310 | loss 1.8541 | lr 6.61e-05 | grad 0.88 | tok/s 58041
step   1320 | loss 1.8133 | lr 7.00e-05 | grad 1.28 | tok/s 59193
step   1330 | loss 1.7292 | lr 7.40e-05 | grad 0.77 | tok/s 59293
step   1340 | loss 1.6479 | lr 7.81e-05 | grad 1.12 | tok/s 59342
step   1350 | loss 1.7330 | lr 8.22e-05 | grad 1.91 | tok/s 60764
step   1360 | loss 1.6266 | lr 8.64e-05 | grad 0.75 | tok/s 57784
step   1370 | loss 1.7797 | lr 9.07e-05 | grad 0.67 | tok/s 58754
step   1380 | loss 1.8149 | lr 9.50e-05 | grad 1.05 | tok/s 59196
step   1390 | loss 1.7131 | lr 9.94e-05 | grad 1.62 | tok/s 57756
step   1400 | loss 1.7199 | lr 1.04e-04 | grad 5.84 | tok/s 60075
step   1410 | loss 1.7464 | lr 1.08e-04 | grad 1.10 | tok/s 60720
step   1420 | loss 1.7780 | lr 1.13e-04 | grad 1.02 | tok/s 57877
step   1430 | loss 1.6000 | lr 1.17e-04 | grad 1.08 | tok/s 56468
step   1440 | loss 1.5427 | lr 1.22e-04 | grad 0.86 | tok/s 59486
step   1450 | loss 1.6186 | lr 1.27e-04 | grad 2.09 | tok/s 60907
step   1460 | loss 1.6642 | lr 1.31e-04 | grad 0.74 | tok/s 56679
step   1470 | loss 1.7758 | lr 1.36e-04 | grad 2.19 | tok/s 58758
step   1480 | loss 1.6420 | lr 1.41e-04 | grad 2.09 | tok/s 59463
step   1490 | loss 1.8224 | lr 1.45e-04 | grad 2.81 | tok/s 59439
step   1500 | loss 1.9270 | lr 1.50e-04 | grad 2.56 | tok/s 57807
step   1510 | loss 1.7860 | lr 1.55e-04 | grad 1.34 | tok/s 60736
step   1520 | loss 1.7437 | lr 1.59e-04 | grad 1.21 | tok/s 60116
step   1530 | loss 1.7003 | lr 1.64e-04 | grad 0.87 | tok/s 59690
step   1540 | loss 1.6686 | lr 1.69e-04 | grad 0.81 | tok/s 58655
step   1550 | loss 1.6657 | lr 1.73e-04 | grad 2.95 | tok/s 60737
step   1560 | loss 2.2627 | lr 1.78e-04 | grad 1.51 | tok/s 59347
step   1570 | loss 1.7065 | lr 1.83e-04 | grad 1.31 | tok/s 58316
step   1580 | loss 1.8518 | lr 1.87e-04 | grad 1.24 | tok/s 60172
step   1590 | loss 1.6194 | lr 1.92e-04 | grad 0.96 | tok/s 58740
step   1600 | loss 1.7002 | lr 1.96e-04 | grad 1.14 | tok/s 57656
step   1610 | loss 1.5514 | lr 2.01e-04 | grad 0.84 | tok/s 60951
step   1620 | loss 1.7168 | lr 2.05e-04 | grad 0.77 | tok/s 60027
step   1630 | loss 1.7090 | lr 2.09e-04 | grad 0.93 | tok/s 60532
step   1640 | loss 1.6619 | lr 2.14e-04 | grad 0.70 | tok/s 58450
step   1650 | loss 1.6748 | lr 2.18e-04 | grad 1.54 | tok/s 57573
step   1660 | loss 1.6812 | lr 2.22e-04 | grad 1.06 | tok/s 58076
step   1670 | loss 1.7326 | lr 2.26e-04 | grad 2.17 | tok/s 60543
step   1680 | loss 2.1237 | lr 2.30e-04 | grad 0.82 | tok/s 60465
step   1690 | loss 1.6708 | lr 2.34e-04 | grad 1.23 | tok/s 59040
step   1700 | loss 2.0153 | lr 2.38e-04 | grad 1.13 | tok/s 60165
step   1710 | loss 1.7997 | lr 2.42e-04 | grad 1.18 | tok/s 58456
step   1720 | loss 1.7508 | lr 2.45e-04 | grad 1.18 | tok/s 58891
step   1730 | loss 1.8948 | lr 2.49e-04 | grad 1.47 | tok/s 58791
step   1740 | loss 1.7305 | lr 2.52e-04 | grad 0.85 | tok/s 59659
step   1750 | loss 1.6731 | lr 2.56e-04 | grad 0.89 | tok/s 57428
step   1760 | loss 1.9650 | lr 2.59e-04 | grad 0.95 | tok/s 58243
step   1770 | loss 1.8170 | lr 2.62e-04 | grad 0.95 | tok/s 59860
step   1780 | loss 1.6842 | lr 2.65e-04 | grad 1.15 | tok/s 57633
step   1790 | loss 1.8934 | lr 2.68e-04 | grad 0.94 | tok/s 58471
step   1800 | loss 1.6018 | lr 2.71e-04 | grad 0.81 | tok/s 59593
step   1810 | loss 1.7067 | lr 2.74e-04 | grad 0.92 | tok/s 59344
step   1820 | loss 1.6494 | lr 2.76e-04 | grad 0.90 | tok/s 58705
step   1830 | loss 1.6748 | lr 2.79e-04 | grad 0.87 | tok/s 58542
step   1840 | loss 1.6505 | lr 2.81e-04 | grad 1.17 | tok/s 58013
step   1850 | loss 1.8974 | lr 2.83e-04 | grad 1.21 | tok/s 58623
step   1860 | loss 1.6473 | lr 2.86e-04 | grad 0.75 | tok/s 58469
step   1870 | loss 1.6767 | lr 2.88e-04 | grad 1.53 | tok/s 59662
step   1880 | loss 1.6659 | lr 2.89e-04 | grad 0.81 | tok/s 59851
step   1890 | loss 1.8088 | lr 2.91e-04 | grad 0.95 | tok/s 58897
step   1900 | loss 1.7545 | lr 2.93e-04 | grad 0.97 | tok/s 59362
step   1910 | loss 1.8542 | lr 2.94e-04 | grad 1.62 | tok/s 58658
step   1920 | loss 1.6527 | lr 2.95e-04 | grad 0.79 | tok/s 60538
step   1930 | loss 1.6931 | lr 2.96e-04 | grad 1.16 | tok/s 59869
step   1940 | loss 1.5815 | lr 2.97e-04 | grad 1.01 | tok/s 61009
step   1950 | loss 1.6918 | lr 2.98e-04 | grad 0.91 | tok/s 59445
step   1960 | loss 2.0265 | lr 2.99e-04 | grad 4.50 | tok/s 60558
step   1970 | loss 1.6793 | lr 2.99e-04 | grad 1.74 | tok/s 58486
step   1980 | loss 1.7826 | lr 3.00e-04 | grad 2.69 | tok/s 58571
step   1990 | loss 1.8513 | lr 3.00e-04 | grad 1.20 | tok/s 59807
step   2000 | loss 1.7566 | lr 3.00e-04 | grad 1.34 | tok/s 60359
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7566.pt
step   2010 | loss 1.4574 | lr 3.00e-04 | grad 0.73 | tok/s 51087
step   2020 | loss 1.2971 | lr 3.00e-04 | grad 0.73 | tok/s 62337
step   2030 | loss 1.6451 | lr 2.99e-04 | grad 1.09 | tok/s 61620
step   2040 | loss 1.4493 | lr 2.99e-04 | grad 0.64 | tok/s 62235
step   2050 | loss 1.3998 | lr 2.98e-04 | grad 1.00 | tok/s 61185
step   2060 | loss 1.7467 | lr 2.97e-04 | grad 0.92 | tok/s 58599
step   2070 | loss 1.6621 | lr 2.97e-04 | grad 1.27 | tok/s 61398
step   2080 | loss 1.8142 | lr 2.95e-04 | grad 2.70 | tok/s 57940
step   2090 | loss 1.7225 | lr 2.94e-04 | grad 0.97 | tok/s 60145
step   2100 | loss 1.6935 | lr 2.93e-04 | grad 0.96 | tok/s 58437
step   2110 | loss 1.4520 | lr 2.91e-04 | grad 0.79 | tok/s 60345
step   2120 | loss 1.5663 | lr 2.90e-04 | grad 1.32 | tok/s 59729
step   2130 | loss 1.6770 | lr 2.88e-04 | grad 3.06 | tok/s 58132
step   2140 | loss 1.7344 | lr 2.86e-04 | grad 2.66 | tok/s 58188
step   2150 | loss 1.7176 | lr 2.84e-04 | grad 0.68 | tok/s 58905
step   2160 | loss 1.6863 | lr 2.82e-04 | grad 0.77 | tok/s 58184
step   2170 | loss 1.8040 | lr 2.79e-04 | grad 0.80 | tok/s 58975
step   2180 | loss 1.6383 | lr 2.77e-04 | grad 0.84 | tok/s 60156
step   2190 | loss 1.9157 | lr 2.74e-04 | grad 0.84 | tok/s 60061
step   2200 | loss 1.3879 | lr 2.72e-04 | grad 0.57 | tok/s 62038
step   2210 | loss 1.3514 | lr 2.69e-04 | grad 0.51 | tok/s 61976
step   2220 | loss 1.3045 | lr 2.66e-04 | grad 0.55 | tok/s 62099
step   2230 | loss 1.5566 | lr 2.63e-04 | grad 0.95 | tok/s 59860
step   2240 | loss 1.7749 | lr 2.60e-04 | grad 1.86 | tok/s 61277
step   2250 | loss 1.6818 | lr 2.57e-04 | grad 0.91 | tok/s 60669
step   2260 | loss 1.8046 | lr 2.53e-04 | grad 1.01 | tok/s 59883
step   2270 | loss 1.6241 | lr 2.50e-04 | grad 1.12 | tok/s 58528
step   2280 | loss 1.7352 | lr 2.46e-04 | grad 0.78 | tok/s 58539
step   2290 | loss 1.5831 | lr 2.43e-04 | grad 0.98 | tok/s 59138
step   2300 | loss 1.5630 | lr 2.39e-04 | grad 0.99 | tok/s 57327

Training complete! Final step: 2309
