Using device: cuda
Output directory: benchmark_results/e88_480m_depth_scan/fla-gdn/levelfla-gdn_100m_20260125_162909
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 239,443,856 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.6284 | lr 3.00e-04 | grad 19.00 | tok/s 1475
step     20 | loss 3.0701 | lr 3.00e-04 | grad 5.75 | tok/s 44460
step     30 | loss 3.3036 | lr 3.00e-04 | grad 4.19 | tok/s 44170
step     40 | loss 3.1181 | lr 3.00e-04 | grad 41.00 | tok/s 45502
step     50 | loss 5.3038 | lr 3.00e-04 | grad 26.12 | tok/s 47531
step     60 | loss 4.5482 | lr 3.00e-04 | grad 23.50 | tok/s 47360
step     70 | loss 3.7163 | lr 3.00e-04 | grad 5.16 | tok/s 47298
step     80 | loss 3.2991 | lr 3.00e-04 | grad 9.88 | tok/s 47071
step     90 | loss 2.7675 | lr 3.00e-04 | grad 7.69 | tok/s 47103
step    100 | loss 2.6489 | lr 3.00e-04 | grad 6.50 | tok/s 47032
step    110 | loss 2.4413 | lr 3.00e-04 | grad 2.31 | tok/s 46693
step    120 | loss 2.9393 | lr 3.00e-04 | grad 2.89 | tok/s 44890
step    130 | loss 2.3432 | lr 3.00e-04 | grad 2.39 | tok/s 43999
step    140 | loss 2.1799 | lr 3.00e-04 | grad 3.09 | tok/s 44146
step    150 | loss 2.1195 | lr 3.00e-04 | grad 3.00 | tok/s 45534
step    160 | loss 2.1658 | lr 3.00e-04 | grad 3.20 | tok/s 45611
step    170 | loss 2.3429 | lr 3.00e-04 | grad 5.31 | tok/s 43203
step    180 | loss 2.2615 | lr 3.00e-04 | grad 4.84 | tok/s 44553
step    190 | loss 2.0672 | lr 3.00e-04 | grad 3.06 | tok/s 42665
step    200 | loss 1.8209 | lr 3.00e-04 | grad 2.09 | tok/s 45485
step    210 | loss 1.7072 | lr 3.00e-04 | grad 2.27 | tok/s 44087
step    220 | loss 2.2274 | lr 3.00e-04 | grad 4.06 | tok/s 37857
step    230 | loss 2.1409 | lr 3.00e-04 | grad 1.40 | tok/s 42467
step    240 | loss 1.9460 | lr 3.00e-04 | grad 2.41 | tok/s 42597
step    250 | loss 2.1669 | lr 3.00e-04 | grad 1.59 | tok/s 42778
step    260 | loss 1.7935 | lr 3.00e-04 | grad 1.31 | tok/s 43983
step    270 | loss 1.9634 | lr 3.00e-04 | grad 1.35 | tok/s 44249
step    280 | loss 1.7318 | lr 3.00e-04 | grad 1.86 | tok/s 42805
step    290 | loss 1.7045 | lr 3.00e-04 | grad 2.97 | tok/s 41152
step    300 | loss 1.7826 | lr 3.00e-04 | grad 2.36 | tok/s 41531
step    310 | loss 1.8036 | lr 3.00e-04 | grad 1.51 | tok/s 42465
step    320 | loss 1.6218 | lr 3.00e-04 | grad 2.64 | tok/s 40725
step    330 | loss 1.8227 | lr 3.00e-04 | grad 1.73 | tok/s 42456
step    340 | loss 1.9310 | lr 3.00e-04 | grad 23.62 | tok/s 43156
step    350 | loss 1.8708 | lr 3.00e-04 | grad 2.66 | tok/s 42321
step    360 | loss 1.7081 | lr 3.00e-04 | grad 1.64 | tok/s 43448
step    370 | loss 1.5034 | lr 3.00e-04 | grad 1.30 | tok/s 42613
step    380 | loss 1.5335 | lr 3.00e-04 | grad 1.38 | tok/s 44410
step    390 | loss 1.2332 | lr 3.00e-04 | grad 1.30 | tok/s 44638
step    400 | loss 1.1465 | lr 3.00e-04 | grad 1.49 | tok/s 44140
step    410 | loss 1.8683 | lr 3.00e-04 | grad 1.63 | tok/s 42501
step    420 | loss 1.7309 | lr 3.00e-04 | grad 2.02 | tok/s 42557
step    430 | loss 1.6889 | lr 3.00e-04 | grad 2.22 | tok/s 44284
step    440 | loss 1.5716 | lr 3.00e-04 | grad 1.93 | tok/s 42992
step    450 | loss 1.7267 | lr 3.00e-04 | grad 1.48 | tok/s 42429
step    460 | loss 1.5447 | lr 3.00e-04 | grad 4.03 | tok/s 42089
step    470 | loss 1.6235 | lr 3.00e-04 | grad 2.45 | tok/s 41966
step    480 | loss 1.5909 | lr 3.00e-04 | grad 1.88 | tok/s 43858
step    490 | loss 1.5759 | lr 3.00e-04 | grad 1.56 | tok/s 42513
step    500 | loss 1.6051 | lr 3.00e-04 | grad 1.28 | tok/s 42110
step    510 | loss 1.8039 | lr 3.00e-04 | grad 9.25 | tok/s 41402
step    520 | loss 1.6243 | lr 3.00e-04 | grad 1.65 | tok/s 39663
step    530 | loss 1.4890 | lr 3.00e-04 | grad 1.61 | tok/s 42023
step    540 | loss 1.7116 | lr 3.00e-04 | grad 1.57 | tok/s 41814
step    550 | loss 1.5983 | lr 3.00e-04 | grad 1.55 | tok/s 40813
step    560 | loss 1.3431 | lr 3.00e-04 | grad 1.64 | tok/s 42784
step    570 | loss 1.4192 | lr 3.00e-04 | grad 1.57 | tok/s 44079
step    580 | loss 1.3298 | lr 3.00e-04 | grad 1.24 | tok/s 44058
step    590 | loss 1.2847 | lr 3.00e-04 | grad 1.07 | tok/s 44062
step    600 | loss 1.3493 | lr 3.00e-04 | grad 1.55 | tok/s 44064
step    610 | loss 1.2687 | lr 3.00e-04 | grad 1.31 | tok/s 43912
step    620 | loss 1.2972 | lr 3.00e-04 | grad 1.15 | tok/s 43913
step    630 | loss 1.3402 | lr 3.00e-04 | grad 3.70 | tok/s 43336
step    640 | loss 1.6214 | lr 3.00e-04 | grad 2.42 | tok/s 41387
step    650 | loss 1.6444 | lr 3.00e-04 | grad 1.85 | tok/s 41084
step    660 | loss 1.5216 | lr 3.00e-04 | grad 1.80 | tok/s 41287
step    670 | loss 1.5699 | lr 3.00e-04 | grad 1.64 | tok/s 42771
step    680 | loss 1.5939 | lr 3.00e-04 | grad 2.02 | tok/s 41284
step    690 | loss 1.6258 | lr 3.00e-04 | grad 1.47 | tok/s 40999
step    700 | loss 1.5712 | lr 3.00e-04 | grad 1.91 | tok/s 40616
step    710 | loss 1.4748 | lr 3.00e-04 | grad 1.44 | tok/s 41772
step    720 | loss 1.6161 | lr 3.00e-04 | grad 2.50 | tok/s 40830
step    730 | loss 1.3043 | lr 3.00e-04 | grad 1.27 | tok/s 42620
step    740 | loss 1.3960 | lr 3.00e-04 | grad 1.26 | tok/s 41393
step    750 | loss 1.8183 | lr 3.00e-04 | grad 3.28 | tok/s 43021
step    760 | loss 1.5838 | lr 3.00e-04 | grad 1.37 | tok/s 42906
step    770 | loss 1.4854 | lr 3.00e-04 | grad 2.45 | tok/s 42064
step    780 | loss 1.5157 | lr 3.00e-04 | grad 1.49 | tok/s 40839
step    790 | loss 1.4662 | lr 3.00e-04 | grad 1.55 | tok/s 41933
step    800 | loss 1.6347 | lr 3.00e-04 | grad 3.88 | tok/s 43151
step    810 | loss 1.4203 | lr 3.00e-04 | grad 2.27 | tok/s 41752
step    820 | loss 1.2502 | lr 3.00e-04 | grad 2.92 | tok/s 36730
step    830 | loss 1.3975 | lr 3.00e-04 | grad 1.98 | tok/s 41352
step    840 | loss 1.5046 | lr 3.00e-04 | grad 1.20 | tok/s 40445
step    850 | loss 1.5455 | lr 3.00e-04 | grad 1.25 | tok/s 40534
step    860 | loss 1.5703 | lr 3.00e-04 | grad 1.56 | tok/s 40735
step    870 | loss 1.5163 | lr 3.00e-04 | grad 2.36 | tok/s 41175
step    880 | loss 1.4821 | lr 3.00e-04 | grad 1.62 | tok/s 43139
step    890 | loss 1.5649 | lr 3.00e-04 | grad 5.25 | tok/s 41035
step    900 | loss 1.4869 | lr 3.00e-04 | grad 1.27 | tok/s 41108
step    910 | loss 1.4630 | lr 3.00e-04 | grad 1.56 | tok/s 41536
step    920 | loss 1.5179 | lr 3.00e-04 | grad 1.27 | tok/s 41036
step    930 | loss 1.5014 | lr 3.00e-04 | grad 1.29 | tok/s 41081
step    940 | loss 1.3947 | lr 3.00e-04 | grad 1.47 | tok/s 42343
step    950 | loss 1.3278 | lr 3.00e-04 | grad 1.23 | tok/s 40568
step    960 | loss 1.4786 | lr 3.00e-04 | grad 1.26 | tok/s 40048
step    970 | loss 1.4231 | lr 3.00e-04 | grad 1.19 | tok/s 40466
step    980 | loss 1.4302 | lr 3.00e-04 | grad 1.26 | tok/s 41565
step    990 | loss 1.9581 | lr 3.00e-04 | grad 2.23 | tok/s 43147
step   1000 | loss 1.6366 | lr 3.00e-04 | grad 1.20 | tok/s 41380
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6366.pt
step   1010 | loss 1.5220 | lr 3.00e-04 | grad 1.49 | tok/s 19949
step   1020 | loss 1.2279 | lr 3.00e-04 | grad 1.52 | tok/s 42153
step   1030 | loss 1.1829 | lr 3.00e-04 | grad 2.27 | tok/s 42964
step   1040 | loss 1.4078 | lr 3.00e-04 | grad 1.48 | tok/s 42782
step   1050 | loss 1.7138 | lr 3.00e-04 | grad 4.56 | tok/s 40935
step   1060 | loss 1.9037 | lr 3.00e-04 | grad 1.21 | tok/s 42998
step   1070 | loss 1.4780 | lr 3.00e-04 | grad 4.28 | tok/s 41496
step   1080 | loss 1.0806 | lr 3.00e-04 | grad 2.03 | tok/s 42329
step   1090 | loss 1.3772 | lr 3.00e-04 | grad 1.70 | tok/s 42295
step   1100 | loss 1.2331 | lr 3.00e-04 | grad 1.20 | tok/s 43513
step   1110 | loss 1.2180 | lr 3.00e-04 | grad 0.92 | tok/s 43422
step   1120 | loss 1.1871 | lr 3.00e-04 | grad 1.24 | tok/s 43415
step   1130 | loss 1.2452 | lr 3.00e-04 | grad 1.34 | tok/s 42216
step   1140 | loss 1.5065 | lr 3.00e-04 | grad 1.91 | tok/s 42655
step   1150 | loss 1.8028 | lr 3.00e-04 | grad 3.64 | tok/s 41853
step   1160 | loss 1.4339 | lr 3.00e-04 | grad 1.89 | tok/s 41840
step   1170 | loss 1.6553 | lr 3.00e-04 | grad 1.63 | tok/s 40927
step   1180 | loss 1.7489 | lr 3.00e-04 | grad 1.45 | tok/s 41142
step   1190 | loss 1.3523 | lr 3.00e-04 | grad 0.98 | tok/s 39782
step   1200 | loss 1.4323 | lr 3.00e-04 | grad 2.84 | tok/s 42283
step   1210 | loss 1.5416 | lr 3.00e-04 | grad 1.42 | tok/s 43266
step   1220 | loss 1.1257 | lr 3.00e-04 | grad 1.55 | tok/s 42728
step   1230 | loss 1.4333 | lr 3.00e-04 | grad 1.45 | tok/s 40354
step   1240 | loss 1.3308 | lr 3.00e-04 | grad 1.52 | tok/s 41406
step   1250 | loss 1.2919 | lr 3.00e-04 | grad 1.39 | tok/s 42346
step   1260 | loss 1.3215 | lr 3.00e-04 | grad 1.42 | tok/s 41852
step   1270 | loss 1.4607 | lr 3.00e-04 | grad 2.28 | tok/s 42371
step   1280 | loss 1.4114 | lr 3.00e-04 | grad 1.45 | tok/s 41899
step   1290 | loss 1.3486 | lr 3.00e-04 | grad 1.16 | tok/s 41617
step   1300 | loss 1.3917 | lr 3.00e-04 | grad 1.34 | tok/s 40996
step   1310 | loss 1.3458 | lr 3.00e-04 | grad 1.42 | tok/s 40718
step   1320 | loss 1.6333 | lr 3.00e-04 | grad 3.05 | tok/s 40685
step   1330 | loss 1.4857 | lr 3.00e-04 | grad 1.55 | tok/s 41740
step   1340 | loss 1.5137 | lr 3.00e-04 | grad 1.63 | tok/s 42471
step   1350 | loss 1.3894 | lr 3.00e-04 | grad 1.55 | tok/s 40940
step   1360 | loss 1.4656 | lr 3.00e-04 | grad 1.45 | tok/s 40478
step   1370 | loss 1.4742 | lr 3.00e-04 | grad 4.22 | tok/s 41466
step   1380 | loss 1.4181 | lr 3.00e-04 | grad 1.57 | tok/s 40685
step   1390 | loss 1.7020 | lr 3.00e-04 | grad 2.58 | tok/s 38926
step   1400 | loss 1.3965 | lr 3.00e-04 | grad 2.69 | tok/s 40036
step   1410 | loss 1.2907 | lr 3.00e-04 | grad 1.23 | tok/s 41802
step   1420 | loss 1.4870 | lr 3.00e-04 | grad 1.22 | tok/s 41198
step   1430 | loss 1.3963 | lr 3.00e-04 | grad 2.69 | tok/s 39762
step   1440 | loss 1.2007 | lr 3.00e-04 | grad 4.94 | tok/s 42781
step   1450 | loss 1.6242 | lr 3.00e-04 | grad 1.59 | tok/s 40875
step   1460 | loss 1.4440 | lr 3.00e-04 | grad 1.73 | tok/s 42374
step   1470 | loss 1.4178 | lr 3.00e-04 | grad 2.20 | tok/s 42243
step   1480 | loss 1.5358 | lr 3.00e-04 | grad 3.77 | tok/s 40411
step   1490 | loss 1.3177 | lr 3.00e-04 | grad 1.36 | tok/s 39388
step   1500 | loss 1.3238 | lr 3.00e-04 | grad 1.34 | tok/s 42221
step   1510 | loss 1.8868 | lr 3.00e-04 | grad 9.00 | tok/s 41104
step   1520 | loss 1.4422 | lr 3.00e-04 | grad 1.45 | tok/s 41482
step   1530 | loss 1.2353 | lr 3.00e-04 | grad 1.18 | tok/s 40777
step   1540 | loss 1.4689 | lr 3.00e-04 | grad 1.35 | tok/s 41393
step   1550 | loss 1.3511 | lr 3.00e-04 | grad 1.25 | tok/s 41426
step   1560 | loss 1.4885 | lr 3.00e-04 | grad 1.16 | tok/s 41682
step   1570 | loss 1.4256 | lr 3.00e-04 | grad 2.38 | tok/s 41035
step   1580 | loss 1.1312 | lr 3.00e-04 | grad 1.15 | tok/s 42781
step   1590 | loss 1.3257 | lr 3.00e-04 | grad 1.35 | tok/s 41834
step   1600 | loss 1.2277 | lr 3.00e-04 | grad 1.51 | tok/s 42019
step   1610 | loss 1.4181 | lr 3.00e-04 | grad 3.52 | tok/s 40090
step   1620 | loss 1.2736 | lr 3.00e-04 | grad 4.22 | tok/s 42950
step   1630 | loss 1.8559 | lr 3.00e-04 | grad 3.00 | tok/s 41898
step   1640 | loss 2.0937 | lr 3.00e-04 | grad 1.67 | tok/s 43181
step   1650 | loss 1.7176 | lr 3.00e-04 | grad 1.77 | tok/s 43122
step   1660 | loss 1.5372 | lr 3.00e-04 | grad 1.55 | tok/s 43138
step   1670 | loss 1.4166 | lr 3.00e-04 | grad 1.43 | tok/s 42893
step   1680 | loss 1.3739 | lr 3.00e-04 | grad 1.45 | tok/s 43147
step   1690 | loss 1.5206 | lr 3.00e-04 | grad 1.81 | tok/s 41352
step   1700 | loss 1.3785 | lr 3.00e-04 | grad 1.23 | tok/s 40862
step   1710 | loss 1.4205 | lr 3.00e-04 | grad 1.84 | tok/s 39266
step   1720 | loss 1.3507 | lr 3.00e-04 | grad 1.47 | tok/s 41189
step   1730 | loss 1.1935 | lr 3.00e-04 | grad 2.20 | tok/s 42445
step   1740 | loss 1.4617 | lr 3.00e-04 | grad 1.71 | tok/s 40449
step   1750 | loss 1.3860 | lr 3.00e-04 | grad 1.31 | tok/s 41614
step   1760 | loss 1.3647 | lr 3.00e-04 | grad 1.36 | tok/s 40948
step   1770 | loss 1.3015 | lr 3.00e-04 | grad 1.31 | tok/s 41586
step   1780 | loss 1.3162 | lr 3.00e-04 | grad 1.88 | tok/s 40933
step   1790 | loss 1.5780 | lr 3.00e-04 | grad 1.44 | tok/s 40894
step   1800 | loss 1.7233 | lr 3.00e-04 | grad 1.37 | tok/s 39568
step   1810 | loss 1.3637 | lr 3.00e-04 | grad 1.98 | tok/s 40717
step   1820 | loss 1.2336 | lr 3.00e-04 | grad 1.38 | tok/s 41224
step   1830 | loss 1.4151 | lr 3.00e-04 | grad 1.10 | tok/s 40390
step   1840 | loss 1.4049 | lr 3.00e-04 | grad 1.89 | tok/s 41187
step   1850 | loss 1.4501 | lr 3.00e-04 | grad 1.84 | tok/s 40326
step   1860 | loss 1.4311 | lr 3.00e-04 | grad 1.94 | tok/s 41089
step   1870 | loss 1.3082 | lr 3.00e-04 | grad 3.39 | tok/s 39808
step   1880 | loss 1.4168 | lr 3.00e-04 | grad 2.48 | tok/s 40791
step   1890 | loss 1.4736 | lr 3.00e-04 | grad 1.35 | tok/s 40366
step   1900 | loss 1.3384 | lr 3.00e-04 | grad 1.05 | tok/s 42160
step   1910 | loss 1.2873 | lr 3.00e-04 | grad 1.54 | tok/s 43137
step   1920 | loss 1.2076 | lr 3.00e-04 | grad 1.02 | tok/s 43118
step   1930 | loss 1.1902 | lr 3.00e-04 | grad 1.21 | tok/s 43141
step   1940 | loss 1.1605 | lr 3.00e-04 | grad 1.04 | tok/s 43170
step   1950 | loss 1.1213 | lr 3.00e-04 | grad 1.11 | tok/s 43186
step   1960 | loss 1.4123 | lr 3.00e-04 | grad 4.16 | tok/s 40762
step   1970 | loss 1.4891 | lr 3.00e-04 | grad 1.47 | tok/s 40471
step   1980 | loss 1.3940 | lr 3.00e-04 | grad 1.71 | tok/s 38391
step   1990 | loss 1.4760 | lr 3.00e-04 | grad 2.62 | tok/s 40288
step   2000 | loss 1.3724 | lr 3.00e-04 | grad 1.38 | tok/s 39441
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3724.pt
step   2010 | loss 1.5747 | lr 3.00e-04 | grad 1.46 | tok/s 21410
step   2020 | loss 1.3570 | lr 3.00e-04 | grad 1.31 | tok/s 42327
step   2030 | loss 1.0790 | lr 3.00e-04 | grad 1.43 | tok/s 43596
step   2040 | loss 1.3624 | lr 3.00e-04 | grad 1.30 | tok/s 38959
step   2050 | loss 1.3839 | lr 3.00e-04 | grad 1.61 | tok/s 41565
step   2060 | loss 1.7288 | lr 3.00e-04 | grad 1.32 | tok/s 39572
step   2070 | loss 1.3522 | lr 3.00e-04 | grad 1.18 | tok/s 41956
step   2080 | loss 1.3579 | lr 3.00e-04 | grad 1.73 | tok/s 40871
step   2090 | loss 1.5880 | lr 3.00e-04 | grad 1.91 | tok/s 41349
step   2100 | loss 1.1016 | lr 3.00e-04 | grad 1.37 | tok/s 41520
step   2110 | loss 1.1687 | lr 3.00e-04 | grad 1.20 | tok/s 41054
step   2120 | loss 1.5986 | lr 3.00e-04 | grad 2.66 | tok/s 42043
step   2130 | loss 1.5726 | lr 3.00e-04 | grad 1.30 | tok/s 42583
step   2140 | loss 1.3484 | lr 3.00e-04 | grad 1.64 | tok/s 40691
step   2150 | loss 2.1917 | lr 3.00e-04 | grad 1.49 | tok/s 41929
step   2160 | loss 1.4298 | lr 3.00e-04 | grad 2.19 | tok/s 40299
step   2170 | loss 1.4477 | lr 3.00e-04 | grad 1.50 | tok/s 40935
step   2180 | loss 1.7231 | lr 3.00e-04 | grad 1.63 | tok/s 41779
step   2190 | loss 1.3391 | lr 3.00e-04 | grad 1.12 | tok/s 40809
step   2200 | loss 1.4055 | lr 3.00e-04 | grad 1.14 | tok/s 41568
step   2210 | loss 1.1281 | lr 3.00e-04 | grad 1.66 | tok/s 43191
step   2220 | loss 1.4427 | lr 3.00e-04 | grad 2.45 | tok/s 40579
step   2230 | loss 1.1805 | lr 3.00e-04 | grad 1.32 | tok/s 43338
step   2240 | loss 1.4219 | lr 3.00e-04 | grad 1.32 | tok/s 41232
step   2250 | loss 1.3905 | lr 3.00e-04 | grad 1.58 | tok/s 39912
step   2260 | loss 1.5594 | lr 3.00e-04 | grad 1.23 | tok/s 40721
step   2270 | loss 1.3057 | lr 3.00e-04 | grad 2.92 | tok/s 41782
step   2280 | loss 1.3429 | lr 3.00e-04 | grad 1.12 | tok/s 40689
step   2290 | loss 1.4823 | lr 3.00e-04 | grad 1.91 | tok/s 42158
step   2300 | loss 1.6750 | lr 3.00e-04 | grad 2.16 | tok/s 40235
step   2310 | loss 1.3875 | lr 3.00e-04 | grad 1.40 | tok/s 40945
step   2320 | loss 1.2106 | lr 3.00e-04 | grad 1.29 | tok/s 40517
step   2330 | loss 1.6214 | lr 3.00e-04 | grad 2.30 | tok/s 41151
step   2340 | loss 1.3664 | lr 3.00e-04 | grad 1.53 | tok/s 41339
step   2350 | loss 1.3754 | lr 3.00e-04 | grad 1.08 | tok/s 43207
step   2360 | loss 1.3076 | lr 3.00e-04 | grad 1.12 | tok/s 43179
step   2370 | loss 1.2549 | lr 3.00e-04 | grad 1.17 | tok/s 43228
step   2380 | loss 1.2321 | lr 3.00e-04 | grad 1.20 | tok/s 43169
step   2390 | loss 1.1992 | lr 3.00e-04 | grad 1.16 | tok/s 43208
step   2400 | loss 1.1791 | lr 3.00e-04 | grad 0.99 | tok/s 43193
step   2410 | loss 1.1668 | lr 3.00e-04 | grad 1.10 | tok/s 43180
step   2420 | loss 1.1821 | lr 3.00e-04 | grad 1.15 | tok/s 43199
step   2430 | loss 1.1405 | lr 3.00e-04 | grad 1.15 | tok/s 43032
step   2440 | loss 1.2500 | lr 3.00e-04 | grad 1.72 | tok/s 42527
step   2450 | loss 1.4584 | lr 3.00e-04 | grad 0.95 | tok/s 42098
step   2460 | loss 1.0624 | lr 3.00e-04 | grad 1.31 | tok/s 40917
step   2470 | loss 1.4059 | lr 3.00e-04 | grad 1.38 | tok/s 39721
step   2480 | loss 1.3046 | lr 3.00e-04 | grad 1.10 | tok/s 41653
step   2490 | loss 1.5170 | lr 3.00e-04 | grad 1.55 | tok/s 42204
step   2500 | loss 1.2959 | lr 3.00e-04 | grad 3.42 | tok/s 41630
step   2510 | loss 1.4427 | lr 3.00e-04 | grad 2.77 | tok/s 41808
step   2520 | loss 1.4253 | lr 3.00e-04 | grad 1.89 | tok/s 41893
step   2530 | loss 1.5222 | lr 3.00e-04 | grad 2.33 | tok/s 41530
step   2540 | loss 1.4434 | lr 3.00e-04 | grad 1.33 | tok/s 41051
step   2550 | loss 1.2890 | lr 3.00e-04 | grad 2.66 | tok/s 40289
step   2560 | loss 1.4788 | lr 3.00e-04 | grad 1.29 | tok/s 41465
step   2570 | loss 1.4230 | lr 3.00e-04 | grad 1.84 | tok/s 39977
step   2580 | loss 1.3036 | lr 3.00e-04 | grad 1.28 | tok/s 41364
step   2590 | loss 1.4884 | lr 3.00e-04 | grad 1.55 | tok/s 40588
step   2600 | loss 1.3106 | lr 3.00e-04 | grad 1.03 | tok/s 40310
step   2610 | loss 1.5801 | lr 3.00e-04 | grad 1.20 | tok/s 40729
step   2620 | loss 1.3176 | lr 3.00e-04 | grad 1.15 | tok/s 40227
step   2630 | loss 1.4467 | lr 3.00e-04 | grad 1.14 | tok/s 39913
step   2640 | loss 1.3958 | lr 3.00e-04 | grad 1.52 | tok/s 42456
step   2650 | loss 1.4096 | lr 3.00e-04 | grad 4.09 | tok/s 40692
step   2660 | loss 1.1930 | lr 3.00e-04 | grad 1.25 | tok/s 41740
step   2670 | loss 1.2738 | lr 3.00e-04 | grad 2.34 | tok/s 41182
step   2680 | loss 1.2507 | lr 3.00e-04 | grad 1.61 | tok/s 41211
step   2690 | loss 1.2440 | lr 3.00e-04 | grad 1.14 | tok/s 41435
step   2700 | loss 1.1832 | lr 3.00e-04 | grad 1.83 | tok/s 43073
step   2710 | loss 1.3093 | lr 3.00e-04 | grad 1.17 | tok/s 40366
step   2720 | loss 1.2788 | lr 3.00e-04 | grad 1.98 | tok/s 39905
step   2730 | loss 1.3753 | lr 3.00e-04 | grad 1.09 | tok/s 40483
step   2740 | loss 1.4212 | lr 3.00e-04 | grad 1.11 | tok/s 40938
step   2750 | loss 1.4769 | lr 3.00e-04 | grad 1.16 | tok/s 41154
step   2760 | loss 1.2876 | lr 3.00e-04 | grad 1.16 | tok/s 40854
step   2770 | loss 1.3572 | lr 3.00e-04 | grad 1.27 | tok/s 39958
step   2780 | loss 1.3784 | lr 3.00e-04 | grad 2.77 | tok/s 40147
step   2790 | loss 1.2030 | lr 3.00e-04 | grad 1.11 | tok/s 42762
step   2800 | loss 1.3970 | lr 3.00e-04 | grad 7.59 | tok/s 40544
step   2810 | loss 1.2401 | lr 3.00e-04 | grad 1.65 | tok/s 41986
step   2820 | loss 1.3851 | lr 3.00e-04 | grad 1.90 | tok/s 42033
step   2830 | loss 1.4682 | lr 3.00e-04 | grad 1.12 | tok/s 38918
step   2840 | loss 1.2958 | lr 3.00e-04 | grad 1.60 | tok/s 41183
step   2850 | loss 1.3712 | lr 3.00e-04 | grad 1.77 | tok/s 38427
step   2860 | loss 1.2337 | lr 3.00e-04 | grad 1.99 | tok/s 39732
step   2870 | loss 1.2798 | lr 3.00e-04 | grad 1.56 | tok/s 39940
step   2880 | loss 1.1516 | lr 3.00e-04 | grad 1.05 | tok/s 42461

Training complete! Final step: 2880
