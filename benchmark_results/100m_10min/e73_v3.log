Using device: cuda
Output directory: benchmark_results/100m_10min/e73_v3/level73_100m_20260115_131751
Auto r_h_mode: none (level 73 is matrix state - gated update is bounded)
Model: Level 73, 104,020,736 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss nan | lr 2.70e-06 | grad nan | tok/s 15911
step     20 | loss nan | lr 5.70e-06 | grad nan | tok/s 29424
step     30 | loss nan | lr 8.70e-06 | grad nan | tok/s 31061
step     40 | loss nan | lr 1.17e-05 | grad nan | tok/s 31107
step     50 | loss nan | lr 1.47e-05 | grad nan | tok/s 31088
step     60 | loss nan | lr 1.77e-05 | grad nan | tok/s 30295
step     70 | loss nan | lr 2.07e-05 | grad nan | tok/s 29318
step     80 | loss nan | lr 2.37e-05 | grad nan | tok/s 30464
step     90 | loss nan | lr 2.67e-05 | grad nan | tok/s 29477
step    100 | loss nan | lr 2.97e-05 | grad nan | tok/s 29722
step    110 | loss nan | lr 3.27e-05 | grad nan | tok/s 29297
step    120 | loss nan | lr 3.57e-05 | grad nan | tok/s 28895
step    130 | loss nan | lr 3.87e-05 | grad nan | tok/s 29505
step    140 | loss nan | lr 4.17e-05 | grad nan | tok/s 29637
step    150 | loss nan | lr 4.47e-05 | grad nan | tok/s 28267
step    160 | loss nan | lr 4.77e-05 | grad nan | tok/s 28530
step    170 | loss nan | lr 5.07e-05 | grad nan | tok/s 29462
step    180 | loss nan | lr 5.37e-05 | grad nan | tok/s 29540
step    190 | loss nan | lr 5.67e-05 | grad nan | tok/s 29983
step    200 | loss nan | lr 5.97e-05 | grad nan | tok/s 30675
step    210 | loss nan | lr 6.27e-05 | grad nan | tok/s 29432
step    220 | loss nan | lr 6.57e-05 | grad nan | tok/s 30408
step    230 | loss nan | lr 6.87e-05 | grad nan | tok/s 29338
step    240 | loss nan | lr 7.17e-05 | grad nan | tok/s 29897
step    250 | loss nan | lr 7.47e-05 | grad nan | tok/s 29486
step    260 | loss nan | lr 7.77e-05 | grad nan | tok/s 28306
step    270 | loss nan | lr 8.07e-05 | grad nan | tok/s 29361
step    280 | loss nan | lr 8.37e-05 | grad nan | tok/s 29311
step    290 | loss nan | lr 8.67e-05 | grad nan | tok/s 30931
step    300 | loss nan | lr 8.97e-05 | grad nan | tok/s 30947
step    310 | loss nan | lr 9.27e-05 | grad nan | tok/s 30925
step    320 | loss nan | lr 9.57e-05 | grad nan | tok/s 29745
step    330 | loss nan | lr 9.87e-05 | grad nan | tok/s 29055
step    340 | loss nan | lr 1.02e-04 | grad nan | tok/s 29671
step    350 | loss nan | lr 1.05e-04 | grad nan | tok/s 28807
step    360 | loss nan | lr 1.08e-04 | grad nan | tok/s 29155
step    370 | loss nan | lr 1.11e-04 | grad nan | tok/s 29809
step    380 | loss nan | lr 1.14e-04 | grad nan | tok/s 30493
step    390 | loss nan | lr 1.17e-04 | grad nan | tok/s 29366
step    400 | loss nan | lr 1.20e-04 | grad nan | tok/s 30113
step    410 | loss nan | lr 1.23e-04 | grad nan | tok/s 29144
step    420 | loss nan | lr 1.26e-04 | grad nan | tok/s 28974
step    430 | loss nan | lr 1.29e-04 | grad nan | tok/s 28899
step    440 | loss nan | lr 1.32e-04 | grad nan | tok/s 30091
step    450 | loss nan | lr 1.35e-04 | grad nan | tok/s 29268
step    460 | loss nan | lr 1.38e-04 | grad nan | tok/s 29343
step    470 | loss nan | lr 1.41e-04 | grad nan | tok/s 29674
step    480 | loss nan | lr 1.44e-04 | grad nan | tok/s 28259
step    490 | loss nan | lr 1.47e-04 | grad nan | tok/s 29161
step    500 | loss nan | lr 1.50e-04 | grad nan | tok/s 30080
step    510 | loss nan | lr 1.53e-04 | grad nan | tok/s 29257
step    520 | loss nan | lr 1.56e-04 | grad nan | tok/s 30229
step    530 | loss nan | lr 1.59e-04 | grad nan | tok/s 29677
step    540 | loss nan | lr 1.62e-04 | grad nan | tok/s 29504
step    550 | loss nan | lr 1.65e-04 | grad nan | tok/s 30438
step    560 | loss nan | lr 1.68e-04 | grad nan | tok/s 30858
step    570 | loss nan | lr 1.71e-04 | grad nan | tok/s 30135
step    580 | loss nan | lr 1.74e-04 | grad nan | tok/s 29768
step    590 | loss nan | lr 1.77e-04 | grad nan | tok/s 29129
step    600 | loss nan | lr 1.80e-04 | grad nan | tok/s 29132
step    610 | loss nan | lr 1.83e-04 | grad nan | tok/s 30635
step    620 | loss nan | lr 1.86e-04 | grad nan | tok/s 28944
step    630 | loss nan | lr 1.89e-04 | grad nan | tok/s 30020
step    640 | loss nan | lr 1.92e-04 | grad nan | tok/s 30144
step    650 | loss nan | lr 1.95e-04 | grad nan | tok/s 29568
step    660 | loss nan | lr 1.98e-04 | grad nan | tok/s 29121
step    670 | loss nan | lr 2.01e-04 | grad nan | tok/s 30225
step    680 | loss nan | lr 2.04e-04 | grad nan | tok/s 29054
step    690 | loss nan | lr 2.07e-04 | grad nan | tok/s 29129
step    700 | loss nan | lr 2.10e-04 | grad nan | tok/s 29294
step    710 | loss nan | lr 2.13e-04 | grad nan | tok/s 29484
step    720 | loss nan | lr 2.16e-04 | grad nan | tok/s 29297
step    730 | loss nan | lr 2.19e-04 | grad nan | tok/s 29597
step    740 | loss nan | lr 2.22e-04 | grad nan | tok/s 29303
step    750 | loss nan | lr 2.25e-04 | grad nan | tok/s 29008
step    760 | loss nan | lr 2.28e-04 | grad nan | tok/s 29358
step    770 | loss nan | lr 2.31e-04 | grad nan | tok/s 29084
step    780 | loss nan | lr 2.34e-04 | grad nan | tok/s 29540
step    790 | loss nan | lr 2.37e-04 | grad nan | tok/s 29785
step    800 | loss nan | lr 2.40e-04 | grad nan | tok/s 29770
step    810 | loss nan | lr 2.43e-04 | grad nan | tok/s 29497
step    820 | loss nan | lr 2.46e-04 | grad nan | tok/s 30269
step    830 | loss nan | lr 2.49e-04 | grad nan | tok/s 30698
step    840 | loss nan | lr 2.52e-04 | grad nan | tok/s 30773
step    850 | loss nan | lr 2.55e-04 | grad nan | tok/s 29167
step    860 | loss nan | lr 2.58e-04 | grad nan | tok/s 28623
step    870 | loss nan | lr 2.61e-04 | grad nan | tok/s 29514
step    880 | loss nan | lr 2.64e-04 | grad nan | tok/s 29394
step    890 | loss nan | lr 2.67e-04 | grad nan | tok/s 29342
step    900 | loss nan | lr 2.70e-04 | grad nan | tok/s 28576
step    910 | loss nan | lr 2.73e-04 | grad nan | tok/s 29071
step    920 | loss nan | lr 2.76e-04 | grad nan | tok/s 29013
step    930 | loss nan | lr 2.79e-04 | grad nan | tok/s 28932
step    940 | loss nan | lr 2.82e-04 | grad nan | tok/s 28538
step    950 | loss nan | lr 2.85e-04 | grad nan | tok/s 29293
step    960 | loss nan | lr 2.88e-04 | grad nan | tok/s 30760
step    970 | loss nan | lr 2.91e-04 | grad nan | tok/s 30730
step    980 | loss nan | lr 2.94e-04 | grad nan | tok/s 29862
step    990 | loss nan | lr 2.97e-04 | grad nan | tok/s 29056
step   1000 | loss nan | lr 3.00e-04 | grad nan | tok/s 28257
  >>> saved checkpoint: checkpoint_step_001000_loss_nan.pt
step   1010 | loss nan | lr 1.06e-06 | grad nan | tok/s 25549
step   1020 | loss nan | lr 1.27e-06 | grad nan | tok/s 28402
step   1030 | loss nan | lr 1.62e-06 | grad nan | tok/s 27956
step   1040 | loss nan | lr 2.12e-06 | grad nan | tok/s 28559
step   1050 | loss nan | lr 2.77e-06 | grad nan | tok/s 28622
step   1060 | loss nan | lr 3.56e-06 | grad nan | tok/s 28733
step   1070 | loss nan | lr 4.50e-06 | grad nan | tok/s 28767
step   1080 | loss nan | lr 5.58e-06 | grad nan | tok/s 28392
step   1090 | loss nan | lr 6.81e-06 | grad nan | tok/s 28493
step   1100 | loss nan | lr 8.17e-06 | grad nan | tok/s 28422
step   1110 | loss nan | lr 9.68e-06 | grad nan | tok/s 28940

Training complete! Final step: 1115
