Using device: cuda
Output directory: benchmark_results/100m_10min/e68/level68_100m_20260115_104347
Auto r_h_mode: none (level 68 has bounded/no W_h)
Model: Level 68, 98,583,680 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.6375 | lr 2.70e-06 | grad 13.12 | tok/s 3182
step     20 | loss 5.5529 | lr 5.70e-06 | grad 9.62 | tok/s 3540
step     30 | loss 5.7258 | lr 8.70e-06 | grad 8.69 | tok/s 3651
step     40 | loss 5.6055 | lr 1.17e-05 | grad 9.06 | tok/s 3415
step     50 | loss 5.4123 | lr 1.47e-05 | grad 7.62 | tok/s 3425
step     60 | loss 5.1110 | lr 1.77e-05 | grad 10.12 | tok/s 3441
step     70 | loss 4.5482 | lr 2.07e-05 | grad 6.84 | tok/s 3119
step     80 | loss 4.1439 | lr 2.37e-05 | grad 7.28 | tok/s 3116
step     90 | loss 4.1438 | lr 2.67e-05 | grad 4.59 | tok/s 2988
step    100 | loss 3.9085 | lr 2.97e-05 | grad 3.02 | tok/s 3293
step    110 | loss 3.6684 | lr 3.27e-05 | grad 2.25 | tok/s 3339
step    120 | loss 3.7178 | lr 3.57e-05 | grad 1.98 | tok/s 3466

Training complete! Final step: 127
