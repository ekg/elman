Using device: cuda
Output directory: benchmark_results/100m_10min/e64/level64_100m_20260115_103337
Auto r_h_mode: none (level 64 has bounded/no W_h)
Model: Level 64, 98,532,480 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.6085 | lr 2.70e-06 | grad 10.62 | tok/s 14304
step     20 | loss 5.5746 | lr 5.70e-06 | grad 7.62 | tok/s 88432
step     30 | loss 5.6069 | lr 8.70e-06 | grad 6.69 | tok/s 93793
step     40 | loss 5.5195 | lr 1.17e-05 | grad 7.03 | tok/s 93740
step     50 | loss 5.3930 | lr 1.47e-05 | grad 6.25 | tok/s 93623
step     60 | loss 5.1957 | lr 1.77e-05 | grad 8.94 | tok/s 91630
step     70 | loss 4.7887 | lr 2.07e-05 | grad 7.81 | tok/s 88517
step     80 | loss 4.3916 | lr 2.37e-05 | grad 8.44 | tok/s 91884
step     90 | loss 4.3420 | lr 2.67e-05 | grad 4.94 | tok/s 88965
step    100 | loss 4.0194 | lr 2.97e-05 | grad 3.77 | tok/s 89420
step    110 | loss 3.7538 | lr 3.27e-05 | grad 3.30 | tok/s 75948
step    120 | loss 3.7646 | lr 3.57e-05 | grad 2.58 | tok/s 33303
step    130 | loss 3.6576 | lr 3.87e-05 | grad 2.27 | tok/s 36346
step    140 | loss 3.4199 | lr 4.17e-05 | grad 1.98 | tok/s 34802
step    150 | loss 3.2977 | lr 4.47e-05 | grad 2.64 | tok/s 81079
step    160 | loss 3.2325 | lr 4.77e-05 | grad 1.94 | tok/s 82441
step    170 | loss 3.3667 | lr 5.07e-05 | grad 3.19 | tok/s 84385
step    180 | loss 3.4595 | lr 5.37e-05 | grad 1.70 | tok/s 85460
step    190 | loss 3.3145 | lr 5.67e-05 | grad 1.41 | tok/s 86761
step    200 | loss 3.2979 | lr 5.97e-05 | grad 1.30 | tok/s 88247
step    210 | loss 3.3310 | lr 6.27e-05 | grad 2.19 | tok/s 85278
step    220 | loss 3.4008 | lr 6.57e-05 | grad 1.31 | tok/s 90412
step    230 | loss 3.1947 | lr 6.87e-05 | grad 2.02 | tok/s 86344
step    240 | loss 3.3481 | lr 7.17e-05 | grad 1.47 | tok/s 88011
step    250 | loss 3.2235 | lr 7.47e-05 | grad 1.46 | tok/s 47021
step    260 | loss 3.1825 | lr 7.77e-05 | grad 1.09 | tok/s 58100
step    270 | loss 3.1734 | lr 8.07e-05 | grad 1.67 | tok/s 87563
step    280 | loss 3.1171 | lr 8.37e-05 | grad 2.70 | tok/s 87263
step    290 | loss 3.1754 | lr 8.67e-05 | grad 0.69 | tok/s 92079
step    300 | loss 3.1529 | lr 8.97e-05 | grad 0.88 | tok/s 92090
step    310 | loss 3.1565 | lr 9.27e-05 | grad 0.84 | tok/s 91790
step    320 | loss 3.1207 | lr 9.57e-05 | grad 2.39 | tok/s 88082
step    330 | loss 3.1876 | lr 9.87e-05 | grad 1.51 | tok/s 85978
step    340 | loss 3.2092 | lr 1.02e-04 | grad 1.50 | tok/s 87789
step    350 | loss 3.1713 | lr 1.05e-04 | grad 1.23 | tok/s 84589
step    360 | loss 3.1681 | lr 1.08e-04 | grad 2.22 | tok/s 44252
step    370 | loss 3.1454 | lr 1.11e-04 | grad 1.23 | tok/s 32116
step    380 | loss 3.5189 | lr 1.14e-04 | grad 1.83 | tok/s 41869
step    390 | loss 3.1101 | lr 1.17e-04 | grad 1.35 | tok/s 35480
step    400 | loss 3.2755 | lr 1.20e-04 | grad 3.20 | tok/s 38572
step    410 | loss 2.9523 | lr 1.23e-04 | grad 1.65 | tok/s 36533
step    420 | loss 3.1022 | lr 1.26e-04 | grad 1.46 | tok/s 36743
step    430 | loss 3.1724 | lr 1.29e-04 | grad 2.00 | tok/s 36097
step    440 | loss 3.3789 | lr 1.32e-04 | grad 1.53 | tok/s 38668
step    450 | loss 3.0927 | lr 1.35e-04 | grad 1.17 | tok/s 36952
step    460 | loss 3.1389 | lr 1.38e-04 | grad 1.11 | tok/s 36909
step    470 | loss 3.1736 | lr 1.41e-04 | grad 0.98 | tok/s 59682
step    480 | loss 2.9998 | lr 1.44e-04 | grad 1.11 | tok/s 84403
step    490 | loss 2.9802 | lr 1.47e-04 | grad 1.10 | tok/s 86037
step    500 | loss 3.5244 | lr 1.50e-04 | grad 1.47 | tok/s 88469
step    510 | loss 2.9461 | lr 1.53e-04 | grad 3.11 | tok/s 86479
step    520 | loss 2.9833 | lr 1.56e-04 | grad 1.78 | tok/s 89196
step    530 | loss 3.3839 | lr 1.59e-04 | grad 2.64 | tok/s 87239
step    540 | loss 2.8266 | lr 1.62e-04 | grad 1.79 | tok/s 87098
step    550 | loss 2.9163 | lr 1.65e-04 | grad 1.33 | tok/s 89507
step    560 | loss 2.8170 | lr 1.68e-04 | grad 1.99 | tok/s 90693
step    570 | loss 2.9588 | lr 1.71e-04 | grad 3.52 | tok/s 88508
step    580 | loss 3.1146 | lr 1.74e-04 | grad 1.24 | tok/s 87228
step    590 | loss 3.1500 | lr 1.77e-04 | grad 1.65 | tok/s 85508
step    600 | loss 2.8658 | lr 1.80e-04 | grad 2.33 | tok/s 85725
step    610 | loss 2.8934 | lr 1.83e-04 | grad 2.39 | tok/s 89724
step    620 | loss 2.6653 | lr 1.86e-04 | grad 2.03 | tok/s 85157
step    630 | loss 2.6587 | lr 1.89e-04 | grad 3.14 | tok/s 87839
step    640 | loss 3.0108 | lr 1.92e-04 | grad 1.81 | tok/s 87846
step    650 | loss 2.6587 | lr 1.95e-04 | grad 1.72 | tok/s 86163
step    660 | loss 2.8339 | lr 1.98e-04 | grad 3.59 | tok/s 82730
step    670 | loss 2.7924 | lr 2.01e-04 | grad 2.94 | tok/s 87973
step    680 | loss 2.7101 | lr 2.04e-04 | grad 2.97 | tok/s 84833
step    690 | loss 2.7100 | lr 2.07e-04 | grad 2.72 | tok/s 85481
step    700 | loss 2.7601 | lr 2.10e-04 | grad 2.20 | tok/s 85925
step    710 | loss 2.7141 | lr 2.13e-04 | grad 2.69 | tok/s 86382
step    720 | loss 2.6585 | lr 2.16e-04 | grad 3.05 | tok/s 86032
step    730 | loss 2.7329 | lr 2.19e-04 | grad 2.12 | tok/s 86790
step    740 | loss 2.5667 | lr 2.22e-04 | grad 3.23 | tok/s 62799
step    750 | loss 2.4342 | lr 2.25e-04 | grad 2.30 | tok/s 43179
step    760 | loss 2.7514 | lr 2.28e-04 | grad 2.52 | tok/s 48727
step    770 | loss 2.4061 | lr 2.31e-04 | grad 2.11 | tok/s 61699
step    780 | loss 2.5091 | lr 2.34e-04 | grad 2.89 | tok/s 53099
step    790 | loss 2.5264 | lr 2.37e-04 | grad 2.23 | tok/s 62442
step    800 | loss 2.4664 | lr 2.40e-04 | grad 2.14 | tok/s 62495
step    810 | loss 2.3485 | lr 2.43e-04 | grad 2.22 | tok/s 61421
step    820 | loss 2.8714 | lr 2.46e-04 | grad 1.47 | tok/s 64129
step    830 | loss 2.6185 | lr 2.49e-04 | grad 2.14 | tok/s 64434
step    840 | loss 2.3751 | lr 2.52e-04 | grad 2.17 | tok/s 64138
step    850 | loss 2.5500 | lr 2.55e-04 | grad 2.62 | tok/s 52910
step    860 | loss 2.4394 | lr 2.58e-04 | grad 3.83 | tok/s 51018
step    870 | loss 2.4146 | lr 2.61e-04 | grad 2.31 | tok/s 53685
step    880 | loss 2.4797 | lr 2.64e-04 | grad 2.27 | tok/s 51809
step    890 | loss 2.3279 | lr 2.67e-04 | grad 2.06 | tok/s 55922
step    900 | loss 2.6759 | lr 2.70e-04 | grad 2.53 | tok/s 59467
step    910 | loss 2.3623 | lr 2.73e-04 | grad 2.36 | tok/s 60842
step    920 | loss 2.3064 | lr 2.76e-04 | grad 2.88 | tok/s 60691
step    930 | loss 2.4061 | lr 2.79e-04 | grad 2.41 | tok/s 61090
step    940 | loss 2.2963 | lr 2.82e-04 | grad 2.30 | tok/s 59199
step    950 | loss 2.4124 | lr 2.85e-04 | grad 7.78 | tok/s 62430
step    960 | loss 2.2930 | lr 2.88e-04 | grad 3.62 | tok/s 63015
step    970 | loss 2.1096 | lr 2.91e-04 | grad 1.80 | tok/s 63594
step    980 | loss 2.1723 | lr 2.94e-04 | grad 3.92 | tok/s 60759
step    990 | loss 2.4416 | lr 2.97e-04 | grad 2.64 | tok/s 61122
step   1000 | loss 2.3013 | lr 3.00e-04 | grad 3.17 | tok/s 58447
  >>> saved checkpoint: checkpoint_step_001000_loss_2.3013.pt
step   1010 | loss 2.5636 | lr 1.06e-06 | grad 2.39 | tok/s 50414
step   1020 | loss 2.2645 | lr 1.27e-06 | grad 2.34 | tok/s 79861
step   1030 | loss 2.4614 | lr 1.62e-06 | grad 2.38 | tok/s 78654
step   1040 | loss 2.2522 | lr 2.12e-06 | grad 2.64 | tok/s 80381
step   1050 | loss 2.2182 | lr 2.77e-06 | grad 2.23 | tok/s 80617
step   1060 | loss 2.6037 | lr 3.56e-06 | grad 2.88 | tok/s 80856
step   1070 | loss 2.6473 | lr 4.50e-06 | grad 2.09 | tok/s 81087
step   1080 | loss 2.6890 | lr 5.58e-06 | grad 2.06 | tok/s 80131
step   1090 | loss 2.5532 | lr 6.81e-06 | grad 2.12 | tok/s 80588
step   1100 | loss 2.2283 | lr 8.17e-06 | grad 1.98 | tok/s 80147
step   1110 | loss 2.3087 | lr 9.68e-06 | grad 1.05 | tok/s 69589
step   1120 | loss 2.6991 | lr 1.13e-05 | grad 1.19 | tok/s 61597
step   1130 | loss 2.2246 | lr 1.31e-05 | grad 0.86 | tok/s 75140
step   1140 | loss 2.1792 | lr 1.50e-05 | grad 1.24 | tok/s 80368
step   1150 | loss 2.4375 | lr 1.71e-05 | grad 1.18 | tok/s 80283
step   1160 | loss 2.0870 | lr 1.93e-05 | grad 0.62 | tok/s 79392
step   1170 | loss 2.3370 | lr 2.16e-05 | grad 1.03 | tok/s 80211
step   1180 | loss 2.1145 | lr 2.40e-05 | grad 1.06 | tok/s 84455
step   1190 | loss 2.0897 | lr 2.66e-05 | grad 0.59 | tok/s 84389
step   1200 | loss 2.0617 | lr 2.93e-05 | grad 1.08 | tok/s 84462
step   1210 | loss 2.0568 | lr 3.21e-05 | grad 0.68 | tok/s 84424
step   1220 | loss 2.0867 | lr 3.50e-05 | grad 1.27 | tok/s 82998
step   1230 | loss 2.0100 | lr 3.80e-05 | grad 1.26 | tok/s 80778
step   1240 | loss 2.1642 | lr 4.12e-05 | grad 1.42 | tok/s 78175
step   1250 | loss 2.2803 | lr 4.45e-05 | grad 2.70 | tok/s 81680
step   1260 | loss 2.2955 | lr 4.78e-05 | grad 2.20 | tok/s 81691
step   1270 | loss 2.3632 | lr 5.13e-05 | grad 1.55 | tok/s 80607
step   1280 | loss 2.2280 | lr 5.48e-05 | grad 1.20 | tok/s 79680
step   1290 | loss 2.1546 | lr 5.85e-05 | grad 1.35 | tok/s 79431
step   1300 | loss 2.1892 | lr 6.22e-05 | grad 1.05 | tok/s 78922
step   1310 | loss 2.3047 | lr 6.61e-05 | grad 1.73 | tok/s 78817
step   1320 | loss 2.2487 | lr 7.00e-05 | grad 1.88 | tok/s 80392
step   1330 | loss 2.2073 | lr 7.40e-05 | grad 1.72 | tok/s 80414
step   1340 | loss 2.1450 | lr 7.81e-05 | grad 1.31 | tok/s 80440
step   1350 | loss 2.2449 | lr 8.22e-05 | grad 2.20 | tok/s 82528
step   1360 | loss 2.1308 | lr 8.64e-05 | grad 1.41 | tok/s 78441
step   1370 | loss 2.2241 | lr 9.07e-05 | grad 1.41 | tok/s 79570
step   1380 | loss 2.2984 | lr 9.50e-05 | grad 1.58 | tok/s 80195
step   1390 | loss 2.1814 | lr 9.94e-05 | grad 1.43 | tok/s 78188
step   1400 | loss 2.2506 | lr 1.04e-04 | grad 11.62 | tok/s 81501
step   1410 | loss 2.2755 | lr 1.08e-04 | grad 1.90 | tok/s 82286
step   1420 | loss 2.2291 | lr 1.13e-04 | grad 1.68 | tok/s 78223
step   1430 | loss 2.0419 | lr 1.17e-04 | grad 1.36 | tok/s 76442
step   1440 | loss 1.9953 | lr 1.22e-04 | grad 1.77 | tok/s 80715
step   1450 | loss 2.1006 | lr 1.27e-04 | grad 3.02 | tok/s 82437
step   1460 | loss 2.0697 | lr 1.31e-04 | grad 2.31 | tok/s 76833
step   1470 | loss 2.1738 | lr 1.36e-04 | grad 2.53 | tok/s 79635
step   1480 | loss 2.1076 | lr 1.41e-04 | grad 3.11 | tok/s 80536
step   1490 | loss 2.2888 | lr 1.45e-04 | grad 4.59 | tok/s 80386
step   1500 | loss 2.2850 | lr 1.50e-04 | grad 2.78 | tok/s 78236
step   1510 | loss 2.2936 | lr 1.55e-04 | grad 2.25 | tok/s 82330
step   1520 | loss 2.2425 | lr 1.59e-04 | grad 1.81 | tok/s 81586
step   1530 | loss 2.1651 | lr 1.64e-04 | grad 1.53 | tok/s 80876
step   1540 | loss 2.1340 | lr 1.69e-04 | grad 1.78 | tok/s 79437
step   1550 | loss 2.1267 | lr 1.73e-04 | grad 5.44 | tok/s 82542
step   1560 | loss 2.5601 | lr 1.78e-04 | grad 3.20 | tok/s 80482
step   1570 | loss 2.1650 | lr 1.83e-04 | grad 2.59 | tok/s 78949
step   1580 | loss 2.3263 | lr 1.87e-04 | grad 2.59 | tok/s 81457
step   1590 | loss 2.0582 | lr 1.92e-04 | grad 2.59 | tok/s 79515
step   1600 | loss 2.0886 | lr 1.96e-04 | grad 2.22 | tok/s 78090
step   1610 | loss 1.9373 | lr 2.01e-04 | grad 1.45 | tok/s 82463
step   1620 | loss 2.1208 | lr 2.05e-04 | grad 1.86 | tok/s 81356
step   1630 | loss 2.1690 | lr 2.09e-04 | grad 2.52 | tok/s 82015
step   1640 | loss 2.0823 | lr 2.14e-04 | grad 1.87 | tok/s 79185
step   1650 | loss 2.1064 | lr 2.18e-04 | grad 2.45 | tok/s 78040
step   1660 | loss 2.1184 | lr 2.22e-04 | grad 2.61 | tok/s 78515
step   1670 | loss 2.2222 | lr 2.26e-04 | grad 2.38 | tok/s 81896
step   1680 | loss 2.5627 | lr 2.30e-04 | grad 2.19 | tok/s 81940
step   1690 | loss 2.1420 | lr 2.34e-04 | grad 2.17 | tok/s 80066
step   1700 | loss 2.4907 | lr 2.38e-04 | grad 1.98 | tok/s 81735
step   1710 | loss 2.2143 | lr 2.42e-04 | grad 2.22 | tok/s 79335
step   1720 | loss 2.2047 | lr 2.45e-04 | grad 2.72 | tok/s 79697
step   1730 | loss 2.3346 | lr 2.49e-04 | grad 2.86 | tok/s 79666
step   1740 | loss 2.2021 | lr 2.52e-04 | grad 2.30 | tok/s 80956
step   1750 | loss 2.0738 | lr 2.56e-04 | grad 2.27 | tok/s 77978
step   1760 | loss 2.3345 | lr 2.59e-04 | grad 2.47 | tok/s 79099
step   1770 | loss 2.2430 | lr 2.62e-04 | grad 1.81 | tok/s 80959
step   1780 | loss 2.1340 | lr 2.65e-04 | grad 2.31 | tok/s 77873
step   1790 | loss 2.3484 | lr 2.68e-04 | grad 1.62 | tok/s 79292
step   1800 | loss 2.0588 | lr 2.71e-04 | grad 2.67 | tok/s 80743
step   1810 | loss 2.0477 | lr 2.74e-04 | grad 1.83 | tok/s 80331
step   1820 | loss 2.0722 | lr 2.76e-04 | grad 2.02 | tok/s 79380
step   1830 | loss 2.0810 | lr 2.79e-04 | grad 1.41 | tok/s 79217
step   1840 | loss 2.0685 | lr 2.81e-04 | grad 3.05 | tok/s 78577
step   1850 | loss 2.3269 | lr 2.83e-04 | grad 2.50 | tok/s 79301
step   1860 | loss 2.0603 | lr 2.86e-04 | grad 1.97 | tok/s 79198
step   1870 | loss 2.1182 | lr 2.88e-04 | grad 1.97 | tok/s 80935
step   1880 | loss 2.0520 | lr 2.89e-04 | grad 3.22 | tok/s 81054
step   1890 | loss 2.1643 | lr 2.91e-04 | grad 2.81 | tok/s 79763
step   1900 | loss 2.1708 | lr 2.93e-04 | grad 1.76 | tok/s 80480
step   1910 | loss 2.2031 | lr 2.94e-04 | grad 3.11 | tok/s 79552
step   1920 | loss 2.1116 | lr 2.95e-04 | grad 1.94 | tok/s 81909
step   1930 | loss 2.0705 | lr 2.96e-04 | grad 2.06 | tok/s 81219
step   1940 | loss 1.9580 | lr 2.97e-04 | grad 2.45 | tok/s 82828
step   1950 | loss 2.0689 | lr 2.98e-04 | grad 2.58 | tok/s 80570
step   1960 | loss 2.4420 | lr 2.99e-04 | grad 4.09 | tok/s 82289
step   1970 | loss 2.1939 | lr 2.99e-04 | grad 3.36 | tok/s 79484
step   1980 | loss 2.1868 | lr 3.00e-04 | grad 2.72 | tok/s 79343
step   1990 | loss 2.2776 | lr 3.00e-04 | grad 2.72 | tok/s 81242
step   2000 | loss 2.2256 | lr 3.00e-04 | grad 2.64 | tok/s 81994
  >>> saved checkpoint: checkpoint_step_002000_loss_2.2256.pt
step   2010 | loss 1.9534 | lr 3.00e-04 | grad 2.02 | tok/s 58108
step   2020 | loss 1.7657 | lr 3.00e-04 | grad 1.88 | tok/s 84360
step   2030 | loss 2.0361 | lr 2.99e-04 | grad 2.14 | tok/s 83387
step   2040 | loss 1.8893 | lr 2.99e-04 | grad 2.16 | tok/s 84311
step   2050 | loss 1.7919 | lr 2.98e-04 | grad 1.69 | tok/s 83111
step   2060 | loss 2.0229 | lr 2.97e-04 | grad 1.59 | tok/s 79425
step   2070 | loss 1.9489 | lr 2.97e-04 | grad 2.25 | tok/s 83525
step   2080 | loss 2.1396 | lr 2.95e-04 | grad 4.47 | tok/s 78944
step   2090 | loss 2.1176 | lr 2.94e-04 | grad 1.86 | tok/s 81620
step   2100 | loss 2.0389 | lr 2.93e-04 | grad 2.38 | tok/s 79229
step   2110 | loss 1.8516 | lr 2.91e-04 | grad 1.97 | tok/s 82060
step   2120 | loss 1.8866 | lr 2.90e-04 | grad 2.38 | tok/s 81347
step   2130 | loss 2.0074 | lr 2.88e-04 | grad 2.84 | tok/s 78911
step   2140 | loss 2.0530 | lr 2.86e-04 | grad 2.67 | tok/s 78801
step   2150 | loss 2.0729 | lr 2.84e-04 | grad 2.20 | tok/s 79972
step   2160 | loss 2.0146 | lr 2.82e-04 | grad 1.46 | tok/s 79221
step   2170 | loss 2.1591 | lr 2.79e-04 | grad 2.23 | tok/s 80048
step   2180 | loss 2.0373 | lr 2.77e-04 | grad 1.72 | tok/s 81534
step   2190 | loss 2.2956 | lr 2.74e-04 | grad 2.11 | tok/s 81438
step   2200 | loss 1.8018 | lr 2.72e-04 | grad 1.73 | tok/s 84235
step   2210 | loss 1.7481 | lr 2.69e-04 | grad 2.64 | tok/s 84227
step   2220 | loss 1.6865 | lr 2.66e-04 | grad 1.49 | tok/s 84245
step   2230 | loss 1.8461 | lr 2.63e-04 | grad 1.42 | tok/s 81335
step   2240 | loss 2.1762 | lr 2.60e-04 | grad 2.91 | tok/s 83239
step   2250 | loss 2.0754 | lr 2.57e-04 | grad 2.14 | tok/s 82466
step   2260 | loss 2.1632 | lr 2.53e-04 | grad 1.91 | tok/s 81382
step   2270 | loss 1.9581 | lr 2.50e-04 | grad 2.56 | tok/s 79556
step   2280 | loss 2.0271 | lr 2.46e-04 | grad 1.38 | tok/s 79592
step   2290 | loss 1.8775 | lr 2.43e-04 | grad 1.76 | tok/s 80662
step   2300 | loss 1.8528 | lr 2.39e-04 | grad 1.47 | tok/s 77968
step   2310 | loss 1.8662 | lr 2.35e-04 | grad 1.48 | tok/s 83019
step   2320 | loss 1.8102 | lr 2.31e-04 | grad 1.18 | tok/s 84416
step   2330 | loss 1.6997 | lr 2.27e-04 | grad 1.41 | tok/s 84225
step   2340 | loss 1.8395 | lr 2.23e-04 | grad 1.58 | tok/s 82345
step   2350 | loss 1.9648 | lr 2.19e-04 | grad 1.59 | tok/s 79938
step   2360 | loss 2.4094 | lr 2.15e-04 | grad 3.50 | tok/s 81451
step   2370 | loss 2.0268 | lr 2.10e-04 | grad 2.28 | tok/s 80952
step   2380 | loss 1.8256 | lr 2.06e-04 | grad 1.96 | tok/s 80088
step   2390 | loss 1.8480 | lr 2.02e-04 | grad 1.91 | tok/s 79811
step   2400 | loss 1.9439 | lr 1.97e-04 | grad 2.03 | tok/s 78921
step   2410 | loss 1.8554 | lr 1.93e-04 | grad 1.72 | tok/s 79669
step   2420 | loss 2.1236 | lr 1.88e-04 | grad 1.66 | tok/s 80262
step   2430 | loss 1.9749 | lr 1.84e-04 | grad 2.05 | tok/s 79354
step   2440 | loss 2.0181 | lr 1.79e-04 | grad 1.72 | tok/s 81466
step   2450 | loss 1.6958 | lr 1.74e-04 | grad 1.52 | tok/s 80264
step   2460 | loss 1.9734 | lr 1.70e-04 | grad 2.02 | tok/s 79847
step   2470 | loss 2.0311 | lr 1.65e-04 | grad 1.29 | tok/s 82067
step   2480 | loss 1.8096 | lr 1.60e-04 | grad 1.30 | tok/s 78662
step   2490 | loss 1.7622 | lr 1.56e-04 | grad 1.48 | tok/s 79076
step   2500 | loss 1.8918 | lr 1.51e-04 | grad 1.73 | tok/s 81393
step   2510 | loss 1.9119 | lr 1.46e-04 | grad 1.60 | tok/s 81006
step   2520 | loss 2.0392 | lr 1.42e-04 | grad 1.76 | tok/s 79068
step   2530 | loss 1.8727 | lr 1.37e-04 | grad 1.38 | tok/s 78314
step   2540 | loss 1.8633 | lr 1.32e-04 | grad 1.33 | tok/s 79144
step   2550 | loss 2.2720 | lr 1.28e-04 | grad 2.80 | tok/s 80145
step   2560 | loss 2.0467 | lr 1.23e-04 | grad 1.53 | tok/s 81699
step   2570 | loss 1.8237 | lr 1.18e-04 | grad 2.94 | tok/s 78484
step   2580 | loss 1.9437 | lr 1.14e-04 | grad 1.65 | tok/s 81330
step   2590 | loss 1.6476 | lr 1.09e-04 | grad 1.28 | tok/s 79366
step   2600 | loss 1.8295 | lr 1.05e-04 | grad 1.28 | tok/s 81438
step   2610 | loss 1.7976 | lr 1.00e-04 | grad 1.23 | tok/s 82084
step   2620 | loss 1.7315 | lr 9.59e-05 | grad 1.16 | tok/s 84121
step   2630 | loss 1.7245 | lr 9.16e-05 | grad 0.79 | tok/s 81611
step   2640 | loss 1.7773 | lr 8.73e-05 | grad 1.44 | tok/s 79467
step   2650 | loss 1.7174 | lr 8.30e-05 | grad 1.20 | tok/s 76585
step   2660 | loss 2.1465 | lr 7.89e-05 | grad 2.77 | tok/s 82396
step   2670 | loss 1.7282 | lr 7.48e-05 | grad 1.41 | tok/s 84218
step   2680 | loss 1.6748 | lr 7.08e-05 | grad 0.93 | tok/s 83939
step   2690 | loss 1.6137 | lr 6.69e-05 | grad 1.05 | tok/s 83986
step   2700 | loss 1.7771 | lr 6.30e-05 | grad 1.29 | tok/s 81057
step   2710 | loss 1.8554 | lr 5.92e-05 | grad 2.02 | tok/s 78702
step   2720 | loss 2.2574 | lr 5.56e-05 | grad 1.43 | tok/s 82863
step   2730 | loss 1.8111 | lr 5.20e-05 | grad 1.24 | tok/s 80122
step   2740 | loss 1.6547 | lr 4.85e-05 | grad 1.16 | tok/s 79878
step   2750 | loss 1.8583 | lr 4.51e-05 | grad 0.98 | tok/s 80791
step   2760 | loss 1.9072 | lr 4.18e-05 | grad 1.92 | tok/s 77427
step   2770 | loss 1.7257 | lr 3.87e-05 | grad 0.91 | tok/s 81019

Training complete! Final step: 2772
