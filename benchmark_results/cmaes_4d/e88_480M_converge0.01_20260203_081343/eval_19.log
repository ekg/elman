Using device: cuda
Output directory: benchmark_results/cmaes_4d/e88_480M_converge0.01_20260203_081343/eval_19/levelE88_100m_20260203_091435
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 211,696,086 parameters
Using schedule-free AdamW (lr=0.0009961372669712177)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 4.6752 | lr 9.96e-04 | grad 9.50 | tok/s 17037
step     20 | loss 4.4858 | lr 9.96e-04 | grad 10.50 | tok/s 35253
step     30 | loss 3.2805 | lr 9.96e-04 | grad 3.69 | tok/s 35515
step     40 | loss 2.5942 | lr 9.96e-04 | grad 3.06 | tok/s 35287
step     50 | loss 2.2069 | lr 9.96e-04 | grad 1.82 | tok/s 35086
step     60 | loss 2.8800 | lr 9.96e-04 | grad 3.41 | tok/s 33634
step     70 | loss 2.4451 | lr 9.96e-04 | grad 3.34 | tok/s 34092
step     80 | loss 2.3712 | lr 9.96e-04 | grad 2.72 | tok/s 33794
step     90 | loss 2.3421 | lr 9.96e-04 | grad 2.34 | tok/s 32915
step    100 | loss 1.9557 | lr 9.96e-04 | grad 2.05 | tok/s 34024
step    110 | loss 2.2895 | lr 9.96e-04 | grad 1.48 | tok/s 32864
step    120 | loss 2.2550 | lr 9.96e-04 | grad 2.31 | tok/s 33037
step    130 | loss 2.0327 | lr 9.96e-04 | grad 2.28 | tok/s 33829
step    140 | loss 1.8517 | lr 9.96e-04 | grad 1.86 | tok/s 32242
step    150 | loss 1.9008 | lr 9.96e-04 | grad 1.03 | tok/s 32481
step    160 | loss 1.9137 | lr 9.96e-04 | grad 2.14 | tok/s 32544
step    170 | loss 2.0242 | lr 9.96e-04 | grad 2.08 | tok/s 33288
step    180 | loss 1.6776 | lr 9.96e-04 | grad 1.79 | tok/s 33174
step    190 | loss 1.4011 | lr 9.96e-04 | grad 1.18 | tok/s 34357
step    200 | loss 1.6313 | lr 9.96e-04 | grad 1.56 | tok/s 33353
step    210 | loss 1.7741 | lr 9.96e-04 | grad 1.38 | tok/s 33849
step    220 | loss 1.7326 | lr 9.96e-04 | grad 1.82 | tok/s 33182
step    230 | loss 1.6492 | lr 9.96e-04 | grad 1.43 | tok/s 33056
step    240 | loss 1.7070 | lr 9.96e-04 | grad 1.46 | tok/s 33785
step    250 | loss 1.8058 | lr 9.96e-04 | grad 1.43 | tok/s 33005
step    260 | loss 1.6258 | lr 9.96e-04 | grad 1.57 | tok/s 32289
step    270 | loss 1.6545 | lr 9.96e-04 | grad 2.83 | tok/s 32982
step    280 | loss 1.4637 | lr 9.96e-04 | grad 1.59 | tok/s 34035
step    290 | loss 1.3428 | lr 9.96e-04 | grad 1.30 | tok/s 34377
step    300 | loss 1.3504 | lr 9.96e-04 | grad 1.46 | tok/s 34425
step    310 | loss 1.4644 | lr 9.96e-04 | grad 1.55 | tok/s 34054
step    320 | loss 1.6547 | lr 9.96e-04 | grad 0.92 | tok/s 32559
step    330 | loss 1.6572 | lr 9.96e-04 | grad 1.95 | tok/s 33584
step    340 | loss 1.6319 | lr 9.96e-04 | grad 1.44 | tok/s 32528
step    350 | loss 1.5780 | lr 9.96e-04 | grad 0.98 | tok/s 32326
step    360 | loss 1.4637 | lr 9.96e-04 | grad 1.34 | tok/s 33435
step    370 | loss 1.7948 | lr 9.96e-04 | grad 1.23 | tok/s 33465
step    380 | loss 1.5430 | lr 9.96e-04 | grad 1.14 | tok/s 34007
step    390 | loss 1.5258 | lr 9.96e-04 | grad 1.57 | tok/s 33160
step    400 | loss 1.4962 | lr 9.96e-04 | grad 1.06 | tok/s 33495
step    410 | loss 1.5286 | lr 9.96e-04 | grad 1.34 | tok/s 32435
step    420 | loss 1.5815 | lr 9.96e-04 | grad 1.17 | tok/s 32670
step    430 | loss 1.6026 | lr 9.96e-04 | grad 2.56 | tok/s 33659
step    440 | loss 1.5486 | lr 9.96e-04 | grad 1.17 | tok/s 33079
step    450 | loss 1.5408 | lr 9.96e-04 | grad 1.10 | tok/s 33060
step    460 | loss 1.5622 | lr 9.96e-04 | grad 1.45 | tok/s 33085
step    470 | loss 1.4247 | lr 9.96e-04 | grad 1.09 | tok/s 32158
step    480 | loss 1.4575 | lr 9.96e-04 | grad 1.27 | tok/s 32890
step    490 | loss 1.8280 | lr 9.96e-04 | grad 1.34 | tok/s 33843
step    500 | loss 1.5061 | lr 9.96e-04 | grad 2.66 | tok/s 33041
step    510 | loss 1.2943 | lr 9.96e-04 | grad 0.85 | tok/s 34078
step    520 | loss 1.9416 | lr 9.96e-04 | grad 2.11 | tok/s 33141
step    530 | loss 1.3371 | lr 9.96e-04 | grad 2.81 | tok/s 33616
step    540 | loss 1.3914 | lr 9.96e-04 | grad 1.29 | tok/s 33919
step    550 | loss 1.2411 | lr 9.96e-04 | grad 1.26 | tok/s 34447
step    560 | loss 1.3771 | lr 9.96e-04 | grad 3.34 | tok/s 33950
step    570 | loss 1.7327 | lr 9.96e-04 | grad 1.07 | tok/s 34074
step    580 | loss 1.8026 | lr 9.96e-04 | grad 3.41 | tok/s 32881
step    590 | loss 1.4489 | lr 9.96e-04 | grad 1.27 | tok/s 33155
step    600 | loss 1.3974 | lr 9.96e-04 | grad 1.19 | tok/s 34448
step    610 | loss 1.4213 | lr 9.96e-04 | grad 1.15 | tok/s 32729
step    620 | loss 1.3500 | lr 9.96e-04 | grad 1.34 | tok/s 33941
step    630 | loss 1.4961 | lr 9.96e-04 | grad 1.23 | tok/s 33889
step    640 | loss 1.4294 | lr 9.96e-04 | grad 1.35 | tok/s 33162
step    650 | loss 1.5384 | lr 9.96e-04 | grad 3.12 | tok/s 32747
step    660 | loss 1.5278 | lr 9.96e-04 | grad 1.38 | tok/s 33743
step    670 | loss 1.5041 | lr 9.96e-04 | grad 1.18 | tok/s 33095
step    680 | loss 1.4745 | lr 9.96e-04 | grad 1.40 | tok/s 32853
step    690 | loss 1.5805 | lr 9.96e-04 | grad 1.68 | tok/s 33138
step    700 | loss 1.4602 | lr 9.96e-04 | grad 1.05 | tok/s 33454
step    710 | loss 1.3931 | lr 9.96e-04 | grad 5.03 | tok/s 33123
step    720 | loss 1.5728 | lr 9.96e-04 | grad 0.96 | tok/s 33355
step    730 | loss 1.5610 | lr 9.96e-04 | grad 2.61 | tok/s 33263
step    740 | loss 1.3808 | lr 9.96e-04 | grad 1.22 | tok/s 32899
step    750 | loss 1.6854 | lr 9.96e-04 | grad 1.30 | tok/s 33306
step    760 | loss 1.4024 | lr 9.96e-04 | grad 1.46 | tok/s 33265
step    770 | loss 1.4917 | lr 9.96e-04 | grad 1.44 | tok/s 33760
step    780 | loss 1.3175 | lr 9.96e-04 | grad 1.17 | tok/s 33864
step    790 | loss 1.3670 | lr 9.96e-04 | grad 3.33 | tok/s 33535
step    800 | loss 1.3553 | lr 9.96e-04 | grad 1.06 | tok/s 33304
step    810 | loss 2.0610 | lr 9.96e-04 | grad 2.98 | tok/s 34301
step    820 | loss 1.6972 | lr 9.96e-04 | grad 1.93 | tok/s 34584
step    830 | loss 1.4673 | lr 9.96e-04 | grad 1.66 | tok/s 34586
step    840 | loss 1.4934 | lr 9.96e-04 | grad 1.01 | tok/s 32981
step    850 | loss 1.3998 | lr 9.96e-04 | grad 0.84 | tok/s 33392
step    860 | loss 1.3930 | lr 9.96e-04 | grad 1.16 | tok/s 33283
step    870 | loss 1.4591 | lr 9.96e-04 | grad 1.58 | tok/s 33822
step    880 | loss 1.3786 | lr 9.96e-04 | grad 1.74 | tok/s 32897
step    890 | loss 1.6602 | lr 9.96e-04 | grad 1.51 | tok/s 31810
step    900 | loss 1.3139 | lr 9.96e-04 | grad 1.68 | tok/s 32774
step    910 | loss 1.4630 | lr 9.96e-04 | grad 1.01 | tok/s 33038
step    920 | loss 1.3782 | lr 9.96e-04 | grad 1.14 | tok/s 32848
step    930 | loss 1.4754 | lr 9.96e-04 | grad 1.45 | tok/s 32833
step    940 | loss 1.4407 | lr 9.96e-04 | grad 1.76 | tok/s 33603
step    950 | loss 1.2389 | lr 9.96e-04 | grad 1.77 | tok/s 34493
step    960 | loss 1.1793 | lr 9.96e-04 | grad 1.59 | tok/s 34522
step    970 | loss 1.3826 | lr 9.96e-04 | grad 1.43 | tok/s 33321
step    980 | loss 1.4843 | lr 9.96e-04 | grad 2.11 | tok/s 32752
step    990 | loss 1.4577 | lr 9.96e-04 | grad 1.68 | tok/s 33230
step   1000 | loss 1.3273 | lr 9.96e-04 | grad 1.20 | tok/s 34021
  >>> saved checkpoint: checkpoint_step_001000_loss_1.3273.pt
step   1010 | loss 1.3539 | lr 9.96e-04 | grad 1.27 | tok/s 24405
step   1020 | loss 1.7118 | lr 9.96e-04 | grad 1.16 | tok/s 33243
step   1030 | loss 1.5103 | lr 9.96e-04 | grad 1.00 | tok/s 33274
step   1040 | loss 1.1855 | lr 9.96e-04 | grad 1.02 | tok/s 33060
step   1050 | loss 1.6406 | lr 9.96e-04 | grad 0.97 | tok/s 33944
step   1060 | loss 1.8162 | lr 9.96e-04 | grad 1.37 | tok/s 33278
step   1070 | loss 1.4654 | lr 9.96e-04 | grad 1.69 | tok/s 32790
step   1080 | loss 1.5732 | lr 9.96e-04 | grad 0.95 | tok/s 33702
step   1090 | loss 1.3740 | lr 9.96e-04 | grad 1.40 | tok/s 34234
step   1100 | loss 1.3252 | lr 9.96e-04 | grad 1.53 | tok/s 33742
step   1110 | loss 1.4546 | lr 9.96e-04 | grad 0.97 | tok/s 32616
step   1120 | loss 1.4781 | lr 9.96e-04 | grad 1.05 | tok/s 33294
step   1130 | loss 1.4961 | lr 9.96e-04 | grad 2.38 | tok/s 33201
step   1140 | loss 1.4703 | lr 9.96e-04 | grad 1.97 | tok/s 32770
step   1150 | loss 1.5370 | lr 9.96e-04 | grad 1.22 | tok/s 32436
step   1160 | loss 1.3536 | lr 9.96e-04 | grad 1.59 | tok/s 34163
step   1170 | loss 1.2897 | lr 9.96e-04 | grad 1.34 | tok/s 34481
step   1180 | loss 1.2182 | lr 9.96e-04 | grad 1.46 | tok/s 34477
step   1190 | loss 1.1866 | lr 9.96e-04 | grad 1.31 | tok/s 34503
step   1200 | loss 1.1605 | lr 9.96e-04 | grad 1.14 | tok/s 34498
step   1210 | loss 1.2734 | lr 9.96e-04 | grad 0.86 | tok/s 34002
step   1220 | loss 1.3633 | lr 9.96e-04 | grad 0.85 | tok/s 32458
step   1230 | loss 1.4424 | lr 9.96e-04 | grad 1.18 | tok/s 33671
step   1240 | loss 1.3698 | lr 9.96e-04 | grad 1.59 | tok/s 33317
step   1250 | loss 1.5858 | lr 9.96e-04 | grad 0.89 | tok/s 33142
step   1260 | loss 1.4302 | lr 9.96e-04 | grad 1.47 | tok/s 33096
step   1270 | loss 1.4758 | lr 9.96e-04 | grad 2.70 | tok/s 32650
step   1280 | loss 1.4089 | lr 9.96e-04 | grad 1.20 | tok/s 32816
step   1290 | loss 1.4626 | lr 9.96e-04 | grad 0.80 | tok/s 32702
step   1300 | loss 1.4126 | lr 9.96e-04 | grad 1.10 | tok/s 32916
step   1310 | loss 1.4267 | lr 9.96e-04 | grad 0.98 | tok/s 33507
step   1320 | loss 1.2783 | lr 9.96e-04 | grad 1.19 | tok/s 32963
step   1330 | loss 1.2784 | lr 9.96e-04 | grad 1.07 | tok/s 33764
step   1340 | loss 1.2969 | lr 9.96e-04 | grad 1.11 | tok/s 33015
step   1350 | loss 1.3632 | lr 9.96e-04 | grad 1.68 | tok/s 32845
step   1360 | loss 1.4961 | lr 9.96e-04 | grad 1.13 | tok/s 32881
step   1370 | loss 1.3687 | lr 9.96e-04 | grad 0.87 | tok/s 32883
step   1380 | loss 1.3162 | lr 9.96e-04 | grad 1.07 | tok/s 33784
step   1390 | loss 1.4086 | lr 9.96e-04 | grad 1.62 | tok/s 33819
step   1400 | loss 1.4333 | lr 9.96e-04 | grad 2.20 | tok/s 32492
step   1410 | loss 1.3530 | lr 9.96e-04 | grad 1.01 | tok/s 31974
step   1420 | loss 1.2365 | lr 9.96e-04 | grad 0.90 | tok/s 33080
step   1430 | loss 1.1878 | lr 9.96e-04 | grad 1.02 | tok/s 33949
step   1440 | loss 1.4092 | lr 9.96e-04 | grad 1.93 | tok/s 31359
step   1450 | loss 1.4403 | lr 9.96e-04 | grad 1.33 | tok/s 33109
step   1460 | loss 1.2936 | lr 9.96e-04 | grad 2.77 | tok/s 33394
step   1470 | loss 1.3689 | lr 9.96e-04 | grad 1.47 | tok/s 33185
step   1480 | loss 1.5908 | lr 9.96e-04 | grad 2.16 | tok/s 32688
step   1490 | loss 1.3357 | lr 9.96e-04 | grad 1.02 | tok/s 33795
step   1500 | loss 1.4020 | lr 9.96e-04 | grad 1.29 | tok/s 33557
step   1510 | loss 1.3596 | lr 9.96e-04 | grad 1.06 | tok/s 33290
step   1520 | loss 1.2987 | lr 9.96e-04 | grad 1.22 | tok/s 32886
step   1530 | loss 1.3116 | lr 9.96e-04 | grad 3.50 | tok/s 34179
step   1540 | loss 1.7662 | lr 9.96e-04 | grad 1.19 | tok/s 33213
step   1550 | loss 1.3618 | lr 9.96e-04 | grad 1.21 | tok/s 32813
step   1560 | loss 1.4018 | lr 9.96e-04 | grad 1.16 | tok/s 33680
step   1570 | loss 1.2821 | lr 9.96e-04 | grad 1.44 | tok/s 32956
step   1580 | loss 1.4176 | lr 9.96e-04 | grad 0.88 | tok/s 32696
step   1590 | loss 1.2258 | lr 9.96e-04 | grad 1.02 | tok/s 34158
step   1600 | loss 1.4196 | lr 9.96e-04 | grad 1.02 | tok/s 33444
step   1610 | loss 1.3453 | lr 9.96e-04 | grad 1.54 | tok/s 33831
step   1620 | loss 1.3127 | lr 9.96e-04 | grad 1.27 | tok/s 32436
step   1630 | loss 1.3565 | lr 9.96e-04 | grad 3.16 | tok/s 32765
step   1640 | loss 1.3818 | lr 9.96e-04 | grad 1.17 | tok/s 32841
step   1650 | loss 1.3402 | lr 9.96e-04 | grad 2.08 | tok/s 33935
step   1660 | loss 1.5970 | lr 9.96e-04 | grad 1.38 | tok/s 33564
step   1670 | loss 1.2609 | lr 9.96e-04 | grad 1.07 | tok/s 33172
step   1680 | loss 1.4142 | lr 9.96e-04 | grad 1.60 | tok/s 33574
step   1690 | loss 1.4175 | lr 9.96e-04 | grad 1.12 | tok/s 33288
step   1700 | loss 1.3087 | lr 9.96e-04 | grad 1.66 | tok/s 33029
step   1710 | loss 1.4146 | lr 9.96e-04 | grad 1.05 | tok/s 33153
step   1720 | loss 1.3750 | lr 9.96e-04 | grad 0.96 | tok/s 33067
step   1730 | loss 1.3747 | lr 9.96e-04 | grad 1.55 | tok/s 32709
step   1740 | loss 1.4243 | lr 9.96e-04 | grad 1.23 | tok/s 33198
step   1750 | loss 1.4796 | lr 9.96e-04 | grad 2.25 | tok/s 32962
step   1760 | loss 1.3531 | lr 9.96e-04 | grad 1.65 | tok/s 32831
step   1770 | loss 1.4683 | lr 9.96e-04 | grad 1.05 | tok/s 32717
step   1780 | loss 1.3639 | lr 9.96e-04 | grad 1.76 | tok/s 33621
step   1790 | loss 1.2754 | lr 9.96e-04 | grad 1.55 | tok/s 33777
step   1800 | loss 1.2768 | lr 9.96e-04 | grad 0.95 | tok/s 32703
step   1810 | loss 1.3524 | lr 9.96e-04 | grad 0.89 | tok/s 32825
step   1820 | loss 1.4477 | lr 9.96e-04 | grad 1.20 | tok/s 32959
step   1830 | loss 1.4604 | lr 9.96e-04 | grad 0.91 | tok/s 32692
step   1840 | loss 1.2807 | lr 9.96e-04 | grad 0.80 | tok/s 33127
step   1850 | loss 1.2720 | lr 9.96e-04 | grad 1.20 | tok/s 33894
step   1860 | loss 1.3552 | lr 9.96e-04 | grad 1.25 | tok/s 33614
step   1870 | loss 1.4391 | lr 9.96e-04 | grad 2.92 | tok/s 33311
step   1880 | loss 1.3178 | lr 9.96e-04 | grad 1.30 | tok/s 33404
step   1890 | loss 1.4501 | lr 9.96e-04 | grad 0.95 | tok/s 33157
step   1900 | loss 1.2012 | lr 9.96e-04 | grad 0.86 | tok/s 33657
step   1910 | loss 1.2889 | lr 9.96e-04 | grad 1.26 | tok/s 33642
step   1920 | loss 1.4259 | lr 9.96e-04 | grad 0.91 | tok/s 34280
step   1930 | loss 1.3249 | lr 9.96e-04 | grad 1.31 | tok/s 33488
step   1940 | loss 1.3218 | lr 9.96e-04 | grad 1.00 | tok/s 33752
step   1950 | loss 1.2316 | lr 9.96e-04 | grad 1.35 | tok/s 33135
step   1960 | loss 1.4023 | lr 9.96e-04 | grad 2.00 | tok/s 33579
step   1970 | loss 1.2995 | lr 9.96e-04 | grad 1.41 | tok/s 33016
step   1980 | loss 1.2683 | lr 9.96e-04 | grad 0.98 | tok/s 34035
step   1990 | loss 1.0788 | lr 9.96e-04 | grad 1.29 | tok/s 34607
step   2000 | loss 1.1034 | lr 9.96e-04 | grad 3.62 | tok/s 34583
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1034.pt
step   2010 | loss 1.2468 | lr 9.96e-04 | grad 1.17 | tok/s 25003
step   2020 | loss 1.1406 | lr 9.96e-04 | grad 0.92 | tok/s 34741
step   2030 | loss 1.3592 | lr 9.96e-04 | grad 1.08 | tok/s 33272
step   2040 | loss 1.3870 | lr 9.96e-04 | grad 1.41 | tok/s 33762
step   2050 | loss 1.3476 | lr 9.96e-04 | grad 1.77 | tok/s 33412
step   2060 | loss 1.3910 | lr 9.96e-04 | grad 0.90 | tok/s 33429
step   2070 | loss 1.3173 | lr 9.96e-04 | grad 1.27 | tok/s 33064
step   2080 | loss 1.2001 | lr 9.96e-04 | grad 0.98 | tok/s 33713
step   2090 | loss 1.2264 | lr 9.96e-04 | grad 0.95 | tok/s 33162
step   2100 | loss 1.1056 | lr 9.96e-04 | grad 1.53 | tok/s 33667
step   2110 | loss 1.4177 | lr 9.96e-04 | grad 0.95 | tok/s 32988
step   2120 | loss 1.4195 | lr 9.96e-04 | grad 1.19 | tok/s 33301
step   2130 | loss 1.4125 | lr 9.96e-04 | grad 1.89 | tok/s 32926
step   2140 | loss 1.4484 | lr 9.96e-04 | grad 1.00 | tok/s 33514
step   2150 | loss 1.3153 | lr 9.96e-04 | grad 1.29 | tok/s 33272
step   2160 | loss 1.4472 | lr 9.96e-04 | grad 1.20 | tok/s 34066
step   2170 | loss 1.1645 | lr 9.96e-04 | grad 1.09 | tok/s 34224
step   2180 | loss 1.1266 | lr 9.96e-04 | grad 0.91 | tok/s 34640
step   2190 | loss 1.1182 | lr 9.96e-04 | grad 0.96 | tok/s 34675
step   2200 | loss 1.2043 | lr 9.96e-04 | grad 1.91 | tok/s 33983
step   2210 | loss 1.3247 | lr 9.96e-04 | grad 3.05 | tok/s 34049
step   2220 | loss 1.3181 | lr 9.96e-04 | grad 1.07 | tok/s 34283
step   2230 | loss 1.3987 | lr 9.96e-04 | grad 1.05 | tok/s 33799
step   2240 | loss 1.2642 | lr 9.96e-04 | grad 1.00 | tok/s 33355
step   2250 | loss 1.3946 | lr 9.96e-04 | grad 2.67 | tok/s 33440
step   2260 | loss 1.3279 | lr 9.96e-04 | grad 0.89 | tok/s 33043
step   2270 | loss 1.2958 | lr 9.96e-04 | grad 0.94 | tok/s 32818
step   2280 | loss 1.3311 | lr 9.96e-04 | grad 1.41 | tok/s 33768
step   2290 | loss 1.2860 | lr 9.96e-04 | grad 1.06 | tok/s 34612
step   2300 | loss 1.2220 | lr 9.96e-04 | grad 1.16 | tok/s 34596
step   2310 | loss 1.2876 | lr 9.96e-04 | grad 0.96 | tok/s 34122
step   2320 | loss 1.3413 | lr 9.96e-04 | grad 0.83 | tok/s 33435
step   2330 | loss 1.5856 | lr 9.96e-04 | grad 1.77 | tok/s 33553
step   2340 | loss 1.3738 | lr 9.96e-04 | grad 2.06 | tok/s 33533
step   2350 | loss 1.2798 | lr 9.96e-04 | grad 1.08 | tok/s 33175
step   2360 | loss 1.2696 | lr 9.96e-04 | grad 1.14 | tok/s 32934
step   2370 | loss 1.3690 | lr 9.96e-04 | grad 2.56 | tok/s 33019
step   2380 | loss 1.3148 | lr 9.96e-04 | grad 1.32 | tok/s 32815
step   2390 | loss 1.3565 | lr 9.96e-04 | grad 0.92 | tok/s 33349
step   2400 | loss 1.3142 | lr 9.96e-04 | grad 1.00 | tok/s 32600
step   2410 | loss 1.4267 | lr 9.96e-04 | grad 1.10 | tok/s 32853
step   2420 | loss 1.2362 | lr 9.96e-04 | grad 1.43 | tok/s 33253
step   2430 | loss 1.3433 | lr 9.96e-04 | grad 2.48 | tok/s 33694
step   2440 | loss 1.0522 | lr 9.96e-04 | grad 1.64 | tok/s 34596
step   2450 | loss 1.2492 | lr 9.96e-04 | grad 0.80 | tok/s 33241
step   2460 | loss 1.2617 | lr 9.96e-04 | grad 1.02 | tok/s 32885
step   2470 | loss 1.3065 | lr 9.96e-04 | grad 1.37 | tok/s 33674
step   2480 | loss 1.3056 | lr 9.96e-04 | grad 1.05 | tok/s 33665
step   2490 | loss 1.4946 | lr 9.96e-04 | grad 2.59 | tok/s 33060
step   2500 | loss 1.3799 | lr 9.96e-04 | grad 1.23 | tok/s 32668
step   2510 | loss 1.3219 | lr 9.96e-04 | grad 0.92 | tok/s 33007
step   2520 | loss 1.6792 | lr 9.96e-04 | grad 1.59 | tok/s 33268
step   2530 | loss 1.3996 | lr 9.96e-04 | grad 1.12 | tok/s 33788
step   2540 | loss 1.3475 | lr 9.96e-04 | grad 2.34 | tok/s 32898
step   2550 | loss 1.3190 | lr 9.96e-04 | grad 0.74 | tok/s 33550
step   2560 | loss 1.2706 | lr 9.96e-04 | grad 1.05 | tok/s 33092
step   2570 | loss 1.3721 | lr 9.96e-04 | grad 1.26 | tok/s 34026
step   2580 | loss 1.2866 | lr 9.96e-04 | grad 1.07 | tok/s 33868
step   2590 | loss 1.2117 | lr 9.96e-04 | grad 1.26 | tok/s 34595
step   2600 | loss 1.3167 | lr 9.96e-04 | grad 1.27 | tok/s 33594
step   2610 | loss 1.2946 | lr 9.96e-04 | grad 1.04 | tok/s 32965
step   2620 | loss 1.3271 | lr 9.96e-04 | grad 1.37 | tok/s 32106
step   2630 | loss 1.5661 | lr 9.96e-04 | grad 1.02 | tok/s 34197
step   2640 | loss 1.2236 | lr 9.96e-04 | grad 1.02 | tok/s 34595
step   2650 | loss 1.1872 | lr 9.96e-04 | grad 0.97 | tok/s 34602
step   2660 | loss 1.1680 | lr 9.96e-04 | grad 0.76 | tok/s 34561
step   2670 | loss 1.3232 | lr 9.96e-04 | grad 1.04 | tok/s 33128
step   2680 | loss 1.4327 | lr 9.96e-04 | grad 2.78 | tok/s 32838
step   2690 | loss 1.6018 | lr 9.96e-04 | grad 2.83 | tok/s 34011
step   2700 | loss 1.2530 | lr 9.96e-04 | grad 0.96 | tok/s 33185
step   2710 | loss 1.1758 | lr 9.96e-04 | grad 0.84 | tok/s 33608
step   2720 | loss 1.3881 | lr 9.96e-04 | grad 0.93 | tok/s 33113
step   2730 | loss 1.4496 | lr 9.96e-04 | grad 0.95 | tok/s 32592
step   2740 | loss 1.3203 | lr 9.96e-04 | grad 1.52 | tok/s 33772
step   2750 | loss 1.2644 | lr 9.96e-04 | grad 0.77 | tok/s 32719
step   2760 | loss 1.1998 | lr 9.96e-04 | grad 0.82 | tok/s 33057
step   2770 | loss 1.6071 | lr 9.96e-04 | grad 2.23 | tok/s 33234
step   2780 | loss 1.2093 | lr 9.96e-04 | grad 0.69 | tok/s 33910
step   2790 | loss 1.5328 | lr 9.96e-04 | grad 1.18 | tok/s 33762
step   2800 | loss 1.3272 | lr 9.96e-04 | grad 1.21 | tok/s 33817
step   2810 | loss 1.3171 | lr 9.96e-04 | grad 1.05 | tok/s 33320
step   2820 | loss 1.2349 | lr 9.96e-04 | grad 1.62 | tok/s 33699
step   2830 | loss 1.2210 | lr 9.96e-04 | grad 1.48 | tok/s 33285
step   2840 | loss 1.4051 | lr 9.96e-04 | grad 3.70 | tok/s 33746
step   2850 | loss 1.5332 | lr 9.96e-04 | grad 0.91 | tok/s 33464
step   2860 | loss 1.4760 | lr 9.96e-04 | grad 1.01 | tok/s 33856
step   2870 | loss 1.2709 | lr 9.96e-04 | grad 0.70 | tok/s 32915
step   2880 | loss 1.4626 | lr 9.96e-04 | grad 2.95 | tok/s 32995
step   2890 | loss 1.3027 | lr 9.96e-04 | grad 0.85 | tok/s 33710
step   2900 | loss 1.3313 | lr 9.96e-04 | grad 0.82 | tok/s 33230
step   2910 | loss 1.3063 | lr 9.96e-04 | grad 1.23 | tok/s 33028
step   2920 | loss 1.3051 | lr 9.96e-04 | grad 1.12 | tok/s 33123
step   2930 | loss 1.3972 | lr 9.96e-04 | grad 1.13 | tok/s 32853
step   2940 | loss 1.3132 | lr 9.96e-04 | grad 1.27 | tok/s 33142
step   2950 | loss 1.2845 | lr 9.96e-04 | grad 0.84 | tok/s 33830
step   2960 | loss 1.2084 | lr 9.96e-04 | grad 1.14 | tok/s 32243
step   2970 | loss 1.2349 | lr 9.96e-04 | grad 2.23 | tok/s 33505
step   2980 | loss 1.2652 | lr 9.96e-04 | grad 1.17 | tok/s 33437
step   2990 | loss 1.3388 | lr 9.96e-04 | grad 1.30 | tok/s 33635
step   3000 | loss 1.3320 | lr 9.96e-04 | grad 1.02 | tok/s 33224
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3320.pt
step   3010 | loss 1.3663 | lr 9.96e-04 | grad 2.39 | tok/s 24630
step   3020 | loss 1.2449 | lr 9.96e-04 | grad 1.04 | tok/s 33403
step   3030 | loss 1.2412 | lr 9.96e-04 | grad 0.91 | tok/s 33083
step   3040 | loss 1.2850 | lr 9.96e-04 | grad 0.85 | tok/s 33611
step   3050 | loss 1.2101 | lr 9.96e-04 | grad 1.36 | tok/s 33996
step   3060 | loss 1.2911 | lr 9.96e-04 | grad 0.95 | tok/s 33194
step   3070 | loss 1.2549 | lr 9.96e-04 | grad 0.99 | tok/s 33270
step   3080 | loss 1.2795 | lr 9.96e-04 | grad 1.01 | tok/s 33273
step   3090 | loss 1.4988 | lr 9.96e-04 | grad 2.89 | tok/s 33562
step   3100 | loss 1.6570 | lr 9.96e-04 | grad 2.45 | tok/s 34671
step   3110 | loss 1.3769 | lr 9.96e-04 | grad 2.34 | tok/s 34648
step   3120 | loss 1.3917 | lr 9.96e-04 | grad 1.20 | tok/s 33391
step   3130 | loss 1.8425 | lr 9.96e-04 | grad 1.04 | tok/s 33124
step   3140 | loss 1.1710 | lr 9.96e-04 | grad 1.09 | tok/s 33622
step   3150 | loss 1.5185 | lr 9.96e-04 | grad 3.33 | tok/s 33545
step   3160 | loss 1.2947 | lr 9.96e-04 | grad 0.92 | tok/s 33006
step   3170 | loss 1.4678 | lr 9.96e-04 | grad 1.12 | tok/s 33994
step   3180 | loss 1.2585 | lr 9.96e-04 | grad 1.15 | tok/s 34054
step   3190 | loss 1.3274 | lr 9.96e-04 | grad 0.83 | tok/s 33456
step   3200 | loss 1.3696 | lr 9.96e-04 | grad 1.09 | tok/s 32497
step   3210 | loss 1.3310 | lr 9.96e-04 | grad 0.87 | tok/s 31565
step   3220 | loss 1.1632 | lr 9.96e-04 | grad 0.89 | tok/s 33174
step   3230 | loss 1.3954 | lr 9.96e-04 | grad 1.73 | tok/s 33398
step   3240 | loss 1.3390 | lr 9.96e-04 | grad 0.81 | tok/s 33392
step   3250 | loss 1.3195 | lr 9.96e-04 | grad 2.55 | tok/s 34395
step   3260 | loss 1.3395 | lr 9.96e-04 | grad 1.11 | tok/s 32935
step   3270 | loss 1.3028 | lr 9.96e-04 | grad 0.98 | tok/s 33567
step   3280 | loss 1.4223 | lr 9.96e-04 | grad 1.41 | tok/s 33207
step   3290 | loss 1.2843 | lr 9.96e-04 | grad 1.11 | tok/s 33689
step   3300 | loss 1.3157 | lr 9.96e-04 | grad 1.10 | tok/s 32638
step   3310 | loss 1.3204 | lr 9.96e-04 | grad 1.46 | tok/s 31990
step   3320 | loss 1.3450 | lr 9.96e-04 | grad 1.01 | tok/s 34582
step   3330 | loss 1.2634 | lr 9.96e-04 | grad 0.89 | tok/s 34172
step   3340 | loss 1.2079 | lr 9.96e-04 | grad 1.85 | tok/s 33122
step   3350 | loss 1.4381 | lr 9.96e-04 | grad 26.75 | tok/s 33877
step   3360 | loss 1.3565 | lr 9.96e-04 | grad 0.72 | tok/s 33092
step   3370 | loss 1.1964 | lr 9.96e-04 | grad 0.88 | tok/s 32609
step   3380 | loss 1.2773 | lr 9.96e-04 | grad 2.11 | tok/s 33663
step   3390 | loss 1.2869 | lr 9.96e-04 | grad 1.48 | tok/s 33795
step   3400 | loss 1.7232 | lr 9.96e-04 | grad 2.39 | tok/s 33764
step   3410 | loss 1.2730 | lr 9.96e-04 | grad 0.90 | tok/s 33414
step   3420 | loss 1.4308 | lr 9.96e-04 | grad 1.02 | tok/s 33493
step   3430 | loss 1.0908 | lr 9.96e-04 | grad 1.97 | tok/s 34255
step   3440 | loss 1.3045 | lr 9.96e-04 | grad 1.05 | tok/s 32302
step   3450 | loss 1.3735 | lr 9.96e-04 | grad 1.05 | tok/s 32826
step   3460 | loss 1.2950 | lr 9.96e-04 | grad 1.14 | tok/s 33710
step   3470 | loss 1.5395 | lr 9.96e-04 | grad 1.02 | tok/s 32996
step   3480 | loss 1.2937 | lr 9.96e-04 | grad 1.35 | tok/s 33091
step   3490 | loss 1.2189 | lr 9.96e-04 | grad 0.93 | tok/s 33087
step   3500 | loss 1.2976 | lr 9.96e-04 | grad 1.35 | tok/s 33286
step   3510 | loss 1.3118 | lr 9.96e-04 | grad 0.93 | tok/s 32683
step   3520 | loss 1.3366 | lr 9.96e-04 | grad 0.78 | tok/s 33653
step   3530 | loss 1.3188 | lr 9.96e-04 | grad 0.90 | tok/s 33450
step   3540 | loss 1.2623 | lr 9.96e-04 | grad 1.15 | tok/s 33112
step   3550 | loss 1.4576 | lr 9.96e-04 | grad 0.99 | tok/s 33532
step   3560 | loss 1.3492 | lr 9.96e-04 | grad 1.00 | tok/s 32570
step   3570 | loss 1.2877 | lr 9.96e-04 | grad 0.91 | tok/s 33348
step   3580 | loss 1.2591 | lr 9.96e-04 | grad 1.48 | tok/s 33545
step   3590 | loss 1.3110 | lr 9.96e-04 | grad 1.48 | tok/s 34453
step   3600 | loss 1.2291 | lr 9.96e-04 | grad 1.12 | tok/s 34629
step   3610 | loss 1.2044 | lr 9.96e-04 | grad 1.29 | tok/s 34595
step   3620 | loss 1.1574 | lr 9.96e-04 | grad 1.02 | tok/s 34599
step   3630 | loss 1.1383 | lr 9.96e-04 | grad 0.93 | tok/s 34565
step   3640 | loss 1.1445 | lr 9.96e-04 | grad 1.39 | tok/s 34566
step   3650 | loss 1.2308 | lr 9.96e-04 | grad 1.32 | tok/s 33178
step   3660 | loss 1.4289 | lr 9.96e-04 | grad 0.95 | tok/s 33522
step   3670 | loss 1.1847 | lr 9.96e-04 | grad 0.91 | tok/s 33862
step   3680 | loss 1.2001 | lr 9.96e-04 | grad 1.23 | tok/s 33050
step   3690 | loss 1.2218 | lr 9.96e-04 | grad 1.33 | tok/s 33219
step   3700 | loss 1.2559 | lr 9.96e-04 | grad 1.39 | tok/s 33732
step   3710 | loss 1.2813 | lr 9.96e-04 | grad 1.56 | tok/s 34321
step   3720 | loss 1.2524 | lr 9.96e-04 | grad 3.19 | tok/s 33420
step   3730 | loss 1.2306 | lr 9.96e-04 | grad 1.14 | tok/s 34038
step   3740 | loss 1.3711 | lr 9.96e-04 | grad 0.76 | tok/s 33481
step   3750 | loss 1.2725 | lr 9.96e-04 | grad 1.54 | tok/s 34177
step   3760 | loss 1.2127 | lr 9.96e-04 | grad 1.92 | tok/s 33453

Training complete! Final step: 3764
