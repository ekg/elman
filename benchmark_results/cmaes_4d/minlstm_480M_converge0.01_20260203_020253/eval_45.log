Using device: cuda
Output directory: benchmark_results/cmaes_4d/minlstm_480M_converge0.01_20260203_020253/eval_45/levelminlstm_100m_20260203_043504
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level minlstm, 497,886,208 parameters
Using schedule-free AdamW (lr=0.0002584249438931225)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 5.6703 | lr 2.58e-04 | grad 8.69 | tok/s 12274
step     20 | loss 2.9994 | lr 2.58e-04 | grad 3.28 | tok/s 13755
step     30 | loss 2.8767 | lr 2.58e-04 | grad 4.56 | tok/s 13819
step     40 | loss 2.7867 | lr 2.58e-04 | grad 3.14 | tok/s 13177
step     50 | loss 2.5486 | lr 2.58e-04 | grad 10.25 | tok/s 13141
step     60 | loss 2.9843 | lr 2.58e-04 | grad 4.66 | tok/s 13991
step     70 | loss 2.4217 | lr 2.58e-04 | grad 3.88 | tok/s 14006
step     80 | loss 3.7745 | lr 2.58e-04 | grad 13.19 | tok/s 13942
step     90 | loss 4.3772 | lr 2.58e-04 | grad 5.38 | tok/s 14322
step    100 | loss 3.6625 | lr 2.58e-04 | grad 5.19 | tok/s 14309
step    110 | loss 3.4155 | lr 2.58e-04 | grad 2.84 | tok/s 14309
step    120 | loss 3.3973 | lr 2.58e-04 | grad 6.16 | tok/s 14271
step    130 | loss 3.4224 | lr 2.58e-04 | grad 9.19 | tok/s 14278
step    140 | loss 3.0194 | lr 2.58e-04 | grad 9.69 | tok/s 14255
step    150 | loss 3.0974 | lr 2.58e-04 | grad 9.31 | tok/s 14231
step    160 | loss 3.0078 | lr 2.58e-04 | grad 13.69 | tok/s 14228
step    170 | loss 2.8922 | lr 2.58e-04 | grad 9.06 | tok/s 14221
step    180 | loss 2.8680 | lr 2.58e-04 | grad 3.14 | tok/s 14218
step    190 | loss 2.8499 | lr 2.58e-04 | grad 3.23 | tok/s 14192
step    200 | loss 2.8254 | lr 2.58e-04 | grad 1.86 | tok/s 14189
step    210 | loss 2.6680 | lr 2.58e-04 | grad 3.91 | tok/s 14183
step    220 | loss 2.5897 | lr 2.58e-04 | grad 3.86 | tok/s 14011
step    230 | loss 2.6872 | lr 2.58e-04 | grad 6.38 | tok/s 14001
step    240 | loss 2.6305 | lr 2.58e-04 | grad 2.22 | tok/s 13251
step    250 | loss 2.5266 | lr 2.58e-04 | grad 2.64 | tok/s 13346
step    260 | loss 2.2538 | lr 2.58e-04 | grad 3.66 | tok/s 13998
step    270 | loss 2.3470 | lr 2.58e-04 | grad 3.05 | tok/s 13483
step    280 | loss 2.4014 | lr 2.58e-04 | grad 7.28 | tok/s 13835
step    290 | loss 2.6360 | lr 2.58e-04 | grad 4.69 | tok/s 13781
step    300 | loss 1.6260 | lr 2.58e-04 | grad 3.03 | tok/s 14179
step    310 | loss 2.2800 | lr 2.58e-04 | grad 3.25 | tok/s 13921
step    320 | loss 2.6823 | lr 2.58e-04 | grad 2.75 | tok/s 14128
step    330 | loss 2.3329 | lr 2.58e-04 | grad 2.67 | tok/s 12785
step    340 | loss 2.4946 | lr 2.58e-04 | grad 1.66 | tok/s 13545
step    350 | loss 2.3403 | lr 2.58e-04 | grad 2.34 | tok/s 13390
step    360 | loss 2.4804 | lr 2.58e-04 | grad 3.78 | tok/s 14106
step    370 | loss 2.2458 | lr 2.58e-04 | grad 2.14 | tok/s 12985
step    380 | loss 2.1711 | lr 2.58e-04 | grad 2.08 | tok/s 13267
step    390 | loss 2.0416 | lr 2.58e-04 | grad 2.09 | tok/s 13965
step    400 | loss 1.9742 | lr 2.58e-04 | grad 3.20 | tok/s 13990
step    410 | loss 2.0096 | lr 2.58e-04 | grad 3.53 | tok/s 14100
step    420 | loss 1.9557 | lr 2.58e-04 | grad 2.31 | tok/s 12905
step    430 | loss 2.3376 | lr 2.58e-04 | grad 3.09 | tok/s 13729
step    440 | loss 2.5324 | lr 2.58e-04 | grad 2.31 | tok/s 13490
step    450 | loss 2.7017 | lr 2.58e-04 | grad 30.12 | tok/s 13542
step    460 | loss 2.2825 | lr 2.58e-04 | grad 1.99 | tok/s 13221
step    470 | loss 2.1727 | lr 2.58e-04 | grad 1.93 | tok/s 13451
step    480 | loss 2.2043 | lr 2.58e-04 | grad 2.41 | tok/s 13707
step    490 | loss 2.5935 | lr 2.58e-04 | grad 2.64 | tok/s 13562
step    500 | loss 1.9707 | lr 2.58e-04 | grad 2.22 | tok/s 13341
step    510 | loss 2.1453 | lr 2.58e-04 | grad 2.22 | tok/s 13909
step    520 | loss 2.1198 | lr 2.58e-04 | grad 1.76 | tok/s 14003
step    530 | loss 2.2556 | lr 2.58e-04 | grad 2.59 | tok/s 13844
step    540 | loss 2.1054 | lr 2.58e-04 | grad 1.66 | tok/s 13476
step    550 | loss 1.8709 | lr 2.58e-04 | grad 2.36 | tok/s 13460
step    560 | loss 1.9933 | lr 2.58e-04 | grad 5.81 | tok/s 12337
step    570 | loss 2.0183 | lr 2.58e-04 | grad 2.14 | tok/s 13490
step    580 | loss 1.9353 | lr 2.58e-04 | grad 2.20 | tok/s 13213
step    590 | loss 1.8652 | lr 2.58e-04 | grad 2.08 | tok/s 13067
step    600 | loss 2.3191 | lr 2.58e-04 | grad 2.09 | tok/s 13358
step    610 | loss 2.0149 | lr 2.58e-04 | grad 2.34 | tok/s 13385
step    620 | loss 1.8498 | lr 2.58e-04 | grad 3.50 | tok/s 13298
step    630 | loss 1.9311 | lr 2.58e-04 | grad 3.62 | tok/s 13025
step    640 | loss 2.0996 | lr 2.58e-04 | grad 3.66 | tok/s 13327
step    650 | loss 2.0483 | lr 2.58e-04 | grad 2.70 | tok/s 13460
step    660 | loss 1.9974 | lr 2.58e-04 | grad 2.33 | tok/s 13655
step    670 | loss 1.8897 | lr 2.58e-04 | grad 1.92 | tok/s 13340
step    680 | loss 2.3095 | lr 2.58e-04 | grad 1.62 | tok/s 13896
step    690 | loss 2.1148 | lr 2.58e-04 | grad 2.59 | tok/s 13182
step    700 | loss 2.0735 | lr 2.58e-04 | grad 2.38 | tok/s 14094
step    710 | loss 1.9551 | lr 2.58e-04 | grad 2.45 | tok/s 13692
step    720 | loss 1.7108 | lr 2.58e-04 | grad 2.12 | tok/s 12440
step    730 | loss 1.9001 | lr 2.58e-04 | grad 2.81 | tok/s 14089
step    740 | loss 1.7638 | lr 2.58e-04 | grad 1.63 | tok/s 13834
step    750 | loss 1.7286 | lr 2.58e-04 | grad 2.17 | tok/s 14088
step    760 | loss 1.5384 | lr 2.58e-04 | grad 2.59 | tok/s 14083
step    770 | loss 1.5028 | lr 2.58e-04 | grad 1.82 | tok/s 14088
step    780 | loss 1.4350 | lr 2.58e-04 | grad 2.11 | tok/s 14105
step    790 | loss 1.3486 | lr 2.58e-04 | grad 2.00 | tok/s 14096
step    800 | loss 1.8952 | lr 2.58e-04 | grad 2.64 | tok/s 13167
step    810 | loss 2.1246 | lr 2.58e-04 | grad 2.56 | tok/s 13530
step    820 | loss 1.9334 | lr 2.58e-04 | grad 3.08 | tok/s 13348
step    830 | loss 1.9553 | lr 2.58e-04 | grad 2.22 | tok/s 13606
step    840 | loss 1.9061 | lr 2.58e-04 | grad 2.59 | tok/s 14070
step    850 | loss 1.9931 | lr 2.58e-04 | grad 9.06 | tok/s 14005
step    860 | loss 1.8618 | lr 2.58e-04 | grad 2.31 | tok/s 13951
step    870 | loss 1.8087 | lr 2.58e-04 | grad 1.65 | tok/s 13456
step    880 | loss 1.8607 | lr 2.58e-04 | grad 2.97 | tok/s 13360
step    890 | loss 1.9619 | lr 2.58e-04 | grad 1.72 | tok/s 13629
step    900 | loss 1.8912 | lr 2.58e-04 | grad 2.03 | tok/s 13655
step    910 | loss 1.6791 | lr 2.58e-04 | grad 1.98 | tok/s 13289
step    920 | loss 1.7946 | lr 2.58e-04 | grad 2.34 | tok/s 13924
step    930 | loss 1.8106 | lr 2.58e-04 | grad 1.95 | tok/s 13387
step    940 | loss 1.8594 | lr 2.58e-04 | grad 2.08 | tok/s 13561
step    950 | loss 1.7825 | lr 2.58e-04 | grad 2.19 | tok/s 14016
step    960 | loss 1.6571 | lr 2.58e-04 | grad 2.27 | tok/s 14088
step    970 | loss 1.8314 | lr 2.58e-04 | grad 1.53 | tok/s 13467
step    980 | loss 1.9663 | lr 2.58e-04 | grad 1.62 | tok/s 13564
step    990 | loss 1.7229 | lr 2.58e-04 | grad 1.88 | tok/s 13524
step   1000 | loss 1.8801 | lr 2.58e-04 | grad 2.09 | tok/s 13364
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8801.pt
step   1010 | loss 1.9089 | lr 2.58e-04 | grad 2.03 | tok/s 5800
step   1020 | loss 1.8732 | lr 2.58e-04 | grad 1.89 | tok/s 12862
step   1030 | loss 1.6929 | lr 2.58e-04 | grad 2.22 | tok/s 13170
step   1040 | loss 1.7136 | lr 2.58e-04 | grad 2.34 | tok/s 14025
step   1050 | loss 1.6825 | lr 2.58e-04 | grad 2.16 | tok/s 12796
step   1060 | loss 1.9396 | lr 2.58e-04 | grad 1.84 | tok/s 13917
step   1070 | loss 2.0534 | lr 2.58e-04 | grad 1.73 | tok/s 13997
step   1080 | loss 1.7905 | lr 2.58e-04 | grad 1.98 | tok/s 13274
step   1090 | loss 1.5388 | lr 2.58e-04 | grad 1.73 | tok/s 12956
step   1100 | loss 1.3451 | lr 2.58e-04 | grad 2.48 | tok/s 13719
step   1110 | loss 1.7642 | lr 2.58e-04 | grad 2.00 | tok/s 13930
step   1120 | loss 1.5995 | lr 2.58e-04 | grad 1.93 | tok/s 14115
step   1130 | loss 1.5937 | lr 2.58e-04 | grad 2.36 | tok/s 14107
step   1140 | loss 1.5013 | lr 2.58e-04 | grad 1.77 | tok/s 14104
step   1150 | loss 1.5595 | lr 2.58e-04 | grad 2.20 | tok/s 14115
step   1160 | loss 1.4637 | lr 2.58e-04 | grad 2.05 | tok/s 14112
step   1170 | loss 1.4462 | lr 2.58e-04 | grad 1.99 | tok/s 14113
step   1180 | loss 1.5728 | lr 2.58e-04 | grad 2.09 | tok/s 14129
step   1190 | loss 1.4852 | lr 2.58e-04 | grad 1.86 | tok/s 14121
step   1200 | loss 1.4284 | lr 2.58e-04 | grad 1.94 | tok/s 14126
step   1210 | loss 1.5023 | lr 2.58e-04 | grad 1.95 | tok/s 14108
step   1220 | loss 1.5027 | lr 2.58e-04 | grad 1.97 | tok/s 14112
step   1230 | loss 1.4389 | lr 2.58e-04 | grad 2.16 | tok/s 14115
step   1240 | loss 1.4683 | lr 2.58e-04 | grad 2.08 | tok/s 14128
step   1250 | loss 1.9144 | lr 2.58e-04 | grad 1.95 | tok/s 13562
step   1260 | loss 1.8332 | lr 2.58e-04 | grad 2.31 | tok/s 13072
step   1270 | loss 1.5639 | lr 2.58e-04 | grad 1.95 | tok/s 13702
step   1280 | loss 1.9197 | lr 2.58e-04 | grad 2.45 | tok/s 13105
step   1290 | loss 1.7057 | lr 2.58e-04 | grad 2.05 | tok/s 13761
step   1300 | loss 1.7374 | lr 2.58e-04 | grad 2.61 | tok/s 13865
step   1310 | loss 1.6544 | lr 2.58e-04 | grad 2.17 | tok/s 13400
step   1320 | loss 1.7500 | lr 2.58e-04 | grad 1.49 | tok/s 13804
step   1330 | loss 1.9571 | lr 2.58e-04 | grad 5.34 | tok/s 14055
step   1340 | loss 1.4402 | lr 2.58e-04 | grad 2.17 | tok/s 13333
step   1350 | loss 1.9999 | lr 2.58e-04 | grad 2.72 | tok/s 12854
step   1360 | loss 1.8237 | lr 2.58e-04 | grad 1.85 | tok/s 13611
step   1370 | loss 1.6218 | lr 2.58e-04 | grad 2.81 | tok/s 13410
step   1380 | loss 1.8567 | lr 2.58e-04 | grad 2.11 | tok/s 13312
step   1390 | loss 1.7158 | lr 2.58e-04 | grad 1.73 | tok/s 13196
step   1400 | loss 1.6405 | lr 2.58e-04 | grad 2.08 | tok/s 13161
step   1410 | loss 1.5863 | lr 2.58e-04 | grad 1.93 | tok/s 13527
step   1420 | loss 1.8533 | lr 2.58e-04 | grad 3.75 | tok/s 13191
step   1430 | loss 1.6908 | lr 2.58e-04 | grad 1.54 | tok/s 13676
step   1440 | loss 1.4936 | lr 2.58e-04 | grad 2.16 | tok/s 13703
step   1450 | loss 1.3177 | lr 2.58e-04 | grad 1.92 | tok/s 14113
step   1460 | loss 1.7630 | lr 2.58e-04 | grad 1.91 | tok/s 13382
step   1470 | loss 1.7693 | lr 2.58e-04 | grad 1.77 | tok/s 13601
step   1480 | loss 1.9458 | lr 2.58e-04 | grad 3.94 | tok/s 13844
step   1490 | loss 2.2632 | lr 2.58e-04 | grad 2.39 | tok/s 14061
step   1500 | loss 1.6348 | lr 2.58e-04 | grad 1.79 | tok/s 14108
step   1510 | loss 1.6707 | lr 2.58e-04 | grad 2.06 | tok/s 13920
step   1520 | loss 1.6430 | lr 2.58e-04 | grad 1.64 | tok/s 13924
step   1530 | loss 1.6446 | lr 2.58e-04 | grad 1.84 | tok/s 13842
step   1540 | loss 1.7164 | lr 2.58e-04 | grad 1.71 | tok/s 13254
step   1550 | loss 1.6483 | lr 2.58e-04 | grad 1.66 | tok/s 13757
step   1560 | loss 1.6248 | lr 2.58e-04 | grad 4.84 | tok/s 13609
step   1570 | loss 1.5951 | lr 2.58e-04 | grad 1.59 | tok/s 13782
step   1580 | loss 1.7816 | lr 2.58e-04 | grad 2.86 | tok/s 13781
step   1590 | loss 2.1863 | lr 2.58e-04 | grad 1.94 | tok/s 13561
step   1600 | loss 1.4367 | lr 2.58e-04 | grad 2.12 | tok/s 13810
step   1610 | loss 1.0228 | lr 2.58e-04 | grad 1.89 | tok/s 14008
step   1620 | loss 1.5117 | lr 2.58e-04 | grad 2.48 | tok/s 12612
step   1630 | loss 1.7941 | lr 2.58e-04 | grad 2.41 | tok/s 13725
step   1640 | loss 1.4587 | lr 2.58e-04 | grad 1.83 | tok/s 13963
step   1650 | loss 1.7150 | lr 2.58e-04 | grad 2.25 | tok/s 12657
step   1660 | loss 1.6742 | lr 2.58e-04 | grad 1.51 | tok/s 13363
step   1670 | loss 1.4729 | lr 2.58e-04 | grad 2.16 | tok/s 13775
step   1680 | loss 2.0808 | lr 2.58e-04 | grad 2.58 | tok/s 13132
step   1690 | loss 1.6335 | lr 2.58e-04 | grad 2.58 | tok/s 13375
step   1700 | loss 1.7451 | lr 2.58e-04 | grad 2.08 | tok/s 13806
step   1710 | loss 1.6544 | lr 2.58e-04 | grad 2.89 | tok/s 13289
step   1720 | loss 1.7632 | lr 2.58e-04 | grad 3.09 | tok/s 13799
step   1730 | loss 1.7721 | lr 2.58e-04 | grad 3.16 | tok/s 14094
step   1740 | loss 1.6203 | lr 2.58e-04 | grad 2.38 | tok/s 14006
step   1750 | loss 1.7224 | lr 2.58e-04 | grad 3.09 | tok/s 13599
step   1760 | loss 1.6885 | lr 2.58e-04 | grad 2.09 | tok/s 13360
step   1770 | loss 1.7232 | lr 2.58e-04 | grad 2.05 | tok/s 13782
step   1780 | loss 1.6226 | lr 2.58e-04 | grad 1.81 | tok/s 13377
step   1790 | loss 1.6403 | lr 2.58e-04 | grad 1.70 | tok/s 13578
step   1800 | loss 1.5901 | lr 2.58e-04 | grad 1.75 | tok/s 13670
step   1810 | loss 1.7233 | lr 2.58e-04 | grad 1.72 | tok/s 13442
step   1820 | loss 1.6657 | lr 2.58e-04 | grad 2.11 | tok/s 13198
step   1830 | loss 1.7089 | lr 2.58e-04 | grad 2.83 | tok/s 13782
step   1840 | loss 1.7246 | lr 2.58e-04 | grad 1.52 | tok/s 13296
step   1850 | loss 1.5959 | lr 2.58e-04 | grad 1.67 | tok/s 13725
step   1860 | loss 1.4801 | lr 2.58e-04 | grad 1.86 | tok/s 13788
step   1870 | loss 1.5993 | lr 2.58e-04 | grad 1.86 | tok/s 13109
step   1880 | loss 1.3666 | lr 2.58e-04 | grad 1.55 | tok/s 13397
step   1890 | loss 1.7156 | lr 2.58e-04 | grad 1.72 | tok/s 12628
step   1900 | loss 1.5800 | lr 2.58e-04 | grad 1.71 | tok/s 13744
step   1910 | loss 1.5712 | lr 2.58e-04 | grad 1.72 | tok/s 12809
step   1920 | loss 1.5948 | lr 2.58e-04 | grad 1.66 | tok/s 13800
step   1930 | loss 1.5626 | lr 2.58e-04 | grad 1.77 | tok/s 13552
step   1940 | loss 1.5948 | lr 2.58e-04 | grad 1.98 | tok/s 13456
step   1950 | loss 2.1107 | lr 2.58e-04 | grad 3.50 | tok/s 13968
step   1960 | loss 2.0209 | lr 2.58e-04 | grad 3.25 | tok/s 14109
step   1970 | loss 1.8714 | lr 2.58e-04 | grad 2.27 | tok/s 13765
step   1980 | loss 1.7301 | lr 2.58e-04 | grad 2.17 | tok/s 13317
step   1990 | loss 1.5701 | lr 2.58e-04 | grad 1.88 | tok/s 13587
step   2000 | loss 1.9079 | lr 2.58e-04 | grad 2.05 | tok/s 13662
  >>> saved checkpoint: checkpoint_step_002000_loss_1.9079.pt
step   2010 | loss 1.2470 | lr 2.58e-04 | grad 2.30 | tok/s 6018
step   2020 | loss 1.4652 | lr 2.58e-04 | grad 1.71 | tok/s 13708
step   2030 | loss 1.4754 | lr 2.58e-04 | grad 2.20 | tok/s 14029
step   2040 | loss 1.2798 | lr 2.58e-04 | grad 1.66 | tok/s 14250
step   2050 | loss 1.5001 | lr 2.58e-04 | grad 2.14 | tok/s 14185
step   2060 | loss 1.6761 | lr 2.58e-04 | grad 1.72 | tok/s 12819
step   2070 | loss 1.8658 | lr 2.58e-04 | grad 1.98 | tok/s 13872
step   2080 | loss 2.2727 | lr 2.58e-04 | grad 4.28 | tok/s 13747
step   2090 | loss 2.0337 | lr 2.58e-04 | grad 1.72 | tok/s 14142
step   2100 | loss 1.6412 | lr 2.58e-04 | grad 1.64 | tok/s 13657
step   2110 | loss 1.6974 | lr 2.58e-04 | grad 1.85 | tok/s 13545
step   2120 | loss 1.3085 | lr 2.58e-04 | grad 2.58 | tok/s 13872
step   2130 | loss 0.9883 | lr 2.58e-04 | grad 1.99 | tok/s 14117
step   2140 | loss 1.8009 | lr 2.58e-04 | grad 1.61 | tok/s 13365
step   2150 | loss 1.4549 | lr 2.58e-04 | grad 1.66 | tok/s 14133
step   2160 | loss 1.3714 | lr 2.58e-04 | grad 1.75 | tok/s 14141
step   2170 | loss 1.3827 | lr 2.58e-04 | grad 1.85 | tok/s 14125
step   2180 | loss 1.3660 | lr 2.58e-04 | grad 1.88 | tok/s 14115
step   2190 | loss 1.3711 | lr 2.58e-04 | grad 1.68 | tok/s 14131
step   2200 | loss 1.3554 | lr 2.58e-04 | grad 1.91 | tok/s 14104
step   2210 | loss 1.2960 | lr 2.58e-04 | grad 1.69 | tok/s 14111
step   2220 | loss 1.3074 | lr 2.58e-04 | grad 1.87 | tok/s 14123
step   2230 | loss 1.4230 | lr 2.58e-04 | grad 2.45 | tok/s 13987
step   2240 | loss 1.5444 | lr 2.58e-04 | grad 1.37 | tok/s 13978
step   2250 | loss 1.7046 | lr 2.58e-04 | grad 2.78 | tok/s 13628
step   2260 | loss 1.8666 | lr 2.58e-04 | grad 2.84 | tok/s 13850
step   2270 | loss 1.9183 | lr 2.58e-04 | grad 4.16 | tok/s 13912
step   2280 | loss 1.8298 | lr 2.58e-04 | grad 2.62 | tok/s 13961
step   2290 | loss 1.4959 | lr 2.58e-04 | grad 1.73 | tok/s 14116
step   2300 | loss 2.1858 | lr 2.58e-04 | grad 4.31 | tok/s 13410
step   2310 | loss 1.7240 | lr 2.58e-04 | grad 2.88 | tok/s 13225
step   2320 | loss 1.6749 | lr 2.58e-04 | grad 3.56 | tok/s 13618
step   2330 | loss 2.0263 | lr 2.58e-04 | grad 1.45 | tok/s 13119
step   2340 | loss 1.5302 | lr 2.58e-04 | grad 1.89 | tok/s 13236
step   2350 | loss 1.6161 | lr 2.58e-04 | grad 1.55 | tok/s 13826
step   2360 | loss 1.5300 | lr 2.58e-04 | grad 1.62 | tok/s 13797
step   2370 | loss 1.5696 | lr 2.58e-04 | grad 3.23 | tok/s 13788
step   2380 | loss 1.8383 | lr 2.58e-04 | grad 2.34 | tok/s 14122
step   2390 | loss 1.5268 | lr 2.58e-04 | grad 1.76 | tok/s 14111
step   2400 | loss 1.3053 | lr 2.58e-04 | grad 1.62 | tok/s 14093
step   2410 | loss 1.1855 | lr 2.58e-04 | grad 2.00 | tok/s 13998
step   2420 | loss 1.5610 | lr 2.58e-04 | grad 3.17 | tok/s 13135
step   2430 | loss 1.6266 | lr 2.58e-04 | grad 1.66 | tok/s 13314
step   2440 | loss 1.3611 | lr 2.58e-04 | grad 2.16 | tok/s 13885
step   2450 | loss 1.6016 | lr 2.58e-04 | grad 1.69 | tok/s 13355
step   2460 | loss 1.6011 | lr 2.58e-04 | grad 1.40 | tok/s 13950
step   2470 | loss 1.2720 | lr 2.58e-04 | grad 2.36 | tok/s 14022
step   2480 | loss 1.4519 | lr 2.58e-04 | grad 2.59 | tok/s 14022
step   2490 | loss 1.4168 | lr 2.58e-04 | grad 2.19 | tok/s 13362
step   2500 | loss 1.6629 | lr 2.58e-04 | grad 2.64 | tok/s 13784
step   2510 | loss 1.6192 | lr 2.58e-04 | grad 2.12 | tok/s 14098
step   2520 | loss 1.5620 | lr 2.58e-04 | grad 2.09 | tok/s 14094
step   2530 | loss 1.6320 | lr 2.58e-04 | grad 1.38 | tok/s 13729
step   2540 | loss 1.4619 | lr 2.58e-04 | grad 1.91 | tok/s 13262
step   2550 | loss 1.4864 | lr 2.58e-04 | grad 1.62 | tok/s 14016
step   2560 | loss 1.3488 | lr 2.58e-04 | grad 3.89 | tok/s 13178
step   2570 | loss 1.8038 | lr 2.58e-04 | grad 1.62 | tok/s 13701
step   2580 | loss 1.4515 | lr 2.58e-04 | grad 2.14 | tok/s 12853
step   2590 | loss 1.5283 | lr 2.58e-04 | grad 2.30 | tok/s 13881
step   2600 | loss 1.6849 | lr 2.58e-04 | grad 2.78 | tok/s 12709
step   2610 | loss 1.8303 | lr 2.58e-04 | grad 2.17 | tok/s 14003
step   2620 | loss 1.7133 | lr 2.58e-04 | grad 1.84 | tok/s 13502
step   2630 | loss 1.6138 | lr 2.58e-04 | grad 1.89 | tok/s 13927
step   2640 | loss 1.6247 | lr 2.58e-04 | grad 2.12 | tok/s 13685
step   2650 | loss 1.7066 | lr 2.58e-04 | grad 1.77 | tok/s 13948
step   2660 | loss 1.5961 | lr 2.58e-04 | grad 1.43 | tok/s 13616
step   2670 | loss 1.4890 | lr 2.58e-04 | grad 2.33 | tok/s 13321
step   2680 | loss 1.7306 | lr 2.58e-04 | grad 8.44 | tok/s 13107
step   2690 | loss 1.6734 | lr 2.58e-04 | grad 1.79 | tok/s 13963
step   2700 | loss 1.5358 | lr 2.58e-04 | grad 2.92 | tok/s 13750
step   2710 | loss 1.7526 | lr 2.58e-04 | grad 5.34 | tok/s 13380
step   2720 | loss 1.4900 | lr 2.58e-04 | grad 2.83 | tok/s 12769
step   2730 | loss 1.4381 | lr 2.58e-04 | grad 1.34 | tok/s 13703
step   2740 | loss 1.5203 | lr 2.58e-04 | grad 2.50 | tok/s 13629
step   2750 | loss 2.0429 | lr 2.58e-04 | grad 2.03 | tok/s 13965
step   2760 | loss 1.4928 | lr 2.58e-04 | grad 1.62 | tok/s 13305
step   2770 | loss 1.6338 | lr 2.58e-04 | grad 2.16 | tok/s 13078
step   2780 | loss 1.3218 | lr 2.58e-04 | grad 1.91 | tok/s 14076
step   2790 | loss 1.6964 | lr 2.58e-04 | grad 4.38 | tok/s 13357
step   2800 | loss 1.6827 | lr 2.58e-04 | grad 1.91 | tok/s 13241
step   2810 | loss 1.3300 | lr 2.58e-04 | grad 1.50 | tok/s 13685
step   2820 | loss 1.5277 | lr 2.58e-04 | grad 1.77 | tok/s 12854
step   2830 | loss 1.5203 | lr 2.58e-04 | grad 3.02 | tok/s 13703
step   2840 | loss 1.1224 | lr 2.58e-04 | grad 2.19 | tok/s 14073
step   2850 | loss 1.8042 | lr 2.58e-04 | grad 3.73 | tok/s 13743
step   2860 | loss 1.8993 | lr 2.58e-04 | grad 2.48 | tok/s 13459
step   2870 | loss 1.4895 | lr 2.58e-04 | grad 1.53 | tok/s 13396
step   2880 | loss 1.5921 | lr 2.58e-04 | grad 1.58 | tok/s 13568
step   2890 | loss 1.5537 | lr 2.58e-04 | grad 1.49 | tok/s 14052
step   2900 | loss 1.5814 | lr 2.58e-04 | grad 1.85 | tok/s 13519
step   2910 | loss 1.6696 | lr 2.58e-04 | grad 1.87 | tok/s 13803
step   2920 | loss 1.5455 | lr 2.58e-04 | grad 1.37 | tok/s 12968
step   2930 | loss 1.8276 | lr 2.58e-04 | grad 1.73 | tok/s 13668
step   2940 | loss 1.4055 | lr 2.58e-04 | grad 2.03 | tok/s 13029
step   2950 | loss 1.5075 | lr 2.58e-04 | grad 1.62 | tok/s 13237
step   2960 | loss 1.4667 | lr 2.58e-04 | grad 1.76 | tok/s 13896
step   2970 | loss 1.4224 | lr 2.58e-04 | grad 1.52 | tok/s 13669
step   2980 | loss 1.8481 | lr 2.58e-04 | grad 2.16 | tok/s 13513
step   2990 | loss 2.3725 | lr 2.58e-04 | grad 2.14 | tok/s 13755
step   3000 | loss 1.5029 | lr 2.58e-04 | grad 1.85 | tok/s 13969
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5029.pt
step   3010 | loss 1.4392 | lr 2.58e-04 | grad 3.34 | tok/s 5907
step   3020 | loss 1.4106 | lr 2.58e-04 | grad 1.62 | tok/s 13432
step   3030 | loss 1.5991 | lr 2.58e-04 | grad 2.34 | tok/s 13306
step   3040 | loss 1.5925 | lr 2.58e-04 | grad 1.88 | tok/s 13750
step   3050 | loss 1.5382 | lr 2.58e-04 | grad 1.78 | tok/s 13796
step   3060 | loss 1.4669 | lr 2.58e-04 | grad 2.14 | tok/s 13939
step   3070 | loss 1.7267 | lr 2.58e-04 | grad 3.25 | tok/s 13883
step   3080 | loss 1.5290 | lr 2.58e-04 | grad 1.68 | tok/s 13871
step   3090 | loss 1.5551 | lr 2.58e-04 | grad 1.76 | tok/s 13886
step   3100 | loss 1.6417 | lr 2.58e-04 | grad 1.97 | tok/s 13353
step   3110 | loss 1.4331 | lr 2.58e-04 | grad 1.46 | tok/s 13988
step   3120 | loss 1.0720 | lr 2.58e-04 | grad 1.41 | tok/s 14119
step   3130 | loss 1.5149 | lr 2.58e-04 | grad 5.03 | tok/s 13344
step   3140 | loss 1.3629 | lr 2.58e-04 | grad 1.46 | tok/s 14106
step   3150 | loss 1.2790 | lr 2.58e-04 | grad 1.44 | tok/s 14110
step   3160 | loss 1.4329 | lr 2.58e-04 | grad 1.98 | tok/s 13499
step   3170 | loss 1.7208 | lr 2.58e-04 | grad 1.63 | tok/s 13282
step   3180 | loss 1.5256 | lr 2.58e-04 | grad 2.80 | tok/s 13301
step   3190 | loss 1.3009 | lr 2.58e-04 | grad 3.73 | tok/s 13908
step   3200 | loss 1.3513 | lr 2.58e-04 | grad 5.47 | tok/s 14167
step   3210 | loss 1.6245 | lr 2.58e-04 | grad 1.88 | tok/s 13636
step   3220 | loss 2.2871 | lr 2.58e-04 | grad 2.17 | tok/s 13736
step   3230 | loss 2.1412 | lr 2.58e-04 | grad 2.42 | tok/s 14123
step   3240 | loss 1.9284 | lr 2.58e-04 | grad 3.22 | tok/s 14107
step   3250 | loss 1.8322 | lr 2.58e-04 | grad 2.12 | tok/s 14094
step   3260 | loss 1.7672 | lr 2.58e-04 | grad 2.66 | tok/s 14089
step   3270 | loss 1.6692 | lr 2.58e-04 | grad 2.62 | tok/s 14095
step   3280 | loss 1.6311 | lr 2.58e-04 | grad 1.98 | tok/s 14074
step   3290 | loss 1.5833 | lr 2.58e-04 | grad 2.31 | tok/s 14090
step   3300 | loss 1.5370 | lr 2.58e-04 | grad 2.47 | tok/s 14096
step   3310 | loss 1.5381 | lr 2.58e-04 | grad 2.11 | tok/s 14089
step   3320 | loss 1.5006 | lr 2.58e-04 | grad 2.39 | tok/s 14089
step   3330 | loss 1.5306 | lr 2.58e-04 | grad 2.02 | tok/s 14085
step   3340 | loss 1.8283 | lr 2.58e-04 | grad 2.62 | tok/s 13239
step   3350 | loss 1.5524 | lr 2.58e-04 | grad 1.71 | tok/s 13775
step   3360 | loss 1.5254 | lr 2.58e-04 | grad 1.66 | tok/s 13279
step   3370 | loss 1.4989 | lr 2.58e-04 | grad 1.89 | tok/s 13118
step   3380 | loss 1.6878 | lr 2.58e-04 | grad 3.59 | tok/s 13306
step   3390 | loss 1.5595 | lr 2.58e-04 | grad 1.63 | tok/s 13416
step   3400 | loss 1.2875 | lr 2.58e-04 | grad 3.22 | tok/s 14057
step   3410 | loss 1.2145 | lr 2.58e-04 | grad 1.40 | tok/s 14085
step   3420 | loss 1.5326 | lr 2.58e-04 | grad 2.31 | tok/s 13478
step   3430 | loss 1.5408 | lr 2.58e-04 | grad 1.67 | tok/s 13492
step   3440 | loss 1.5935 | lr 2.58e-04 | grad 1.63 | tok/s 13203
step   3450 | loss 1.4371 | lr 2.58e-04 | grad 1.60 | tok/s 13815
step   3460 | loss 1.8024 | lr 2.58e-04 | grad 3.47 | tok/s 13715
step   3470 | loss 1.4550 | lr 2.58e-04 | grad 1.67 | tok/s 13859
step   3480 | loss 1.5619 | lr 2.58e-04 | grad 1.86 | tok/s 13793
step   3490 | loss 1.3984 | lr 2.58e-04 | grad 1.83 | tok/s 13024
step   3500 | loss 1.3082 | lr 2.58e-04 | grad 1.39 | tok/s 14066
step   3510 | loss 1.4295 | lr 2.58e-04 | grad 1.82 | tok/s 13201
step   3520 | loss 1.6022 | lr 2.58e-04 | grad 1.76 | tok/s 13639
step   3530 | loss 1.7838 | lr 2.58e-04 | grad 4.53 | tok/s 13799
step   3540 | loss 1.6977 | lr 2.58e-04 | grad 1.74 | tok/s 13677
step   3550 | loss 1.9990 | lr 2.58e-04 | grad 11.75 | tok/s 13211
step   3560 | loss 1.6655 | lr 2.58e-04 | grad 2.27 | tok/s 12748
step   3570 | loss 1.5464 | lr 2.58e-04 | grad 1.86 | tok/s 12961
step   3580 | loss 1.3259 | lr 2.58e-04 | grad 1.59 | tok/s 13411
step   3590 | loss 1.2867 | lr 2.58e-04 | grad 1.66 | tok/s 14069
step   3600 | loss 1.4711 | lr 2.58e-04 | grad 1.45 | tok/s 12920
step   3610 | loss 1.6762 | lr 2.58e-04 | grad 1.70 | tok/s 13144
step   3620 | loss 1.3860 | lr 2.58e-04 | grad 1.41 | tok/s 14065
step   3630 | loss 1.5593 | lr 2.58e-04 | grad 1.98 | tok/s 13368
step   3640 | loss 1.7019 | lr 2.58e-04 | grad 1.66 | tok/s 13492
step   3650 | loss 1.5143 | lr 2.58e-04 | grad 1.70 | tok/s 13078
step   3660 | loss 1.4864 | lr 2.58e-04 | grad 1.66 | tok/s 13053
step   3670 | loss 1.6256 | lr 2.58e-04 | grad 2.44 | tok/s 13556
step   3680 | loss 1.2895 | lr 2.58e-04 | grad 1.91 | tok/s 13487
step   3690 | loss 1.4777 | lr 2.58e-04 | grad 2.45 | tok/s 13318
step   3700 | loss 1.5945 | lr 2.58e-04 | grad 1.59 | tok/s 13562
step   3710 | loss 1.3946 | lr 2.58e-04 | grad 1.47 | tok/s 13044
step   3720 | loss 1.6769 | lr 2.58e-04 | grad 1.90 | tok/s 13749
step   3730 | loss 1.6352 | lr 2.58e-04 | grad 4.38 | tok/s 13281
step   3740 | loss 1.3834 | lr 2.58e-04 | grad 2.19 | tok/s 13963
step   3750 | loss 1.7133 | lr 2.58e-04 | grad 2.41 | tok/s 13333
step   3760 | loss 1.4511 | lr 2.58e-04 | grad 2.08 | tok/s 14054
step   3770 | loss 1.3895 | lr 2.58e-04 | grad 2.02 | tok/s 14065
step   3780 | loss 1.3531 | lr 2.58e-04 | grad 1.70 | tok/s 14061
step   3790 | loss 1.3166 | lr 2.58e-04 | grad 1.80 | tok/s 14052
step   3800 | loss 1.3260 | lr 2.58e-04 | grad 2.03 | tok/s 14064
step   3810 | loss 1.3084 | lr 2.58e-04 | grad 1.47 | tok/s 14073
step   3820 | loss 1.2703 | lr 2.58e-04 | grad 1.58 | tok/s 14076
step   3830 | loss 1.2963 | lr 2.58e-04 | grad 1.56 | tok/s 14067
step   3840 | loss 1.2522 | lr 2.58e-04 | grad 1.48 | tok/s 14068
step   3850 | loss 1.2362 | lr 2.58e-04 | grad 1.70 | tok/s 14066
step   3860 | loss 1.3684 | lr 2.58e-04 | grad 2.03 | tok/s 13960
step   3870 | loss 1.5198 | lr 2.58e-04 | grad 2.44 | tok/s 13289
step   3880 | loss 1.7567 | lr 2.58e-04 | grad 1.70 | tok/s 13419
step   3890 | loss 1.6061 | lr 2.58e-04 | grad 2.70 | tok/s 12801
step   3900 | loss 1.4488 | lr 2.58e-04 | grad 1.60 | tok/s 13729
step   3910 | loss 1.6259 | lr 2.58e-04 | grad 1.72 | tok/s 13812
step   3920 | loss 1.5716 | lr 2.58e-04 | grad 3.22 | tok/s 13030
step   3930 | loss 1.6344 | lr 2.58e-04 | grad 1.45 | tok/s 13696
step   3940 | loss 1.6635 | lr 2.58e-04 | grad 2.11 | tok/s 13693
step   3950 | loss 1.4596 | lr 2.58e-04 | grad 1.30 | tok/s 13065
step   3960 | loss 1.6024 | lr 2.58e-04 | grad 1.62 | tok/s 13488
step   3970 | loss 1.6669 | lr 2.58e-04 | grad 2.25 | tok/s 14070
step   3980 | loss 1.6556 | lr 2.58e-04 | grad 1.85 | tok/s 13200
step   3990 | loss 1.4342 | lr 2.58e-04 | grad 1.49 | tok/s 14030
step   4000 | loss 1.0609 | lr 2.58e-04 | grad 1.59 | tok/s 14196
  >>> saved checkpoint: checkpoint_step_004000_loss_1.0609.pt
step   4010 | loss 1.2869 | lr 2.58e-04 | grad 1.56 | tok/s 6165
step   4020 | loss 1.6017 | lr 2.58e-04 | grad 3.44 | tok/s 12682
step   4030 | loss 1.4266 | lr 2.58e-04 | grad 1.40 | tok/s 12843
step   4040 | loss 1.4796 | lr 2.58e-04 | grad 1.55 | tok/s 14028
step   4050 | loss 1.5349 | lr 2.58e-04 | grad 1.55 | tok/s 13135
step   4060 | loss 2.2188 | lr 2.58e-04 | grad 15.81 | tok/s 13398
step   4070 | loss 1.6143 | lr 2.58e-04 | grad 1.28 | tok/s 13365
step   4080 | loss 1.5270 | lr 2.58e-04 | grad 1.70 | tok/s 13642
step   4090 | loss 1.4060 | lr 2.58e-04 | grad 1.60 | tok/s 13805
step   4100 | loss 1.4710 | lr 2.58e-04 | grad 1.77 | tok/s 13546
step   4110 | loss 1.5009 | lr 2.58e-04 | grad 1.48 | tok/s 13873
step   4120 | loss 1.7345 | lr 2.58e-04 | grad 2.53 | tok/s 13507
step   4130 | loss 1.6576 | lr 2.58e-04 | grad 1.59 | tok/s 13197
step   4140 | loss 1.0526 | lr 2.58e-04 | grad 4.91 | tok/s 14248
step   4150 | loss 1.4544 | lr 2.58e-04 | grad 3.62 | tok/s 12977
step   4160 | loss 1.3510 | lr 2.58e-04 | grad 1.89 | tok/s 13104
step   4170 | loss 1.0729 | lr 2.58e-04 | grad 1.94 | tok/s 14129
step   4180 | loss 1.8179 | lr 2.58e-04 | grad 5.34 | tok/s 13717
step   4190 | loss 1.9630 | lr 2.58e-04 | grad 5.06 | tok/s 13986
step   4200 | loss 1.4976 | lr 2.58e-04 | grad 4.38 | tok/s 14119
step   4210 | loss 1.6427 | lr 2.58e-04 | grad 2.38 | tok/s 13487
step   4220 | loss 1.4187 | lr 2.58e-04 | grad 2.41 | tok/s 13392
step   4230 | loss 2.0631 | lr 2.58e-04 | grad 3.61 | tok/s 13541
step   4240 | loss 2.3025 | lr 2.58e-04 | grad 2.89 | tok/s 13992
step   4250 | loss 1.6311 | lr 2.58e-04 | grad 1.66 | tok/s 13087
step   4260 | loss 1.4142 | lr 2.58e-04 | grad 1.68 | tok/s 13135
step   4270 | loss 1.6122 | lr 2.58e-04 | grad 1.58 | tok/s 13868
step   4280 | loss 1.7095 | lr 2.58e-04 | grad 1.88 | tok/s 13768
step   4290 | loss 1.5229 | lr 2.58e-04 | grad 3.36 | tok/s 12968
step   4300 | loss 1.9383 | lr 2.58e-04 | grad 1.77 | tok/s 14074
step   4310 | loss 1.5369 | lr 2.58e-04 | grad 1.71 | tok/s 13548
step   4320 | loss 1.6304 | lr 2.58e-04 | grad 1.80 | tok/s 13649
step   4330 | loss 1.4534 | lr 2.58e-04 | grad 1.77 | tok/s 13465
step   4340 | loss 1.5208 | lr 2.58e-04 | grad 3.09 | tok/s 13987
step   4350 | loss 1.3961 | lr 2.58e-04 | grad 2.33 | tok/s 14003
step   4360 | loss 1.0608 | lr 2.58e-04 | grad 2.27 | tok/s 14034
step   4370 | loss 1.6405 | lr 2.58e-04 | grad 2.08 | tok/s 13983
step   4380 | loss 1.6407 | lr 2.58e-04 | grad 1.41 | tok/s 13129
step   4390 | loss 1.4243 | lr 2.58e-04 | grad 1.80 | tok/s 13932
step   4400 | loss 1.3118 | lr 2.58e-04 | grad 3.36 | tok/s 14116
step   4410 | loss 1.3433 | lr 2.58e-04 | grad 2.78 | tok/s 14120
step   4420 | loss 1.7263 | lr 2.58e-04 | grad 1.66 | tok/s 13524
step   4430 | loss 1.3215 | lr 2.58e-04 | grad 2.22 | tok/s 13518
step   4440 | loss 1.6803 | lr 2.58e-04 | grad 1.92 | tok/s 13039
step   4450 | loss 1.5580 | lr 2.58e-04 | grad 1.77 | tok/s 12961
step   4460 | loss 1.8517 | lr 2.58e-04 | grad 1.50 | tok/s 13766
step   4470 | loss 1.3874 | lr 2.58e-04 | grad 1.82 | tok/s 13817
step   4480 | loss 1.4781 | lr 2.58e-04 | grad 2.00 | tok/s 13463
step   4490 | loss 1.5353 | lr 2.58e-04 | grad 2.44 | tok/s 13387
step   4500 | loss 1.4219 | lr 2.58e-04 | grad 2.25 | tok/s 13357
step   4510 | loss 1.6379 | lr 2.58e-04 | grad 6.75 | tok/s 14030
step   4520 | loss 1.6226 | lr 2.58e-04 | grad 4.19 | tok/s 13869
step   4530 | loss 1.7520 | lr 2.58e-04 | grad 2.25 | tok/s 13151
step   4540 | loss 1.7337 | lr 2.58e-04 | grad 2.94 | tok/s 12863
step   4550 | loss 1.6253 | lr 2.58e-04 | grad 1.44 | tok/s 13167
step   4560 | loss 1.4781 | lr 2.58e-04 | grad 2.31 | tok/s 13944
step   4570 | loss 1.3746 | lr 2.58e-04 | grad 1.52 | tok/s 13807
step   4580 | loss 1.3677 | lr 2.58e-04 | grad 1.66 | tok/s 12949
step   4590 | loss 1.9556 | lr 2.58e-04 | grad 2.70 | tok/s 13294
step   4600 | loss 1.4372 | lr 2.58e-04 | grad 2.20 | tok/s 13298
step   4610 | loss 1.7258 | lr 2.58e-04 | grad 1.28 | tok/s 13327
step   4620 | loss 1.2623 | lr 2.58e-04 | grad 2.02 | tok/s 13744
step   4630 | loss 1.5573 | lr 2.58e-04 | grad 1.45 | tok/s 14091
step   4640 | loss 1.4543 | lr 2.58e-04 | grad 1.67 | tok/s 14085
step   4650 | loss 1.4172 | lr 2.58e-04 | grad 1.54 | tok/s 14093
step   4660 | loss 1.4158 | lr 2.58e-04 | grad 1.72 | tok/s 14091
step   4670 | loss 1.3771 | lr 2.58e-04 | grad 1.59 | tok/s 14092
step   4680 | loss 1.3708 | lr 2.58e-04 | grad 1.71 | tok/s 14081
step   4690 | loss 1.3520 | lr 2.58e-04 | grad 1.84 | tok/s 14083
step   4700 | loss 1.3298 | lr 2.58e-04 | grad 1.66 | tok/s 14083
step   4710 | loss 1.3721 | lr 2.58e-04 | grad 1.46 | tok/s 14084
step   4720 | loss 1.2828 | lr 2.58e-04 | grad 1.60 | tok/s 14080
step   4730 | loss 1.2567 | lr 2.58e-04 | grad 1.78 | tok/s 14092
step   4740 | loss 1.3250 | lr 2.58e-04 | grad 1.89 | tok/s 14101
step   4750 | loss 1.3043 | lr 2.58e-04 | grad 1.54 | tok/s 14094
step   4760 | loss 1.2504 | lr 2.58e-04 | grad 1.87 | tok/s 14102
step   4770 | loss 1.2841 | lr 2.58e-04 | grad 1.73 | tok/s 14093
step   4780 | loss 1.2794 | lr 2.58e-04 | grad 1.57 | tok/s 14100
step   4790 | loss 1.2839 | lr 2.58e-04 | grad 1.22 | tok/s 14108
step   4800 | loss 1.2416 | lr 2.58e-04 | grad 1.39 | tok/s 14114
step   4810 | loss 1.2341 | lr 2.58e-04 | grad 1.55 | tok/s 14102
step   4820 | loss 1.4138 | lr 2.58e-04 | grad 2.27 | tok/s 14073
step   4830 | loss 1.8497 | lr 2.58e-04 | grad 1.78 | tok/s 13479
step   4840 | loss 1.3362 | lr 2.58e-04 | grad 1.66 | tok/s 13833
step   4850 | loss 0.7867 | lr 2.58e-04 | grad 1.52 | tok/s 13897
step   4860 | loss 1.4922 | lr 2.58e-04 | grad 2.25 | tok/s 13586
step   4870 | loss 1.5137 | lr 2.58e-04 | grad 2.88 | tok/s 12910
step   4880 | loss 1.4799 | lr 2.58e-04 | grad 1.71 | tok/s 12956
step   4890 | loss 1.4383 | lr 2.58e-04 | grad 2.33 | tok/s 13737
step   4900 | loss 1.3901 | lr 2.58e-04 | grad 1.66 | tok/s 13466
step   4910 | loss 1.5032 | lr 2.58e-04 | grad 1.53 | tok/s 13756
step   4920 | loss 1.7163 | lr 2.58e-04 | grad 1.55 | tok/s 13963
step   4930 | loss 1.3125 | lr 2.58e-04 | grad 1.66 | tok/s 14092
step   4940 | loss 1.4799 | lr 2.58e-04 | grad 4.28 | tok/s 13258
step   4950 | loss 1.4028 | lr 2.58e-04 | grad 1.65 | tok/s 13282
step   4960 | loss 1.7195 | lr 2.58e-04 | grad 2.48 | tok/s 13980
step   4970 | loss 1.3488 | lr 2.58e-04 | grad 1.78 | tok/s 13988
step   4980 | loss 1.6754 | lr 2.58e-04 | grad 3.42 | tok/s 13617
step   4990 | loss 1.5592 | lr 2.58e-04 | grad 1.54 | tok/s 13190
step   5000 | loss 1.6712 | lr 2.58e-04 | grad 4.16 | tok/s 14091
  >>> saved checkpoint: checkpoint_step_005000_loss_1.6712.pt
step   5010 | loss 1.5625 | lr 2.58e-04 | grad 2.34 | tok/s 5795
step   5020 | loss 1.5766 | lr 2.58e-04 | grad 1.58 | tok/s 13817
step   5030 | loss 1.4038 | lr 2.58e-04 | grad 1.45 | tok/s 13757
step   5040 | loss 1.5677 | lr 2.58e-04 | grad 1.84 | tok/s 13225
step   5050 | loss 1.6609 | lr 2.58e-04 | grad 1.83 | tok/s 13909
step   5060 | loss 1.5858 | lr 2.58e-04 | grad 1.62 | tok/s 13623
step   5070 | loss 1.5058 | lr 2.58e-04 | grad 2.42 | tok/s 13031
step   5080 | loss 1.5201 | lr 2.58e-04 | grad 5.38 | tok/s 13279
step   5090 | loss 1.4736 | lr 2.58e-04 | grad 1.74 | tok/s 13653
step   5100 | loss 1.3446 | lr 2.58e-04 | grad 1.27 | tok/s 13537
step   5110 | loss 1.5863 | lr 2.58e-04 | grad 2.17 | tok/s 13500
step   5120 | loss 1.6687 | lr 2.58e-04 | grad 1.63 | tok/s 13274
step   5130 | loss 1.4152 | lr 2.58e-04 | grad 1.76 | tok/s 13419
step   5140 | loss 1.4957 | lr 2.58e-04 | grad 1.38 | tok/s 13619
step   5150 | loss 1.7978 | lr 2.58e-04 | grad 2.97 | tok/s 14023
step   5160 | loss 1.5809 | lr 2.58e-04 | grad 1.55 | tok/s 12906
step   5170 | loss 1.3970 | lr 2.58e-04 | grad 1.92 | tok/s 13296
step   5180 | loss 1.4415 | lr 2.58e-04 | grad 1.66 | tok/s 13076
step   5190 | loss 1.5196 | lr 2.58e-04 | grad 1.52 | tok/s 12976
step   5200 | loss 1.5665 | lr 2.58e-04 | grad 1.59 | tok/s 14121
step   5210 | loss 1.5854 | lr 2.58e-04 | grad 2.19 | tok/s 13614
step   5220 | loss 1.2792 | lr 2.58e-04 | grad 1.80 | tok/s 14137
step   5230 | loss 1.7157 | lr 2.58e-04 | grad 4.44 | tok/s 13028
step   5240 | loss 1.5894 | lr 2.58e-04 | grad 1.81 | tok/s 13821
step   5250 | loss 1.1643 | lr 2.58e-04 | grad 1.85 | tok/s 14153
step   5260 | loss 1.3349 | lr 2.58e-04 | grad 2.69 | tok/s 13611
step   5270 | loss 1.4576 | lr 2.58e-04 | grad 5.09 | tok/s 13841
step   5280 | loss 1.4876 | lr 2.58e-04 | grad 1.33 | tok/s 12929
step   5290 | loss 1.3214 | lr 2.58e-04 | grad 2.11 | tok/s 13412
step   5300 | loss 1.2869 | lr 2.58e-04 | grad 1.77 | tok/s 13897
step   5310 | loss 1.4816 | lr 2.58e-04 | grad 1.63 | tok/s 13374
step   5320 | loss 1.3822 | lr 2.58e-04 | grad 1.52 | tok/s 14100
step   5330 | loss 1.3011 | lr 2.58e-04 | grad 2.41 | tok/s 14031
step   5340 | loss 1.1812 | lr 2.58e-04 | grad 1.68 | tok/s 13324
step   5350 | loss 1.5304 | lr 2.58e-04 | grad 3.19 | tok/s 13577
step   5360 | loss 1.4457 | lr 2.58e-04 | grad 2.16 | tok/s 13227
step   5370 | loss 1.3651 | lr 2.58e-04 | grad 1.67 | tok/s 13365
step   5380 | loss 1.4405 | lr 2.58e-04 | grad 1.91 | tok/s 12982
step   5390 | loss 1.5283 | lr 2.58e-04 | grad 2.08 | tok/s 13682
step   5400 | loss 1.3972 | lr 2.58e-04 | grad 1.40 | tok/s 13566
step   5410 | loss 1.6335 | lr 2.58e-04 | grad 2.33 | tok/s 13670
step   5420 | loss 1.8495 | lr 2.58e-04 | grad 1.70 | tok/s 13333
step   5430 | loss 1.5310 | lr 2.58e-04 | grad 1.45 | tok/s 13794
step   5440 | loss 1.3863 | lr 2.58e-04 | grad 2.28 | tok/s 13611
step   5450 | loss 1.3981 | lr 2.58e-04 | grad 1.38 | tok/s 13171
step   5460 | loss 1.4056 | lr 2.58e-04 | grad 3.25 | tok/s 13827
step   5470 | loss 1.5839 | lr 2.58e-04 | grad 1.71 | tok/s 13414
step   5480 | loss 1.4764 | lr 2.58e-04 | grad 1.77 | tok/s 13525
step   5490 | loss 1.5234 | lr 2.58e-04 | grad 3.59 | tok/s 13344
step   5500 | loss 1.4484 | lr 2.58e-04 | grad 1.81 | tok/s 14005
step   5510 | loss 1.1240 | lr 2.58e-04 | grad 1.48 | tok/s 14120
step   5520 | loss 1.4727 | lr 2.58e-04 | grad 1.77 | tok/s 13481
step   5530 | loss 1.6663 | lr 2.58e-04 | grad 3.97 | tok/s 13597
step   5540 | loss 1.3197 | lr 2.58e-04 | grad 1.92 | tok/s 13597
step   5550 | loss 1.3301 | lr 2.58e-04 | grad 1.49 | tok/s 13883
step   5560 | loss 1.4041 | lr 2.58e-04 | grad 2.16 | tok/s 13753
step   5570 | loss 1.5003 | lr 2.58e-04 | grad 2.92 | tok/s 13771
step   5580 | loss 1.5781 | lr 2.58e-04 | grad 4.50 | tok/s 13134
step   5590 | loss 1.6139 | lr 2.58e-04 | grad 1.40 | tok/s 13020
step   5600 | loss 1.4629 | lr 2.58e-04 | grad 2.05 | tok/s 13166
step   5610 | loss 1.4114 | lr 2.58e-04 | grad 2.22 | tok/s 14127
step   5620 | loss 1.5522 | lr 2.58e-04 | grad 1.75 | tok/s 13098
step   5630 | loss 1.4697 | lr 2.58e-04 | grad 1.74 | tok/s 12512
step   5640 | loss 1.4341 | lr 2.58e-04 | grad 1.59 | tok/s 12999
step   5650 | loss 1.2472 | lr 2.58e-04 | grad 1.20 | tok/s 13660
step   5660 | loss 1.4315 | lr 2.58e-04 | grad 1.56 | tok/s 13379
step   5670 | loss 1.3950 | lr 2.58e-04 | grad 1.70 | tok/s 12717
step   5680 | loss 1.1596 | lr 2.58e-04 | grad 2.27 | tok/s 14011
step   5690 | loss 1.3085 | lr 2.58e-04 | grad 1.41 | tok/s 14093
step   5700 | loss 1.1701 | lr 2.58e-04 | grad 1.61 | tok/s 14085
step   5710 | loss 1.1393 | lr 2.58e-04 | grad 1.70 | tok/s 14094
step   5720 | loss 1.4058 | lr 2.58e-04 | grad 1.60 | tok/s 13348
step   5730 | loss 1.5454 | lr 2.58e-04 | grad 1.51 | tok/s 13567
step   5740 | loss 1.4580 | lr 2.58e-04 | grad 1.55 | tok/s 13166
step   5750 | loss 1.4607 | lr 2.58e-04 | grad 1.95 | tok/s 12945
step   5760 | loss 1.5406 | lr 2.58e-04 | grad 1.84 | tok/s 13532
step   5770 | loss 1.6195 | lr 2.58e-04 | grad 1.60 | tok/s 13516
step   5780 | loss 1.6277 | lr 2.58e-04 | grad 3.36 | tok/s 13742
step   5790 | loss 1.5268 | lr 2.58e-04 | grad 1.59 | tok/s 13614
step   5800 | loss 1.5133 | lr 2.58e-04 | grad 2.58 | tok/s 12812
step   5810 | loss 1.3243 | lr 2.58e-04 | grad 1.98 | tok/s 14108
step   5820 | loss 1.5343 | lr 2.58e-04 | grad 2.72 | tok/s 13626
step   5830 | loss 1.3903 | lr 2.58e-04 | grad 2.12 | tok/s 13041
step   5840 | loss 1.2319 | lr 2.58e-04 | grad 2.94 | tok/s 13700
step   5850 | loss 1.4209 | lr 2.58e-04 | grad 1.79 | tok/s 13857
step   5860 | loss 1.4823 | lr 2.58e-04 | grad 1.56 | tok/s 13723
step   5870 | loss 1.2982 | lr 2.58e-04 | grad 2.05 | tok/s 13470
step   5880 | loss 1.4323 | lr 2.58e-04 | grad 1.28 | tok/s 13555
step   5890 | loss 1.9453 | lr 2.58e-04 | grad 2.14 | tok/s 13341
step   5900 | loss 1.5348 | lr 2.58e-04 | grad 1.59 | tok/s 13879
step   5910 | loss 1.3501 | lr 2.58e-04 | grad 2.16 | tok/s 12732
step   5920 | loss 1.8633 | lr 2.58e-04 | grad 1.70 | tok/s 13534
step   5930 | loss 1.6777 | lr 2.58e-04 | grad 2.14 | tok/s 13357
step   5940 | loss 1.3367 | lr 2.58e-04 | grad 1.61 | tok/s 13825
step   5950 | loss 1.5260 | lr 2.58e-04 | grad 1.68 | tok/s 13429
step   5960 | loss 1.2826 | lr 2.58e-04 | grad 1.66 | tok/s 14085
step   5970 | loss 1.5949 | lr 2.58e-04 | grad 1.47 | tok/s 13801
step   5980 | loss 1.6218 | lr 2.58e-04 | grad 2.67 | tok/s 13520
step   5990 | loss 1.4499 | lr 2.58e-04 | grad 1.86 | tok/s 13462
step   6000 | loss 1.3528 | lr 2.58e-04 | grad 1.69 | tok/s 13966
  >>> saved checkpoint: checkpoint_step_006000_loss_1.3528.pt
step   6010 | loss 1.4604 | lr 2.58e-04 | grad 2.02 | tok/s 5240
step   6020 | loss 1.5544 | lr 2.58e-04 | grad 1.73 | tok/s 14192
step   6030 | loss 1.4404 | lr 2.58e-04 | grad 2.61 | tok/s 13685
step   6040 | loss 1.3809 | lr 2.58e-04 | grad 2.03 | tok/s 13266

Training complete! Final step: 6046
