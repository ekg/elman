Using device: cuda
Output directory: benchmark_results/cmaes_4d/minlstm_480M_converge0.01_20260203_020253/eval_6/levelminlstm_100m_20260203_020300
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level minlstm, 212,825,088 parameters
Using schedule-free AdamW (lr=0.0005270822173054829)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 4.8572 | lr 5.27e-04 | grad 3.66 | tok/s 22119
step     20 | loss 3.0649 | lr 5.27e-04 | grad 2.98 | tok/s 24611
step     30 | loss 3.1765 | lr 5.27e-04 | grad 4.75 | tok/s 24802
step     40 | loss 3.5922 | lr 5.27e-04 | grad 6.53 | tok/s 25586
step     50 | loss 4.5912 | lr 5.27e-04 | grad 4.06 | tok/s 26267
step     60 | loss 3.6056 | lr 5.27e-04 | grad 3.81 | tok/s 26256
step     70 | loss 3.3187 | lr 5.27e-04 | grad 2.05 | tok/s 26253
step     80 | loss 3.1867 | lr 5.27e-04 | grad 4.34 | tok/s 26220
step     90 | loss 2.9874 | lr 5.27e-04 | grad 1.84 | tok/s 26186
step    100 | loss 2.9403 | lr 5.27e-04 | grad 1.83 | tok/s 26168
step    110 | loss 2.7339 | lr 5.27e-04 | grad 3.73 | tok/s 25989
step    120 | loss 3.2785 | lr 5.27e-04 | grad 2.14 | tok/s 25133
step    130 | loss 2.6361 | lr 5.27e-04 | grad 4.38 | tok/s 25225
step    140 | loss 2.6190 | lr 5.27e-04 | grad 2.48 | tok/s 25227
step    150 | loss 2.6514 | lr 5.27e-04 | grad 2.17 | tok/s 25770
step    160 | loss 2.7446 | lr 5.27e-04 | grad 3.17 | tok/s 25864
step    170 | loss 2.6121 | lr 5.27e-04 | grad 1.68 | tok/s 24262
step    180 | loss 2.6852 | lr 5.27e-04 | grad 3.84 | tok/s 25368
step    190 | loss 2.4290 | lr 5.27e-04 | grad 2.33 | tok/s 24158
step    200 | loss 2.2519 | lr 5.27e-04 | grad 3.61 | tok/s 25765
step    210 | loss 2.2234 | lr 5.27e-04 | grad 1.97 | tok/s 24866
step    220 | loss 2.5671 | lr 5.27e-04 | grad 1.99 | tok/s 25048
step    230 | loss 2.5841 | lr 5.27e-04 | grad 3.11 | tok/s 24614
step    240 | loss 2.3676 | lr 5.27e-04 | grad 1.75 | tok/s 25004
step    250 | loss 2.4685 | lr 5.27e-04 | grad 2.41 | tok/s 24768
step    260 | loss 2.3102 | lr 5.27e-04 | grad 1.83 | tok/s 25685
step    270 | loss 2.3179 | lr 5.27e-04 | grad 1.67 | tok/s 25114
step    280 | loss 2.0864 | lr 5.27e-04 | grad 2.78 | tok/s 23718
step    290 | loss 2.1280 | lr 5.27e-04 | grad 1.84 | tok/s 24545
step    300 | loss 2.2566 | lr 5.27e-04 | grad 1.88 | tok/s 24309
step    310 | loss 2.0709 | lr 5.27e-04 | grad 1.74 | tok/s 24545
step    320 | loss 2.1797 | lr 5.27e-04 | grad 2.48 | tok/s 24257
step    330 | loss 2.1545 | lr 5.27e-04 | grad 1.61 | tok/s 24953
step    340 | loss 2.2634 | lr 5.27e-04 | grad 2.05 | tok/s 25032
step    350 | loss 2.3175 | lr 5.27e-04 | grad 1.91 | tok/s 25086
step    360 | loss 1.9946 | lr 5.27e-04 | grad 1.41 | tok/s 24042
step    370 | loss 2.0461 | lr 5.27e-04 | grad 1.95 | tok/s 25713
step    380 | loss 1.9050 | lr 5.27e-04 | grad 2.06 | tok/s 25940
step    390 | loss 1.7432 | lr 5.27e-04 | grad 1.95 | tok/s 25952
step    400 | loss 1.8487 | lr 5.27e-04 | grad 2.89 | tok/s 25093
step    410 | loss 2.1650 | lr 5.27e-04 | grad 2.23 | tok/s 24747
step    420 | loss 2.1263 | lr 5.27e-04 | grad 1.56 | tok/s 25493
step    430 | loss 2.1001 | lr 5.27e-04 | grad 1.27 | tok/s 25740
step    440 | loss 1.9980 | lr 5.27e-04 | grad 1.57 | tok/s 24696
step    450 | loss 2.0545 | lr 5.27e-04 | grad 1.01 | tok/s 25112
step    460 | loss 1.9097 | lr 5.27e-04 | grad 1.31 | tok/s 25045
step    470 | loss 1.9721 | lr 5.27e-04 | grad 1.36 | tok/s 24818
step    480 | loss 1.9456 | lr 5.27e-04 | grad 2.59 | tok/s 25886
step    490 | loss 2.0353 | lr 5.27e-04 | grad 1.98 | tok/s 24891
step    500 | loss 1.9299 | lr 5.27e-04 | grad 1.17 | tok/s 24765
step    510 | loss 2.1670 | lr 5.27e-04 | grad 1.28 | tok/s 24577
step    520 | loss 1.8550 | lr 5.27e-04 | grad 1.68 | tok/s 24377
step    530 | loss 1.9027 | lr 5.27e-04 | grad 1.40 | tok/s 24665
step    540 | loss 2.0901 | lr 5.27e-04 | grad 1.12 | tok/s 24949
step    550 | loss 1.5567 | lr 5.27e-04 | grad 1.19 | tok/s 24504
step    560 | loss 1.8472 | lr 5.27e-04 | grad 1.38 | tok/s 25588
step    570 | loss 1.7231 | lr 5.27e-04 | grad 1.31 | tok/s 25939
step    580 | loss 1.6694 | lr 5.27e-04 | grad 1.30 | tok/s 25933
step    590 | loss 1.6090 | lr 5.27e-04 | grad 1.29 | tok/s 25925
step    600 | loss 1.6487 | lr 5.27e-04 | grad 1.52 | tok/s 25952
step    610 | loss 1.6188 | lr 5.27e-04 | grad 1.36 | tok/s 25930
step    620 | loss 1.5798 | lr 5.27e-04 | grad 1.52 | tok/s 25936
step    630 | loss 1.8852 | lr 5.27e-04 | grad 1.29 | tok/s 24956
step    640 | loss 1.8114 | lr 5.27e-04 | grad 1.39 | tok/s 24223
step    650 | loss 1.8839 | lr 5.27e-04 | grad 1.56 | tok/s 25299
step    660 | loss 1.8121 | lr 5.27e-04 | grad 1.50 | tok/s 25152
step    670 | loss 1.8864 | lr 5.27e-04 | grad 1.38 | tok/s 25477
step    680 | loss 1.9472 | lr 5.27e-04 | grad 1.51 | tok/s 23952
step    690 | loss 1.8474 | lr 5.27e-04 | grad 1.30 | tok/s 24965
step    700 | loss 1.7558 | lr 5.27e-04 | grad 1.29 | tok/s 24103
step    710 | loss 1.8601 | lr 5.27e-04 | grad 1.17 | tok/s 24795
step    720 | loss 1.7776 | lr 5.27e-04 | grad 1.56 | tok/s 24610
step    730 | loss 1.6137 | lr 5.27e-04 | grad 3.38 | tok/s 25796
step    740 | loss 1.8225 | lr 5.27e-04 | grad 1.16 | tok/s 24846
step    750 | loss 2.2893 | lr 5.27e-04 | grad 1.73 | tok/s 25812
step    760 | loss 1.7432 | lr 5.27e-04 | grad 1.69 | tok/s 25788
step    770 | loss 1.6972 | lr 5.27e-04 | grad 1.38 | tok/s 25030
step    780 | loss 1.7604 | lr 5.27e-04 | grad 1.30 | tok/s 25268
step    790 | loss 1.8129 | lr 5.27e-04 | grad 1.98 | tok/s 25116
step    800 | loss 2.1199 | lr 5.27e-04 | grad 1.20 | tok/s 24980
step    810 | loss 1.2799 | lr 5.27e-04 | grad 1.20 | tok/s 25029
step    820 | loss 1.7734 | lr 5.27e-04 | grad 1.27 | tok/s 24980
step    830 | loss 1.7673 | lr 5.27e-04 | grad 1.20 | tok/s 23778
step    840 | loss 1.8352 | lr 5.27e-04 | grad 2.17 | tok/s 25131
step    850 | loss 1.7875 | lr 5.27e-04 | grad 1.74 | tok/s 24730
step    860 | loss 1.8205 | lr 5.27e-04 | grad 1.39 | tok/s 24758
step    870 | loss 1.9310 | lr 5.27e-04 | grad 2.00 | tok/s 25975
step    880 | loss 1.7653 | lr 5.27e-04 | grad 1.47 | tok/s 25028
step    890 | loss 1.7325 | lr 5.27e-04 | grad 1.20 | tok/s 24734
step    900 | loss 1.7074 | lr 5.27e-04 | grad 1.26 | tok/s 24994
step    910 | loss 1.7863 | lr 5.27e-04 | grad 1.63 | tok/s 24485
step    920 | loss 1.7363 | lr 5.27e-04 | grad 1.01 | tok/s 25209
step    930 | loss 1.7000 | lr 5.27e-04 | grad 1.12 | tok/s 25048
step    940 | loss 1.5986 | lr 5.27e-04 | grad 0.92 | tok/s 24874
step    950 | loss 1.6875 | lr 5.27e-04 | grad 1.44 | tok/s 23721
step    960 | loss 1.6312 | lr 5.27e-04 | grad 0.93 | tok/s 24331
step    970 | loss 1.6422 | lr 5.27e-04 | grad 1.14 | tok/s 24926
step    980 | loss 2.1250 | lr 5.27e-04 | grad 2.81 | tok/s 25740
step    990 | loss 2.0551 | lr 5.27e-04 | grad 1.70 | tok/s 25416
step   1000 | loss 1.7830 | lr 5.27e-04 | grad 0.86 | tok/s 24560
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7830.pt
step   1010 | loss 1.4200 | lr 5.27e-04 | grad 1.15 | tok/s 16785
step   1020 | loss 1.4253 | lr 5.27e-04 | grad 1.10 | tok/s 25679
step   1030 | loss 1.7049 | lr 5.27e-04 | grad 1.00 | tok/s 25503
step   1040 | loss 1.9429 | lr 5.27e-04 | grad 4.94 | tok/s 24504
step   1050 | loss 2.2100 | lr 5.27e-04 | grad 1.16 | tok/s 25709
step   1060 | loss 1.7524 | lr 5.27e-04 | grad 1.48 | tok/s 24859
step   1070 | loss 1.3354 | lr 5.27e-04 | grad 1.38 | tok/s 25557
step   1080 | loss 1.5788 | lr 5.27e-04 | grad 1.60 | tok/s 25588
step   1090 | loss 1.4591 | lr 5.27e-04 | grad 1.30 | tok/s 25957
step   1100 | loss 1.4321 | lr 5.27e-04 | grad 1.34 | tok/s 25959
step   1110 | loss 1.3989 | lr 5.27e-04 | grad 1.31 | tok/s 25965
step   1120 | loss 1.4795 | lr 5.27e-04 | grad 1.31 | tok/s 25699
step   1130 | loss 1.8446 | lr 5.27e-04 | grad 3.84 | tok/s 25494
step   1140 | loss 2.0858 | lr 5.27e-04 | grad 1.43 | tok/s 25379
step   1150 | loss 1.7564 | lr 5.27e-04 | grad 4.97 | tok/s 25484
step   1160 | loss 1.9743 | lr 5.27e-04 | grad 1.42 | tok/s 24933
step   1170 | loss 1.8979 | lr 5.27e-04 | grad 1.30 | tok/s 24457
step   1180 | loss 1.6628 | lr 5.27e-04 | grad 1.13 | tok/s 24769
step   1190 | loss 1.7116 | lr 5.27e-04 | grad 1.42 | tok/s 25674
step   1200 | loss 1.7238 | lr 5.27e-04 | grad 1.13 | tok/s 25958
step   1210 | loss 1.3602 | lr 5.27e-04 | grad 1.52 | tok/s 25397
step   1220 | loss 1.6181 | lr 5.27e-04 | grad 0.99 | tok/s 24653
step   1230 | loss 1.6373 | lr 5.27e-04 | grad 1.17 | tok/s 25039
step   1240 | loss 1.5004 | lr 5.27e-04 | grad 1.19 | tok/s 25681
step   1250 | loss 1.5357 | lr 5.27e-04 | grad 1.11 | tok/s 25129
step   1260 | loss 1.7493 | lr 5.27e-04 | grad 1.84 | tok/s 25778
step   1270 | loss 1.6688 | lr 5.27e-04 | grad 1.40 | tok/s 25301
step   1280 | loss 1.5402 | lr 5.27e-04 | grad 1.23 | tok/s 25412
step   1290 | loss 1.6747 | lr 5.27e-04 | grad 1.10 | tok/s 24492
step   1300 | loss 1.6284 | lr 5.27e-04 | grad 1.82 | tok/s 24376
step   1310 | loss 1.8953 | lr 5.27e-04 | grad 1.25 | tok/s 24970
step   1320 | loss 1.6652 | lr 5.27e-04 | grad 1.50 | tok/s 25389
step   1330 | loss 1.8258 | lr 5.27e-04 | grad 1.12 | tok/s 25258
step   1340 | loss 1.5685 | lr 5.27e-04 | grad 1.20 | tok/s 24568
step   1350 | loss 1.7734 | lr 5.27e-04 | grad 1.14 | tok/s 25351
step   1360 | loss 1.7590 | lr 5.27e-04 | grad 1.00 | tok/s 24623
step   1370 | loss 1.5240 | lr 5.27e-04 | grad 1.03 | tok/s 24725
step   1380 | loss 1.9257 | lr 5.27e-04 | grad 1.02 | tok/s 25404
step   1390 | loss 1.5991 | lr 5.27e-04 | grad 1.33 | tok/s 24468
step   1400 | loss 1.7599 | lr 5.27e-04 | grad 1.77 | tok/s 24919
step   1410 | loss 1.4656 | lr 5.27e-04 | grad 0.92 | tok/s 24733
step   1420 | loss 1.5769 | lr 5.27e-04 | grad 2.02 | tok/s 24990
step   1430 | loss 1.6827 | lr 5.27e-04 | grad 0.88 | tok/s 25302
step   1440 | loss 1.7429 | lr 5.27e-04 | grad 1.24 | tok/s 24894
step   1450 | loss 1.7041 | lr 5.27e-04 | grad 1.38 | tok/s 25684
step   1460 | loss 1.6541 | lr 5.27e-04 | grad 1.12 | tok/s 24870
step   1470 | loss 1.7375 | lr 5.27e-04 | grad 1.23 | tok/s 24717
step   1480 | loss 1.5059 | lr 5.27e-04 | grad 1.20 | tok/s 24325
step   1490 | loss 1.5753 | lr 5.27e-04 | grad 1.23 | tok/s 24932
step   1500 | loss 2.1487 | lr 5.27e-04 | grad 1.33 | tok/s 25411
step   1510 | loss 1.5415 | lr 5.27e-04 | grad 2.78 | tok/s 25274
step   1520 | loss 1.5599 | lr 5.27e-04 | grad 1.22 | tok/s 24483
step   1530 | loss 1.6294 | lr 5.27e-04 | grad 0.95 | tok/s 25271
step   1540 | loss 1.6627 | lr 5.27e-04 | grad 1.79 | tok/s 25550
step   1550 | loss 1.6143 | lr 5.27e-04 | grad 0.87 | tok/s 25495
step   1560 | loss 1.6132 | lr 5.27e-04 | grad 0.89 | tok/s 25110
step   1570 | loss 1.3887 | lr 5.27e-04 | grad 2.72 | tok/s 25266
step   1580 | loss 1.4348 | lr 5.27e-04 | grad 1.14 | tok/s 25978
step   1590 | loss 1.6264 | lr 5.27e-04 | grad 1.05 | tok/s 24606
step   1600 | loss 1.4732 | lr 5.27e-04 | grad 2.78 | tok/s 25007
step   1610 | loss 1.5970 | lr 5.27e-04 | grad 0.95 | tok/s 25547
step   1620 | loss 2.3547 | lr 5.27e-04 | grad 1.52 | tok/s 25607
step   1630 | loss 2.0340 | lr 5.27e-04 | grad 2.23 | tok/s 25966
step   1640 | loss 1.8798 | lr 5.27e-04 | grad 1.93 | tok/s 25984
step   1650 | loss 1.7679 | lr 5.27e-04 | grad 1.75 | tok/s 25962
step   1660 | loss 1.6940 | lr 5.27e-04 | grad 1.87 | tok/s 25986
step   1670 | loss 1.6684 | lr 5.27e-04 | grad 1.65 | tok/s 25977
step   1680 | loss 1.7723 | lr 5.27e-04 | grad 1.27 | tok/s 24836
step   1690 | loss 1.5643 | lr 5.27e-04 | grad 1.22 | tok/s 24352
step   1700 | loss 1.6631 | lr 5.27e-04 | grad 1.14 | tok/s 24637
step   1710 | loss 1.3342 | lr 5.27e-04 | grad 0.93 | tok/s 25933
step   1720 | loss 1.5877 | lr 5.27e-04 | grad 1.16 | tok/s 24868
step   1730 | loss 1.5653 | lr 5.27e-04 | grad 1.23 | tok/s 24923
step   1740 | loss 1.6802 | lr 5.27e-04 | grad 1.19 | tok/s 25457
step   1750 | loss 1.5517 | lr 5.27e-04 | grad 1.05 | tok/s 24753
step   1760 | loss 1.4453 | lr 5.27e-04 | grad 1.36 | tok/s 25135
step   1770 | loss 1.8045 | lr 5.27e-04 | grad 2.48 | tok/s 25313
step   1780 | loss 1.9157 | lr 5.27e-04 | grad 5.34 | tok/s 24789
step   1790 | loss 1.6267 | lr 5.27e-04 | grad 1.17 | tok/s 23653
step   1800 | loss 1.4032 | lr 5.27e-04 | grad 0.98 | tok/s 25341
step   1810 | loss 1.6044 | lr 5.27e-04 | grad 1.23 | tok/s 24021
step   1820 | loss 1.5183 | lr 5.27e-04 | grad 1.02 | tok/s 25311
step   1830 | loss 1.6599 | lr 5.27e-04 | grad 1.05 | tok/s 24477
step   1840 | loss 1.6157 | lr 5.27e-04 | grad 1.73 | tok/s 24534
step   1850 | loss 1.4544 | lr 5.27e-04 | grad 0.83 | tok/s 24723
step   1860 | loss 1.5808 | lr 5.27e-04 | grad 0.98 | tok/s 24509
step   1870 | loss 1.7081 | lr 5.27e-04 | grad 1.76 | tok/s 24919
step   1880 | loss 1.6302 | lr 5.27e-04 | grad 2.42 | tok/s 25157
step   1890 | loss 1.4875 | lr 5.27e-04 | grad 1.38 | tok/s 25983
step   1900 | loss 1.4019 | lr 5.27e-04 | grad 1.47 | tok/s 25965
step   1910 | loss 1.3852 | lr 5.27e-04 | grad 1.27 | tok/s 25961
step   1920 | loss 1.3544 | lr 5.27e-04 | grad 1.22 | tok/s 25977
step   1930 | loss 1.3031 | lr 5.27e-04 | grad 1.15 | tok/s 25961
step   1940 | loss 1.5054 | lr 5.27e-04 | grad 1.55 | tok/s 25132
step   1950 | loss 1.7394 | lr 5.27e-04 | grad 1.48 | tok/s 24160
step   1960 | loss 1.6022 | lr 5.27e-04 | grad 1.08 | tok/s 25352
step   1970 | loss 1.6490 | lr 5.27e-04 | grad 1.11 | tok/s 24622
step   1980 | loss 1.6025 | lr 5.27e-04 | grad 0.88 | tok/s 24650
step   1990 | loss 1.7501 | lr 5.27e-04 | grad 1.43 | tok/s 25435
step   2000 | loss 1.6102 | lr 5.27e-04 | grad 0.79 | tok/s 25094
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6102.pt
step   2010 | loss 1.2675 | lr 5.27e-04 | grad 1.14 | tok/s 17234
step   2020 | loss 1.5358 | lr 5.27e-04 | grad 1.24 | tok/s 23877
step   2030 | loss 1.5308 | lr 5.27e-04 | grad 1.21 | tok/s 24760
step   2040 | loss 1.8906 | lr 5.27e-04 | grad 1.16 | tok/s 24414
step   2050 | loss 1.5084 | lr 5.27e-04 | grad 1.05 | tok/s 25426
step   2060 | loss 1.5449 | lr 5.27e-04 | grad 1.23 | tok/s 24952
step   2070 | loss 1.7694 | lr 5.27e-04 | grad 1.19 | tok/s 25054
step   2080 | loss 1.2513 | lr 5.27e-04 | grad 1.21 | tok/s 24691
step   2090 | loss 1.3767 | lr 5.27e-04 | grad 1.05 | tok/s 24922
step   2100 | loss 1.8929 | lr 5.27e-04 | grad 2.27 | tok/s 25535
step   2110 | loss 1.7838 | lr 5.27e-04 | grad 1.73 | tok/s 25447
step   2120 | loss 1.7237 | lr 5.27e-04 | grad 4.75 | tok/s 24820
step   2130 | loss 2.1745 | lr 5.27e-04 | grad 1.22 | tok/s 25156
step   2140 | loss 1.6080 | lr 5.27e-04 | grad 1.14 | tok/s 24661
step   2150 | loss 1.6340 | lr 5.27e-04 | grad 2.00 | tok/s 24647
step   2160 | loss 1.8434 | lr 5.27e-04 | grad 1.18 | tok/s 25489
step   2170 | loss 1.5911 | lr 5.27e-04 | grad 1.16 | tok/s 25177
step   2180 | loss 1.6064 | lr 5.27e-04 | grad 1.12 | tok/s 25554
step   2190 | loss 1.4100 | lr 5.27e-04 | grad 2.44 | tok/s 25932
step   2200 | loss 1.5548 | lr 5.27e-04 | grad 1.45 | tok/s 24820
step   2210 | loss 1.4242 | lr 5.27e-04 | grad 1.32 | tok/s 26008
step   2220 | loss 1.6207 | lr 5.27e-04 | grad 1.24 | tok/s 25104
step   2230 | loss 1.6072 | lr 5.27e-04 | grad 1.08 | tok/s 23973
step   2240 | loss 1.6958 | lr 5.27e-04 | grad 1.30 | tok/s 25138
step   2250 | loss 1.5022 | lr 5.27e-04 | grad 1.04 | tok/s 25001
step   2260 | loss 1.5094 | lr 5.27e-04 | grad 1.27 | tok/s 24899
step   2270 | loss 1.7645 | lr 5.27e-04 | grad 1.23 | tok/s 25044
step   2280 | loss 1.7293 | lr 5.27e-04 | grad 1.10 | tok/s 23941
step   2290 | loss 1.4765 | lr 5.27e-04 | grad 1.41 | tok/s 25413
step   2300 | loss 1.5720 | lr 5.27e-04 | grad 4.31 | tok/s 24286
step   2310 | loss 1.7528 | lr 5.27e-04 | grad 0.91 | tok/s 24555
step   2320 | loss 1.4524 | lr 5.27e-04 | grad 1.19 | tok/s 25537
step   2330 | loss 1.5071 | lr 5.27e-04 | grad 1.24 | tok/s 25973
step   2340 | loss 1.4657 | lr 5.27e-04 | grad 1.26 | tok/s 25992
step   2350 | loss 1.4298 | lr 5.27e-04 | grad 1.21 | tok/s 25989
step   2360 | loss 1.4150 | lr 5.27e-04 | grad 1.32 | tok/s 26012
step   2370 | loss 1.3604 | lr 5.27e-04 | grad 1.54 | tok/s 26005
step   2380 | loss 1.3543 | lr 5.27e-04 | grad 1.06 | tok/s 26001
step   2390 | loss 1.3337 | lr 5.27e-04 | grad 1.15 | tok/s 25995
step   2400 | loss 1.3569 | lr 5.27e-04 | grad 1.15 | tok/s 25991
step   2410 | loss 1.3022 | lr 5.27e-04 | grad 1.13 | tok/s 25966
step   2420 | loss 1.6714 | lr 5.27e-04 | grad 1.70 | tok/s 25532
step   2430 | loss 1.1242 | lr 5.27e-04 | grad 0.73 | tok/s 25597
step   2440 | loss 1.4914 | lr 5.27e-04 | grad 0.88 | tok/s 24243
step   2450 | loss 1.4909 | lr 5.27e-04 | grad 1.02 | tok/s 24612
step   2460 | loss 1.5154 | lr 5.27e-04 | grad 1.20 | tok/s 25052
step   2470 | loss 1.6081 | lr 5.27e-04 | grad 0.77 | tok/s 25652
step   2480 | loss 1.5021 | lr 5.27e-04 | grad 1.11 | tok/s 24575
step   2490 | loss 1.5941 | lr 5.27e-04 | grad 1.38 | tok/s 25693
step   2500 | loss 1.7199 | lr 5.27e-04 | grad 1.52 | tok/s 24689
step   2510 | loss 1.6742 | lr 5.27e-04 | grad 1.04 | tok/s 25257
step   2520 | loss 1.5818 | lr 5.27e-04 | grad 0.97 | tok/s 24927
step   2530 | loss 1.5744 | lr 5.27e-04 | grad 1.62 | tok/s 25014
step   2540 | loss 1.6675 | lr 5.27e-04 | grad 1.30 | tok/s 25098
step   2550 | loss 1.5553 | lr 5.27e-04 | grad 1.22 | tok/s 24187
step   2560 | loss 1.5473 | lr 5.27e-04 | grad 1.54 | tok/s 24978
step   2570 | loss 1.5497 | lr 5.27e-04 | grad 1.30 | tok/s 24603
step   2580 | loss 1.5973 | lr 5.27e-04 | grad 2.53 | tok/s 25150
step   2590 | loss 1.6468 | lr 5.27e-04 | grad 0.96 | tok/s 24164
step   2600 | loss 1.4776 | lr 5.27e-04 | grad 1.21 | tok/s 24429
step   2610 | loss 1.6163 | lr 5.27e-04 | grad 1.19 | tok/s 25266
step   2620 | loss 1.5094 | lr 5.27e-04 | grad 0.95 | tok/s 25310
step   2630 | loss 1.6328 | lr 5.27e-04 | grad 0.90 | tok/s 25154
step   2640 | loss 1.2675 | lr 5.27e-04 | grad 0.90 | tok/s 25541
step   2650 | loss 1.5804 | lr 5.27e-04 | grad 0.69 | tok/s 24160
step   2660 | loss 1.3327 | lr 5.27e-04 | grad 1.15 | tok/s 25095
step   2670 | loss 1.4880 | lr 5.27e-04 | grad 1.20 | tok/s 25807
step   2680 | loss 1.4073 | lr 5.27e-04 | grad 1.00 | tok/s 25110
step   2690 | loss 1.5040 | lr 5.27e-04 | grad 1.20 | tok/s 24607
step   2700 | loss 1.4803 | lr 5.27e-04 | grad 1.27 | tok/s 24133
step   2710 | loss 1.4494 | lr 5.27e-04 | grad 0.73 | tok/s 25408
step   2720 | loss 1.8402 | lr 5.27e-04 | grad 0.94 | tok/s 24601
step   2730 | loss 1.4823 | lr 5.27e-04 | grad 0.89 | tok/s 24964
step   2740 | loss 1.5330 | lr 5.27e-04 | grad 1.43 | tok/s 25172
step   2750 | loss 1.5008 | lr 5.27e-04 | grad 1.36 | tok/s 24421
step   2760 | loss 1.4951 | lr 5.27e-04 | grad 1.01 | tok/s 25925
step   2770 | loss 1.4086 | lr 5.27e-04 | grad 0.97 | tok/s 25008
step   2780 | loss 1.5508 | lr 5.27e-04 | grad 1.29 | tok/s 25479
step   2790 | loss 1.4350 | lr 5.27e-04 | grad 1.28 | tok/s 25476
step   2800 | loss 1.6964 | lr 5.27e-04 | grad 4.00 | tok/s 24440
step   2810 | loss 1.4441 | lr 5.27e-04 | grad 1.38 | tok/s 24479
step   2820 | loss 1.5498 | lr 5.27e-04 | grad 0.99 | tok/s 24493
step   2830 | loss 1.4617 | lr 5.27e-04 | grad 0.86 | tok/s 23662
step   2840 | loss 1.3947 | lr 5.27e-04 | grad 0.88 | tok/s 24755
step   2850 | loss 1.3093 | lr 5.27e-04 | grad 1.15 | tok/s 25138
step   2860 | loss 1.2871 | lr 5.27e-04 | grad 1.07 | tok/s 25988
step   2870 | loss 1.3924 | lr 5.27e-04 | grad 1.00 | tok/s 25201
step   2880 | loss 1.5355 | lr 5.27e-04 | grad 1.13 | tok/s 24318
step   2890 | loss 1.5965 | lr 5.27e-04 | grad 2.28 | tok/s 24520
step   2900 | loss 1.6354 | lr 5.27e-04 | grad 1.01 | tok/s 25453
step   2910 | loss 1.4961 | lr 5.27e-04 | grad 1.12 | tok/s 24384
step   2920 | loss 1.5008 | lr 5.27e-04 | grad 1.00 | tok/s 25122
step   2930 | loss 1.3549 | lr 5.27e-04 | grad 3.39 | tok/s 25063
step   2940 | loss 1.5282 | lr 5.27e-04 | grad 0.92 | tok/s 25368
step   2950 | loss 1.5251 | lr 5.27e-04 | grad 1.91 | tok/s 24514
step   2960 | loss 1.6937 | lr 5.27e-04 | grad 1.14 | tok/s 24775
step   2970 | loss 1.7686 | lr 5.27e-04 | grad 2.83 | tok/s 24373
step   2980 | loss 1.4716 | lr 5.27e-04 | grad 1.13 | tok/s 25312
step   2990 | loss 1.4979 | lr 5.27e-04 | grad 1.34 | tok/s 25473
step   3000 | loss 1.6509 | lr 5.27e-04 | grad 1.16 | tok/s 25167
  >>> saved checkpoint: checkpoint_step_003000_loss_1.6509.pt
step   3010 | loss 1.4537 | lr 5.27e-04 | grad 0.93 | tok/s 17056
step   3020 | loss 1.5675 | lr 5.27e-04 | grad 1.88 | tok/s 25267
step   3030 | loss 1.4492 | lr 5.27e-04 | grad 0.96 | tok/s 24704
step   3040 | loss 1.4129 | lr 5.27e-04 | grad 0.96 | tok/s 24273
step   3050 | loss 1.4505 | lr 5.27e-04 | grad 1.19 | tok/s 25097
step   3060 | loss 1.3440 | lr 5.27e-04 | grad 0.92 | tok/s 25843
step   3070 | loss 1.5654 | lr 5.27e-04 | grad 2.23 | tok/s 25403
step   3080 | loss 2.2009 | lr 5.27e-04 | grad 2.92 | tok/s 24878
step   3090 | loss 1.6523 | lr 5.27e-04 | grad 1.52 | tok/s 25101
step   3100 | loss 1.4999 | lr 5.27e-04 | grad 0.93 | tok/s 24166
step   3110 | loss 1.3985 | lr 5.27e-04 | grad 1.11 | tok/s 25173
step   3120 | loss 1.5515 | lr 5.27e-04 | grad 1.23 | tok/s 25754
step   3130 | loss 1.5049 | lr 5.27e-04 | grad 0.95 | tok/s 24702
step   3140 | loss 1.4496 | lr 5.27e-04 | grad 1.07 | tok/s 24373
step   3150 | loss 1.3813 | lr 5.27e-04 | grad 1.70 | tok/s 24824
step   3160 | loss 1.4379 | lr 5.27e-04 | grad 1.08 | tok/s 23677
step   3170 | loss 1.5996 | lr 5.27e-04 | grad 1.10 | tok/s 25842
step   3180 | loss 1.3515 | lr 5.27e-04 | grad 0.76 | tok/s 25579
step   3190 | loss 1.3631 | lr 5.27e-04 | grad 2.02 | tok/s 25449
step   3200 | loss 1.6423 | lr 5.27e-04 | grad 1.73 | tok/s 25371
step   3210 | loss 1.3919 | lr 5.27e-04 | grad 0.88 | tok/s 25028
step   3220 | loss 1.5861 | lr 5.27e-04 | grad 1.16 | tok/s 25162
step   3230 | loss 1.3965 | lr 5.27e-04 | grad 1.09 | tok/s 25737
step   3240 | loss 1.4718 | lr 5.27e-04 | grad 0.98 | tok/s 24222
step   3250 | loss 1.4072 | lr 5.27e-04 | grad 0.79 | tok/s 24051
step   3260 | loss 1.4532 | lr 5.27e-04 | grad 1.58 | tok/s 24555
step   3270 | loss 1.5059 | lr 5.27e-04 | grad 0.78 | tok/s 24932
step   3280 | loss 1.4421 | lr 5.27e-04 | grad 1.04 | tok/s 24332
step   3290 | loss 1.5694 | lr 5.27e-04 | grad 0.93 | tok/s 24935
step   3300 | loss 1.3708 | lr 5.27e-04 | grad 1.14 | tok/s 25049
step   3310 | loss 1.6608 | lr 5.27e-04 | grad 1.49 | tok/s 25855
step   3320 | loss 1.9719 | lr 5.27e-04 | grad 6.44 | tok/s 25193
step   3330 | loss 1.6323 | lr 5.27e-04 | grad 1.20 | tok/s 25001
step   3340 | loss 1.3948 | lr 5.27e-04 | grad 1.48 | tok/s 24093
step   3350 | loss 1.2840 | lr 5.27e-04 | grad 0.75 | tok/s 25766
step   3360 | loss 1.6020 | lr 5.27e-04 | grad 3.00 | tok/s 25655
step   3370 | loss 1.5371 | lr 5.27e-04 | grad 1.02 | tok/s 24640
step   3380 | loss 1.6233 | lr 5.27e-04 | grad 1.82 | tok/s 24595
step   3390 | loss 1.4512 | lr 5.27e-04 | grad 0.82 | tok/s 25030
step   3400 | loss 1.4217 | lr 5.27e-04 | grad 1.16 | tok/s 24634
step   3410 | loss 1.5306 | lr 5.27e-04 | grad 0.82 | tok/s 25007
step   3420 | loss 1.5738 | lr 5.27e-04 | grad 1.22 | tok/s 24627
step   3430 | loss 1.5927 | lr 5.27e-04 | grad 1.04 | tok/s 24951
step   3440 | loss 1.4927 | lr 5.27e-04 | grad 1.15 | tok/s 24987
step   3450 | loss 1.4787 | lr 5.27e-04 | grad 1.31 | tok/s 24654
step   3460 | loss 1.5120 | lr 5.27e-04 | grad 0.91 | tok/s 24544
step   3470 | loss 1.4818 | lr 5.27e-04 | grad 1.00 | tok/s 24557
step   3480 | loss 1.7350 | lr 5.27e-04 | grad 0.94 | tok/s 25142
step   3490 | loss 1.3736 | lr 5.27e-04 | grad 1.27 | tok/s 24416
step   3500 | loss 1.6180 | lr 5.27e-04 | grad 0.81 | tok/s 25201
step   3510 | loss 1.6143 | lr 5.27e-04 | grad 0.76 | tok/s 24062
step   3520 | loss 1.4209 | lr 5.27e-04 | grad 0.84 | tok/s 24027
step   3530 | loss 1.5065 | lr 5.27e-04 | grad 2.28 | tok/s 25412
step   3540 | loss 1.6624 | lr 5.27e-04 | grad 1.74 | tok/s 24701
step   3550 | loss 1.5105 | lr 5.27e-04 | grad 1.16 | tok/s 24172
step   3560 | loss 1.4104 | lr 5.27e-04 | grad 0.88 | tok/s 25410
step   3570 | loss 1.5370 | lr 5.27e-04 | grad 1.18 | tok/s 25046
step   3580 | loss 1.3619 | lr 5.27e-04 | grad 0.99 | tok/s 25923
step   3590 | loss 1.3647 | lr 5.27e-04 | grad 1.23 | tok/s 24627
step   3600 | loss 1.4754 | lr 5.27e-04 | grad 1.28 | tok/s 23987
step   3610 | loss 1.3312 | lr 5.27e-04 | grad 1.44 | tok/s 25084
step   3620 | loss 1.5680 | lr 5.27e-04 | grad 2.88 | tok/s 25131
step   3630 | loss 1.4089 | lr 5.27e-04 | grad 0.90 | tok/s 23800
step   3640 | loss 1.5021 | lr 5.27e-04 | grad 1.96 | tok/s 25404
step   3650 | loss 1.6394 | lr 5.27e-04 | grad 0.95 | tok/s 24180
step   3660 | loss 1.6263 | lr 5.27e-04 | grad 1.11 | tok/s 24975
step   3670 | loss 1.5108 | lr 5.27e-04 | grad 1.24 | tok/s 23949
step   3680 | loss 1.4015 | lr 5.27e-04 | grad 1.08 | tok/s 25252
step   3690 | loss 1.3799 | lr 5.27e-04 | grad 1.15 | tok/s 24385
step   3700 | loss 1.4299 | lr 5.27e-04 | grad 1.13 | tok/s 25490
step   3710 | loss 1.3383 | lr 5.27e-04 | grad 1.02 | tok/s 25479
step   3720 | loss 1.4751 | lr 5.27e-04 | grad 0.98 | tok/s 25073
step   3730 | loss 1.4573 | lr 5.27e-04 | grad 1.14 | tok/s 25333
step   3740 | loss 1.5933 | lr 5.27e-04 | grad 1.44 | tok/s 24820
step   3750 | loss 1.5951 | lr 5.27e-04 | grad 1.18 | tok/s 25078
step   3760 | loss 1.4148 | lr 5.27e-04 | grad 1.47 | tok/s 25028
step   3770 | loss 1.4270 | lr 5.27e-04 | grad 0.78 | tok/s 24958
step   3780 | loss 1.6778 | lr 5.27e-04 | grad 2.06 | tok/s 24313
step   3790 | loss 1.4475 | lr 5.27e-04 | grad 1.05 | tok/s 25561
step   3800 | loss 1.3203 | lr 5.27e-04 | grad 0.88 | tok/s 25079
step   3810 | loss 1.3092 | lr 5.27e-04 | grad 0.87 | tok/s 25174
step   3820 | loss 1.4439 | lr 5.27e-04 | grad 0.88 | tok/s 25083
step   3830 | loss 1.3850 | lr 5.27e-04 | grad 1.12 | tok/s 25500
step   3840 | loss 1.3869 | lr 5.27e-04 | grad 1.01 | tok/s 25718
step   3850 | loss 1.6101 | lr 5.27e-04 | grad 1.29 | tok/s 25467
step   3860 | loss 1.4182 | lr 5.27e-04 | grad 1.03 | tok/s 25169
step   3870 | loss 1.5004 | lr 5.27e-04 | grad 1.59 | tok/s 25232
step   3880 | loss 1.5386 | lr 5.27e-04 | grad 2.84 | tok/s 25422
step   3890 | loss 1.2924 | lr 5.27e-04 | grad 0.91 | tok/s 25157
step   3900 | loss 1.3771 | lr 5.27e-04 | grad 1.23 | tok/s 24698
step   3910 | loss 1.3583 | lr 5.27e-04 | grad 1.20 | tok/s 24864
step   3920 | loss 1.5640 | lr 5.27e-04 | grad 1.48 | tok/s 24614
step   3930 | loss 1.5154 | lr 5.27e-04 | grad 0.86 | tok/s 25849
step   3940 | loss 1.4614 | lr 5.27e-04 | grad 1.09 | tok/s 24496
step   3950 | loss 1.4173 | lr 5.27e-04 | grad 1.48 | tok/s 25171
step   3960 | loss 1.4092 | lr 5.27e-04 | grad 0.83 | tok/s 25629
step   3970 | loss 1.3025 | lr 5.27e-04 | grad 0.89 | tok/s 25349
step   3980 | loss 1.1907 | lr 5.27e-04 | grad 0.95 | tok/s 25946
step   3990 | loss 1.1538 | lr 5.27e-04 | grad 0.96 | tok/s 25950
step   4000 | loss 1.1525 | lr 5.27e-04 | grad 0.92 | tok/s 25944
  >>> saved checkpoint: checkpoint_step_004000_loss_1.1525.pt
step   4010 | loss 1.3688 | lr 5.27e-04 | grad 1.10 | tok/s 16964
step   4020 | loss 1.4961 | lr 5.27e-04 | grad 1.15 | tok/s 25754
step   4030 | loss 1.2933 | lr 5.27e-04 | grad 0.96 | tok/s 25956
step   4040 | loss 1.2724 | lr 5.27e-04 | grad 1.05 | tok/s 25976
step   4050 | loss 1.2558 | lr 5.27e-04 | grad 0.85 | tok/s 25982
step   4060 | loss 1.3285 | lr 5.27e-04 | grad 0.85 | tok/s 25388
step   4070 | loss 1.5161 | lr 5.27e-04 | grad 1.19 | tok/s 24964
step   4080 | loss 1.5347 | lr 5.27e-04 | grad 1.17 | tok/s 24335
step   4090 | loss 1.4691 | lr 5.27e-04 | grad 1.09 | tok/s 25666
step   4100 | loss 1.4156 | lr 5.27e-04 | grad 1.05 | tok/s 25494
step   4110 | loss 1.5450 | lr 5.27e-04 | grad 1.09 | tok/s 24937
step   4120 | loss 1.4785 | lr 5.27e-04 | grad 1.13 | tok/s 24529
step   4130 | loss 1.5654 | lr 5.27e-04 | grad 0.83 | tok/s 25458
step   4140 | loss 1.3325 | lr 5.27e-04 | grad 1.27 | tok/s 24861
step   4150 | loss 1.4741 | lr 5.27e-04 | grad 0.79 | tok/s 24590
step   4160 | loss 1.4288 | lr 5.27e-04 | grad 1.20 | tok/s 24560
step   4170 | loss 1.3061 | lr 5.27e-04 | grad 1.02 | tok/s 25473
step   4180 | loss 1.2095 | lr 5.27e-04 | grad 1.09 | tok/s 25453
step   4190 | loss 1.4955 | lr 5.27e-04 | grad 0.93 | tok/s 24087
step   4200 | loss 0.9347 | lr 5.27e-04 | grad 0.90 | tok/s 26017
step   4210 | loss 1.3995 | lr 5.27e-04 | grad 0.93 | tok/s 24612
step   4220 | loss 1.6009 | lr 5.27e-04 | grad 1.05 | tok/s 24875
step   4230 | loss 1.4828 | lr 5.27e-04 | grad 0.88 | tok/s 24681
step   4240 | loss 1.6039 | lr 5.27e-04 | grad 2.27 | tok/s 24861
step   4250 | loss 1.4150 | lr 5.27e-04 | grad 1.19 | tok/s 24880
step   4260 | loss 1.6314 | lr 5.27e-04 | grad 6.09 | tok/s 24462
step   4270 | loss 1.4051 | lr 5.27e-04 | grad 0.96 | tok/s 24706
step   4280 | loss 1.4483 | lr 5.27e-04 | grad 0.93 | tok/s 24713
step   4290 | loss 1.7483 | lr 5.27e-04 | grad 1.54 | tok/s 25550
step   4300 | loss 1.4241 | lr 5.27e-04 | grad 0.94 | tok/s 24438
step   4310 | loss 1.4684 | lr 5.27e-04 | grad 0.81 | tok/s 25266
step   4320 | loss 1.5324 | lr 5.27e-04 | grad 2.56 | tok/s 25798
step   4330 | loss 1.5741 | lr 5.27e-04 | grad 0.98 | tok/s 25447
step   4340 | loss 1.3766 | lr 5.27e-04 | grad 0.98 | tok/s 25156
step   4350 | loss 1.2352 | lr 5.27e-04 | grad 0.84 | tok/s 25957
step   4360 | loss 1.2157 | lr 5.27e-04 | grad 0.95 | tok/s 25945
step   4370 | loss 1.2760 | lr 5.27e-04 | grad 0.92 | tok/s 25951
step   4380 | loss 1.2394 | lr 5.27e-04 | grad 1.08 | tok/s 25951
step   4390 | loss 1.2271 | lr 5.27e-04 | grad 0.84 | tok/s 25944
step   4400 | loss 1.2429 | lr 5.27e-04 | grad 1.00 | tok/s 25935
step   4410 | loss 1.3553 | lr 5.27e-04 | grad 1.13 | tok/s 25047
step   4420 | loss 1.4930 | lr 5.27e-04 | grad 0.83 | tok/s 24943
step   4430 | loss 1.4444 | lr 5.27e-04 | grad 3.50 | tok/s 25870
step   4440 | loss 1.4763 | lr 5.27e-04 | grad 2.34 | tok/s 25924
step   4450 | loss 1.5151 | lr 5.27e-04 | grad 1.07 | tok/s 25389
step   4460 | loss 1.4154 | lr 5.27e-04 | grad 1.30 | tok/s 25542
step   4470 | loss 1.5827 | lr 5.27e-04 | grad 1.01 | tok/s 25240
step   4480 | loss 1.3723 | lr 5.27e-04 | grad 1.16 | tok/s 24935
step   4490 | loss 1.3988 | lr 5.27e-04 | grad 0.93 | tok/s 25395
step   4500 | loss 1.3509 | lr 5.27e-04 | grad 1.29 | tok/s 25206
step   4510 | loss 1.6035 | lr 5.27e-04 | grad 1.30 | tok/s 24782
step   4520 | loss 1.5091 | lr 5.27e-04 | grad 1.08 | tok/s 24289
step   4530 | loss 1.4158 | lr 5.27e-04 | grad 1.08 | tok/s 25064
step   4540 | loss 1.4408 | lr 5.27e-04 | grad 0.80 | tok/s 24593
step   4550 | loss 1.4219 | lr 5.27e-04 | grad 3.84 | tok/s 24778
step   4560 | loss 1.4289 | lr 5.27e-04 | grad 1.43 | tok/s 24356
step   4570 | loss 1.4696 | lr 5.27e-04 | grad 0.86 | tok/s 25940
step   4580 | loss 1.4117 | lr 5.27e-04 | grad 1.02 | tok/s 25945
step   4590 | loss 1.3955 | lr 5.27e-04 | grad 0.81 | tok/s 25929
step   4600 | loss 1.3544 | lr 5.27e-04 | grad 0.88 | tok/s 25912
step   4610 | loss 1.3261 | lr 5.27e-04 | grad 0.96 | tok/s 25915
step   4620 | loss 1.3247 | lr 5.27e-04 | grad 0.94 | tok/s 25911
step   4630 | loss 1.4977 | lr 5.27e-04 | grad 1.19 | tok/s 25380
step   4640 | loss 1.3552 | lr 5.27e-04 | grad 0.89 | tok/s 25011
step   4650 | loss 1.5656 | lr 5.27e-04 | grad 0.98 | tok/s 25560
step   4660 | loss 1.5157 | lr 5.27e-04 | grad 1.52 | tok/s 24658
step   4670 | loss 1.9005 | lr 5.27e-04 | grad 2.45 | tok/s 25200
step   4680 | loss 1.6579 | lr 5.27e-04 | grad 1.20 | tok/s 24781
step   4690 | loss 1.3986 | lr 5.27e-04 | grad 0.88 | tok/s 25736
step   4700 | loss 1.3847 | lr 5.27e-04 | grad 1.17 | tok/s 25265
step   4710 | loss 1.4134 | lr 5.27e-04 | grad 1.06 | tok/s 24422
step   4720 | loss 1.4168 | lr 5.27e-04 | grad 1.00 | tok/s 25036
step   4730 | loss 1.3329 | lr 5.27e-04 | grad 2.48 | tok/s 24290
step   4740 | loss 1.3707 | lr 5.27e-04 | grad 0.83 | tok/s 24730
step   4750 | loss 1.5372 | lr 5.27e-04 | grad 2.42 | tok/s 25134
step   4760 | loss 1.4590 | lr 5.27e-04 | grad 1.00 | tok/s 24078
step   4770 | loss 1.4393 | lr 5.27e-04 | grad 0.89 | tok/s 24898
step   4780 | loss 1.5489 | lr 5.27e-04 | grad 3.66 | tok/s 25317
step   4790 | loss 1.4875 | lr 5.27e-04 | grad 1.52 | tok/s 25053
step   4800 | loss 1.3530 | lr 5.27e-04 | grad 0.76 | tok/s 23642
step   4810 | loss 1.6232 | lr 5.27e-04 | grad 0.88 | tok/s 24927
step   4820 | loss 1.6390 | lr 5.27e-04 | grad 1.15 | tok/s 25124
step   4830 | loss 1.3957 | lr 5.27e-04 | grad 0.81 | tok/s 25206
step   4840 | loss 1.3247 | lr 5.27e-04 | grad 0.84 | tok/s 24687
step   4850 | loss 1.2863 | lr 5.27e-04 | grad 1.14 | tok/s 25383
step   4860 | loss 1.4976 | lr 5.27e-04 | grad 0.90 | tok/s 24592
step   4870 | loss 1.4275 | lr 5.27e-04 | grad 1.62 | tok/s 25735
step   4880 | loss 1.3239 | lr 5.27e-04 | grad 1.45 | tok/s 25944
step   4890 | loss 1.1484 | lr 5.27e-04 | grad 1.31 | tok/s 25944
step   4900 | loss 1.3642 | lr 5.27e-04 | grad 0.85 | tok/s 24705
step   4910 | loss 1.2989 | lr 5.27e-04 | grad 1.02 | tok/s 25577
step   4920 | loss 1.3985 | lr 5.27e-04 | grad 1.59 | tok/s 24255
step   4930 | loss 1.3505 | lr 5.27e-04 | grad 0.92 | tok/s 24617
step   4940 | loss 1.3459 | lr 5.27e-04 | grad 1.52 | tok/s 25243
step   4950 | loss 1.3709 | lr 5.27e-04 | grad 1.17 | tok/s 25534
step   4960 | loss 1.5482 | lr 5.27e-04 | grad 0.93 | tok/s 24754
step   4970 | loss 1.3283 | lr 5.27e-04 | grad 1.25 | tok/s 25629
step   4980 | loss 1.3825 | lr 5.27e-04 | grad 1.00 | tok/s 25355
step   4990 | loss 1.7719 | lr 5.27e-04 | grad 0.82 | tok/s 24314
step   5000 | loss 1.5464 | lr 5.27e-04 | grad 0.84 | tok/s 24546
  >>> saved checkpoint: checkpoint_step_005000_loss_1.5464.pt
step   5010 | loss 1.5282 | lr 5.27e-04 | grad 2.06 | tok/s 16386
step   5020 | loss 1.3734 | lr 5.27e-04 | grad 0.75 | tok/s 24600
step   5030 | loss 1.5189 | lr 5.27e-04 | grad 1.03 | tok/s 24831
step   5040 | loss 1.3605 | lr 5.27e-04 | grad 0.94 | tok/s 24429
step   5050 | loss 2.1717 | lr 5.27e-04 | grad 1.37 | tok/s 25451
step   5060 | loss 1.4665 | lr 5.27e-04 | grad 1.09 | tok/s 25434
step   5070 | loss 1.5281 | lr 5.27e-04 | grad 2.06 | tok/s 25459
step   5080 | loss 1.4169 | lr 5.27e-04 | grad 0.75 | tok/s 24315
step   5090 | loss 1.4631 | lr 5.27e-04 | grad 1.54 | tok/s 25028
step   5100 | loss 1.5374 | lr 5.27e-04 | grad 0.97 | tok/s 25688
step   5110 | loss 1.3963 | lr 5.27e-04 | grad 1.01 | tok/s 25022
step   5120 | loss 1.3338 | lr 5.27e-04 | grad 0.98 | tok/s 24403
step   5130 | loss 1.3926 | lr 5.27e-04 | grad 1.18 | tok/s 25025
step   5140 | loss 1.5070 | lr 5.27e-04 | grad 3.31 | tok/s 25448
step   5150 | loss 1.4342 | lr 5.27e-04 | grad 0.92 | tok/s 25693
step   5160 | loss 1.3038 | lr 5.27e-04 | grad 0.90 | tok/s 25055
step   5170 | loss 1.5041 | lr 5.27e-04 | grad 0.87 | tok/s 25854
step   5180 | loss 1.3440 | lr 5.27e-04 | grad 1.12 | tok/s 25964
step   5190 | loss 1.2873 | lr 5.27e-04 | grad 1.20 | tok/s 25974
step   5200 | loss 1.3455 | lr 5.27e-04 | grad 0.96 | tok/s 25975
step   5210 | loss 1.4636 | lr 5.27e-04 | grad 1.24 | tok/s 24728
step   5220 | loss 1.4461 | lr 5.27e-04 | grad 1.64 | tok/s 24498
step   5230 | loss 1.4362 | lr 5.27e-04 | grad 1.16 | tok/s 25099
step   5240 | loss 1.4987 | lr 5.27e-04 | grad 1.06 | tok/s 23914
step   5250 | loss 1.3607 | lr 5.27e-04 | grad 1.48 | tok/s 23923
step   5260 | loss 1.7600 | lr 5.27e-04 | grad 2.83 | tok/s 25877
step   5270 | loss 1.5704 | lr 5.27e-04 | grad 0.81 | tok/s 25508
step   5280 | loss 1.3225 | lr 5.27e-04 | grad 0.93 | tok/s 25973
step   5290 | loss 1.3173 | lr 5.27e-04 | grad 0.86 | tok/s 25990
step   5300 | loss 1.2514 | lr 5.27e-04 | grad 0.61 | tok/s 25981
step   5310 | loss 1.3359 | lr 5.27e-04 | grad 1.01 | tok/s 25976
step   5320 | loss 1.2463 | lr 5.27e-04 | grad 0.77 | tok/s 25993
step   5330 | loss 1.3279 | lr 5.27e-04 | grad 0.86 | tok/s 25991
step   5340 | loss 1.4761 | lr 5.27e-04 | grad 1.09 | tok/s 24576
step   5350 | loss 1.3443 | lr 5.27e-04 | grad 0.97 | tok/s 25284
step   5360 | loss 1.5089 | lr 5.27e-04 | grad 0.96 | tok/s 23682
step   5370 | loss 1.5532 | lr 5.27e-04 | grad 1.83 | tok/s 25423
step   5380 | loss 1.6692 | lr 5.27e-04 | grad 2.38 | tok/s 25657
step   5390 | loss 1.5887 | lr 5.27e-04 | grad 1.16 | tok/s 25381
step   5400 | loss 1.5174 | lr 5.27e-04 | grad 1.03 | tok/s 24647
step   5410 | loss 1.3108 | lr 5.27e-04 | grad 0.88 | tok/s 25404
step   5420 | loss 1.2578 | lr 5.27e-04 | grad 1.18 | tok/s 25211
step   5430 | loss 1.2871 | lr 5.27e-04 | grad 0.79 | tok/s 25002
step   5440 | loss 1.5159 | lr 5.27e-04 | grad 1.02 | tok/s 24620
step   5450 | loss 1.5051 | lr 5.27e-04 | grad 0.95 | tok/s 25203
step   5460 | loss 1.4629 | lr 5.27e-04 | grad 1.08 | tok/s 24635
step   5470 | loss 1.6352 | lr 5.27e-04 | grad 1.08 | tok/s 24235
step   5480 | loss 1.4701 | lr 5.27e-04 | grad 1.25 | tok/s 25336
step   5490 | loss 1.3644 | lr 5.27e-04 | grad 0.97 | tok/s 25430
step   5500 | loss 1.3847 | lr 5.27e-04 | grad 0.91 | tok/s 24389
step   5510 | loss 1.3769 | lr 5.27e-04 | grad 0.64 | tok/s 24984
step   5520 | loss 1.2736 | lr 5.27e-04 | grad 0.82 | tok/s 24580
step   5530 | loss 1.3748 | lr 5.27e-04 | grad 1.05 | tok/s 25018
step   5540 | loss 1.6309 | lr 5.27e-04 | grad 1.62 | tok/s 25145
step   5550 | loss 1.6219 | lr 5.27e-04 | grad 1.64 | tok/s 24799
step   5560 | loss 1.5672 | lr 5.27e-04 | grad 1.13 | tok/s 25312
step   5570 | loss 1.0814 | lr 5.27e-04 | grad 0.57 | tok/s 25765
step   5580 | loss 1.6775 | lr 5.27e-04 | grad 2.89 | tok/s 25468
step   5590 | loss 1.6594 | lr 5.27e-04 | grad 1.00 | tok/s 25162
step   5600 | loss 1.3728 | lr 5.27e-04 | grad 2.02 | tok/s 25610
step   5610 | loss 1.4865 | lr 5.27e-04 | grad 1.05 | tok/s 25254
step   5620 | loss 1.4494 | lr 5.27e-04 | grad 0.88 | tok/s 25634
step   5630 | loss 1.4210 | lr 5.27e-04 | grad 2.27 | tok/s 24394
step   5640 | loss 1.2280 | lr 5.27e-04 | grad 1.02 | tok/s 25319

Training complete! Final step: 5649
