Using device: cuda
Output directory: benchmark_results/cmaes_4d/mingru_480M_converge0.01_20260203_003041/eval_11/levelmingru_100m_20260203_010105
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 963,489,792 parameters
Using schedule-free AdamW (lr=0.00040324640863651987)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 9.7490 | lr 4.03e-04 | grad 36.50 | tok/s 7709
step     20 | loss 3.4992 | lr 4.03e-04 | grad 13.62 | tok/s 8010
step     30 | loss 3.1564 | lr 4.03e-04 | grad 25.88 | tok/s 8008
step     40 | loss 3.1009 | lr 4.03e-04 | grad 3.86 | tok/s 7628
step     50 | loss 2.9532 | lr 4.03e-04 | grad 18.25 | tok/s 7582
step     60 | loss 3.5258 | lr 4.03e-04 | grad 4.44 | tok/s 8070
step     70 | loss 2.8122 | lr 4.03e-04 | grad 8.31 | tok/s 8066
step     80 | loss 5.0277 | lr 4.03e-04 | grad 17.75 | tok/s 8023
step     90 | loss 5.6829 | lr 4.03e-04 | grad 14.50 | tok/s 8253
step    100 | loss 4.3295 | lr 4.03e-04 | grad 7.47 | tok/s 8239
step    110 | loss 4.0291 | lr 4.03e-04 | grad 12.19 | tok/s 8221
step    120 | loss 3.8844 | lr 4.03e-04 | grad 8.38 | tok/s 8206
step    130 | loss 3.9382 | lr 4.03e-04 | grad 5.62 | tok/s 8206
step    140 | loss 3.2640 | lr 4.03e-04 | grad 15.38 | tok/s 8199
step    150 | loss 3.5210 | lr 4.03e-04 | grad 11.94 | tok/s 8184
step    160 | loss 3.2609 | lr 4.03e-04 | grad 4.66 | tok/s 8183
step    170 | loss 3.0712 | lr 4.03e-04 | grad 9.31 | tok/s 8173
step    180 | loss 3.0486 | lr 4.03e-04 | grad 5.28 | tok/s 8170
step    190 | loss 2.9536 | lr 4.03e-04 | grad 6.72 | tok/s 8153
step    200 | loss 2.9378 | lr 4.03e-04 | grad 6.56 | tok/s 8151
step    210 | loss 2.7459 | lr 4.03e-04 | grad 5.97 | tok/s 8151
step    220 | loss 2.6676 | lr 4.03e-04 | grad 4.62 | tok/s 8055
step    230 | loss 3.0935 | lr 4.03e-04 | grad 9.69 | tok/s 8073
step    240 | loss 3.1940 | lr 4.03e-04 | grad 4.25 | tok/s 7644
step    250 | loss 2.7007 | lr 4.03e-04 | grad 4.09 | tok/s 7711
step    260 | loss 2.5145 | lr 4.03e-04 | grad 4.69 | tok/s 8085
step    270 | loss 2.6108 | lr 4.03e-04 | grad 6.00 | tok/s 7805
step    280 | loss 2.5926 | lr 4.03e-04 | grad 7.88 | tok/s 8000
step    290 | loss 2.8918 | lr 4.03e-04 | grad 4.00 | tok/s 7974
step    300 | loss 2.0831 | lr 4.03e-04 | grad 2.89 | tok/s 8205
step    310 | loss 2.6021 | lr 4.03e-04 | grad 4.84 | tok/s 8058
step    320 | loss 2.7982 | lr 4.03e-04 | grad 3.94 | tok/s 8160
step    330 | loss 2.4966 | lr 4.03e-04 | grad 4.47 | tok/s 7383
step    340 | loss 2.6857 | lr 4.03e-04 | grad 2.55 | tok/s 7833
step    350 | loss 2.5181 | lr 4.03e-04 | grad 3.58 | tok/s 7761
step    360 | loss 2.8779 | lr 4.03e-04 | grad 3.38 | tok/s 8176
step    370 | loss 2.5534 | lr 4.03e-04 | grad 4.31 | tok/s 7530
step    380 | loss 2.3654 | lr 4.03e-04 | grad 2.89 | tok/s 7690
step    390 | loss 2.2679 | lr 4.03e-04 | grad 2.78 | tok/s 8105
step    400 | loss 2.2253 | lr 4.03e-04 | grad 3.72 | tok/s 8106
step    410 | loss 2.3148 | lr 4.03e-04 | grad 3.03 | tok/s 8181
step    420 | loss 2.1669 | lr 4.03e-04 | grad 2.67 | tok/s 7487
step    430 | loss 2.6093 | lr 4.03e-04 | grad 5.94 | tok/s 7969
step    440 | loss 2.6828 | lr 4.03e-04 | grad 4.03 | tok/s 7817
step    450 | loss 2.6305 | lr 4.03e-04 | grad 15.62 | tok/s 7830
step    460 | loss 2.4210 | lr 4.03e-04 | grad 2.42 | tok/s 7662
step    470 | loss 2.4379 | lr 4.03e-04 | grad 2.86 | tok/s 7809
step    480 | loss 2.4469 | lr 4.03e-04 | grad 3.08 | tok/s 7963
step    490 | loss 2.8269 | lr 4.03e-04 | grad 3.27 | tok/s 7871
step    500 | loss 2.1901 | lr 4.03e-04 | grad 3.66 | tok/s 7752
step    510 | loss 2.3725 | lr 4.03e-04 | grad 3.97 | tok/s 8075
step    520 | loss 2.3579 | lr 4.03e-04 | grad 2.06 | tok/s 8117
step    530 | loss 2.4792 | lr 4.03e-04 | grad 3.72 | tok/s 8037
step    540 | loss 2.2876 | lr 4.03e-04 | grad 2.42 | tok/s 7830
step    550 | loss 2.1207 | lr 4.03e-04 | grad 3.28 | tok/s 7820
step    560 | loss 2.2062 | lr 4.03e-04 | grad 6.25 | tok/s 7161
step    570 | loss 2.2478 | lr 4.03e-04 | grad 2.55 | tok/s 7824
step    580 | loss 2.1870 | lr 4.03e-04 | grad 2.55 | tok/s 7683
step    590 | loss 2.1085 | lr 4.03e-04 | grad 1.93 | tok/s 7588
step    600 | loss 2.5653 | lr 4.03e-04 | grad 2.95 | tok/s 7767
step    610 | loss 2.2208 | lr 4.03e-04 | grad 3.69 | tok/s 7781
step    620 | loss 2.0662 | lr 4.03e-04 | grad 3.72 | tok/s 7732
step    630 | loss 2.1689 | lr 4.03e-04 | grad 4.69 | tok/s 7593
step    640 | loss 2.3954 | lr 4.03e-04 | grad 4.47 | tok/s 7755
step    650 | loss 2.2893 | lr 4.03e-04 | grad 3.31 | tok/s 7835
step    660 | loss 2.2291 | lr 4.03e-04 | grad 3.25 | tok/s 7957
step    670 | loss 2.1442 | lr 4.03e-04 | grad 2.39 | tok/s 7764
step    680 | loss 2.6362 | lr 4.03e-04 | grad 2.53 | tok/s 8092
step    690 | loss 2.3592 | lr 4.03e-04 | grad 2.28 | tok/s 7671
step    700 | loss 2.4980 | lr 4.03e-04 | grad 3.09 | tok/s 8185
step    710 | loss 2.3084 | lr 4.03e-04 | grad 3.34 | tok/s 7966
step    720 | loss 1.9469 | lr 4.03e-04 | grad 2.92 | tok/s 7233
step    730 | loss 2.3022 | lr 4.03e-04 | grad 3.73 | tok/s 8192
step    740 | loss 2.0996 | lr 4.03e-04 | grad 2.12 | tok/s 8052
step    750 | loss 2.1506 | lr 4.03e-04 | grad 2.38 | tok/s 8194
step    760 | loss 1.9534 | lr 4.03e-04 | grad 2.12 | tok/s 8197
step    770 | loss 1.9987 | lr 4.03e-04 | grad 2.66 | tok/s 8190
step    780 | loss 1.9399 | lr 4.03e-04 | grad 2.67 | tok/s 8198
step    790 | loss 1.8660 | lr 4.03e-04 | grad 1.84 | tok/s 8198
step    800 | loss 2.1900 | lr 4.03e-04 | grad 3.73 | tok/s 7660
step    810 | loss 2.3945 | lr 4.03e-04 | grad 2.25 | tok/s 7870
step    820 | loss 2.1717 | lr 4.03e-04 | grad 3.30 | tok/s 7766
step    830 | loss 2.2068 | lr 4.03e-04 | grad 2.77 | tok/s 7918
step    840 | loss 2.2965 | lr 4.03e-04 | grad 3.36 | tok/s 8189
step    850 | loss 2.3151 | lr 4.03e-04 | grad 8.31 | tok/s 8152
step    860 | loss 2.2007 | lr 4.03e-04 | grad 2.36 | tok/s 8118
step    870 | loss 2.1269 | lr 4.03e-04 | grad 1.93 | tok/s 7838
step    880 | loss 2.1817 | lr 4.03e-04 | grad 2.98 | tok/s 7785
step    890 | loss 2.2319 | lr 4.03e-04 | grad 1.45 | tok/s 7942
step    900 | loss 2.1723 | lr 4.03e-04 | grad 2.80 | tok/s 7965
step    910 | loss 1.9497 | lr 4.03e-04 | grad 2.00 | tok/s 7751
step    920 | loss 2.2041 | lr 4.03e-04 | grad 2.84 | tok/s 8091
step    930 | loss 2.1171 | lr 4.03e-04 | grad 3.03 | tok/s 7800
step    940 | loss 2.1740 | lr 4.03e-04 | grad 3.23 | tok/s 7902
step    950 | loss 2.2385 | lr 4.03e-04 | grad 2.39 | tok/s 8158
step    960 | loss 2.0778 | lr 4.03e-04 | grad 2.41 | tok/s 8200
step    970 | loss 2.1334 | lr 4.03e-04 | grad 1.98 | tok/s 7842
step    980 | loss 2.2665 | lr 4.03e-04 | grad 1.82 | tok/s 7891
step    990 | loss 2.0382 | lr 4.03e-04 | grad 2.00 | tok/s 7858
step   1000 | loss 2.1289 | lr 4.03e-04 | grad 2.22 | tok/s 7782
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1289.pt
step   1010 | loss 2.1052 | lr 4.03e-04 | grad 1.88 | tok/s 2459
step   1020 | loss 2.0527 | lr 4.03e-04 | grad 2.20 | tok/s 7538
step   1030 | loss 2.0071 | lr 4.03e-04 | grad 2.36 | tok/s 8069
step   1040 | loss 2.0185 | lr 4.03e-04 | grad 1.67 | tok/s 7894
step   1050 | loss 2.1224 | lr 4.03e-04 | grad 3.12 | tok/s 7849
step   1060 | loss 2.2781 | lr 4.03e-04 | grad 2.58 | tok/s 8060
step   1070 | loss 2.2931 | lr 4.03e-04 | grad 2.78 | tok/s 7838
step   1080 | loss 1.9160 | lr 4.03e-04 | grad 2.08 | tok/s 7494
step   1090 | loss 1.5381 | lr 4.03e-04 | grad 3.14 | tok/s 8129
step   1100 | loss 2.0988 | lr 4.03e-04 | grad 4.34 | tok/s 8028
step   1110 | loss 2.0048 | lr 4.03e-04 | grad 2.16 | tok/s 8242
step   1120 | loss 1.9986 | lr 4.03e-04 | grad 2.70 | tok/s 8248
step   1130 | loss 1.9346 | lr 4.03e-04 | grad 2.05 | tok/s 8241
step   1140 | loss 1.9116 | lr 4.03e-04 | grad 2.86 | tok/s 8243
step   1150 | loss 1.9066 | lr 4.03e-04 | grad 2.78 | tok/s 8248
step   1160 | loss 1.8029 | lr 4.03e-04 | grad 3.27 | tok/s 8227
step   1170 | loss 1.9290 | lr 4.03e-04 | grad 3.28 | tok/s 8230
step   1180 | loss 1.9773 | lr 4.03e-04 | grad 2.78 | tok/s 8226
step   1190 | loss 1.8652 | lr 4.03e-04 | grad 3.02 | tok/s 8223
step   1200 | loss 1.8943 | lr 4.03e-04 | grad 3.11 | tok/s 8218
step   1210 | loss 1.8611 | lr 4.03e-04 | grad 2.06 | tok/s 8215
step   1220 | loss 1.8249 | lr 4.03e-04 | grad 1.95 | tok/s 8204
step   1230 | loss 1.8496 | lr 4.03e-04 | grad 2.81 | tok/s 8206
step   1240 | loss 1.9783 | lr 4.03e-04 | grad 2.14 | tok/s 7972
step   1250 | loss 2.2480 | lr 4.03e-04 | grad 3.02 | tok/s 7803
step   1260 | loss 1.8359 | lr 4.03e-04 | grad 4.56 | tok/s 7763
step   1270 | loss 2.0530 | lr 4.03e-04 | grad 2.27 | tok/s 7584
step   1280 | loss 2.1646 | lr 4.03e-04 | grad 2.88 | tok/s 8070
step   1290 | loss 1.9839 | lr 4.03e-04 | grad 2.09 | tok/s 7911
step   1300 | loss 2.0084 | lr 4.03e-04 | grad 2.12 | tok/s 7793
step   1310 | loss 2.0085 | lr 4.03e-04 | grad 2.31 | tok/s 8097
step   1320 | loss 2.2364 | lr 4.03e-04 | grad 3.16 | tok/s 8095
step   1330 | loss 1.9815 | lr 4.03e-04 | grad 3.66 | tok/s 7993
step   1340 | loss 2.1345 | lr 4.03e-04 | grad 3.00 | tok/s 7514
step   1350 | loss 2.1671 | lr 4.03e-04 | grad 2.25 | tok/s 7614
step   1360 | loss 2.0009 | lr 4.03e-04 | grad 2.09 | tok/s 7809
step   1370 | loss 2.1224 | lr 4.03e-04 | grad 3.84 | tok/s 7934
step   1380 | loss 2.0680 | lr 4.03e-04 | grad 3.33 | tok/s 7559
step   1390 | loss 1.8449 | lr 4.03e-04 | grad 2.17 | tok/s 7643
step   1400 | loss 2.0647 | lr 4.03e-04 | grad 2.52 | tok/s 7929
step   1410 | loss 2.1135 | lr 4.03e-04 | grad 1.57 | tok/s 7707
step   1420 | loss 2.0792 | lr 4.03e-04 | grad 1.98 | tok/s 7725
step   1430 | loss 1.9197 | lr 4.03e-04 | grad 3.31 | tok/s 7786
step   1440 | loss 1.8315 | lr 4.03e-04 | grad 2.81 | tok/s 8186
step   1450 | loss 1.9994 | lr 4.03e-04 | grad 3.09 | tok/s 8073
step   1460 | loss 2.0866 | lr 4.03e-04 | grad 2.17 | tok/s 7565
step   1470 | loss 2.0136 | lr 4.03e-04 | grad 2.17 | tok/s 8091
step   1480 | loss 2.7344 | lr 4.03e-04 | grad 2.47 | tok/s 8120
step   1490 | loss 2.2548 | lr 4.03e-04 | grad 1.96 | tok/s 8142
step   1500 | loss 1.8969 | lr 4.03e-04 | grad 2.62 | tok/s 8173
step   1510 | loss 2.1617 | lr 4.03e-04 | grad 2.56 | tok/s 8074
step   1520 | loss 1.9554 | lr 4.03e-04 | grad 3.00 | tok/s 7911
step   1530 | loss 1.8786 | lr 4.03e-04 | grad 3.55 | tok/s 7871
step   1540 | loss 2.1598 | lr 4.03e-04 | grad 2.47 | tok/s 7847
step   1550 | loss 1.8183 | lr 4.03e-04 | grad 2.47 | tok/s 8089
step   1560 | loss 2.0495 | lr 4.03e-04 | grad 2.31 | tok/s 7738
step   1570 | loss 2.0038 | lr 4.03e-04 | grad 1.98 | tok/s 8107
step   1580 | loss 2.5557 | lr 4.03e-04 | grad 2.55 | tok/s 8044
step   1590 | loss 2.0321 | lr 4.03e-04 | grad 1.59 | tok/s 7701
step   1600 | loss 1.2306 | lr 4.03e-04 | grad 1.67 | tok/s 8269
step   1610 | loss 1.7781 | lr 4.03e-04 | grad 3.02 | tok/s 7562
step   1620 | loss 2.0985 | lr 4.03e-04 | grad 2.86 | tok/s 7769
step   1630 | loss 1.9585 | lr 4.03e-04 | grad 3.17 | tok/s 7987
step   1640 | loss 1.9644 | lr 4.03e-04 | grad 3.84 | tok/s 7718
step   1650 | loss 1.9935 | lr 4.03e-04 | grad 2.59 | tok/s 7314
step   1660 | loss 1.9425 | lr 4.03e-04 | grad 2.72 | tok/s 8192
step   1670 | loss 2.2102 | lr 4.03e-04 | grad 2.23 | tok/s 7692
step   1680 | loss 1.9496 | lr 4.03e-04 | grad 1.61 | tok/s 7582
step   1690 | loss 2.0550 | lr 4.03e-04 | grad 2.97 | tok/s 8064
step   1700 | loss 2.0437 | lr 4.03e-04 | grad 3.17 | tok/s 7696
step   1710 | loss 2.0456 | lr 4.03e-04 | grad 2.00 | tok/s 7931
step   1720 | loss 2.2076 | lr 4.03e-04 | grad 3.14 | tok/s 8192
step   1730 | loss 2.1740 | lr 4.03e-04 | grad 2.16 | tok/s 8189
step   1740 | loss 2.0152 | lr 4.03e-04 | grad 2.11 | tok/s 7852
step   1750 | loss 2.0004 | lr 4.03e-04 | grad 3.69 | tok/s 7959
step   1760 | loss 2.0033 | lr 4.03e-04 | grad 1.93 | tok/s 7811
step   1770 | loss 1.9067 | lr 4.03e-04 | grad 2.92 | tok/s 7807
step   1780 | loss 1.9570 | lr 4.03e-04 | grad 2.64 | tok/s 7934
step   1790 | loss 1.9277 | lr 4.03e-04 | grad 1.84 | tok/s 7882
step   1800 | loss 2.0989 | lr 4.03e-04 | grad 3.11 | tok/s 7702
step   1810 | loss 1.9536 | lr 4.03e-04 | grad 2.36 | tok/s 7757
step   1820 | loss 2.0148 | lr 4.03e-04 | grad 2.98 | tok/s 7940
step   1830 | loss 1.9195 | lr 4.03e-04 | grad 2.88 | tok/s 7946
step   1840 | loss 1.9506 | lr 4.03e-04 | grad 1.91 | tok/s 7679
step   1850 | loss 1.9791 | lr 4.03e-04 | grad 2.72 | tok/s 8119
step   1860 | loss 1.8365 | lr 4.03e-04 | grad 2.92 | tok/s 7604
step   1870 | loss 1.8544 | lr 4.03e-04 | grad 1.64 | tok/s 8107
step   1880 | loss 1.9143 | lr 4.03e-04 | grad 4.09 | tok/s 7296
step   1890 | loss 1.9402 | lr 4.03e-04 | grad 2.38 | tok/s 7698
step   1900 | loss 1.8478 | lr 4.03e-04 | grad 3.50 | tok/s 7782
step   1910 | loss 1.9115 | lr 4.03e-04 | grad 1.95 | tok/s 7599
step   1920 | loss 1.8866 | lr 4.03e-04 | grad 2.34 | tok/s 8074
step   1930 | loss 1.9058 | lr 4.03e-04 | grad 3.48 | tok/s 7670
step   1940 | loss 2.0393 | lr 4.03e-04 | grad 4.97 | tok/s 8053
step   1950 | loss 2.5590 | lr 4.03e-04 | grad 4.03 | tok/s 8187
step   1960 | loss 2.2479 | lr 4.03e-04 | grad 2.56 | tok/s 8115
step   1970 | loss 2.2271 | lr 4.03e-04 | grad 2.83 | tok/s 7940
step   1980 | loss 1.9588 | lr 4.03e-04 | grad 2.80 | tok/s 7785
step   1990 | loss 2.1114 | lr 4.03e-04 | grad 3.17 | tok/s 7719
step   2000 | loss 1.9061 | lr 4.03e-04 | grad 2.02 | tok/s 7921
  >>> saved checkpoint: checkpoint_step_002000_loss_1.9061.pt
step   2010 | loss 1.8085 | lr 4.03e-04 | grad 2.62 | tok/s 2650
step   2020 | loss 1.6078 | lr 4.03e-04 | grad 0.47 | tok/s 8348
step   2030 | loss 1.8780 | lr 4.03e-04 | grad 2.61 | tok/s 8319
step   2040 | loss 1.9782 | lr 4.03e-04 | grad 2.50 | tok/s 8123
step   2050 | loss 2.0380 | lr 4.03e-04 | grad 2.12 | tok/s 7670
step   2060 | loss 2.0818 | lr 4.03e-04 | grad 2.72 | tok/s 7940
step   2070 | loss 2.6215 | lr 4.03e-04 | grad 3.98 | tok/s 8182
step   2080 | loss 2.2255 | lr 4.03e-04 | grad 2.84 | tok/s 8196
step   2090 | loss 1.9916 | lr 4.03e-04 | grad 2.80 | tok/s 7991
step   2100 | loss 2.1176 | lr 4.03e-04 | grad 4.31 | tok/s 7843
step   2110 | loss 1.3857 | lr 4.03e-04 | grad 2.39 | tok/s 8135
step   2120 | loss 1.5530 | lr 4.03e-04 | grad 2.95 | tok/s 8128
step   2130 | loss 1.9866 | lr 4.03e-04 | grad 2.00 | tok/s 7843
step   2140 | loss 1.8022 | lr 4.03e-04 | grad 2.19 | tok/s 8232
step   2150 | loss 1.7489 | lr 4.03e-04 | grad 2.61 | tok/s 8236
step   2160 | loss 1.7770 | lr 4.03e-04 | grad 2.42 | tok/s 8224
step   2170 | loss 1.7289 | lr 4.03e-04 | grad 3.00 | tok/s 8223
step   2180 | loss 1.7146 | lr 4.03e-04 | grad 3.12 | tok/s 8222
step   2190 | loss 1.7252 | lr 4.03e-04 | grad 2.94 | tok/s 8213
step   2200 | loss 1.6711 | lr 4.03e-04 | grad 2.47 | tok/s 8220
step   2210 | loss 1.6661 | lr 4.03e-04 | grad 3.19 | tok/s 8224
step   2220 | loss 1.8230 | lr 4.03e-04 | grad 3.41 | tok/s 8083
step   2230 | loss 1.8711 | lr 4.03e-04 | grad 2.11 | tok/s 8195
step   2240 | loss 2.1806 | lr 4.03e-04 | grad 2.66 | tok/s 7920
step   2250 | loss 2.1791 | lr 4.03e-04 | grad 1.87 | tok/s 8014
step   2260 | loss 2.3393 | lr 4.03e-04 | grad 3.91 | tok/s 8143
step   2270 | loss 2.0122 | lr 4.03e-04 | grad 2.91 | tok/s 8117
step   2280 | loss 1.9100 | lr 4.03e-04 | grad 2.44 | tok/s 7929
step   2290 | loss 2.4810 | lr 4.03e-04 | grad 3.66 | tok/s 8101
step   2300 | loss 2.0081 | lr 4.03e-04 | grad 2.58 | tok/s 7688
step   2310 | loss 2.1053 | lr 4.03e-04 | grad 4.50 | tok/s 7715
step   2320 | loss 2.1580 | lr 4.03e-04 | grad 2.42 | tok/s 7853
step   2330 | loss 1.9415 | lr 4.03e-04 | grad 4.81 | tok/s 7642
step   2340 | loss 1.8825 | lr 4.03e-04 | grad 4.00 | tok/s 8027
step   2350 | loss 1.9311 | lr 4.03e-04 | grad 2.80 | tok/s 8127
step   2360 | loss 2.0176 | lr 4.03e-04 | grad 4.25 | tok/s 8047
step   2370 | loss 2.1457 | lr 4.03e-04 | grad 2.08 | tok/s 8218
step   2380 | loss 1.8556 | lr 4.03e-04 | grad 2.44 | tok/s 8198
step   2390 | loss 1.7141 | lr 4.03e-04 | grad 2.77 | tok/s 8202
step   2400 | loss 1.5669 | lr 4.03e-04 | grad 2.27 | tok/s 7964
step   2410 | loss 1.9274 | lr 4.03e-04 | grad 2.77 | tok/s 7697
step   2420 | loss 1.9163 | lr 4.03e-04 | grad 1.92 | tok/s 7832
step   2430 | loss 1.7879 | lr 4.03e-04 | grad 2.95 | tok/s 8043
step   2440 | loss 1.9070 | lr 4.03e-04 | grad 3.14 | tok/s 7836
step   2450 | loss 1.8719 | lr 4.03e-04 | grad 2.73 | tok/s 8137
step   2460 | loss 1.7125 | lr 4.03e-04 | grad 1.84 | tok/s 8101
step   2470 | loss 1.8062 | lr 4.03e-04 | grad 1.50 | tok/s 8195
step   2480 | loss 1.8120 | lr 4.03e-04 | grad 2.11 | tok/s 7768
step   2490 | loss 2.0631 | lr 4.03e-04 | grad 2.28 | tok/s 8028
step   2500 | loss 1.9650 | lr 4.03e-04 | grad 3.09 | tok/s 8201
step   2510 | loss 2.0559 | lr 4.03e-04 | grad 3.89 | tok/s 8179
step   2520 | loss 1.8370 | lr 4.03e-04 | grad 2.03 | tok/s 7910
step   2530 | loss 1.8778 | lr 4.03e-04 | grad 2.05 | tok/s 7857
step   2540 | loss 1.7911 | lr 4.03e-04 | grad 2.38 | tok/s 8153
step   2550 | loss 1.8986 | lr 4.03e-04 | grad 3.94 | tok/s 7672
step   2560 | loss 1.9607 | lr 4.03e-04 | grad 2.66 | tok/s 7983
step   2570 | loss 1.8097 | lr 4.03e-04 | grad 2.78 | tok/s 7487
step   2580 | loss 1.8664 | lr 4.03e-04 | grad 2.80 | tok/s 7895
step   2590 | loss 2.0644 | lr 4.03e-04 | grad 2.88 | tok/s 7585
step   2600 | loss 2.1631 | lr 4.03e-04 | grad 2.75 | tok/s 8149
step   2610 | loss 1.9960 | lr 4.03e-04 | grad 2.20 | tok/s 7872
step   2620 | loss 1.9141 | lr 4.03e-04 | grad 2.31 | tok/s 8110
step   2630 | loss 1.9571 | lr 4.03e-04 | grad 3.22 | tok/s 7889
step   2640 | loss 2.2096 | lr 4.03e-04 | grad 2.22 | tok/s 8185
step   2650 | loss 1.8108 | lr 4.03e-04 | grad 2.36 | tok/s 7927
step   2660 | loss 1.8841 | lr 4.03e-04 | grad 2.11 | tok/s 7622
step   2670 | loss 2.0760 | lr 4.03e-04 | grad 4.03 | tok/s 7781
step   2680 | loss 1.8598 | lr 4.03e-04 | grad 2.42 | tok/s 8143
step   2690 | loss 1.9526 | lr 4.03e-04 | grad 2.81 | tok/s 7911
step   2700 | loss 2.1634 | lr 4.03e-04 | grad 2.39 | tok/s 7792
step   2710 | loss 1.8337 | lr 4.03e-04 | grad 2.56 | tok/s 7468
step   2720 | loss 1.7778 | lr 4.03e-04 | grad 2.42 | tok/s 8026
step   2730 | loss 2.0346 | lr 4.03e-04 | grad 3.50 | tok/s 7934
step   2740 | loss 2.1667 | lr 4.03e-04 | grad 2.64 | tok/s 8110
step   2750 | loss 1.7396 | lr 4.03e-04 | grad 1.53 | tok/s 7548
step   2760 | loss 1.9901 | lr 4.03e-04 | grad 2.28 | tok/s 7792
step   2770 | loss 1.7797 | lr 4.03e-04 | grad 2.03 | tok/s 8186
step   2780 | loss 2.1619 | lr 4.03e-04 | grad 3.33 | tok/s 7626
step   2790 | loss 1.8638 | lr 4.03e-04 | grad 2.70 | tok/s 7852
step   2800 | loss 1.7643 | lr 4.03e-04 | grad 2.56 | tok/s 7823
step   2810 | loss 1.8282 | lr 4.03e-04 | grad 1.45 | tok/s 7548
step   2820 | loss 1.8678 | lr 4.03e-04 | grad 4.25 | tok/s 8050
step   2830 | loss 1.6613 | lr 4.03e-04 | grad 2.70 | tok/s 8195
step   2840 | loss 2.2583 | lr 4.03e-04 | grad 1.95 | tok/s 7935
step   2850 | loss 2.1494 | lr 4.03e-04 | grad 3.05 | tok/s 7894
step   2860 | loss 1.7676 | lr 4.03e-04 | grad 2.05 | tok/s 7735
step   2870 | loss 2.0189 | lr 4.03e-04 | grad 2.02 | tok/s 7968
step   2880 | loss 1.9493 | lr 4.03e-04 | grad 2.52 | tok/s 8193
step   2890 | loss 1.8766 | lr 4.03e-04 | grad 3.78 | tok/s 7878
step   2900 | loss 1.9158 | lr 4.03e-04 | grad 1.80 | tok/s 7883
step   2910 | loss 1.9088 | lr 4.03e-04 | grad 2.55 | tok/s 7649
step   2920 | loss 2.0555 | lr 4.03e-04 | grad 2.19 | tok/s 8017
step   2930 | loss 1.7151 | lr 4.03e-04 | grad 1.95 | tok/s 7366
step   2940 | loss 1.8268 | lr 4.03e-04 | grad 2.38 | tok/s 7924
step   2950 | loss 1.8235 | lr 4.03e-04 | grad 2.91 | tok/s 7995
step   2960 | loss 1.8110 | lr 4.03e-04 | grad 4.00 | tok/s 8038
step   2970 | loss 2.1226 | lr 4.03e-04 | grad 2.94 | tok/s 7788
step   2980 | loss 2.4972 | lr 4.03e-04 | grad 3.17 | tok/s 7984
step   2990 | loss 1.9003 | lr 4.03e-04 | grad 2.50 | tok/s 8007
step   3000 | loss 1.7335 | lr 4.03e-04 | grad 2.72 | tok/s 7956
  >>> saved checkpoint: checkpoint_step_003000_loss_1.7335.pt
step   3010 | loss 1.8091 | lr 4.03e-04 | grad 2.52 | tok/s 2633
step   3020 | loss 1.8879 | lr 4.03e-04 | grad 2.33 | tok/s 7860
step   3030 | loss 1.8538 | lr 4.03e-04 | grad 2.78 | tok/s 8245
step   3040 | loss 1.8525 | lr 4.03e-04 | grad 2.67 | tok/s 8010
step   3050 | loss 1.9467 | lr 4.03e-04 | grad 3.00 | tok/s 8147
step   3060 | loss 1.8554 | lr 4.03e-04 | grad 2.36 | tok/s 8241
step   3070 | loss 1.8810 | lr 4.03e-04 | grad 2.25 | tok/s 7955
step   3080 | loss 1.8277 | lr 4.03e-04 | grad 3.00 | tok/s 7787
step   3090 | loss 1.9942 | lr 4.03e-04 | grad 2.12 | tok/s 8160
step   3100 | loss 1.5764 | lr 4.03e-04 | grad 2.67 | tok/s 8252
step   3110 | loss 1.7210 | lr 4.03e-04 | grad 3.12 | tok/s 7964
step   3120 | loss 1.9036 | lr 4.03e-04 | grad 2.42 | tok/s 8077
step   3130 | loss 1.7473 | lr 4.03e-04 | grad 2.38 | tok/s 8239
step   3140 | loss 1.7696 | lr 4.03e-04 | grad 2.25 | tok/s 7973
step   3150 | loss 2.0004 | lr 4.03e-04 | grad 2.05 | tok/s 7807
step   3160 | loss 1.7653 | lr 4.03e-04 | grad 1.97 | tok/s 7652
step   3170 | loss 1.7501 | lr 4.03e-04 | grad 3.12 | tok/s 8023
step   3180 | loss 1.2507 | lr 4.03e-04 | grad 2.55 | tok/s 8287
step   3190 | loss 2.2313 | lr 4.03e-04 | grad 3.70 | tok/s 7936
step   3200 | loss 2.3714 | lr 4.03e-04 | grad 3.06 | tok/s 7994
step   3210 | loss 2.4930 | lr 4.03e-04 | grad 2.97 | tok/s 8217
step   3220 | loss 2.2582 | lr 4.03e-04 | grad 3.52 | tok/s 8222
step   3230 | loss 2.1654 | lr 4.03e-04 | grad 3.17 | tok/s 8215
step   3240 | loss 2.1141 | lr 4.03e-04 | grad 3.22 | tok/s 8206
step   3250 | loss 2.0249 | lr 4.03e-04 | grad 3.16 | tok/s 8214
step   3260 | loss 2.0115 | lr 4.03e-04 | grad 2.39 | tok/s 8212
step   3270 | loss 1.9508 | lr 4.03e-04 | grad 3.39 | tok/s 8212
step   3280 | loss 1.9451 | lr 4.03e-04 | grad 3.27 | tok/s 8209
step   3290 | loss 1.9116 | lr 4.03e-04 | grad 3.03 | tok/s 8211
step   3300 | loss 1.9191 | lr 4.03e-04 | grad 3.20 | tok/s 8212
step   3310 | loss 1.8932 | lr 4.03e-04 | grad 3.38 | tok/s 8206
step   3320 | loss 2.1319 | lr 4.03e-04 | grad 3.95 | tok/s 7713
step   3330 | loss 1.9122 | lr 4.03e-04 | grad 2.94 | tok/s 8097
step   3340 | loss 1.8377 | lr 4.03e-04 | grad 3.73 | tok/s 7765
step   3350 | loss 1.8680 | lr 4.03e-04 | grad 3.58 | tok/s 7632
step   3360 | loss 1.9424 | lr 4.03e-04 | grad 2.42 | tok/s 7829
step   3370 | loss 1.8780 | lr 4.03e-04 | grad 2.17 | tok/s 7746
step   3380 | loss 1.7433 | lr 4.03e-04 | grad 2.94 | tok/s 8135
step   3390 | loss 1.6574 | lr 4.03e-04 | grad 1.45 | tok/s 8206
step   3400 | loss 1.7844 | lr 4.03e-04 | grad 2.89 | tok/s 8030
step   3410 | loss 1.8950 | lr 4.03e-04 | grad 3.17 | tok/s 7684
step   3420 | loss 1.8972 | lr 4.03e-04 | grad 2.83 | tok/s 7811
step   3430 | loss 1.8317 | lr 4.03e-04 | grad 2.14 | tok/s 7990
step   3440 | loss 1.9305 | lr 4.03e-04 | grad 3.75 | tok/s 7997
step   3450 | loss 1.9058 | lr 4.03e-04 | grad 2.52 | tok/s 8012
step   3460 | loss 1.8725 | lr 4.03e-04 | grad 2.53 | tok/s 8045
step   3470 | loss 1.7920 | lr 4.03e-04 | grad 1.95 | tok/s 7879
step   3480 | loss 1.7239 | lr 4.03e-04 | grad 2.50 | tok/s 7931
step   3490 | loss 1.7711 | lr 4.03e-04 | grad 2.59 | tok/s 7823

Training complete! Final step: 3497
