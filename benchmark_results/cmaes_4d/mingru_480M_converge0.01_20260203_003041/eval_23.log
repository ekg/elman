Using device: cuda
Output directory: benchmark_results/cmaes_4d/mingru_480M_converge0.01_20260203_003041/eval_23/levelmingru_100m_20260203_013142
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 591,962,112 parameters
Using schedule-free AdamW (lr=0.0008178859861526901)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 9.3202 | lr 8.18e-04 | grad 20.00 | tok/s 11406
step     20 | loss 3.7658 | lr 8.18e-04 | grad 3.78 | tok/s 12447
step     30 | loss 3.0739 | lr 8.18e-04 | grad 9.12 | tok/s 12528
step     40 | loss 2.9814 | lr 8.18e-04 | grad 3.92 | tok/s 11967
step     50 | loss 2.8578 | lr 8.18e-04 | grad 22.00 | tok/s 11927
step     60 | loss 3.1776 | lr 8.18e-04 | grad 5.97 | tok/s 12691
step     70 | loss 2.5706 | lr 8.18e-04 | grad 5.00 | tok/s 12701
step     80 | loss 4.3860 | lr 8.18e-04 | grad 18.25 | tok/s 12656
step     90 | loss 4.7454 | lr 8.18e-04 | grad 9.75 | tok/s 13019
step    100 | loss 3.8731 | lr 8.18e-04 | grad 8.69 | tok/s 12999
step    110 | loss 3.4891 | lr 8.18e-04 | grad 4.62 | tok/s 12981
step    120 | loss 3.4340 | lr 8.18e-04 | grad 5.19 | tok/s 12973
step    130 | loss 3.3480 | lr 8.18e-04 | grad 9.25 | tok/s 12945
step    140 | loss 2.8191 | lr 8.18e-04 | grad 9.69 | tok/s 12915
step    150 | loss 2.9331 | lr 8.18e-04 | grad 12.88 | tok/s 12882
step    160 | loss 2.7149 | lr 8.18e-04 | grad 4.97 | tok/s 12863
step    170 | loss 2.5395 | lr 8.18e-04 | grad 8.19 | tok/s 12833
step    180 | loss 2.4743 | lr 8.18e-04 | grad 4.19 | tok/s 12815
step    190 | loss 2.4316 | lr 8.18e-04 | grad 4.00 | tok/s 12785
step    200 | loss 2.3736 | lr 8.18e-04 | grad 3.17 | tok/s 12771
step    210 | loss 2.1970 | lr 8.18e-04 | grad 5.41 | tok/s 12748
step    220 | loss 2.2583 | lr 8.18e-04 | grad 9.06 | tok/s 12574
step    230 | loss 2.9968 | lr 8.18e-04 | grad 9.56 | tok/s 12583
step    240 | loss 2.9686 | lr 8.18e-04 | grad 3.50 | tok/s 11899
step    250 | loss 2.5696 | lr 8.18e-04 | grad 3.95 | tok/s 11979
step    260 | loss 2.3217 | lr 8.18e-04 | grad 4.56 | tok/s 12563
step    270 | loss 2.4103 | lr 8.18e-04 | grad 4.66 | tok/s 12097
step    280 | loss 2.4236 | lr 8.18e-04 | grad 8.50 | tok/s 12396
step    290 | loss 2.6154 | lr 8.18e-04 | grad 6.31 | tok/s 12339
step    300 | loss 1.4570 | lr 8.18e-04 | grad 3.39 | tok/s 12679
step    310 | loss 2.2126 | lr 8.18e-04 | grad 4.16 | tok/s 12442
step    320 | loss 2.5611 | lr 8.18e-04 | grad 4.22 | tok/s 12619
step    330 | loss 2.3292 | lr 8.18e-04 | grad 3.27 | tok/s 11404
step    340 | loss 2.4761 | lr 8.18e-04 | grad 2.31 | tok/s 12074
step    350 | loss 2.3402 | lr 8.18e-04 | grad 3.56 | tok/s 11946
step    360 | loss 2.3716 | lr 8.18e-04 | grad 3.23 | tok/s 12575
step    370 | loss 2.2419 | lr 8.18e-04 | grad 2.81 | tok/s 11546
step    380 | loss 2.1585 | lr 8.18e-04 | grad 3.05 | tok/s 11802
step    390 | loss 2.0152 | lr 8.18e-04 | grad 2.66 | tok/s 12418
step    400 | loss 1.9384 | lr 8.18e-04 | grad 4.31 | tok/s 12419
step    410 | loss 1.9923 | lr 8.18e-04 | grad 5.47 | tok/s 12517
step    420 | loss 1.9379 | lr 8.18e-04 | grad 3.12 | tok/s 11450
step    430 | loss 2.3399 | lr 8.18e-04 | grad 3.05 | tok/s 12176
step    440 | loss 2.4786 | lr 8.18e-04 | grad 3.30 | tok/s 11947
step    450 | loss 2.3134 | lr 8.18e-04 | grad 9.75 | tok/s 11979
step    460 | loss 2.2004 | lr 8.18e-04 | grad 2.45 | tok/s 11720
step    470 | loss 2.1188 | lr 8.18e-04 | grad 2.03 | tok/s 11929
step    480 | loss 2.1598 | lr 8.18e-04 | grad 2.89 | tok/s 12151
step    490 | loss 2.4685 | lr 8.18e-04 | grad 3.03 | tok/s 12021
step    500 | loss 1.9220 | lr 8.18e-04 | grad 2.92 | tok/s 11802
step    510 | loss 2.0927 | lr 8.18e-04 | grad 2.73 | tok/s 12303
step    520 | loss 2.0647 | lr 8.18e-04 | grad 1.45 | tok/s 12372
step    530 | loss 2.1752 | lr 8.18e-04 | grad 3.03 | tok/s 12249
step    540 | loss 2.0507 | lr 8.18e-04 | grad 2.09 | tok/s 11924
step    550 | loss 1.8106 | lr 8.18e-04 | grad 2.70 | tok/s 11911
step    560 | loss 1.9298 | lr 8.18e-04 | grad 6.25 | tok/s 10904
step    570 | loss 1.9427 | lr 8.18e-04 | grad 2.92 | tok/s 11919
step    580 | loss 1.8808 | lr 8.18e-04 | grad 2.73 | tok/s 11677
step    590 | loss 1.7927 | lr 8.18e-04 | grad 2.42 | tok/s 11528
step    600 | loss 2.2292 | lr 8.18e-04 | grad 2.42 | tok/s 11821
step    610 | loss 1.9397 | lr 8.18e-04 | grad 2.72 | tok/s 11818
step    620 | loss 1.7805 | lr 8.18e-04 | grad 3.33 | tok/s 11729
step    630 | loss 1.8679 | lr 8.18e-04 | grad 4.00 | tok/s 11496
step    640 | loss 2.0324 | lr 8.18e-04 | grad 4.12 | tok/s 11771
step    650 | loss 1.9429 | lr 8.18e-04 | grad 3.56 | tok/s 11881
step    660 | loss 1.9281 | lr 8.18e-04 | grad 2.39 | tok/s 12059
step    670 | loss 1.8103 | lr 8.18e-04 | grad 2.45 | tok/s 11757
step    680 | loss 2.2048 | lr 8.18e-04 | grad 2.19 | tok/s 12245
step    690 | loss 2.0401 | lr 8.18e-04 | grad 2.28 | tok/s 11622
step    700 | loss 1.9641 | lr 8.18e-04 | grad 3.09 | tok/s 12392
step    710 | loss 1.8322 | lr 8.18e-04 | grad 3.00 | tok/s 12058
step    720 | loss 1.6428 | lr 8.18e-04 | grad 2.78 | tok/s 10953
step    730 | loss 1.8045 | lr 8.18e-04 | grad 2.78 | tok/s 12407
step    740 | loss 1.6900 | lr 8.18e-04 | grad 1.58 | tok/s 12183
step    750 | loss 1.6257 | lr 8.18e-04 | grad 2.14 | tok/s 12395
step    760 | loss 1.4296 | lr 8.18e-04 | grad 2.70 | tok/s 12382
step    770 | loss 1.3788 | lr 8.18e-04 | grad 1.73 | tok/s 12373
step    780 | loss 1.3238 | lr 8.18e-04 | grad 2.17 | tok/s 12392
step    790 | loss 1.2546 | lr 8.18e-04 | grad 2.16 | tok/s 12383
step    800 | loss 1.8039 | lr 8.18e-04 | grad 2.59 | tok/s 11585
step    810 | loss 2.0246 | lr 8.18e-04 | grad 2.58 | tok/s 11901
step    820 | loss 1.8664 | lr 8.18e-04 | grad 3.12 | tok/s 11732
step    830 | loss 1.8539 | lr 8.18e-04 | grad 2.03 | tok/s 11964
step    840 | loss 1.7752 | lr 8.18e-04 | grad 2.83 | tok/s 12374
step    850 | loss 1.9017 | lr 8.18e-04 | grad 9.06 | tok/s 12318
step    860 | loss 1.7355 | lr 8.18e-04 | grad 2.42 | tok/s 12272
step    870 | loss 1.7336 | lr 8.18e-04 | grad 1.39 | tok/s 11850
step    880 | loss 1.7681 | lr 8.18e-04 | grad 2.95 | tok/s 11771
step    890 | loss 1.8774 | lr 8.18e-04 | grad 1.34 | tok/s 11995
step    900 | loss 1.8102 | lr 8.18e-04 | grad 2.06 | tok/s 12020
step    910 | loss 1.6047 | lr 8.18e-04 | grad 2.64 | tok/s 11698
step    920 | loss 1.7119 | lr 8.18e-04 | grad 1.96 | tok/s 12234
step    930 | loss 1.7184 | lr 8.18e-04 | grad 2.00 | tok/s 11774
step    940 | loss 1.7656 | lr 8.18e-04 | grad 2.00 | tok/s 11926
step    950 | loss 1.7146 | lr 8.18e-04 | grad 1.85 | tok/s 12311
step    960 | loss 1.5463 | lr 8.18e-04 | grad 1.53 | tok/s 12378
step    970 | loss 1.7318 | lr 8.18e-04 | grad 1.59 | tok/s 11838
step    980 | loss 1.8743 | lr 8.18e-04 | grad 1.41 | tok/s 11930
step    990 | loss 1.6324 | lr 8.18e-04 | grad 1.88 | tok/s 11884
step   1000 | loss 1.7935 | lr 8.18e-04 | grad 2.16 | tok/s 11755
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7935.pt
step   1010 | loss 1.8358 | lr 8.18e-04 | grad 1.32 | tok/s 4046
step   1020 | loss 1.7798 | lr 8.18e-04 | grad 2.03 | tok/s 11282
step   1030 | loss 1.6419 | lr 8.18e-04 | grad 2.70 | tok/s 11908
step   1040 | loss 1.6481 | lr 8.18e-04 | grad 1.77 | tok/s 12268
step   1050 | loss 1.6861 | lr 8.18e-04 | grad 2.95 | tok/s 11380
step   1060 | loss 1.8815 | lr 8.18e-04 | grad 2.34 | tok/s 12272
step   1070 | loss 1.8915 | lr 8.18e-04 | grad 1.90 | tok/s 12343
step   1080 | loss 1.6131 | lr 8.18e-04 | grad 2.19 | tok/s 11330
step   1090 | loss 1.3387 | lr 8.18e-04 | grad 0.93 | tok/s 11883
step   1100 | loss 1.4407 | lr 8.18e-04 | grad 1.90 | tok/s 11902
step   1110 | loss 1.6746 | lr 8.18e-04 | grad 3.02 | tok/s 12437
step   1120 | loss 1.5274 | lr 8.18e-04 | grad 1.88 | tok/s 12438
step   1130 | loss 1.4821 | lr 8.18e-04 | grad 2.45 | tok/s 12444
step   1140 | loss 1.4388 | lr 8.18e-04 | grad 2.11 | tok/s 12425
step   1150 | loss 1.4742 | lr 8.18e-04 | grad 2.39 | tok/s 12428
step   1160 | loss 1.3679 | lr 8.18e-04 | grad 2.30 | tok/s 12422
step   1170 | loss 1.3877 | lr 8.18e-04 | grad 2.06 | tok/s 12425
step   1180 | loss 1.5293 | lr 8.18e-04 | grad 1.91 | tok/s 12419
step   1190 | loss 1.3833 | lr 8.18e-04 | grad 2.52 | tok/s 12416
step   1200 | loss 1.3643 | lr 8.18e-04 | grad 1.88 | tok/s 12420
step   1210 | loss 1.4101 | lr 8.18e-04 | grad 2.45 | tok/s 12408
step   1220 | loss 1.4384 | lr 8.18e-04 | grad 1.54 | tok/s 12415
step   1230 | loss 1.4082 | lr 8.18e-04 | grad 1.76 | tok/s 12410
step   1240 | loss 1.3577 | lr 8.18e-04 | grad 1.93 | tok/s 12395
step   1250 | loss 1.9781 | lr 8.18e-04 | grad 1.66 | tok/s 11923
step   1260 | loss 1.6147 | lr 8.18e-04 | grad 4.00 | tok/s 11498
step   1270 | loss 1.5867 | lr 8.18e-04 | grad 1.80 | tok/s 11632
step   1280 | loss 1.8474 | lr 8.18e-04 | grad 3.14 | tok/s 11950
step   1290 | loss 1.6110 | lr 8.18e-04 | grad 2.23 | tok/s 11953
step   1300 | loss 1.6417 | lr 8.18e-04 | grad 2.08 | tok/s 12063
step   1310 | loss 1.6239 | lr 8.18e-04 | grad 2.73 | tok/s 12033
step   1320 | loss 1.7242 | lr 8.18e-04 | grad 1.82 | tok/s 12128
step   1330 | loss 1.7657 | lr 8.18e-04 | grad 1.55 | tok/s 12204
step   1340 | loss 1.4606 | lr 8.18e-04 | grad 1.88 | tok/s 11660
step   1350 | loss 1.9435 | lr 8.18e-04 | grad 1.69 | tok/s 11276
step   1360 | loss 1.6549 | lr 8.18e-04 | grad 1.56 | tok/s 11957
step   1370 | loss 1.5713 | lr 8.18e-04 | grad 2.91 | tok/s 11992
step   1380 | loss 1.7824 | lr 8.18e-04 | grad 2.12 | tok/s 11334
step   1390 | loss 1.6640 | lr 8.18e-04 | grad 1.95 | tok/s 11958
step   1400 | loss 1.5392 | lr 8.18e-04 | grad 1.55 | tok/s 11564
step   1410 | loss 1.5227 | lr 8.18e-04 | grad 1.27 | tok/s 11711
step   1420 | loss 1.8252 | lr 8.18e-04 | grad 3.36 | tok/s 11624
step   1430 | loss 1.5536 | lr 8.18e-04 | grad 1.88 | tok/s 12003
step   1440 | loss 1.3307 | lr 8.18e-04 | grad 1.81 | tok/s 12152
step   1450 | loss 1.2351 | lr 8.18e-04 | grad 2.31 | tok/s 12331
step   1460 | loss 1.7675 | lr 8.18e-04 | grad 1.80 | tok/s 11729
step   1470 | loss 1.6506 | lr 8.18e-04 | grad 1.85 | tok/s 12014
step   1480 | loss 2.0115 | lr 8.18e-04 | grad 4.91 | tok/s 12148
step   1490 | loss 1.8438 | lr 8.18e-04 | grad 1.80 | tok/s 12331
step   1500 | loss 1.5427 | lr 8.18e-04 | grad 2.08 | tok/s 12373
step   1510 | loss 1.6199 | lr 8.18e-04 | grad 1.29 | tok/s 12232
step   1520 | loss 1.5408 | lr 8.18e-04 | grad 1.37 | tok/s 12012
step   1530 | loss 1.5819 | lr 8.18e-04 | grad 2.58 | tok/s 12344
step   1540 | loss 1.6506 | lr 8.18e-04 | grad 1.76 | tok/s 11479
step   1550 | loss 1.5104 | lr 8.18e-04 | grad 1.93 | tok/s 12226
step   1560 | loss 1.6212 | lr 8.18e-04 | grad 1.55 | tok/s 11659
step   1570 | loss 1.4697 | lr 8.18e-04 | grad 1.65 | tok/s 12370
step   1580 | loss 1.8653 | lr 8.18e-04 | grad 2.47 | tok/s 12080
step   1590 | loss 1.8700 | lr 8.18e-04 | grad 1.64 | tok/s 11635
step   1600 | loss 1.2239 | lr 8.18e-04 | grad 3.67 | tok/s 12402
step   1610 | loss 1.0343 | lr 8.18e-04 | grad 1.73 | tok/s 12077
step   1620 | loss 1.5337 | lr 8.18e-04 | grad 2.11 | tok/s 11270
step   1630 | loss 1.6140 | lr 8.18e-04 | grad 1.86 | tok/s 12052
step   1640 | loss 1.4607 | lr 8.18e-04 | grad 2.72 | tok/s 12030
step   1650 | loss 1.6002 | lr 8.18e-04 | grad 1.97 | tok/s 11349
step   1660 | loss 1.5497 | lr 8.18e-04 | grad 1.71 | tok/s 11737
step   1670 | loss 1.5144 | lr 8.18e-04 | grad 3.38 | tok/s 12014
step   1680 | loss 1.8494 | lr 8.18e-04 | grad 2.06 | tok/s 11530
step   1690 | loss 1.5713 | lr 8.18e-04 | grad 3.41 | tok/s 11741
step   1700 | loss 1.6161 | lr 8.18e-04 | grad 1.86 | tok/s 12033
step   1710 | loss 1.5859 | lr 8.18e-04 | grad 1.45 | tok/s 11906
step   1720 | loss 1.6638 | lr 8.18e-04 | grad 2.33 | tok/s 12104
step   1730 | loss 1.5183 | lr 8.18e-04 | grad 2.56 | tok/s 12382
step   1740 | loss 1.5074 | lr 8.18e-04 | grad 2.23 | tok/s 12201
step   1750 | loss 1.6935 | lr 8.18e-04 | grad 2.66 | tok/s 11864
step   1760 | loss 1.5787 | lr 8.18e-04 | grad 1.81 | tok/s 11827
step   1770 | loss 1.5418 | lr 8.18e-04 | grad 2.02 | tok/s 11711
step   1780 | loss 1.6068 | lr 8.18e-04 | grad 2.23 | tok/s 12162
step   1790 | loss 1.5293 | lr 8.18e-04 | grad 1.62 | tok/s 11904
step   1800 | loss 1.6620 | lr 8.18e-04 | grad 1.47 | tok/s 11921
step   1810 | loss 1.5398 | lr 8.18e-04 | grad 2.03 | tok/s 11569
step   1820 | loss 1.6027 | lr 8.18e-04 | grad 1.52 | tok/s 11724
step   1830 | loss 1.5946 | lr 8.18e-04 | grad 1.66 | tok/s 12085
step   1840 | loss 1.6015 | lr 8.18e-04 | grad 1.52 | tok/s 11723
step   1850 | loss 1.5004 | lr 8.18e-04 | grad 1.38 | tok/s 12140
step   1860 | loss 1.4077 | lr 8.18e-04 | grad 1.52 | tok/s 11810
step   1870 | loss 1.5317 | lr 8.18e-04 | grad 1.77 | tok/s 11837
step   1880 | loss 1.3309 | lr 8.18e-04 | grad 1.44 | tok/s 11679
step   1890 | loss 1.5887 | lr 8.18e-04 | grad 1.86 | tok/s 10998
step   1900 | loss 1.4616 | lr 8.18e-04 | grad 1.55 | tok/s 11932
step   1910 | loss 1.5368 | lr 8.18e-04 | grad 2.08 | tok/s 11421
step   1920 | loss 1.5376 | lr 8.18e-04 | grad 1.91 | tok/s 12280
step   1930 | loss 1.5106 | lr 8.18e-04 | grad 1.52 | tok/s 11719
step   1940 | loss 1.5423 | lr 8.18e-04 | grad 1.77 | tok/s 12000
step   1950 | loss 2.0580 | lr 8.18e-04 | grad 3.14 | tok/s 12271
step   1960 | loss 1.7835 | lr 8.18e-04 | grad 3.80 | tok/s 12397
step   1970 | loss 1.7126 | lr 8.18e-04 | grad 1.24 | tok/s 12087
step   1980 | loss 1.6369 | lr 8.18e-04 | grad 1.63 | tok/s 11571
step   1990 | loss 1.5584 | lr 8.18e-04 | grad 2.80 | tok/s 11904
step   2000 | loss 1.7039 | lr 8.18e-04 | grad 1.80 | tok/s 12030
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7039.pt
step   2010 | loss 1.2661 | lr 8.18e-04 | grad 1.52 | tok/s 4172
step   2020 | loss 1.4185 | lr 8.18e-04 | grad 2.00 | tok/s 12205
step   2030 | loss 1.0986 | lr 8.18e-04 | grad 2.06 | tok/s 12615
step   2040 | loss 1.5507 | lr 8.18e-04 | grad 1.94 | tok/s 12499
step   2050 | loss 1.4082 | lr 8.18e-04 | grad 1.59 | tok/s 12051
step   2060 | loss 1.7089 | lr 8.18e-04 | grad 1.15 | tok/s 11735
step   2070 | loss 1.8845 | lr 8.18e-04 | grad 3.66 | tok/s 11846
step   2080 | loss 2.3512 | lr 8.18e-04 | grad 4.94 | tok/s 12492
step   2090 | loss 1.7195 | lr 8.18e-04 | grad 2.80 | tok/s 12220
step   2100 | loss 1.5039 | lr 8.18e-04 | grad 2.02 | tok/s 12255
step   2110 | loss 1.5874 | lr 8.18e-04 | grad 1.70 | tok/s 11622
step   2120 | loss 0.9461 | lr 8.18e-04 | grad 3.14 | tok/s 12595
step   2130 | loss 1.3601 | lr 8.18e-04 | grad 2.41 | tok/s 12009
step   2140 | loss 1.5159 | lr 8.18e-04 | grad 1.74 | tok/s 12098
step   2150 | loss 1.3855 | lr 8.18e-04 | grad 2.28 | tok/s 12432
step   2160 | loss 1.2789 | lr 8.18e-04 | grad 1.96 | tok/s 12419
step   2170 | loss 1.3471 | lr 8.18e-04 | grad 1.65 | tok/s 12421
step   2180 | loss 1.2878 | lr 8.18e-04 | grad 1.44 | tok/s 12413
step   2190 | loss 1.3069 | lr 8.18e-04 | grad 2.11 | tok/s 12418
step   2200 | loss 1.2823 | lr 8.18e-04 | grad 1.93 | tok/s 12414
step   2210 | loss 1.2427 | lr 8.18e-04 | grad 1.84 | tok/s 12410
step   2220 | loss 1.2305 | lr 8.18e-04 | grad 1.91 | tok/s 12400
step   2230 | loss 1.4764 | lr 8.18e-04 | grad 2.03 | tok/s 12167
step   2240 | loss 1.4211 | lr 8.18e-04 | grad 1.40 | tok/s 11967
step   2250 | loss 1.6959 | lr 8.18e-04 | grad 3.89 | tok/s 12395
step   2260 | loss 1.6739 | lr 8.18e-04 | grad 2.06 | tok/s 11982
step   2270 | loss 2.0497 | lr 8.18e-04 | grad 2.20 | tok/s 12283
step   2280 | loss 1.5367 | lr 8.18e-04 | grad 2.80 | tok/s 12389
step   2290 | loss 1.6015 | lr 8.18e-04 | grad 3.55 | tok/s 11960
step   2300 | loss 1.7993 | lr 8.18e-04 | grad 2.33 | tok/s 12157
step   2310 | loss 1.5600 | lr 8.18e-04 | grad 1.61 | tok/s 11680
step   2320 | loss 1.8757 | lr 8.18e-04 | grad 1.88 | tok/s 11650
step   2330 | loss 1.6182 | lr 8.18e-04 | grad 2.27 | tok/s 11726
step   2340 | loss 1.5627 | lr 8.18e-04 | grad 1.89 | tok/s 11568
step   2350 | loss 1.4623 | lr 8.18e-04 | grad 1.78 | tok/s 12095
step   2360 | loss 1.3849 | lr 8.18e-04 | grad 1.17 | tok/s 12397
step   2370 | loss 1.6433 | lr 8.18e-04 | grad 2.14 | tok/s 12128
step   2380 | loss 1.6341 | lr 8.18e-04 | grad 1.78 | tok/s 12402
step   2390 | loss 1.2493 | lr 8.18e-04 | grad 1.43 | tok/s 12368
step   2400 | loss 1.1690 | lr 8.18e-04 | grad 1.66 | tok/s 12373
step   2410 | loss 1.2657 | lr 8.18e-04 | grad 1.21 | tok/s 11891
step   2420 | loss 1.5382 | lr 8.18e-04 | grad 1.18 | tok/s 11457
step   2430 | loss 1.4437 | lr 8.18e-04 | grad 2.33 | tok/s 12120
step   2440 | loss 1.4293 | lr 8.18e-04 | grad 1.62 | tok/s 11995
step   2450 | loss 1.5584 | lr 8.18e-04 | grad 1.24 | tok/s 11942
step   2460 | loss 1.3522 | lr 8.18e-04 | grad 1.77 | tok/s 12307
step   2470 | loss 1.2968 | lr 8.18e-04 | grad 1.64 | tok/s 12230
step   2480 | loss 1.2978 | lr 8.18e-04 | grad 1.94 | tok/s 12280
step   2490 | loss 1.4704 | lr 8.18e-04 | grad 1.79 | tok/s 11718
step   2500 | loss 1.5981 | lr 8.18e-04 | grad 2.14 | tok/s 12212
step   2510 | loss 1.2680 | lr 8.18e-04 | grad 2.17 | tok/s 12356
step   2520 | loss 1.6171 | lr 8.18e-04 | grad 1.49 | tok/s 12180
step   2530 | loss 1.3731 | lr 8.18e-04 | grad 1.85 | tok/s 11946
step   2540 | loss 1.5139 | lr 8.18e-04 | grad 2.30 | tok/s 11908
step   2550 | loss 1.2567 | lr 8.18e-04 | grad 1.41 | tok/s 12386
step   2560 | loss 1.6017 | lr 8.18e-04 | grad 2.30 | tok/s 11541
step   2570 | loss 1.4198 | lr 8.18e-04 | grad 1.78 | tok/s 11881
step   2580 | loss 1.4392 | lr 8.18e-04 | grad 1.55 | tok/s 11500
step   2590 | loss 1.5147 | lr 8.18e-04 | grad 1.45 | tok/s 11768
step   2600 | loss 1.7519 | lr 8.18e-04 | grad 2.36 | tok/s 11550
step   2610 | loss 1.5716 | lr 8.18e-04 | grad 2.08 | tok/s 12300
step   2620 | loss 1.6194 | lr 8.18e-04 | grad 1.72 | tok/s 11986
step   2630 | loss 1.4640 | lr 8.18e-04 | grad 1.71 | tok/s 12251
step   2640 | loss 1.6526 | lr 8.18e-04 | grad 1.45 | tok/s 11918
step   2650 | loss 1.5609 | lr 8.18e-04 | grad 1.13 | tok/s 12164
step   2660 | loss 1.3998 | lr 8.18e-04 | grad 2.28 | tok/s 11957
step   2670 | loss 1.4908 | lr 8.18e-04 | grad 1.41 | tok/s 11492
step   2680 | loss 1.7313 | lr 8.18e-04 | grad 2.16 | tok/s 11920
step   2690 | loss 1.4140 | lr 8.18e-04 | grad 2.23 | tok/s 12311
step   2700 | loss 1.5343 | lr 8.18e-04 | grad 2.23 | tok/s 11984
step   2710 | loss 1.6252 | lr 8.18e-04 | grad 1.37 | tok/s 11514
step   2720 | loss 1.4365 | lr 8.18e-04 | grad 1.69 | tok/s 11328
step   2730 | loss 1.2417 | lr 8.18e-04 | grad 1.73 | tok/s 12257
step   2740 | loss 1.8005 | lr 8.18e-04 | grad 4.16 | tok/s 12071
step   2750 | loss 1.6398 | lr 8.18e-04 | grad 1.46 | tok/s 12128
step   2760 | loss 1.4110 | lr 8.18e-04 | grad 1.98 | tok/s 11493
step   2770 | loss 1.5160 | lr 8.18e-04 | grad 1.86 | tok/s 11847
step   2780 | loss 1.2510 | lr 8.18e-04 | grad 1.25 | tok/s 12221
step   2790 | loss 1.9042 | lr 8.18e-04 | grad 1.88 | tok/s 11541
step   2800 | loss 1.2926 | lr 8.18e-04 | grad 1.91 | tok/s 12015
step   2810 | loss 1.3798 | lr 8.18e-04 | grad 1.44 | tok/s 11586
step   2820 | loss 1.4514 | lr 8.18e-04 | grad 1.47 | tok/s 11581
step   2830 | loss 1.2739 | lr 8.18e-04 | grad 2.28 | tok/s 12274
step   2840 | loss 1.0765 | lr 8.18e-04 | grad 1.62 | tok/s 12270
step   2850 | loss 1.7981 | lr 8.18e-04 | grad 1.93 | tok/s 11862
step   2860 | loss 1.7521 | lr 8.18e-04 | grad 1.84 | tok/s 11924
step   2870 | loss 1.4918 | lr 8.18e-04 | grad 1.87 | tok/s 11843
step   2880 | loss 1.5248 | lr 8.18e-04 | grad 1.56 | tok/s 12136
step   2890 | loss 1.4422 | lr 8.18e-04 | grad 2.02 | tok/s 12341
step   2900 | loss 1.4709 | lr 8.18e-04 | grad 1.70 | tok/s 11862
step   2910 | loss 1.5399 | lr 8.18e-04 | grad 1.91 | tok/s 11874
step   2920 | loss 1.6471 | lr 8.18e-04 | grad 3.66 | tok/s 11638
step   2930 | loss 1.5605 | lr 8.18e-04 | grad 2.12 | tok/s 11966
step   2940 | loss 1.3409 | lr 8.18e-04 | grad 2.06 | tok/s 11253
step   2950 | loss 1.3746 | lr 8.18e-04 | grad 1.64 | tok/s 11964
step   2960 | loss 1.4202 | lr 8.18e-04 | grad 1.52 | tok/s 12067
step   2970 | loss 1.4486 | lr 8.18e-04 | grad 2.22 | tok/s 11728
step   2980 | loss 1.9762 | lr 8.18e-04 | grad 12.88 | tok/s 12134
step   2990 | loss 1.9397 | lr 8.18e-04 | grad 1.53 | tok/s 12110
step   3000 | loss 1.4244 | lr 8.18e-04 | grad 1.37 | tok/s 12083
  >>> saved checkpoint: checkpoint_step_003000_loss_1.4244.pt
step   3010 | loss 1.3502 | lr 8.18e-04 | grad 1.54 | tok/s 4081
step   3020 | loss 1.4801 | lr 8.18e-04 | grad 2.03 | tok/s 12148
step   3030 | loss 1.5332 | lr 8.18e-04 | grad 1.52 | tok/s 11932
step   3040 | loss 1.4887 | lr 8.18e-04 | grad 1.55 | tok/s 12114
step   3050 | loss 1.4214 | lr 8.18e-04 | grad 1.21 | tok/s 12072
step   3060 | loss 1.5752 | lr 8.18e-04 | grad 1.94 | tok/s 12307
step   3070 | loss 1.5231 | lr 8.18e-04 | grad 1.42 | tok/s 12425
step   3080 | loss 1.4891 | lr 8.18e-04 | grad 1.61 | tok/s 12002
step   3090 | loss 1.3925 | lr 8.18e-04 | grad 1.34 | tok/s 11919
step   3100 | loss 1.5934 | lr 8.18e-04 | grad 1.84 | tok/s 12174
step   3110 | loss 1.1023 | lr 8.18e-04 | grad 1.47 | tok/s 12444
step   3120 | loss 1.1995 | lr 8.18e-04 | grad 1.88 | tok/s 12445
step   3130 | loss 1.4634 | lr 8.18e-04 | grad 1.12 | tok/s 11760
step   3140 | loss 1.1550 | lr 8.18e-04 | grad 1.57 | tok/s 12434
step   3150 | loss 1.3160 | lr 8.18e-04 | grad 1.30 | tok/s 12274
step   3160 | loss 1.6993 | lr 8.18e-04 | grad 1.34 | tok/s 11558
step   3170 | loss 1.3701 | lr 8.18e-04 | grad 1.65 | tok/s 11768
step   3180 | loss 1.3810 | lr 8.18e-04 | grad 1.66 | tok/s 12087
step   3190 | loss 1.0819 | lr 8.18e-04 | grad 2.28 | tok/s 12353
step   3200 | loss 1.5973 | lr 8.18e-04 | grad 1.30 | tok/s 12001
step   3210 | loss 1.7609 | lr 8.18e-04 | grad 1.66 | tok/s 12079
step   3220 | loss 2.3009 | lr 8.18e-04 | grad 3.48 | tok/s 12417
step   3230 | loss 1.9725 | lr 8.18e-04 | grad 2.47 | tok/s 12408
step   3240 | loss 1.7941 | lr 8.18e-04 | grad 2.20 | tok/s 12413
step   3250 | loss 1.7241 | lr 8.18e-04 | grad 3.41 | tok/s 12420
step   3260 | loss 1.6448 | lr 8.18e-04 | grad 3.16 | tok/s 12410
step   3270 | loss 1.5924 | lr 8.18e-04 | grad 2.75 | tok/s 12405
step   3280 | loss 1.5245 | lr 8.18e-04 | grad 2.44 | tok/s 12407
step   3290 | loss 1.4873 | lr 8.18e-04 | grad 2.47 | tok/s 12408
step   3300 | loss 1.4880 | lr 8.18e-04 | grad 2.30 | tok/s 12409
step   3310 | loss 1.4422 | lr 8.18e-04 | grad 1.80 | tok/s 12411
step   3320 | loss 1.4460 | lr 8.18e-04 | grad 2.05 | tok/s 12417
step   3330 | loss 1.7311 | lr 8.18e-04 | grad 2.22 | tok/s 11990
step   3340 | loss 1.4667 | lr 8.18e-04 | grad 1.79 | tok/s 12006
step   3350 | loss 1.4872 | lr 8.18e-04 | grad 1.15 | tok/s 11668
step   3360 | loss 1.4904 | lr 8.18e-04 | grad 1.90 | tok/s 11551
step   3370 | loss 1.5218 | lr 8.18e-04 | grad 1.74 | tok/s 11857
step   3380 | loss 1.5340 | lr 8.18e-04 | grad 1.34 | tok/s 11973
step   3390 | loss 1.3710 | lr 8.18e-04 | grad 1.52 | tok/s 12090
step   3400 | loss 1.1802 | lr 8.18e-04 | grad 2.12 | tok/s 12425
step   3410 | loss 1.2381 | lr 8.18e-04 | grad 2.41 | tok/s 12376
step   3420 | loss 1.5831 | lr 8.18e-04 | grad 1.49 | tok/s 11632
step   3430 | loss 1.4852 | lr 8.18e-04 | grad 1.88 | tok/s 11781
step   3440 | loss 1.4559 | lr 8.18e-04 | grad 1.31 | tok/s 12083
step   3450 | loss 1.4966 | lr 8.18e-04 | grad 2.09 | tok/s 12025
step   3460 | loss 1.5392 | lr 8.18e-04 | grad 1.10 | tok/s 12093
step   3470 | loss 1.4851 | lr 8.18e-04 | grad 1.50 | tok/s 12172
step   3480 | loss 1.4130 | lr 8.18e-04 | grad 1.75 | tok/s 12336
step   3490 | loss 1.2872 | lr 8.18e-04 | grad 1.27 | tok/s 11588
step   3500 | loss 1.2881 | lr 8.18e-04 | grad 1.34 | tok/s 11997
step   3510 | loss 1.4906 | lr 8.18e-04 | grad 1.61 | tok/s 12028
step   3520 | loss 1.6058 | lr 8.18e-04 | grad 2.23 | tok/s 11869
step   3530 | loss 1.6392 | lr 8.18e-04 | grad 1.97 | tok/s 12270
step   3540 | loss 1.4704 | lr 8.18e-04 | grad 1.22 | tok/s 11747
step   3550 | loss 1.9871 | lr 8.18e-04 | grad 1.27 | tok/s 11324
step   3560 | loss 1.5279 | lr 8.18e-04 | grad 2.94 | tok/s 11453
step   3570 | loss 1.2917 | lr 8.18e-04 | grad 1.70 | tok/s 12130
step   3580 | loss 1.2388 | lr 8.18e-04 | grad 1.62 | tok/s 11832
step   3590 | loss 1.3645 | lr 8.18e-04 | grad 1.60 | tok/s 11965
step   3600 | loss 1.5325 | lr 8.18e-04 | grad 1.42 | tok/s 11277
step   3610 | loss 1.4156 | lr 8.18e-04 | grad 1.33 | tok/s 12198
step   3620 | loss 1.4364 | lr 8.18e-04 | grad 1.88 | tok/s 12099
step   3630 | loss 1.5195 | lr 8.18e-04 | grad 1.91 | tok/s 11933
step   3640 | loss 1.5416 | lr 8.18e-04 | grad 1.87 | tok/s 11653
step   3650 | loss 1.4064 | lr 8.18e-04 | grad 1.48 | tok/s 11635
step   3660 | loss 1.4492 | lr 8.18e-04 | grad 1.98 | tok/s 11475
step   3670 | loss 1.3598 | lr 8.18e-04 | grad 1.41 | tok/s 12387
step   3680 | loss 1.3431 | lr 8.18e-04 | grad 1.56 | tok/s 11749
step   3690 | loss 1.4308 | lr 8.18e-04 | grad 2.36 | tok/s 11737
step   3700 | loss 1.4125 | lr 8.18e-04 | grad 1.91 | tok/s 11328
step   3710 | loss 1.5303 | lr 8.18e-04 | grad 1.92 | tok/s 12275
step   3720 | loss 1.5116 | lr 8.18e-04 | grad 2.00 | tok/s 12007
step   3730 | loss 1.4932 | lr 8.18e-04 | grad 2.20 | tok/s 11747
step   3740 | loss 1.2040 | lr 8.18e-04 | grad 1.27 | tok/s 11995
step   3750 | loss 1.7219 | lr 8.18e-04 | grad 1.43 | tok/s 12268
step   3760 | loss 1.3568 | lr 8.18e-04 | grad 1.49 | tok/s 12426
step   3770 | loss 1.3116 | lr 8.18e-04 | grad 1.84 | tok/s 12422
step   3780 | loss 1.2943 | lr 8.18e-04 | grad 2.05 | tok/s 12424
step   3790 | loss 1.2662 | lr 8.18e-04 | grad 2.27 | tok/s 12417
step   3800 | loss 1.2749 | lr 8.18e-04 | grad 2.42 | tok/s 12427
step   3810 | loss 1.2229 | lr 8.18e-04 | grad 1.70 | tok/s 12422
step   3820 | loss 1.2311 | lr 8.18e-04 | grad 1.71 | tok/s 12415
step   3830 | loss 1.2228 | lr 8.18e-04 | grad 1.98 | tok/s 12403
step   3840 | loss 1.2116 | lr 8.18e-04 | grad 1.50 | tok/s 12401
step   3850 | loss 1.1671 | lr 8.18e-04 | grad 2.02 | tok/s 12400
step   3860 | loss 1.4941 | lr 8.18e-04 | grad 1.58 | tok/s 11926
step   3870 | loss 1.7278 | lr 8.18e-04 | grad 2.62 | tok/s 11798
step   3880 | loss 1.3897 | lr 8.18e-04 | grad 1.54 | tok/s 11482
step   3890 | loss 1.6235 | lr 8.18e-04 | grad 5.69 | tok/s 11797
step   3900 | loss 1.4895 | lr 8.18e-04 | grad 1.35 | tok/s 12013
step   3910 | loss 1.3432 | lr 8.18e-04 | grad 1.24 | tok/s 11804
step   3920 | loss 1.6381 | lr 8.18e-04 | grad 1.58 | tok/s 11764
step   3930 | loss 1.4923 | lr 8.18e-04 | grad 1.64 | tok/s 12198
step   3940 | loss 1.5187 | lr 8.18e-04 | grad 1.57 | tok/s 11914
step   3950 | loss 1.4178 | lr 8.18e-04 | grad 1.97 | tok/s 11384
step   3960 | loss 1.5201 | lr 8.18e-04 | grad 3.38 | tok/s 12415
step   3970 | loss 1.5400 | lr 8.18e-04 | grad 1.95 | tok/s 11766
step   3980 | loss 1.5512 | lr 8.18e-04 | grad 2.09 | tok/s 12219
step   3990 | loss 0.9825 | lr 8.18e-04 | grad 1.01 | tok/s 12550
step   4000 | loss 1.1374 | lr 8.18e-04 | grad 1.24 | tok/s 12409
  >>> saved checkpoint: checkpoint_step_004000_loss_1.1374.pt
step   4010 | loss 1.3747 | lr 8.18e-04 | grad 1.57 | tok/s 3944
step   4020 | loss 1.4875 | lr 8.18e-04 | grad 1.59 | tok/s 11525
step   4030 | loss 1.3735 | lr 8.18e-04 | grad 1.55 | tok/s 11969
step   4040 | loss 1.4461 | lr 8.18e-04 | grad 1.73 | tok/s 11909
step   4050 | loss 2.0597 | lr 8.18e-04 | grad 19.25 | tok/s 11634
step   4060 | loss 1.7638 | lr 8.18e-04 | grad 2.08 | tok/s 11896
step   4070 | loss 1.4333 | lr 8.18e-04 | grad 1.84 | tok/s 12139
step   4080 | loss 1.3848 | lr 8.18e-04 | grad 1.61 | tok/s 12301
step   4090 | loss 1.4143 | lr 8.18e-04 | grad 1.85 | tok/s 11911
step   4100 | loss 1.4269 | lr 8.18e-04 | grad 1.30 | tok/s 12055
step   4110 | loss 1.5177 | lr 8.18e-04 | grad 1.60 | tok/s 11941
step   4120 | loss 1.7000 | lr 8.18e-04 | grad 1.25 | tok/s 12098
step   4130 | loss 1.0594 | lr 8.18e-04 | grad 1.88 | tok/s 12133
step   4140 | loss 1.2154 | lr 8.18e-04 | grad 1.32 | tok/s 11639
step   4150 | loss 1.4123 | lr 8.18e-04 | grad 1.57 | tok/s 11433
step   4160 | loss 1.0382 | lr 8.18e-04 | grad 1.04 | tok/s 12462
step   4170 | loss 1.4841 | lr 8.18e-04 | grad 2.77 | tok/s 12128
step   4180 | loss 1.8534 | lr 8.18e-04 | grad 3.78 | tok/s 12342
step   4190 | loss 1.4832 | lr 8.18e-04 | grad 2.19 | tok/s 12449
step   4200 | loss 1.5194 | lr 8.18e-04 | grad 1.73 | tok/s 11912
step   4210 | loss 1.4138 | lr 8.18e-04 | grad 1.48 | tok/s 12073
step   4220 | loss 1.7342 | lr 8.18e-04 | grad 4.09 | tok/s 11693
step   4230 | loss 2.3623 | lr 8.18e-04 | grad 2.69 | tok/s 12438
step   4240 | loss 1.6412 | lr 8.18e-04 | grad 1.62 | tok/s 11620
step   4250 | loss 1.3962 | lr 8.18e-04 | grad 1.30 | tok/s 11600
step   4260 | loss 1.5582 | lr 8.18e-04 | grad 1.46 | tok/s 11991
step   4270 | loss 1.5164 | lr 8.18e-04 | grad 3.06 | tok/s 12278
step   4280 | loss 1.4143 | lr 8.18e-04 | grad 3.42 | tok/s 11290
step   4290 | loss 1.8579 | lr 8.18e-04 | grad 1.70 | tok/s 12423
step   4300 | loss 1.5304 | lr 8.18e-04 | grad 1.10 | tok/s 11925
step   4310 | loss 1.5526 | lr 8.18e-04 | grad 2.08 | tok/s 12018
step   4320 | loss 1.3733 | lr 8.18e-04 | grad 1.42 | tok/s 12036
step   4330 | loss 1.4277 | lr 8.18e-04 | grad 4.47 | tok/s 12275
step   4340 | loss 1.5129 | lr 8.18e-04 | grad 1.17 | tok/s 12142
step   4350 | loss 0.8232 | lr 8.18e-04 | grad 1.25 | tok/s 12523
step   4360 | loss 1.5540 | lr 8.18e-04 | grad 3.16 | tok/s 12284
step   4370 | loss 1.5385 | lr 8.18e-04 | grad 1.51 | tok/s 11549
step   4380 | loss 1.4145 | lr 8.18e-04 | grad 2.02 | tok/s 12169
step   4390 | loss 1.1758 | lr 8.18e-04 | grad 2.03 | tok/s 12407
step   4400 | loss 1.2051 | lr 8.18e-04 | grad 1.64 | tok/s 12411
step   4410 | loss 1.6558 | lr 8.18e-04 | grad 1.19 | tok/s 11947
step   4420 | loss 1.3393 | lr 8.18e-04 | grad 1.37 | tok/s 12069
step   4430 | loss 1.5590 | lr 8.18e-04 | grad 1.78 | tok/s 11468
step   4440 | loss 1.4560 | lr 8.18e-04 | grad 1.56 | tok/s 11492
step   4450 | loss 1.7656 | lr 8.18e-04 | grad 2.75 | tok/s 11858
step   4460 | loss 1.4051 | lr 8.18e-04 | grad 1.36 | tok/s 12178
step   4470 | loss 1.3421 | lr 8.18e-04 | grad 1.55 | tok/s 11865
step   4480 | loss 1.4703 | lr 8.18e-04 | grad 1.80 | tok/s 12067
step   4490 | loss 1.3726 | lr 8.18e-04 | grad 1.17 | tok/s 11605
step   4500 | loss 1.4369 | lr 8.18e-04 | grad 1.75 | tok/s 12246
step   4510 | loss 1.5958 | lr 8.18e-04 | grad 1.23 | tok/s 12273
step   4520 | loss 1.6935 | lr 8.18e-04 | grad 1.47 | tok/s 11690
step   4530 | loss 1.6342 | lr 8.18e-04 | grad 2.59 | tok/s 11324
step   4540 | loss 1.6101 | lr 8.18e-04 | grad 1.75 | tok/s 11616
step   4550 | loss 1.4248 | lr 8.18e-04 | grad 1.64 | tok/s 12173
step   4560 | loss 1.3349 | lr 8.18e-04 | grad 2.67 | tok/s 12152
step   4570 | loss 1.2572 | lr 8.18e-04 | grad 1.12 | tok/s 11588
step   4580 | loss 1.7452 | lr 8.18e-04 | grad 3.84 | tok/s 11680
step   4590 | loss 1.5746 | lr 8.18e-04 | grad 2.05 | tok/s 11861
step   4600 | loss 1.6571 | lr 8.18e-04 | grad 1.40 | tok/s 11657
step   4610 | loss 1.1661 | lr 8.18e-04 | grad 1.22 | tok/s 12130
step   4620 | loss 1.5460 | lr 8.18e-04 | grad 1.73 | tok/s 12318
step   4630 | loss 1.4036 | lr 8.18e-04 | grad 1.70 | tok/s 12424
step   4640 | loss 1.3769 | lr 8.18e-04 | grad 2.00 | tok/s 12426
step   4650 | loss 1.3498 | lr 8.18e-04 | grad 1.21 | tok/s 12412
step   4660 | loss 1.3415 | lr 8.18e-04 | grad 1.71 | tok/s 12409
step   4670 | loss 1.3188 | lr 8.18e-04 | grad 1.70 | tok/s 12407
step   4680 | loss 1.2869 | lr 8.18e-04 | grad 1.89 | tok/s 12405
step   4690 | loss 1.2877 | lr 8.18e-04 | grad 1.61 | tok/s 12408
step   4700 | loss 1.3127 | lr 8.18e-04 | grad 1.67 | tok/s 12401
step   4710 | loss 1.2445 | lr 8.18e-04 | grad 1.65 | tok/s 12402
step   4720 | loss 1.1979 | lr 8.18e-04 | grad 1.52 | tok/s 12404
step   4730 | loss 1.2456 | lr 8.18e-04 | grad 1.71 | tok/s 12405
step   4740 | loss 1.2479 | lr 8.18e-04 | grad 1.76 | tok/s 12408
step   4750 | loss 1.2150 | lr 8.18e-04 | grad 1.58 | tok/s 12408
step   4760 | loss 1.2309 | lr 8.18e-04 | grad 1.62 | tok/s 12401
step   4770 | loss 1.2172 | lr 8.18e-04 | grad 1.27 | tok/s 12396
step   4780 | loss 1.2478 | lr 8.18e-04 | grad 1.62 | tok/s 12400
step   4790 | loss 1.1745 | lr 8.18e-04 | grad 1.72 | tok/s 12407
step   4800 | loss 1.1788 | lr 8.18e-04 | grad 1.92 | tok/s 12403
step   4810 | loss 1.3102 | lr 8.18e-04 | grad 1.52 | tok/s 12376
step   4820 | loss 1.7478 | lr 8.18e-04 | grad 1.99 | tok/s 12020
step   4830 | loss 1.3620 | lr 8.18e-04 | grad 1.63 | tok/s 12043
step   4840 | loss 0.7258 | lr 8.18e-04 | grad 0.78 | tok/s 12520
step   4850 | loss 1.3758 | lr 8.18e-04 | grad 1.25 | tok/s 11793
step   4860 | loss 1.4119 | lr 8.18e-04 | grad 1.20 | tok/s 11399
step   4870 | loss 1.5037 | lr 8.18e-04 | grad 1.62 | tok/s 11519
step   4880 | loss 1.2495 | lr 8.18e-04 | grad 1.64 | tok/s 12044
step   4890 | loss 1.4423 | lr 8.18e-04 | grad 1.41 | tok/s 11654
step   4900 | loss 1.3814 | lr 8.18e-04 | grad 1.62 | tok/s 12278
step   4910 | loss 1.6693 | lr 8.18e-04 | grad 5.00 | tok/s 12099
step   4920 | loss 1.2644 | lr 8.18e-04 | grad 1.43 | tok/s 12421
step   4930 | loss 1.3962 | lr 8.18e-04 | grad 1.82 | tok/s 11790
step   4940 | loss 1.3624 | lr 8.18e-04 | grad 1.33 | tok/s 11699
step   4950 | loss 1.5581 | lr 8.18e-04 | grad 1.94 | tok/s 12185
step   4960 | loss 1.2586 | lr 8.18e-04 | grad 1.63 | tok/s 12380
step   4970 | loss 1.5587 | lr 8.18e-04 | grad 3.41 | tok/s 12060
step   4980 | loss 1.5198 | lr 8.18e-04 | grad 1.43 | tok/s 11537
step   4990 | loss 1.4984 | lr 8.18e-04 | grad 1.03 | tok/s 12424
step   5000 | loss 1.5499 | lr 8.18e-04 | grad 1.62 | tok/s 11761
  >>> saved checkpoint: checkpoint_step_005000_loss_1.5499.pt
step   5010 | loss 1.4227 | lr 8.18e-04 | grad 1.13 | tok/s 4230
step   5020 | loss 1.3351 | lr 8.18e-04 | grad 1.34 | tok/s 12192
step   5030 | loss 1.4861 | lr 8.18e-04 | grad 1.55 | tok/s 11712
step   5040 | loss 1.5492 | lr 8.18e-04 | grad 1.17 | tok/s 12328
step   5050 | loss 1.5217 | lr 8.18e-04 | grad 1.37 | tok/s 12062
step   5060 | loss 1.4418 | lr 8.18e-04 | grad 2.02 | tok/s 11537
step   5070 | loss 1.4698 | lr 8.18e-04 | grad 6.03 | tok/s 11764
step   5080 | loss 1.4235 | lr 8.18e-04 | grad 1.52 | tok/s 12065
step   5090 | loss 1.2774 | lr 8.18e-04 | grad 1.05 | tok/s 11975
step   5100 | loss 1.4926 | lr 8.18e-04 | grad 2.19 | tok/s 11937
step   5110 | loss 1.5857 | lr 8.18e-04 | grad 1.62 | tok/s 11725
step   5120 | loss 1.3649 | lr 8.18e-04 | grad 1.55 | tok/s 11854
step   5130 | loss 1.4408 | lr 8.18e-04 | grad 1.28 | tok/s 12035
step   5140 | loss 1.6459 | lr 8.18e-04 | grad 2.67 | tok/s 12398
step   5150 | loss 1.4909 | lr 8.18e-04 | grad 1.49 | tok/s 11397
step   5160 | loss 1.3413 | lr 8.18e-04 | grad 1.73 | tok/s 11738
step   5170 | loss 1.3747 | lr 8.18e-04 | grad 1.15 | tok/s 11556
step   5180 | loss 1.4490 | lr 8.18e-04 | grad 1.27 | tok/s 11452
step   5190 | loss 1.5150 | lr 8.18e-04 | grad 1.62 | tok/s 12440
step   5200 | loss 1.5049 | lr 8.18e-04 | grad 2.06 | tok/s 11997
step   5210 | loss 1.2123 | lr 8.18e-04 | grad 1.30 | tok/s 12441
step   5220 | loss 1.6139 | lr 8.18e-04 | grad 2.64 | tok/s 11468
step   5230 | loss 1.5013 | lr 8.18e-04 | grad 1.33 | tok/s 12181
step   5240 | loss 1.0915 | lr 8.18e-04 | grad 1.35 | tok/s 12472
step   5250 | loss 1.2818 | lr 8.18e-04 | grad 1.52 | tok/s 11999
step   5260 | loss 1.3601 | lr 8.18e-04 | grad 4.62 | tok/s 12210
step   5270 | loss 1.4250 | lr 8.18e-04 | grad 1.22 | tok/s 11379
step   5280 | loss 1.2502 | lr 8.18e-04 | grad 1.62 | tok/s 11815
step   5290 | loss 1.2363 | lr 8.18e-04 | grad 1.45 | tok/s 12240
step   5300 | loss 1.3898 | lr 8.18e-04 | grad 1.27 | tok/s 11767

Training complete! Final step: 5309
