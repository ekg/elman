Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_002340/eval_7/level42_100m_20260202_002347
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 482,190,336 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 6.9283 | lr 3.00e-04 | grad 35.75 | tok/s 2475
step     20 | loss 3.4103 | lr 3.00e-04 | grad 3.80 | tok/s 3726
step     30 | loss 3.6556 | lr 3.00e-04 | grad 10.31 | tok/s 3726
step     40 | loss 3.6879 | lr 3.00e-04 | grad 21.38 | tok/s 3821
step     50 | loss 6.5180 | lr 3.00e-04 | grad 44.00 | tok/s 3903
step     60 | loss 3.8310 | lr 3.00e-04 | grad 7.75 | tok/s 3898
step     70 | loss 3.9451 | lr 3.00e-04 | grad 9.50 | tok/s 3901
step     80 | loss 3.8167 | lr 3.00e-04 | grad 14.50 | tok/s 3887
step     90 | loss 3.3917 | lr 3.00e-04 | grad 12.06 | tok/s 3883
step    100 | loss 3.5468 | lr 3.00e-04 | grad 11.25 | tok/s 3871
step    110 | loss 3.1712 | lr 3.00e-04 | grad 6.69 | tok/s 3871
step    120 | loss 3.2472 | lr 3.00e-04 | grad 16.38 | tok/s 3816
step    130 | loss 3.1465 | lr 3.00e-04 | grad 4.88 | tok/s 3731
step    140 | loss 2.7005 | lr 3.00e-04 | grad 9.62 | tok/s 3801
step    150 | loss 2.8934 | lr 3.00e-04 | grad 7.94 | tok/s 3744
step    160 | loss 2.4390 | lr 3.00e-04 | grad 10.12 | tok/s 3854
step    170 | loss 2.9731 | lr 3.00e-04 | grad 4.56 | tok/s 3775
step    180 | loss 2.7687 | lr 3.00e-04 | grad 3.75 | tok/s 3707
step    190 | loss 2.7681 | lr 3.00e-04 | grad 5.03 | tok/s 3737
step    200 | loss 2.5896 | lr 3.00e-04 | grad 4.09 | tok/s 3651
step    210 | loss 2.2626 | lr 3.00e-04 | grad 3.84 | tok/s 3865
step    220 | loss 2.1682 | lr 3.00e-04 | grad 2.53 | tok/s 3628
step    230 | loss 2.7419 | lr 3.00e-04 | grad 5.03 | tok/s 3709
step    240 | loss 3.1916 | lr 3.00e-04 | grad 3.28 | tok/s 3723
step    250 | loss 2.5569 | lr 3.00e-04 | grad 7.69 | tok/s 3803
step    260 | loss 2.6502 | lr 3.00e-04 | grad 3.03 | tok/s 3731
step    270 | loss 2.3703 | lr 3.00e-04 | grad 2.77 | tok/s 3806
step    280 | loss 2.5010 | lr 3.00e-04 | grad 3.06 | tok/s 3818
step    290 | loss 2.0877 | lr 3.00e-04 | grad 3.64 | tok/s 3604
step    300 | loss 2.4094 | lr 3.00e-04 | grad 4.69 | tok/s 3610
step    310 | loss 2.1911 | lr 3.00e-04 | grad 7.47 | tok/s 3566
step    320 | loss 2.3772 | lr 3.00e-04 | grad 3.64 | tok/s 3705
step    330 | loss 2.0816 | lr 3.00e-04 | grad 3.05 | tok/s 3615
step    340 | loss 2.4268 | lr 3.00e-04 | grad 5.47 | tok/s 3719
step    350 | loss 2.1446 | lr 3.00e-04 | grad 3.09 | tok/s 3691
step    360 | loss 2.6754 | lr 3.00e-04 | grad 9.31 | tok/s 3733
step    370 | loss 2.4491 | lr 3.00e-04 | grad 2.75 | tok/s 3842
step    380 | loss 2.0086 | lr 3.00e-04 | grad 2.36 | tok/s 3537
step    390 | loss 2.1187 | lr 3.00e-04 | grad 2.62 | tok/s 3866
step    400 | loss 1.9601 | lr 3.00e-04 | grad 2.98 | tok/s 3866
step    410 | loss 1.8641 | lr 3.00e-04 | grad 2.47 | tok/s 3866
step    420 | loss 1.9621 | lr 3.00e-04 | grad 5.44 | tok/s 3723
step    430 | loss 2.2179 | lr 3.00e-04 | grad 1.74 | tok/s 3585
step    440 | loss 2.2809 | lr 3.00e-04 | grad 2.41 | tok/s 3823
step    450 | loss 2.2327 | lr 3.00e-04 | grad 2.98 | tok/s 3836
step    460 | loss 2.1250 | lr 3.00e-04 | grad 2.55 | tok/s 3735
step    470 | loss 2.2171 | lr 3.00e-04 | grad 2.66 | tok/s 3696
step    480 | loss 2.0411 | lr 3.00e-04 | grad 3.45 | tok/s 3724
step    490 | loss 2.2046 | lr 3.00e-04 | grad 2.59 | tok/s 3697
step    500 | loss 2.1505 | lr 3.00e-04 | grad 2.55 | tok/s 3808
step    510 | loss 2.0931 | lr 3.00e-04 | grad 1.91 | tok/s 3738
step    520 | loss 2.1364 | lr 3.00e-04 | grad 1.56 | tok/s 3728
step    530 | loss 2.3240 | lr 3.00e-04 | grad 2.34 | tok/s 3724
step    540 | loss 2.1623 | lr 3.00e-04 | grad 1.63 | tok/s 3617
step    550 | loss 1.9240 | lr 3.00e-04 | grad 1.59 | tok/s 3744
step    560 | loss 2.0852 | lr 3.00e-04 | grad 4.03 | tok/s 3669
step    570 | loss 2.1767 | lr 3.00e-04 | grad 1.77 | tok/s 3685
step    580 | loss 1.6987 | lr 3.00e-04 | grad 3.14 | tok/s 3639
step    590 | loss 1.9384 | lr 3.00e-04 | grad 2.39 | tok/s 3869
step    600 | loss 1.8159 | lr 3.00e-04 | grad 2.88 | tok/s 3876
step    610 | loss 1.7784 | lr 3.00e-04 | grad 2.08 | tok/s 3871
step    620 | loss 1.7228 | lr 3.00e-04 | grad 2.11 | tok/s 3874
step    630 | loss 1.7768 | lr 3.00e-04 | grad 2.36 | tok/s 3879
step    640 | loss 1.7280 | lr 3.00e-04 | grad 2.27 | tok/s 3869
step    650 | loss 1.7184 | lr 3.00e-04 | grad 2.72 | tok/s 3871
step    660 | loss 1.9392 | lr 3.00e-04 | grad 2.28 | tok/s 3796
step    670 | loss 1.9308 | lr 3.00e-04 | grad 2.48 | tok/s 3723
step    680 | loss 2.2009 | lr 3.00e-04 | grad 2.20 | tok/s 3771
step    690 | loss 1.9775 | lr 3.00e-04 | grad 2.00 | tok/s 3756
step    700 | loss 2.1023 | lr 3.00e-04 | grad 3.66 | tok/s 3774
step    710 | loss 2.0980 | lr 3.00e-04 | grad 4.12 | tok/s 3626
step    720 | loss 1.9712 | lr 3.00e-04 | grad 1.43 | tok/s 3619
step    730 | loss 2.1043 | lr 3.00e-04 | grad 5.19 | tok/s 3705
step    740 | loss 1.8196 | lr 3.00e-04 | grad 1.73 | tok/s 3661
step    750 | loss 2.0732 | lr 3.00e-04 | grad 6.34 | tok/s 3608
step    760 | loss 1.7943 | lr 3.00e-04 | grad 3.44 | tok/s 3759
step    770 | loss 1.9488 | lr 3.00e-04 | grad 2.97 | tok/s 3785
step    780 | loss 2.2206 | lr 3.00e-04 | grad 4.50 | tok/s 3807
step    790 | loss 2.4540 | lr 3.00e-04 | grad 1.88 | tok/s 3865
step    800 | loss 1.9119 | lr 3.00e-04 | grad 2.02 | tok/s 3870
step    810 | loss 1.8620 | lr 3.00e-04 | grad 4.50 | tok/s 3629
step    820 | loss 1.8426 | lr 3.00e-04 | grad 2.33 | tok/s 3709
step    830 | loss 2.0839 | lr 3.00e-04 | grad 3.52 | tok/s 3785
step    840 | loss 2.4706 | lr 3.00e-04 | grad 2.12 | tok/s 3739
step    850 | loss 1.5015 | lr 3.00e-04 | grad 2.86 | tok/s 3809
step    860 | loss 1.9728 | lr 3.00e-04 | grad 2.19 | tok/s 3633
step    870 | loss 1.8978 | lr 3.00e-04 | grad 3.30 | tok/s 3659
step    880 | loss 1.8944 | lr 3.00e-04 | grad 2.95 | tok/s 3719
step    890 | loss 2.2835 | lr 3.00e-04 | grad 4.59 | tok/s 3690
step    900 | loss 2.0422 | lr 3.00e-04 | grad 3.22 | tok/s 3792
step    910 | loss 2.1357 | lr 3.00e-04 | grad 2.64 | tok/s 3828
step    920 | loss 2.0872 | lr 3.00e-04 | grad 2.66 | tok/s 3822
step    930 | loss 1.9681 | lr 3.00e-04 | grad 2.53 | tok/s 3726
step    940 | loss 1.8603 | lr 3.00e-04 | grad 2.25 | tok/s 3666
step    950 | loss 1.9133 | lr 3.00e-04 | grad 2.48 | tok/s 3682
step    960 | loss 1.8354 | lr 3.00e-04 | grad 1.80 | tok/s 3595
step    970 | loss 1.9016 | lr 3.00e-04 | grad 2.58 | tok/s 3721
step    980 | loss 1.8404 | lr 3.00e-04 | grad 2.67 | tok/s 4345
step    990 | loss 1.8079 | lr 3.00e-04 | grad 2.27 | tok/s 4711
step   1000 | loss 1.8357 | lr 3.00e-04 | grad 1.68 | tok/s 3481
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8357.pt
step   1010 | loss 1.7734 | lr 3.00e-04 | grad 2.91 | tok/s 2714
step   1020 | loss 1.7925 | lr 3.00e-04 | grad 2.36 | tok/s 3792
step   1030 | loss 2.1738 | lr 3.00e-04 | grad 5.03 | tok/s 3756
step   1040 | loss 2.4657 | lr 3.00e-04 | grad 2.61 | tok/s 3832
step   1050 | loss 1.8925 | lr 3.00e-04 | grad 1.93 | tok/s 3681
step   1060 | loss 2.2065 | lr 3.00e-04 | grad 2.02 | tok/s 3704
step   1070 | loss 1.5648 | lr 3.00e-04 | grad 2.67 | tok/s 3811
step   1080 | loss 1.7092 | lr 3.00e-04 | grad 2.17 | tok/s 3868
step   1090 | loss 2.0464 | lr 3.00e-04 | grad 3.92 | tok/s 3756
step   1100 | loss 2.2856 | lr 3.00e-04 | grad 4.56 | tok/s 3781
step   1110 | loss 2.1131 | lr 3.00e-04 | grad 2.80 | tok/s 3774
step   1120 | loss 1.9324 | lr 3.00e-04 | grad 7.56 | tok/s 3742
step   1130 | loss 1.6342 | lr 3.00e-04 | grad 3.66 | tok/s 3716
step   1140 | loss 1.6764 | lr 3.00e-04 | grad 2.33 | tok/s 3867
step   1150 | loss 1.5830 | lr 3.00e-04 | grad 2.00 | tok/s 3872
step   1160 | loss 1.5694 | lr 3.00e-04 | grad 2.28 | tok/s 3874
step   1170 | loss 1.5013 | lr 3.00e-04 | grad 2.78 | tok/s 3874
step   1180 | loss 1.6243 | lr 3.00e-04 | grad 2.30 | tok/s 3855
step   1190 | loss 2.0146 | lr 3.00e-04 | grad 4.16 | tok/s 3855
step   1200 | loss 2.2176 | lr 3.00e-04 | grad 9.56 | tok/s 3795
step   1210 | loss 1.9408 | lr 3.00e-04 | grad 2.62 | tok/s 3826
step   1220 | loss 2.4948 | lr 3.00e-04 | grad 8.31 | tok/s 3634
step   1230 | loss 2.1797 | lr 3.00e-04 | grad 4.91 | tok/s 3752
step   1240 | loss 1.8367 | lr 3.00e-04 | grad 2.50 | tok/s 3684
step   1250 | loss 1.8033 | lr 3.00e-04 | grad 2.62 | tok/s 3795
step   1260 | loss 2.1970 | lr 3.00e-04 | grad 3.28 | tok/s 3864
step   1270 | loss 1.6213 | lr 3.00e-04 | grad 2.08 | tok/s 3866
step   1280 | loss 1.6904 | lr 3.00e-04 | grad 3.84 | tok/s 3667
step   1290 | loss 1.7478 | lr 3.00e-04 | grad 2.69 | tok/s 3652
step   1300 | loss 1.8237 | lr 3.00e-04 | grad 4.19 | tok/s 3730
step   1310 | loss 1.6921 | lr 3.00e-04 | grad 3.41 | tok/s 3827
step   1320 | loss 1.7841 | lr 3.00e-04 | grad 2.67 | tok/s 3774
step   1330 | loss 2.0093 | lr 3.00e-04 | grad 2.34 | tok/s 3871
step   1340 | loss 1.7974 | lr 3.00e-04 | grad 2.75 | tok/s 3721
step   1350 | loss 1.7089 | lr 3.00e-04 | grad 2.16 | tok/s 3838
step   1360 | loss 1.9362 | lr 3.00e-04 | grad 2.16 | tok/s 3629
step   1370 | loss 1.8449 | lr 3.00e-04 | grad 5.12 | tok/s 3712
step   1380 | loss 2.2085 | lr 3.00e-04 | grad 2.75 | tok/s 3733
step   1390 | loss 1.8734 | lr 3.00e-04 | grad 1.97 | tok/s 3826
step   1400 | loss 2.0151 | lr 3.00e-04 | grad 3.20 | tok/s 3808
step   1410 | loss 1.7273 | lr 3.00e-04 | grad 2.58 | tok/s 3668
step   1420 | loss 2.0065 | lr 3.00e-04 | grad 2.94 | tok/s 3708
step   1430 | loss 1.8750 | lr 3.00e-04 | grad 5.31 | tok/s 3721
step   1440 | loss 1.9441 | lr 3.00e-04 | grad 2.59 | tok/s 3650
step   1450 | loss 1.9601 | lr 3.00e-04 | grad 2.36 | tok/s 3825
step   1460 | loss 1.8091 | lr 3.00e-04 | grad 2.98 | tok/s 3703
step   1470 | loss 1.7148 | lr 3.00e-04 | grad 3.02 | tok/s 3760
step   1480 | loss 2.1069 | lr 3.00e-04 | grad 2.92 | tok/s 3615
step   1490 | loss 1.7180 | lr 3.00e-04 | grad 2.62 | tok/s 3698
step   1500 | loss 1.8043 | lr 3.00e-04 | grad 2.77 | tok/s 3821
step   1510 | loss 2.2520 | lr 3.00e-04 | grad 6.41 | tok/s 3698
step   1520 | loss 1.7441 | lr 3.00e-04 | grad 2.27 | tok/s 3704
step   1530 | loss 1.8059 | lr 3.00e-04 | grad 1.84 | tok/s 3744
step   1540 | loss 1.7892 | lr 3.00e-04 | grad 2.08 | tok/s 3782
step   1550 | loss 1.9045 | lr 3.00e-04 | grad 1.93 | tok/s 3642
step   1560 | loss 1.6731 | lr 3.00e-04 | grad 2.28 | tok/s 3601
step   1570 | loss 1.6966 | lr 3.00e-04 | grad 2.38 | tok/s 3725
step   1580 | loss 2.3976 | lr 3.00e-04 | grad 2.55 | tok/s 3841
step   1590 | loss 1.7346 | lr 3.00e-04 | grad 4.12 | tok/s 3788
step   1600 | loss 1.6598 | lr 3.00e-04 | grad 2.22 | tok/s 3713
step   1610 | loss 1.7913 | lr 3.00e-04 | grad 2.12 | tok/s 3728
step   1620 | loss 1.7116 | lr 3.00e-04 | grad 2.72 | tok/s 3809
step   1630 | loss 1.7893 | lr 3.00e-04 | grad 2.20 | tok/s 3835
step   1640 | loss 1.8104 | lr 3.00e-04 | grad 1.66 | tok/s 3771
step   1650 | loss 1.5425 | lr 3.00e-04 | grad 2.86 | tok/s 3880
step   1660 | loss 1.7186 | lr 3.00e-04 | grad 2.28 | tok/s 3696
step   1670 | loss 1.6625 | lr 3.00e-04 | grad 2.81 | tok/s 4558
step   1680 | loss 1.8867 | lr 3.00e-04 | grad 2.08 | tok/s 7830
step   1690 | loss 1.6208 | lr 3.00e-04 | grad 1.93 | tok/s 7697
step   1700 | loss 1.6212 | lr 3.00e-04 | grad 4.25 | tok/s 8060

Training complete! Final step: 1703
