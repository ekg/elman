Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_002340/eval_2/level42_100m_20260202_002347
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 494,895,232 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 6.7328 | lr 3.00e-04 | grad 23.00 | tok/s 2439
step     20 | loss 3.0755 | lr 3.00e-04 | grad 8.12 | tok/s 3436
step     30 | loss 3.3939 | lr 3.00e-04 | grad 4.00 | tok/s 3471
step     40 | loss 4.6165 | lr 3.00e-04 | grad 6.25 | tok/s 3575
step     50 | loss 5.5384 | lr 3.00e-04 | grad 11.00 | tok/s 3620
step     60 | loss 3.7407 | lr 3.00e-04 | grad 12.94 | tok/s 3586
step     70 | loss 3.7627 | lr 3.00e-04 | grad 8.56 | tok/s 3606
step     80 | loss 3.4074 | lr 3.00e-04 | grad 17.50 | tok/s 3578
step     90 | loss 3.2637 | lr 3.00e-04 | grad 5.72 | tok/s 3601
step    100 | loss 3.0147 | lr 3.00e-04 | grad 7.72 | tok/s 3638
step    110 | loss 2.9317 | lr 3.00e-04 | grad 5.72 | tok/s 3567
step    120 | loss 3.4286 | lr 3.00e-04 | grad 3.44 | tok/s 3358
step    130 | loss 2.6026 | lr 3.00e-04 | grad 4.88 | tok/s 3425
step    140 | loss 2.8443 | lr 3.00e-04 | grad 5.41 | tok/s 3457
step    150 | loss 2.6119 | lr 3.00e-04 | grad 4.75 | tok/s 3535
step    160 | loss 2.8291 | lr 3.00e-04 | grad 3.52 | tok/s 3566
step    170 | loss 2.7470 | lr 3.00e-04 | grad 5.25 | tok/s 3339
step    180 | loss 2.7521 | lr 3.00e-04 | grad 7.72 | tok/s 3479
step    190 | loss 2.4973 | lr 3.00e-04 | grad 3.97 | tok/s 3403
step    200 | loss 2.2607 | lr 3.00e-04 | grad 2.44 | tok/s 3562
step    210 | loss 2.1727 | lr 3.00e-04 | grad 3.42 | tok/s 3350
step    220 | loss 2.5924 | lr 3.00e-04 | grad 2.45 | tok/s 3415
step    230 | loss 2.5779 | lr 3.00e-04 | grad 2.88 | tok/s 3421
step    240 | loss 2.5360 | lr 3.00e-04 | grad 6.56 | tok/s 3430
step    250 | loss 2.3582 | lr 3.00e-04 | grad 3.81 | tok/s 3460
step    260 | loss 2.3101 | lr 3.00e-04 | grad 2.62 | tok/s 3580
step    270 | loss 2.3888 | lr 3.00e-04 | grad 4.09 | tok/s 3498
step    280 | loss 2.1887 | lr 3.00e-04 | grad 4.22 | tok/s 3389
step    290 | loss 2.2157 | lr 3.00e-04 | grad 2.09 | tok/s 3402
step    300 | loss 2.3501 | lr 3.00e-04 | grad 2.58 | tok/s 3366
step    310 | loss 2.1425 | lr 3.00e-04 | grad 3.72 | tok/s 3520
step    320 | loss 2.3344 | lr 3.00e-04 | grad 4.12 | tok/s 3404
step    330 | loss 2.2441 | lr 3.00e-04 | grad 2.41 | tok/s 3532
step    340 | loss 2.3637 | lr 3.00e-04 | grad 2.95 | tok/s 3429
step    350 | loss 2.5252 | lr 3.00e-04 | grad 2.84 | tok/s 3578
step    360 | loss 2.1679 | lr 3.00e-04 | grad 2.94 | tok/s 3472
step    370 | loss 2.1308 | lr 3.00e-04 | grad 3.36 | tok/s 3550
step    380 | loss 1.9770 | lr 3.00e-04 | grad 2.61 | tok/s 3600
step    390 | loss 1.8483 | lr 3.00e-04 | grad 2.28 | tok/s 3601
step    400 | loss 2.0808 | lr 3.00e-04 | grad 3.20 | tok/s 3466
step    410 | loss 2.2408 | lr 3.00e-04 | grad 2.47 | tok/s 3411
step    420 | loss 2.3237 | lr 3.00e-04 | grad 2.11 | tok/s 3603
step    430 | loss 2.2207 | lr 3.00e-04 | grad 2.34 | tok/s 3593
step    440 | loss 2.2205 | lr 3.00e-04 | grad 2.53 | tok/s 3422
step    450 | loss 2.0946 | lr 3.00e-04 | grad 2.39 | tok/s 3480
step    460 | loss 2.0811 | lr 3.00e-04 | grad 1.87 | tok/s 3527
step    470 | loss 2.0787 | lr 3.00e-04 | grad 2.12 | tok/s 3475
step    480 | loss 2.2349 | lr 3.00e-04 | grad 4.38 | tok/s 3586
step    490 | loss 2.1988 | lr 3.00e-04 | grad 1.92 | tok/s 3443
step    500 | loss 2.0753 | lr 3.00e-04 | grad 1.99 | tok/s 3406
step    510 | loss 2.3656 | lr 3.00e-04 | grad 5.31 | tok/s 3402
step    520 | loss 1.9574 | lr 3.00e-04 | grad 3.03 | tok/s 3439
step    530 | loss 2.1229 | lr 3.00e-04 | grad 2.91 | tok/s 3439
step    540 | loss 2.1859 | lr 3.00e-04 | grad 2.09 | tok/s 3444
step    550 | loss 1.7101 | lr 3.00e-04 | grad 2.47 | tok/s 3448
step    560 | loss 1.9594 | lr 3.00e-04 | grad 2.08 | tok/s 3585
step    570 | loss 1.8288 | lr 3.00e-04 | grad 2.45 | tok/s 3602
step    580 | loss 1.7870 | lr 3.00e-04 | grad 1.74 | tok/s 3598
step    590 | loss 1.7786 | lr 3.00e-04 | grad 2.30 | tok/s 3601
step    600 | loss 1.7865 | lr 3.00e-04 | grad 2.59 | tok/s 3604
step    610 | loss 1.7518 | lr 3.00e-04 | grad 1.67 | tok/s 3598
step    620 | loss 1.6741 | lr 3.00e-04 | grad 2.50 | tok/s 3597
step    630 | loss 2.0993 | lr 3.00e-04 | grad 3.00 | tok/s 3484
step    640 | loss 2.0517 | lr 3.00e-04 | grad 2.70 | tok/s 3307
step    650 | loss 2.0397 | lr 3.00e-04 | grad 1.95 | tok/s 3553
step    660 | loss 1.9325 | lr 3.00e-04 | grad 2.84 | tok/s 3438
step    670 | loss 2.1497 | lr 3.00e-04 | grad 2.00 | tok/s 3495
step    680 | loss 2.1512 | lr 3.00e-04 | grad 2.45 | tok/s 3397
step    690 | loss 1.9904 | lr 3.00e-04 | grad 1.90 | tok/s 3418
step    700 | loss 1.8782 | lr 3.00e-04 | grad 2.45 | tok/s 3338
step    710 | loss 2.0944 | lr 3.00e-04 | grad 1.38 | tok/s 3371
step    720 | loss 1.9834 | lr 3.00e-04 | grad 2.02 | tok/s 3448
step    730 | loss 1.8296 | lr 3.00e-04 | grad 2.62 | tok/s 3527
step    740 | loss 2.0207 | lr 3.00e-04 | grad 4.41 | tok/s 3405
step    750 | loss 2.4210 | lr 3.00e-04 | grad 2.25 | tok/s 3584
step    760 | loss 1.9539 | lr 3.00e-04 | grad 1.91 | tok/s 3598
step    770 | loss 1.9544 | lr 3.00e-04 | grad 4.50 | tok/s 3487
step    780 | loss 1.8729 | lr 3.00e-04 | grad 2.66 | tok/s 3529
step    790 | loss 1.9620 | lr 3.00e-04 | grad 2.08 | tok/s 3450
step    800 | loss 2.2408 | lr 3.00e-04 | grad 1.75 | tok/s 3473
step    810 | loss 1.4045 | lr 3.00e-04 | grad 1.98 | tok/s 3391
step    820 | loss 2.0207 | lr 3.00e-04 | grad 3.16 | tok/s 3512
step    830 | loss 1.9237 | lr 3.00e-04 | grad 2.02 | tok/s 3295
step    840 | loss 2.1250 | lr 3.00e-04 | grad 3.23 | tok/s 3437
step    850 | loss 1.9651 | lr 3.00e-04 | grad 3.25 | tok/s 3403
step    860 | loss 1.9593 | lr 3.00e-04 | grad 2.42 | tok/s 3502
step    870 | loss 2.1574 | lr 3.00e-04 | grad 2.17 | tok/s 3600
step    880 | loss 1.9867 | lr 3.00e-04 | grad 2.97 | tok/s 3507
step    890 | loss 1.8936 | lr 3.00e-04 | grad 3.36 | tok/s 3360
step    900 | loss 1.8493 | lr 3.00e-04 | grad 2.44 | tok/s 3478
step    910 | loss 2.0322 | lr 3.00e-04 | grad 1.70 | tok/s 3348
step    920 | loss 2.0178 | lr 3.00e-04 | grad 8.69 | tok/s 3513
step    930 | loss 1.8150 | lr 3.00e-04 | grad 2.39 | tok/s 3489
step    940 | loss 1.7665 | lr 3.00e-04 | grad 1.88 | tok/s 3357
step    950 | loss 1.9132 | lr 3.00e-04 | grad 1.63 | tok/s 3353
step    960 | loss 1.7844 | lr 3.00e-04 | grad 1.63 | tok/s 3389
step    970 | loss 1.7710 | lr 3.00e-04 | grad 2.20 | tok/s 3456
step    980 | loss 2.4937 | lr 3.00e-04 | grad 3.72 | tok/s 3601
step    990 | loss 2.1197 | lr 3.00e-04 | grad 2.12 | tok/s 3478
step   1000 | loss 1.8706 | lr 3.00e-04 | grad 3.02 | tok/s 3470
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8706.pt
step   1010 | loss 1.6240 | lr 3.00e-04 | grad 2.17 | tok/s 2712
step   1020 | loss 1.6561 | lr 3.00e-04 | grad 2.00 | tok/s 3608
step   1030 | loss 1.9276 | lr 3.00e-04 | grad 3.61 | tok/s 3530
step   1040 | loss 2.4148 | lr 3.00e-04 | grad 3.89 | tok/s 3465
step   1050 | loss 2.1780 | lr 3.00e-04 | grad 3.91 | tok/s 3517
step   1060 | loss 1.9112 | lr 3.00e-04 | grad 2.92 | tok/s 3471
step   1070 | loss 1.5924 | lr 3.00e-04 | grad 3.14 | tok/s 3457
step   1080 | loss 1.6702 | lr 3.00e-04 | grad 2.36 | tok/s 3598
step   1090 | loss 1.5914 | lr 3.00e-04 | grad 2.11 | tok/s 3602
step   1100 | loss 1.5701 | lr 3.00e-04 | grad 2.00 | tok/s 3601
step   1110 | loss 1.4928 | lr 3.00e-04 | grad 2.41 | tok/s 3602
step   1120 | loss 1.6276 | lr 3.00e-04 | grad 2.33 | tok/s 3544
step   1130 | loss 2.0364 | lr 3.00e-04 | grad 2.30 | tok/s 3588
step   1140 | loss 2.3090 | lr 3.00e-04 | grad 1.94 | tok/s 3547
step   1150 | loss 2.0410 | lr 3.00e-04 | grad 4.59 | tok/s 3483
step   1160 | loss 2.2054 | lr 3.00e-04 | grad 5.19 | tok/s 3474
step   1170 | loss 1.9833 | lr 3.00e-04 | grad 2.39 | tok/s 3414
step   1180 | loss 1.9939 | lr 3.00e-04 | grad 1.88 | tok/s 3418
step   1190 | loss 1.9542 | lr 3.00e-04 | grad 2.31 | tok/s 3561
step   1200 | loss 1.8513 | lr 3.00e-04 | grad 1.99 | tok/s 3597
step   1210 | loss 1.5390 | lr 3.00e-04 | grad 1.87 | tok/s 3458
step   1220 | loss 1.7242 | lr 3.00e-04 | grad 1.54 | tok/s 3539
step   1230 | loss 1.8733 | lr 3.00e-04 | grad 3.06 | tok/s 3487
step   1240 | loss 1.5622 | lr 3.00e-04 | grad 2.52 | tok/s 3561
step   1250 | loss 1.7443 | lr 3.00e-04 | grad 1.88 | tok/s 3434
step   1260 | loss 1.8659 | lr 3.00e-04 | grad 2.17 | tok/s 3605
step   1270 | loss 1.8021 | lr 3.00e-04 | grad 2.47 | tok/s 3513
step   1280 | loss 1.6755 | lr 3.00e-04 | grad 2.38 | tok/s 3548
step   1290 | loss 1.8508 | lr 3.00e-04 | grad 2.20 | tok/s 3259
step   1300 | loss 1.9365 | lr 3.00e-04 | grad 3.55 | tok/s 3447
step   1310 | loss 2.1231 | lr 3.00e-04 | grad 3.08 | tok/s 3480
step   1320 | loss 1.7855 | lr 3.00e-04 | grad 3.12 | tok/s 3553
step   1330 | loss 2.0356 | lr 3.00e-04 | grad 2.38 | tok/s 5591
step   1340 | loss 1.6697 | lr 3.00e-04 | grad 2.61 | tok/s 3420
step   1350 | loss 1.9990 | lr 3.00e-04 | grad 1.72 | tok/s 3495
step   1360 | loss 1.9619 | lr 3.00e-04 | grad 6.59 | tok/s 3480
step   1370 | loss 1.8179 | lr 3.00e-04 | grad 2.92 | tok/s 3364
step   1380 | loss 2.0286 | lr 3.00e-04 | grad 3.47 | tok/s 3564
step   1390 | loss 1.8920 | lr 3.00e-04 | grad 4.44 | tok/s 3404
step   1400 | loss 1.8789 | lr 3.00e-04 | grad 4.88 | tok/s 3561
step   1410 | loss 1.7961 | lr 3.00e-04 | grad 3.25 | tok/s 3476
step   1420 | loss 1.8048 | lr 3.00e-04 | grad 2.95 | tok/s 3424
step   1430 | loss 1.9017 | lr 3.00e-04 | grad 6.69 | tok/s 3595
step   1440 | loss 1.9565 | lr 3.00e-04 | grad 2.38 | tok/s 3393
step   1450 | loss 1.9078 | lr 3.00e-04 | grad 2.44 | tok/s 3545
step   1460 | loss 1.8663 | lr 3.00e-04 | grad 3.27 | tok/s 3482
step   1470 | loss 1.8787 | lr 3.00e-04 | grad 2.38 | tok/s 3378
step   1480 | loss 1.6129 | lr 3.00e-04 | grad 4.16 | tok/s 3278
step   1490 | loss 1.6783 | lr 3.00e-04 | grad 2.62 | tok/s 3515
step   1500 | loss 2.3515 | lr 3.00e-04 | grad 1.82 | tok/s 3468
step   1510 | loss 1.7320 | lr 3.00e-04 | grad 2.19 | tok/s 3500
step   1520 | loss 1.6599 | lr 3.00e-04 | grad 1.95 | tok/s 3491
step   1530 | loss 1.7724 | lr 3.00e-04 | grad 2.08 | tok/s 3436
step   1540 | loss 1.8820 | lr 3.00e-04 | grad 5.44 | tok/s 3532
step   1550 | loss 1.8178 | lr 3.00e-04 | grad 2.02 | tok/s 3550
step   1560 | loss 1.7886 | lr 3.00e-04 | grad 5.22 | tok/s 6278
step   1570 | loss 1.7137 | lr 3.00e-04 | grad 1.59 | tok/s 7771
step   1580 | loss 1.2375 | lr 3.00e-04 | grad 2.09 | tok/s 7865

Training complete! Final step: 1587
