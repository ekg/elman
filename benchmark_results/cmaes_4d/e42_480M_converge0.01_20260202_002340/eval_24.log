Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_002340/eval_24/level42_100m_20260202_012420
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 499,363,200 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 6.9094 | lr 3.00e-04 | grad 16.12 | tok/s 4316
step     20 | loss 4.2177 | lr 3.00e-04 | grad 8.38 | tok/s 7379
step     30 | loss 3.2226 | lr 3.00e-04 | grad 5.53 | tok/s 7461
step     40 | loss 3.1583 | lr 3.00e-04 | grad 9.56 | tok/s 7150
step     50 | loss 3.5102 | lr 3.00e-04 | grad 8.56 | tok/s 7266
step     60 | loss 3.0896 | lr 3.00e-04 | grad 9.12 | tok/s 7506
step     70 | loss 2.7489 | lr 3.00e-04 | grad 14.25 | tok/s 7608
step     80 | loss 6.5437 | lr 3.00e-04 | grad 42.00 | tok/s 7655
step     90 | loss 5.1289 | lr 3.00e-04 | grad 8.69 | tok/s 7795
step    100 | loss 4.1503 | lr 3.00e-04 | grad 6.84 | tok/s 7792
step    110 | loss 4.0714 | lr 3.00e-04 | grad 15.38 | tok/s 7794
step    120 | loss 3.8953 | lr 3.00e-04 | grad 15.25 | tok/s 7792
step    130 | loss 3.8690 | lr 3.00e-04 | grad 7.94 | tok/s 7788
step    140 | loss 3.3968 | lr 3.00e-04 | grad 7.28 | tok/s 7787
step    150 | loss 3.6672 | lr 3.00e-04 | grad 14.06 | tok/s 7787
step    160 | loss 3.1770 | lr 3.00e-04 | grad 12.62 | tok/s 7788
step    170 | loss 3.1690 | lr 3.00e-04 | grad 8.38 | tok/s 7781
step    180 | loss 3.0504 | lr 3.00e-04 | grad 10.94 | tok/s 7786
step    190 | loss 3.1564 | lr 3.00e-04 | grad 10.31 | tok/s 7780
step    200 | loss 2.8182 | lr 3.00e-04 | grad 4.78 | tok/s 7783
step    210 | loss 2.8187 | lr 3.00e-04 | grad 8.38 | tok/s 7779
step    220 | loss 3.0734 | lr 3.00e-04 | grad 4.66 | tok/s 7682
step    230 | loss 3.6484 | lr 3.00e-04 | grad 10.94 | tok/s 7595
step    240 | loss 2.8013 | lr 3.00e-04 | grad 6.25 | tok/s 7206
step    250 | loss 2.5933 | lr 3.00e-04 | grad 3.77 | tok/s 7412
step    260 | loss 2.3841 | lr 3.00e-04 | grad 4.09 | tok/s 7653
step    270 | loss 2.6160 | lr 3.00e-04 | grad 4.34 | tok/s 7549
step    280 | loss 2.7525 | lr 3.00e-04 | grad 2.81 | tok/s 7404
step    290 | loss 2.5700 | lr 3.00e-04 | grad 4.75 | tok/s 7779
step    300 | loss 1.7136 | lr 3.00e-04 | grad 2.23 | tok/s 7784
step    310 | loss 3.0154 | lr 3.00e-04 | grad 3.97 | tok/s 7656
step    320 | loss 2.6224 | lr 3.00e-04 | grad 7.16 | tok/s 7500
step    330 | loss 2.4499 | lr 3.00e-04 | grad 2.41 | tok/s 7240
step    340 | loss 2.7157 | lr 3.00e-04 | grad 2.30 | tok/s 7356
step    350 | loss 2.5519 | lr 3.00e-04 | grad 2.59 | tok/s 7544
step    360 | loss 2.7218 | lr 3.00e-04 | grad 4.22 | tok/s 7716
step    370 | loss 2.4202 | lr 3.00e-04 | grad 3.34 | tok/s 6984
step    380 | loss 2.3136 | lr 3.00e-04 | grad 2.45 | tok/s 7447
step    390 | loss 2.1622 | lr 3.00e-04 | grad 2.64 | tok/s 7782
step    400 | loss 2.1771 | lr 3.00e-04 | grad 3.19 | tok/s 7711
step    410 | loss 2.1047 | lr 3.00e-04 | grad 1.73 | tok/s 7537
step    420 | loss 2.2879 | lr 3.00e-04 | grad 4.12 | tok/s 7191
step    430 | loss 2.5896 | lr 3.00e-04 | grad 2.80 | tok/s 7652
step    440 | loss 2.6169 | lr 3.00e-04 | grad 3.00 | tok/s 7241
step    450 | loss 2.8937 | lr 3.00e-04 | grad 1.85 | tok/s 7490
step    460 | loss 2.2985 | lr 3.00e-04 | grad 4.09 | tok/s 7332
step    470 | loss 2.4209 | lr 3.00e-04 | grad 2.22 | tok/s 7558
step    480 | loss 2.8519 | lr 3.00e-04 | grad 4.28 | tok/s 7565
step    490 | loss 2.2961 | lr 3.00e-04 | grad 2.67 | tok/s 7142
step    500 | loss 2.2497 | lr 3.00e-04 | grad 3.70 | tok/s 7631
step    510 | loss 2.2418 | lr 3.00e-04 | grad 2.03 | tok/s 7740
step    520 | loss 2.2365 | lr 3.00e-04 | grad 2.34 | tok/s 7721
step    530 | loss 2.4358 | lr 3.00e-04 | grad 1.65 | tok/s 7415
step    540 | loss 2.1448 | lr 3.00e-04 | grad 2.89 | tok/s 7425
step    550 | loss 2.0038 | lr 3.00e-04 | grad 3.03 | tok/s 7268
step    560 | loss 2.1959 | lr 3.00e-04 | grad 2.30 | tok/s 7075
step    570 | loss 2.1563 | lr 3.00e-04 | grad 2.53 | tok/s 7271
step    580 | loss 2.0275 | lr 3.00e-04 | grad 2.33 | tok/s 7245
step    590 | loss 2.4153 | lr 3.00e-04 | grad 2.94 | tok/s 7434
step    600 | loss 2.2510 | lr 3.00e-04 | grad 1.93 | tok/s 7179
step    610 | loss 2.0965 | lr 3.00e-04 | grad 1.67 | tok/s 7545
step    620 | loss 1.9552 | lr 3.00e-04 | grad 2.25 | tok/s 7147
step    630 | loss 2.1231 | lr 3.00e-04 | grad 2.72 | tok/s 7206
step    640 | loss 2.3193 | lr 3.00e-04 | grad 1.95 | tok/s 7402
step    650 | loss 2.1202 | lr 3.00e-04 | grad 2.80 | tok/s 7441
step    660 | loss 2.1404 | lr 3.00e-04 | grad 1.53 | tok/s 7477
step    670 | loss 2.4963 | lr 3.00e-04 | grad 9.75 | tok/s 7523
step    680 | loss 2.1214 | lr 3.00e-04 | grad 2.38 | tok/s 7374
step    690 | loss 2.4761 | lr 3.00e-04 | grad 2.92 | tok/s 7627
step    700 | loss 2.2038 | lr 3.00e-04 | grad 2.81 | tok/s 7780
step    710 | loss 2.0522 | lr 3.00e-04 | grad 2.16 | tok/s 7260
step    720 | loss 1.8815 | lr 3.00e-04 | grad 2.86 | tok/s 7150
step    730 | loss 2.0076 | lr 3.00e-04 | grad 2.42 | tok/s 7764
step    740 | loss 2.0291 | lr 3.00e-04 | grad 2.27 | tok/s 7660
step    750 | loss 1.8494 | lr 3.00e-04 | grad 1.70 | tok/s 7781
step    760 | loss 1.7064 | lr 3.00e-04 | grad 2.12 | tok/s 7777
step    770 | loss 1.6707 | lr 3.00e-04 | grad 2.14 | tok/s 7781
step    780 | loss 1.6281 | lr 3.00e-04 | grad 1.69 | tok/s 7780
step    790 | loss 1.6775 | lr 3.00e-04 | grad 2.23 | tok/s 7536
step    800 | loss 2.4344 | lr 3.00e-04 | grad 3.55 | tok/s 7510
step    810 | loss 2.0800 | lr 3.00e-04 | grad 1.94 | tok/s 7467
step    820 | loss 2.1071 | lr 3.00e-04 | grad 3.39 | tok/s 7172
step    830 | loss 2.1901 | lr 3.00e-04 | grad 1.98 | tok/s 7700
step    840 | loss 2.0498 | lr 3.00e-04 | grad 1.67 | tok/s 7785
step    850 | loss 2.0038 | lr 3.00e-04 | grad 1.99 | tok/s 7736
step    860 | loss 2.0817 | lr 3.00e-04 | grad 3.47 | tok/s 7657
step    870 | loss 1.9555 | lr 3.00e-04 | grad 1.77 | tok/s 7379
step    880 | loss 2.1686 | lr 3.00e-04 | grad 2.83 | tok/s 7403
step    890 | loss 2.0853 | lr 3.00e-04 | grad 2.30 | tok/s 7516
step    900 | loss 1.9701 | lr 3.00e-04 | grad 1.82 | tok/s 7516
step    910 | loss 1.8504 | lr 3.00e-04 | grad 2.38 | tok/s 7358
step    920 | loss 2.0345 | lr 3.00e-04 | grad 2.81 | tok/s 7642
step    930 | loss 2.0079 | lr 3.00e-04 | grad 2.91 | tok/s 7300
step    940 | loss 1.9222 | lr 3.00e-04 | grad 1.80 | tok/s 7710
step    950 | loss 2.0581 | lr 3.00e-04 | grad 2.38 | tok/s 7740
step    960 | loss 1.8972 | lr 3.00e-04 | grad 2.91 | tok/s 7745
step    970 | loss 2.0943 | lr 3.00e-04 | grad 2.33 | tok/s 7288
step    980 | loss 2.0135 | lr 3.00e-04 | grad 1.58 | tok/s 7488
step    990 | loss 1.9154 | lr 3.00e-04 | grad 1.62 | tok/s 7617
step   1000 | loss 2.2851 | lr 3.00e-04 | grad 9.12 | tok/s 7308
  >>> saved checkpoint: checkpoint_step_001000_loss_2.2851.pt
step   1010 | loss 2.1668 | lr 3.00e-04 | grad 2.16 | tok/s 4641
step   1020 | loss 2.0014 | lr 3.00e-04 | grad 1.51 | tok/s 7124
step   1030 | loss 1.8620 | lr 3.00e-04 | grad 1.83 | tok/s 7414
step   1040 | loss 1.8593 | lr 3.00e-04 | grad 1.80 | tok/s 7663
step   1050 | loss 1.9757 | lr 3.00e-04 | grad 2.77 | tok/s 7085
step   1060 | loss 2.1502 | lr 3.00e-04 | grad 2.81 | tok/s 7668
step   1070 | loss 2.1743 | lr 3.00e-04 | grad 2.02 | tok/s 7621
step   1080 | loss 1.7749 | lr 3.00e-04 | grad 1.66 | tok/s 6921
step   1090 | loss 1.4733 | lr 3.00e-04 | grad 1.42 | tok/s 7615
step   1100 | loss 1.7845 | lr 3.00e-04 | grad 3.44 | tok/s 7395
step   1110 | loss 1.8558 | lr 3.00e-04 | grad 1.84 | tok/s 7787
step   1120 | loss 1.7493 | lr 3.00e-04 | grad 2.94 | tok/s 7781
step   1130 | loss 1.6765 | lr 3.00e-04 | grad 1.81 | tok/s 7785
step   1140 | loss 1.6554 | lr 3.00e-04 | grad 2.09 | tok/s 7790
step   1150 | loss 1.6643 | lr 3.00e-04 | grad 1.80 | tok/s 7783
step   1160 | loss 1.5628 | lr 3.00e-04 | grad 2.25 | tok/s 7783
step   1170 | loss 1.5893 | lr 3.00e-04 | grad 2.03 | tok/s 7786
step   1180 | loss 1.7408 | lr 3.00e-04 | grad 1.59 | tok/s 7784
step   1190 | loss 1.6045 | lr 3.00e-04 | grad 2.06 | tok/s 7787
step   1200 | loss 1.5894 | lr 3.00e-04 | grad 2.33 | tok/s 7782
step   1210 | loss 1.6139 | lr 3.00e-04 | grad 1.96 | tok/s 7781
step   1220 | loss 1.6185 | lr 3.00e-04 | grad 2.45 | tok/s 7783
step   1230 | loss 1.5932 | lr 3.00e-04 | grad 1.62 | tok/s 7783
step   1240 | loss 1.5385 | lr 3.00e-04 | grad 1.52 | tok/s 7782
step   1250 | loss 2.3712 | lr 3.00e-04 | grad 2.48 | tok/s 7362
step   1260 | loss 1.7434 | lr 3.00e-04 | grad 4.00 | tok/s 7273
step   1270 | loss 2.0046 | lr 3.00e-04 | grad 3.91 | tok/s 7269
step   1280 | loss 1.9783 | lr 3.00e-04 | grad 2.50 | tok/s 7488
step   1290 | loss 1.8080 | lr 3.00e-04 | grad 2.20 | tok/s 7443
step   1300 | loss 1.8815 | lr 3.00e-04 | grad 2.09 | tok/s 7491
step   1310 | loss 1.8336 | lr 3.00e-04 | grad 2.30 | tok/s 7630
step   1320 | loss 1.9497 | lr 3.00e-04 | grad 1.68 | tok/s 7650
step   1330 | loss 2.0129 | lr 3.00e-04 | grad 2.09 | tok/s 7662
step   1340 | loss 1.8699 | lr 3.00e-04 | grad 7.75 | tok/s 7300
step   1350 | loss 2.0579 | lr 3.00e-04 | grad 2.05 | tok/s 7054
step   1360 | loss 1.8945 | lr 3.00e-04 | grad 2.02 | tok/s 7499
step   1370 | loss 1.6858 | lr 3.00e-04 | grad 1.67 | tok/s 7412
step   1380 | loss 2.1042 | lr 3.00e-04 | grad 1.50 | tok/s 7120
step   1390 | loss 1.8427 | lr 3.00e-04 | grad 1.73 | tok/s 7559
step   1400 | loss 1.7850 | lr 3.00e-04 | grad 1.76 | tok/s 7286
step   1410 | loss 1.8100 | lr 3.00e-04 | grad 2.55 | tok/s 7313
step   1420 | loss 2.1320 | lr 3.00e-04 | grad 4.66 | tok/s 7326
step   1430 | loss 1.7574 | lr 3.00e-04 | grad 1.69 | tok/s 7455
step   1440 | loss 1.5286 | lr 3.00e-04 | grad 2.03 | tok/s 7706
step   1450 | loss 1.4913 | lr 3.00e-04 | grad 3.55 | tok/s 7757
step   1460 | loss 2.0239 | lr 3.00e-04 | grad 2.06 | tok/s 7312
step   1470 | loss 1.9212 | lr 3.00e-04 | grad 1.88 | tok/s 7584
step   1480 | loss 2.4034 | lr 3.00e-04 | grad 3.59 | tok/s 7633
step   1490 | loss 2.1188 | lr 3.00e-04 | grad 1.80 | tok/s 7749
step   1500 | loss 1.7858 | lr 3.00e-04 | grad 1.80 | tok/s 7781
step   1510 | loss 1.9036 | lr 3.00e-04 | grad 1.97 | tok/s 7675
step   1520 | loss 1.7520 | lr 3.00e-04 | grad 3.89 | tok/s 7523
step   1530 | loss 1.7110 | lr 3.00e-04 | grad 1.74 | tok/s 7702
step   1540 | loss 1.9446 | lr 3.00e-04 | grad 2.09 | tok/s 7238
step   1550 | loss 1.6669 | lr 3.00e-04 | grad 2.12 | tok/s 7722
step   1560 | loss 1.8613 | lr 3.00e-04 | grad 2.92 | tok/s 7321
step   1570 | loss 1.7030 | lr 3.00e-04 | grad 2.03 | tok/s 7776
step   1580 | loss 2.2293 | lr 3.00e-04 | grad 2.78 | tok/s 7598
step   1590 | loss 2.0736 | lr 3.00e-04 | grad 1.84 | tok/s 7300
step   1600 | loss 1.3369 | lr 3.00e-04 | grad 1.25 | tok/s 7786
step   1610 | loss 1.2817 | lr 3.00e-04 | grad 2.17 | tok/s 7524
step   1620 | loss 1.7764 | lr 3.00e-04 | grad 2.59 | tok/s 7065
step   1630 | loss 1.8053 | lr 3.00e-04 | grad 2.44 | tok/s 7562
step   1640 | loss 1.6510 | lr 3.00e-04 | grad 1.91 | tok/s 7388
step   1650 | loss 1.8264 | lr 3.00e-04 | grad 2.00 | tok/s 7077
step   1660 | loss 1.7867 | lr 3.00e-04 | grad 1.88 | tok/s 7557
step   1670 | loss 1.7839 | lr 3.00e-04 | grad 3.19 | tok/s 7540
step   1680 | loss 2.1001 | lr 3.00e-04 | grad 1.90 | tok/s 7224
step   1690 | loss 1.8430 | lr 3.00e-04 | grad 4.19 | tok/s 7367
step   1700 | loss 1.8413 | lr 3.00e-04 | grad 2.58 | tok/s 7529
step   1710 | loss 1.8171 | lr 3.00e-04 | grad 1.69 | tok/s 7390
step   1720 | loss 1.9126 | lr 3.00e-04 | grad 2.34 | tok/s 7704
step   1730 | loss 1.7818 | lr 3.00e-04 | grad 2.03 | tok/s 7784
step   1740 | loss 1.7932 | lr 3.00e-04 | grad 1.93 | tok/s 7582
step   1750 | loss 1.9062 | lr 3.00e-04 | grad 2.23 | tok/s 7449
step   1760 | loss 1.8079 | lr 3.00e-04 | grad 1.63 | tok/s 7484
step   1770 | loss 1.7104 | lr 3.00e-04 | grad 1.92 | tok/s 7352
step   1780 | loss 1.7619 | lr 3.00e-04 | grad 2.27 | tok/s 7644
step   1790 | loss 1.7009 | lr 3.00e-04 | grad 1.59 | tok/s 7447
step   1800 | loss 1.8918 | lr 3.00e-04 | grad 2.16 | tok/s 7506
step   1810 | loss 1.7220 | lr 3.00e-04 | grad 2.28 | tok/s 7235
step   1820 | loss 1.8317 | lr 3.00e-04 | grad 4.28 | tok/s 7337
step   1830 | loss 1.7007 | lr 3.00e-04 | grad 2.14 | tok/s 7638
step   1840 | loss 1.8297 | lr 3.00e-04 | grad 2.56 | tok/s 7312
step   1850 | loss 1.6781 | lr 3.00e-04 | grad 2.39 | tok/s 7664
step   1860 | loss 1.5944 | lr 3.00e-04 | grad 2.34 | tok/s 7408
step   1870 | loss 1.7318 | lr 3.00e-04 | grad 3.22 | tok/s 7435
step   1880 | loss 1.5605 | lr 3.00e-04 | grad 1.64 | tok/s 7279
step   1890 | loss 1.8356 | lr 3.00e-04 | grad 1.77 | tok/s 6920
step   1900 | loss 1.6353 | lr 3.00e-04 | grad 2.25 | tok/s 7491
step   1910 | loss 1.7191 | lr 3.00e-04 | grad 2.55 | tok/s 7096
step   1920 | loss 1.6906 | lr 3.00e-04 | grad 2.25 | tok/s 7788
step   1930 | loss 1.6995 | lr 3.00e-04 | grad 3.20 | tok/s 7297
step   1940 | loss 1.6767 | lr 3.00e-04 | grad 2.14 | tok/s 7591
step   1950 | loss 2.3845 | lr 3.00e-04 | grad 2.38 | tok/s 7704
step   1960 | loss 1.9962 | lr 3.00e-04 | grad 2.69 | tok/s 7783
step   1970 | loss 1.9140 | lr 3.00e-04 | grad 2.08 | tok/s 7589
step   1980 | loss 1.8575 | lr 3.00e-04 | grad 1.88 | tok/s 7254
step   1990 | loss 1.9893 | lr 3.00e-04 | grad 9.62 | tok/s 7392
step   2000 | loss 1.7416 | lr 3.00e-04 | grad 1.98 | tok/s 7494
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7416.pt
step   2010 | loss 1.2602 | lr 3.00e-04 | grad 2.12 | tok/s 4998
step   2020 | loss 1.5635 | lr 3.00e-04 | grad 1.76 | tok/s 7424
step   2030 | loss 1.4025 | lr 3.00e-04 | grad 0.59 | tok/s 7808
step   2040 | loss 1.6231 | lr 3.00e-04 | grad 1.89 | tok/s 7785
step   2050 | loss 1.6097 | lr 3.00e-04 | grad 2.06 | tok/s 7628
step   2060 | loss 1.8469 | lr 3.00e-04 | grad 1.70 | tok/s 7191
step   2070 | loss 1.8996 | lr 3.00e-04 | grad 2.52 | tok/s 7461
step   2080 | loss 2.4515 | lr 3.00e-04 | grad 3.97 | tok/s 7712
step   2090 | loss 2.0615 | lr 3.00e-04 | grad 2.69 | tok/s 7741
step   2100 | loss 1.7299 | lr 3.00e-04 | grad 2.66 | tok/s 7544
step   2110 | loss 1.9089 | lr 3.00e-04 | grad 6.66 | tok/s 7404
step   2120 | loss 1.1658 | lr 3.00e-04 | grad 2.30 | tok/s 7640
step   2130 | loss 1.3193 | lr 3.00e-04 | grad 3.73 | tok/s 7644
step   2140 | loss 1.8235 | lr 3.00e-04 | grad 1.98 | tok/s 7410
step   2150 | loss 1.5137 | lr 3.00e-04 | grad 1.93 | tok/s 7784
step   2160 | loss 1.4230 | lr 3.00e-04 | grad 1.89 | tok/s 7783
step   2170 | loss 1.4674 | lr 3.00e-04 | grad 1.99 | tok/s 7791
step   2180 | loss 1.4181 | lr 3.00e-04 | grad 1.73 | tok/s 7791
step   2190 | loss 1.4245 | lr 3.00e-04 | grad 2.03 | tok/s 7786
step   2200 | loss 1.4276 | lr 3.00e-04 | grad 1.99 | tok/s 7783
step   2210 | loss 1.3525 | lr 3.00e-04 | grad 1.89 | tok/s 7782
step   2220 | loss 1.3555 | lr 3.00e-04 | grad 2.38 | tok/s 7781
step   2230 | loss 1.5824 | lr 3.00e-04 | grad 1.80 | tok/s 7651
step   2240 | loss 1.5939 | lr 3.00e-04 | grad 2.05 | tok/s 7768
step   2250 | loss 1.9645 | lr 3.00e-04 | grad 2.22 | tok/s 7510
step   2260 | loss 1.9218 | lr 3.00e-04 | grad 1.62 | tok/s 7586
step   2270 | loss 2.2254 | lr 3.00e-04 | grad 3.78 | tok/s 7707
step   2280 | loss 1.7919 | lr 3.00e-04 | grad 1.98 | tok/s 7698
step   2290 | loss 1.6271 | lr 3.00e-04 | grad 2.25 | tok/s 7503
step   2300 | loss 2.3633 | lr 3.00e-04 | grad 2.75 | tok/s 7672
step   2310 | loss 1.7925 | lr 3.00e-04 | grad 1.45 | tok/s 7285
step   2320 | loss 1.9643 | lr 3.00e-04 | grad 4.47 | tok/s 7308
step   2330 | loss 2.0490 | lr 3.00e-04 | grad 2.92 | tok/s 7442
step   2340 | loss 1.8222 | lr 3.00e-04 | grad 6.09 | tok/s 7239
step   2350 | loss 1.6189 | lr 3.00e-04 | grad 3.39 | tok/s 7607
step   2360 | loss 1.6290 | lr 3.00e-04 | grad 2.27 | tok/s 7701
step   2370 | loss 1.7656 | lr 3.00e-04 | grad 3.52 | tok/s 7620
step   2380 | loss 1.9028 | lr 3.00e-04 | grad 2.00 | tok/s 7787
step   2390 | loss 1.5313 | lr 3.00e-04 | grad 2.19 | tok/s 7770
step   2400 | loss 1.3815 | lr 3.00e-04 | grad 1.68 | tok/s 7788
step   2410 | loss 1.3083 | lr 3.00e-04 | grad 1.98 | tok/s 7525
step   2420 | loss 1.7371 | lr 3.00e-04 | grad 3.56 | tok/s 7292
step   2430 | loss 1.6830 | lr 3.00e-04 | grad 1.78 | tok/s 7418
step   2440 | loss 1.5003 | lr 3.00e-04 | grad 3.20 | tok/s 7616
step   2450 | loss 1.6976 | lr 3.00e-04 | grad 2.25 | tok/s 7424
step   2460 | loss 1.6000 | lr 3.00e-04 | grad 2.22 | tok/s 7710
step   2470 | loss 1.3989 | lr 3.00e-04 | grad 1.93 | tok/s 7676
step   2480 | loss 1.4713 | lr 3.00e-04 | grad 1.35 | tok/s 7781
step   2490 | loss 1.5505 | lr 3.00e-04 | grad 1.62 | tok/s 7370
step   2500 | loss 1.8324 | lr 3.00e-04 | grad 1.72 | tok/s 7616
step   2510 | loss 1.5593 | lr 3.00e-04 | grad 1.88 | tok/s 7787
step   2520 | loss 1.7541 | lr 3.00e-04 | grad 4.41 | tok/s 7763
step   2530 | loss 1.5971 | lr 3.00e-04 | grad 2.12 | tok/s 7494
step   2540 | loss 1.6466 | lr 3.00e-04 | grad 2.17 | tok/s 7442
step   2550 | loss 1.4662 | lr 3.00e-04 | grad 2.39 | tok/s 7739
step   2560 | loss 1.6986 | lr 3.00e-04 | grad 4.59 | tok/s 7260
step   2570 | loss 1.6901 | lr 3.00e-04 | grad 1.76 | tok/s 7563
step   2580 | loss 1.5995 | lr 3.00e-04 | grad 1.80 | tok/s 7088
step   2590 | loss 1.6042 | lr 3.00e-04 | grad 1.95 | tok/s 7492
step   2600 | loss 1.8758 | lr 3.00e-04 | grad 2.91 | tok/s 7188
step   2610 | loss 1.7972 | lr 3.00e-04 | grad 2.50 | tok/s 7738
step   2620 | loss 1.8033 | lr 3.00e-04 | grad 1.88 | tok/s 7464
step   2630 | loss 1.6588 | lr 3.00e-04 | grad 1.94 | tok/s 7707
step   2640 | loss 1.7178 | lr 3.00e-04 | grad 2.06 | tok/s 7490
step   2650 | loss 1.9299 | lr 3.00e-04 | grad 3.41 | tok/s 7788
step   2660 | loss 1.5822 | lr 3.00e-04 | grad 2.14 | tok/s 7525
step   2670 | loss 1.6634 | lr 3.00e-04 | grad 2.42 | tok/s 7223
step   2680 | loss 1.9023 | lr 3.00e-04 | grad 4.66 | tok/s 7380
step   2690 | loss 1.5656 | lr 3.00e-04 | grad 1.94 | tok/s 7722
step   2700 | loss 1.7100 | lr 3.00e-04 | grad 2.89 | tok/s 7506
step   2710 | loss 1.9320 | lr 3.00e-04 | grad 3.70 | tok/s 7396
step   2720 | loss 1.5694 | lr 3.00e-04 | grad 2.20 | tok/s 7078
step   2730 | loss 1.5579 | lr 3.00e-04 | grad 1.74 | tok/s 7623
step   2740 | loss 1.8436 | lr 3.00e-04 | grad 3.95 | tok/s 7534
step   2750 | loss 1.9367 | lr 3.00e-04 | grad 2.08 | tok/s 7719
step   2760 | loss 1.5413 | lr 3.00e-04 | grad 2.11 | tok/s 7159
step   2770 | loss 1.7470 | lr 3.00e-04 | grad 2.19 | tok/s 7399
step   2780 | loss 1.4065 | lr 3.00e-04 | grad 1.42 | tok/s 7785
step   2790 | loss 2.0688 | lr 3.00e-04 | grad 3.92 | tok/s 7244
step   2800 | loss 1.6334 | lr 3.00e-04 | grad 1.60 | tok/s 7460
step   2810 | loss 1.4809 | lr 3.00e-04 | grad 2.02 | tok/s 7436
step   2820 | loss 1.6114 | lr 3.00e-04 | grad 1.33 | tok/s 7166
step   2830 | loss 1.6428 | lr 3.00e-04 | grad 2.95 | tok/s 7648
step   2840 | loss 1.2595 | lr 3.00e-04 | grad 2.92 | tok/s 7794
step   2850 | loss 2.0430 | lr 3.00e-04 | grad 2.08 | tok/s 7530
step   2860 | loss 1.9763 | lr 3.00e-04 | grad 1.58 | tok/s 7499
step   2870 | loss 1.5722 | lr 3.00e-04 | grad 1.64 | tok/s 7334
step   2880 | loss 1.7687 | lr 3.00e-04 | grad 2.47 | tok/s 7573
step   2890 | loss 1.6231 | lr 3.00e-04 | grad 2.94 | tok/s 7784
step   2900 | loss 1.6729 | lr 3.00e-04 | grad 2.44 | tok/s 7479
step   2910 | loss 1.7379 | lr 3.00e-04 | grad 1.41 | tok/s 7484
step   2920 | loss 1.6809 | lr 3.00e-04 | grad 2.30 | tok/s 7259
step   2930 | loss 1.8859 | lr 3.00e-04 | grad 1.89 | tok/s 7597
step   2940 | loss 1.4775 | lr 3.00e-04 | grad 2.08 | tok/s 6985
step   2950 | loss 1.5850 | lr 3.00e-04 | grad 2.09 | tok/s 7516
step   2960 | loss 1.5388 | lr 3.00e-04 | grad 2.67 | tok/s 7584
step   2970 | loss 1.5224 | lr 3.00e-04 | grad 2.06 | tok/s 7641
step   2980 | loss 1.9421 | lr 3.00e-04 | grad 1.80 | tok/s 7394
step   2990 | loss 2.3907 | lr 3.00e-04 | grad 2.52 | tok/s 7584
step   3000 | loss 1.6259 | lr 3.00e-04 | grad 2.95 | tok/s 7607
  >>> saved checkpoint: checkpoint_step_003000_loss_1.6259.pt
step   3010 | loss 1.3544 | lr 3.00e-04 | grad 2.81 | tok/s 4932
step   3020 | loss 1.5438 | lr 3.00e-04 | grad 2.20 | tok/s 7318
step   3030 | loss 1.6629 | lr 3.00e-04 | grad 2.22 | tok/s 7385
step   3040 | loss 1.6913 | lr 3.00e-04 | grad 2.16 | tok/s 7567
step   3050 | loss 1.6090 | lr 3.00e-04 | grad 1.86 | tok/s 7490
step   3060 | loss 1.5459 | lr 3.00e-04 | grad 2.23 | tok/s 7716
step   3070 | loss 1.8524 | lr 3.00e-04 | grad 1.91 | tok/s 7722
step   3080 | loss 1.5563 | lr 3.00e-04 | grad 2.09 | tok/s 7553
step   3090 | loss 1.6093 | lr 3.00e-04 | grad 1.34 | tok/s 7616
step   3100 | loss 1.7904 | lr 3.00e-04 | grad 2.33 | tok/s 7463
step   3110 | loss 1.4536 | lr 3.00e-04 | grad 1.38 | tok/s 7707
step   3120 | loss 1.1372 | lr 3.00e-04 | grad 1.95 | tok/s 7786
step   3130 | loss 1.6732 | lr 3.00e-04 | grad 2.91 | tok/s 7349
step   3140 | loss 1.3910 | lr 3.00e-04 | grad 1.61 | tok/s 7790
step   3150 | loss 1.3571 | lr 3.00e-04 | grad 1.91 | tok/s 7792
step   3160 | loss 1.5639 | lr 3.00e-04 | grad 3.28 | tok/s 7345
step   3170 | loss 1.6986 | lr 3.00e-04 | grad 1.63 | tok/s 7311
step   3180 | loss 1.6178 | lr 3.00e-04 | grad 1.73 | tok/s 7419
step   3190 | loss 1.3484 | lr 3.00e-04 | grad 4.97 | tok/s 7647
step   3200 | loss 1.4980 | lr 3.00e-04 | grad 3.39 | tok/s 7725
step   3210 | loss 1.6409 | lr 3.00e-04 | grad 1.48 | tok/s 7565
step   3220 | loss 2.5569 | lr 3.00e-04 | grad 4.00 | tok/s 7562
step   3230 | loss 2.1956 | lr 3.00e-04 | grad 2.47 | tok/s 7785
step   3240 | loss 1.9661 | lr 3.00e-04 | grad 2.86 | tok/s 7781
step   3250 | loss 1.8508 | lr 3.00e-04 | grad 3.17 | tok/s 7789
step   3260 | loss 1.7808 | lr 3.00e-04 | grad 3.30 | tok/s 7789
step   3270 | loss 1.7101 | lr 3.00e-04 | grad 2.48 | tok/s 7787
step   3280 | loss 1.6618 | lr 3.00e-04 | grad 2.80 | tok/s 7789
step   3290 | loss 1.6090 | lr 3.00e-04 | grad 2.44 | tok/s 7785
step   3300 | loss 1.5761 | lr 3.00e-04 | grad 2.84 | tok/s 7782
step   3310 | loss 1.5551 | lr 3.00e-04 | grad 2.38 | tok/s 7785
step   3320 | loss 1.5472 | lr 3.00e-04 | grad 2.08 | tok/s 7785
step   3330 | loss 1.5493 | lr 3.00e-04 | grad 2.58 | tok/s 7782
step   3340 | loss 1.9368 | lr 3.00e-04 | grad 2.27 | tok/s 7299
step   3350 | loss 1.6381 | lr 3.00e-04 | grad 1.96 | tok/s 7537
step   3360 | loss 1.5830 | lr 3.00e-04 | grad 2.14 | tok/s 7403
step   3370 | loss 1.5958 | lr 3.00e-04 | grad 2.48 | tok/s 7198

Training complete! Final step: 3370
