Using device: cuda
Output directory: benchmark_results/cmaes_4d/e1_480M_converge0.01_20260202_122123/eval_46/level1_100m_20260202_145334
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 333,466,496 parameters
Using schedule-free AdamW (lr=0.0005874400826456754)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 4.6735 | lr 5.87e-04 | grad 10.94 | tok/s 18196
step     20 | loss 4.2709 | lr 5.87e-04 | grad 6.25 | tok/s 38687
step     30 | loss 3.6822 | lr 5.87e-04 | grad 3.89 | tok/s 39030
step     40 | loss 2.6670 | lr 5.87e-04 | grad 2.72 | tok/s 38929
step     50 | loss 2.3788 | lr 5.87e-04 | grad 2.27 | tok/s 38828
step     60 | loss 3.0267 | lr 5.87e-04 | grad 2.81 | tok/s 37226
step     70 | loss 2.7574 | lr 5.87e-04 | grad 2.77 | tok/s 37823
step     80 | loss 2.6996 | lr 5.87e-04 | grad 1.77 | tok/s 37486
step     90 | loss 2.5931 | lr 5.87e-04 | grad 1.75 | tok/s 36540
step    100 | loss 2.2593 | lr 5.87e-04 | grad 2.14 | tok/s 37772
step    110 | loss 2.4942 | lr 5.87e-04 | grad 1.34 | tok/s 36475
step    120 | loss 2.4860 | lr 5.87e-04 | grad 1.66 | tok/s 36720
step    130 | loss 2.3045 | lr 5.87e-04 | grad 1.86 | tok/s 37605
step    140 | loss 2.1161 | lr 5.87e-04 | grad 1.63 | tok/s 35770
step    150 | loss 2.1748 | lr 5.87e-04 | grad 0.87 | tok/s 36106
step    160 | loss 2.1634 | lr 5.87e-04 | grad 2.30 | tok/s 36226
step    170 | loss 2.2843 | lr 5.87e-04 | grad 1.91 | tok/s 37070
step    180 | loss 2.0073 | lr 5.87e-04 | grad 2.03 | tok/s 36914
step    190 | loss 1.7738 | lr 5.87e-04 | grad 1.91 | tok/s 38135
step    200 | loss 1.9522 | lr 5.87e-04 | grad 0.93 | tok/s 37047
step    210 | loss 2.0641 | lr 5.87e-04 | grad 1.23 | tok/s 37634
step    220 | loss 1.9976 | lr 5.87e-04 | grad 1.07 | tok/s 36888
step    230 | loss 1.8853 | lr 5.87e-04 | grad 0.96 | tok/s 36799
step    240 | loss 1.9373 | lr 5.87e-04 | grad 1.35 | tok/s 37602
step    250 | loss 2.0303 | lr 5.87e-04 | grad 1.21 | tok/s 36728
step    260 | loss 1.8390 | lr 5.87e-04 | grad 1.20 | tok/s 35890
step    270 | loss 1.8644 | lr 5.87e-04 | grad 2.11 | tok/s 36733
step    280 | loss 1.6610 | lr 5.87e-04 | grad 1.31 | tok/s 37911
step    290 | loss 1.5259 | lr 5.87e-04 | grad 1.02 | tok/s 38296
step    300 | loss 1.5407 | lr 5.87e-04 | grad 0.86 | tok/s 38280
step    310 | loss 1.6533 | lr 5.87e-04 | grad 1.20 | tok/s 37970
step    320 | loss 1.8362 | lr 5.87e-04 | grad 0.81 | tok/s 36356
step    330 | loss 1.8367 | lr 5.87e-04 | grad 1.56 | tok/s 37417
step    340 | loss 1.7959 | lr 5.87e-04 | grad 1.27 | tok/s 36202
step    350 | loss 1.7695 | lr 5.87e-04 | grad 1.15 | tok/s 35963
step    360 | loss 1.6658 | lr 5.87e-04 | grad 1.22 | tok/s 37202
step    370 | loss 2.0395 | lr 5.87e-04 | grad 1.08 | tok/s 37252
step    380 | loss 1.6970 | lr 5.87e-04 | grad 0.82 | tok/s 37825
step    390 | loss 1.6964 | lr 5.87e-04 | grad 0.96 | tok/s 36898
step    400 | loss 1.6897 | lr 5.87e-04 | grad 0.84 | tok/s 37334
step    410 | loss 1.6854 | lr 5.87e-04 | grad 0.95 | tok/s 36080
step    420 | loss 1.7615 | lr 5.87e-04 | grad 0.87 | tok/s 36367
step    430 | loss 1.8108 | lr 5.87e-04 | grad 1.73 | tok/s 37454
step    440 | loss 1.7110 | lr 5.87e-04 | grad 0.71 | tok/s 36814
step    450 | loss 1.6682 | lr 5.87e-04 | grad 0.77 | tok/s 36761
step    460 | loss 1.7072 | lr 5.87e-04 | grad 1.13 | tok/s 36882
step    470 | loss 1.5687 | lr 5.87e-04 | grad 0.90 | tok/s 35789
step    480 | loss 1.5651 | lr 5.87e-04 | grad 0.82 | tok/s 36592
step    490 | loss 2.0035 | lr 5.87e-04 | grad 1.09 | tok/s 37681
step    500 | loss 1.6369 | lr 5.87e-04 | grad 2.77 | tok/s 36886
step    510 | loss 1.4483 | lr 5.87e-04 | grad 0.68 | tok/s 37998
step    520 | loss 2.0562 | lr 5.87e-04 | grad 2.00 | tok/s 36859
step    530 | loss 1.5004 | lr 5.87e-04 | grad 0.81 | tok/s 37456
step    540 | loss 1.5099 | lr 5.87e-04 | grad 1.39 | tok/s 37630
step    550 | loss 1.3498 | lr 5.87e-04 | grad 1.10 | tok/s 38243
step    560 | loss 1.5097 | lr 5.87e-04 | grad 2.56 | tok/s 37764
step    570 | loss 1.9128 | lr 5.87e-04 | grad 0.96 | tok/s 37802
step    580 | loss 2.0320 | lr 5.87e-04 | grad 2.05 | tok/s 36509
step    590 | loss 1.5585 | lr 5.87e-04 | grad 1.09 | tok/s 36886
step    600 | loss 1.5707 | lr 5.87e-04 | grad 1.00 | tok/s 38304
step    610 | loss 1.5440 | lr 5.87e-04 | grad 0.72 | tok/s 36355
step    620 | loss 1.4713 | lr 5.87e-04 | grad 0.95 | tok/s 37742
step    630 | loss 1.6529 | lr 5.87e-04 | grad 1.12 | tok/s 37616
step    640 | loss 1.5525 | lr 5.87e-04 | grad 1.28 | tok/s 36776
step    650 | loss 1.6886 | lr 5.87e-04 | grad 3.05 | tok/s 36347
step    660 | loss 1.6599 | lr 5.87e-04 | grad 1.38 | tok/s 37446
step    670 | loss 1.6742 | lr 5.87e-04 | grad 0.98 | tok/s 36700
step    680 | loss 1.6071 | lr 5.87e-04 | grad 1.09 | tok/s 36410
step    690 | loss 1.7089 | lr 5.87e-04 | grad 1.16 | tok/s 36770
step    700 | loss 1.6086 | lr 5.87e-04 | grad 0.87 | tok/s 37098
step    710 | loss 1.5582 | lr 5.87e-04 | grad 3.58 | tok/s 36747
step    720 | loss 1.7146 | lr 5.87e-04 | grad 0.82 | tok/s 36992
step    730 | loss 1.7106 | lr 5.87e-04 | grad 2.09 | tok/s 36912
step    740 | loss 1.5060 | lr 5.87e-04 | grad 0.86 | tok/s 36532
step    750 | loss 1.7657 | lr 5.87e-04 | grad 0.73 | tok/s 36915
step    760 | loss 1.5284 | lr 5.87e-04 | grad 0.81 | tok/s 36896
step    770 | loss 1.6067 | lr 5.87e-04 | grad 1.05 | tok/s 37463
step    780 | loss 1.4448 | lr 5.87e-04 | grad 0.79 | tok/s 37569
step    790 | loss 1.5014 | lr 5.87e-04 | grad 2.19 | tok/s 37121
step    800 | loss 1.4575 | lr 5.87e-04 | grad 0.92 | tok/s 36883
step    810 | loss 2.0927 | lr 5.87e-04 | grad 1.73 | tok/s 37976
step    820 | loss 1.6804 | lr 5.87e-04 | grad 1.42 | tok/s 38219
step    830 | loss 1.5158 | lr 5.87e-04 | grad 1.02 | tok/s 38289
step    840 | loss 1.6118 | lr 5.87e-04 | grad 0.57 | tok/s 36503
step    850 | loss 1.4927 | lr 5.87e-04 | grad 0.61 | tok/s 36912
step    860 | loss 1.5073 | lr 5.87e-04 | grad 0.91 | tok/s 36854
step    870 | loss 1.5773 | lr 5.87e-04 | grad 0.93 | tok/s 37519
step    880 | loss 1.4876 | lr 5.87e-04 | grad 1.52 | tok/s 36464
step    890 | loss 1.7903 | lr 5.87e-04 | grad 0.91 | tok/s 36299
step    900 | loss 1.4658 | lr 5.87e-04 | grad 0.97 | tok/s 36333
step    910 | loss 1.5603 | lr 5.87e-04 | grad 0.86 | tok/s 36639
step    920 | loss 1.5054 | lr 5.87e-04 | grad 0.95 | tok/s 36422
step    930 | loss 1.5783 | lr 5.87e-04 | grad 0.97 | tok/s 36456
step    940 | loss 1.5750 | lr 5.87e-04 | grad 0.74 | tok/s 37326
step    950 | loss 1.3293 | lr 5.87e-04 | grad 1.02 | tok/s 38252
step    960 | loss 1.2710 | lr 5.87e-04 | grad 0.86 | tok/s 38333
step    970 | loss 1.5080 | lr 5.87e-04 | grad 0.88 | tok/s 36944
step    980 | loss 1.6218 | lr 5.87e-04 | grad 1.11 | tok/s 36318
step    990 | loss 1.5835 | lr 5.87e-04 | grad 1.10 | tok/s 36820
step   1000 | loss 1.4915 | lr 5.87e-04 | grad 0.71 | tok/s 37741
  >>> saved checkpoint: checkpoint_step_001000_loss_1.4915.pt
step   1010 | loss 1.4648 | lr 5.87e-04 | grad 0.73 | tok/s 22936
step   1020 | loss 1.7109 | lr 5.87e-04 | grad 0.62 | tok/s 36917
step   1030 | loss 1.6229 | lr 5.87e-04 | grad 0.89 | tok/s 36909
step   1040 | loss 1.3003 | lr 5.87e-04 | grad 0.62 | tok/s 36765
step   1050 | loss 1.7594 | lr 5.87e-04 | grad 0.79 | tok/s 37659
step   1060 | loss 1.9413 | lr 5.87e-04 | grad 0.96 | tok/s 36880
step   1070 | loss 1.5915 | lr 5.87e-04 | grad 0.89 | tok/s 36417
step   1080 | loss 1.7074 | lr 5.87e-04 | grad 0.55 | tok/s 37440
step   1090 | loss 1.5288 | lr 5.87e-04 | grad 1.34 | tok/s 38118
step   1100 | loss 1.4612 | lr 5.87e-04 | grad 1.11 | tok/s 37479
step   1110 | loss 1.5801 | lr 5.87e-04 | grad 0.54 | tok/s 36321
step   1120 | loss 1.5737 | lr 5.87e-04 | grad 0.88 | tok/s 37060
step   1130 | loss 1.6057 | lr 5.87e-04 | grad 1.77 | tok/s 36903
step   1140 | loss 1.5752 | lr 5.87e-04 | grad 2.08 | tok/s 36452
step   1150 | loss 1.6432 | lr 5.87e-04 | grad 0.97 | tok/s 36066
step   1160 | loss 1.4282 | lr 5.87e-04 | grad 1.02 | tok/s 38038
step   1170 | loss 1.3545 | lr 5.87e-04 | grad 0.93 | tok/s 38386
step   1180 | loss 1.2823 | lr 5.87e-04 | grad 0.91 | tok/s 38365
step   1190 | loss 1.2657 | lr 5.87e-04 | grad 0.93 | tok/s 38376
step   1200 | loss 1.2308 | lr 5.87e-04 | grad 0.69 | tok/s 38375
step   1210 | loss 1.3746 | lr 5.87e-04 | grad 0.36 | tok/s 37848
step   1220 | loss 1.4562 | lr 5.87e-04 | grad 0.59 | tok/s 36058
step   1230 | loss 1.5396 | lr 5.87e-04 | grad 0.73 | tok/s 37403
step   1240 | loss 1.5115 | lr 5.87e-04 | grad 1.23 | tok/s 37088
step   1250 | loss 1.7279 | lr 5.87e-04 | grad 0.66 | tok/s 36911
step   1260 | loss 1.5460 | lr 5.87e-04 | grad 1.14 | tok/s 36829
step   1270 | loss 1.5828 | lr 5.87e-04 | grad 0.81 | tok/s 36350
step   1280 | loss 1.5365 | lr 5.87e-04 | grad 0.69 | tok/s 36599
step   1290 | loss 1.5800 | lr 5.87e-04 | grad 0.62 | tok/s 36325
step   1300 | loss 1.5191 | lr 5.87e-04 | grad 0.76 | tok/s 36652
step   1310 | loss 1.5589 | lr 5.87e-04 | grad 0.88 | tok/s 37207
step   1320 | loss 1.3932 | lr 5.87e-04 | grad 0.68 | tok/s 36625
step   1330 | loss 1.3842 | lr 5.87e-04 | grad 0.59 | tok/s 37566
step   1340 | loss 1.4484 | lr 5.87e-04 | grad 0.55 | tok/s 36745
step   1350 | loss 1.4600 | lr 5.87e-04 | grad 1.08 | tok/s 36572
step   1360 | loss 1.6402 | lr 5.87e-04 | grad 0.91 | tok/s 36541
step   1370 | loss 1.4790 | lr 5.87e-04 | grad 0.62 | tok/s 36529
step   1380 | loss 1.4380 | lr 5.87e-04 | grad 0.70 | tok/s 37583
step   1390 | loss 1.4845 | lr 5.87e-04 | grad 1.04 | tok/s 37581
step   1400 | loss 1.5525 | lr 5.87e-04 | grad 1.84 | tok/s 36095
step   1410 | loss 1.4606 | lr 5.87e-04 | grad 0.60 | tok/s 35484
step   1420 | loss 1.3212 | lr 5.87e-04 | grad 0.72 | tok/s 36866
step   1430 | loss 1.3025 | lr 5.87e-04 | grad 0.71 | tok/s 37729
step   1440 | loss 1.5233 | lr 5.87e-04 | grad 1.20 | tok/s 36022
step   1450 | loss 1.5457 | lr 5.87e-04 | grad 0.87 | tok/s 36782
step   1460 | loss 1.4150 | lr 5.87e-04 | grad 1.84 | tok/s 37083
step   1470 | loss 1.4983 | lr 5.87e-04 | grad 1.07 | tok/s 36789
step   1480 | loss 1.7316 | lr 5.87e-04 | grad 1.44 | tok/s 36290
step   1490 | loss 1.4649 | lr 5.87e-04 | grad 0.94 | tok/s 37510
step   1500 | loss 1.5249 | lr 5.87e-04 | grad 0.84 | tok/s 37241
step   1510 | loss 1.4676 | lr 5.87e-04 | grad 0.67 | tok/s 36962
step   1520 | loss 1.4212 | lr 5.87e-04 | grad 0.89 | tok/s 36480
step   1530 | loss 1.3938 | lr 5.87e-04 | grad 2.34 | tok/s 37871
step   1540 | loss 1.9280 | lr 5.87e-04 | grad 1.20 | tok/s 36809
step   1550 | loss 1.4556 | lr 5.87e-04 | grad 0.72 | tok/s 36399
step   1560 | loss 1.5467 | lr 5.87e-04 | grad 0.87 | tok/s 37303
step   1570 | loss 1.3764 | lr 5.87e-04 | grad 0.95 | tok/s 36499
step   1580 | loss 1.5227 | lr 5.87e-04 | grad 0.55 | tok/s 36285
step   1590 | loss 1.3317 | lr 5.87e-04 | grad 0.60 | tok/s 37949
step   1600 | loss 1.5025 | lr 5.87e-04 | grad 0.70 | tok/s 37107
step   1610 | loss 1.4507 | lr 5.87e-04 | grad 0.93 | tok/s 37542
step   1620 | loss 1.4223 | lr 5.87e-04 | grad 0.75 | tok/s 35952
step   1630 | loss 1.4812 | lr 5.87e-04 | grad 2.45 | tok/s 36258
step   1640 | loss 1.4969 | lr 5.87e-04 | grad 1.09 | tok/s 36367
step   1650 | loss 1.4706 | lr 5.87e-04 | grad 1.26 | tok/s 37609
step   1660 | loss 1.7193 | lr 5.87e-04 | grad 1.10 | tok/s 37163
step   1670 | loss 1.3454 | lr 5.87e-04 | grad 0.76 | tok/s 36748
step   1680 | loss 1.5207 | lr 5.87e-04 | grad 1.04 | tok/s 37203
step   1690 | loss 1.5583 | lr 5.87e-04 | grad 0.90 | tok/s 36848
step   1700 | loss 1.4500 | lr 5.87e-04 | grad 1.12 | tok/s 36557
step   1710 | loss 1.5482 | lr 5.87e-04 | grad 0.68 | tok/s 36663
step   1720 | loss 1.4855 | lr 5.87e-04 | grad 0.64 | tok/s 36576
step   1730 | loss 1.4802 | lr 5.87e-04 | grad 0.91 | tok/s 36171
step   1740 | loss 1.5658 | lr 5.87e-04 | grad 0.80 | tok/s 36696
step   1750 | loss 1.6139 | lr 5.87e-04 | grad 1.27 | tok/s 36430
step   1760 | loss 1.4548 | lr 5.87e-04 | grad 1.30 | tok/s 36311
step   1770 | loss 1.5851 | lr 5.87e-04 | grad 0.58 | tok/s 36168
step   1780 | loss 1.4578 | lr 5.87e-04 | grad 1.27 | tok/s 37187
step   1790 | loss 1.3655 | lr 5.87e-04 | grad 2.38 | tok/s 37412
step   1800 | loss 1.3816 | lr 5.87e-04 | grad 0.58 | tok/s 36197
step   1810 | loss 1.4637 | lr 5.87e-04 | grad 0.69 | tok/s 36353
step   1820 | loss 1.5688 | lr 5.87e-04 | grad 0.87 | tok/s 36421
step   1830 | loss 1.5578 | lr 5.87e-04 | grad 0.80 | tok/s 36158
step   1840 | loss 1.3891 | lr 5.87e-04 | grad 0.71 | tok/s 36664
step   1850 | loss 1.3824 | lr 5.87e-04 | grad 0.87 | tok/s 37490
step   1860 | loss 1.4521 | lr 5.87e-04 | grad 0.74 | tok/s 37231
step   1870 | loss 1.5639 | lr 5.87e-04 | grad 1.46 | tok/s 36877
step   1880 | loss 1.4446 | lr 5.87e-04 | grad 0.79 | tok/s 37017
step   1890 | loss 1.5771 | lr 5.87e-04 | grad 0.59 | tok/s 36734
step   1900 | loss 1.3120 | lr 5.87e-04 | grad 0.89 | tok/s 37277
step   1910 | loss 1.3865 | lr 5.87e-04 | grad 0.74 | tok/s 37201
step   1920 | loss 1.4882 | lr 5.87e-04 | grad 0.82 | tok/s 37898
step   1930 | loss 1.4220 | lr 5.87e-04 | grad 1.09 | tok/s 37056
step   1940 | loss 1.4840 | lr 5.87e-04 | grad 0.96 | tok/s 37331
step   1950 | loss 1.3707 | lr 5.87e-04 | grad 0.92 | tok/s 36720
step   1960 | loss 1.5606 | lr 5.87e-04 | grad 2.02 | tok/s 37181
step   1970 | loss 1.4130 | lr 5.87e-04 | grad 1.16 | tok/s 36563
step   1980 | loss 1.3686 | lr 5.87e-04 | grad 0.60 | tok/s 37617
step   1990 | loss 1.1528 | lr 5.87e-04 | grad 1.16 | tok/s 38357
step   2000 | loss 1.2010 | lr 5.87e-04 | grad 2.59 | tok/s 38308
  >>> saved checkpoint: checkpoint_step_002000_loss_1.2010.pt
step   2010 | loss 1.3415 | lr 5.87e-04 | grad 0.85 | tok/s 24563
step   2020 | loss 1.2118 | lr 5.87e-04 | grad 0.71 | tok/s 38503
step   2030 | loss 1.4761 | lr 5.87e-04 | grad 0.94 | tok/s 36901
step   2040 | loss 1.4548 | lr 5.87e-04 | grad 0.73 | tok/s 37439
step   2050 | loss 1.4890 | lr 5.87e-04 | grad 1.55 | tok/s 37030
step   2060 | loss 1.5115 | lr 5.87e-04 | grad 0.68 | tok/s 36981
step   2070 | loss 1.4223 | lr 5.87e-04 | grad 0.75 | tok/s 36623
step   2080 | loss 1.3078 | lr 5.87e-04 | grad 0.69 | tok/s 37348
step   2090 | loss 1.3510 | lr 5.87e-04 | grad 0.84 | tok/s 36698
step   2100 | loss 1.2035 | lr 5.87e-04 | grad 1.28 | tok/s 37375
step   2110 | loss 1.5090 | lr 5.87e-04 | grad 0.79 | tok/s 36509
step   2120 | loss 1.5471 | lr 5.87e-04 | grad 1.01 | tok/s 36873
step   2130 | loss 1.5083 | lr 5.87e-04 | grad 1.36 | tok/s 36507
step   2140 | loss 1.5678 | lr 5.87e-04 | grad 0.93 | tok/s 37134
step   2150 | loss 1.4317 | lr 5.87e-04 | grad 1.20 | tok/s 36834
step   2160 | loss 1.5768 | lr 5.87e-04 | grad 1.02 | tok/s 37757
step   2170 | loss 1.2441 | lr 5.87e-04 | grad 0.59 | tok/s 37875
step   2180 | loss 1.2010 | lr 5.87e-04 | grad 0.59 | tok/s 38306
step   2190 | loss 1.1955 | lr 5.87e-04 | grad 0.65 | tok/s 38343
step   2200 | loss 1.3230 | lr 5.87e-04 | grad 1.66 | tok/s 37563
step   2210 | loss 1.4302 | lr 5.87e-04 | grad 2.16 | tok/s 37645
step   2220 | loss 1.4231 | lr 5.87e-04 | grad 0.71 | tok/s 37938
step   2230 | loss 1.5274 | lr 5.87e-04 | grad 0.79 | tok/s 37389
step   2240 | loss 1.3740 | lr 5.87e-04 | grad 0.71 | tok/s 36859
step   2250 | loss 1.5103 | lr 5.87e-04 | grad 2.33 | tok/s 36973
step   2260 | loss 1.4252 | lr 5.87e-04 | grad 0.74 | tok/s 36598
step   2270 | loss 1.4182 | lr 5.87e-04 | grad 0.82 | tok/s 36378
step   2280 | loss 1.4027 | lr 5.87e-04 | grad 1.24 | tok/s 37467
step   2290 | loss 1.3424 | lr 5.87e-04 | grad 0.81 | tok/s 38326
step   2300 | loss 1.2838 | lr 5.87e-04 | grad 0.64 | tok/s 38295
step   2310 | loss 1.3688 | lr 5.87e-04 | grad 0.73 | tok/s 37796
step   2320 | loss 1.4893 | lr 5.87e-04 | grad 0.75 | tok/s 37063
step   2330 | loss 1.7493 | lr 5.87e-04 | grad 1.40 | tok/s 37195
step   2340 | loss 1.4984 | lr 5.87e-04 | grad 0.90 | tok/s 37232
step   2350 | loss 1.3910 | lr 5.87e-04 | grad 0.73 | tok/s 36832
step   2360 | loss 1.3593 | lr 5.87e-04 | grad 0.93 | tok/s 36511
step   2370 | loss 1.4825 | lr 5.87e-04 | grad 1.50 | tok/s 36679
step   2380 | loss 1.4157 | lr 5.87e-04 | grad 1.03 | tok/s 36375
step   2390 | loss 1.4856 | lr 5.87e-04 | grad 0.67 | tok/s 36993
step   2400 | loss 1.4168 | lr 5.87e-04 | grad 0.84 | tok/s 36123
step   2410 | loss 1.5635 | lr 5.87e-04 | grad 0.78 | tok/s 37189
step   2420 | loss 1.3322 | lr 5.87e-04 | grad 1.34 | tok/s 36937
step   2430 | loss 1.4547 | lr 5.87e-04 | grad 1.25 | tok/s 37338
step   2440 | loss 1.1990 | lr 5.87e-04 | grad 1.12 | tok/s 38305
step   2450 | loss 1.3725 | lr 5.87e-04 | grad 0.70 | tok/s 36857
step   2460 | loss 1.3469 | lr 5.87e-04 | grad 0.68 | tok/s 36364
step   2470 | loss 1.4184 | lr 5.87e-04 | grad 0.96 | tok/s 37263
step   2480 | loss 1.4345 | lr 5.87e-04 | grad 0.77 | tok/s 37276
step   2490 | loss 1.6182 | lr 5.87e-04 | grad 1.56 | tok/s 36652
step   2500 | loss 1.4942 | lr 5.87e-04 | grad 1.05 | tok/s 36239
step   2510 | loss 1.4553 | lr 5.87e-04 | grad 0.78 | tok/s 36523
step   2520 | loss 1.7391 | lr 5.87e-04 | grad 1.88 | tok/s 36939
step   2530 | loss 1.5158 | lr 5.87e-04 | grad 1.21 | tok/s 37516
step   2540 | loss 1.4678 | lr 5.87e-04 | grad 1.55 | tok/s 36490
step   2550 | loss 1.4340 | lr 5.87e-04 | grad 0.72 | tok/s 37208
step   2560 | loss 1.3613 | lr 5.87e-04 | grad 0.77 | tok/s 36713
step   2570 | loss 1.4848 | lr 5.87e-04 | grad 0.51 | tok/s 37741
step   2580 | loss 1.3887 | lr 5.87e-04 | grad 0.67 | tok/s 37600
step   2590 | loss 1.2754 | lr 5.87e-04 | grad 0.91 | tok/s 38291
step   2600 | loss 1.3932 | lr 5.87e-04 | grad 0.95 | tok/s 37273
step   2610 | loss 1.4276 | lr 5.87e-04 | grad 0.83 | tok/s 36548
step   2620 | loss 1.4319 | lr 5.87e-04 | grad 1.10 | tok/s 35547
step   2630 | loss 1.6668 | lr 5.87e-04 | grad 0.55 | tok/s 37903
step   2640 | loss 1.2985 | lr 5.87e-04 | grad 0.49 | tok/s 38310
step   2650 | loss 1.2571 | lr 5.87e-04 | grad 0.54 | tok/s 38321
step   2660 | loss 1.2445 | lr 5.87e-04 | grad 0.54 | tok/s 38320
step   2670 | loss 1.4215 | lr 5.87e-04 | grad 0.72 | tok/s 36736
step   2680 | loss 1.5655 | lr 5.87e-04 | grad 1.17 | tok/s 36402
step   2690 | loss 1.7323 | lr 5.87e-04 | grad 2.17 | tok/s 37719
step   2700 | loss 1.3712 | lr 5.87e-04 | grad 0.66 | tok/s 36829
step   2710 | loss 1.2915 | lr 5.87e-04 | grad 0.57 | tok/s 37317
step   2720 | loss 1.5023 | lr 5.87e-04 | grad 0.64 | tok/s 36755
step   2730 | loss 1.5700 | lr 5.87e-04 | grad 0.64 | tok/s 36180
step   2740 | loss 1.4336 | lr 5.87e-04 | grad 0.65 | tok/s 37548
step   2750 | loss 1.3748 | lr 5.87e-04 | grad 0.59 | tok/s 36409
step   2760 | loss 1.3021 | lr 5.87e-04 | grad 0.75 | tok/s 36747
step   2770 | loss 1.7789 | lr 5.87e-04 | grad 2.12 | tok/s 36934
step   2780 | loss 1.3469 | lr 5.87e-04 | grad 0.50 | tok/s 37674
step   2790 | loss 1.6798 | lr 5.87e-04 | grad 0.99 | tok/s 37405
step   2800 | loss 1.4575 | lr 5.87e-04 | grad 0.86 | tok/s 37487
step   2810 | loss 1.4061 | lr 5.87e-04 | grad 0.66 | tok/s 37035
step   2820 | loss 1.3427 | lr 5.87e-04 | grad 1.38 | tok/s 37410
step   2830 | loss 1.3697 | lr 5.87e-04 | grad 1.33 | tok/s 36941
step   2840 | loss 1.5755 | lr 5.87e-04 | grad 3.23 | tok/s 37484
step   2850 | loss 1.6466 | lr 5.87e-04 | grad 0.88 | tok/s 37162
step   2860 | loss 1.6082 | lr 5.87e-04 | grad 0.88 | tok/s 37587
step   2870 | loss 1.3644 | lr 5.87e-04 | grad 0.95 | tok/s 36482
step   2880 | loss 1.5991 | lr 5.87e-04 | grad 2.00 | tok/s 36595
step   2890 | loss 1.4406 | lr 5.87e-04 | grad 0.67 | tok/s 37395
step   2900 | loss 1.4349 | lr 5.87e-04 | grad 0.72 | tok/s 36799
step   2910 | loss 1.4380 | lr 5.87e-04 | grad 0.98 | tok/s 36662
step   2920 | loss 1.4279 | lr 5.87e-04 | grad 0.90 | tok/s 36782
step   2930 | loss 1.5285 | lr 5.87e-04 | grad 1.27 | tok/s 36480
step   2940 | loss 1.4176 | lr 5.87e-04 | grad 0.72 | tok/s 36838
step   2950 | loss 1.4180 | lr 5.87e-04 | grad 0.75 | tok/s 37553
step   2960 | loss 1.3437 | lr 5.87e-04 | grad 0.65 | tok/s 37160
step   2970 | loss 1.3646 | lr 5.87e-04 | grad 2.09 | tok/s 37215
step   2980 | loss 1.3922 | lr 5.87e-04 | grad 0.93 | tok/s 37161
step   2990 | loss 1.4540 | lr 5.87e-04 | grad 1.28 | tok/s 37391
step   3000 | loss 1.4356 | lr 5.87e-04 | grad 0.68 | tok/s 36954
  >>> saved checkpoint: checkpoint_step_003000_loss_1.4356.pt
step   3010 | loss 1.5005 | lr 5.87e-04 | grad 1.71 | tok/s 23236
step   3020 | loss 1.3495 | lr 5.87e-04 | grad 0.91 | tok/s 37106
step   3030 | loss 1.3344 | lr 5.87e-04 | grad 0.63 | tok/s 36868
step   3040 | loss 1.3700 | lr 5.87e-04 | grad 0.70 | tok/s 37367
step   3050 | loss 1.3130 | lr 5.87e-04 | grad 0.66 | tok/s 37842
step   3060 | loss 1.3980 | lr 5.87e-04 | grad 0.71 | tok/s 36967
step   3070 | loss 1.3556 | lr 5.87e-04 | grad 0.51 | tok/s 36980
step   3080 | loss 1.3663 | lr 5.87e-04 | grad 0.59 | tok/s 36987
step   3090 | loss 1.6626 | lr 5.87e-04 | grad 4.09 | tok/s 37287
step   3100 | loss 1.7049 | lr 5.87e-04 | grad 1.29 | tok/s 38560
step   3110 | loss 1.4127 | lr 5.87e-04 | grad 1.47 | tok/s 38530
step   3120 | loss 1.4935 | lr 5.87e-04 | grad 0.98 | tok/s 37109
step   3130 | loss 1.9751 | lr 5.87e-04 | grad 0.71 | tok/s 36822
step   3140 | loss 1.2793 | lr 5.87e-04 | grad 0.81 | tok/s 37380
step   3150 | loss 1.6546 | lr 5.87e-04 | grad 2.73 | tok/s 37280
step   3160 | loss 1.3934 | lr 5.87e-04 | grad 1.00 | tok/s 36708
step   3170 | loss 1.6163 | lr 5.87e-04 | grad 0.88 | tok/s 37797
step   3180 | loss 1.3934 | lr 5.87e-04 | grad 0.94 | tok/s 37903
step   3190 | loss 1.4229 | lr 5.87e-04 | grad 0.68 | tok/s 37286
step   3200 | loss 1.5054 | lr 5.87e-04 | grad 1.01 | tok/s 36174
step   3210 | loss 1.4450 | lr 5.87e-04 | grad 0.57 | tok/s 35153
step   3220 | loss 1.2515 | lr 5.87e-04 | grad 0.66 | tok/s 36927
step   3230 | loss 1.4957 | lr 5.87e-04 | grad 1.00 | tok/s 37186
step   3240 | loss 1.4409 | lr 5.87e-04 | grad 0.59 | tok/s 37206
step   3250 | loss 1.4465 | lr 5.87e-04 | grad 2.19 | tok/s 38332
step   3260 | loss 1.4528 | lr 5.87e-04 | grad 0.63 | tok/s 36649
step   3270 | loss 1.4255 | lr 5.87e-04 | grad 0.78 | tok/s 37403
step   3280 | loss 1.4999 | lr 5.87e-04 | grad 1.16 | tok/s 37015
step   3290 | loss 1.4456 | lr 5.87e-04 | grad 0.93 | tok/s 37514
step   3300 | loss 1.4169 | lr 5.87e-04 | grad 0.85 | tok/s 36264
step   3310 | loss 1.4382 | lr 5.87e-04 | grad 1.05 | tok/s 35618
step   3320 | loss 1.4071 | lr 5.87e-04 | grad 0.55 | tok/s 38549
step   3330 | loss 1.3592 | lr 5.87e-04 | grad 0.77 | tok/s 38095
step   3340 | loss 1.3217 | lr 5.87e-04 | grad 1.39 | tok/s 36920
step   3350 | loss 1.5109 | lr 5.87e-04 | grad 1.48 | tok/s 37779
step   3360 | loss 1.4770 | lr 5.87e-04 | grad 0.56 | tok/s 36885
step   3370 | loss 1.2907 | lr 5.87e-04 | grad 0.49 | tok/s 36324
step   3380 | loss 1.3983 | lr 5.87e-04 | grad 1.08 | tok/s 37542
step   3390 | loss 1.4024 | lr 5.87e-04 | grad 0.75 | tok/s 37622
step   3400 | loss 1.9197 | lr 5.87e-04 | grad 1.48 | tok/s 37577
step   3410 | loss 1.3806 | lr 5.87e-04 | grad 0.82 | tok/s 37241
step   3420 | loss 1.5177 | lr 5.87e-04 | grad 0.57 | tok/s 37322
step   3430 | loss 1.2049 | lr 5.87e-04 | grad 1.47 | tok/s 38148
step   3440 | loss 1.4192 | lr 5.87e-04 | grad 0.71 | tok/s 36016
step   3450 | loss 1.4876 | lr 5.87e-04 | grad 0.73 | tok/s 36592
step   3460 | loss 1.4031 | lr 5.87e-04 | grad 0.95 | tok/s 37583
step   3470 | loss 1.6501 | lr 5.87e-04 | grad 0.68 | tok/s 36735
step   3480 | loss 1.4327 | lr 5.87e-04 | grad 1.26 | tok/s 36895
step   3490 | loss 1.3145 | lr 5.87e-04 | grad 0.70 | tok/s 36882
step   3500 | loss 1.4362 | lr 5.87e-04 | grad 1.05 | tok/s 37047
step   3510 | loss 1.4327 | lr 5.87e-04 | grad 0.62 | tok/s 36455
step   3520 | loss 1.4237 | lr 5.87e-04 | grad 0.58 | tok/s 37575
step   3530 | loss 1.4370 | lr 5.87e-04 | grad 0.65 | tok/s 37285
step   3540 | loss 1.3750 | lr 5.87e-04 | grad 0.85 | tok/s 36932
step   3550 | loss 1.5423 | lr 5.87e-04 | grad 0.86 | tok/s 37425
step   3560 | loss 1.4829 | lr 5.87e-04 | grad 0.77 | tok/s 36358
step   3570 | loss 1.4198 | lr 5.87e-04 | grad 0.84 | tok/s 37152
step   3580 | loss 1.3636 | lr 5.87e-04 | grad 1.29 | tok/s 37380
step   3590 | loss 1.4086 | lr 5.87e-04 | grad 1.03 | tok/s 38368
step   3600 | loss 1.2776 | lr 5.87e-04 | grad 0.52 | tok/s 38621
step   3610 | loss 1.2588 | lr 5.87e-04 | grad 0.81 | tok/s 38603
step   3620 | loss 1.2214 | lr 5.87e-04 | grad 0.55 | tok/s 38583
step   3630 | loss 1.2010 | lr 5.87e-04 | grad 0.77 | tok/s 38563
step   3640 | loss 1.2028 | lr 5.87e-04 | grad 0.51 | tok/s 38627
step   3650 | loss 1.3220 | lr 5.87e-04 | grad 1.30 | tok/s 37091
step   3660 | loss 1.5551 | lr 5.87e-04 | grad 0.79 | tok/s 37426
step   3670 | loss 1.3014 | lr 5.87e-04 | grad 0.72 | tok/s 37775
step   3680 | loss 1.3125 | lr 5.87e-04 | grad 0.88 | tok/s 36854
step   3690 | loss 1.3202 | lr 5.87e-04 | grad 1.07 | tok/s 37078
step   3700 | loss 1.3629 | lr 5.87e-04 | grad 0.98 | tok/s 37606
step   3710 | loss 1.3804 | lr 5.87e-04 | grad 1.31 | tok/s 38271
step   3720 | loss 1.3403 | lr 5.87e-04 | grad 2.11 | tok/s 37260
step   3730 | loss 1.3804 | lr 5.87e-04 | grad 1.07 | tok/s 37941
step   3740 | loss 1.5370 | lr 5.87e-04 | grad 0.62 | tok/s 37292
step   3750 | loss 1.3593 | lr 5.87e-04 | grad 0.81 | tok/s 38140
step   3760 | loss 1.3236 | lr 5.87e-04 | grad 1.09 | tok/s 37252
step   3770 | loss 1.4426 | lr 5.87e-04 | grad 2.53 | tok/s 37459
step   3780 | loss 1.2907 | lr 5.87e-04 | grad 0.81 | tok/s 37075
step   3790 | loss 1.3766 | lr 5.87e-04 | grad 1.23 | tok/s 37806
step   3800 | loss 1.3728 | lr 5.87e-04 | grad 0.74 | tok/s 36819
step   3810 | loss 1.3433 | lr 5.87e-04 | grad 0.69 | tok/s 37918
step   3820 | loss 1.2936 | lr 5.87e-04 | grad 0.64 | tok/s 36488
step   3830 | loss 1.2851 | lr 5.87e-04 | grad 0.64 | tok/s 37057
step   3840 | loss 1.2590 | lr 5.87e-04 | grad 1.27 | tok/s 37549
step   3850 | loss 1.3746 | lr 5.87e-04 | grad 1.39 | tok/s 36777
step   3860 | loss 1.4109 | lr 5.87e-04 | grad 0.53 | tok/s 36895
step   3870 | loss 1.3708 | lr 5.87e-04 | grad 0.74 | tok/s 37265
step   3880 | loss 1.3289 | lr 5.87e-04 | grad 0.65 | tok/s 37158
step   3890 | loss 1.3476 | lr 5.87e-04 | grad 0.64 | tok/s 36387
step   3900 | loss 1.4037 | lr 5.87e-04 | grad 0.75 | tok/s 36214
step   3910 | loss 1.3330 | lr 5.87e-04 | grad 0.72 | tok/s 36682
step   3920 | loss 1.3676 | lr 5.87e-04 | grad 0.51 | tok/s 37037
step   3930 | loss 1.4865 | lr 5.87e-04 | grad 0.70 | tok/s 37092
step   3940 | loss 1.2189 | lr 5.87e-04 | grad 0.69 | tok/s 37876
step   3950 | loss 1.4861 | lr 5.87e-04 | grad 0.75 | tok/s 37660
step   3960 | loss 1.3690 | lr 5.87e-04 | grad 0.69 | tok/s 36250
step   3970 | loss 1.2899 | lr 5.87e-04 | grad 1.20 | tok/s 37541
step   3980 | loss 1.2940 | lr 5.87e-04 | grad 0.97 | tok/s 37154
step   3990 | loss 1.2898 | lr 5.87e-04 | grad 0.48 | tok/s 36705
step   4000 | loss 1.4725 | lr 5.87e-04 | grad 0.75 | tok/s 37126
  >>> saved checkpoint: checkpoint_step_004000_loss_1.4725.pt
step   4010 | loss 1.4817 | lr 5.87e-04 | grad 0.60 | tok/s 22796
step   4020 | loss 1.4483 | lr 5.87e-04 | grad 0.71 | tok/s 36800
step   4030 | loss 1.3749 | lr 5.87e-04 | grad 0.70 | tok/s 37567
step   4040 | loss 1.4221 | lr 5.87e-04 | grad 0.85 | tok/s 38192
step   4050 | loss 1.3936 | lr 5.87e-04 | grad 1.24 | tok/s 37001
step   4060 | loss 1.4568 | lr 5.87e-04 | grad 1.91 | tok/s 36030
step   4070 | loss 1.4056 | lr 5.87e-04 | grad 0.84 | tok/s 37793
step   4080 | loss 1.4851 | lr 5.87e-04 | grad 0.66 | tok/s 36913
step   4090 | loss 1.4378 | lr 5.87e-04 | grad 1.28 | tok/s 37715
step   4100 | loss 1.6392 | lr 5.87e-04 | grad 0.54 | tok/s 36480
step   4110 | loss 1.7036 | lr 5.87e-04 | grad 1.80 | tok/s 37168
step   4120 | loss 1.4215 | lr 5.87e-04 | grad 0.77 | tok/s 37325
step   4130 | loss 1.5503 | lr 5.87e-04 | grad 0.77 | tok/s 37828
step   4140 | loss 1.3576 | lr 5.87e-04 | grad 0.68 | tok/s 37754
step   4150 | loss 1.5044 | lr 5.87e-04 | grad 0.58 | tok/s 37449
step   4160 | loss 1.4569 | lr 5.87e-04 | grad 0.59 | tok/s 36589

Training complete! Final step: 4162
