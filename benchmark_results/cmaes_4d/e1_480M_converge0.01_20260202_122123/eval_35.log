Using device: cuda
Output directory: benchmark_results/cmaes_4d/e1_480M_converge0.01_20260202_122123/eval_35/level1_100m_20260202_142317
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 283,584,000 parameters
Using schedule-free AdamW (lr=0.0006882494719339372)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 5.2539 | lr 6.88e-04 | grad 10.56 | tok/s 17218
step     20 | loss 4.4692 | lr 6.88e-04 | grad 6.44 | tok/s 34313
step     30 | loss 3.6380 | lr 6.88e-04 | grad 4.25 | tok/s 34975
step     40 | loss 2.6908 | lr 6.88e-04 | grad 2.72 | tok/s 34826
step     50 | loss 2.4128 | lr 6.88e-04 | grad 1.68 | tok/s 34980
step     60 | loss 3.0008 | lr 6.88e-04 | grad 2.81 | tok/s 33612
step     70 | loss 2.6751 | lr 6.88e-04 | grad 3.36 | tok/s 34146
step     80 | loss 2.7463 | lr 6.88e-04 | grad 1.16 | tok/s 33891
step     90 | loss 2.5425 | lr 6.88e-04 | grad 1.74 | tok/s 32875
step    100 | loss 2.2185 | lr 6.88e-04 | grad 2.31 | tok/s 32801
step    110 | loss 2.4731 | lr 6.88e-04 | grad 1.10 | tok/s 33091
step    120 | loss 2.4625 | lr 6.88e-04 | grad 1.64 | tok/s 33324
step    130 | loss 2.2809 | lr 6.88e-04 | grad 2.08 | tok/s 32665
step    140 | loss 2.1032 | lr 6.88e-04 | grad 1.83 | tok/s 30590
step    150 | loss 2.1530 | lr 6.88e-04 | grad 1.05 | tok/s 30998
step    160 | loss 2.1624 | lr 6.88e-04 | grad 2.20 | tok/s 31506
step    170 | loss 2.2777 | lr 6.88e-04 | grad 1.87 | tok/s 33681
step    180 | loss 1.9914 | lr 6.88e-04 | grad 1.88 | tok/s 33522
step    190 | loss 1.7754 | lr 6.88e-04 | grad 2.00 | tok/s 34789
step    200 | loss 1.9429 | lr 6.88e-04 | grad 1.02 | tok/s 33686
step    210 | loss 2.0604 | lr 6.88e-04 | grad 1.28 | tok/s 34202
step    220 | loss 1.9993 | lr 6.88e-04 | grad 0.98 | tok/s 33587
step    230 | loss 1.8769 | lr 6.88e-04 | grad 1.03 | tok/s 33443
step    240 | loss 1.9387 | lr 6.88e-04 | grad 1.55 | tok/s 34010
step    250 | loss 2.0258 | lr 6.88e-04 | grad 1.23 | tok/s 33346
step    260 | loss 1.8392 | lr 6.88e-04 | grad 1.34 | tok/s 32595
step    270 | loss 1.8543 | lr 6.88e-04 | grad 2.20 | tok/s 33234
step    280 | loss 1.6575 | lr 6.88e-04 | grad 1.23 | tok/s 34403
step    290 | loss 1.5157 | lr 6.88e-04 | grad 1.06 | tok/s 34682
step    300 | loss 1.5303 | lr 6.88e-04 | grad 1.31 | tok/s 34705
step    310 | loss 1.6395 | lr 6.88e-04 | grad 1.24 | tok/s 34465
step    320 | loss 1.8246 | lr 6.88e-04 | grad 0.88 | tok/s 32877
step    330 | loss 1.8340 | lr 6.88e-04 | grad 1.66 | tok/s 33834
step    340 | loss 1.7842 | lr 6.88e-04 | grad 1.33 | tok/s 32910
step    350 | loss 1.7576 | lr 6.88e-04 | grad 1.19 | tok/s 32591
step    360 | loss 1.6595 | lr 6.88e-04 | grad 1.16 | tok/s 33873
step    370 | loss 2.0396 | lr 6.88e-04 | grad 1.36 | tok/s 33777
step    380 | loss 1.6890 | lr 6.88e-04 | grad 0.83 | tok/s 34436
step    390 | loss 1.6858 | lr 6.88e-04 | grad 1.04 | tok/s 33621
step    400 | loss 1.6763 | lr 6.88e-04 | grad 0.85 | tok/s 33894
step    410 | loss 1.6761 | lr 6.88e-04 | grad 1.09 | tok/s 32717
step    420 | loss 1.7478 | lr 6.88e-04 | grad 0.92 | tok/s 32879
step    430 | loss 1.7932 | lr 6.88e-04 | grad 1.30 | tok/s 33902
step    440 | loss 1.6923 | lr 6.88e-04 | grad 0.80 | tok/s 33394
step    450 | loss 1.6583 | lr 6.88e-04 | grad 0.75 | tok/s 33464
step    460 | loss 1.7005 | lr 6.88e-04 | grad 1.15 | tok/s 33224
step    470 | loss 1.5615 | lr 6.88e-04 | grad 1.02 | tok/s 32512
step    480 | loss 1.5538 | lr 6.88e-04 | grad 1.02 | tok/s 32894
step    490 | loss 1.9925 | lr 6.88e-04 | grad 1.16 | tok/s 34238
step    500 | loss 1.6245 | lr 6.88e-04 | grad 2.84 | tok/s 32831
step    510 | loss 1.4266 | lr 6.88e-04 | grad 0.62 | tok/s 34609
step    520 | loss 2.0445 | lr 6.88e-04 | grad 1.86 | tok/s 33617
step    530 | loss 1.4852 | lr 6.88e-04 | grad 0.68 | tok/s 34011
step    540 | loss 1.4938 | lr 6.88e-04 | grad 1.21 | tok/s 34337
step    550 | loss 1.3376 | lr 6.88e-04 | grad 1.12 | tok/s 34840
step    560 | loss 1.5002 | lr 6.88e-04 | grad 2.53 | tok/s 34397
step    570 | loss 1.9007 | lr 6.88e-04 | grad 0.97 | tok/s 34521
step    580 | loss 2.0159 | lr 6.88e-04 | grad 2.09 | tok/s 33162
step    590 | loss 1.5452 | lr 6.88e-04 | grad 1.07 | tok/s 33540
step    600 | loss 1.5564 | lr 6.88e-04 | grad 1.26 | tok/s 34741
step    610 | loss 1.5350 | lr 6.88e-04 | grad 0.81 | tok/s 32955
step    620 | loss 1.4555 | lr 6.88e-04 | grad 0.87 | tok/s 34081
step    630 | loss 1.6265 | lr 6.88e-04 | grad 1.09 | tok/s 34095
step    640 | loss 1.5413 | lr 6.88e-04 | grad 1.40 | tok/s 33385
step    650 | loss 1.6827 | lr 6.88e-04 | grad 3.22 | tok/s 32809
step    660 | loss 1.6494 | lr 6.88e-04 | grad 1.45 | tok/s 33807
step    670 | loss 1.6634 | lr 6.88e-04 | grad 1.12 | tok/s 33439
step    680 | loss 1.5864 | lr 6.88e-04 | grad 1.13 | tok/s 33165
step    690 | loss 1.6962 | lr 6.88e-04 | grad 1.22 | tok/s 33325
step    700 | loss 1.5987 | lr 6.88e-04 | grad 0.92 | tok/s 33827
step    710 | loss 1.5489 | lr 6.88e-04 | grad 3.77 | tok/s 33493
step    720 | loss 1.6958 | lr 6.88e-04 | grad 0.86 | tok/s 33577
step    730 | loss 1.6964 | lr 6.88e-04 | grad 2.14 | tok/s 33623
step    740 | loss 1.4881 | lr 6.88e-04 | grad 0.95 | tok/s 33259
step    750 | loss 1.7406 | lr 6.88e-04 | grad 0.80 | tok/s 33648
step    760 | loss 1.5152 | lr 6.88e-04 | grad 0.98 | tok/s 33586
step    770 | loss 1.5968 | lr 6.88e-04 | grad 1.12 | tok/s 33971
step    780 | loss 1.4306 | lr 6.88e-04 | grad 0.98 | tok/s 34249
step    790 | loss 1.4874 | lr 6.88e-04 | grad 2.23 | tok/s 33809
step    800 | loss 1.4491 | lr 6.88e-04 | grad 0.97 | tok/s 33603
step    810 | loss 2.0794 | lr 6.88e-04 | grad 1.84 | tok/s 34639
step    820 | loss 1.6616 | lr 6.88e-04 | grad 1.36 | tok/s 34866
step    830 | loss 1.4880 | lr 6.88e-04 | grad 1.21 | tok/s 34864
step    840 | loss 1.5885 | lr 6.88e-04 | grad 0.59 | tok/s 33225
step    850 | loss 1.4778 | lr 6.88e-04 | grad 0.63 | tok/s 33675
step    860 | loss 1.4945 | lr 6.88e-04 | grad 0.93 | tok/s 33571
step    870 | loss 1.5601 | lr 6.88e-04 | grad 0.96 | tok/s 34155
step    880 | loss 1.4745 | lr 6.88e-04 | grad 1.56 | tok/s 33189
step    890 | loss 1.7765 | lr 6.88e-04 | grad 0.93 | tok/s 33013
step    900 | loss 1.4454 | lr 6.88e-04 | grad 1.03 | tok/s 32814
step    910 | loss 1.5450 | lr 6.88e-04 | grad 0.88 | tok/s 32568
step    920 | loss 1.4887 | lr 6.88e-04 | grad 0.99 | tok/s 32871
step    930 | loss 1.5682 | lr 6.88e-04 | grad 1.09 | tok/s 32950
step    940 | loss 1.5664 | lr 6.88e-04 | grad 0.96 | tok/s 33728
step    950 | loss 1.3146 | lr 6.88e-04 | grad 1.34 | tok/s 34480
step    960 | loss 1.2583 | lr 6.88e-04 | grad 1.21 | tok/s 34715
step    970 | loss 1.4880 | lr 6.88e-04 | grad 0.90 | tok/s 33507
step    980 | loss 1.5985 | lr 6.88e-04 | grad 1.23 | tok/s 32718
step    990 | loss 1.5675 | lr 6.88e-04 | grad 1.05 | tok/s 33412
step   1000 | loss 1.4776 | lr 6.88e-04 | grad 0.71 | tok/s 34223
  >>> saved checkpoint: checkpoint_step_001000_loss_1.4776.pt
step   1010 | loss 1.4471 | lr 6.88e-04 | grad 0.79 | tok/s 23649
step   1020 | loss 1.7212 | lr 6.88e-04 | grad 0.64 | tok/s 33426
step   1030 | loss 1.6071 | lr 6.88e-04 | grad 0.96 | tok/s 33367
step   1040 | loss 1.2814 | lr 6.88e-04 | grad 0.61 | tok/s 33317
step   1050 | loss 1.7354 | lr 6.88e-04 | grad 0.78 | tok/s 34186
step   1060 | loss 1.9114 | lr 6.88e-04 | grad 1.08 | tok/s 33500
step   1070 | loss 1.5751 | lr 6.88e-04 | grad 0.95 | tok/s 33042
step   1080 | loss 1.6892 | lr 6.88e-04 | grad 0.57 | tok/s 33996
step   1090 | loss 1.5082 | lr 6.88e-04 | grad 1.40 | tok/s 34550
step   1100 | loss 1.4365 | lr 6.88e-04 | grad 1.26 | tok/s 34082
step   1110 | loss 1.5638 | lr 6.88e-04 | grad 0.59 | tok/s 32904
step   1120 | loss 1.5595 | lr 6.88e-04 | grad 0.91 | tok/s 33460
step   1130 | loss 1.5967 | lr 6.88e-04 | grad 1.90 | tok/s 33550
step   1140 | loss 1.5655 | lr 6.88e-04 | grad 2.27 | tok/s 33159
step   1150 | loss 1.6099 | lr 6.88e-04 | grad 1.04 | tok/s 32817
step   1160 | loss 1.4122 | lr 6.88e-04 | grad 1.13 | tok/s 34596
step   1170 | loss 1.3345 | lr 6.88e-04 | grad 1.05 | tok/s 34892
step   1180 | loss 1.2668 | lr 6.88e-04 | grad 0.92 | tok/s 34879
step   1190 | loss 1.2442 | lr 6.88e-04 | grad 1.09 | tok/s 34864
step   1200 | loss 1.2156 | lr 6.88e-04 | grad 1.01 | tok/s 34704
step   1210 | loss 1.3515 | lr 6.88e-04 | grad 0.35 | tok/s 34365
step   1220 | loss 1.4433 | lr 6.88e-04 | grad 0.81 | tok/s 32769
step   1230 | loss 1.5312 | lr 6.88e-04 | grad 0.81 | tok/s 33998
step   1240 | loss 1.4934 | lr 6.88e-04 | grad 1.29 | tok/s 33705
step   1250 | loss 1.7114 | lr 6.88e-04 | grad 0.68 | tok/s 33535
step   1260 | loss 1.5283 | lr 6.88e-04 | grad 1.17 | tok/s 33482
step   1270 | loss 1.5622 | lr 6.88e-04 | grad 0.83 | tok/s 33067
step   1280 | loss 1.5256 | lr 6.88e-04 | grad 0.71 | tok/s 33250
step   1290 | loss 1.5591 | lr 6.88e-04 | grad 0.67 | tok/s 33048
step   1300 | loss 1.5054 | lr 6.88e-04 | grad 0.75 | tok/s 33317
step   1310 | loss 1.5463 | lr 6.88e-04 | grad 0.91 | tok/s 33984
step   1320 | loss 1.3697 | lr 6.88e-04 | grad 0.69 | tok/s 33458
step   1330 | loss 1.3710 | lr 6.88e-04 | grad 0.66 | tok/s 34249
step   1340 | loss 1.4399 | lr 6.88e-04 | grad 0.55 | tok/s 33269
step   1350 | loss 1.4473 | lr 6.88e-04 | grad 1.12 | tok/s 33076
step   1360 | loss 1.6261 | lr 6.88e-04 | grad 0.93 | tok/s 33250
step   1370 | loss 1.4602 | lr 6.88e-04 | grad 0.64 | tok/s 33268
step   1380 | loss 1.4150 | lr 6.88e-04 | grad 0.74 | tok/s 34155
step   1390 | loss 1.4744 | lr 6.88e-04 | grad 1.10 | tok/s 34198
step   1400 | loss 1.5321 | lr 6.88e-04 | grad 2.00 | tok/s 32824
step   1410 | loss 1.4447 | lr 6.88e-04 | grad 0.69 | tok/s 32299
step   1420 | loss 1.3072 | lr 6.88e-04 | grad 0.71 | tok/s 33474
step   1430 | loss 1.2795 | lr 6.88e-04 | grad 0.72 | tok/s 34316
step   1440 | loss 1.5077 | lr 6.88e-04 | grad 1.16 | tok/s 32773
step   1450 | loss 1.5345 | lr 6.88e-04 | grad 0.89 | tok/s 33444
step   1460 | loss 1.4063 | lr 6.88e-04 | grad 2.00 | tok/s 33728
step   1470 | loss 1.4829 | lr 6.88e-04 | grad 1.14 | tok/s 33352
step   1480 | loss 1.7142 | lr 6.88e-04 | grad 1.48 | tok/s 33027
step   1490 | loss 1.4424 | lr 6.88e-04 | grad 0.97 | tok/s 34136
step   1500 | loss 1.5053 | lr 6.88e-04 | grad 0.89 | tok/s 33900
step   1510 | loss 1.4528 | lr 6.88e-04 | grad 0.67 | tok/s 33618
step   1520 | loss 1.4060 | lr 6.88e-04 | grad 0.87 | tok/s 33216
step   1530 | loss 1.3889 | lr 6.88e-04 | grad 2.72 | tok/s 34463
step   1540 | loss 1.8730 | lr 6.88e-04 | grad 1.12 | tok/s 33516
step   1550 | loss 1.4387 | lr 6.88e-04 | grad 0.76 | tok/s 33113
step   1560 | loss 1.5322 | lr 6.88e-04 | grad 0.95 | tok/s 33972
step   1570 | loss 1.3638 | lr 6.88e-04 | grad 0.97 | tok/s 33232
step   1580 | loss 1.5099 | lr 6.88e-04 | grad 0.59 | tok/s 32976
step   1590 | loss 1.3194 | lr 6.88e-04 | grad 0.64 | tok/s 34475
step   1600 | loss 1.4887 | lr 6.88e-04 | grad 0.81 | tok/s 33745
step   1610 | loss 1.4384 | lr 6.88e-04 | grad 0.97 | tok/s 34166
step   1620 | loss 1.4079 | lr 6.88e-04 | grad 0.81 | tok/s 32707
step   1630 | loss 1.4723 | lr 6.88e-04 | grad 2.69 | tok/s 33026
step   1640 | loss 1.4816 | lr 6.88e-04 | grad 1.12 | tok/s 32913
step   1650 | loss 1.4509 | lr 6.88e-04 | grad 1.26 | tok/s 34194
step   1660 | loss 1.7035 | lr 6.88e-04 | grad 1.16 | tok/s 33439
step   1670 | loss 1.3261 | lr 6.88e-04 | grad 0.71 | tok/s 33437
step   1680 | loss 1.5219 | lr 6.88e-04 | grad 1.02 | tok/s 33705
step   1690 | loss 1.5495 | lr 6.88e-04 | grad 0.91 | tok/s 33347
step   1700 | loss 1.4309 | lr 6.88e-04 | grad 1.10 | tok/s 33269
step   1710 | loss 1.5263 | lr 6.88e-04 | grad 0.70 | tok/s 33363
step   1720 | loss 1.4662 | lr 6.88e-04 | grad 0.68 | tok/s 33134
step   1730 | loss 1.4682 | lr 6.88e-04 | grad 0.90 | tok/s 32764
step   1740 | loss 1.5402 | lr 6.88e-04 | grad 0.83 | tok/s 33046
step   1750 | loss 1.5908 | lr 6.88e-04 | grad 1.34 | tok/s 33020
step   1760 | loss 1.4392 | lr 6.88e-04 | grad 1.43 | tok/s 33074
step   1770 | loss 1.5721 | lr 6.88e-04 | grad 0.63 | tok/s 32966
step   1780 | loss 1.4428 | lr 6.88e-04 | grad 1.38 | tok/s 33854
step   1790 | loss 1.3496 | lr 6.88e-04 | grad 1.92 | tok/s 33854
step   1800 | loss 1.3606 | lr 6.88e-04 | grad 0.59 | tok/s 32953
step   1810 | loss 1.4455 | lr 6.88e-04 | grad 0.70 | tok/s 33088
step   1820 | loss 1.5636 | lr 6.88e-04 | grad 0.96 | tok/s 33208
step   1830 | loss 1.5423 | lr 6.88e-04 | grad 0.84 | tok/s 32955
step   1840 | loss 1.3737 | lr 6.88e-04 | grad 0.73 | tok/s 33411
step   1850 | loss 1.3689 | lr 6.88e-04 | grad 0.96 | tok/s 33860
step   1860 | loss 1.4348 | lr 6.88e-04 | grad 0.77 | tok/s 33918
step   1870 | loss 1.5538 | lr 6.88e-04 | grad 1.58 | tok/s 33592
step   1880 | loss 1.4282 | lr 6.88e-04 | grad 0.85 | tok/s 33540
step   1890 | loss 1.5599 | lr 6.88e-04 | grad 0.59 | tok/s 33443
step   1900 | loss 1.2900 | lr 6.88e-04 | grad 1.23 | tok/s 33936
step   1910 | loss 1.3660 | lr 6.88e-04 | grad 0.78 | tok/s 33812
step   1920 | loss 1.4842 | lr 6.88e-04 | grad 0.86 | tok/s 34553
step   1930 | loss 1.4077 | lr 6.88e-04 | grad 1.24 | tok/s 33601
step   1940 | loss 1.4550 | lr 6.88e-04 | grad 0.94 | tok/s 33838
step   1950 | loss 1.3445 | lr 6.88e-04 | grad 1.00 | tok/s 33434
step   1960 | loss 1.5399 | lr 6.88e-04 | grad 2.05 | tok/s 33902
step   1970 | loss 1.3987 | lr 6.88e-04 | grad 1.23 | tok/s 33325
step   1980 | loss 1.3518 | lr 6.88e-04 | grad 0.63 | tok/s 34284
step   1990 | loss 1.1391 | lr 6.88e-04 | grad 1.05 | tok/s 34910
step   2000 | loss 1.1749 | lr 6.88e-04 | grad 2.66 | tok/s 34717
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1749.pt
step   2010 | loss 1.3250 | lr 6.88e-04 | grad 0.97 | tok/s 25315
step   2020 | loss 1.1941 | lr 6.88e-04 | grad 0.71 | tok/s 35011
step   2030 | loss 1.4534 | lr 6.88e-04 | grad 0.96 | tok/s 33307
step   2040 | loss 1.4418 | lr 6.88e-04 | grad 0.87 | tok/s 33997
step   2050 | loss 1.4658 | lr 6.88e-04 | grad 1.62 | tok/s 33493
step   2060 | loss 1.5009 | lr 6.88e-04 | grad 0.69 | tok/s 33662
step   2070 | loss 1.4058 | lr 6.88e-04 | grad 0.81 | tok/s 33116
step   2080 | loss 1.2916 | lr 6.88e-04 | grad 0.69 | tok/s 33948
step   2090 | loss 1.3317 | lr 6.88e-04 | grad 0.92 | tok/s 33371
step   2100 | loss 1.1819 | lr 6.88e-04 | grad 1.33 | tok/s 33921
step   2110 | loss 1.4954 | lr 6.88e-04 | grad 0.82 | tok/s 33219
step   2120 | loss 1.5194 | lr 6.88e-04 | grad 1.02 | tok/s 33556
step   2130 | loss 1.4911 | lr 6.88e-04 | grad 1.36 | tok/s 33205
step   2140 | loss 1.5556 | lr 6.88e-04 | grad 0.88 | tok/s 33789
step   2150 | loss 1.4114 | lr 6.88e-04 | grad 1.08 | tok/s 33365
step   2160 | loss 1.5663 | lr 6.88e-04 | grad 1.10 | tok/s 34353
step   2170 | loss 1.2268 | lr 6.88e-04 | grad 0.87 | tok/s 34477
step   2180 | loss 1.1840 | lr 6.88e-04 | grad 0.57 | tok/s 34896
step   2190 | loss 1.1762 | lr 6.88e-04 | grad 0.65 | tok/s 34908
step   2200 | loss 1.2978 | lr 6.88e-04 | grad 1.66 | tok/s 34196
step   2210 | loss 1.4230 | lr 6.88e-04 | grad 2.16 | tok/s 34100
step   2220 | loss 1.4132 | lr 6.88e-04 | grad 0.70 | tok/s 34497
step   2230 | loss 1.5069 | lr 6.88e-04 | grad 0.84 | tok/s 33953
step   2240 | loss 1.3504 | lr 6.88e-04 | grad 0.68 | tok/s 33601
step   2250 | loss 1.4941 | lr 6.88e-04 | grad 2.45 | tok/s 33685
step   2260 | loss 1.4044 | lr 6.88e-04 | grad 0.72 | tok/s 33312
step   2270 | loss 1.3973 | lr 6.88e-04 | grad 0.82 | tok/s 32974
step   2280 | loss 1.3835 | lr 6.88e-04 | grad 1.57 | tok/s 34074
step   2290 | loss 1.3269 | lr 6.88e-04 | grad 0.68 | tok/s 34712
step   2300 | loss 1.2648 | lr 6.88e-04 | grad 0.88 | tok/s 34904
step   2310 | loss 1.3525 | lr 6.88e-04 | grad 0.76 | tok/s 34424
step   2320 | loss 1.4821 | lr 6.88e-04 | grad 0.77 | tok/s 33544
step   2330 | loss 1.7250 | lr 6.88e-04 | grad 1.41 | tok/s 33655
step   2340 | loss 1.4874 | lr 6.88e-04 | grad 0.90 | tok/s 33859
step   2350 | loss 1.3754 | lr 6.88e-04 | grad 0.73 | tok/s 33513
step   2360 | loss 1.3457 | lr 6.88e-04 | grad 1.08 | tok/s 33231
step   2370 | loss 1.4566 | lr 6.88e-04 | grad 1.41 | tok/s 33372
step   2380 | loss 1.4005 | lr 6.88e-04 | grad 1.09 | tok/s 32958
step   2390 | loss 1.4916 | lr 6.88e-04 | grad 0.70 | tok/s 33658
step   2400 | loss 1.3953 | lr 6.88e-04 | grad 0.86 | tok/s 32889
step   2410 | loss 1.5501 | lr 6.88e-04 | grad 0.78 | tok/s 33862
step   2420 | loss 1.3209 | lr 6.88e-04 | grad 1.40 | tok/s 33422
step   2430 | loss 1.4398 | lr 6.88e-04 | grad 1.34 | tok/s 34105
step   2440 | loss 1.1842 | lr 6.88e-04 | grad 1.28 | tok/s 35012
step   2450 | loss 1.3557 | lr 6.88e-04 | grad 0.66 | tok/s 33434
step   2460 | loss 1.3328 | lr 6.88e-04 | grad 0.71 | tok/s 33200
step   2470 | loss 1.4040 | lr 6.88e-04 | grad 1.01 | tok/s 34036
step   2480 | loss 1.4099 | lr 6.88e-04 | grad 0.80 | tok/s 34089
step   2490 | loss 1.6045 | lr 6.88e-04 | grad 1.54 | tok/s 33161
step   2500 | loss 1.4788 | lr 6.88e-04 | grad 1.17 | tok/s 32927
step   2510 | loss 1.4302 | lr 6.88e-04 | grad 0.79 | tok/s 33217
step   2520 | loss 1.7303 | lr 6.88e-04 | grad 1.73 | tok/s 33549
step   2530 | loss 1.4966 | lr 6.88e-04 | grad 1.29 | tok/s 34102
step   2540 | loss 1.4565 | lr 6.88e-04 | grad 1.62 | tok/s 33172
step   2550 | loss 1.4099 | lr 6.88e-04 | grad 0.72 | tok/s 33849
step   2560 | loss 1.3441 | lr 6.88e-04 | grad 0.79 | tok/s 33415
step   2570 | loss 1.4701 | lr 6.88e-04 | grad 0.59 | tok/s 34338
step   2580 | loss 1.3691 | lr 6.88e-04 | grad 0.80 | tok/s 34193
step   2590 | loss 1.2572 | lr 6.88e-04 | grad 0.85 | tok/s 34880
step   2600 | loss 1.3752 | lr 6.88e-04 | grad 0.97 | tok/s 33728
step   2610 | loss 1.4041 | lr 6.88e-04 | grad 0.83 | tok/s 33253
step   2620 | loss 1.4118 | lr 6.88e-04 | grad 1.13 | tok/s 32378
step   2630 | loss 1.6282 | lr 6.88e-04 | grad 0.54 | tok/s 34229
step   2640 | loss 1.2789 | lr 6.88e-04 | grad 0.54 | tok/s 34898
step   2650 | loss 1.2388 | lr 6.88e-04 | grad 0.54 | tok/s 34885
step   2660 | loss 1.2241 | lr 6.88e-04 | grad 0.47 | tok/s 34901
step   2670 | loss 1.4022 | lr 6.88e-04 | grad 0.79 | tok/s 33246
step   2680 | loss 1.5444 | lr 6.88e-04 | grad 1.76 | tok/s 33101
step   2690 | loss 1.7125 | lr 6.88e-04 | grad 2.16 | tok/s 34289
step   2700 | loss 1.3537 | lr 6.88e-04 | grad 0.73 | tok/s 33428
step   2710 | loss 1.2737 | lr 6.88e-04 | grad 0.64 | tok/s 33909
step   2720 | loss 1.4895 | lr 6.88e-04 | grad 0.66 | tok/s 33385
step   2730 | loss 1.5589 | lr 6.88e-04 | grad 0.65 | tok/s 32886
step   2740 | loss 1.4218 | lr 6.88e-04 | grad 0.72 | tok/s 34104
step   2750 | loss 1.3559 | lr 6.88e-04 | grad 0.60 | tok/s 32897
step   2760 | loss 1.2826 | lr 6.88e-04 | grad 0.81 | tok/s 33241
step   2770 | loss 1.7667 | lr 6.88e-04 | grad 2.08 | tok/s 33611
step   2780 | loss 1.3223 | lr 6.88e-04 | grad 0.53 | tok/s 34105
step   2790 | loss 1.6554 | lr 6.88e-04 | grad 1.03 | tok/s 34051
step   2800 | loss 1.4504 | lr 6.88e-04 | grad 1.00 | tok/s 34126
step   2810 | loss 1.3867 | lr 6.88e-04 | grad 0.71 | tok/s 33528
step   2820 | loss 1.3246 | lr 6.88e-04 | grad 1.35 | tok/s 33998
step   2830 | loss 1.3461 | lr 6.88e-04 | grad 1.37 | tok/s 33577
step   2840 | loss 1.5521 | lr 6.88e-04 | grad 3.36 | tok/s 34046
step   2850 | loss 1.6128 | lr 6.88e-04 | grad 0.90 | tok/s 33795
step   2860 | loss 1.5769 | lr 6.88e-04 | grad 0.87 | tok/s 34170
step   2870 | loss 1.3484 | lr 6.88e-04 | grad 0.86 | tok/s 33173
step   2880 | loss 1.5775 | lr 6.88e-04 | grad 2.78 | tok/s 33241
step   2890 | loss 1.4111 | lr 6.88e-04 | grad 0.69 | tok/s 33815
step   2900 | loss 1.4174 | lr 6.88e-04 | grad 0.77 | tok/s 33468
step   2910 | loss 1.4183 | lr 6.88e-04 | grad 1.11 | tok/s 33297
step   2920 | loss 1.4104 | lr 6.88e-04 | grad 0.96 | tok/s 33408
step   2930 | loss 1.5127 | lr 6.88e-04 | grad 1.34 | tok/s 33126
step   2940 | loss 1.4007 | lr 6.88e-04 | grad 0.79 | tok/s 33440
step   2950 | loss 1.4000 | lr 6.88e-04 | grad 0.64 | tok/s 34143
step   2960 | loss 1.3213 | lr 6.88e-04 | grad 0.67 | tok/s 33703
step   2970 | loss 1.3475 | lr 6.88e-04 | grad 2.16 | tok/s 33814
step   2980 | loss 1.3743 | lr 6.88e-04 | grad 0.95 | tok/s 33595
step   2990 | loss 1.4393 | lr 6.88e-04 | grad 1.34 | tok/s 33834
step   3000 | loss 1.4160 | lr 6.88e-04 | grad 0.73 | tok/s 33531
  >>> saved checkpoint: checkpoint_step_003000_loss_1.4160.pt
step   3010 | loss 1.4886 | lr 6.88e-04 | grad 1.66 | tok/s 23471
step   3020 | loss 1.3346 | lr 6.88e-04 | grad 0.89 | tok/s 33585
step   3030 | loss 1.3196 | lr 6.88e-04 | grad 0.60 | tok/s 33209
step   3040 | loss 1.3542 | lr 6.88e-04 | grad 0.73 | tok/s 33828
step   3050 | loss 1.2919 | lr 6.88e-04 | grad 0.69 | tok/s 34185
step   3060 | loss 1.3781 | lr 6.88e-04 | grad 0.71 | tok/s 33415
step   3070 | loss 1.3418 | lr 6.88e-04 | grad 0.56 | tok/s 33377
step   3080 | loss 1.3524 | lr 6.88e-04 | grad 0.62 | tok/s 33368
step   3090 | loss 1.6262 | lr 6.88e-04 | grad 3.28 | tok/s 33790
step   3100 | loss 1.6555 | lr 6.88e-04 | grad 1.84 | tok/s 34906
step   3110 | loss 1.3584 | lr 6.88e-04 | grad 1.88 | tok/s 34899
step   3120 | loss 1.4630 | lr 6.88e-04 | grad 0.88 | tok/s 33612
step   3130 | loss 2.0821 | lr 6.88e-04 | grad 0.75 | tok/s 33184
step   3140 | loss 1.2667 | lr 6.88e-04 | grad 0.89 | tok/s 33871
step   3150 | loss 1.6318 | lr 6.88e-04 | grad 2.61 | tok/s 33782
step   3160 | loss 1.3801 | lr 6.88e-04 | grad 1.09 | tok/s 33280
step   3170 | loss 1.6061 | lr 6.88e-04 | grad 0.94 | tok/s 34242
step   3180 | loss 1.3647 | lr 6.88e-04 | grad 0.93 | tok/s 34306
step   3190 | loss 1.4072 | lr 6.88e-04 | grad 0.73 | tok/s 33750
step   3200 | loss 1.4889 | lr 6.88e-04 | grad 0.96 | tok/s 32756
step   3210 | loss 1.4289 | lr 6.88e-04 | grad 0.57 | tok/s 31861
step   3220 | loss 1.2331 | lr 6.88e-04 | grad 0.67 | tok/s 33443
step   3230 | loss 1.4787 | lr 6.88e-04 | grad 1.20 | tok/s 33692
step   3240 | loss 1.4146 | lr 6.88e-04 | grad 0.61 | tok/s 33545
step   3250 | loss 1.4171 | lr 6.88e-04 | grad 1.74 | tok/s 34700
step   3260 | loss 1.4274 | lr 6.88e-04 | grad 0.63 | tok/s 33197
step   3270 | loss 1.4007 | lr 6.88e-04 | grad 0.75 | tok/s 33871
step   3280 | loss 1.4798 | lr 6.88e-04 | grad 1.15 | tok/s 33522
step   3290 | loss 1.4147 | lr 6.88e-04 | grad 0.88 | tok/s 33810
step   3300 | loss 1.4024 | lr 6.88e-04 | grad 0.80 | tok/s 32865
step   3310 | loss 1.4169 | lr 6.88e-04 | grad 1.09 | tok/s 32261
step   3320 | loss 1.3909 | lr 6.88e-04 | grad 0.66 | tok/s 34891
step   3330 | loss 1.3388 | lr 6.88e-04 | grad 0.78 | tok/s 34334
step   3340 | loss 1.3142 | lr 6.88e-04 | grad 1.34 | tok/s 33362
step   3350 | loss 1.4750 | lr 6.88e-04 | grad 3.67 | tok/s 34146
step   3360 | loss 1.4503 | lr 6.88e-04 | grad 0.59 | tok/s 33388
step   3370 | loss 1.2735 | lr 6.88e-04 | grad 0.51 | tok/s 32915
step   3380 | loss 1.3793 | lr 6.88e-04 | grad 1.12 | tok/s 33989
step   3390 | loss 1.3868 | lr 6.88e-04 | grad 0.77 | tok/s 33906
step   3400 | loss 1.8832 | lr 6.88e-04 | grad 1.73 | tok/s 33860
step   3410 | loss 1.3636 | lr 6.88e-04 | grad 0.84 | tok/s 33712
step   3420 | loss 1.4939 | lr 6.88e-04 | grad 0.75 | tok/s 33778
step   3430 | loss 1.1697 | lr 6.88e-04 | grad 1.42 | tok/s 34523
step   3440 | loss 1.4007 | lr 6.88e-04 | grad 0.79 | tok/s 32652
step   3450 | loss 1.4703 | lr 6.88e-04 | grad 0.77 | tok/s 33212
step   3460 | loss 1.3861 | lr 6.88e-04 | grad 0.96 | tok/s 33909
step   3470 | loss 1.6194 | lr 6.88e-04 | grad 0.68 | tok/s 33246
step   3480 | loss 1.4115 | lr 6.88e-04 | grad 1.30 | tok/s 33356
step   3490 | loss 1.2978 | lr 6.88e-04 | grad 0.75 | tok/s 33354
step   3500 | loss 1.4160 | lr 6.88e-04 | grad 1.12 | tok/s 33509
step   3510 | loss 1.4081 | lr 6.88e-04 | grad 0.68 | tok/s 32957
step   3520 | loss 1.4077 | lr 6.88e-04 | grad 0.59 | tok/s 33933
step   3530 | loss 1.4242 | lr 6.88e-04 | grad 0.68 | tok/s 33684
step   3540 | loss 1.3702 | lr 6.88e-04 | grad 0.84 | tok/s 33250
step   3550 | loss 1.5239 | lr 6.88e-04 | grad 0.91 | tok/s 33797
step   3560 | loss 1.4615 | lr 6.88e-04 | grad 0.86 | tok/s 32865
step   3570 | loss 1.3994 | lr 6.88e-04 | grad 0.80 | tok/s 33612
step   3580 | loss 1.3417 | lr 6.88e-04 | grad 1.14 | tok/s 33810
step   3590 | loss 1.3894 | lr 6.88e-04 | grad 1.23 | tok/s 34574
step   3600 | loss 1.2649 | lr 6.88e-04 | grad 0.82 | tok/s 34843
step   3610 | loss 1.2483 | lr 6.88e-04 | grad 0.86 | tok/s 34875
step   3620 | loss 1.2033 | lr 6.88e-04 | grad 0.48 | tok/s 34883
step   3630 | loss 1.1825 | lr 6.88e-04 | grad 1.12 | tok/s 34891
step   3640 | loss 1.1838 | lr 6.88e-04 | grad 0.54 | tok/s 34897
step   3650 | loss 1.3096 | lr 6.88e-04 | grad 1.35 | tok/s 33510
step   3660 | loss 1.5296 | lr 6.88e-04 | grad 0.79 | tok/s 33858
step   3670 | loss 1.2792 | lr 6.88e-04 | grad 0.67 | tok/s 34145
step   3680 | loss 1.2928 | lr 6.88e-04 | grad 0.93 | tok/s 33369
step   3690 | loss 1.3052 | lr 6.88e-04 | grad 1.12 | tok/s 33544
step   3700 | loss 1.3409 | lr 6.88e-04 | grad 1.02 | tok/s 34052
step   3710 | loss 1.3626 | lr 6.88e-04 | grad 1.62 | tok/s 34581
step   3720 | loss 1.3246 | lr 6.88e-04 | grad 2.30 | tok/s 33756
step   3730 | loss 1.3907 | lr 6.88e-04 | grad 1.13 | tok/s 34310
step   3740 | loss 1.4972 | lr 6.88e-04 | grad 0.64 | tok/s 33813
step   3750 | loss 1.3490 | lr 6.88e-04 | grad 0.77 | tok/s 34496
step   3760 | loss 1.3013 | lr 6.88e-04 | grad 1.03 | tok/s 33294
step   3770 | loss 1.4326 | lr 6.88e-04 | grad 2.67 | tok/s 33504
step   3780 | loss 1.2774 | lr 6.88e-04 | grad 0.79 | tok/s 33444

Training complete! Final step: 3786
