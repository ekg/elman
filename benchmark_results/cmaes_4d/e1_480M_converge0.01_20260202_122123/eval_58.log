Using device: cuda
Output directory: benchmark_results/cmaes_4d/e1_480M_converge0.01_20260202_122123/eval_58/level1_100m_20260202_155358
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 84,182,016 parameters
Using schedule-free AdamW (lr=0.00033249651861679604)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 3.6193 | lr 3.32e-04 | grad 6.72 | tok/s 24175
step     20 | loss 3.3685 | lr 3.32e-04 | grad 7.53 | tok/s 70184
step     30 | loss 2.9720 | lr 3.32e-04 | grad 3.20 | tok/s 64629
step     40 | loss 2.2879 | lr 3.32e-04 | grad 2.66 | tok/s 65092
step     50 | loss 1.9899 | lr 3.32e-04 | grad 1.49 | tok/s 64937
step     60 | loss 2.5656 | lr 3.32e-04 | grad 2.22 | tok/s 65942
step     70 | loss 2.3070 | lr 3.32e-04 | grad 4.16 | tok/s 64350
step     80 | loss 2.2568 | lr 3.32e-04 | grad 1.73 | tok/s 65199
step     90 | loss 2.2463 | lr 3.32e-04 | grad 1.61 | tok/s 71388
step    100 | loss 1.7772 | lr 3.32e-04 | grad 1.41 | tok/s 73091
step    110 | loss 2.1529 | lr 3.32e-04 | grad 1.65 | tok/s 71944
step    120 | loss 2.1329 | lr 3.32e-04 | grad 1.67 | tok/s 72771
step    130 | loss 1.9409 | lr 3.32e-04 | grad 1.68 | tok/s 74496
step    140 | loss 1.7806 | lr 3.32e-04 | grad 2.36 | tok/s 70949
step    150 | loss 1.8535 | lr 3.32e-04 | grad 1.46 | tok/s 71602
step    160 | loss 1.8426 | lr 3.32e-04 | grad 1.38 | tok/s 70488
step    170 | loss 1.9836 | lr 3.32e-04 | grad 2.95 | tok/s 73948
step    180 | loss 1.6965 | lr 3.32e-04 | grad 1.56 | tok/s 73619
step    190 | loss 1.4500 | lr 3.32e-04 | grad 1.12 | tok/s 72553
step    200 | loss 1.6589 | lr 3.32e-04 | grad 1.88 | tok/s 71541
step    210 | loss 1.8068 | lr 3.32e-04 | grad 2.14 | tok/s 73336
step    220 | loss 1.7536 | lr 3.32e-04 | grad 2.59 | tok/s 71512
step    230 | loss 1.6578 | lr 3.32e-04 | grad 2.05 | tok/s 73403
step    240 | loss 1.7365 | lr 3.32e-04 | grad 1.90 | tok/s 74675
step    250 | loss 1.8219 | lr 3.32e-04 | grad 1.50 | tok/s 73140
step    260 | loss 1.6522 | lr 3.32e-04 | grad 2.05 | tok/s 71518
step    270 | loss 1.6871 | lr 3.32e-04 | grad 2.23 | tok/s 73009
step    280 | loss 1.4902 | lr 3.32e-04 | grad 1.51 | tok/s 75319
step    290 | loss 1.3765 | lr 3.32e-04 | grad 1.47 | tok/s 74725
step    300 | loss 1.3879 | lr 3.32e-04 | grad 1.09 | tok/s 75331
step    310 | loss 1.4963 | lr 3.32e-04 | grad 2.47 | tok/s 75512
step    320 | loss 1.7076 | lr 3.32e-04 | grad 1.48 | tok/s 70431
step    330 | loss 1.6984 | lr 3.32e-04 | grad 3.19 | tok/s 74540
step    340 | loss 1.6669 | lr 3.32e-04 | grad 1.62 | tok/s 70465
step    350 | loss 1.6283 | lr 3.32e-04 | grad 1.45 | tok/s 71270
step    360 | loss 1.5268 | lr 3.32e-04 | grad 1.18 | tok/s 74126
step    370 | loss 1.9196 | lr 3.32e-04 | grad 2.06 | tok/s 73852
step    380 | loss 1.6055 | lr 3.32e-04 | grad 1.81 | tok/s 75541
step    390 | loss 1.5780 | lr 3.32e-04 | grad 1.27 | tok/s 72522
step    400 | loss 1.5838 | lr 3.32e-04 | grad 1.49 | tok/s 73108
step    410 | loss 1.5912 | lr 3.32e-04 | grad 1.77 | tok/s 71115
step    420 | loss 1.6516 | lr 3.32e-04 | grad 2.23 | tok/s 72263
step    430 | loss 1.7132 | lr 3.32e-04 | grad 2.84 | tok/s 74584
step    440 | loss 1.6148 | lr 3.32e-04 | grad 1.48 | tok/s 73204
step    450 | loss 1.5804 | lr 3.32e-04 | grad 1.67 | tok/s 73110
step    460 | loss 1.6000 | lr 3.32e-04 | grad 2.33 | tok/s 72940
step    470 | loss 1.4895 | lr 3.32e-04 | grad 1.29 | tok/s 70796
step    480 | loss 1.4970 | lr 3.32e-04 | grad 1.35 | tok/s 72088
step    490 | loss 1.9523 | lr 3.32e-04 | grad 2.38 | tok/s 74532
step    500 | loss 1.5512 | lr 3.32e-04 | grad 3.42 | tok/s 72766
step    510 | loss 1.3797 | lr 3.32e-04 | grad 1.44 | tok/s 73507
step    520 | loss 1.9878 | lr 3.32e-04 | grad 1.97 | tok/s 73624
step    530 | loss 1.4155 | lr 3.32e-04 | grad 1.24 | tok/s 74234
step    540 | loss 1.4391 | lr 3.32e-04 | grad 1.22 | tok/s 74003
step    550 | loss 1.2848 | lr 3.32e-04 | grad 1.15 | tok/s 76037
step    560 | loss 1.4305 | lr 3.32e-04 | grad 5.09 | tok/s 73277
step    570 | loss 1.8477 | lr 3.32e-04 | grad 1.98 | tok/s 75058
step    580 | loss 1.9509 | lr 3.32e-04 | grad 3.09 | tok/s 72109
step    590 | loss 1.4851 | lr 3.32e-04 | grad 2.41 | tok/s 70217
step    600 | loss 1.5384 | lr 3.32e-04 | grad 1.84 | tok/s 76178
step    610 | loss 1.4783 | lr 3.32e-04 | grad 1.61 | tok/s 72297
step    620 | loss 1.4155 | lr 3.32e-04 | grad 1.33 | tok/s 74954
step    630 | loss 1.5904 | lr 3.32e-04 | grad 1.73 | tok/s 75144
step    640 | loss 1.4994 | lr 3.32e-04 | grad 1.72 | tok/s 73206
step    650 | loss 1.6450 | lr 3.32e-04 | grad 6.25 | tok/s 72378
step    660 | loss 1.6059 | lr 3.32e-04 | grad 2.44 | tok/s 74126
step    670 | loss 1.5961 | lr 3.32e-04 | grad 2.38 | tok/s 71993
step    680 | loss 1.5575 | lr 3.32e-04 | grad 2.31 | tok/s 70659
step    690 | loss 1.6733 | lr 3.32e-04 | grad 3.25 | tok/s 72998
step    700 | loss 1.5480 | lr 3.32e-04 | grad 1.50 | tok/s 74120
step    710 | loss 1.5410 | lr 3.32e-04 | grad 4.75 | tok/s 73408
step    720 | loss 1.6380 | lr 3.32e-04 | grad 2.19 | tok/s 73589
step    730 | loss 1.6390 | lr 3.32e-04 | grad 4.25 | tok/s 73548
step    740 | loss 1.4519 | lr 3.32e-04 | grad 1.95 | tok/s 70839
step    750 | loss 1.6889 | lr 3.32e-04 | grad 1.52 | tok/s 73432
step    760 | loss 1.4798 | lr 3.32e-04 | grad 1.22 | tok/s 73092
step    770 | loss 1.5555 | lr 3.32e-04 | grad 1.65 | tok/s 73901
step    780 | loss 1.4152 | lr 3.32e-04 | grad 1.33 | tok/s 73055
step    790 | loss 1.4430 | lr 3.32e-04 | grad 3.39 | tok/s 74022
step    800 | loss 1.4410 | lr 3.32e-04 | grad 2.05 | tok/s 70347
step    810 | loss 2.1811 | lr 3.32e-04 | grad 1.95 | tok/s 75691
step    820 | loss 1.7139 | lr 3.32e-04 | grad 1.72 | tok/s 74951
step    830 | loss 1.4904 | lr 3.32e-04 | grad 1.61 | tok/s 74706
step    840 | loss 1.6041 | lr 3.32e-04 | grad 1.38 | tok/s 71354
step    850 | loss 1.4668 | lr 3.32e-04 | grad 1.38 | tok/s 73664
step    860 | loss 1.4746 | lr 3.32e-04 | grad 2.11 | tok/s 71518
step    870 | loss 1.5317 | lr 3.32e-04 | grad 1.34 | tok/s 73277
step    880 | loss 1.4590 | lr 3.32e-04 | grad 2.55 | tok/s 70884
step    890 | loss 1.7664 | lr 3.32e-04 | grad 1.73 | tok/s 72027
step    900 | loss 1.4118 | lr 3.32e-04 | grad 1.77 | tok/s 70782
step    910 | loss 1.5300 | lr 3.32e-04 | grad 1.45 | tok/s 72131
step    920 | loss 1.4767 | lr 3.32e-04 | grad 1.98 | tok/s 70986
step    930 | loss 1.5501 | lr 3.32e-04 | grad 2.06 | tok/s 70895
step    940 | loss 1.5044 | lr 3.32e-04 | grad 1.22 | tok/s 69560
step    950 | loss 1.2934 | lr 3.32e-04 | grad 1.09 | tok/s 75571
step    960 | loss 1.2295 | lr 3.32e-04 | grad 1.02 | tok/s 75843
step    970 | loss 1.4574 | lr 3.32e-04 | grad 1.91 | tok/s 73507
step    980 | loss 1.5952 | lr 3.32e-04 | grad 2.70 | tok/s 72345
step    990 | loss 1.5700 | lr 3.32e-04 | grad 2.48 | tok/s 73715
step   1000 | loss 1.4695 | lr 3.32e-04 | grad 1.80 | tok/s 73857
  >>> saved checkpoint: checkpoint_step_001000_loss_1.4695.pt
step   1010 | loss 1.4322 | lr 3.32e-04 | grad 1.61 | tok/s 57656
step   1020 | loss 1.7050 | lr 3.32e-04 | grad 1.54 | tok/s 72159
step   1030 | loss 1.5265 | lr 3.32e-04 | grad 2.06 | tok/s 72244
step   1040 | loss 1.3879 | lr 3.32e-04 | grad 2.86 | tok/s 71570
step   1050 | loss 1.6683 | lr 3.32e-04 | grad 2.14 | tok/s 75156
step   1060 | loss 2.0141 | lr 3.32e-04 | grad 3.41 | tok/s 73592
step   1070 | loss 1.5980 | lr 3.32e-04 | grad 2.83 | tok/s 71553
step   1080 | loss 1.6969 | lr 3.32e-04 | grad 1.77 | tok/s 73188
step   1090 | loss 1.4092 | lr 3.32e-04 | grad 1.70 | tok/s 75038
step   1100 | loss 1.5301 | lr 3.32e-04 | grad 3.70 | tok/s 74669
step   1110 | loss 1.5067 | lr 3.32e-04 | grad 1.57 | tok/s 71679
step   1120 | loss 1.5361 | lr 3.32e-04 | grad 1.54 | tok/s 72535
step   1130 | loss 1.5456 | lr 3.32e-04 | grad 2.23 | tok/s 73929
step   1140 | loss 1.6293 | lr 3.32e-04 | grad 1.25 | tok/s 70926
step   1150 | loss 1.5011 | lr 3.32e-04 | grad 1.41 | tok/s 71913
step   1160 | loss 1.4977 | lr 3.32e-04 | grad 1.27 | tok/s 74789
step   1170 | loss 1.3746 | lr 3.32e-04 | grad 1.30 | tok/s 76091
step   1180 | loss 1.3028 | lr 3.32e-04 | grad 1.38 | tok/s 76339
step   1190 | loss 1.2479 | lr 3.32e-04 | grad 1.24 | tok/s 76147
step   1200 | loss 1.2418 | lr 3.32e-04 | grad 1.17 | tok/s 75736
step   1210 | loss 1.4686 | lr 3.32e-04 | grad 1.62 | tok/s 74531
step   1220 | loss 1.3163 | lr 3.32e-04 | grad 1.70 | tok/s 71342
step   1230 | loss 1.5233 | lr 3.32e-04 | grad 2.25 | tok/s 73319
step   1240 | loss 1.4845 | lr 3.32e-04 | grad 2.62 | tok/s 73967
step   1250 | loss 1.6650 | lr 3.32e-04 | grad 2.06 | tok/s 74399
step   1260 | loss 1.5072 | lr 3.32e-04 | grad 1.46 | tok/s 73121
step   1270 | loss 1.5673 | lr 3.32e-04 | grad 1.78 | tok/s 72480
step   1280 | loss 1.5417 | lr 3.32e-04 | grad 2.48 | tok/s 73174
step   1290 | loss 1.5589 | lr 3.32e-04 | grad 1.51 | tok/s 72696
step   1300 | loss 1.5063 | lr 3.32e-04 | grad 1.43 | tok/s 71587
step   1310 | loss 1.5487 | lr 3.32e-04 | grad 2.19 | tok/s 73049
step   1320 | loss 1.3768 | lr 3.32e-04 | grad 1.51 | tok/s 73915
step   1330 | loss 1.3636 | lr 3.32e-04 | grad 1.46 | tok/s 72502
step   1340 | loss 1.4472 | lr 3.32e-04 | grad 1.37 | tok/s 73579
step   1350 | loss 1.4368 | lr 3.32e-04 | grad 1.52 | tok/s 72050
step   1360 | loss 1.6221 | lr 3.32e-04 | grad 2.34 | tok/s 74271
step   1370 | loss 1.4476 | lr 3.32e-04 | grad 1.72 | tok/s 71121
step   1380 | loss 1.4500 | lr 3.32e-04 | grad 1.52 | tok/s 74043
step   1390 | loss 1.4664 | lr 3.32e-04 | grad 1.85 | tok/s 74097
step   1400 | loss 1.5091 | lr 3.32e-04 | grad 1.88 | tok/s 70374
step   1410 | loss 1.4727 | lr 3.32e-04 | grad 1.48 | tok/s 70610
step   1420 | loss 1.3041 | lr 3.32e-04 | grad 1.41 | tok/s 71578
step   1430 | loss 1.2938 | lr 3.32e-04 | grad 2.84 | tok/s 75428
step   1440 | loss 1.4322 | lr 3.32e-04 | grad 1.40 | tok/s 71716
step   1450 | loss 1.5842 | lr 3.32e-04 | grad 2.30 | tok/s 72891
step   1460 | loss 1.4498 | lr 3.32e-04 | grad 1.70 | tok/s 73093
step   1470 | loss 1.3972 | lr 3.32e-04 | grad 2.53 | tok/s 73554
step   1480 | loss 1.6201 | lr 3.32e-04 | grad 2.45 | tok/s 72287
step   1490 | loss 1.6146 | lr 3.32e-04 | grad 1.92 | tok/s 73489
step   1500 | loss 1.4949 | lr 3.32e-04 | grad 1.91 | tok/s 74262
step   1510 | loss 1.4723 | lr 3.32e-04 | grad 2.30 | tok/s 74389
step   1520 | loss 1.4028 | lr 3.32e-04 | grad 1.49 | tok/s 70836
step   1530 | loss 1.2898 | lr 3.32e-04 | grad 1.34 | tok/s 75141
step   1540 | loss 1.8993 | lr 3.32e-04 | grad 1.56 | tok/s 73771
step   1550 | loss 1.4835 | lr 3.32e-04 | grad 1.90 | tok/s 70639
step   1560 | loss 1.4994 | lr 3.32e-04 | grad 1.74 | tok/s 74697
step   1570 | loss 1.4414 | lr 3.32e-04 | grad 1.74 | tok/s 72122
step   1580 | loss 1.4930 | lr 3.32e-04 | grad 1.46 | tok/s 71548
step   1590 | loss 1.3324 | lr 3.32e-04 | grad 1.91 | tok/s 75724
step   1600 | loss 1.4608 | lr 3.32e-04 | grad 1.56 | tok/s 74185
step   1610 | loss 1.4508 | lr 3.32e-04 | grad 1.65 | tok/s 74438
step   1620 | loss 1.3953 | lr 3.32e-04 | grad 1.72 | tok/s 72728
step   1630 | loss 1.4694 | lr 3.32e-04 | grad 4.50 | tok/s 71596
step   1640 | loss 1.4645 | lr 3.32e-04 | grad 1.98 | tok/s 71055
step   1650 | loss 1.4409 | lr 3.32e-04 | grad 2.86 | tok/s 74370
step   1660 | loss 1.7150 | lr 3.32e-04 | grad 1.46 | tok/s 74854
step   1670 | loss 1.4041 | lr 3.32e-04 | grad 1.84 | tok/s 71768
step   1680 | loss 1.4622 | lr 3.32e-04 | grad 1.62 | tok/s 74284
step   1690 | loss 1.5381 | lr 3.32e-04 | grad 1.66 | tok/s 72974
step   1700 | loss 1.4364 | lr 3.32e-04 | grad 1.72 | tok/s 72333
step   1710 | loss 1.5635 | lr 3.32e-04 | grad 2.19 | tok/s 70691
step   1720 | loss 1.4910 | lr 3.32e-04 | grad 1.43 | tok/s 74417
step   1730 | loss 1.4606 | lr 3.32e-04 | grad 1.49 | tok/s 69577
step   1740 | loss 1.5772 | lr 3.32e-04 | grad 1.45 | tok/s 70351
step   1750 | loss 1.5418 | lr 3.32e-04 | grad 1.32 | tok/s 72430
step   1760 | loss 1.4698 | lr 3.32e-04 | grad 1.69 | tok/s 71360
step   1770 | loss 1.6111 | lr 3.32e-04 | grad 2.06 | tok/s 72124
step   1780 | loss 1.3879 | lr 3.32e-04 | grad 1.29 | tok/s 73590
step   1790 | loss 1.4517 | lr 3.32e-04 | grad 1.61 | tok/s 73359
step   1800 | loss 1.3614 | lr 3.32e-04 | grad 1.60 | tok/s 70415
step   1810 | loss 1.4377 | lr 3.32e-04 | grad 1.30 | tok/s 72795
step   1820 | loss 1.5224 | lr 3.32e-04 | grad 4.78 | tok/s 72795
step   1830 | loss 1.5453 | lr 3.32e-04 | grad 1.60 | tok/s 72494
step   1840 | loss 1.3934 | lr 3.32e-04 | grad 1.53 | tok/s 70798
step   1850 | loss 1.4017 | lr 3.32e-04 | grad 2.80 | tok/s 75559
step   1860 | loss 1.4342 | lr 3.32e-04 | grad 1.82 | tok/s 74699
step   1870 | loss 1.5239 | lr 3.32e-04 | grad 2.66 | tok/s 72743
step   1880 | loss 1.4727 | lr 3.32e-04 | grad 2.59 | tok/s 72657
step   1890 | loss 1.6005 | lr 3.32e-04 | grad 2.38 | tok/s 72862
step   1900 | loss 1.3247 | lr 3.32e-04 | grad 1.56 | tok/s 74153
step   1910 | loss 1.3415 | lr 3.32e-04 | grad 1.35 | tok/s 74464
step   1920 | loss 1.4053 | lr 3.32e-04 | grad 1.75 | tok/s 75742
step   1930 | loss 1.4414 | lr 3.32e-04 | grad 2.12 | tok/s 74871
step   1940 | loss 1.5439 | lr 3.32e-04 | grad 1.87 | tok/s 74367
step   1950 | loss 1.3515 | lr 3.32e-04 | grad 1.47 | tok/s 72804
step   1960 | loss 1.5445 | lr 3.32e-04 | grad 2.44 | tok/s 73365
step   1970 | loss 1.4107 | lr 3.32e-04 | grad 1.21 | tok/s 71668
step   1980 | loss 1.4521 | lr 3.32e-04 | grad 2.14 | tok/s 72434
step   1990 | loss 1.1883 | lr 3.32e-04 | grad 1.17 | tok/s 76140
step   2000 | loss 1.1730 | lr 3.32e-04 | grad 1.37 | tok/s 76360
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1730.pt
step   2010 | loss 1.4139 | lr 3.32e-04 | grad 1.55 | tok/s 60811
step   2020 | loss 1.2288 | lr 3.32e-04 | grad 1.21 | tok/s 76779
step   2030 | loss 1.2938 | lr 3.32e-04 | grad 1.60 | tok/s 74732
step   2040 | loss 1.5500 | lr 3.32e-04 | grad 1.39 | tok/s 69822
step   2050 | loss 1.4166 | lr 3.32e-04 | grad 1.46 | tok/s 73739
step   2060 | loss 1.5194 | lr 3.32e-04 | grad 1.41 | tok/s 70968
step   2070 | loss 1.4376 | lr 3.32e-04 | grad 1.80 | tok/s 73616
step   2080 | loss 1.4398 | lr 3.32e-04 | grad 2.03 | tok/s 69775
step   2090 | loss 1.2857 | lr 3.32e-04 | grad 4.34 | tok/s 75013
step   2100 | loss 1.1468 | lr 3.32e-04 | grad 1.76 | tok/s 74096
step   2110 | loss 1.5414 | lr 3.32e-04 | grad 1.70 | tok/s 73427
step   2120 | loss 1.5087 | lr 3.32e-04 | grad 1.41 | tok/s 72842
step   2130 | loss 1.5008 | lr 3.32e-04 | grad 1.49 | tok/s 71659
step   2140 | loss 1.4392 | lr 3.32e-04 | grad 1.30 | tok/s 72875
step   2150 | loss 1.5892 | lr 3.32e-04 | grad 1.86 | tok/s 73232
step   2160 | loss 1.5984 | lr 3.32e-04 | grad 2.12 | tok/s 74744
step   2170 | loss 1.3174 | lr 3.32e-04 | grad 1.46 | tok/s 73561
step   2180 | loss 1.1916 | lr 3.32e-04 | grad 1.37 | tok/s 76470
step   2190 | loss 1.2110 | lr 3.32e-04 | grad 1.27 | tok/s 76519
step   2200 | loss 1.1897 | lr 3.32e-04 | grad 1.23 | tok/s 74439
step   2210 | loss 1.3936 | lr 3.32e-04 | grad 1.37 | tok/s 71646
step   2220 | loss 1.4540 | lr 3.32e-04 | grad 2.61 | tok/s 75596
step   2230 | loss 1.5159 | lr 3.32e-04 | grad 4.09 | tok/s 74338
step   2240 | loss 1.4078 | lr 3.32e-04 | grad 1.30 | tok/s 74071
step   2250 | loss 1.4192 | lr 3.32e-04 | grad 2.02 | tok/s 73541
step   2260 | loss 1.4987 | lr 3.32e-04 | grad 1.56 | tok/s 70060
step   2270 | loss 1.3937 | lr 3.32e-04 | grad 1.41 | tok/s 72220
step   2280 | loss 1.4479 | lr 3.32e-04 | grad 1.48 | tok/s 73307
step   2290 | loss 1.3821 | lr 3.32e-04 | grad 1.27 | tok/s 76439
step   2300 | loss 1.3120 | lr 3.32e-04 | grad 1.16 | tok/s 74273
step   2310 | loss 1.2837 | lr 3.32e-04 | grad 1.35 | tok/s 75390
step   2320 | loss 1.4814 | lr 3.32e-04 | grad 1.97 | tok/s 73783
step   2330 | loss 1.5047 | lr 3.32e-04 | grad 2.69 | tok/s 73434
step   2340 | loss 1.7913 | lr 3.32e-04 | grad 2.56 | tok/s 74258
step   2350 | loss 1.3936 | lr 3.32e-04 | grad 2.14 | tok/s 74635
step   2360 | loss 1.4063 | lr 3.32e-04 | grad 1.23 | tok/s 72078
step   2370 | loss 1.3960 | lr 3.32e-04 | grad 3.16 | tok/s 71958
step   2380 | loss 1.4672 | lr 3.32e-04 | grad 2.38 | tok/s 72527
step   2390 | loss 1.4732 | lr 3.32e-04 | grad 1.48 | tok/s 72475
step   2400 | loss 1.4130 | lr 3.32e-04 | grad 1.96 | tok/s 71667
step   2410 | loss 1.5471 | lr 3.32e-04 | grad 1.94 | tok/s 74129
step   2420 | loss 1.3695 | lr 3.32e-04 | grad 1.36 | tok/s 73118
step   2430 | loss 1.3784 | lr 3.32e-04 | grad 1.45 | tok/s 74053
step   2440 | loss 1.3143 | lr 3.32e-04 | grad 1.97 | tok/s 75152
step   2450 | loss 1.2969 | lr 3.32e-04 | grad 1.55 | tok/s 74564
step   2460 | loss 1.3428 | lr 3.32e-04 | grad 1.45 | tok/s 71598
step   2470 | loss 1.3977 | lr 3.32e-04 | grad 5.47 | tok/s 73726
step   2480 | loss 1.4429 | lr 3.32e-04 | grad 1.38 | tok/s 73330
step   2490 | loss 1.5648 | lr 3.32e-04 | grad 1.88 | tok/s 72822
step   2500 | loss 1.5053 | lr 3.32e-04 | grad 1.46 | tok/s 71789
step   2510 | loss 1.4909 | lr 3.32e-04 | grad 3.06 | tok/s 71735
step   2520 | loss 1.4298 | lr 3.32e-04 | grad 1.88 | tok/s 70892
step   2530 | loss 1.8745 | lr 3.32e-04 | grad 1.73 | tok/s 74933
step   2540 | loss 1.3865 | lr 3.32e-04 | grad 1.58 | tok/s 73171
step   2550 | loss 1.6523 | lr 3.32e-04 | grad 4.44 | tok/s 73547
step   2560 | loss 1.3326 | lr 3.32e-04 | grad 1.69 | tok/s 70911
step   2570 | loss 1.4670 | lr 3.32e-04 | grad 1.44 | tok/s 72254
step   2580 | loss 1.4156 | lr 3.32e-04 | grad 1.77 | tok/s 74630
step   2590 | loss 1.3429 | lr 3.32e-04 | grad 1.36 | tok/s 76394
step   2600 | loss 1.2836 | lr 3.32e-04 | grad 1.55 | tok/s 74401
step   2610 | loss 1.4699 | lr 3.32e-04 | grad 1.45 | tok/s 67305
step   2620 | loss 1.4357 | lr 3.32e-04 | grad 1.29 | tok/s 70184
step   2630 | loss 1.7084 | lr 3.32e-04 | grad 1.86 | tok/s 72230
step   2640 | loss 1.3623 | lr 3.32e-04 | grad 1.09 | tok/s 75739
step   2650 | loss 1.2690 | lr 3.32e-04 | grad 1.38 | tok/s 76431
step   2660 | loss 1.2774 | lr 3.32e-04 | grad 1.61 | tok/s 76268
step   2670 | loss 1.3891 | lr 3.32e-04 | grad 1.58 | tok/s 73829
step   2680 | loss 1.4373 | lr 3.32e-04 | grad 2.42 | tok/s 71978
step   2690 | loss 1.8001 | lr 3.32e-04 | grad 2.42 | tok/s 72245
step   2700 | loss 1.4951 | lr 3.32e-04 | grad 2.02 | tok/s 70211
step   2710 | loss 1.3018 | lr 3.32e-04 | grad 2.94 | tok/s 74290
step   2720 | loss 1.4253 | lr 3.32e-04 | grad 1.75 | tok/s 73087
step   2730 | loss 1.4978 | lr 3.32e-04 | grad 1.30 | tok/s 72140
step   2740 | loss 1.5677 | lr 3.32e-04 | grad 1.48 | tok/s 71539
step   2750 | loss 1.4005 | lr 3.32e-04 | grad 1.84 | tok/s 73020
step   2760 | loss 1.3222 | lr 3.32e-04 | grad 1.42 | tok/s 72597
step   2770 | loss 1.6935 | lr 3.32e-04 | grad 3.22 | tok/s 74002
step   2780 | loss 1.5748 | lr 3.32e-04 | grad 2.11 | tok/s 74420
step   2790 | loss 1.4610 | lr 3.32e-04 | grad 1.89 | tok/s 73272
step   2800 | loss 1.4936 | lr 3.32e-04 | grad 1.48 | tok/s 73154
step   2810 | loss 1.4960 | lr 3.32e-04 | grad 1.46 | tok/s 73646
step   2820 | loss 1.3463 | lr 3.32e-04 | grad 2.77 | tok/s 74341
step   2830 | loss 1.3457 | lr 3.32e-04 | grad 3.23 | tok/s 72257
step   2840 | loss 1.4414 | lr 3.32e-04 | grad 3.59 | tok/s 74104
step   2850 | loss 1.7752 | lr 3.32e-04 | grad 1.76 | tok/s 75060
step   2860 | loss 1.6137 | lr 3.32e-04 | grad 3.08 | tok/s 74444
step   2870 | loss 1.4110 | lr 3.32e-04 | grad 1.48 | tok/s 72018
step   2880 | loss 1.3875 | lr 3.32e-04 | grad 1.29 | tok/s 72305
step   2890 | loss 1.5732 | lr 3.32e-04 | grad 3.38 | tok/s 75030
step   2900 | loss 1.3832 | lr 3.32e-04 | grad 1.24 | tok/s 73786
step   2910 | loss 1.4443 | lr 3.32e-04 | grad 1.98 | tok/s 70919
step   2920 | loss 1.4456 | lr 3.32e-04 | grad 1.98 | tok/s 72333
step   2930 | loss 1.5709 | lr 3.32e-04 | grad 1.84 | tok/s 73293
step   2940 | loss 1.4100 | lr 3.32e-04 | grad 2.47 | tok/s 72527
step   2950 | loss 1.4720 | lr 3.32e-04 | grad 2.11 | tok/s 73455
step   2960 | loss 1.3788 | lr 3.32e-04 | grad 1.18 | tok/s 73747
step   2970 | loss 1.3067 | lr 3.32e-04 | grad 2.67 | tok/s 74366
step   2980 | loss 1.4579 | lr 3.32e-04 | grad 2.75 | tok/s 74499
step   2990 | loss 1.3692 | lr 3.32e-04 | grad 1.45 | tok/s 73751
step   3000 | loss 1.5187 | lr 3.32e-04 | grad 1.77 | tok/s 73915
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5187.pt
step   3010 | loss 1.3996 | lr 3.32e-04 | grad 2.09 | tok/s 57867
step   3020 | loss 1.4589 | lr 3.32e-04 | grad 1.80 | tok/s 73263
step   3030 | loss 1.3260 | lr 3.32e-04 | grad 1.23 | tok/s 72092
step   3040 | loss 1.3302 | lr 3.32e-04 | grad 1.45 | tok/s 74076
step   3050 | loss 1.3813 | lr 3.32e-04 | grad 2.03 | tok/s 74687
step   3060 | loss 1.3419 | lr 3.32e-04 | grad 1.77 | tok/s 73937
step   3070 | loss 1.4161 | lr 3.32e-04 | grad 2.44 | tok/s 70795
step   3080 | loss 1.3698 | lr 3.32e-04 | grad 3.69 | tok/s 74006
step   3090 | loss 1.3703 | lr 3.32e-04 | grad 2.31 | tok/s 72671
step   3100 | loss 1.9368 | lr 3.32e-04 | grad 2.53 | tok/s 74058
step   3110 | loss 1.5909 | lr 3.32e-04 | grad 1.61 | tok/s 74394
step   3120 | loss 1.4251 | lr 3.32e-04 | grad 2.55 | tok/s 76319
step   3130 | loss 1.4913 | lr 3.32e-04 | grad 1.57 | tok/s 68220
step   3140 | loss 1.9612 | lr 3.32e-04 | grad 1.66 | tok/s 75004
step   3150 | loss 1.5289 | lr 3.32e-04 | grad 2.16 | tok/s 73633
step   3160 | loss 1.5432 | lr 3.32e-04 | grad 1.61 | tok/s 73108
step   3170 | loss 1.4384 | lr 3.32e-04 | grad 4.12 | tok/s 73294
step   3180 | loss 1.5527 | lr 3.32e-04 | grad 1.68 | tok/s 75011
step   3190 | loss 1.4615 | lr 3.32e-04 | grad 1.72 | tok/s 75342
step   3200 | loss 1.5269 | lr 3.32e-04 | grad 1.55 | tok/s 72527
step   3210 | loss 1.4500 | lr 3.32e-04 | grad 3.92 | tok/s 70952
step   3220 | loss 1.4251 | lr 3.32e-04 | grad 1.72 | tok/s 70698
step   3230 | loss 1.2737 | lr 3.32e-04 | grad 1.56 | tok/s 71389
step   3240 | loss 1.6181 | lr 3.32e-04 | grad 1.99 | tok/s 72881
step   3250 | loss 1.3961 | lr 3.32e-04 | grad 1.91 | tok/s 73691
step   3260 | loss 1.5091 | lr 3.32e-04 | grad 5.16 | tok/s 74333
step   3270 | loss 1.4484 | lr 3.32e-04 | grad 1.64 | tok/s 72668
step   3280 | loss 1.4631 | lr 3.32e-04 | grad 1.35 | tok/s 73554
step   3290 | loss 1.4877 | lr 3.32e-04 | grad 1.88 | tok/s 70879
step   3300 | loss 1.4784 | lr 3.32e-04 | grad 2.52 | tok/s 73180
step   3310 | loss 1.3907 | lr 3.32e-04 | grad 1.48 | tok/s 70600
step   3320 | loss 1.4440 | lr 3.32e-04 | grad 1.62 | tok/s 71615
step   3330 | loss 1.3930 | lr 3.32e-04 | grad 1.27 | tok/s 76314
step   3340 | loss 1.3696 | lr 3.32e-04 | grad 4.31 | tok/s 73212
step   3350 | loss 1.3306 | lr 3.32e-04 | grad 3.20 | tok/s 74077
step   3360 | loss 1.5570 | lr 3.32e-04 | grad 2.14 | tok/s 76006
step   3370 | loss 1.3915 | lr 3.32e-04 | grad 1.91 | tok/s 69850
step   3380 | loss 1.3035 | lr 3.32e-04 | grad 1.89 | tok/s 69546
step   3390 | loss 1.4569 | lr 3.32e-04 | grad 2.05 | tok/s 74778
step   3400 | loss 1.4670 | lr 3.32e-04 | grad 2.91 | tok/s 73997
step   3410 | loss 1.9002 | lr 3.32e-04 | grad 1.64 | tok/s 73291
step   3420 | loss 1.4609 | lr 3.32e-04 | grad 1.84 | tok/s 71843
step   3430 | loss 1.4002 | lr 3.32e-04 | grad 1.44 | tok/s 75625
step   3440 | loss 1.3554 | lr 3.32e-04 | grad 1.51 | tok/s 72128
step   3450 | loss 1.5044 | lr 3.32e-04 | grad 1.39 | tok/s 71082
step   3460 | loss 1.4162 | lr 3.32e-04 | grad 2.02 | tok/s 71627
step   3470 | loss 1.5155 | lr 3.32e-04 | grad 3.31 | tok/s 73855
step   3480 | loss 1.6244 | lr 3.32e-04 | grad 2.67 | tok/s 72545
step   3490 | loss 1.4319 | lr 3.32e-04 | grad 1.47 | tok/s 73045
step   3500 | loss 1.2877 | lr 3.32e-04 | grad 1.27 | tok/s 72319
step   3510 | loss 1.4383 | lr 3.32e-04 | grad 1.80 | tok/s 73384
step   3520 | loss 1.4793 | lr 3.32e-04 | grad 1.40 | tok/s 70590
step   3530 | loss 1.4918 | lr 3.32e-04 | grad 1.56 | tok/s 74396
step   3540 | loss 1.3798 | lr 3.32e-04 | grad 2.64 | tok/s 72892
step   3550 | loss 1.4296 | lr 3.32e-04 | grad 1.36 | tok/s 73931
step   3560 | loss 1.5836 | lr 3.32e-04 | grad 2.16 | tok/s 71659
step   3570 | loss 1.4542 | lr 3.32e-04 | grad 2.17 | tok/s 72934
step   3580 | loss 1.3999 | lr 3.32e-04 | grad 1.34 | tok/s 72453
step   3590 | loss 1.3960 | lr 3.32e-04 | grad 1.70 | tok/s 75289
step   3600 | loss 1.4044 | lr 3.32e-04 | grad 1.38 | tok/s 76224
step   3610 | loss 1.2840 | lr 3.32e-04 | grad 1.08 | tok/s 76279
step   3620 | loss 1.2551 | lr 3.32e-04 | grad 1.05 | tok/s 76264
step   3630 | loss 1.2195 | lr 3.32e-04 | grad 1.16 | tok/s 76322
step   3640 | loss 1.2173 | lr 3.32e-04 | grad 1.10 | tok/s 75536
step   3650 | loss 1.2118 | lr 3.32e-04 | grad 1.48 | tok/s 76140
step   3660 | loss 1.3913 | lr 3.32e-04 | grad 2.06 | tok/s 73009
step   3670 | loss 1.6462 | lr 3.32e-04 | grad 1.49 | tok/s 71998
step   3680 | loss 1.2762 | lr 3.32e-04 | grad 1.94 | tok/s 75137
step   3690 | loss 1.3004 | lr 3.32e-04 | grad 1.88 | tok/s 72719
step   3700 | loss 1.3904 | lr 3.32e-04 | grad 1.44 | tok/s 74006
step   3710 | loss 1.3477 | lr 3.32e-04 | grad 2.17 | tok/s 74711
step   3720 | loss 1.4679 | lr 3.32e-04 | grad 1.96 | tok/s 71747
step   3730 | loss 1.3449 | lr 3.32e-04 | grad 2.89 | tok/s 74393
step   3740 | loss 1.5665 | lr 3.32e-04 | grad 3.56 | tok/s 73585
step   3750 | loss 1.3541 | lr 3.32e-04 | grad 1.54 | tok/s 74461
step   3760 | loss 1.4010 | lr 3.32e-04 | grad 2.73 | tok/s 75038
step   3770 | loss 1.2981 | lr 3.32e-04 | grad 1.55 | tok/s 72765
step   3780 | loss 1.5081 | lr 3.32e-04 | grad 1.39 | tok/s 73493
step   3790 | loss 1.3223 | lr 3.32e-04 | grad 4.03 | tok/s 72843
step   3800 | loss 1.3843 | lr 3.32e-04 | grad 1.52 | tok/s 73164
step   3810 | loss 1.4652 | lr 3.32e-04 | grad 4.62 | tok/s 73132
step   3820 | loss 1.2281 | lr 3.32e-04 | grad 1.40 | tok/s 71465
step   3830 | loss 1.3095 | lr 3.32e-04 | grad 4.12 | tok/s 72245
step   3840 | loss 1.2810 | lr 3.32e-04 | grad 1.85 | tok/s 74369
step   3850 | loss 1.2997 | lr 3.32e-04 | grad 1.80 | tok/s 72873
step   3860 | loss 1.4424 | lr 3.32e-04 | grad 2.30 | tok/s 69715
step   3870 | loss 1.4336 | lr 3.32e-04 | grad 1.99 | tok/s 71970
step   3880 | loss 1.3090 | lr 3.32e-04 | grad 2.33 | tok/s 74408
step   3890 | loss 1.3673 | lr 3.32e-04 | grad 2.19 | tok/s 72647
step   3900 | loss 1.3709 | lr 3.32e-04 | grad 1.79 | tok/s 72069
step   3910 | loss 1.3946 | lr 3.32e-04 | grad 1.40 | tok/s 70855
step   3920 | loss 1.3768 | lr 3.32e-04 | grad 1.73 | tok/s 74069
step   3930 | loss 1.3901 | lr 3.32e-04 | grad 2.16 | tok/s 73219
step   3940 | loss 1.4483 | lr 3.32e-04 | grad 1.96 | tok/s 73611
step   3950 | loss 1.3048 | lr 3.32e-04 | grad 4.50 | tok/s 74484
step   3960 | loss 1.4217 | lr 3.32e-04 | grad 1.26 | tok/s 70664
step   3970 | loss 1.3113 | lr 3.32e-04 | grad 1.38 | tok/s 70414
step   3980 | loss 1.3738 | lr 3.32e-04 | grad 1.34 | tok/s 72540
step   3990 | loss 1.2837 | lr 3.32e-04 | grad 1.36 | tok/s 72719
step   4000 | loss 1.3489 | lr 3.32e-04 | grad 1.53 | tok/s 71327
  >>> saved checkpoint: checkpoint_step_004000_loss_1.3489.pt
step   4010 | loss 1.6150 | lr 3.32e-04 | grad 2.86 | tok/s 59478
step   4020 | loss 1.4369 | lr 3.32e-04 | grad 2.06 | tok/s 68079
step   4030 | loss 1.4375 | lr 3.32e-04 | grad 1.74 | tok/s 72620
step   4040 | loss 1.4060 | lr 3.32e-04 | grad 3.11 | tok/s 73644
step   4050 | loss 1.4366 | lr 3.32e-04 | grad 1.66 | tok/s 74156
step   4060 | loss 1.4661 | lr 3.32e-04 | grad 1.35 | tok/s 73593
step   4070 | loss 1.4245 | lr 3.32e-04 | grad 1.58 | tok/s 71633
step   4080 | loss 1.4716 | lr 3.32e-04 | grad 2.22 | tok/s 74129
step   4090 | loss 1.4322 | lr 3.32e-04 | grad 1.28 | tok/s 72355
step   4100 | loss 1.4805 | lr 3.32e-04 | grad 1.64 | tok/s 75322
step   4110 | loss 1.7170 | lr 3.32e-04 | grad 3.36 | tok/s 71668
step   4120 | loss 1.7556 | lr 3.32e-04 | grad 2.30 | tok/s 72147
step   4130 | loss 1.3136 | lr 3.32e-04 | grad 1.91 | tok/s 69432
step   4140 | loss 1.6269 | lr 3.32e-04 | grad 2.83 | tok/s 72819
step   4150 | loss 1.3437 | lr 3.32e-04 | grad 1.66 | tok/s 74736
step   4160 | loss 1.5616 | lr 3.32e-04 | grad 1.48 | tok/s 72584
step   4170 | loss 1.4685 | lr 3.32e-04 | grad 1.66 | tok/s 68232
step   4180 | loss 1.3516 | lr 3.32e-04 | grad 1.26 | tok/s 73308
step   4190 | loss 1.2992 | lr 3.32e-04 | grad 1.50 | tok/s 71789
step   4200 | loss 1.3267 | lr 3.32e-04 | grad 1.28 | tok/s 70604
step   4210 | loss 1.4031 | lr 3.32e-04 | grad 2.42 | tok/s 73328
step   4220 | loss 1.4617 | lr 3.32e-04 | grad 3.20 | tok/s 76414
step   4230 | loss 1.3769 | lr 3.32e-04 | grad 2.27 | tok/s 70929
step   4240 | loss 1.4732 | lr 3.32e-04 | grad 1.99 | tok/s 71676
step   4250 | loss 1.4654 | lr 3.32e-04 | grad 1.74 | tok/s 74000
step   4260 | loss 1.3743 | lr 3.32e-04 | grad 2.45 | tok/s 72262
step   4270 | loss 1.4497 | lr 3.32e-04 | grad 2.08 | tok/s 71998
step   4280 | loss 1.3522 | lr 3.32e-04 | grad 2.45 | tok/s 72777
step   4290 | loss 1.5196 | lr 3.32e-04 | grad 1.49 | tok/s 71903
step   4300 | loss 1.3856 | lr 3.32e-04 | grad 1.68 | tok/s 71880
step   4310 | loss 1.4002 | lr 3.32e-04 | grad 3.41 | tok/s 68715
step   4320 | loss 1.4295 | lr 3.32e-04 | grad 1.51 | tok/s 71384
step   4330 | loss 1.4129 | lr 3.32e-04 | grad 1.84 | tok/s 69606
step   4340 | loss 1.3105 | lr 3.32e-04 | grad 1.34 | tok/s 74465
step   4350 | loss 1.4346 | lr 3.32e-04 | grad 3.45 | tok/s 73880
step   4360 | loss 1.4627 | lr 3.32e-04 | grad 1.64 | tok/s 71948
step   4370 | loss 1.3256 | lr 3.32e-04 | grad 1.58 | tok/s 74842
step   4380 | loss 1.3777 | lr 3.32e-04 | grad 1.63 | tok/s 73865
step   4390 | loss 1.4584 | lr 3.32e-04 | grad 1.45 | tok/s 73008
step   4400 | loss 1.3405 | lr 3.32e-04 | grad 2.44 | tok/s 72541
step   4410 | loss 1.3404 | lr 3.32e-04 | grad 1.51 | tok/s 74017
step   4420 | loss 1.4029 | lr 3.32e-04 | grad 1.59 | tok/s 71758
step   4430 | loss 1.4233 | lr 3.32e-04 | grad 1.39 | tok/s 73237
step   4440 | loss 1.4552 | lr 3.32e-04 | grad 3.70 | tok/s 72619
step   4450 | loss 1.4955 | lr 3.32e-04 | grad 1.22 | tok/s 73509
step   4460 | loss 1.2890 | lr 3.32e-04 | grad 1.16 | tok/s 76530
step   4470 | loss 1.2331 | lr 3.32e-04 | grad 1.12 | tok/s 75774
step   4480 | loss 1.2013 | lr 3.32e-04 | grad 0.98 | tok/s 76131
step   4490 | loss 1.2504 | lr 3.32e-04 | grad 2.06 | tok/s 76061
step   4500 | loss 1.5022 | lr 3.32e-04 | grad 1.69 | tok/s 73912
step   4510 | loss 1.4579 | lr 3.32e-04 | grad 2.33 | tok/s 74090
step   4520 | loss 1.3125 | lr 3.32e-04 | grad 1.35 | tok/s 70168
step   4530 | loss 1.3905 | lr 3.32e-04 | grad 3.03 | tok/s 74305
step   4540 | loss 1.4494 | lr 3.32e-04 | grad 1.40 | tok/s 71708
step   4550 | loss 1.4606 | lr 3.32e-04 | grad 1.49 | tok/s 72039
step   4560 | loss 1.2267 | lr 3.32e-04 | grad 1.18 | tok/s 71713
step   4570 | loss 1.0737 | lr 3.32e-04 | grad 1.32 | tok/s 73392
step   4580 | loss 1.3254 | lr 3.32e-04 | grad 1.23 | tok/s 72978
step   4590 | loss 1.2940 | lr 3.32e-04 | grad 1.48 | tok/s 73141
step   4600 | loss 1.6915 | lr 3.32e-04 | grad 2.66 | tok/s 74311
step   4610 | loss 1.7508 | lr 3.32e-04 | grad 3.73 | tok/s 75373
step   4620 | loss 1.6218 | lr 3.32e-04 | grad 4.97 | tok/s 76623
step   4630 | loss 1.5229 | lr 3.32e-04 | grad 3.05 | tok/s 76179
step   4640 | loss 1.5688 | lr 3.32e-04 | grad 3.31 | tok/s 76528
step   4650 | loss 1.5290 | lr 3.32e-04 | grad 1.66 | tok/s 76485
step   4660 | loss 1.5225 | lr 3.32e-04 | grad 2.48 | tok/s 74665
step   4670 | loss 1.5479 | lr 3.32e-04 | grad 3.91 | tok/s 76479
step   4680 | loss 1.4604 | lr 3.32e-04 | grad 1.91 | tok/s 75680
step   4690 | loss 1.3578 | lr 3.32e-04 | grad 2.09 | tok/s 76085
step   4700 | loss 1.2795 | lr 3.32e-04 | grad 1.84 | tok/s 75733
step   4710 | loss 1.4389 | lr 3.32e-04 | grad 2.50 | tok/s 74798
step   4720 | loss 1.5085 | lr 3.32e-04 | grad 2.30 | tok/s 74769
step   4730 | loss 1.4756 | lr 3.32e-04 | grad 2.77 | tok/s 76240
step   4740 | loss 1.4505 | lr 3.32e-04 | grad 2.70 | tok/s 76336
step   4750 | loss 1.4483 | lr 3.32e-04 | grad 4.09 | tok/s 76017
step   4760 | loss 1.4218 | lr 3.32e-04 | grad 1.91 | tok/s 76294
step   4770 | loss 1.4617 | lr 3.32e-04 | grad 3.38 | tok/s 74456
step   4780 | loss 1.5626 | lr 3.32e-04 | grad 3.20 | tok/s 76576
step   4790 | loss 1.5062 | lr 3.32e-04 | grad 1.61 | tok/s 70836
step   4800 | loss 1.3630 | lr 3.32e-04 | grad 2.09 | tok/s 67173
step   4810 | loss 1.4717 | lr 3.32e-04 | grad 1.55 | tok/s 60742
step   4820 | loss 1.3943 | lr 3.32e-04 | grad 2.39 | tok/s 62679
step   4830 | loss 1.3684 | lr 3.32e-04 | grad 3.91 | tok/s 67152
step   4840 | loss 1.3065 | lr 3.32e-04 | grad 1.29 | tok/s 63370
step   4850 | loss 1.4595 | lr 3.32e-04 | grad 1.77 | tok/s 63496
step   4860 | loss 1.3900 | lr 3.32e-04 | grad 1.80 | tok/s 62470
step   4870 | loss 1.3034 | lr 3.32e-04 | grad 1.95 | tok/s 64790
step   4880 | loss 1.3971 | lr 3.32e-04 | grad 1.41 | tok/s 63463
step   4890 | loss 1.4243 | lr 3.32e-04 | grad 2.78 | tok/s 63753
step   4900 | loss 1.5731 | lr 3.32e-04 | grad 1.25 | tok/s 62286
step   4910 | loss 1.3409 | lr 3.32e-04 | grad 1.12 | tok/s 66151
step   4920 | loss 1.3207 | lr 3.32e-04 | grad 2.44 | tok/s 64427
step   4930 | loss 1.5853 | lr 3.32e-04 | grad 8.75 | tok/s 63594
step   4940 | loss 1.2542 | lr 3.32e-04 | grad 3.52 | tok/s 66944
step   4950 | loss 0.8837 | lr 3.32e-04 | grad 5.34 | tok/s 65326
step   4960 | loss 0.7708 | lr 3.32e-04 | grad 1.62 | tok/s 66818
step   4970 | loss 0.8408 | lr 3.32e-04 | grad 2.56 | tok/s 64051
step   4980 | loss 0.9968 | lr 3.32e-04 | grad 1.82 | tok/s 64136
step   4990 | loss 1.4444 | lr 3.32e-04 | grad 2.22 | tok/s 62837
step   5000 | loss 1.1977 | lr 3.32e-04 | grad 1.31 | tok/s 62879
  >>> saved checkpoint: checkpoint_step_005000_loss_1.1977.pt
step   5010 | loss 1.3845 | lr 3.32e-04 | grad 1.37 | tok/s 58589
step   5020 | loss 1.3134 | lr 3.32e-04 | grad 1.26 | tok/s 66270
step   5030 | loss 1.2958 | lr 3.32e-04 | grad 1.23 | tok/s 65516
step   5040 | loss 1.1868 | lr 3.32e-04 | grad 1.23 | tok/s 67976
step   5050 | loss 1.2810 | lr 3.32e-04 | grad 1.90 | tok/s 65389
step   5060 | loss 1.4260 | lr 3.32e-04 | grad 3.73 | tok/s 63180
step   5070 | loss 1.5424 | lr 3.32e-04 | grad 1.49 | tok/s 61661
step   5080 | loss 1.2962 | lr 3.32e-04 | grad 2.58 | tok/s 65396
step   5090 | loss 1.3462 | lr 3.32e-04 | grad 3.38 | tok/s 61750
step   5100 | loss 1.3305 | lr 3.32e-04 | grad 1.37 | tok/s 67550
step   5110 | loss 1.3493 | lr 3.32e-04 | grad 1.39 | tok/s 62305
step   5120 | loss 1.2656 | lr 3.32e-04 | grad 1.71 | tok/s 64596
step   5130 | loss 1.2456 | lr 3.32e-04 | grad 2.02 | tok/s 63043
step   5140 | loss 1.5311 | lr 3.32e-04 | grad 2.36 | tok/s 62321
step   5150 | loss 1.3175 | lr 3.32e-04 | grad 1.27 | tok/s 62167
step   5160 | loss 1.4355 | lr 3.32e-04 | grad 1.32 | tok/s 66461
step   5170 | loss 1.4065 | lr 3.32e-04 | grad 1.40 | tok/s 64991
step   5180 | loss 1.2823 | lr 3.32e-04 | grad 2.36 | tok/s 65245
step   5190 | loss 1.3271 | lr 3.32e-04 | grad 1.24 | tok/s 64053
step   5200 | loss 1.3308 | lr 3.32e-04 | grad 1.51 | tok/s 64556
step   5210 | loss 1.2907 | lr 3.32e-04 | grad 1.40 | tok/s 64043
step   5220 | loss 1.3413 | lr 3.32e-04 | grad 1.97 | tok/s 67535
step   5230 | loss 1.3552 | lr 3.32e-04 | grad 2.05 | tok/s 62193
step   5240 | loss 1.5196 | lr 3.32e-04 | grad 1.84 | tok/s 61730
step   5250 | loss 1.2743 | lr 3.32e-04 | grad 2.36 | tok/s 64492
step   5260 | loss 1.3864 | lr 3.32e-04 | grad 1.79 | tok/s 63803
step   5270 | loss 1.3907 | lr 3.32e-04 | grad 3.33 | tok/s 61405
step   5280 | loss 1.3774 | lr 3.32e-04 | grad 1.38 | tok/s 61682
step   5290 | loss 1.2576 | lr 3.32e-04 | grad 2.64 | tok/s 64736
step   5300 | loss 1.3690 | lr 3.32e-04 | grad 1.81 | tok/s 62491
step   5310 | loss 1.4379 | lr 3.32e-04 | grad 1.35 | tok/s 62206
step   5320 | loss 1.3761 | lr 3.32e-04 | grad 1.58 | tok/s 61422
step   5330 | loss 1.4020 | lr 3.32e-04 | grad 1.35 | tok/s 61684
step   5340 | loss 1.3034 | lr 3.32e-04 | grad 1.63 | tok/s 64744
step   5350 | loss 1.4626 | lr 3.32e-04 | grad 1.76 | tok/s 63702
step   5360 | loss 1.5597 | lr 3.32e-04 | grad 1.44 | tok/s 65799
step   5370 | loss 1.3921 | lr 3.32e-04 | grad 1.27 | tok/s 69005
step   5380 | loss 1.3752 | lr 3.32e-04 | grad 1.48 | tok/s 72068
step   5390 | loss 1.2796 | lr 3.32e-04 | grad 1.39 | tok/s 72605
step   5400 | loss 1.3771 | lr 3.32e-04 | grad 1.72 | tok/s 70530
step   5410 | loss 1.2620 | lr 3.32e-04 | grad 2.16 | tok/s 74699
step   5420 | loss 1.3608 | lr 3.32e-04 | grad 1.62 | tok/s 71906
step   5430 | loss 1.3435 | lr 3.32e-04 | grad 1.89 | tok/s 71677
step   5440 | loss 1.3322 | lr 3.32e-04 | grad 1.56 | tok/s 71981
step   5450 | loss 1.4257 | lr 3.32e-04 | grad 1.77 | tok/s 73981
step   5460 | loss 1.1665 | lr 3.32e-04 | grad 3.12 | tok/s 73935
step   5470 | loss 1.1206 | lr 3.32e-04 | grad 1.34 | tok/s 73424
step   5480 | loss 1.3901 | lr 3.32e-04 | grad 1.70 | tok/s 74261
step   5490 | loss 1.2986 | lr 3.32e-04 | grad 1.59 | tok/s 76017
step   5500 | loss 1.3648 | lr 3.32e-04 | grad 1.48 | tok/s 72298
step   5510 | loss 1.2941 | lr 3.32e-04 | grad 2.09 | tok/s 72313
step   5520 | loss 1.2293 | lr 3.32e-04 | grad 1.32 | tok/s 70958
step   5530 | loss 1.4410 | lr 3.32e-04 | grad 2.11 | tok/s 68976
step   5540 | loss 1.2454 | lr 3.32e-04 | grad 1.95 | tok/s 71977
step   5550 | loss 1.3626 | lr 3.32e-04 | grad 1.45 | tok/s 68726
step   5560 | loss 1.3603 | lr 3.32e-04 | grad 1.20 | tok/s 71449
step   5570 | loss 1.3695 | lr 3.32e-04 | grad 1.68 | tok/s 70589
step   5580 | loss 1.3488 | lr 3.32e-04 | grad 3.05 | tok/s 74605
step   5590 | loss 1.3624 | lr 3.32e-04 | grad 2.70 | tok/s 71266
step   5600 | loss 1.0301 | lr 3.32e-04 | grad 2.98 | tok/s 75788
step   5610 | loss 1.2976 | lr 3.32e-04 | grad 2.14 | tok/s 71443
step   5620 | loss 1.3376 | lr 3.32e-04 | grad 1.22 | tok/s 73359
step   5630 | loss 1.4643 | lr 3.32e-04 | grad 2.11 | tok/s 71806
step   5640 | loss 1.3880 | lr 3.32e-04 | grad 1.36 | tok/s 71795
step   5650 | loss 1.2663 | lr 3.32e-04 | grad 1.24 | tok/s 71630
step   5660 | loss 1.3680 | lr 3.32e-04 | grad 3.36 | tok/s 74661
step   5670 | loss 1.4142 | lr 3.32e-04 | grad 1.91 | tok/s 75144
step   5680 | loss 1.3880 | lr 3.32e-04 | grad 2.08 | tok/s 74252
step   5690 | loss 1.4872 | lr 3.32e-04 | grad 1.35 | tok/s 73971
step   5700 | loss 1.3944 | lr 3.32e-04 | grad 1.25 | tok/s 69052
step   5710 | loss 1.4433 | lr 3.32e-04 | grad 3.23 | tok/s 74632
step   5720 | loss 0.8514 | lr 3.32e-04 | grad 1.28 | tok/s 75765
step   5730 | loss 1.2716 | lr 3.32e-04 | grad 1.70 | tok/s 72037
step   5740 | loss 1.1105 | lr 3.32e-04 | grad 1.78 | tok/s 74278
step   5750 | loss 1.2599 | lr 3.32e-04 | grad 1.91 | tok/s 74662
step   5760 | loss 1.3438 | lr 3.32e-04 | grad 1.94 | tok/s 73405
step   5770 | loss 1.4613 | lr 3.32e-04 | grad 2.69 | tok/s 72790
step   5780 | loss 1.2405 | lr 3.32e-04 | grad 1.42 | tok/s 71768
step   5790 | loss 1.4686 | lr 3.32e-04 | grad 1.30 | tok/s 71892
step   5800 | loss 1.3480 | lr 3.32e-04 | grad 2.62 | tok/s 70348
step   5810 | loss 1.2849 | lr 3.32e-04 | grad 1.73 | tok/s 74685
step   5820 | loss 1.3751 | lr 3.32e-04 | grad 1.68 | tok/s 74107
step   5830 | loss 1.3239 | lr 3.32e-04 | grad 1.33 | tok/s 72843
step   5840 | loss 1.3241 | lr 3.32e-04 | grad 1.48 | tok/s 72542
step   5850 | loss 1.3796 | lr 3.32e-04 | grad 1.12 | tok/s 70655
step   5860 | loss 1.3960 | lr 3.32e-04 | grad 2.45 | tok/s 74054
step   5870 | loss 1.3692 | lr 3.32e-04 | grad 2.25 | tok/s 70850
step   5880 | loss 1.2635 | lr 3.32e-04 | grad 2.16 | tok/s 73410
step   5890 | loss 1.3582 | lr 3.32e-04 | grad 1.28 | tok/s 75780
step   5900 | loss 1.2787 | lr 3.32e-04 | grad 1.54 | tok/s 74804
step   5910 | loss 1.3067 | lr 3.32e-04 | grad 1.50 | tok/s 75582
step   5920 | loss 1.2901 | lr 3.32e-04 | grad 1.34 | tok/s 73630
step   5930 | loss 1.3248 | lr 3.32e-04 | grad 1.15 | tok/s 73456
step   5940 | loss 1.4220 | lr 3.32e-04 | grad 1.79 | tok/s 68393
step   5950 | loss 1.2237 | lr 3.32e-04 | grad 2.20 | tok/s 73628
step   5960 | loss 1.3674 | lr 3.32e-04 | grad 1.32 | tok/s 71911
step   5970 | loss 1.5374 | lr 3.32e-04 | grad 3.91 | tok/s 73492
step   5980 | loss 1.5406 | lr 3.32e-04 | grad 1.54 | tok/s 74889
step   5990 | loss 1.3455 | lr 3.32e-04 | grad 2.38 | tok/s 72862
step   6000 | loss 1.3248 | lr 3.32e-04 | grad 1.29 | tok/s 75032
  >>> saved checkpoint: checkpoint_step_006000_loss_1.3248.pt
step   6010 | loss 1.5424 | lr 3.32e-04 | grad 2.84 | tok/s 57170
step   6020 | loss 1.2912 | lr 3.32e-04 | grad 1.80 | tok/s 74021
step   6030 | loss 1.3949 | lr 3.32e-04 | grad 1.52 | tok/s 71404
step   6040 | loss 1.3943 | lr 3.32e-04 | grad 1.85 | tok/s 74627
step   6050 | loss 1.4106 | lr 3.32e-04 | grad 1.65 | tok/s 72442
step   6060 | loss 1.4858 | lr 3.32e-04 | grad 1.17 | tok/s 72614
step   6070 | loss 1.3759 | lr 3.32e-04 | grad 1.73 | tok/s 71374
step   6080 | loss 1.2978 | lr 3.32e-04 | grad 1.38 | tok/s 71167
step   6090 | loss 1.2343 | lr 3.32e-04 | grad 1.53 | tok/s 73673
step   6100 | loss 1.4616 | lr 3.32e-04 | grad 2.00 | tok/s 72580
step   6110 | loss 1.4179 | lr 3.32e-04 | grad 1.66 | tok/s 73118
step   6120 | loss 1.3964 | lr 3.32e-04 | grad 1.48 | tok/s 71560
step   6130 | loss 1.3854 | lr 3.32e-04 | grad 1.70 | tok/s 75038
step   6140 | loss 1.3473 | lr 3.32e-04 | grad 3.86 | tok/s 71309
step   6150 | loss 1.3012 | lr 3.32e-04 | grad 1.38 | tok/s 72872
step   6160 | loss 1.3418 | lr 3.32e-04 | grad 2.11 | tok/s 73364
step   6170 | loss 1.4183 | lr 3.32e-04 | grad 1.74 | tok/s 72054
step   6180 | loss 1.3795 | lr 3.32e-04 | grad 1.49 | tok/s 72059
step   6190 | loss 1.4945 | lr 3.32e-04 | grad 2.80 | tok/s 74872
step   6200 | loss 1.5692 | lr 3.32e-04 | grad 1.78 | tok/s 73609
step   6210 | loss 1.3807 | lr 3.32e-04 | grad 1.93 | tok/s 72709
step   6220 | loss 1.2500 | lr 3.32e-04 | grad 1.20 | tok/s 74748
step   6230 | loss 1.2005 | lr 3.32e-04 | grad 1.38 | tok/s 73293
step   6240 | loss 1.1610 | lr 3.32e-04 | grad 1.34 | tok/s 75899
step   6250 | loss 1.1495 | lr 3.32e-04 | grad 1.94 | tok/s 74812
step   6260 | loss 1.1719 | lr 3.32e-04 | grad 1.35 | tok/s 76406
step   6270 | loss 1.3119 | lr 3.32e-04 | grad 3.03 | tok/s 73675
step   6280 | loss 1.5184 | lr 3.32e-04 | grad 2.27 | tok/s 74486
step   6290 | loss 1.3632 | lr 3.32e-04 | grad 1.49 | tok/s 73680
step   6300 | loss 1.2627 | lr 3.32e-04 | grad 1.80 | tok/s 73150
step   6310 | loss 1.3617 | lr 3.32e-04 | grad 1.95 | tok/s 74506
step   6320 | loss 1.3296 | lr 3.32e-04 | grad 2.12 | tok/s 73439
step   6330 | loss 1.5322 | lr 3.32e-04 | grad 1.86 | tok/s 73180
step   6340 | loss 1.5996 | lr 3.32e-04 | grad 1.51 | tok/s 76054
step   6350 | loss 1.4450 | lr 3.32e-04 | grad 1.22 | tok/s 70968
step   6360 | loss 1.3861 | lr 3.32e-04 | grad 1.24 | tok/s 74740
step   6370 | loss 1.3468 | lr 3.32e-04 | grad 1.02 | tok/s 76270
step   6380 | loss 1.3644 | lr 3.32e-04 | grad 1.17 | tok/s 75940
step   6390 | loss 1.3569 | lr 3.32e-04 | grad 1.74 | tok/s 71863
step   6400 | loss 1.3630 | lr 3.32e-04 | grad 1.28 | tok/s 74574
step   6410 | loss 1.2971 | lr 3.32e-04 | grad 1.19 | tok/s 76157
step   6420 | loss 1.2603 | lr 3.32e-04 | grad 1.12 | tok/s 75965
step   6430 | loss 1.2401 | lr 3.32e-04 | grad 1.06 | tok/s 75576
step   6440 | loss 1.2662 | lr 3.32e-04 | grad 1.17 | tok/s 74291
step   6450 | loss 1.3040 | lr 3.32e-04 | grad 1.26 | tok/s 75814
step   6460 | loss 1.3468 | lr 3.32e-04 | grad 1.23 | tok/s 76529
step   6470 | loss 1.2704 | lr 3.32e-04 | grad 1.06 | tok/s 74496
step   6480 | loss 1.2502 | lr 3.32e-04 | grad 1.01 | tok/s 76257
step   6490 | loss 1.2294 | lr 3.32e-04 | grad 1.14 | tok/s 75985
step   6500 | loss 1.2422 | lr 3.32e-04 | grad 1.16 | tok/s 76458
step   6510 | loss 1.2427 | lr 3.32e-04 | grad 1.23 | tok/s 76472
step   6520 | loss 1.1542 | lr 3.32e-04 | grad 1.04 | tok/s 76440
step   6530 | loss 1.1130 | lr 3.32e-04 | grad 1.05 | tok/s 76753
step   6540 | loss 1.0943 | lr 3.32e-04 | grad 1.16 | tok/s 76387
step   6550 | loss 1.1064 | lr 3.32e-04 | grad 1.08 | tok/s 76713
step   6560 | loss 1.2455 | lr 3.32e-04 | grad 1.12 | tok/s 76644
step   6570 | loss 1.1373 | lr 3.32e-04 | grad 1.14 | tok/s 76505
step   6580 | loss 1.0768 | lr 3.32e-04 | grad 1.20 | tok/s 74681
step   6590 | loss 1.1182 | lr 3.32e-04 | grad 1.05 | tok/s 74106
step   6600 | loss 1.1876 | lr 3.32e-04 | grad 1.18 | tok/s 76519
step   6610 | loss 1.2271 | lr 3.32e-04 | grad 1.08 | tok/s 76822
step   6620 | loss 1.1604 | lr 3.32e-04 | grad 1.29 | tok/s 76461
step   6630 | loss 1.1296 | lr 3.32e-04 | grad 1.07 | tok/s 76315
step   6640 | loss 1.1286 | lr 3.32e-04 | grad 1.16 | tok/s 76560
step   6650 | loss 1.1108 | lr 3.32e-04 | grad 1.19 | tok/s 76244
step   6660 | loss 1.1184 | lr 3.32e-04 | grad 1.21 | tok/s 76641
step   6670 | loss 1.2681 | lr 3.32e-04 | grad 1.27 | tok/s 74510
step   6680 | loss 1.1892 | lr 3.32e-04 | grad 1.12 | tok/s 74558
step   6690 | loss 1.1625 | lr 3.32e-04 | grad 1.35 | tok/s 76276
step   6700 | loss 1.1293 | lr 3.32e-04 | grad 1.22 | tok/s 74776
step   6710 | loss 1.1538 | lr 3.32e-04 | grad 1.14 | tok/s 74950
step   6720 | loss 1.1536 | lr 3.32e-04 | grad 1.24 | tok/s 76036
step   6730 | loss 1.0653 | lr 3.32e-04 | grad 1.21 | tok/s 74854
step   6740 | loss 1.0461 | lr 3.32e-04 | grad 1.13 | tok/s 76411
step   6750 | loss 1.0263 | lr 3.32e-04 | grad 1.19 | tok/s 76408
step   6760 | loss 1.0112 | lr 3.32e-04 | grad 1.29 | tok/s 76293
step   6770 | loss 1.0446 | lr 3.32e-04 | grad 1.16 | tok/s 66174
step   6780 | loss 1.3068 | lr 3.32e-04 | grad 1.17 | tok/s 65184
step   6790 | loss 1.2742 | lr 3.32e-04 | grad 1.34 | tok/s 66340
step   6800 | loss 1.2549 | lr 3.32e-04 | grad 1.11 | tok/s 63994
step   6810 | loss 1.2426 | lr 3.32e-04 | grad 1.05 | tok/s 65368
step   6820 | loss 1.2811 | lr 3.32e-04 | grad 1.22 | tok/s 68939
step   6830 | loss 1.2823 | lr 3.32e-04 | grad 1.26 | tok/s 68285
step   6840 | loss 1.2777 | lr 3.32e-04 | grad 1.12 | tok/s 67005
step   6850 | loss 1.2327 | lr 3.32e-04 | grad 1.12 | tok/s 68192
step   6860 | loss 1.2395 | lr 3.32e-04 | grad 1.41 | tok/s 64232
step   6870 | loss 1.1284 | lr 3.32e-04 | grad 1.29 | tok/s 67734
step   6880 | loss 1.1053 | lr 3.32e-04 | grad 1.08 | tok/s 74825
step   6890 | loss 1.0564 | lr 3.32e-04 | grad 1.34 | tok/s 72163
step   6900 | loss 1.0436 | lr 3.32e-04 | grad 1.23 | tok/s 76359
step   6910 | loss 1.1354 | lr 3.32e-04 | grad 1.12 | tok/s 76588
step   6920 | loss 1.1226 | lr 3.32e-04 | grad 1.29 | tok/s 76532
step   6930 | loss 1.0823 | lr 3.32e-04 | grad 1.09 | tok/s 76124
step   6940 | loss 1.0620 | lr 3.32e-04 | grad 1.10 | tok/s 75973
step   6950 | loss 1.0534 | lr 3.32e-04 | grad 1.24 | tok/s 76582
step   6960 | loss 1.0410 | lr 3.32e-04 | grad 1.16 | tok/s 76005
step   6970 | loss 1.0139 | lr 3.32e-04 | grad 1.21 | tok/s 76269
step   6980 | loss 0.9900 | lr 3.32e-04 | grad 1.27 | tok/s 76280
step   6990 | loss 1.1156 | lr 3.32e-04 | grad 1.19 | tok/s 74383
step   7000 | loss 1.1901 | lr 3.32e-04 | grad 1.16 | tok/s 74740
  >>> saved checkpoint: checkpoint_step_007000_loss_1.1901.pt
step   7010 | loss 1.3767 | lr 3.32e-04 | grad 5.94 | tok/s 60362
step   7020 | loss 1.6922 | lr 3.32e-04 | grad 3.70 | tok/s 74220
step   7030 | loss 1.4884 | lr 3.32e-04 | grad 2.98 | tok/s 75740
step   7040 | loss 1.3767 | lr 3.32e-04 | grad 2.64 | tok/s 76483
step   7050 | loss 1.3330 | lr 3.32e-04 | grad 2.75 | tok/s 76173
step   7060 | loss 1.2858 | lr 3.32e-04 | grad 2.70 | tok/s 76306
step   7070 | loss 1.2422 | lr 3.32e-04 | grad 2.78 | tok/s 76401
step   7080 | loss 1.2181 | lr 3.32e-04 | grad 1.97 | tok/s 76544
step   7090 | loss 1.2018 | lr 3.32e-04 | grad 2.28 | tok/s 76577
step   7100 | loss 1.1841 | lr 3.32e-04 | grad 2.27 | tok/s 76343
step   7110 | loss 1.1520 | lr 3.32e-04 | grad 2.58 | tok/s 76451
step   7120 | loss 1.1411 | lr 3.32e-04 | grad 2.31 | tok/s 74514
step   7130 | loss 1.1215 | lr 3.32e-04 | grad 2.33 | tok/s 74020
step   7140 | loss 1.0685 | lr 3.32e-04 | grad 2.75 | tok/s 76263
step   7150 | loss 1.0513 | lr 3.32e-04 | grad 2.22 | tok/s 76525
step   7160 | loss 1.1063 | lr 3.32e-04 | grad 2.77 | tok/s 74931
step   7170 | loss 1.1098 | lr 3.32e-04 | grad 1.59 | tok/s 74871
step   7180 | loss 1.0519 | lr 3.32e-04 | grad 1.68 | tok/s 76487
step   7190 | loss 1.0407 | lr 3.32e-04 | grad 1.56 | tok/s 76379
step   7200 | loss 1.0197 | lr 3.32e-04 | grad 1.53 | tok/s 74605
step   7210 | loss 0.9891 | lr 3.32e-04 | grad 1.60 | tok/s 76068
step   7220 | loss 1.0057 | lr 3.32e-04 | grad 1.52 | tok/s 75924
step   7230 | loss 0.9741 | lr 3.32e-04 | grad 1.59 | tok/s 76369
step   7240 | loss 0.9875 | lr 3.32e-04 | grad 1.73 | tok/s 76110
step   7250 | loss 0.9744 | lr 3.32e-04 | grad 1.60 | tok/s 76447
step   7260 | loss 0.9641 | lr 3.32e-04 | grad 1.55 | tok/s 75826
step   7270 | loss 0.9331 | lr 3.32e-04 | grad 1.72 | tok/s 76536
step   7280 | loss 0.9649 | lr 3.32e-04 | grad 1.74 | tok/s 76315
step   7290 | loss 0.9636 | lr 3.32e-04 | grad 1.61 | tok/s 76112
step   7300 | loss 0.9704 | lr 3.32e-04 | grad 1.53 | tok/s 74520
step   7310 | loss 0.9574 | lr 3.32e-04 | grad 1.71 | tok/s 76234
step   7320 | loss 0.9556 | lr 3.32e-04 | grad 1.69 | tok/s 76057
step   7330 | loss 0.9501 | lr 3.32e-04 | grad 1.72 | tok/s 75997
step   7340 | loss 0.9596 | lr 3.32e-04 | grad 1.69 | tok/s 76619
step   7350 | loss 0.9476 | lr 3.32e-04 | grad 1.64 | tok/s 76394
step   7360 | loss 0.9554 | lr 3.32e-04 | grad 1.53 | tok/s 76608
step   7370 | loss 0.9523 | lr 3.32e-04 | grad 1.60 | tok/s 76671
step   7380 | loss 0.9237 | lr 3.32e-04 | grad 1.57 | tok/s 76250
step   7390 | loss 0.8922 | lr 3.32e-04 | grad 1.77 | tok/s 76205
step   7400 | loss 0.9122 | lr 3.32e-04 | grad 1.73 | tok/s 76267
step   7410 | loss 0.8996 | lr 3.32e-04 | grad 1.72 | tok/s 75772
step   7420 | loss 0.8879 | lr 3.32e-04 | grad 1.58 | tok/s 74712
step   7430 | loss 1.3440 | lr 3.32e-04 | grad 1.53 | tok/s 76040
step   7440 | loss 1.2744 | lr 3.32e-04 | grad 1.79 | tok/s 72733
step   7450 | loss 1.2000 | lr 3.32e-04 | grad 1.34 | tok/s 74381
step   7460 | loss 1.2055 | lr 3.32e-04 | grad 1.38 | tok/s 76329
step   7470 | loss 1.2051 | lr 3.32e-04 | grad 1.34 | tok/s 74664
step   7480 | loss 1.2024 | lr 3.32e-04 | grad 1.30 | tok/s 76329
step   7490 | loss 1.1734 | lr 3.32e-04 | grad 1.55 | tok/s 76145
step   7500 | loss 1.4184 | lr 3.32e-04 | grad 6.56 | tok/s 74795
step   7510 | loss 1.4085 | lr 3.32e-04 | grad 1.96 | tok/s 72867
step   7520 | loss 1.2827 | lr 3.32e-04 | grad 2.78 | tok/s 72279
step   7530 | loss 1.4394 | lr 3.32e-04 | grad 7.03 | tok/s 71946
step   7540 | loss 1.3989 | lr 3.32e-04 | grad 2.20 | tok/s 75137
step   7550 | loss 1.4238 | lr 3.32e-04 | grad 1.60 | tok/s 74768
step   7560 | loss 1.4202 | lr 3.32e-04 | grad 1.57 | tok/s 72013
step   7570 | loss 1.2816 | lr 3.32e-04 | grad 1.34 | tok/s 73422
step   7580 | loss 1.6271 | lr 3.32e-04 | grad 2.06 | tok/s 73569
step   7590 | loss 1.3788 | lr 3.32e-04 | grad 1.73 | tok/s 72835
step   7600 | loss 1.3218 | lr 3.32e-04 | grad 1.99 | tok/s 69995
step   7610 | loss 1.4722 | lr 3.32e-04 | grad 2.52 | tok/s 73492
step   7620 | loss 1.3494 | lr 3.32e-04 | grad 2.12 | tok/s 73668
step   7630 | loss 1.4086 | lr 3.32e-04 | grad 3.41 | tok/s 72576
step   7640 | loss 1.4270 | lr 3.32e-04 | grad 1.73 | tok/s 72980
step   7650 | loss 1.3493 | lr 3.32e-04 | grad 1.59 | tok/s 75530
step   7660 | loss 1.4568 | lr 3.32e-04 | grad 1.59 | tok/s 73156
step   7670 | loss 1.5562 | lr 3.32e-04 | grad 2.31 | tok/s 73084
step   7680 | loss 1.3916 | lr 3.32e-04 | grad 5.44 | tok/s 71201
step   7690 | loss 1.3556 | lr 3.32e-04 | grad 1.81 | tok/s 73521
step   7700 | loss 1.3256 | lr 3.32e-04 | grad 2.02 | tok/s 70937
step   7710 | loss 1.2951 | lr 3.32e-04 | grad 1.36 | tok/s 73093
step   7720 | loss 1.4117 | lr 3.32e-04 | grad 1.96 | tok/s 70150
step   7730 | loss 1.3639 | lr 3.32e-04 | grad 2.22 | tok/s 73161
step   7740 | loss 1.3200 | lr 3.32e-04 | grad 1.72 | tok/s 70591
step   7750 | loss 1.2705 | lr 3.32e-04 | grad 1.95 | tok/s 73320
step   7760 | loss 1.3800 | lr 3.32e-04 | grad 2.12 | tok/s 72888
step   7770 | loss 1.2686 | lr 3.32e-04 | grad 2.30 | tok/s 71268
step   7780 | loss 1.4096 | lr 3.32e-04 | grad 1.59 | tok/s 73861
step   7790 | loss 1.3662 | lr 3.32e-04 | grad 2.00 | tok/s 72959
step   7800 | loss 1.4066 | lr 3.32e-04 | grad 1.65 | tok/s 72346
step   7810 | loss 1.4709 | lr 3.32e-04 | grad 1.38 | tok/s 74884
step   7820 | loss 1.3805 | lr 3.32e-04 | grad 1.30 | tok/s 73866
step   7830 | loss 1.1345 | lr 3.32e-04 | grad 1.26 | tok/s 76292
step   7840 | loss 1.0473 | lr 3.32e-04 | grad 1.17 | tok/s 76408
step   7850 | loss 1.1862 | lr 3.32e-04 | grad 1.64 | tok/s 74380
step   7860 | loss 1.3700 | lr 3.32e-04 | grad 1.66 | tok/s 74513
step   7870 | loss 1.4636 | lr 3.32e-04 | grad 2.00 | tok/s 72246
step   7880 | loss 1.3515 | lr 3.32e-04 | grad 1.21 | tok/s 74066
step   7890 | loss 1.3912 | lr 3.32e-04 | grad 3.05 | tok/s 70054
step   7900 | loss 1.4774 | lr 3.32e-04 | grad 2.45 | tok/s 73289
step   7910 | loss 1.5620 | lr 3.32e-04 | grad 2.05 | tok/s 76247
step   7920 | loss 1.3143 | lr 3.32e-04 | grad 4.66 | tok/s 72595
step   7930 | loss 1.3758 | lr 3.32e-04 | grad 1.41 | tok/s 70745
step   7940 | loss 1.3051 | lr 3.32e-04 | grad 1.25 | tok/s 69559
step   7950 | loss 1.3246 | lr 3.32e-04 | grad 3.08 | tok/s 74260
step   7960 | loss 1.3460 | lr 3.32e-04 | grad 2.45 | tok/s 72424
step   7970 | loss 1.5033 | lr 3.32e-04 | grad 1.31 | tok/s 67530
step   7980 | loss 1.3696 | lr 3.32e-04 | grad 2.47 | tok/s 70392
step   7990 | loss 1.3555 | lr 3.32e-04 | grad 1.99 | tok/s 70129
step   8000 | loss 1.3223 | lr 3.32e-04 | grad 1.64 | tok/s 69785
  >>> saved checkpoint: checkpoint_step_008000_loss_1.3223.pt
step   8010 | loss 1.2689 | lr 3.32e-04 | grad 1.22 | tok/s 60107
step   8020 | loss 1.4263 | lr 3.32e-04 | grad 1.49 | tok/s 75307
step   8030 | loss 1.1861 | lr 3.32e-04 | grad 1.22 | tok/s 76418
step   8040 | loss 1.1345 | lr 3.32e-04 | grad 1.02 | tok/s 76134
step   8050 | loss 1.0782 | lr 3.32e-04 | grad 1.48 | tok/s 74499
step   8060 | loss 1.0464 | lr 3.32e-04 | grad 1.17 | tok/s 75850
step   8070 | loss 1.3263 | lr 3.32e-04 | grad 2.41 | tok/s 74367
step   8080 | loss 1.3448 | lr 3.32e-04 | grad 1.96 | tok/s 70204
step   8090 | loss 1.3136 | lr 3.32e-04 | grad 1.38 | tok/s 71724
step   8100 | loss 1.3601 | lr 3.32e-04 | grad 1.52 | tok/s 71450
step   8110 | loss 1.3534 | lr 3.32e-04 | grad 1.84 | tok/s 72150
step   8120 | loss 1.4154 | lr 3.32e-04 | grad 2.27 | tok/s 72833
step   8130 | loss 1.4972 | lr 3.32e-04 | grad 1.49 | tok/s 73281

Training complete! Final step: 8130
