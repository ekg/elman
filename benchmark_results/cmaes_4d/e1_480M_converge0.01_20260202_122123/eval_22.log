Using device: cuda
Output directory: benchmark_results/cmaes_4d/e1_480M_converge0.01_20260202_122123/eval_22/level1_100m_20260202_132240
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 674,906,624 parameters
Using schedule-free AdamW (lr=0.0004148253901350878)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 5.1425 | lr 4.15e-04 | grad 7.00 | tok/s 4421
step     20 | loss 2.7301 | lr 4.15e-04 | grad 3.48 | tok/s 7631
step     30 | loss 2.8468 | lr 4.15e-04 | grad 2.25 | tok/s 7728
step     40 | loss 2.5363 | lr 4.15e-04 | grad 3.19 | tok/s 7410
step     50 | loss 3.2579 | lr 4.15e-04 | grad 5.84 | tok/s 7531
step     60 | loss 2.2965 | lr 4.15e-04 | grad 1.62 | tok/s 7772
step     70 | loss 2.3029 | lr 4.15e-04 | grad 4.50 | tok/s 7876
step     80 | loss 5.0079 | lr 4.15e-04 | grad 11.94 | tok/s 7928
step     90 | loss 4.3583 | lr 4.15e-04 | grad 2.75 | tok/s 8067
step    100 | loss 3.7069 | lr 4.15e-04 | grad 3.17 | tok/s 8066
step    110 | loss 3.5736 | lr 4.15e-04 | grad 9.75 | tok/s 8063
step    120 | loss 3.3914 | lr 4.15e-04 | grad 11.12 | tok/s 8058
step    130 | loss 3.2688 | lr 4.15e-04 | grad 6.12 | tok/s 8061
step    140 | loss 2.8370 | lr 4.15e-04 | grad 4.41 | tok/s 8055
step    150 | loss 2.9948 | lr 4.15e-04 | grad 8.06 | tok/s 8052
step    160 | loss 2.5596 | lr 4.15e-04 | grad 8.12 | tok/s 8056
step    170 | loss 2.6612 | lr 4.15e-04 | grad 7.88 | tok/s 8054
step    180 | loss 2.4333 | lr 4.15e-04 | grad 6.00 | tok/s 8053
step    190 | loss 2.5774 | lr 4.15e-04 | grad 7.03 | tok/s 8049
step    200 | loss 2.3648 | lr 4.15e-04 | grad 3.45 | tok/s 8055
step    210 | loss 2.4103 | lr 4.15e-04 | grad 4.59 | tok/s 8054
step    220 | loss 2.5529 | lr 4.15e-04 | grad 2.69 | tok/s 7955
step    230 | loss 2.7116 | lr 4.15e-04 | grad 3.28 | tok/s 7857
step    240 | loss 2.4817 | lr 4.15e-04 | grad 2.78 | tok/s 7465
step    250 | loss 2.3082 | lr 4.15e-04 | grad 1.93 | tok/s 7677
step    260 | loss 2.0026 | lr 4.15e-04 | grad 2.48 | tok/s 7920
step    270 | loss 2.3160 | lr 4.15e-04 | grad 3.06 | tok/s 7814
step    280 | loss 2.4834 | lr 4.15e-04 | grad 2.75 | tok/s 7668
step    290 | loss 2.0261 | lr 4.15e-04 | grad 2.48 | tok/s 8060
step    300 | loss 0.9920 | lr 4.15e-04 | grad 3.94 | tok/s 8059
step    310 | loss 2.7211 | lr 4.15e-04 | grad 2.56 | tok/s 7926
step    320 | loss 2.3672 | lr 4.15e-04 | grad 3.45 | tok/s 7762
step    330 | loss 2.1693 | lr 4.15e-04 | grad 1.50 | tok/s 7498
step    340 | loss 2.4058 | lr 4.15e-04 | grad 1.87 | tok/s 7614
step    350 | loss 2.1501 | lr 4.15e-04 | grad 1.74 | tok/s 7810
step    360 | loss 1.8374 | lr 4.15e-04 | grad 4.09 | tok/s 7984
step    370 | loss 2.1475 | lr 4.15e-04 | grad 2.02 | tok/s 7233
step    380 | loss 1.9943 | lr 4.15e-04 | grad 1.79 | tok/s 7706
step    390 | loss 1.7733 | lr 4.15e-04 | grad 1.32 | tok/s 8050
step    400 | loss 1.7817 | lr 4.15e-04 | grad 2.03 | tok/s 7983
step    410 | loss 1.6348 | lr 4.15e-04 | grad 1.26 | tok/s 7805
step    420 | loss 2.0271 | lr 4.15e-04 | grad 2.72 | tok/s 7449
step    430 | loss 2.2923 | lr 4.15e-04 | grad 1.95 | tok/s 7925
step    440 | loss 2.3234 | lr 4.15e-04 | grad 2.12 | tok/s 7495
step    450 | loss 2.3867 | lr 4.15e-04 | grad 1.52 | tok/s 7757
step    460 | loss 1.9325 | lr 4.15e-04 | grad 2.36 | tok/s 7591
step    470 | loss 2.0126 | lr 4.15e-04 | grad 1.97 | tok/s 7823
step    480 | loss 2.3642 | lr 4.15e-04 | grad 2.81 | tok/s 7824
step    490 | loss 1.9785 | lr 4.15e-04 | grad 1.50 | tok/s 7402
step    500 | loss 1.9088 | lr 4.15e-04 | grad 2.23 | tok/s 7904
step    510 | loss 1.8879 | lr 4.15e-04 | grad 1.20 | tok/s 8013
step    520 | loss 1.8839 | lr 4.15e-04 | grad 1.41 | tok/s 7994
step    530 | loss 2.0449 | lr 4.15e-04 | grad 1.26 | tok/s 7683
step    540 | loss 1.8963 | lr 4.15e-04 | grad 1.58 | tok/s 7689
step    550 | loss 1.7231 | lr 4.15e-04 | grad 1.45 | tok/s 7528
step    560 | loss 1.8927 | lr 4.15e-04 | grad 1.53 | tok/s 7332
step    570 | loss 1.8377 | lr 4.15e-04 | grad 1.66 | tok/s 7531
step    580 | loss 1.7249 | lr 4.15e-04 | grad 1.50 | tok/s 7504
step    590 | loss 2.0164 | lr 4.15e-04 | grad 1.69 | tok/s 7699
step    600 | loss 1.9532 | lr 4.15e-04 | grad 1.20 | tok/s 7436
step    610 | loss 1.7813 | lr 4.15e-04 | grad 1.27 | tok/s 7822
step    620 | loss 1.6787 | lr 4.15e-04 | grad 1.16 | tok/s 7409
step    630 | loss 1.7946 | lr 4.15e-04 | grad 1.92 | tok/s 7469
step    640 | loss 1.9656 | lr 4.15e-04 | grad 1.12 | tok/s 7668
step    650 | loss 1.8027 | lr 4.15e-04 | grad 1.98 | tok/s 7710
step    660 | loss 1.8448 | lr 4.15e-04 | grad 1.09 | tok/s 7740
step    670 | loss 2.0383 | lr 4.15e-04 | grad 1.60 | tok/s 7793
step    680 | loss 1.8351 | lr 4.15e-04 | grad 1.38 | tok/s 7639
step    690 | loss 1.9744 | lr 4.15e-04 | grad 1.89 | tok/s 7904
step    700 | loss 1.5750 | lr 4.15e-04 | grad 1.48 | tok/s 8059
step    710 | loss 1.7096 | lr 4.15e-04 | grad 1.30 | tok/s 7523
step    720 | loss 1.5762 | lr 4.15e-04 | grad 1.71 | tok/s 7407
step    730 | loss 1.4858 | lr 4.15e-04 | grad 1.66 | tok/s 8045
step    740 | loss 1.6502 | lr 4.15e-04 | grad 1.46 | tok/s 7935
step    750 | loss 1.3830 | lr 4.15e-04 | grad 1.16 | tok/s 8058
step    760 | loss 1.2784 | lr 4.15e-04 | grad 1.10 | tok/s 8055
step    770 | loss 1.2333 | lr 4.15e-04 | grad 1.22 | tok/s 8058
step    780 | loss 1.1908 | lr 4.15e-04 | grad 1.05 | tok/s 8058
step    790 | loss 1.2761 | lr 4.15e-04 | grad 1.69 | tok/s 7803
step    800 | loss 1.9790 | lr 4.15e-04 | grad 3.00 | tok/s 7781
step    810 | loss 1.7742 | lr 4.15e-04 | grad 1.21 | tok/s 7740
step    820 | loss 1.8037 | lr 4.15e-04 | grad 2.03 | tok/s 7432
step    830 | loss 1.6945 | lr 4.15e-04 | grad 1.17 | tok/s 7976
step    840 | loss 1.5405 | lr 4.15e-04 | grad 1.03 | tok/s 8059
step    850 | loss 1.6632 | lr 4.15e-04 | grad 1.39 | tok/s 8017
step    860 | loss 1.5977 | lr 4.15e-04 | grad 2.41 | tok/s 7923
step    870 | loss 1.6231 | lr 4.15e-04 | grad 1.41 | tok/s 7635
step    880 | loss 1.7831 | lr 4.15e-04 | grad 1.25 | tok/s 7672
step    890 | loss 1.7759 | lr 4.15e-04 | grad 1.65 | tok/s 7780
step    900 | loss 1.6452 | lr 4.15e-04 | grad 1.21 | tok/s 7789
step    910 | loss 1.5130 | lr 4.15e-04 | grad 1.52 | tok/s 7614
step    920 | loss 1.6507 | lr 4.15e-04 | grad 1.88 | tok/s 7927
step    930 | loss 1.7041 | lr 4.15e-04 | grad 1.71 | tok/s 7568
step    940 | loss 1.5304 | lr 4.15e-04 | grad 1.09 | tok/s 7983
step    950 | loss 1.5667 | lr 4.15e-04 | grad 1.16 | tok/s 8021
step    960 | loss 1.4323 | lr 4.15e-04 | grad 1.22 | tok/s 8031
step    970 | loss 1.7970 | lr 4.15e-04 | grad 1.62 | tok/s 7551
step    980 | loss 1.6952 | lr 4.15e-04 | grad 1.16 | tok/s 7758
step    990 | loss 1.5704 | lr 4.15e-04 | grad 1.06 | tok/s 7889
step   1000 | loss 1.9416 | lr 4.15e-04 | grad 4.94 | tok/s 7567
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9416.pt
step   1010 | loss 1.8475 | lr 4.15e-04 | grad 1.40 | tok/s 4238
step   1020 | loss 1.7509 | lr 4.15e-04 | grad 1.60 | tok/s 7392
step   1030 | loss 1.5187 | lr 4.15e-04 | grad 0.97 | tok/s 7713
step   1040 | loss 1.5912 | lr 4.15e-04 | grad 2.02 | tok/s 7864
step   1050 | loss 1.6677 | lr 4.15e-04 | grad 1.24 | tok/s 7406
step   1060 | loss 1.8069 | lr 4.15e-04 | grad 1.38 | tok/s 7914
step   1070 | loss 1.7677 | lr 4.15e-04 | grad 1.80 | tok/s 7785
step   1080 | loss 1.4839 | lr 4.15e-04 | grad 1.09 | tok/s 7204
step   1090 | loss 1.0841 | lr 4.15e-04 | grad 0.54 | tok/s 7991
step   1100 | loss 1.6243 | lr 4.15e-04 | grad 1.55 | tok/s 7659
step   1110 | loss 1.4910 | lr 4.15e-04 | grad 1.35 | tok/s 8063
step   1120 | loss 1.4163 | lr 4.15e-04 | grad 1.19 | tok/s 8063
step   1130 | loss 1.3539 | lr 4.15e-04 | grad 1.15 | tok/s 8062
step   1140 | loss 1.3565 | lr 4.15e-04 | grad 1.02 | tok/s 8061
step   1150 | loss 1.3592 | lr 4.15e-04 | grad 1.21 | tok/s 8060
step   1160 | loss 1.2795 | lr 4.15e-04 | grad 1.32 | tok/s 8058
step   1170 | loss 1.3236 | lr 4.15e-04 | grad 1.12 | tok/s 8063
step   1180 | loss 1.3842 | lr 4.15e-04 | grad 1.26 | tok/s 8061
step   1190 | loss 1.2950 | lr 4.15e-04 | grad 1.27 | tok/s 8060
step   1200 | loss 1.2920 | lr 4.15e-04 | grad 0.95 | tok/s 8061
step   1210 | loss 1.3293 | lr 4.15e-04 | grad 0.97 | tok/s 8061
step   1220 | loss 1.3411 | lr 4.15e-04 | grad 1.02 | tok/s 8060
step   1230 | loss 1.3303 | lr 4.15e-04 | grad 1.12 | tok/s 8063
step   1240 | loss 1.3287 | lr 4.15e-04 | grad 1.58 | tok/s 7995
step   1250 | loss 2.0103 | lr 4.15e-04 | grad 1.36 | tok/s 7634
step   1260 | loss 1.4084 | lr 4.15e-04 | grad 3.39 | tok/s 7522
step   1270 | loss 1.8221 | lr 4.15e-04 | grad 1.39 | tok/s 7511
step   1280 | loss 1.6368 | lr 4.15e-04 | grad 1.98 | tok/s 7851
step   1290 | loss 1.5356 | lr 4.15e-04 | grad 1.26 | tok/s 7707
step   1300 | loss 1.5833 | lr 4.15e-04 | grad 0.98 | tok/s 7641
step   1310 | loss 1.5284 | lr 4.15e-04 | grad 0.94 | tok/s 8022
step   1320 | loss 1.6303 | lr 4.15e-04 | grad 1.15 | tok/s 7922
step   1330 | loss 1.6084 | lr 4.15e-04 | grad 0.97 | tok/s 7935
step   1340 | loss 1.6398 | lr 4.15e-04 | grad 1.91 | tok/s 7479
step   1350 | loss 1.7426 | lr 4.15e-04 | grad 1.12 | tok/s 7396
step   1360 | loss 1.5903 | lr 4.15e-04 | grad 0.80 | tok/s 7768
step   1370 | loss 1.5657 | lr 4.15e-04 | grad 4.62 | tok/s 7674
step   1380 | loss 1.6790 | lr 4.15e-04 | grad 2.02 | tok/s 7372
step   1390 | loss 1.5414 | lr 4.15e-04 | grad 3.61 | tok/s 7786
step   1400 | loss 1.4392 | lr 4.15e-04 | grad 0.84 | tok/s 7592
step   1410 | loss 1.5809 | lr 4.15e-04 | grad 4.72 | tok/s 7574
step   1420 | loss 1.7024 | lr 4.15e-04 | grad 1.23 | tok/s 7559
step   1430 | loss 1.4277 | lr 4.15e-04 | grad 1.24 | tok/s 7668
step   1440 | loss 1.1942 | lr 4.15e-04 | grad 1.36 | tok/s 8057
step   1450 | loss 1.2133 | lr 4.15e-04 | grad 1.16 | tok/s 7955
step   1460 | loss 1.7472 | lr 4.15e-04 | grad 1.16 | tok/s 7519
step   1470 | loss 1.5763 | lr 4.15e-04 | grad 1.12 | tok/s 7992
step   1480 | loss 1.9326 | lr 4.15e-04 | grad 1.94 | tok/s 7906
step   1490 | loss 1.6365 | lr 4.15e-04 | grad 1.38 | tok/s 8023
step   1500 | loss 1.3918 | lr 4.15e-04 | grad 1.03 | tok/s 8056
step   1510 | loss 1.6203 | lr 4.15e-04 | grad 1.38 | tok/s 7949
step   1520 | loss 1.4691 | lr 4.15e-04 | grad 1.78 | tok/s 7789
step   1530 | loss 1.4495 | lr 4.15e-04 | grad 2.61 | tok/s 7980
step   1540 | loss 1.6562 | lr 4.15e-04 | grad 1.41 | tok/s 7497
step   1550 | loss 1.3471 | lr 4.15e-04 | grad 1.38 | tok/s 8000
step   1560 | loss 1.6398 | lr 4.15e-04 | grad 0.83 | tok/s 7581
step   1570 | loss 1.3643 | lr 4.15e-04 | grad 1.10 | tok/s 7983
step   1580 | loss 1.7877 | lr 4.15e-04 | grad 2.44 | tok/s 7944
step   1590 | loss 1.6549 | lr 4.15e-04 | grad 1.12 | tok/s 7561
step   1600 | loss 0.9870 | lr 4.15e-04 | grad 0.56 | tok/s 8077
step   1610 | loss 1.1439 | lr 4.15e-04 | grad 1.04 | tok/s 7627
step   1620 | loss 1.4898 | lr 4.15e-04 | grad 1.84 | tok/s 7493
step   1630 | loss 1.4874 | lr 4.15e-04 | grad 1.21 | tok/s 7832
step   1640 | loss 1.4135 | lr 4.15e-04 | grad 1.18 | tok/s 7597
step   1650 | loss 1.5826 | lr 4.15e-04 | grad 1.16 | tok/s 7178
step   1660 | loss 1.4132 | lr 4.15e-04 | grad 0.93 | tok/s 8037
step   1670 | loss 1.5330 | lr 4.15e-04 | grad 2.28 | tok/s 7736
step   1680 | loss 1.7254 | lr 4.15e-04 | grad 0.87 | tok/s 7406
step   1690 | loss 1.5335 | lr 4.15e-04 | grad 1.77 | tok/s 7774
step   1700 | loss 1.5264 | lr 4.15e-04 | grad 1.01 | tok/s 7694
step   1710 | loss 1.5099 | lr 4.15e-04 | grad 1.07 | tok/s 7687
step   1720 | loss 1.5962 | lr 4.15e-04 | grad 1.26 | tok/s 8027
step   1730 | loss 1.2958 | lr 4.15e-04 | grad 1.66 | tok/s 8059
step   1740 | loss 1.4710 | lr 4.15e-04 | grad 1.13 | tok/s 7782
step   1750 | loss 1.5952 | lr 4.15e-04 | grad 1.34 | tok/s 7790
step   1760 | loss 1.5869 | lr 4.15e-04 | grad 1.09 | tok/s 7752
step   1770 | loss 1.4678 | lr 4.15e-04 | grad 1.14 | tok/s 7614
step   1780 | loss 1.5230 | lr 4.15e-04 | grad 1.02 | tok/s 7851
step   1790 | loss 1.4683 | lr 4.15e-04 | grad 1.61 | tok/s 7776
step   1800 | loss 1.6030 | lr 4.15e-04 | grad 1.18 | tok/s 7627
step   1810 | loss 1.5062 | lr 4.15e-04 | grad 2.09 | tok/s 7488
step   1820 | loss 1.5381 | lr 4.15e-04 | grad 3.70 | tok/s 7739
step   1830 | loss 1.5088 | lr 4.15e-04 | grad 2.47 | tok/s 7899
step   1840 | loss 1.5218 | lr 4.15e-04 | grad 0.86 | tok/s 7512
step   1850 | loss 1.3520 | lr 4.15e-04 | grad 1.25 | tok/s 8018
step   1860 | loss 1.3945 | lr 4.15e-04 | grad 1.27 | tok/s 7595
step   1870 | loss 1.4298 | lr 4.15e-04 | grad 0.83 | tok/s 7773
step   1880 | loss 1.3182 | lr 4.15e-04 | grad 1.19 | tok/s 7473
step   1890 | loss 1.5406 | lr 4.15e-04 | grad 1.14 | tok/s 7240
step   1900 | loss 1.4115 | lr 4.15e-04 | grad 1.26 | tok/s 7761
step   1910 | loss 1.4874 | lr 4.15e-04 | grad 1.20 | tok/s 7349
step   1920 | loss 1.4107 | lr 4.15e-04 | grad 1.00 | tok/s 8063
step   1930 | loss 1.4790 | lr 4.15e-04 | grad 1.61 | tok/s 7415
step   1940 | loss 1.4723 | lr 4.15e-04 | grad 1.48 | tok/s 7998
step   1950 | loss 1.9170 | lr 4.15e-04 | grad 1.56 | tok/s 7975
step   1960 | loss 1.5766 | lr 4.15e-04 | grad 1.87 | tok/s 8061
step   1970 | loss 1.5642 | lr 4.15e-04 | grad 1.02 | tok/s 7859
step   1980 | loss 1.5926 | lr 4.15e-04 | grad 1.18 | tok/s 7512
step   1990 | loss 1.6536 | lr 4.15e-04 | grad 1.41 | tok/s 7649
step   2000 | loss 1.5189 | lr 4.15e-04 | grad 1.18 | tok/s 7767
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5189.pt
step   2010 | loss 1.2156 | lr 4.15e-04 | grad 1.11 | tok/s 4437
step   2020 | loss 1.3464 | lr 4.15e-04 | grad 1.44 | tok/s 7865
step   2030 | loss 1.0152 | lr 4.15e-04 | grad 1.80 | tok/s 8076
step   2040 | loss 1.3947 | lr 4.15e-04 | grad 1.30 | tok/s 8064
step   2050 | loss 1.3014 | lr 4.15e-04 | grad 0.84 | tok/s 7777
step   2060 | loss 1.6595 | lr 4.15e-04 | grad 0.98 | tok/s 7570
step   2070 | loss 1.8157 | lr 4.15e-04 | grad 3.45 | tok/s 7647
step   2080 | loss 2.0967 | lr 4.15e-04 | grad 2.48 | tok/s 8063
step   2090 | loss 1.6654 | lr 4.15e-04 | grad 1.74 | tok/s 7904
step   2100 | loss 1.4583 | lr 4.15e-04 | grad 1.49 | tok/s 7920
step   2110 | loss 1.5305 | lr 4.15e-04 | grad 1.30 | tok/s 7509
step   2120 | loss 0.8895 | lr 4.15e-04 | grad 1.17 | tok/s 8084
step   2130 | loss 1.3123 | lr 4.15e-04 | grad 1.51 | tok/s 7747
step   2140 | loss 1.4667 | lr 4.15e-04 | grad 1.02 | tok/s 7830
step   2150 | loss 1.3119 | lr 4.15e-04 | grad 1.32 | tok/s 8057
step   2160 | loss 1.2036 | lr 4.15e-04 | grad 1.36 | tok/s 8056
step   2170 | loss 1.2651 | lr 4.15e-04 | grad 1.01 | tok/s 8053
step   2180 | loss 1.2185 | lr 4.15e-04 | grad 0.77 | tok/s 8057
step   2190 | loss 1.2383 | lr 4.15e-04 | grad 1.23 | tok/s 8058
step   2200 | loss 1.2072 | lr 4.15e-04 | grad 0.90 | tok/s 8057
step   2210 | loss 1.1780 | lr 4.15e-04 | grad 1.52 | tok/s 8057
step   2220 | loss 1.1634 | lr 4.15e-04 | grad 1.04 | tok/s 8059
step   2230 | loss 1.4174 | lr 4.15e-04 | grad 1.30 | tok/s 7905
step   2240 | loss 1.3303 | lr 4.15e-04 | grad 1.00 | tok/s 7770
step   2250 | loss 1.5896 | lr 4.15e-04 | grad 2.92 | tok/s 8056
step   2260 | loss 1.6139 | lr 4.15e-04 | grad 1.19 | tok/s 7783
step   2270 | loss 2.0030 | lr 4.15e-04 | grad 1.38 | tok/s 7965
step   2280 | loss 1.4612 | lr 4.15e-04 | grad 2.12 | tok/s 8053
step   2290 | loss 1.5807 | lr 4.15e-04 | grad 6.00 | tok/s 7767
step   2300 | loss 1.6186 | lr 4.15e-04 | grad 1.71 | tok/s 7886
step   2310 | loss 1.4703 | lr 4.15e-04 | grad 1.36 | tok/s 7596
step   2320 | loss 1.8838 | lr 4.15e-04 | grad 1.62 | tok/s 7565
step   2330 | loss 1.6013 | lr 4.15e-04 | grad 1.45 | tok/s 7616
step   2340 | loss 1.5729 | lr 4.15e-04 | grad 1.42 | tok/s 7511
step   2350 | loss 1.4111 | lr 4.15e-04 | grad 1.30 | tok/s 7860
step   2360 | loss 1.2956 | lr 4.15e-04 | grad 0.75 | tok/s 8057
step   2370 | loss 1.6077 | lr 4.15e-04 | grad 1.80 | tok/s 7888
step   2380 | loss 1.5024 | lr 4.15e-04 | grad 1.44 | tok/s 8059
step   2390 | loss 1.1776 | lr 4.15e-04 | grad 0.98 | tok/s 8041
step   2400 | loss 1.0989 | lr 4.15e-04 | grad 0.90 | tok/s 8060
step   2410 | loss 1.2233 | lr 4.15e-04 | grad 0.94 | tok/s 7716
step   2420 | loss 1.5061 | lr 4.15e-04 | grad 1.08 | tok/s 7440
step   2430 | loss 1.3793 | lr 4.15e-04 | grad 1.48 | tok/s 7866
step   2440 | loss 1.3540 | lr 4.15e-04 | grad 0.91 | tok/s 7788
step   2450 | loss 1.5015 | lr 4.15e-04 | grad 0.99 | tok/s 7766
step   2460 | loss 1.2625 | lr 4.15e-04 | grad 0.94 | tok/s 7999
step   2470 | loss 1.2179 | lr 4.15e-04 | grad 1.09 | tok/s 7949
step   2480 | loss 1.2469 | lr 4.15e-04 | grad 1.73 | tok/s 7988
step   2490 | loss 1.4367 | lr 4.15e-04 | grad 1.20 | tok/s 7616
step   2500 | loss 1.5144 | lr 4.15e-04 | grad 1.57 | tok/s 7952
step   2510 | loss 1.1172 | lr 4.15e-04 | grad 1.52 | tok/s 8054
step   2520 | loss 1.5520 | lr 4.15e-04 | grad 1.09 | tok/s 7937
step   2530 | loss 1.3266 | lr 4.15e-04 | grad 1.09 | tok/s 7772
step   2540 | loss 1.4158 | lr 4.15e-04 | grad 1.20 | tok/s 7736
step   2550 | loss 1.1941 | lr 4.15e-04 | grad 0.84 | tok/s 8057
step   2560 | loss 1.5531 | lr 4.15e-04 | grad 2.14 | tok/s 7482
step   2570 | loss 1.3474 | lr 4.15e-04 | grad 1.16 | tok/s 7725
step   2580 | loss 1.3949 | lr 4.15e-04 | grad 1.20 | tok/s 7464
step   2590 | loss 1.4509 | lr 4.15e-04 | grad 1.03 | tok/s 7649
step   2600 | loss 1.6892 | lr 4.15e-04 | grad 2.44 | tok/s 7489
step   2610 | loss 1.3099 | lr 4.15e-04 | grad 1.59 | tok/s 7994
step   2620 | loss 1.5589 | lr 4.15e-04 | grad 1.08 | tok/s 7787
step   2630 | loss 1.4017 | lr 4.15e-04 | grad 1.17 | tok/s 7979
step   2640 | loss 1.6268 | lr 4.15e-04 | grad 1.76 | tok/s 7759
step   2650 | loss 1.4388 | lr 4.15e-04 | grad 1.20 | tok/s 7924
step   2660 | loss 1.3507 | lr 4.15e-04 | grad 1.41 | tok/s 7776
step   2670 | loss 1.4303 | lr 4.15e-04 | grad 1.07 | tok/s 7452
step   2680 | loss 1.7140 | lr 4.15e-04 | grad 1.51 | tok/s 7738
step   2690 | loss 1.3260 | lr 4.15e-04 | grad 1.58 | tok/s 8000
step   2700 | loss 1.4824 | lr 4.15e-04 | grad 1.48 | tok/s 7796
step   2710 | loss 1.5362 | lr 4.15e-04 | grad 1.04 | tok/s 7472
step   2720 | loss 1.3760 | lr 4.15e-04 | grad 1.34 | tok/s 7355
step   2730 | loss 1.1891 | lr 4.15e-04 | grad 1.30 | tok/s 7980
step   2740 | loss 1.7515 | lr 4.15e-04 | grad 2.28 | tok/s 7871
step   2750 | loss 1.5810 | lr 4.15e-04 | grad 0.98 | tok/s 7893
step   2760 | loss 1.3925 | lr 4.15e-04 | grad 1.40 | tok/s 7463
step   2770 | loss 1.4815 | lr 4.15e-04 | grad 1.33 | tok/s 7710
step   2780 | loss 1.1490 | lr 4.15e-04 | grad 0.90 | tok/s 7956
step   2790 | loss 1.8608 | lr 4.15e-04 | grad 1.48 | tok/s 7503
step   2800 | loss 1.2623 | lr 4.15e-04 | grad 1.01 | tok/s 7816
step   2810 | loss 1.3227 | lr 4.15e-04 | grad 1.40 | tok/s 7527
step   2820 | loss 1.4074 | lr 4.15e-04 | grad 1.16 | tok/s 7525
step   2830 | loss 1.1373 | lr 4.15e-04 | grad 1.39 | tok/s 7983
step   2840 | loss 1.0058 | lr 4.15e-04 | grad 1.07 | tok/s 7990
step   2850 | loss 1.7259 | lr 4.15e-04 | grad 1.38 | tok/s 7706
step   2860 | loss 1.6991 | lr 4.15e-04 | grad 1.16 | tok/s 7755
step   2870 | loss 1.4500 | lr 4.15e-04 | grad 1.34 | tok/s 7687
step   2880 | loss 1.4482 | lr 4.15e-04 | grad 1.09 | tok/s 7901
step   2890 | loss 1.3450 | lr 4.15e-04 | grad 2.12 | tok/s 8037
step   2900 | loss 1.4149 | lr 4.15e-04 | grad 0.95 | tok/s 7723
step   2910 | loss 1.4986 | lr 4.15e-04 | grad 1.57 | tok/s 7724
step   2920 | loss 1.6158 | lr 4.15e-04 | grad 3.31 | tok/s 7567
step   2930 | loss 1.4969 | lr 4.15e-04 | grad 1.62 | tok/s 7773
step   2940 | loss 1.2974 | lr 4.15e-04 | grad 1.17 | tok/s 7319
step   2950 | loss 1.3238 | lr 4.15e-04 | grad 1.04 | tok/s 7790
step   2960 | loss 1.4008 | lr 4.15e-04 | grad 1.14 | tok/s 7844
step   2970 | loss 1.4016 | lr 4.15e-04 | grad 1.88 | tok/s 7628
step   2980 | loss 1.9195 | lr 4.15e-04 | grad 5.66 | tok/s 7892
step   2990 | loss 1.9278 | lr 4.15e-04 | grad 1.29 | tok/s 7884
step   3000 | loss 1.3578 | lr 4.15e-04 | grad 1.06 | tok/s 7869
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3578.pt
step   3010 | loss 1.1703 | lr 4.15e-04 | grad 1.02 | tok/s 4335
step   3020 | loss 1.4164 | lr 4.15e-04 | grad 0.96 | tok/s 7726
step   3030 | loss 1.4660 | lr 4.15e-04 | grad 2.14 | tok/s 7733
step   3040 | loss 1.4818 | lr 4.15e-04 | grad 1.16 | tok/s 7831
step   3050 | loss 1.4471 | lr 4.15e-04 | grad 1.06 | tok/s 7751
step   3060 | loss 1.3475 | lr 4.15e-04 | grad 1.06 | tok/s 7953
step   3070 | loss 1.6420 | lr 4.15e-04 | grad 1.02 | tok/s 8027
step   3080 | loss 1.3877 | lr 4.15e-04 | grad 0.93 | tok/s 7820
step   3090 | loss 1.4036 | lr 4.15e-04 | grad 1.58 | tok/s 7798
step   3100 | loss 1.5126 | lr 4.15e-04 | grad 1.15 | tok/s 7716
step   3110 | loss 1.1439 | lr 4.15e-04 | grad 0.97 | tok/s 8056
step   3120 | loss 1.0500 | lr 4.15e-04 | grad 0.94 | tok/s 8055
step   3130 | loss 1.5233 | lr 4.15e-04 | grad 1.35 | tok/s 7608
step   3140 | loss 1.0564 | lr 4.15e-04 | grad 1.03 | tok/s 8058
step   3150 | loss 1.2281 | lr 4.15e-04 | grad 1.57 | tok/s 7980
step   3160 | loss 1.5735 | lr 4.15e-04 | grad 2.59 | tok/s 7602
step   3170 | loss 1.3354 | lr 4.15e-04 | grad 0.83 | tok/s 7643
step   3180 | loss 1.4116 | lr 4.15e-04 | grad 0.83 | tok/s 7683
step   3190 | loss 1.0028 | lr 4.15e-04 | grad 1.62 | tok/s 7919
step   3200 | loss 1.4828 | lr 4.15e-04 | grad 1.94 | tok/s 7767
step   3210 | loss 1.7438 | lr 4.15e-04 | grad 2.22 | tok/s 7932
step   3220 | loss 2.0825 | lr 4.15e-04 | grad 1.65 | tok/s 7957
step   3230 | loss 1.7299 | lr 4.15e-04 | grad 1.85 | tok/s 8054
step   3240 | loss 1.5284 | lr 4.15e-04 | grad 1.44 | tok/s 8054
step   3250 | loss 1.5052 | lr 4.15e-04 | grad 1.50 | tok/s 8061
step   3260 | loss 1.4065 | lr 4.15e-04 | grad 1.83 | tok/s 8061
step   3270 | loss 1.3992 | lr 4.15e-04 | grad 1.45 | tok/s 8054
step   3280 | loss 1.3113 | lr 4.15e-04 | grad 1.52 | tok/s 8056
step   3290 | loss 1.3217 | lr 4.15e-04 | grad 1.62 | tok/s 8059
step   3300 | loss 1.3049 | lr 4.15e-04 | grad 1.31 | tok/s 8058
step   3310 | loss 1.2494 | lr 4.15e-04 | grad 1.16 | tok/s 8058
step   3320 | loss 1.2837 | lr 4.15e-04 | grad 1.51 | tok/s 8053
step   3330 | loss 1.5318 | lr 4.15e-04 | grad 2.31 | tok/s 7928
step   3340 | loss 1.4310 | lr 4.15e-04 | grad 1.91 | tok/s 7659
step   3350 | loss 1.4093 | lr 4.15e-04 | grad 1.16 | tok/s 7774
step   3360 | loss 1.3656 | lr 4.15e-04 | grad 0.98 | tok/s 7391
step   3370 | loss 1.5005 | lr 4.15e-04 | grad 1.10 | tok/s 7512
step   3380 | loss 1.4845 | lr 4.15e-04 | grad 1.11 | tok/s 7757
step   3390 | loss 1.3896 | lr 4.15e-04 | grad 1.04 | tok/s 7800
step   3400 | loss 1.1550 | lr 4.15e-04 | grad 0.86 | tok/s 8056
step   3410 | loss 1.0705 | lr 4.15e-04 | grad 1.07 | tok/s 8056
step   3420 | loss 1.5437 | lr 4.15e-04 | grad 1.04 | tok/s 7499
step   3430 | loss 1.4164 | lr 4.15e-04 | grad 1.43 | tok/s 7835
step   3440 | loss 1.4708 | lr 4.15e-04 | grad 1.12 | tok/s 7619
step   3450 | loss 1.4139 | lr 4.15e-04 | grad 1.85 | tok/s 7793
step   3460 | loss 1.4691 | lr 4.15e-04 | grad 1.24 | tok/s 7845
step   3470 | loss 1.3704 | lr 4.15e-04 | grad 1.26 | tok/s 7898

Training complete! Final step: 3475
