Using device: cuda
Output directory: benchmark_results/cmaes_4d/e1_480M_converge0.01_20260202_122123/eval_26/level1_100m_20260202_135257
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 353,371,392 parameters
Using schedule-free AdamW (lr=0.00046121666432074156)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 3.9982 | lr 4.61e-04 | grad 3.41 | tok/s 9419
step     20 | loss 2.5774 | lr 4.61e-04 | grad 1.43 | tok/s 16735
step     30 | loss 2.9861 | lr 4.61e-04 | grad 1.81 | tok/s 17732
step     40 | loss 4.0227 | lr 4.61e-04 | grad 8.88 | tok/s 18112
step     50 | loss 3.7676 | lr 4.61e-04 | grad 5.03 | tok/s 18380
step     60 | loss 2.9618 | lr 4.61e-04 | grad 2.28 | tok/s 18365
step     70 | loss 2.5945 | lr 4.61e-04 | grad 3.41 | tok/s 18345
step     80 | loss 2.3591 | lr 4.61e-04 | grad 2.62 | tok/s 18349
step     90 | loss 2.3049 | lr 4.61e-04 | grad 1.87 | tok/s 18339
step    100 | loss 2.1602 | lr 4.61e-04 | grad 1.49 | tok/s 18321
step    110 | loss 2.3154 | lr 4.61e-04 | grad 3.11 | tok/s 18184
step    120 | loss 2.7977 | lr 4.61e-04 | grad 1.56 | tok/s 17303
step    130 | loss 2.2193 | lr 4.61e-04 | grad 2.34 | tok/s 17720
step    140 | loss 2.4524 | lr 4.61e-04 | grad 3.42 | tok/s 17772
step    150 | loss 1.7933 | lr 4.61e-04 | grad 3.56 | tok/s 18191
step    160 | loss 2.4435 | lr 4.61e-04 | grad 1.17 | tok/s 17608
step    170 | loss 2.3219 | lr 4.61e-04 | grad 1.05 | tok/s 17353
step    180 | loss 2.1215 | lr 4.61e-04 | grad 1.57 | tok/s 17765
step    190 | loss 2.0016 | lr 4.61e-04 | grad 1.40 | tok/s 17444
step    200 | loss 1.7715 | lr 4.61e-04 | grad 1.24 | tok/s 18242
step    210 | loss 1.9451 | lr 4.61e-04 | grad 2.03 | tok/s 17287
step    220 | loss 2.2717 | lr 4.61e-04 | grad 2.25 | tok/s 17488
step    230 | loss 2.0773 | lr 4.61e-04 | grad 1.17 | tok/s 17467
step    240 | loss 2.2802 | lr 4.61e-04 | grad 2.33 | tok/s 17704
step    250 | loss 1.8432 | lr 4.61e-04 | grad 0.86 | tok/s 17588
step    260 | loss 1.9395 | lr 4.61e-04 | grad 1.41 | tok/s 18092
step    270 | loss 1.8666 | lr 4.61e-04 | grad 1.29 | tok/s 17660
step    280 | loss 1.8220 | lr 4.61e-04 | grad 1.10 | tok/s 16597
step    290 | loss 1.7277 | lr 4.61e-04 | grad 1.17 | tok/s 17142
step    300 | loss 2.0063 | lr 4.61e-04 | grad 1.17 | tok/s 17295
step    310 | loss 1.7014 | lr 4.61e-04 | grad 0.86 | tok/s 17217
step    320 | loss 1.9214 | lr 4.61e-04 | grad 1.85 | tok/s 17417
step    330 | loss 1.7506 | lr 4.61e-04 | grad 0.91 | tok/s 17608
step    340 | loss 2.0399 | lr 4.61e-04 | grad 1.26 | tok/s 17522
step    350 | loss 1.7836 | lr 4.61e-04 | grad 1.05 | tok/s 18033
step    360 | loss 1.6100 | lr 4.61e-04 | grad 0.91 | tok/s 17246
step    370 | loss 1.5525 | lr 4.61e-04 | grad 0.87 | tok/s 18179
step    380 | loss 1.2962 | lr 4.61e-04 | grad 0.98 | tok/s 18342
step    390 | loss 1.2192 | lr 4.61e-04 | grad 0.70 | tok/s 18336
step    400 | loss 1.8106 | lr 4.61e-04 | grad 0.95 | tok/s 17363
step    410 | loss 1.7797 | lr 4.61e-04 | grad 1.17 | tok/s 17538
step    420 | loss 1.6937 | lr 4.61e-04 | grad 1.23 | tok/s 18295
step    430 | loss 1.6235 | lr 4.61e-04 | grad 0.93 | tok/s 17989
step    440 | loss 1.7334 | lr 4.61e-04 | grad 1.17 | tok/s 17426
step    450 | loss 1.6472 | lr 4.61e-04 | grad 0.74 | tok/s 17626
step    460 | loss 1.6372 | lr 4.61e-04 | grad 0.97 | tok/s 17880
step    470 | loss 1.6240 | lr 4.61e-04 | grad 1.57 | tok/s 17754
step    480 | loss 1.5929 | lr 4.61e-04 | grad 1.45 | tok/s 18143
step    490 | loss 1.7110 | lr 4.61e-04 | grad 1.21 | tok/s 17405
step    500 | loss 1.8510 | lr 4.61e-04 | grad 0.84 | tok/s 17711
step    510 | loss 1.7285 | lr 4.61e-04 | grad 0.77 | tok/s 16909
step    520 | loss 1.5681 | lr 4.61e-04 | grad 0.94 | tok/s 17705
step    530 | loss 1.7313 | lr 4.61e-04 | grad 0.94 | tok/s 17409
step    540 | loss 1.6222 | lr 4.61e-04 | grad 0.73 | tok/s 17046
step    550 | loss 1.3762 | lr 4.61e-04 | grad 1.60 | tok/s 17807
step    560 | loss 1.4523 | lr 4.61e-04 | grad 0.83 | tok/s 18334
step    570 | loss 1.3653 | lr 4.61e-04 | grad 1.01 | tok/s 18338
step    580 | loss 1.3252 | lr 4.61e-04 | grad 0.86 | tok/s 18344
step    590 | loss 1.3625 | lr 4.61e-04 | grad 0.93 | tok/s 18343
step    600 | loss 1.3061 | lr 4.61e-04 | grad 0.83 | tok/s 18344
step    610 | loss 1.3267 | lr 4.61e-04 | grad 0.98 | tok/s 18344
step    620 | loss 1.3204 | lr 4.61e-04 | grad 0.77 | tok/s 18271
step    630 | loss 1.7673 | lr 4.61e-04 | grad 2.67 | tok/s 17255
step    640 | loss 1.7378 | lr 4.61e-04 | grad 0.91 | tok/s 17477
step    650 | loss 1.5707 | lr 4.61e-04 | grad 0.86 | tok/s 17456
step    660 | loss 1.6094 | lr 4.61e-04 | grad 0.91 | tok/s 18124
step    670 | loss 1.6410 | lr 4.61e-04 | grad 2.53 | tok/s 17532
step    680 | loss 1.6515 | lr 4.61e-04 | grad 1.14 | tok/s 17250
step    690 | loss 1.6201 | lr 4.61e-04 | grad 0.91 | tok/s 17123
step    700 | loss 1.4992 | lr 4.61e-04 | grad 0.72 | tok/s 17501
step    710 | loss 1.6682 | lr 4.61e-04 | grad 1.71 | tok/s 17226
step    720 | loss 1.3441 | lr 4.61e-04 | grad 0.82 | tok/s 17904
step    730 | loss 1.4982 | lr 4.61e-04 | grad 0.80 | tok/s 17611
step    740 | loss 1.7853 | lr 4.61e-04 | grad 1.95 | tok/s 18092
step    750 | loss 1.5782 | lr 4.61e-04 | grad 0.93 | tok/s 18303
step    760 | loss 1.5357 | lr 4.61e-04 | grad 1.90 | tok/s 17916
step    770 | loss 1.5693 | lr 4.61e-04 | grad 0.91 | tok/s 17609
step    780 | loss 1.5154 | lr 4.61e-04 | grad 0.97 | tok/s 17737
step    790 | loss 1.6670 | lr 4.61e-04 | grad 2.41 | tok/s 18124
step    800 | loss 1.3549 | lr 4.61e-04 | grad 0.79 | tok/s 17780
step    810 | loss 1.3480 | lr 4.61e-04 | grad 1.48 | tok/s 17190
step    820 | loss 1.4746 | lr 4.61e-04 | grad 1.09 | tok/s 17545
step    830 | loss 1.5257 | lr 4.61e-04 | grad 0.59 | tok/s 17313
step    840 | loss 1.6699 | lr 4.61e-04 | grad 0.85 | tok/s 17233
step    850 | loss 1.5533 | lr 4.61e-04 | grad 0.71 | tok/s 17596
step    860 | loss 1.6348 | lr 4.61e-04 | grad 1.30 | tok/s 17891
step    870 | loss 1.4690 | lr 4.61e-04 | grad 0.90 | tok/s 18028
step    880 | loss 1.5997 | lr 4.61e-04 | grad 0.86 | tok/s 17680
step    890 | loss 1.4970 | lr 4.61e-04 | grad 0.64 | tok/s 17611
step    900 | loss 1.5420 | lr 4.61e-04 | grad 0.75 | tok/s 17541
step    910 | loss 1.5371 | lr 4.61e-04 | grad 2.72 | tok/s 17341
step    920 | loss 1.5003 | lr 4.61e-04 | grad 0.84 | tok/s 17540
step    930 | loss 1.4124 | lr 4.61e-04 | grad 0.90 | tok/s 17744
step    940 | loss 1.3971 | lr 4.61e-04 | grad 0.97 | tok/s 17364
step    950 | loss 1.4941 | lr 4.61e-04 | grad 1.30 | tok/s 17050
step    960 | loss 1.4458 | lr 4.61e-04 | grad 0.73 | tok/s 17529
step    970 | loss 1.4734 | lr 4.61e-04 | grad 0.86 | tok/s 17537
step    980 | loss 1.8907 | lr 4.61e-04 | grad 1.84 | tok/s 18220
step    990 | loss 1.5976 | lr 4.61e-04 | grad 0.85 | tok/s 17485
step   1000 | loss 1.5676 | lr 4.61e-04 | grad 0.95 | tok/s 17541
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5676.pt
step   1010 | loss 1.3209 | lr 4.61e-04 | grad 1.00 | tok/s 12309
step   1020 | loss 1.2833 | lr 4.61e-04 | grad 0.91 | tok/s 18391
step   1030 | loss 1.4907 | lr 4.61e-04 | grad 1.24 | tok/s 17474
step   1040 | loss 2.0936 | lr 4.61e-04 | grad 2.41 | tok/s 17874
step   1050 | loss 1.6121 | lr 4.61e-04 | grad 0.77 | tok/s 18005
step   1060 | loss 1.2613 | lr 4.61e-04 | grad 0.54 | tok/s 17754
step   1070 | loss 1.3984 | lr 4.61e-04 | grad 0.66 | tok/s 17743
step   1080 | loss 1.2777 | lr 4.61e-04 | grad 0.88 | tok/s 18363
step   1090 | loss 1.2532 | lr 4.61e-04 | grad 0.70 | tok/s 18355
step   1100 | loss 1.2296 | lr 4.61e-04 | grad 0.89 | tok/s 18359
step   1110 | loss 1.1789 | lr 4.61e-04 | grad 0.78 | tok/s 18365
step   1120 | loss 1.4021 | lr 4.61e-04 | grad 0.91 | tok/s 17830
step   1130 | loss 1.6886 | lr 4.61e-04 | grad 0.92 | tok/s 18014
step   1140 | loss 1.8037 | lr 4.61e-04 | grad 0.91 | tok/s 18256
step   1150 | loss 1.7007 | lr 4.61e-04 | grad 1.54 | tok/s 17824
step   1160 | loss 1.6915 | lr 4.61e-04 | grad 2.52 | tok/s 17270
step   1170 | loss 1.5630 | lr 4.61e-04 | grad 0.98 | tok/s 17229
step   1180 | loss 1.3821 | lr 4.61e-04 | grad 0.80 | tok/s 18138
step   1190 | loss 1.5980 | lr 4.61e-04 | grad 1.17 | tok/s 18165
step   1200 | loss 1.2018 | lr 4.61e-04 | grad 0.63 | tok/s 18357
step   1210 | loss 1.3655 | lr 4.61e-04 | grad 0.80 | tok/s 17267
step   1220 | loss 1.4092 | lr 4.61e-04 | grad 0.95 | tok/s 17839
step   1230 | loss 1.4192 | lr 4.61e-04 | grad 0.73 | tok/s 17959
step   1240 | loss 1.2803 | lr 4.61e-04 | grad 1.17 | tok/s 18137
step   1250 | loss 1.5164 | lr 4.61e-04 | grad 1.23 | tok/s 17719
step   1260 | loss 1.4085 | lr 4.61e-04 | grad 0.86 | tok/s 18207
step   1270 | loss 1.3999 | lr 4.61e-04 | grad 1.11 | tok/s 17665
step   1280 | loss 1.3927 | lr 4.61e-04 | grad 1.09 | tok/s 17700
step   1290 | loss 1.3877 | lr 4.61e-04 | grad 1.07 | tok/s 17302
step   1300 | loss 1.6002 | lr 4.61e-04 | grad 4.06 | tok/s 17242
step   1310 | loss 1.5517 | lr 4.61e-04 | grad 0.73 | tok/s 17924
step   1320 | loss 1.5148 | lr 4.61e-04 | grad 1.88 | tok/s 17902
step   1330 | loss 1.4497 | lr 4.61e-04 | grad 0.97 | tok/s 17872
step   1340 | loss 1.6383 | lr 4.61e-04 | grad 1.09 | tok/s 17298
step   1350 | loss 1.4497 | lr 4.61e-04 | grad 0.88 | tok/s 17994
step   1360 | loss 1.4723 | lr 4.61e-04 | grad 0.91 | tok/s 16907
step   1370 | loss 1.5438 | lr 4.61e-04 | grad 2.12 | tok/s 18056
step   1380 | loss 1.5073 | lr 4.61e-04 | grad 1.02 | tok/s 17502
step   1390 | loss 1.3704 | lr 4.61e-04 | grad 1.10 | tok/s 17838
step   1400 | loss 1.5808 | lr 4.61e-04 | grad 0.72 | tok/s 17445
step   1410 | loss 1.3779 | lr 4.61e-04 | grad 0.87 | tok/s 17142
step   1420 | loss 1.1301 | lr 4.61e-04 | grad 1.06 | tok/s 18205
step   1430 | loss 1.7611 | lr 4.61e-04 | grad 0.76 | tok/s 17611
step   1440 | loss 1.4832 | lr 4.61e-04 | grad 1.23 | tok/s 17749
step   1450 | loss 1.4364 | lr 4.61e-04 | grad 0.63 | tok/s 17940
step   1460 | loss 1.6101 | lr 4.61e-04 | grad 1.33 | tok/s 17415
step   1470 | loss 1.4217 | lr 4.61e-04 | grad 0.95 | tok/s 17185
step   1480 | loss 1.4208 | lr 4.61e-04 | grad 1.29 | tok/s 17817
step   1490 | loss 1.6515 | lr 4.61e-04 | grad 2.55 | tok/s 17669
step   1500 | loss 1.6130 | lr 4.61e-04 | grad 0.86 | tok/s 17944
step   1510 | loss 1.3013 | lr 4.61e-04 | grad 0.75 | tok/s 17574
step   1520 | loss 1.4934 | lr 4.61e-04 | grad 1.09 | tok/s 17516
step   1530 | loss 1.4120 | lr 4.61e-04 | grad 0.98 | tok/s 18000
step   1540 | loss 1.5065 | lr 4.61e-04 | grad 0.77 | tok/s 17992
step   1550 | loss 1.5019 | lr 4.61e-04 | grad 2.25 | tok/s 17674
step   1560 | loss 1.1838 | lr 4.61e-04 | grad 0.71 | tok/s 18259
step   1570 | loss 1.3686 | lr 4.61e-04 | grad 0.73 | tok/s 17850
step   1580 | loss 1.2514 | lr 4.61e-04 | grad 0.99 | tok/s 17939
step   1590 | loss 1.4959 | lr 4.61e-04 | grad 1.82 | tok/s 17254
step   1600 | loss 1.2491 | lr 4.61e-04 | grad 3.20 | tok/s 18194
step   1610 | loss 1.8832 | lr 4.61e-04 | grad 1.76 | tok/s 17775
step   1620 | loss 1.8750 | lr 4.61e-04 | grad 1.34 | tok/s 18354
step   1630 | loss 1.5566 | lr 4.61e-04 | grad 1.35 | tok/s 18332
step   1640 | loss 1.4278 | lr 4.61e-04 | grad 1.13 | tok/s 18347
step   1650 | loss 1.3443 | lr 4.61e-04 | grad 0.99 | tok/s 18350
step   1660 | loss 1.3002 | lr 4.61e-04 | grad 0.90 | tok/s 18359
step   1670 | loss 1.5011 | lr 4.61e-04 | grad 1.45 | tok/s 17776
step   1680 | loss 1.4023 | lr 4.61e-04 | grad 0.97 | tok/s 17615
step   1690 | loss 1.4849 | lr 4.61e-04 | grad 1.27 | tok/s 17217
step   1700 | loss 1.3445 | lr 4.61e-04 | grad 1.47 | tok/s 17882
step   1710 | loss 1.2877 | lr 4.61e-04 | grad 1.37 | tok/s 17959
step   1720 | loss 1.4521 | lr 4.61e-04 | grad 0.79 | tok/s 17378
step   1730 | loss 1.4732 | lr 4.61e-04 | grad 1.97 | tok/s 17954
step   1740 | loss 1.4068 | lr 4.61e-04 | grad 0.95 | tok/s 18045
step   1750 | loss 1.2622 | lr 4.61e-04 | grad 0.83 | tok/s 17667
step   1760 | loss 1.4095 | lr 4.61e-04 | grad 0.96 | tok/s 17467
step   1770 | loss 1.6360 | lr 4.61e-04 | grad 0.82 | tok/s 17904
step   1780 | loss 1.7620 | lr 4.61e-04 | grad 0.80 | tok/s 16888
step   1790 | loss 1.3526 | lr 4.61e-04 | grad 1.09 | tok/s 17167
step   1800 | loss 1.2829 | lr 4.61e-04 | grad 0.82 | tok/s 17581
step   1810 | loss 1.4375 | lr 4.61e-04 | grad 1.02 | tok/s 17742
step   1820 | loss 1.5319 | lr 4.61e-04 | grad 1.66 | tok/s 17504
step   1830 | loss 1.3972 | lr 4.61e-04 | grad 0.82 | tok/s 17015
step   1840 | loss 1.3615 | lr 4.61e-04 | grad 0.95 | tok/s 17613
step   1850 | loss 1.4260 | lr 4.61e-04 | grad 1.10 | tok/s 17477
step   1860 | loss 1.4509 | lr 4.61e-04 | grad 1.02 | tok/s 17412
step   1870 | loss 1.4613 | lr 4.61e-04 | grad 1.25 | tok/s 17714
step   1880 | loss 1.4940 | lr 4.61e-04 | grad 1.20 | tok/s 17864
step   1890 | loss 1.2575 | lr 4.61e-04 | grad 0.76 | tok/s 18351
step   1900 | loss 1.1942 | lr 4.61e-04 | grad 0.72 | tok/s 18337
step   1910 | loss 1.1840 | lr 4.61e-04 | grad 0.71 | tok/s 18342
step   1920 | loss 1.1647 | lr 4.61e-04 | grad 0.80 | tok/s 18360
step   1930 | loss 1.2106 | lr 4.61e-04 | grad 1.73 | tok/s 18289
step   1940 | loss 1.5544 | lr 4.61e-04 | grad 1.06 | tok/s 17390
step   1950 | loss 1.4182 | lr 4.61e-04 | grad 0.77 | tok/s 17238
step   1960 | loss 1.4923 | lr 4.61e-04 | grad 1.24 | tok/s 17467
step   1970 | loss 1.5504 | lr 4.61e-04 | grad 0.95 | tok/s 17828
step   1980 | loss 1.4263 | lr 4.61e-04 | grad 1.23 | tok/s 17288
step   1990 | loss 1.5322 | lr 4.61e-04 | grad 2.33 | tok/s 17750
step   2000 | loss 1.1775 | lr 4.61e-04 | grad 0.71 | tok/s 18333
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1775.pt
step   2010 | loss 1.3224 | lr 4.61e-04 | grad 1.40 | tok/s 12071
step   2020 | loss 1.3755 | lr 4.61e-04 | grad 0.99 | tok/s 17411
step   2030 | loss 1.7682 | lr 4.61e-04 | grad 11.06 | tok/s 17191
step   2040 | loss 1.4824 | lr 4.61e-04 | grad 1.18 | tok/s 17534
step   2050 | loss 1.3382 | lr 4.61e-04 | grad 0.82 | tok/s 17768
step   2060 | loss 1.5441 | lr 4.61e-04 | grad 1.85 | tok/s 17794
step   2070 | loss 1.3235 | lr 4.61e-04 | grad 1.27 | tok/s 17776
step   2080 | loss 1.3252 | lr 4.61e-04 | grad 0.83 | tok/s 16931
step   2090 | loss 1.2925 | lr 4.61e-04 | grad 2.06 | tok/s 18104
step   2100 | loss 1.5923 | lr 4.61e-04 | grad 1.34 | tok/s 18279
step   2110 | loss 1.4338 | lr 4.61e-04 | grad 1.07 | tok/s 17485
step   2120 | loss 2.1172 | lr 4.61e-04 | grad 2.81 | tok/s 17887
step   2130 | loss 1.4420 | lr 4.61e-04 | grad 0.95 | tok/s 17023
step   2140 | loss 1.5841 | lr 4.61e-04 | grad 0.91 | tok/s 17990
step   2150 | loss 1.6501 | lr 4.61e-04 | grad 0.96 | tok/s 17606
step   2160 | loss 1.5000 | lr 4.61e-04 | grad 0.97 | tok/s 17682
step   2170 | loss 1.4399 | lr 4.61e-04 | grad 2.67 | tok/s 17832
step   2180 | loss 1.2037 | lr 4.61e-04 | grad 1.60 | tok/s 18196
step   2190 | loss 1.5054 | lr 4.61e-04 | grad 0.98 | tok/s 17621
step   2200 | loss 1.2705 | lr 4.61e-04 | grad 1.51 | tok/s 18251
step   2210 | loss 1.4103 | lr 4.61e-04 | grad 0.93 | tok/s 17952
step   2220 | loss 1.4268 | lr 4.61e-04 | grad 0.90 | tok/s 17252
step   2230 | loss 1.6275 | lr 4.61e-04 | grad 1.11 | tok/s 17379
step   2240 | loss 1.3453 | lr 4.61e-04 | grad 0.96 | tok/s 17717
step   2250 | loss 1.3980 | lr 4.61e-04 | grad 0.98 | tok/s 17360
step   2260 | loss 1.5463 | lr 4.61e-04 | grad 2.45 | tok/s 18134
step   2270 | loss 1.6423 | lr 4.61e-04 | grad 1.36 | tok/s 16910
step   2280 | loss 1.4471 | lr 4.61e-04 | grad 0.72 | tok/s 17634
step   2290 | loss 1.3032 | lr 4.61e-04 | grad 0.90 | tok/s 17406
step   2300 | loss 1.5784 | lr 4.61e-04 | grad 0.75 | tok/s 17320
step   2310 | loss 1.4355 | lr 4.61e-04 | grad 0.99 | tok/s 17588
step   2320 | loss 1.3952 | lr 4.61e-04 | grad 0.70 | tok/s 18354
step   2330 | loss 1.2848 | lr 4.61e-04 | grad 1.05 | tok/s 18353
step   2340 | loss 1.2409 | lr 4.61e-04 | grad 0.88 | tok/s 18361
step   2350 | loss 1.2250 | lr 4.61e-04 | grad 0.84 | tok/s 18366
step   2360 | loss 1.1958 | lr 4.61e-04 | grad 0.74 | tok/s 18370
step   2370 | loss 1.1673 | lr 4.61e-04 | grad 0.73 | tok/s 18355
step   2380 | loss 1.1605 | lr 4.61e-04 | grad 0.96 | tok/s 18366
step   2390 | loss 1.1663 | lr 4.61e-04 | grad 0.78 | tok/s 18361
step   2400 | loss 1.1457 | lr 4.61e-04 | grad 0.88 | tok/s 18360
step   2410 | loss 1.2170 | lr 4.61e-04 | grad 0.87 | tok/s 18362
step   2420 | loss 1.5145 | lr 4.61e-04 | grad 0.73 | tok/s 17767
step   2430 | loss 1.0697 | lr 4.61e-04 | grad 0.88 | tok/s 17802
step   2440 | loss 1.4126 | lr 4.61e-04 | grad 0.64 | tok/s 16777
step   2450 | loss 1.3490 | lr 4.61e-04 | grad 0.84 | tok/s 17648
step   2460 | loss 1.5339 | lr 4.61e-04 | grad 1.27 | tok/s 18022
step   2470 | loss 1.3438 | lr 4.61e-04 | grad 3.44 | tok/s 17780
step   2480 | loss 1.4922 | lr 4.61e-04 | grad 2.12 | tok/s 17739
step   2490 | loss 1.4607 | lr 4.61e-04 | grad 2.22 | tok/s 17941
step   2500 | loss 1.5889 | lr 4.61e-04 | grad 1.62 | tok/s 17778
step   2510 | loss 1.4989 | lr 4.61e-04 | grad 0.96 | tok/s 17609
step   2520 | loss 1.3267 | lr 4.61e-04 | grad 1.18 | tok/s 17445
step   2530 | loss 1.5484 | lr 4.61e-04 | grad 0.87 | tok/s 17810
step   2540 | loss 1.4545 | lr 4.61e-04 | grad 1.32 | tok/s 17071
step   2550 | loss 1.3646 | lr 4.61e-04 | grad 0.78 | tok/s 17709
step   2560 | loss 1.5788 | lr 4.61e-04 | grad 0.92 | tok/s 17351
step   2570 | loss 1.3699 | lr 4.61e-04 | grad 0.75 | tok/s 17500
step   2580 | loss 1.5348 | lr 4.61e-04 | grad 0.94 | tok/s 17549
step   2590 | loss 1.3770 | lr 4.61e-04 | grad 1.17 | tok/s 17363
step   2600 | loss 1.4830 | lr 4.61e-04 | grad 0.64 | tok/s 17129
step   2610 | loss 1.3825 | lr 4.61e-04 | grad 0.74 | tok/s 17999
step   2620 | loss 1.5001 | lr 4.61e-04 | grad 0.93 | tok/s 17404
step   2630 | loss 1.2270 | lr 4.61e-04 | grad 0.59 | tok/s 18203
step   2640 | loss 1.3264 | lr 4.61e-04 | grad 1.00 | tok/s 17440
step   2650 | loss 1.2951 | lr 4.61e-04 | grad 0.92 | tok/s 17714
step   2660 | loss 1.3226 | lr 4.61e-04 | grad 0.64 | tok/s 17732
step   2670 | loss 1.1544 | lr 4.61e-04 | grad 0.99 | tok/s 18237
step   2680 | loss 1.3854 | lr 4.61e-04 | grad 0.86 | tok/s 17173
step   2690 | loss 1.3495 | lr 4.61e-04 | grad 0.77 | tok/s 17156
step   2700 | loss 1.3998 | lr 4.61e-04 | grad 0.87 | tok/s 17503
step   2710 | loss 1.6222 | lr 4.61e-04 | grad 4.00 | tok/s 17793
step   2720 | loss 1.4410 | lr 4.61e-04 | grad 1.02 | tok/s 17796
step   2730 | loss 1.3081 | lr 4.61e-04 | grad 0.84 | tok/s 17563
step   2740 | loss 1.4095 | lr 4.61e-04 | grad 0.95 | tok/s 17489
step   2750 | loss 1.4361 | lr 4.61e-04 | grad 0.97 | tok/s 17690
step   2760 | loss 1.2316 | lr 4.61e-04 | grad 0.99 | tok/s 18133
step   2770 | loss 1.3425 | lr 4.61e-04 | grad 1.78 | tok/s 17812
step   2780 | loss 1.2806 | lr 4.61e-04 | grad 1.62 | tok/s 17717
step   2790 | loss 1.4392 | lr 4.61e-04 | grad 1.97 | tok/s 17678
step   2800 | loss 1.4950 | lr 4.61e-04 | grad 1.02 | tok/s 17051
step   2810 | loss 1.3807 | lr 4.61e-04 | grad 0.92 | tok/s 17437
step   2820 | loss 1.4237 | lr 4.61e-04 | grad 0.72 | tok/s 16761
step   2830 | loss 1.2505 | lr 4.61e-04 | grad 0.90 | tok/s 17449
step   2840 | loss 1.2387 | lr 4.61e-04 | grad 0.63 | tok/s 17365
step   2850 | loss 1.2170 | lr 4.61e-04 | grad 0.92 | tok/s 18265
step   2860 | loss 1.1714 | lr 4.61e-04 | grad 2.17 | tok/s 18122
step   2870 | loss 1.3821 | lr 4.61e-04 | grad 1.01 | tok/s 17500
step   2880 | loss 1.3686 | lr 4.61e-04 | grad 0.82 | tok/s 17006
step   2890 | loss 1.4774 | lr 4.61e-04 | grad 0.69 | tok/s 17748
step   2900 | loss 1.5472 | lr 4.61e-04 | grad 0.85 | tok/s 17243
step   2910 | loss 1.3316 | lr 4.61e-04 | grad 4.78 | tok/s 17970
step   2920 | loss 1.3670 | lr 4.61e-04 | grad 0.84 | tok/s 17315
step   2930 | loss 1.3198 | lr 4.61e-04 | grad 1.06 | tok/s 17917
step   2940 | loss 1.2990 | lr 4.61e-04 | grad 1.06 | tok/s 17560
step   2950 | loss 1.6700 | lr 4.61e-04 | grad 0.94 | tok/s 17714
step   2960 | loss 1.3595 | lr 4.61e-04 | grad 1.73 | tok/s 17232
step   2970 | loss 1.6191 | lr 4.61e-04 | grad 0.71 | tok/s 17537
step   2980 | loss 1.3688 | lr 4.61e-04 | grad 0.86 | tok/s 17899
step   2990 | loss 1.4359 | lr 4.61e-04 | grad 1.09 | tok/s 18000
step   3000 | loss 1.3812 | lr 4.61e-04 | grad 1.38 | tok/s 17684
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3812.pt
step   3010 | loss 1.3821 | lr 4.61e-04 | grad 0.77 | tok/s 12456
step   3020 | loss 1.3706 | lr 4.61e-04 | grad 0.85 | tok/s 17704
step   3030 | loss 1.3052 | lr 4.61e-04 | grad 1.12 | tok/s 16927
step   3040 | loss 1.3481 | lr 4.61e-04 | grad 0.78 | tok/s 18090
step   3050 | loss 1.2624 | lr 4.61e-04 | grad 0.79 | tok/s 17885
step   3060 | loss 1.0724 | lr 4.61e-04 | grad 0.80 | tok/s 18174
step   3070 | loss 2.0083 | lr 4.61e-04 | grad 6.00 | tok/s 17342
step   3080 | loss 1.6536 | lr 4.61e-04 | grad 1.18 | tok/s 18059
step   3090 | loss 1.4304 | lr 4.61e-04 | grad 0.98 | tok/s 17254
step   3100 | loss 1.3695 | lr 4.61e-04 | grad 0.81 | tok/s 17268
step   3110 | loss 1.3584 | lr 4.61e-04 | grad 4.16 | tok/s 18313
step   3120 | loss 1.4197 | lr 4.61e-04 | grad 2.06 | tok/s 17400
step   3130 | loss 1.2842 | lr 4.61e-04 | grad 0.95 | tok/s 17528
step   3140 | loss 1.3105 | lr 4.61e-04 | grad 0.85 | tok/s 17481
step   3150 | loss 1.3623 | lr 4.61e-04 | grad 0.93 | tok/s 16722
step   3160 | loss 1.5116 | lr 4.61e-04 | grad 0.69 | tok/s 17893
step   3170 | loss 1.3602 | lr 4.61e-04 | grad 1.38 | tok/s 18130
step   3180 | loss 1.1240 | lr 4.61e-04 | grad 1.08 | tok/s 18179
step   3190 | loss 1.4753 | lr 4.61e-04 | grad 0.76 | tok/s 17905
step   3200 | loss 1.3356 | lr 4.61e-04 | grad 0.68 | tok/s 17620
step   3210 | loss 1.4301 | lr 4.61e-04 | grad 0.88 | tok/s 17796
step   3220 | loss 1.3163 | lr 4.61e-04 | grad 0.82 | tok/s 18014
step   3230 | loss 1.3411 | lr 4.61e-04 | grad 1.37 | tok/s 17504
step   3240 | loss 1.3169 | lr 4.61e-04 | grad 0.72 | tok/s 17280
step   3250 | loss 1.3649 | lr 4.61e-04 | grad 0.86 | tok/s 16856
step   3260 | loss 1.3988 | lr 4.61e-04 | grad 1.22 | tok/s 17455
step   3270 | loss 1.3494 | lr 4.61e-04 | grad 1.03 | tok/s 17315
step   3280 | loss 1.4960 | lr 4.61e-04 | grad 0.89 | tok/s 17515
step   3290 | loss 1.2106 | lr 4.61e-04 | grad 0.77 | tok/s 17795
step   3300 | loss 1.4586 | lr 4.61e-04 | grad 1.44 | tok/s 18057
step   3310 | loss 1.4520 | lr 4.61e-04 | grad 0.78 | tok/s 17830
step   3320 | loss 1.7286 | lr 4.61e-04 | grad 1.32 | tok/s 17821
step   3330 | loss 1.3251 | lr 4.61e-04 | grad 0.85 | tok/s 16812
step   3340 | loss 1.2659 | lr 4.61e-04 | grad 0.96 | tok/s 18209
step   3350 | loss 1.3196 | lr 4.61e-04 | grad 2.27 | tok/s 18126
step   3360 | loss 1.3031 | lr 4.61e-04 | grad 0.86 | tok/s 17557
step   3370 | loss 1.5097 | lr 4.61e-04 | grad 1.20 | tok/s 17279
step   3380 | loss 1.4469 | lr 4.61e-04 | grad 1.12 | tok/s 17988
step   3390 | loss 1.3129 | lr 4.61e-04 | grad 1.31 | tok/s 17300
step   3400 | loss 1.3297 | lr 4.61e-04 | grad 0.79 | tok/s 17709
step   3410 | loss 1.4920 | lr 4.61e-04 | grad 0.70 | tok/s 17199
step   3420 | loss 1.4547 | lr 4.61e-04 | grad 0.87 | tok/s 17665
step   3430 | loss 1.3870 | lr 4.61e-04 | grad 1.46 | tok/s 17807
step   3440 | loss 1.3061 | lr 4.61e-04 | grad 0.92 | tok/s 17497
step   3450 | loss 1.4287 | lr 4.61e-04 | grad 1.00 | tok/s 17211
step   3460 | loss 1.3492 | lr 4.61e-04 | grad 0.74 | tok/s 17269
step   3470 | loss 1.6364 | lr 4.61e-04 | grad 1.20 | tok/s 18034
step   3480 | loss 1.3118 | lr 4.61e-04 | grad 0.88 | tok/s 16815
step   3490 | loss 1.4638 | lr 4.61e-04 | grad 1.01 | tok/s 17877
step   3500 | loss 1.4694 | lr 4.61e-04 | grad 1.49 | tok/s 17383
step   3510 | loss 1.4068 | lr 4.61e-04 | grad 0.69 | tok/s 16661
step   3520 | loss 1.2723 | lr 4.61e-04 | grad 1.18 | tok/s 17757
step   3530 | loss 1.5659 | lr 4.61e-04 | grad 0.90 | tok/s 17728
step   3540 | loss 1.4488 | lr 4.61e-04 | grad 0.86 | tok/s 17078
step   3550 | loss 1.2902 | lr 4.61e-04 | grad 1.06 | tok/s 17797
step   3560 | loss 1.4057 | lr 4.61e-04 | grad 0.57 | tok/s 17797
step   3570 | loss 1.3725 | lr 4.61e-04 | grad 0.66 | tok/s 18048
step   3580 | loss 1.2287 | lr 4.61e-04 | grad 0.66 | tok/s 17623
step   3590 | loss 1.3312 | lr 4.61e-04 | grad 0.69 | tok/s 17236
step   3600 | loss 1.2721 | lr 4.61e-04 | grad 0.74 | tok/s 17686
step   3610 | loss 1.3630 | lr 4.61e-04 | grad 0.90 | tok/s 17386
step   3620 | loss 1.4058 | lr 4.61e-04 | grad 0.85 | tok/s 17197
step   3630 | loss 1.3552 | lr 4.61e-04 | grad 1.79 | tok/s 17502
step   3640 | loss 1.5064 | lr 4.61e-04 | grad 0.94 | tok/s 17379
step   3650 | loss 1.5097 | lr 4.61e-04 | grad 1.09 | tok/s 17573
step   3660 | loss 1.4568 | lr 4.61e-04 | grad 1.25 | tok/s 16945
step   3670 | loss 1.3068 | lr 4.61e-04 | grad 0.91 | tok/s 17547
step   3680 | loss 1.3063 | lr 4.61e-04 | grad 1.74 | tok/s 17352
step   3690 | loss 1.3188 | lr 4.61e-04 | grad 0.62 | tok/s 18020
step   3700 | loss 1.1596 | lr 4.61e-04 | grad 0.77 | tok/s 18195
step   3710 | loss 1.4010 | lr 4.61e-04 | grad 0.86 | tok/s 17459
step   3720 | loss 1.3511 | lr 4.61e-04 | grad 0.75 | tok/s 18274
step   3730 | loss 1.4628 | lr 4.61e-04 | grad 2.92 | tok/s 17358
step   3740 | loss 1.4134 | lr 4.61e-04 | grad 1.71 | tok/s 17626
step   3750 | loss 1.3838 | lr 4.61e-04 | grad 0.82 | tok/s 17614
step   3760 | loss 1.3411 | lr 4.61e-04 | grad 0.95 | tok/s 18027
step   3770 | loss 1.4318 | lr 4.61e-04 | grad 2.59 | tok/s 16957
step   3780 | loss 1.5569 | lr 4.61e-04 | grad 0.94 | tok/s 18065
step   3790 | loss 1.2395 | lr 4.61e-04 | grad 0.88 | tok/s 17542
step   3800 | loss 1.2070 | lr 4.61e-04 | grad 2.09 | tok/s 17927
step   3810 | loss 1.2607 | lr 4.61e-04 | grad 1.07 | tok/s 17585
step   3820 | loss 1.2682 | lr 4.61e-04 | grad 0.95 | tok/s 18030
step   3830 | loss 1.2998 | lr 4.61e-04 | grad 0.62 | tok/s 18343
step   3840 | loss 1.4940 | lr 4.61e-04 | grad 8.94 | tok/s 18013
step   3850 | loss 1.3086 | lr 4.61e-04 | grad 0.84 | tok/s 17831
step   3860 | loss 1.3689 | lr 4.61e-04 | grad 1.32 | tok/s 17576
step   3870 | loss 1.5283 | lr 4.61e-04 | grad 3.62 | tok/s 17952
step   3880 | loss 1.0181 | lr 4.61e-04 | grad 0.97 | tok/s 17760
step   3890 | loss 1.2363 | lr 4.61e-04 | grad 1.27 | tok/s 17711
step   3900 | loss 1.3406 | lr 4.61e-04 | grad 1.05 | tok/s 17540
step   3910 | loss 1.3866 | lr 4.61e-04 | grad 0.75 | tok/s 17213
step   3920 | loss 1.2908 | lr 4.61e-04 | grad 0.75 | tok/s 18213
step   3930 | loss 1.4115 | lr 4.61e-04 | grad 0.81 | tok/s 17271
step   3940 | loss 1.3306 | lr 4.61e-04 | grad 1.71 | tok/s 17813
step   3950 | loss 1.3377 | lr 4.61e-04 | grad 1.14 | tok/s 18002
step   3960 | loss 1.2353 | lr 4.61e-04 | grad 0.70 | tok/s 17913
step   3970 | loss 1.0985 | lr 4.61e-04 | grad 0.79 | tok/s 18343
step   3980 | loss 1.0557 | lr 4.61e-04 | grad 0.78 | tok/s 18336

Training complete! Final step: 3983
