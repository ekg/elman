Using device: cuda
Output directory: benchmark_results/cmaes_4d/e75_480M_converge0.01_20260202_222930/eval_1/levelE75h7n32_100m_20260202_222936
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h7n32, 182,010,720 parameters
Using schedule-free AdamW (lr=0.00033681535317363467)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 4.4147 | lr 3.37e-04 | grad 11.75 | tok/s 19649
step     20 | loss 4.1488 | lr 3.37e-04 | grad 9.69 | tok/s 45923
step     30 | loss 4.0417 | lr 3.37e-04 | grad 6.47 | tok/s 46429
step     40 | loss 3.4732 | lr 3.37e-04 | grad 4.47 | tok/s 46290
step     50 | loss 3.0189 | lr 3.37e-04 | grad 3.81 | tok/s 46112
step     60 | loss 3.1736 | lr 3.37e-04 | grad 3.19 | tok/s 44115
step     70 | loss 3.0848 | lr 3.37e-04 | grad 6.59 | tok/s 44592
step     80 | loss 2.8707 | lr 3.37e-04 | grad 1.89 | tok/s 44171
step     90 | loss 2.8369 | lr 3.37e-04 | grad 1.55 | tok/s 43005
step    100 | loss 2.3958 | lr 3.37e-04 | grad 1.95 | tok/s 44483
step    110 | loss 2.7703 | lr 3.37e-04 | grad 1.51 | tok/s 42839
step    120 | loss 2.6339 | lr 3.37e-04 | grad 1.38 | tok/s 43186
step    130 | loss 2.4234 | lr 3.37e-04 | grad 2.08 | tok/s 43951
step    140 | loss 2.2071 | lr 3.37e-04 | grad 1.62 | tok/s 41865
step    150 | loss 2.2619 | lr 3.37e-04 | grad 1.27 | tok/s 42170
step    160 | loss 2.2427 | lr 3.37e-04 | grad 1.12 | tok/s 42212
step    170 | loss 2.4055 | lr 3.37e-04 | grad 2.19 | tok/s 43147
step    180 | loss 2.1484 | lr 3.37e-04 | grad 1.85 | tok/s 42976
step    190 | loss 1.9264 | lr 3.37e-04 | grad 1.71 | tok/s 44400
step    200 | loss 2.0486 | lr 3.37e-04 | grad 1.16 | tok/s 42981
step    210 | loss 2.1876 | lr 3.37e-04 | grad 1.65 | tok/s 43652
step    220 | loss 2.0973 | lr 3.37e-04 | grad 1.43 | tok/s 42726
step    230 | loss 1.9650 | lr 3.37e-04 | grad 1.40 | tok/s 42676
step    240 | loss 2.0719 | lr 3.37e-04 | grad 1.44 | tok/s 43544
step    250 | loss 2.1045 | lr 3.37e-04 | grad 1.24 | tok/s 42475
step    260 | loss 1.9089 | lr 3.37e-04 | grad 1.75 | tok/s 41459
step    270 | loss 1.9582 | lr 3.37e-04 | grad 3.73 | tok/s 42426
step    280 | loss 1.7610 | lr 3.37e-04 | grad 1.45 | tok/s 43746
step    290 | loss 1.6307 | lr 3.37e-04 | grad 1.48 | tok/s 44367
step    300 | loss 1.6505 | lr 3.37e-04 | grad 1.45 | tok/s 44313
step    310 | loss 1.7299 | lr 3.37e-04 | grad 1.73 | tok/s 43863
step    320 | loss 1.9307 | lr 3.37e-04 | grad 1.20 | tok/s 41799
step    330 | loss 1.9350 | lr 3.37e-04 | grad 2.16 | tok/s 43144
step    340 | loss 1.8807 | lr 3.37e-04 | grad 2.11 | tok/s 41682
step    350 | loss 1.8520 | lr 3.37e-04 | grad 1.19 | tok/s 41477
step    360 | loss 1.7573 | lr 3.37e-04 | grad 1.74 | tok/s 42818
step    370 | loss 2.2242 | lr 3.37e-04 | grad 1.53 | tok/s 42984
step    380 | loss 1.7852 | lr 3.37e-04 | grad 1.54 | tok/s 43622
step    390 | loss 1.7676 | lr 3.37e-04 | grad 1.23 | tok/s 42610
step    400 | loss 1.8039 | lr 3.37e-04 | grad 1.22 | tok/s 42871
step    410 | loss 1.7742 | lr 3.37e-04 | grad 1.47 | tok/s 41671
step    420 | loss 1.8527 | lr 3.37e-04 | grad 2.75 | tok/s 41801
step    430 | loss 1.9876 | lr 3.37e-04 | grad 2.45 | tok/s 43062
step    440 | loss 1.8191 | lr 3.37e-04 | grad 1.18 | tok/s 42302
step    450 | loss 1.7481 | lr 3.37e-04 | grad 1.12 | tok/s 42330
step    460 | loss 1.7901 | lr 3.37e-04 | grad 2.03 | tok/s 42394
step    470 | loss 1.6501 | lr 3.37e-04 | grad 1.15 | tok/s 41212
step    480 | loss 1.6334 | lr 3.37e-04 | grad 1.12 | tok/s 42112
step    490 | loss 2.2047 | lr 3.37e-04 | grad 1.62 | tok/s 43376
step    500 | loss 1.7279 | lr 3.37e-04 | grad 3.34 | tok/s 42502
step    510 | loss 1.5429 | lr 3.37e-04 | grad 1.23 | tok/s 43617
step    520 | loss 2.1470 | lr 3.37e-04 | grad 1.77 | tok/s 42446
step    530 | loss 1.5809 | lr 3.37e-04 | grad 1.34 | tok/s 42984
step    540 | loss 1.5638 | lr 3.37e-04 | grad 1.34 | tok/s 43411
step    550 | loss 1.4113 | lr 3.37e-04 | grad 1.30 | tok/s 44257
step    560 | loss 1.5692 | lr 3.37e-04 | grad 3.56 | tok/s 43502
step    570 | loss 2.0043 | lr 3.37e-04 | grad 1.47 | tok/s 43665
step    580 | loss 2.1446 | lr 3.37e-04 | grad 2.86 | tok/s 41992
step    590 | loss 1.6262 | lr 3.37e-04 | grad 1.54 | tok/s 42429
step    600 | loss 1.7237 | lr 3.37e-04 | grad 1.49 | tok/s 44083
step    610 | loss 1.6100 | lr 3.37e-04 | grad 1.38 | tok/s 41838
step    620 | loss 1.5591 | lr 3.37e-04 | grad 1.22 | tok/s 43495
step    630 | loss 1.8559 | lr 3.37e-04 | grad 1.48 | tok/s 43423
step    640 | loss 1.6256 | lr 3.37e-04 | grad 1.51 | tok/s 42349
step    650 | loss 1.8147 | lr 3.37e-04 | grad 5.22 | tok/s 41783
step    660 | loss 1.7504 | lr 3.37e-04 | grad 2.06 | tok/s 43151
step    670 | loss 1.7653 | lr 3.37e-04 | grad 1.73 | tok/s 42325
step    680 | loss 1.7016 | lr 3.37e-04 | grad 1.76 | tok/s 41934
step    690 | loss 1.8124 | lr 3.37e-04 | grad 2.14 | tok/s 42482
step    700 | loss 1.7138 | lr 3.37e-04 | grad 1.42 | tok/s 42823
step    710 | loss 1.7182 | lr 3.37e-04 | grad 4.47 | tok/s 42356
step    720 | loss 1.7807 | lr 3.37e-04 | grad 1.51 | tok/s 42668
step    730 | loss 1.7722 | lr 3.37e-04 | grad 2.72 | tok/s 42484
step    740 | loss 1.5674 | lr 3.37e-04 | grad 1.39 | tok/s 42001
step    750 | loss 1.8863 | lr 3.37e-04 | grad 1.10 | tok/s 42541
step    760 | loss 1.5987 | lr 3.37e-04 | grad 1.17 | tok/s 42455
step    770 | loss 1.6747 | lr 3.37e-04 | grad 1.46 | tok/s 43146
step    780 | loss 1.5372 | lr 3.37e-04 | grad 1.05 | tok/s 43285
step    790 | loss 1.5981 | lr 3.37e-04 | grad 3.34 | tok/s 42757
step    800 | loss 1.5493 | lr 3.37e-04 | grad 1.56 | tok/s 42412
step    810 | loss 2.3333 | lr 3.37e-04 | grad 2.39 | tok/s 43794
step    820 | loss 1.9865 | lr 3.37e-04 | grad 2.12 | tok/s 44104
step    830 | loss 1.7504 | lr 3.37e-04 | grad 1.88 | tok/s 44153
step    840 | loss 1.7250 | lr 3.37e-04 | grad 1.16 | tok/s 42112
step    850 | loss 1.5541 | lr 3.37e-04 | grad 1.12 | tok/s 42606
step    860 | loss 1.5732 | lr 3.37e-04 | grad 1.53 | tok/s 42469
step    870 | loss 1.6663 | lr 3.37e-04 | grad 1.24 | tok/s 43222
step    880 | loss 1.5665 | lr 3.37e-04 | grad 2.31 | tok/s 41977
step    890 | loss 1.9211 | lr 3.37e-04 | grad 1.41 | tok/s 41731
step    900 | loss 1.5376 | lr 3.37e-04 | grad 1.34 | tok/s 41838
step    910 | loss 1.6226 | lr 3.37e-04 | grad 1.09 | tok/s 42157
step    920 | loss 1.5868 | lr 3.37e-04 | grad 1.43 | tok/s 42010
step    930 | loss 1.6489 | lr 3.37e-04 | grad 1.44 | tok/s 41960
step    940 | loss 1.6283 | lr 3.37e-04 | grad 1.29 | tok/s 42958
step    950 | loss 1.4006 | lr 3.37e-04 | grad 1.16 | tok/s 44186
step    960 | loss 1.3337 | lr 3.37e-04 | grad 1.14 | tok/s 44125
step    970 | loss 1.5639 | lr 3.37e-04 | grad 1.34 | tok/s 42611
step    980 | loss 1.7104 | lr 3.37e-04 | grad 1.96 | tok/s 41746
step    990 | loss 1.6911 | lr 3.37e-04 | grad 2.02 | tok/s 42420
step   1000 | loss 1.5966 | lr 3.37e-04 | grad 1.44 | tok/s 43389
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5966.pt
step   1010 | loss 1.5589 | lr 3.37e-04 | grad 1.38 | tok/s 30041
step   1020 | loss 1.8731 | lr 3.37e-04 | grad 1.06 | tok/s 42222
step   1030 | loss 1.6885 | lr 3.37e-04 | grad 2.09 | tok/s 42628
step   1040 | loss 1.3963 | lr 3.37e-04 | grad 1.31 | tok/s 42103
step   1050 | loss 1.9537 | lr 3.37e-04 | grad 1.77 | tok/s 43801
step   1060 | loss 2.0464 | lr 3.37e-04 | grad 3.11 | tok/s 42217
step   1070 | loss 1.6734 | lr 3.37e-04 | grad 0.99 | tok/s 42323
step   1080 | loss 1.8133 | lr 3.37e-04 | grad 1.12 | tok/s 42776
step   1090 | loss 1.5259 | lr 3.37e-04 | grad 2.33 | tok/s 43443
step   1100 | loss 1.6257 | lr 3.37e-04 | grad 2.89 | tok/s 43309
step   1110 | loss 1.6618 | lr 3.37e-04 | grad 1.46 | tok/s 42019
step   1120 | loss 1.6200 | lr 3.37e-04 | grad 1.66 | tok/s 42560
step   1130 | loss 1.6188 | lr 3.37e-04 | grad 1.16 | tok/s 42454
step   1140 | loss 1.7111 | lr 3.37e-04 | grad 1.23 | tok/s 41790
step   1150 | loss 1.6813 | lr 3.37e-04 | grad 1.63 | tok/s 41762
step   1160 | loss 1.5320 | lr 3.37e-04 | grad 1.28 | tok/s 43651
step   1170 | loss 1.4664 | lr 3.37e-04 | grad 1.05 | tok/s 44244
step   1180 | loss 1.3862 | lr 3.37e-04 | grad 1.18 | tok/s 44181
step   1190 | loss 1.3389 | lr 3.37e-04 | grad 1.05 | tok/s 44134
step   1200 | loss 1.3299 | lr 3.37e-04 | grad 1.24 | tok/s 44138
step   1210 | loss 1.4769 | lr 3.37e-04 | grad 1.16 | tok/s 43426
step   1220 | loss 1.4444 | lr 3.37e-04 | grad 1.73 | tok/s 41364
step   1230 | loss 1.6079 | lr 3.37e-04 | grad 1.30 | tok/s 43112
step   1240 | loss 1.5753 | lr 3.37e-04 | grad 1.95 | tok/s 42677
step   1250 | loss 1.7770 | lr 3.37e-04 | grad 1.23 | tok/s 42483
step   1260 | loss 1.6035 | lr 3.37e-04 | grad 1.66 | tok/s 42270
step   1270 | loss 1.6476 | lr 3.37e-04 | grad 2.03 | tok/s 41946
step   1280 | loss 1.6191 | lr 3.37e-04 | grad 1.07 | tok/s 42020
step   1290 | loss 1.6700 | lr 3.37e-04 | grad 1.64 | tok/s 42117
step   1300 | loss 1.5579 | lr 3.37e-04 | grad 0.96 | tok/s 41829
step   1310 | loss 1.6585 | lr 3.37e-04 | grad 1.26 | tok/s 42585
step   1320 | loss 1.4623 | lr 3.37e-04 | grad 0.89 | tok/s 42547
step   1330 | loss 1.4643 | lr 3.37e-04 | grad 1.24 | tok/s 42874
step   1340 | loss 1.5058 | lr 3.37e-04 | grad 1.15 | tok/s 42358
step   1350 | loss 1.5033 | lr 3.37e-04 | grad 1.19 | tok/s 41841
step   1360 | loss 1.7225 | lr 3.37e-04 | grad 1.13 | tok/s 42519
step   1370 | loss 1.5453 | lr 3.37e-04 | grad 1.24 | tok/s 42260
step   1380 | loss 1.4997 | lr 3.37e-04 | grad 1.09 | tok/s 43000
step   1390 | loss 1.6671 | lr 3.37e-04 | grad 1.45 | tok/s 42917
step   1400 | loss 1.5926 | lr 3.37e-04 | grad 1.25 | tok/s 41530
step   1410 | loss 1.5550 | lr 3.37e-04 | grad 1.59 | tok/s 41227
step   1420 | loss 1.3741 | lr 3.37e-04 | grad 0.93 | tok/s 41979
step   1430 | loss 1.3574 | lr 3.37e-04 | grad 1.57 | tok/s 43534
step   1440 | loss 1.5447 | lr 3.37e-04 | grad 0.99 | tok/s 41641
step   1450 | loss 1.6495 | lr 3.37e-04 | grad 1.47 | tok/s 42077
step   1460 | loss 1.4981 | lr 3.37e-04 | grad 5.19 | tok/s 42645
step   1470 | loss 1.5236 | lr 3.37e-04 | grad 1.20 | tok/s 42672
step   1480 | loss 1.7941 | lr 3.37e-04 | grad 2.61 | tok/s 41872
step   1490 | loss 1.5883 | lr 3.37e-04 | grad 1.14 | tok/s 42752
step   1500 | loss 1.6050 | lr 3.37e-04 | grad 1.54 | tok/s 42838
step   1510 | loss 1.5382 | lr 3.37e-04 | grad 0.98 | tok/s 42829
step   1520 | loss 1.5145 | lr 3.37e-04 | grad 1.35 | tok/s 42131
step   1530 | loss 1.3431 | lr 3.37e-04 | grad 1.53 | tok/s 43345
step   1540 | loss 2.1421 | lr 3.37e-04 | grad 1.30 | tok/s 42601
step   1550 | loss 1.5569 | lr 3.37e-04 | grad 1.48 | tok/s 41474
step   1560 | loss 1.6354 | lr 3.37e-04 | grad 2.84 | tok/s 42996
step   1570 | loss 1.4589 | lr 3.37e-04 | grad 1.22 | tok/s 42058
step   1580 | loss 1.5518 | lr 3.37e-04 | grad 1.07 | tok/s 41600
step   1590 | loss 1.3820 | lr 3.37e-04 | grad 1.19 | tok/s 43563
step   1600 | loss 1.5565 | lr 3.37e-04 | grad 1.14 | tok/s 42786
step   1610 | loss 1.5429 | lr 3.37e-04 | grad 1.05 | tok/s 43042
step   1620 | loss 1.4636 | lr 3.37e-04 | grad 1.06 | tok/s 41906
step   1630 | loss 1.5455 | lr 3.37e-04 | grad 1.88 | tok/s 41244
step   1640 | loss 1.5438 | lr 3.37e-04 | grad 1.21 | tok/s 41932
step   1650 | loss 1.5313 | lr 3.37e-04 | grad 2.58 | tok/s 43093
step   1660 | loss 1.8843 | lr 3.37e-04 | grad 1.12 | tok/s 42866
step   1670 | loss 1.4583 | lr 3.37e-04 | grad 1.29 | tok/s 42119
step   1680 | loss 1.6310 | lr 3.37e-04 | grad 0.98 | tok/s 42886
step   1690 | loss 1.6240 | lr 3.37e-04 | grad 2.23 | tok/s 42405
step   1700 | loss 1.5150 | lr 3.37e-04 | grad 1.58 | tok/s 42084
step   1710 | loss 1.6540 | lr 3.37e-04 | grad 1.44 | tok/s 41929
step   1720 | loss 1.5591 | lr 3.37e-04 | grad 0.91 | tok/s 42474
step   1730 | loss 1.5259 | lr 3.37e-04 | grad 1.12 | tok/s 41483
step   1740 | loss 1.6800 | lr 3.37e-04 | grad 1.44 | tok/s 41953
step   1750 | loss 1.6330 | lr 3.37e-04 | grad 2.11 | tok/s 42451
step   1760 | loss 1.4976 | lr 3.37e-04 | grad 1.95 | tok/s 41507
step   1770 | loss 1.6908 | lr 3.37e-04 | grad 1.06 | tok/s 41969
step   1780 | loss 1.4758 | lr 3.37e-04 | grad 1.11 | tok/s 42804
step   1790 | loss 1.4810 | lr 3.37e-04 | grad 1.08 | tok/s 42906
step   1800 | loss 1.4446 | lr 3.37e-04 | grad 1.20 | tok/s 41982
step   1810 | loss 1.5137 | lr 3.37e-04 | grad 1.12 | tok/s 41598
step   1820 | loss 1.5964 | lr 3.37e-04 | grad 1.21 | tok/s 42087
step   1830 | loss 1.6580 | lr 3.37e-04 | grad 1.13 | tok/s 41508
step   1840 | loss 1.4428 | lr 3.37e-04 | grad 1.61 | tok/s 41969
step   1850 | loss 1.4431 | lr 3.37e-04 | grad 0.92 | tok/s 43613
step   1860 | loss 1.5228 | lr 3.37e-04 | grad 1.19 | tok/s 42930
step   1870 | loss 1.6211 | lr 3.37e-04 | grad 2.38 | tok/s 42055
step   1880 | loss 1.5214 | lr 3.37e-04 | grad 1.45 | tok/s 42838
step   1890 | loss 1.6390 | lr 3.37e-04 | grad 1.59 | tok/s 42104
step   1900 | loss 1.3859 | lr 3.37e-04 | grad 1.83 | tok/s 42616
step   1910 | loss 1.4363 | lr 3.37e-04 | grad 1.07 | tok/s 42908
step   1920 | loss 1.5457 | lr 3.37e-04 | grad 3.83 | tok/s 43717
step   1930 | loss 1.4605 | lr 3.37e-04 | grad 1.20 | tok/s 42638
step   1940 | loss 1.6673 | lr 3.37e-04 | grad 1.09 | tok/s 42958
step   1950 | loss 1.4295 | lr 3.37e-04 | grad 1.59 | tok/s 42373
step   1960 | loss 1.5898 | lr 3.37e-04 | grad 1.35 | tok/s 42649
step   1970 | loss 1.5161 | lr 3.37e-04 | grad 2.16 | tok/s 42195
step   1980 | loss 1.4886 | lr 3.37e-04 | grad 1.20 | tok/s 43251
step   1990 | loss 1.2190 | lr 3.37e-04 | grad 1.04 | tok/s 44219
step   2000 | loss 1.2229 | lr 3.37e-04 | grad 0.95 | tok/s 44165
  >>> saved checkpoint: checkpoint_step_002000_loss_1.2229.pt
step   2010 | loss 1.4776 | lr 3.37e-04 | grad 1.19 | tok/s 32047
step   2020 | loss 1.2835 | lr 3.37e-04 | grad 0.94 | tok/s 44269
step   2030 | loss 1.4549 | lr 3.37e-04 | grad 2.36 | tok/s 42885
step   2040 | loss 1.5323 | lr 3.37e-04 | grad 1.20 | tok/s 42560
step   2050 | loss 1.5194 | lr 3.37e-04 | grad 2.27 | tok/s 43016
step   2060 | loss 1.5887 | lr 3.37e-04 | grad 1.66 | tok/s 42666
step   2070 | loss 1.4757 | lr 3.37e-04 | grad 1.28 | tok/s 42415
step   2080 | loss 1.4395 | lr 3.37e-04 | grad 1.49 | tok/s 42236
step   2090 | loss 1.3947 | lr 3.37e-04 | grad 1.05 | tok/s 42665
step   2100 | loss 1.2203 | lr 3.37e-04 | grad 1.27 | tok/s 42979
step   2110 | loss 1.5823 | lr 3.37e-04 | grad 0.89 | tok/s 41962
step   2120 | loss 1.5861 | lr 3.37e-04 | grad 1.05 | tok/s 42123
step   2130 | loss 1.5521 | lr 3.37e-04 | grad 1.40 | tok/s 41846
step   2140 | loss 1.6437 | lr 3.37e-04 | grad 3.59 | tok/s 42716
step   2150 | loss 1.5395 | lr 3.37e-04 | grad 1.27 | tok/s 42133
step   2160 | loss 1.6939 | lr 3.37e-04 | grad 1.31 | tok/s 43890
step   2170 | loss 1.3447 | lr 3.37e-04 | grad 1.09 | tok/s 43339
step   2180 | loss 1.2569 | lr 3.37e-04 | grad 0.98 | tok/s 44200
step   2190 | loss 1.2433 | lr 3.37e-04 | grad 0.88 | tok/s 44104
step   2200 | loss 1.2835 | lr 3.37e-04 | grad 1.63 | tok/s 43660
step   2210 | loss 1.5246 | lr 3.37e-04 | grad 2.52 | tok/s 42945
step   2220 | loss 1.6661 | lr 3.37e-04 | grad 1.16 | tok/s 44094
step   2230 | loss 1.5800 | lr 3.37e-04 | grad 2.44 | tok/s 43221
step   2240 | loss 1.4456 | lr 3.37e-04 | grad 1.32 | tok/s 42772
step   2250 | loss 1.4818 | lr 3.37e-04 | grad 1.14 | tok/s 42566
step   2260 | loss 1.5404 | lr 3.37e-04 | grad 2.23 | tok/s 41792
step   2270 | loss 1.4445 | lr 3.37e-04 | grad 1.23 | tok/s 42120
step   2280 | loss 1.5050 | lr 3.37e-04 | grad 1.12 | tok/s 42810
step   2290 | loss 1.4329 | lr 3.37e-04 | grad 1.06 | tok/s 44191
step   2300 | loss 1.3597 | lr 3.37e-04 | grad 1.12 | tok/s 44204
step   2310 | loss 1.4411 | lr 3.37e-04 | grad 1.49 | tok/s 43756
step   2320 | loss 1.5360 | lr 3.37e-04 | grad 1.90 | tok/s 42974
step   2330 | loss 1.7319 | lr 3.37e-04 | grad 5.31 | tok/s 42469
step   2340 | loss 1.7118 | lr 3.37e-04 | grad 1.51 | tok/s 43074
step   2350 | loss 1.4648 | lr 3.37e-04 | grad 0.98 | tok/s 42631
step   2360 | loss 1.4319 | lr 3.37e-04 | grad 0.93 | tok/s 41746
step   2370 | loss 1.4704 | lr 3.37e-04 | grad 1.49 | tok/s 42581
step   2380 | loss 1.5658 | lr 3.37e-04 | grad 2.80 | tok/s 41748
step   2390 | loss 1.6036 | lr 3.37e-04 | grad 1.10 | tok/s 42749
step   2400 | loss 1.4527 | lr 3.37e-04 | grad 1.16 | tok/s 41417
step   2410 | loss 1.6124 | lr 3.37e-04 | grad 1.50 | tok/s 42986
step   2420 | loss 1.3562 | lr 3.37e-04 | grad 1.40 | tok/s 42807
step   2430 | loss 1.5029 | lr 3.37e-04 | grad 1.67 | tok/s 42876
step   2440 | loss 1.4968 | lr 3.37e-04 | grad 2.44 | tok/s 44292
step   2450 | loss 1.3805 | lr 3.37e-04 | grad 1.09 | tok/s 43215
step   2460 | loss 1.4228 | lr 3.37e-04 | grad 1.26 | tok/s 41443
step   2470 | loss 1.4287 | lr 3.37e-04 | grad 1.14 | tok/s 43497
step   2480 | loss 1.5191 | lr 3.37e-04 | grad 1.23 | tok/s 42689
step   2490 | loss 1.6919 | lr 3.37e-04 | grad 1.05 | tok/s 42684
step   2500 | loss 1.5511 | lr 3.37e-04 | grad 1.09 | tok/s 41689
step   2510 | loss 1.5618 | lr 3.37e-04 | grad 1.45 | tok/s 41944
step   2520 | loss 1.7428 | lr 3.37e-04 | grad 3.61 | tok/s 42324
step   2530 | loss 1.6514 | lr 3.37e-04 | grad 1.19 | tok/s 43228
step   2540 | loss 1.4927 | lr 3.37e-04 | grad 2.30 | tok/s 41843
step   2550 | loss 1.6065 | lr 3.37e-04 | grad 1.73 | tok/s 43392
step   2560 | loss 1.3684 | lr 3.37e-04 | grad 1.79 | tok/s 42102
step   2570 | loss 1.5563 | lr 3.37e-04 | grad 1.07 | tok/s 43169
step   2580 | loss 1.4689 | lr 3.37e-04 | grad 1.07 | tok/s 43432
step   2590 | loss 1.3742 | lr 3.37e-04 | grad 1.19 | tok/s 44297
step   2600 | loss 1.3902 | lr 3.37e-04 | grad 1.40 | tok/s 43610
step   2610 | loss 1.5154 | lr 3.37e-04 | grad 1.79 | tok/s 41729
step   2620 | loss 1.4639 | lr 3.37e-04 | grad 1.15 | tok/s 41216
step   2630 | loss 1.8013 | lr 3.37e-04 | grad 1.17 | tok/s 43237
step   2640 | loss 1.3468 | lr 3.37e-04 | grad 0.87 | tok/s 44359
step   2650 | loss 1.3315 | lr 3.37e-04 | grad 1.05 | tok/s 44325
step   2660 | loss 1.2946 | lr 3.37e-04 | grad 0.96 | tok/s 44280
step   2670 | loss 1.4571 | lr 3.37e-04 | grad 1.16 | tok/s 42831
step   2680 | loss 1.5564 | lr 3.37e-04 | grad 2.75 | tok/s 41541
step   2690 | loss 1.8220 | lr 3.37e-04 | grad 1.07 | tok/s 43826
step   2700 | loss 1.5477 | lr 3.37e-04 | grad 1.35 | tok/s 42654
step   2710 | loss 1.3405 | lr 3.37e-04 | grad 1.27 | tok/s 42501
step   2720 | loss 1.5411 | lr 3.37e-04 | grad 1.15 | tok/s 42935
step   2730 | loss 1.6632 | lr 3.37e-04 | grad 2.08 | tok/s 41618
step   2740 | loss 1.4724 | lr 3.37e-04 | grad 0.99 | tok/s 42952
step   2750 | loss 1.4719 | lr 3.37e-04 | grad 1.16 | tok/s 41931
step   2760 | loss 1.3293 | lr 3.37e-04 | grad 1.02 | tok/s 42433
step   2770 | loss 1.8231 | lr 3.37e-04 | grad 1.34 | tok/s 42626
step   2780 | loss 1.5112 | lr 3.37e-04 | grad 1.27 | tok/s 43370
step   2790 | loss 1.6807 | lr 3.37e-04 | grad 3.03 | tok/s 43196
step   2800 | loss 1.5146 | lr 3.37e-04 | grad 2.08 | tok/s 43512
step   2810 | loss 1.5289 | lr 3.37e-04 | grad 0.94 | tok/s 42690
step   2820 | loss 1.3895 | lr 3.37e-04 | grad 0.83 | tok/s 43052
step   2830 | loss 1.3926 | lr 3.37e-04 | grad 1.09 | tok/s 43080
step   2840 | loss 1.5242 | lr 3.37e-04 | grad 1.61 | tok/s 42998
step   2850 | loss 1.8650 | lr 3.37e-04 | grad 1.98 | tok/s 42688
step   2860 | loss 1.6244 | lr 3.37e-04 | grad 1.22 | tok/s 43559
step   2870 | loss 1.4736 | lr 3.37e-04 | grad 1.16 | tok/s 41956
step   2880 | loss 1.4883 | lr 3.37e-04 | grad 2.92 | tok/s 41993
step   2890 | loss 1.5457 | lr 3.37e-04 | grad 1.15 | tok/s 43087
step   2900 | loss 1.4722 | lr 3.37e-04 | grad 1.45 | tok/s 43133
step   2910 | loss 1.4953 | lr 3.37e-04 | grad 1.76 | tok/s 41750
step   2920 | loss 1.4474 | lr 3.37e-04 | grad 0.97 | tok/s 42623
step   2930 | loss 1.6434 | lr 3.37e-04 | grad 0.96 | tok/s 41970
step   2940 | loss 1.4629 | lr 3.37e-04 | grad 1.10 | tok/s 42186
step   2950 | loss 1.4905 | lr 3.37e-04 | grad 1.10 | tok/s 43102
step   2960 | loss 1.4419 | lr 3.37e-04 | grad 1.83 | tok/s 42751
step   2970 | loss 1.3471 | lr 3.37e-04 | grad 1.31 | tok/s 43303
step   2980 | loss 1.5076 | lr 3.37e-04 | grad 1.34 | tok/s 42543
step   2990 | loss 1.4767 | lr 3.37e-04 | grad 1.82 | tok/s 43261
step   3000 | loss 1.5035 | lr 3.37e-04 | grad 1.21 | tok/s 42678
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5035.pt
step   3010 | loss 1.4357 | lr 3.37e-04 | grad 1.16 | tok/s 30848
step   3020 | loss 1.5240 | lr 3.37e-04 | grad 0.97 | tok/s 42917
step   3030 | loss 1.4254 | lr 3.37e-04 | grad 1.82 | tok/s 42001
step   3040 | loss 1.4099 | lr 3.37e-04 | grad 2.02 | tok/s 43178
step   3050 | loss 1.3538 | lr 3.37e-04 | grad 1.12 | tok/s 43088
step   3060 | loss 1.4200 | lr 3.37e-04 | grad 1.74 | tok/s 43005
step   3070 | loss 1.4584 | lr 3.37e-04 | grad 1.24 | tok/s 41954
step   3080 | loss 1.3841 | lr 3.37e-04 | grad 1.26 | tok/s 43606
step   3090 | loss 1.4782 | lr 3.37e-04 | grad 2.84 | tok/s 42196
step   3100 | loss 2.1020 | lr 3.37e-04 | grad 2.48 | tok/s 44068
step   3110 | loss 1.7357 | lr 3.37e-04 | grad 1.54 | tok/s 44285
step   3120 | loss 1.6512 | lr 3.37e-04 | grad 1.01 | tok/s 43345
step   3130 | loss 1.8436 | lr 3.37e-04 | grad 20.00 | tok/s 41902
step   3140 | loss 1.6803 | lr 3.37e-04 | grad 0.88 | tok/s 43176
step   3150 | loss 1.6179 | lr 3.37e-04 | grad 0.99 | tok/s 42566
step   3160 | loss 1.5077 | lr 3.37e-04 | grad 0.99 | tok/s 42474
step   3170 | loss 1.6873 | lr 3.37e-04 | grad 2.72 | tok/s 43124
step   3180 | loss 1.4763 | lr 3.37e-04 | grad 1.12 | tok/s 43668
step   3190 | loss 1.5018 | lr 3.37e-04 | grad 2.16 | tok/s 43274
step   3200 | loss 1.5757 | lr 3.37e-04 | grad 1.05 | tok/s 41916
step   3210 | loss 1.5212 | lr 3.37e-04 | grad 1.16 | tok/s 40128
step   3220 | loss 1.3838 | lr 3.37e-04 | grad 1.03 | tok/s 42149
step   3230 | loss 1.3068 | lr 3.37e-04 | grad 1.40 | tok/s 42269
step   3240 | loss 1.7370 | lr 3.37e-04 | grad 1.34 | tok/s 43534
step   3250 | loss 1.4680 | lr 3.37e-04 | grad 1.52 | tok/s 43182
step   3260 | loss 1.6108 | lr 3.37e-04 | grad 1.78 | tok/s 43057
step   3270 | loss 1.4348 | lr 3.37e-04 | grad 1.21 | tok/s 42832
step   3280 | loss 1.5184 | lr 3.37e-04 | grad 1.20 | tok/s 42265
step   3290 | loss 1.5241 | lr 3.37e-04 | grad 1.62 | tok/s 42554
step   3300 | loss 1.4949 | lr 3.37e-04 | grad 1.09 | tok/s 42401
step   3310 | loss 1.4904 | lr 3.37e-04 | grad 0.86 | tok/s 41245
step   3320 | loss 1.4718 | lr 3.37e-04 | grad 1.13 | tok/s 43047
step   3330 | loss 1.4254 | lr 3.37e-04 | grad 1.29 | tok/s 44064
step   3340 | loss 1.3921 | lr 3.37e-04 | grad 3.36 | tok/s 42279
step   3350 | loss 1.5668 | lr 3.37e-04 | grad 3.23 | tok/s 42926
step   3360 | loss 1.5220 | lr 3.37e-04 | grad 1.27 | tok/s 43399
step   3370 | loss 1.3381 | lr 3.37e-04 | grad 1.07 | tok/s 41284
step   3380 | loss 1.3409 | lr 3.37e-04 | grad 1.17 | tok/s 42613
step   3390 | loss 1.5446 | lr 3.37e-04 | grad 1.74 | tok/s 43559
step   3400 | loss 1.5880 | lr 3.37e-04 | grad 9.12 | tok/s 43094
step   3410 | loss 1.8910 | lr 3.37e-04 | grad 0.89 | tok/s 42834
step   3420 | loss 1.5598 | lr 3.37e-04 | grad 1.52 | tok/s 42394
step   3430 | loss 1.4119 | lr 3.37e-04 | grad 1.37 | tok/s 44361
step   3440 | loss 1.5102 | lr 3.37e-04 | grad 1.83 | tok/s 41590
step   3450 | loss 1.5504 | lr 3.37e-04 | grad 0.95 | tok/s 41904
step   3460 | loss 1.4473 | lr 3.37e-04 | grad 1.09 | tok/s 42647
step   3470 | loss 1.7181 | lr 3.37e-04 | grad 1.14 | tok/s 42257
step   3480 | loss 1.4520 | lr 3.37e-04 | grad 1.80 | tok/s 42223
step   3490 | loss 1.4240 | lr 3.37e-04 | grad 1.13 | tok/s 42357
step   3500 | loss 1.3176 | lr 3.37e-04 | grad 0.87 | tok/s 42302
step   3510 | loss 1.4814 | lr 3.37e-04 | grad 1.12 | tok/s 42249
step   3520 | loss 1.5381 | lr 3.37e-04 | grad 0.93 | tok/s 42614
step   3530 | loss 1.5219 | lr 3.37e-04 | grad 0.98 | tok/s 43083
step   3540 | loss 1.3682 | lr 3.37e-04 | grad 0.98 | tok/s 41841
step   3550 | loss 1.4841 | lr 3.37e-04 | grad 0.93 | tok/s 43008
step   3560 | loss 1.6401 | lr 3.37e-04 | grad 1.73 | tok/s 41778
step   3570 | loss 1.4661 | lr 3.37e-04 | grad 4.34 | tok/s 42411
step   3580 | loss 1.4097 | lr 3.37e-04 | grad 2.03 | tok/s 42345
step   3590 | loss 1.5118 | lr 3.37e-04 | grad 1.05 | tok/s 44041
step   3600 | loss 1.3620 | lr 3.37e-04 | grad 0.88 | tok/s 44267
step   3610 | loss 1.3325 | lr 3.37e-04 | grad 0.89 | tok/s 44167
step   3620 | loss 1.2847 | lr 3.37e-04 | grad 1.01 | tok/s 44192
step   3630 | loss 1.2612 | lr 3.37e-04 | grad 1.00 | tok/s 44193
step   3640 | loss 1.2601 | lr 3.37e-04 | grad 0.83 | tok/s 44115
step   3650 | loss 1.3159 | lr 3.37e-04 | grad 1.95 | tok/s 43384
step   3660 | loss 1.4041 | lr 3.37e-04 | grad 0.96 | tok/s 42531
step   3670 | loss 1.6581 | lr 3.37e-04 | grad 1.27 | tok/s 42493
step   3680 | loss 1.3033 | lr 3.37e-04 | grad 1.53 | tok/s 43052
step   3690 | loss 1.3551 | lr 3.37e-04 | grad 1.07 | tok/s 42165
step   3700 | loss 1.4031 | lr 3.37e-04 | grad 0.92 | tok/s 42754
step   3710 | loss 1.3819 | lr 3.37e-04 | grad 1.31 | tok/s 43649
step   3720 | loss 1.5315 | lr 3.37e-04 | grad 1.07 | tok/s 42514
step   3730 | loss 1.3978 | lr 3.37e-04 | grad 1.15 | tok/s 43626
step   3740 | loss 1.6416 | lr 3.37e-04 | grad 1.12 | tok/s 43190
step   3750 | loss 1.3728 | lr 3.37e-04 | grad 1.34 | tok/s 43285
step   3760 | loss 1.4533 | lr 3.37e-04 | grad 1.66 | tok/s 43041
step   3770 | loss 1.2438 | lr 3.37e-04 | grad 1.16 | tok/s 42371
step   3780 | loss 1.7639 | lr 3.37e-04 | grad 1.05 | tok/s 43068
step   3790 | loss 1.3662 | lr 3.37e-04 | grad 1.24 | tok/s 43276
step   3800 | loss 1.4326 | lr 3.37e-04 | grad 1.07 | tok/s 42119
step   3810 | loss 1.4934 | lr 3.37e-04 | grad 1.12 | tok/s 42927
step   3820 | loss 1.2383 | lr 3.37e-04 | grad 0.87 | tok/s 42542
step   3830 | loss 1.3352 | lr 3.37e-04 | grad 1.05 | tok/s 42956
step   3840 | loss 1.2940 | lr 3.37e-04 | grad 0.80 | tok/s 42714
step   3850 | loss 1.4104 | lr 3.37e-04 | grad 1.05 | tok/s 42056
step   3860 | loss 1.4590 | lr 3.37e-04 | grad 1.05 | tok/s 42559
step   3870 | loss 1.4572 | lr 3.37e-04 | grad 1.01 | tok/s 42912
step   3880 | loss 1.3461 | lr 3.37e-04 | grad 1.16 | tok/s 42733
step   3890 | loss 1.4256 | lr 3.37e-04 | grad 1.29 | tok/s 41836
step   3900 | loss 1.4317 | lr 3.37e-04 | grad 1.70 | tok/s 41939
step   3910 | loss 1.4016 | lr 3.37e-04 | grad 1.23 | tok/s 41754
step   3920 | loss 1.4444 | lr 3.37e-04 | grad 1.88 | tok/s 43068
step   3930 | loss 1.5028 | lr 3.37e-04 | grad 1.09 | tok/s 42251
step   3940 | loss 1.3488 | lr 3.37e-04 | grad 1.06 | tok/s 43147
step   3950 | loss 1.4830 | lr 3.37e-04 | grad 4.19 | tok/s 42931
step   3960 | loss 1.4298 | lr 3.37e-04 | grad 1.27 | tok/s 41818
step   3970 | loss 1.2831 | lr 3.37e-04 | grad 1.15 | tok/s 43563
step   3980 | loss 1.4251 | lr 3.37e-04 | grad 1.20 | tok/s 41892
step   3990 | loss 1.3679 | lr 3.37e-04 | grad 2.08 | tok/s 43022
step   4000 | loss 1.4196 | lr 3.37e-04 | grad 1.72 | tok/s 41685
  >>> saved checkpoint: checkpoint_step_004000_loss_1.4196.pt
step   4010 | loss 1.7034 | lr 3.37e-04 | grad 1.16 | tok/s 31727
step   4020 | loss 1.4221 | lr 3.37e-04 | grad 1.49 | tok/s 40826
step   4030 | loss 1.4705 | lr 3.37e-04 | grad 1.31 | tok/s 42896
step   4040 | loss 1.4952 | lr 3.37e-04 | grad 1.95 | tok/s 43520
step   4050 | loss 1.3731 | lr 3.37e-04 | grad 3.52 | tok/s 43003
step   4060 | loss 1.5596 | lr 3.37e-04 | grad 1.36 | tok/s 42048
step   4070 | loss 1.4640 | lr 3.37e-04 | grad 1.10 | tok/s 42409
step   4080 | loss 1.5829 | lr 3.37e-04 | grad 1.26 | tok/s 43023
step   4090 | loss 1.4242 | lr 3.37e-04 | grad 1.51 | tok/s 42748
step   4100 | loss 1.4850 | lr 3.37e-04 | grad 1.11 | tok/s 42684
step   4110 | loss 1.8683 | lr 3.37e-04 | grad 1.65 | tok/s 42358
step   4120 | loss 1.7997 | lr 3.37e-04 | grad 1.40 | tok/s 43028
step   4130 | loss 1.4764 | lr 3.37e-04 | grad 2.84 | tok/s 43302
step   4140 | loss 1.5971 | lr 3.37e-04 | grad 1.24 | tok/s 43543
step   4150 | loss 1.4158 | lr 3.37e-04 | grad 1.17 | tok/s 43041
step   4160 | loss 1.6246 | lr 3.37e-04 | grad 1.09 | tok/s 42412
step   4170 | loss 1.4167 | lr 3.37e-04 | grad 1.27 | tok/s 41886
step   4180 | loss 1.3837 | lr 3.37e-04 | grad 1.11 | tok/s 42597
step   4190 | loss 1.3593 | lr 3.37e-04 | grad 1.24 | tok/s 42259
step   4200 | loss 1.3094 | lr 3.37e-04 | grad 1.18 | tok/s 42816
step   4210 | loss 1.5518 | lr 3.37e-04 | grad 2.58 | tok/s 43195
step   4220 | loss 1.5316 | lr 3.37e-04 | grad 1.03 | tok/s 43116
step   4230 | loss 1.3629 | lr 3.37e-04 | grad 1.12 | tok/s 41263
step   4240 | loss 1.5691 | lr 3.37e-04 | grad 1.00 | tok/s 42643
step   4250 | loss 1.4127 | lr 3.37e-04 | grad 1.59 | tok/s 43333
step   4260 | loss 1.5126 | lr 3.37e-04 | grad 1.97 | tok/s 41704
step   4270 | loss 1.4179 | lr 3.37e-04 | grad 0.88 | tok/s 42519
step   4280 | loss 1.4630 | lr 3.37e-04 | grad 1.84 | tok/s 42662
step   4290 | loss 1.5033 | lr 3.37e-04 | grad 1.32 | tok/s 41961
step   4300 | loss 1.4046 | lr 3.37e-04 | grad 1.89 | tok/s 42257
step   4310 | loss 1.4654 | lr 3.37e-04 | grad 1.04 | tok/s 41449
step   4320 | loss 1.3878 | lr 3.37e-04 | grad 1.05 | tok/s 41806
step   4330 | loss 1.4784 | lr 3.37e-04 | grad 1.13 | tok/s 42350
step   4340 | loss 1.2854 | lr 3.37e-04 | grad 1.71 | tok/s 43473
step   4350 | loss 1.7258 | lr 3.37e-04 | grad 1.31 | tok/s 42056
step   4360 | loss 1.3562 | lr 3.37e-04 | grad 1.12 | tok/s 42918
step   4370 | loss 1.5029 | lr 3.37e-04 | grad 2.12 | tok/s 43278
step   4380 | loss 1.4129 | lr 3.37e-04 | grad 1.34 | tok/s 42824
step   4390 | loss 1.3900 | lr 3.37e-04 | grad 1.07 | tok/s 42067
step   4400 | loss 1.4398 | lr 3.37e-04 | grad 0.85 | tok/s 41727
step   4410 | loss 1.3360 | lr 3.37e-04 | grad 1.31 | tok/s 42546
step   4420 | loss 1.4866 | lr 3.37e-04 | grad 1.24 | tok/s 42892
step   4430 | loss 1.4161 | lr 3.37e-04 | grad 1.07 | tok/s 42093
step   4440 | loss 1.5190 | lr 3.37e-04 | grad 5.38 | tok/s 42998
step   4450 | loss 1.4455 | lr 3.37e-04 | grad 1.13 | tok/s 43078
step   4460 | loss 1.2694 | lr 3.37e-04 | grad 0.74 | tok/s 44156
step   4470 | loss 1.2751 | lr 3.37e-04 | grad 1.03 | tok/s 44226
step   4480 | loss 1.2217 | lr 3.37e-04 | grad 0.98 | tok/s 44227
step   4490 | loss 1.3446 | lr 3.37e-04 | grad 0.96 | tok/s 43224
step   4500 | loss 1.5298 | lr 3.37e-04 | grad 1.61 | tok/s 43157
step   4510 | loss 1.4312 | lr 3.37e-04 | grad 0.94 | tok/s 42870
step   4520 | loss 1.4131 | lr 3.37e-04 | grad 1.12 | tok/s 41619
step   4530 | loss 1.4987 | lr 3.37e-04 | grad 3.47 | tok/s 42669
step   4540 | loss 1.5048 | lr 3.37e-04 | grad 1.53 | tok/s 41372
step   4550 | loss 1.4038 | lr 3.37e-04 | grad 1.64 | tok/s 42485
step   4560 | loss 1.0671 | lr 3.37e-04 | grad 2.09 | tok/s 42960
step   4570 | loss 1.3347 | lr 3.37e-04 | grad 1.18 | tok/s 43161
step   4580 | loss 1.2766 | lr 3.37e-04 | grad 0.88 | tok/s 42572
step   4590 | loss 1.4952 | lr 3.37e-04 | grad 1.04 | tok/s 41761
step   4600 | loss 1.7661 | lr 3.37e-04 | grad 3.38 | tok/s 43758
step   4610 | loss 1.7652 | lr 3.37e-04 | grad 1.59 | tok/s 44105
step   4620 | loss 1.6817 | lr 3.37e-04 | grad 1.64 | tok/s 44104
step   4630 | loss 1.5599 | lr 3.37e-04 | grad 1.46 | tok/s 44204
step   4640 | loss 1.6467 | lr 3.37e-04 | grad 1.29 | tok/s 44122
step   4650 | loss 1.5718 | lr 3.37e-04 | grad 1.23 | tok/s 44105
step   4660 | loss 1.6144 | lr 3.37e-04 | grad 2.83 | tok/s 44117
step   4670 | loss 1.6107 | lr 3.37e-04 | grad 2.03 | tok/s 44104
step   4680 | loss 1.5050 | lr 3.37e-04 | grad 2.17 | tok/s 44115
step   4690 | loss 1.3990 | lr 3.37e-04 | grad 1.55 | tok/s 44125
step   4700 | loss 1.4188 | lr 3.37e-04 | grad 1.19 | tok/s 44205
step   4710 | loss 1.5338 | lr 3.37e-04 | grad 1.84 | tok/s 44085
step   4720 | loss 1.5653 | lr 3.37e-04 | grad 1.63 | tok/s 44114
step   4730 | loss 1.5523 | lr 3.37e-04 | grad 1.12 | tok/s 44115
step   4740 | loss 1.4850 | lr 3.37e-04 | grad 1.25 | tok/s 44203
step   4750 | loss 1.5199 | lr 3.37e-04 | grad 1.61 | tok/s 44106
step   4760 | loss 1.4822 | lr 3.37e-04 | grad 0.96 | tok/s 44050
step   4770 | loss 1.6377 | lr 3.37e-04 | grad 2.28 | tok/s 43207
step   4780 | loss 1.7259 | lr 3.37e-04 | grad 1.53 | tok/s 43186
step   4790 | loss 1.4306 | lr 3.37e-04 | grad 1.11 | tok/s 41114
step   4800 | loss 1.4679 | lr 3.37e-04 | grad 2.48 | tok/s 40908
step   4810 | loss 1.4011 | lr 3.37e-04 | grad 1.32 | tok/s 42285

Training complete! Final step: 4813
