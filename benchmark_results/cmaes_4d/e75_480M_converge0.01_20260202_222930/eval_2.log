Using device: cuda
Output directory: benchmark_results/cmaes_4d/e75_480M_converge0.01_20260202_222930/eval_2/levelE75h11n40_100m_20260202_222937
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h11n40, 147,517,864 parameters
Using schedule-free AdamW (lr=0.0007767298541830645)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 4.8842 | lr 7.77e-04 | grad 12.19 | tok/s 18303
step     20 | loss 4.3029 | lr 7.77e-04 | grad 6.00 | tok/s 39187
step     30 | loss 3.8655 | lr 7.77e-04 | grad 5.38 | tok/s 39655
step     40 | loss 3.0936 | lr 7.77e-04 | grad 4.06 | tok/s 39505
step     50 | loss 2.6511 | lr 7.77e-04 | grad 4.50 | tok/s 39327
step     60 | loss 3.2062 | lr 7.77e-04 | grad 4.00 | tok/s 37688
step     70 | loss 2.8725 | lr 7.77e-04 | grad 3.72 | tok/s 38180
step     80 | loss 2.8167 | lr 7.77e-04 | grad 2.52 | tok/s 37795
step     90 | loss 2.7921 | lr 7.77e-04 | grad 2.80 | tok/s 36813
step    100 | loss 2.3745 | lr 7.77e-04 | grad 2.56 | tok/s 38108
step    110 | loss 2.6031 | lr 7.77e-04 | grad 1.85 | tok/s 36766
step    120 | loss 2.5998 | lr 7.77e-04 | grad 2.55 | tok/s 36972
step    130 | loss 2.3984 | lr 7.77e-04 | grad 2.80 | tok/s 37815
step    140 | loss 2.1914 | lr 7.77e-04 | grad 2.73 | tok/s 36051
step    150 | loss 2.2413 | lr 7.77e-04 | grad 1.56 | tok/s 36354
step    160 | loss 2.2355 | lr 7.77e-04 | grad 2.47 | tok/s 36373
step    170 | loss 2.3881 | lr 7.77e-04 | grad 2.42 | tok/s 37264
step    180 | loss 2.0950 | lr 7.77e-04 | grad 2.06 | tok/s 37166
step    190 | loss 1.8774 | lr 7.77e-04 | grad 1.69 | tok/s 38388
step    200 | loss 2.0091 | lr 7.77e-04 | grad 1.16 | tok/s 37233
step    210 | loss 2.1514 | lr 7.77e-04 | grad 1.28 | tok/s 37759
step    220 | loss 2.0682 | lr 7.77e-04 | grad 1.46 | tok/s 37023
step    230 | loss 1.9382 | lr 7.77e-04 | grad 1.45 | tok/s 36937
step    240 | loss 2.0290 | lr 7.77e-04 | grad 1.48 | tok/s 37722
step    250 | loss 2.0731 | lr 7.77e-04 | grad 1.38 | tok/s 36822
step    260 | loss 1.8946 | lr 7.77e-04 | grad 1.63 | tok/s 36050
step    270 | loss 1.9280 | lr 7.77e-04 | grad 3.58 | tok/s 36834
step    280 | loss 1.7224 | lr 7.77e-04 | grad 1.75 | tok/s 38023
step    290 | loss 1.5906 | lr 7.77e-04 | grad 1.13 | tok/s 38490
step    300 | loss 1.5968 | lr 7.77e-04 | grad 1.51 | tok/s 38461
step    310 | loss 1.7056 | lr 7.77e-04 | grad 1.70 | tok/s 38095
step    320 | loss 1.8826 | lr 7.77e-04 | grad 1.05 | tok/s 36411
step    330 | loss 1.8964 | lr 7.77e-04 | grad 1.97 | tok/s 37574
step    340 | loss 1.8489 | lr 7.77e-04 | grad 1.81 | tok/s 36320
step    350 | loss 1.8204 | lr 7.77e-04 | grad 1.42 | tok/s 36134
step    360 | loss 1.7032 | lr 7.77e-04 | grad 1.60 | tok/s 37372
step    370 | loss 2.1342 | lr 7.77e-04 | grad 1.43 | tok/s 37447
step    380 | loss 1.7653 | lr 7.77e-04 | grad 1.07 | tok/s 38048
step    390 | loss 1.7405 | lr 7.77e-04 | grad 1.38 | tok/s 37087
step    400 | loss 1.7279 | lr 7.77e-04 | grad 1.06 | tok/s 37388
step    410 | loss 1.7318 | lr 7.77e-04 | grad 1.42 | tok/s 36220
step    420 | loss 1.7939 | lr 7.77e-04 | grad 1.48 | tok/s 36453
step    430 | loss 1.8596 | lr 7.77e-04 | grad 2.55 | tok/s 37565
step    440 | loss 1.7607 | lr 7.77e-04 | grad 1.25 | tok/s 36928
step    450 | loss 1.7214 | lr 7.77e-04 | grad 0.99 | tok/s 36909
step    460 | loss 1.7507 | lr 7.77e-04 | grad 1.57 | tok/s 36965
step    470 | loss 1.6102 | lr 7.77e-04 | grad 1.09 | tok/s 35911
step    480 | loss 1.6042 | lr 7.77e-04 | grad 1.18 | tok/s 36766
step    490 | loss 2.1001 | lr 7.77e-04 | grad 1.55 | tok/s 37849
step    500 | loss 1.6763 | lr 7.77e-04 | grad 2.92 | tok/s 37000
step    510 | loss 1.5336 | lr 7.77e-04 | grad 1.20 | tok/s 38089
step    520 | loss 2.1066 | lr 7.77e-04 | grad 1.84 | tok/s 37073
step    530 | loss 1.5310 | lr 7.77e-04 | grad 2.67 | tok/s 37527
step    540 | loss 1.5420 | lr 7.77e-04 | grad 1.29 | tok/s 37874
step    550 | loss 1.3798 | lr 7.77e-04 | grad 1.27 | tok/s 38507
step    560 | loss 1.5325 | lr 7.77e-04 | grad 2.95 | tok/s 38011
step    570 | loss 1.9363 | lr 7.77e-04 | grad 1.26 | tok/s 38035
step    580 | loss 2.0730 | lr 7.77e-04 | grad 3.11 | tok/s 36710
step    590 | loss 1.5942 | lr 7.77e-04 | grad 1.41 | tok/s 37042
step    600 | loss 1.6144 | lr 7.77e-04 | grad 1.31 | tok/s 38496
step    610 | loss 1.5750 | lr 7.77e-04 | grad 1.33 | tok/s 36578
step    620 | loss 1.5001 | lr 7.77e-04 | grad 1.27 | tok/s 37891
step    630 | loss 1.7092 | lr 7.77e-04 | grad 1.30 | tok/s 37851
step    640 | loss 1.5810 | lr 7.77e-04 | grad 1.49 | tok/s 36978
step    650 | loss 1.7391 | lr 7.77e-04 | grad 3.75 | tok/s 36508
step    660 | loss 1.6883 | lr 7.77e-04 | grad 1.63 | tok/s 37680
step    670 | loss 1.6940 | lr 7.77e-04 | grad 1.35 | tok/s 36953
step    680 | loss 1.6460 | lr 7.77e-04 | grad 1.62 | tok/s 36620
step    690 | loss 1.7419 | lr 7.77e-04 | grad 1.66 | tok/s 36952
step    700 | loss 1.6530 | lr 7.77e-04 | grad 1.40 | tok/s 37376
step    710 | loss 1.6049 | lr 7.77e-04 | grad 4.12 | tok/s 36942
step    720 | loss 1.7266 | lr 7.77e-04 | grad 1.15 | tok/s 37220
step    730 | loss 1.7276 | lr 7.77e-04 | grad 2.44 | tok/s 37135
step    740 | loss 1.5189 | lr 7.77e-04 | grad 1.18 | tok/s 36689
step    750 | loss 1.8054 | lr 7.77e-04 | grad 1.16 | tok/s 37144
step    760 | loss 1.5429 | lr 7.77e-04 | grad 1.28 | tok/s 37063
step    770 | loss 1.6358 | lr 7.77e-04 | grad 1.50 | tok/s 37697
step    780 | loss 1.4608 | lr 7.77e-04 | grad 0.90 | tok/s 37803
step    790 | loss 1.5338 | lr 7.77e-04 | grad 2.77 | tok/s 37349
step    800 | loss 1.4856 | lr 7.77e-04 | grad 1.21 | tok/s 37074
step    810 | loss 2.2432 | lr 7.77e-04 | grad 2.67 | tok/s 38251
step    820 | loss 1.9216 | lr 7.77e-04 | grad 1.96 | tok/s 38558
step    830 | loss 1.7181 | lr 7.77e-04 | grad 1.72 | tok/s 38539
step    840 | loss 1.6694 | lr 7.77e-04 | grad 1.09 | tok/s 36753
step    850 | loss 1.5132 | lr 7.77e-04 | grad 0.97 | tok/s 37237
step    860 | loss 1.5253 | lr 7.77e-04 | grad 1.15 | tok/s 37051
step    870 | loss 1.6179 | lr 7.77e-04 | grad 1.31 | tok/s 37736
step    880 | loss 1.5153 | lr 7.77e-04 | grad 1.85 | tok/s 36652
step    890 | loss 1.8293 | lr 7.77e-04 | grad 1.34 | tok/s 36465
step    900 | loss 1.4741 | lr 7.77e-04 | grad 1.38 | tok/s 36471
step    910 | loss 1.5748 | lr 7.77e-04 | grad 0.92 | tok/s 36815
step    920 | loss 1.5240 | lr 7.77e-04 | grad 1.33 | tok/s 36626
step    930 | loss 1.5937 | lr 7.77e-04 | grad 1.27 | tok/s 36575
step    940 | loss 1.5756 | lr 7.77e-04 | grad 1.11 | tok/s 37439
step    950 | loss 1.3503 | lr 7.77e-04 | grad 1.25 | tok/s 38533
step    960 | loss 1.2888 | lr 7.77e-04 | grad 1.01 | tok/s 38518
step    970 | loss 1.5226 | lr 7.77e-04 | grad 1.34 | tok/s 37180
step    980 | loss 1.6459 | lr 7.77e-04 | grad 1.93 | tok/s 36446
step    990 | loss 1.6077 | lr 7.77e-04 | grad 1.44 | tok/s 37021
step   1000 | loss 1.4986 | lr 7.77e-04 | grad 1.17 | tok/s 37844
  >>> saved checkpoint: checkpoint_step_001000_loss_1.4986.pt
step   1010 | loss 1.4837 | lr 7.77e-04 | grad 1.05 | tok/s 29205
step   1020 | loss 1.7516 | lr 7.77e-04 | grad 0.94 | tok/s 36700
step   1030 | loss 1.6266 | lr 7.77e-04 | grad 2.44 | tok/s 37131
step   1040 | loss 1.3430 | lr 7.77e-04 | grad 1.06 | tok/s 36635
step   1050 | loss 1.7584 | lr 7.77e-04 | grad 1.22 | tok/s 38192
step   1060 | loss 1.9636 | lr 7.77e-04 | grad 3.38 | tok/s 36766
step   1070 | loss 1.6197 | lr 7.77e-04 | grad 0.97 | tok/s 36906
step   1080 | loss 1.7426 | lr 7.77e-04 | grad 0.89 | tok/s 37269
step   1090 | loss 1.4691 | lr 7.77e-04 | grad 1.81 | tok/s 37827
step   1100 | loss 1.5183 | lr 7.77e-04 | grad 1.59 | tok/s 37665
step   1110 | loss 1.5977 | lr 7.77e-04 | grad 1.20 | tok/s 36655
step   1120 | loss 1.5781 | lr 7.77e-04 | grad 1.62 | tok/s 37118
step   1130 | loss 1.5641 | lr 7.77e-04 | grad 0.97 | tok/s 37037
step   1140 | loss 1.6600 | lr 7.77e-04 | grad 1.16 | tok/s 36378
step   1150 | loss 1.5962 | lr 7.77e-04 | grad 1.39 | tok/s 36417
step   1160 | loss 1.4894 | lr 7.77e-04 | grad 1.13 | tok/s 37979
step   1170 | loss 1.4138 | lr 7.77e-04 | grad 1.36 | tok/s 38520
step   1180 | loss 1.3435 | lr 7.77e-04 | grad 1.08 | tok/s 38533
step   1190 | loss 1.2862 | lr 7.77e-04 | grad 1.38 | tok/s 38534
step   1200 | loss 1.2789 | lr 7.77e-04 | grad 1.41 | tok/s 38543
step   1210 | loss 1.4451 | lr 7.77e-04 | grad 1.03 | tok/s 37938
step   1220 | loss 1.3992 | lr 7.77e-04 | grad 1.22 | tok/s 36161
step   1230 | loss 1.5617 | lr 7.77e-04 | grad 1.04 | tok/s 37585
step   1240 | loss 1.5118 | lr 7.77e-04 | grad 1.45 | tok/s 37264
step   1250 | loss 1.6957 | lr 7.77e-04 | grad 1.05 | tok/s 37092
step   1260 | loss 1.5556 | lr 7.77e-04 | grad 1.36 | tok/s 36914
step   1270 | loss 1.5877 | lr 7.77e-04 | grad 1.78 | tok/s 36583
step   1280 | loss 1.5645 | lr 7.77e-04 | grad 0.93 | tok/s 36677
step   1290 | loss 1.5889 | lr 7.77e-04 | grad 1.34 | tok/s 36784
step   1300 | loss 1.5038 | lr 7.77e-04 | grad 1.01 | tok/s 36385
step   1310 | loss 1.5967 | lr 7.77e-04 | grad 1.08 | tok/s 37183
step   1320 | loss 1.3881 | lr 7.77e-04 | grad 0.91 | tok/s 37197
step   1330 | loss 1.4007 | lr 7.77e-04 | grad 1.02 | tok/s 37422
step   1340 | loss 1.4347 | lr 7.77e-04 | grad 0.81 | tok/s 36948
step   1350 | loss 1.4508 | lr 7.77e-04 | grad 0.93 | tok/s 36551
step   1360 | loss 1.6507 | lr 7.77e-04 | grad 0.76 | tok/s 37163
step   1370 | loss 1.4934 | lr 7.77e-04 | grad 1.18 | tok/s 36824
step   1380 | loss 1.4317 | lr 7.77e-04 | grad 1.17 | tok/s 37531
step   1390 | loss 1.5325 | lr 7.77e-04 | grad 1.28 | tok/s 37447
step   1400 | loss 1.5480 | lr 7.77e-04 | grad 1.09 | tok/s 36263
step   1410 | loss 1.4882 | lr 7.77e-04 | grad 1.21 | tok/s 35970
step   1420 | loss 1.3280 | lr 7.77e-04 | grad 0.74 | tok/s 36644
step   1430 | loss 1.2982 | lr 7.77e-04 | grad 1.13 | tok/s 38038
step   1440 | loss 1.4872 | lr 7.77e-04 | grad 0.80 | tok/s 36368
step   1450 | loss 1.5961 | lr 7.77e-04 | grad 1.29 | tok/s 36702
step   1460 | loss 1.4374 | lr 7.77e-04 | grad 3.59 | tok/s 37221
step   1470 | loss 1.4615 | lr 7.77e-04 | grad 1.09 | tok/s 37275
step   1480 | loss 1.7237 | lr 7.77e-04 | grad 2.48 | tok/s 36515
step   1490 | loss 1.5154 | lr 7.77e-04 | grad 0.75 | tok/s 37340
step   1500 | loss 1.5307 | lr 7.77e-04 | grad 1.18 | tok/s 37433
step   1510 | loss 1.4795 | lr 7.77e-04 | grad 0.75 | tok/s 37403
step   1520 | loss 1.4465 | lr 7.77e-04 | grad 1.34 | tok/s 36719
step   1530 | loss 1.2796 | lr 7.77e-04 | grad 1.13 | tok/s 37813
step   1540 | loss 2.0849 | lr 7.77e-04 | grad 1.30 | tok/s 37129
step   1550 | loss 1.5083 | lr 7.77e-04 | grad 1.02 | tok/s 36253
step   1560 | loss 1.5524 | lr 7.77e-04 | grad 2.11 | tok/s 37488
step   1570 | loss 1.4043 | lr 7.77e-04 | grad 0.82 | tok/s 36771
step   1580 | loss 1.5102 | lr 7.77e-04 | grad 0.90 | tok/s 36299
step   1590 | loss 1.3294 | lr 7.77e-04 | grad 1.02 | tok/s 38069
step   1600 | loss 1.4977 | lr 7.77e-04 | grad 1.08 | tok/s 37264
step   1610 | loss 1.4774 | lr 7.77e-04 | grad 1.05 | tok/s 37611
step   1620 | loss 1.4127 | lr 7.77e-04 | grad 0.95 | tok/s 36553
step   1630 | loss 1.4842 | lr 7.77e-04 | grad 1.49 | tok/s 36015
step   1640 | loss 1.4927 | lr 7.77e-04 | grad 1.23 | tok/s 36598
step   1650 | loss 1.4587 | lr 7.77e-04 | grad 1.82 | tok/s 37637
step   1660 | loss 1.7795 | lr 7.77e-04 | grad 0.91 | tok/s 37425
step   1670 | loss 1.3995 | lr 7.77e-04 | grad 1.00 | tok/s 36803
step   1680 | loss 1.5000 | lr 7.77e-04 | grad 0.98 | tok/s 37481
step   1690 | loss 1.5765 | lr 7.77e-04 | grad 1.56 | tok/s 37050
step   1700 | loss 1.4369 | lr 7.77e-04 | grad 1.29 | tok/s 36720
step   1710 | loss 1.5705 | lr 7.77e-04 | grad 1.14 | tok/s 36624
step   1720 | loss 1.4935 | lr 7.77e-04 | grad 0.85 | tok/s 37071
step   1730 | loss 1.4907 | lr 7.77e-04 | grad 0.94 | tok/s 36203
step   1740 | loss 1.5989 | lr 7.77e-04 | grad 1.11 | tok/s 36583
step   1750 | loss 1.5611 | lr 7.77e-04 | grad 1.44 | tok/s 37038
step   1760 | loss 1.4453 | lr 7.77e-04 | grad 1.48 | tok/s 36152
step   1770 | loss 1.6141 | lr 7.77e-04 | grad 1.09 | tok/s 36571
step   1780 | loss 1.4389 | lr 7.77e-04 | grad 0.91 | tok/s 37366
step   1790 | loss 1.4230 | lr 7.77e-04 | grad 0.93 | tok/s 37421
step   1800 | loss 1.3863 | lr 7.77e-04 | grad 1.02 | tok/s 35140
step   1810 | loss 1.4625 | lr 7.77e-04 | grad 1.17 | tok/s 36330
step   1820 | loss 1.5459 | lr 7.77e-04 | grad 1.02 | tok/s 36613
step   1830 | loss 1.5893 | lr 7.77e-04 | grad 0.93 | tok/s 36280
step   1840 | loss 1.3911 | lr 7.77e-04 | grad 1.21 | tok/s 36646
step   1850 | loss 1.3643 | lr 7.77e-04 | grad 0.86 | tok/s 38036
step   1860 | loss 1.4810 | lr 7.77e-04 | grad 1.11 | tok/s 37477
step   1870 | loss 1.5416 | lr 7.77e-04 | grad 2.05 | tok/s 36713
step   1880 | loss 1.4497 | lr 7.77e-04 | grad 1.06 | tok/s 37418
step   1890 | loss 1.5783 | lr 7.77e-04 | grad 1.21 | tok/s 36729
step   1900 | loss 1.3226 | lr 7.77e-04 | grad 1.27 | tok/s 37207
step   1910 | loss 1.3633 | lr 7.77e-04 | grad 0.83 | tok/s 37422
step   1920 | loss 1.5130 | lr 7.77e-04 | grad 2.19 | tok/s 38142
step   1930 | loss 1.4142 | lr 7.77e-04 | grad 0.89 | tok/s 37170
step   1940 | loss 1.4769 | lr 7.77e-04 | grad 0.85 | tok/s 37514
step   1950 | loss 1.3736 | lr 7.77e-04 | grad 1.29 | tok/s 37007
step   1960 | loss 1.5032 | lr 7.77e-04 | grad 1.15 | tok/s 37262
step   1970 | loss 1.4598 | lr 7.77e-04 | grad 1.55 | tok/s 36870
step   1980 | loss 1.4159 | lr 7.77e-04 | grad 0.97 | tok/s 37718
step   1990 | loss 1.1676 | lr 7.77e-04 | grad 0.97 | tok/s 38548
step   2000 | loss 1.1648 | lr 7.77e-04 | grad 0.56 | tok/s 38549
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1648.pt
step   2010 | loss 1.4203 | lr 7.77e-04 | grad 1.05 | tok/s 30752
step   2020 | loss 1.2381 | lr 7.77e-04 | grad 0.89 | tok/s 38594
step   2030 | loss 1.4001 | lr 7.77e-04 | grad 2.06 | tok/s 37384
step   2040 | loss 1.4942 | lr 7.77e-04 | grad 1.50 | tok/s 37136
step   2050 | loss 1.4540 | lr 7.77e-04 | grad 1.71 | tok/s 37457
step   2060 | loss 1.5079 | lr 7.77e-04 | grad 1.46 | tok/s 37186
step   2070 | loss 1.4260 | lr 7.77e-04 | grad 1.19 | tok/s 36906
step   2080 | loss 1.3692 | lr 7.77e-04 | grad 1.23 | tok/s 36831
step   2090 | loss 1.3348 | lr 7.77e-04 | grad 0.91 | tok/s 37211
step   2100 | loss 1.1531 | lr 7.77e-04 | grad 1.15 | tok/s 37565
step   2110 | loss 1.5395 | lr 7.77e-04 | grad 0.93 | tok/s 36697
step   2120 | loss 1.5110 | lr 7.77e-04 | grad 0.92 | tok/s 36793
step   2130 | loss 1.5020 | lr 7.77e-04 | grad 1.27 | tok/s 36522
step   2140 | loss 1.5718 | lr 7.77e-04 | grad 2.48 | tok/s 37251
step   2150 | loss 1.4758 | lr 7.77e-04 | grad 1.00 | tok/s 36793
step   2160 | loss 1.5989 | lr 7.77e-04 | grad 1.04 | tok/s 38197
step   2170 | loss 1.2932 | lr 7.77e-04 | grad 0.97 | tok/s 37776
step   2180 | loss 1.2109 | lr 7.77e-04 | grad 1.00 | tok/s 38547
step   2190 | loss 1.1945 | lr 7.77e-04 | grad 0.91 | tok/s 38527
step   2200 | loss 1.2373 | lr 7.77e-04 | grad 1.28 | tok/s 38067
step   2210 | loss 1.4495 | lr 7.77e-04 | grad 2.02 | tok/s 37531
step   2220 | loss 1.4877 | lr 7.77e-04 | grad 0.95 | tok/s 38433
step   2230 | loss 1.5107 | lr 7.77e-04 | grad 1.55 | tok/s 37690
step   2240 | loss 1.3915 | lr 7.77e-04 | grad 0.99 | tok/s 37253
step   2250 | loss 1.4230 | lr 7.77e-04 | grad 0.93 | tok/s 37174
step   2260 | loss 1.4787 | lr 7.77e-04 | grad 1.79 | tok/s 36395
step   2270 | loss 1.3883 | lr 7.77e-04 | grad 1.32 | tok/s 36724
step   2280 | loss 1.4512 | lr 7.77e-04 | grad 1.23 | tok/s 37168
step   2290 | loss 1.3764 | lr 7.77e-04 | grad 0.95 | tok/s 38479
step   2300 | loss 1.3089 | lr 7.77e-04 | grad 0.94 | tok/s 38493
step   2310 | loss 1.3866 | lr 7.77e-04 | grad 2.28 | tok/s 38126
step   2320 | loss 1.4609 | lr 7.77e-04 | grad 1.70 | tok/s 37453
step   2330 | loss 1.6401 | lr 7.77e-04 | grad 3.53 | tok/s 36958
step   2340 | loss 1.6075 | lr 7.77e-04 | grad 1.15 | tok/s 37463
step   2350 | loss 1.4080 | lr 7.77e-04 | grad 0.75 | tok/s 37154
step   2360 | loss 1.3869 | lr 7.77e-04 | grad 0.74 | tok/s 36365
step   2370 | loss 1.4038 | lr 7.77e-04 | grad 1.09 | tok/s 37040
step   2380 | loss 1.4811 | lr 7.77e-04 | grad 1.35 | tok/s 36395
step   2390 | loss 1.5306 | lr 7.77e-04 | grad 0.89 | tok/s 37203
step   2400 | loss 1.4206 | lr 7.77e-04 | grad 0.96 | tok/s 36074
step   2410 | loss 1.5395 | lr 7.77e-04 | grad 1.03 | tok/s 37359
step   2420 | loss 1.3056 | lr 7.77e-04 | grad 0.96 | tok/s 37182
step   2430 | loss 1.4472 | lr 7.77e-04 | grad 1.26 | tok/s 37304
step   2440 | loss 1.3135 | lr 7.77e-04 | grad 1.86 | tok/s 38530
step   2450 | loss 1.2945 | lr 7.77e-04 | grad 0.94 | tok/s 37561
step   2460 | loss 1.3773 | lr 7.77e-04 | grad 0.91 | tok/s 36088
step   2470 | loss 1.3607 | lr 7.77e-04 | grad 0.86 | tok/s 37827
step   2480 | loss 1.4559 | lr 7.77e-04 | grad 0.77 | tok/s 37111
step   2490 | loss 1.5867 | lr 7.77e-04 | grad 0.79 | tok/s 37201
step   2500 | loss 1.5022 | lr 7.77e-04 | grad 0.87 | tok/s 36283
step   2510 | loss 1.4816 | lr 7.77e-04 | grad 1.04 | tok/s 36531
step   2520 | loss 1.6833 | lr 7.77e-04 | grad 4.16 | tok/s 36817
step   2530 | loss 1.5978 | lr 7.77e-04 | grad 1.01 | tok/s 37702
step   2540 | loss 1.4344 | lr 7.77e-04 | grad 1.82 | tok/s 36471
step   2550 | loss 1.5289 | lr 7.77e-04 | grad 1.23 | tok/s 37814
step   2560 | loss 1.3237 | lr 7.77e-04 | grad 1.43 | tok/s 36672
step   2570 | loss 1.4868 | lr 7.77e-04 | grad 1.20 | tok/s 37643
step   2580 | loss 1.4126 | lr 7.77e-04 | grad 1.09 | tok/s 37792
step   2590 | loss 1.3245 | lr 7.77e-04 | grad 0.95 | tok/s 38548
step   2600 | loss 1.3424 | lr 7.77e-04 | grad 1.26 | tok/s 38012
step   2610 | loss 1.4536 | lr 7.77e-04 | grad 1.24 | tok/s 36324
step   2620 | loss 1.4130 | lr 7.77e-04 | grad 0.81 | tok/s 35924
step   2630 | loss 1.7323 | lr 7.77e-04 | grad 0.80 | tok/s 37621
step   2640 | loss 1.3018 | lr 7.77e-04 | grad 0.82 | tok/s 38524
step   2650 | loss 1.2819 | lr 7.77e-04 | grad 1.17 | tok/s 38542
step   2660 | loss 1.2439 | lr 7.77e-04 | grad 0.94 | tok/s 38555
step   2670 | loss 1.4140 | lr 7.77e-04 | grad 1.03 | tok/s 37277
step   2680 | loss 1.4918 | lr 7.77e-04 | grad 1.88 | tok/s 36193
step   2690 | loss 1.7179 | lr 7.77e-04 | grad 0.90 | tok/s 38130
step   2700 | loss 1.4878 | lr 7.77e-04 | grad 1.14 | tok/s 37065
step   2710 | loss 1.2810 | lr 7.77e-04 | grad 0.99 | tok/s 36993
step   2720 | loss 1.4601 | lr 7.77e-04 | grad 0.82 | tok/s 37390
step   2730 | loss 1.5901 | lr 7.77e-04 | grad 1.35 | tok/s 36172
step   2740 | loss 1.4228 | lr 7.77e-04 | grad 0.76 | tok/s 37377
step   2750 | loss 1.4152 | lr 7.77e-04 | grad 1.03 | tok/s 36505
step   2760 | loss 1.2750 | lr 7.77e-04 | grad 0.68 | tok/s 36908
step   2770 | loss 1.7211 | lr 7.77e-04 | grad 0.83 | tok/s 37096
step   2780 | loss 1.4327 | lr 7.77e-04 | grad 0.92 | tok/s 37616
step   2790 | loss 1.5813 | lr 7.77e-04 | grad 2.11 | tok/s 37534
step   2800 | loss 1.4317 | lr 7.77e-04 | grad 1.36 | tok/s 37862
step   2810 | loss 1.4652 | lr 7.77e-04 | grad 0.82 | tok/s 37183
step   2820 | loss 1.3271 | lr 7.77e-04 | grad 0.69 | tok/s 37416
step   2830 | loss 1.3346 | lr 7.77e-04 | grad 0.95 | tok/s 37451
step   2840 | loss 1.4528 | lr 7.77e-04 | grad 1.32 | tok/s 37362
step   2850 | loss 1.7666 | lr 7.77e-04 | grad 1.48 | tok/s 37168
step   2860 | loss 1.5638 | lr 7.77e-04 | grad 0.79 | tok/s 37885
step   2870 | loss 1.4246 | lr 7.77e-04 | grad 1.21 | tok/s 36527
step   2880 | loss 1.4494 | lr 7.77e-04 | grad 2.39 | tok/s 36594
step   2890 | loss 1.4936 | lr 7.77e-04 | grad 0.96 | tok/s 37536
step   2900 | loss 1.4160 | lr 7.77e-04 | grad 1.13 | tok/s 37577
step   2910 | loss 1.4299 | lr 7.77e-04 | grad 1.44 | tok/s 36385
step   2920 | loss 1.3812 | lr 7.77e-04 | grad 0.73 | tok/s 37117
step   2930 | loss 1.5440 | lr 7.77e-04 | grad 0.81 | tok/s 36497
step   2940 | loss 1.4121 | lr 7.77e-04 | grad 0.84 | tok/s 36687
step   2950 | loss 1.4256 | lr 7.77e-04 | grad 0.76 | tok/s 37457
step   2960 | loss 1.3721 | lr 7.77e-04 | grad 1.73 | tok/s 37195
step   2970 | loss 1.2864 | lr 7.77e-04 | grad 1.13 | tok/s 37644
step   2980 | loss 1.3980 | lr 7.77e-04 | grad 0.96 | tok/s 36974
step   2990 | loss 1.4155 | lr 7.77e-04 | grad 1.41 | tok/s 37516
step   3000 | loss 1.4393 | lr 7.77e-04 | grad 0.85 | tok/s 37183
  >>> saved checkpoint: checkpoint_step_003000_loss_1.4393.pt
step   3010 | loss 1.3887 | lr 7.77e-04 | grad 0.99 | tok/s 29323
step   3020 | loss 1.4447 | lr 7.77e-04 | grad 0.73 | tok/s 37262
step   3030 | loss 1.3699 | lr 7.77e-04 | grad 1.30 | tok/s 36535
step   3040 | loss 1.3428 | lr 7.77e-04 | grad 1.77 | tok/s 37567
step   3050 | loss 1.3027 | lr 7.77e-04 | grad 0.73 | tok/s 37447
step   3060 | loss 1.3702 | lr 7.77e-04 | grad 1.06 | tok/s 37412
step   3070 | loss 1.3878 | lr 7.77e-04 | grad 0.96 | tok/s 36416
step   3080 | loss 1.3409 | lr 7.77e-04 | grad 1.01 | tok/s 37788
step   3090 | loss 1.4076 | lr 7.77e-04 | grad 2.64 | tok/s 36775
step   3100 | loss 2.0821 | lr 7.77e-04 | grad 2.42 | tok/s 38340
step   3110 | loss 1.7085 | lr 7.77e-04 | grad 2.83 | tok/s 38587
step   3120 | loss 1.5949 | lr 7.77e-04 | grad 1.09 | tok/s 37726
step   3130 | loss 1.7832 | lr 7.77e-04 | grad 13.06 | tok/s 36455
step   3140 | loss 1.5044 | lr 7.77e-04 | grad 0.65 | tok/s 37627
step   3150 | loss 1.5458 | lr 7.77e-04 | grad 0.77 | tok/s 37062
step   3160 | loss 1.4552 | lr 7.77e-04 | grad 0.84 | tok/s 36981
step   3170 | loss 1.5603 | lr 7.77e-04 | grad 2.17 | tok/s 37531
step   3180 | loss 1.3789 | lr 7.77e-04 | grad 1.30 | tok/s 37925
step   3190 | loss 1.4435 | lr 7.77e-04 | grad 1.38 | tok/s 37705
step   3200 | loss 1.5068 | lr 7.77e-04 | grad 0.97 | tok/s 36512
step   3210 | loss 1.4586 | lr 7.77e-04 | grad 0.94 | tok/s 34925
step   3220 | loss 1.3355 | lr 7.77e-04 | grad 0.71 | tok/s 36611
step   3230 | loss 1.2586 | lr 7.77e-04 | grad 1.01 | tok/s 36777
step   3240 | loss 1.6526 | lr 7.77e-04 | grad 0.86 | tok/s 37893
step   3250 | loss 1.3989 | lr 7.77e-04 | grad 1.80 | tok/s 37658
step   3260 | loss 1.5380 | lr 7.77e-04 | grad 3.86 | tok/s 37460
step   3270 | loss 1.3756 | lr 7.77e-04 | grad 0.90 | tok/s 37381
step   3280 | loss 1.4792 | lr 7.77e-04 | grad 0.88 | tok/s 36799
step   3290 | loss 1.4552 | lr 7.77e-04 | grad 1.20 | tok/s 37089
step   3300 | loss 1.4426 | lr 7.77e-04 | grad 0.90 | tok/s 36935
step   3310 | loss 1.4257 | lr 7.77e-04 | grad 0.62 | tok/s 35892
step   3320 | loss 1.4277 | lr 7.77e-04 | grad 1.16 | tok/s 37429
step   3330 | loss 1.3712 | lr 7.77e-04 | grad 1.08 | tok/s 38321
step   3340 | loss 1.3251 | lr 7.77e-04 | grad 3.09 | tok/s 36863
step   3350 | loss 1.4974 | lr 7.77e-04 | grad 3.53 | tok/s 37388
step   3360 | loss 1.4811 | lr 7.77e-04 | grad 1.66 | tok/s 37863
step   3370 | loss 1.2911 | lr 7.77e-04 | grad 0.99 | tok/s 35949
step   3380 | loss 1.2914 | lr 7.77e-04 | grad 1.23 | tok/s 37040
step   3390 | loss 1.4709 | lr 7.77e-04 | grad 1.23 | tok/s 37924
step   3400 | loss 1.4819 | lr 7.77e-04 | grad 6.16 | tok/s 37549
step   3410 | loss 1.7971 | lr 7.77e-04 | grad 0.64 | tok/s 37330
step   3420 | loss 1.5023 | lr 7.77e-04 | grad 1.02 | tok/s 36903
step   3430 | loss 1.2416 | lr 7.77e-04 | grad 1.25 | tok/s 38513
step   3440 | loss 1.4360 | lr 7.77e-04 | grad 1.56 | tok/s 36120
step   3450 | loss 1.5001 | lr 7.77e-04 | grad 0.75 | tok/s 36484
step   3460 | loss 1.3924 | lr 7.77e-04 | grad 0.93 | tok/s 37204
step   3470 | loss 1.6370 | lr 7.77e-04 | grad 0.89 | tok/s 36862
step   3480 | loss 1.3870 | lr 7.77e-04 | grad 1.24 | tok/s 36782
step   3490 | loss 1.3733 | lr 7.77e-04 | grad 0.88 | tok/s 36826
step   3500 | loss 1.2733 | lr 7.77e-04 | grad 0.82 | tok/s 36808
step   3510 | loss 1.4358 | lr 7.77e-04 | grad 0.74 | tok/s 36861
step   3520 | loss 1.4850 | lr 7.77e-04 | grad 0.89 | tok/s 37098
step   3530 | loss 1.4721 | lr 7.77e-04 | grad 0.82 | tok/s 37524
step   3540 | loss 1.3139 | lr 7.77e-04 | grad 0.93 | tok/s 36453
step   3550 | loss 1.4287 | lr 7.77e-04 | grad 0.79 | tok/s 37563
step   3560 | loss 1.5647 | lr 7.77e-04 | grad 1.16 | tok/s 36488
step   3570 | loss 1.4140 | lr 7.77e-04 | grad 3.05 | tok/s 36905
step   3580 | loss 1.3592 | lr 7.77e-04 | grad 1.41 | tok/s 36896
step   3590 | loss 1.4139 | lr 7.77e-04 | grad 0.98 | tok/s 38311
step   3600 | loss 1.3154 | lr 7.77e-04 | grad 0.95 | tok/s 38489
step   3610 | loss 1.2876 | lr 7.77e-04 | grad 0.98 | tok/s 38535
step   3620 | loss 1.2357 | lr 7.77e-04 | grad 1.00 | tok/s 38511
step   3630 | loss 1.2138 | lr 7.77e-04 | grad 0.96 | tok/s 38500
step   3640 | loss 1.2124 | lr 7.77e-04 | grad 0.76 | tok/s 38512
step   3650 | loss 1.2631 | lr 7.77e-04 | grad 1.52 | tok/s 37852
step   3660 | loss 1.3404 | lr 7.77e-04 | grad 0.81 | tok/s 37078
step   3670 | loss 1.5700 | lr 7.77e-04 | grad 1.15 | tok/s 37121
step   3680 | loss 1.2399 | lr 7.77e-04 | grad 1.10 | tok/s 37544
step   3690 | loss 1.3082 | lr 7.77e-04 | grad 0.78 | tok/s 36680
step   3700 | loss 1.3579 | lr 7.77e-04 | grad 0.76 | tok/s 37236
step   3710 | loss 1.3225 | lr 7.77e-04 | grad 0.93 | tok/s 37999
step   3720 | loss 1.4460 | lr 7.77e-04 | grad 1.01 | tok/s 37167
step   3730 | loss 1.4158 | lr 7.77e-04 | grad 0.77 | tok/s 38082
step   3740 | loss 1.5653 | lr 7.77e-04 | grad 0.81 | tok/s 37615
step   3750 | loss 1.3181 | lr 7.77e-04 | grad 1.02 | tok/s 37673
step   3760 | loss 1.3902 | lr 7.77e-04 | grad 1.05 | tok/s 37493
step   3770 | loss 1.1987 | lr 7.77e-04 | grad 0.84 | tok/s 36915
step   3780 | loss 1.6091 | lr 7.77e-04 | grad 0.92 | tok/s 37559
step   3790 | loss 1.2919 | lr 7.77e-04 | grad 0.98 | tok/s 37712
step   3800 | loss 1.3807 | lr 7.77e-04 | grad 1.04 | tok/s 36673
step   3810 | loss 1.4316 | lr 7.77e-04 | grad 0.78 | tok/s 37498
step   3820 | loss 1.1837 | lr 7.77e-04 | grad 0.90 | tok/s 37017
step   3830 | loss 1.2685 | lr 7.77e-04 | grad 0.83 | tok/s 36079
step   3840 | loss 1.2491 | lr 7.77e-04 | grad 0.62 | tok/s 37236
step   3850 | loss 1.3360 | lr 7.77e-04 | grad 0.81 | tok/s 36652
step   3860 | loss 1.3824 | lr 7.77e-04 | grad 0.76 | tok/s 37119
step   3870 | loss 1.3885 | lr 7.77e-04 | grad 0.75 | tok/s 37444
step   3880 | loss 1.2890 | lr 7.77e-04 | grad 0.81 | tok/s 37290
step   3890 | loss 1.3760 | lr 7.77e-04 | grad 1.03 | tok/s 36474
step   3900 | loss 1.3739 | lr 7.77e-04 | grad 1.23 | tok/s 36562
step   3910 | loss 1.3407 | lr 7.77e-04 | grad 0.84 | tok/s 36460
step   3920 | loss 1.3789 | lr 7.77e-04 | grad 1.47 | tok/s 37650
step   3930 | loss 1.4176 | lr 7.77e-04 | grad 0.92 | tok/s 36920
step   3940 | loss 1.2731 | lr 7.77e-04 | grad 0.80 | tok/s 37700
step   3950 | loss 1.4155 | lr 7.77e-04 | grad 2.72 | tok/s 37378
step   3960 | loss 1.3757 | lr 7.77e-04 | grad 0.95 | tok/s 36495
step   3970 | loss 1.2134 | lr 7.77e-04 | grad 0.98 | tok/s 37962
step   3980 | loss 1.3687 | lr 7.77e-04 | grad 1.01 | tok/s 36592
step   3990 | loss 1.2991 | lr 7.77e-04 | grad 1.29 | tok/s 37585
step   4000 | loss 1.3691 | lr 7.77e-04 | grad 1.25 | tok/s 36378
  >>> saved checkpoint: checkpoint_step_004000_loss_1.3691.pt
step   4010 | loss 1.6157 | lr 7.77e-04 | grad 0.77 | tok/s 30398
step   4020 | loss 1.3677 | lr 7.77e-04 | grad 1.13 | tok/s 35532
step   4030 | loss 1.4037 | lr 7.77e-04 | grad 0.86 | tok/s 37300
step   4040 | loss 1.4233 | lr 7.77e-04 | grad 1.87 | tok/s 37827
step   4050 | loss 1.3025 | lr 7.77e-04 | grad 2.27 | tok/s 37411
step   4060 | loss 1.4760 | lr 7.77e-04 | grad 1.06 | tok/s 36567
step   4070 | loss 1.3861 | lr 7.77e-04 | grad 0.76 | tok/s 36944
step   4080 | loss 1.5209 | lr 7.77e-04 | grad 0.90 | tok/s 37474
step   4090 | loss 1.3651 | lr 7.77e-04 | grad 1.25 | tok/s 37094
step   4100 | loss 1.4109 | lr 7.77e-04 | grad 0.83 | tok/s 37163
step   4110 | loss 1.7609 | lr 7.77e-04 | grad 1.12 | tok/s 36725
step   4120 | loss 1.7640 | lr 7.77e-04 | grad 1.15 | tok/s 37562
step   4130 | loss 1.3817 | lr 7.77e-04 | grad 3.55 | tok/s 37735
step   4140 | loss 1.5057 | lr 7.77e-04 | grad 0.88 | tok/s 37992
step   4150 | loss 1.3239 | lr 7.77e-04 | grad 1.31 | tok/s 37508
step   4160 | loss 1.5529 | lr 7.77e-04 | grad 0.81 | tok/s 37020
step   4170 | loss 1.3540 | lr 7.77e-04 | grad 0.83 | tok/s 36484
step   4180 | loss 1.3347 | lr 7.77e-04 | grad 0.85 | tok/s 37056
step   4190 | loss 1.3129 | lr 7.77e-04 | grad 0.94 | tok/s 36808
step   4200 | loss 1.2621 | lr 7.77e-04 | grad 0.84 | tok/s 37296

Training complete! Final step: 4200
