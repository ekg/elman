Using device: cuda
Output directory: benchmark_results/cmaes_4d/e75_480M_converge0.01_20260202_222930/eval_11/levelE75h11n24_100m_20260202_225948
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h11n24, 84,068,384 parameters
Using schedule-free AdamW (lr=0.0008272179226646855)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 4.5011 | lr 8.27e-04 | grad 13.62 | tok/s 23034
step     20 | loss 4.1822 | lr 8.27e-04 | grad 5.69 | tok/s 68727
step     30 | loss 3.8818 | lr 8.27e-04 | grad 4.41 | tok/s 69608
step     40 | loss 3.3526 | lr 8.27e-04 | grad 4.38 | tok/s 69553
step     50 | loss 2.9764 | lr 8.27e-04 | grad 3.03 | tok/s 69509
step     60 | loss 3.1345 | lr 8.27e-04 | grad 2.92 | tok/s 66632
step     70 | loss 2.8546 | lr 8.27e-04 | grad 4.19 | tok/s 67765
step     80 | loss 2.7822 | lr 8.27e-04 | grad 2.19 | tok/s 67154
step     90 | loss 2.7553 | lr 8.27e-04 | grad 1.89 | tok/s 65424
step    100 | loss 2.3073 | lr 8.27e-04 | grad 2.42 | tok/s 67974
step    110 | loss 2.7656 | lr 8.27e-04 | grad 1.54 | tok/s 65459
step    120 | loss 2.5439 | lr 8.27e-04 | grad 1.59 | tok/s 65855
step    130 | loss 2.3274 | lr 8.27e-04 | grad 2.19 | tok/s 67432
step    140 | loss 2.1211 | lr 8.27e-04 | grad 1.55 | tok/s 64156
step    150 | loss 2.1732 | lr 8.27e-04 | grad 1.02 | tok/s 64677
step    160 | loss 2.1647 | lr 8.27e-04 | grad 1.65 | tok/s 64893
step    170 | loss 2.3306 | lr 8.27e-04 | grad 2.08 | tok/s 66311
step    180 | loss 2.0420 | lr 8.27e-04 | grad 1.43 | tok/s 66146
step    190 | loss 1.7837 | lr 8.27e-04 | grad 1.27 | tok/s 68449
step    200 | loss 1.9588 | lr 8.27e-04 | grad 1.09 | tok/s 66369
step    210 | loss 2.0987 | lr 8.27e-04 | grad 1.18 | tok/s 67265
step    220 | loss 2.0191 | lr 8.27e-04 | grad 1.24 | tok/s 65897
step    230 | loss 1.9069 | lr 8.27e-04 | grad 1.27 | tok/s 65728
step    240 | loss 1.9882 | lr 8.27e-04 | grad 1.28 | tok/s 67192
step    250 | loss 2.0580 | lr 8.27e-04 | grad 1.16 | tok/s 65572
step    260 | loss 1.8532 | lr 8.27e-04 | grad 1.36 | tok/s 64162
step    270 | loss 1.9015 | lr 8.27e-04 | grad 3.02 | tok/s 65579
step    280 | loss 1.6857 | lr 8.27e-04 | grad 1.34 | tok/s 67683
step    290 | loss 1.5422 | lr 8.27e-04 | grad 1.21 | tok/s 68537
step    300 | loss 1.5611 | lr 8.27e-04 | grad 1.22 | tok/s 68462
step    310 | loss 1.6882 | lr 8.27e-04 | grad 1.37 | tok/s 67842
step    320 | loss 1.8587 | lr 8.27e-04 | grad 0.91 | tok/s 64789
step    330 | loss 1.8681 | lr 8.27e-04 | grad 1.71 | tok/s 66848
step    340 | loss 1.8286 | lr 8.27e-04 | grad 1.66 | tok/s 64693
step    350 | loss 1.7967 | lr 8.27e-04 | grad 1.12 | tok/s 64275
step    360 | loss 1.6936 | lr 8.27e-04 | grad 1.25 | tok/s 66500
step    370 | loss 2.1577 | lr 8.27e-04 | grad 1.63 | tok/s 66671
step    380 | loss 1.7439 | lr 8.27e-04 | grad 1.02 | tok/s 67733
step    390 | loss 1.7327 | lr 8.27e-04 | grad 1.06 | tok/s 66003
step    400 | loss 1.7368 | lr 8.27e-04 | grad 0.86 | tok/s 66488
step    410 | loss 1.7245 | lr 8.27e-04 | grad 1.23 | tok/s 64485
step    420 | loss 1.8077 | lr 8.27e-04 | grad 1.15 | tok/s 64920
step    430 | loss 1.8631 | lr 8.27e-04 | grad 1.78 | tok/s 66926
step    440 | loss 1.7575 | lr 8.27e-04 | grad 1.00 | tok/s 65744
step    450 | loss 1.7042 | lr 8.27e-04 | grad 0.82 | tok/s 65764
step    460 | loss 1.7427 | lr 8.27e-04 | grad 1.37 | tok/s 65893
step    470 | loss 1.6075 | lr 8.27e-04 | grad 0.96 | tok/s 63917
step    480 | loss 1.5936 | lr 8.27e-04 | grad 0.93 | tok/s 65426
step    490 | loss 2.1037 | lr 8.27e-04 | grad 1.38 | tok/s 67379
step    500 | loss 1.6785 | lr 8.27e-04 | grad 3.27 | tok/s 65784
step    510 | loss 1.4734 | lr 8.27e-04 | grad 0.78 | tok/s 67741
step    520 | loss 2.0933 | lr 8.27e-04 | grad 2.17 | tok/s 65924
step    530 | loss 1.5273 | lr 8.27e-04 | grad 1.55 | tok/s 66740
step    540 | loss 1.5269 | lr 8.27e-04 | grad 1.12 | tok/s 67364
step    550 | loss 1.3676 | lr 8.27e-04 | grad 1.21 | tok/s 68560
step    560 | loss 1.5270 | lr 8.27e-04 | grad 2.64 | tok/s 67597
step    570 | loss 1.9624 | lr 8.27e-04 | grad 1.00 | tok/s 67733
step    580 | loss 2.0834 | lr 8.27e-04 | grad 3.06 | tok/s 65231
step    590 | loss 1.5831 | lr 8.27e-04 | grad 1.20 | tok/s 65936
step    600 | loss 1.6375 | lr 8.27e-04 | grad 1.20 | tok/s 68481
step    610 | loss 1.5673 | lr 8.27e-04 | grad 0.92 | tok/s 65024
step    620 | loss 1.5114 | lr 8.27e-04 | grad 1.02 | tok/s 67442
step    630 | loss 1.7317 | lr 8.27e-04 | grad 1.16 | tok/s 67358
step    640 | loss 1.5776 | lr 8.27e-04 | grad 1.50 | tok/s 65865
step    650 | loss 1.7314 | lr 8.27e-04 | grad 3.97 | tok/s 64868
step    660 | loss 1.6982 | lr 8.27e-04 | grad 1.69 | tok/s 67028
step    670 | loss 1.7184 | lr 8.27e-04 | grad 1.39 | tok/s 65702
step    680 | loss 1.6362 | lr 8.27e-04 | grad 1.35 | tok/s 65129
step    690 | loss 1.7272 | lr 8.27e-04 | grad 1.39 | tok/s 65764
step    700 | loss 1.6701 | lr 8.27e-04 | grad 1.01 | tok/s 66493
step    710 | loss 1.6184 | lr 8.27e-04 | grad 2.78 | tok/s 65835
step    720 | loss 1.7347 | lr 8.27e-04 | grad 1.28 | tok/s 66231
step    730 | loss 1.7333 | lr 8.27e-04 | grad 2.33 | tok/s 66000
step    740 | loss 1.5272 | lr 8.27e-04 | grad 1.00 | tok/s 65291
step    750 | loss 1.8136 | lr 8.27e-04 | grad 0.96 | tok/s 66089
step    760 | loss 1.5591 | lr 8.27e-04 | grad 1.18 | tok/s 65964
step    770 | loss 1.6408 | lr 8.27e-04 | grad 1.52 | tok/s 67035
step    780 | loss 1.4703 | lr 8.27e-04 | grad 1.10 | tok/s 67249
step    790 | loss 1.5407 | lr 8.27e-04 | grad 2.72 | tok/s 66455
step    800 | loss 1.4857 | lr 8.27e-04 | grad 1.15 | tok/s 65906
step    810 | loss 2.2686 | lr 8.27e-04 | grad 2.39 | tok/s 68037
step    820 | loss 1.9298 | lr 8.27e-04 | grad 1.59 | tok/s 68514
step    830 | loss 1.7066 | lr 8.27e-04 | grad 1.71 | tok/s 68496
step    840 | loss 1.6666 | lr 8.27e-04 | grad 0.92 | tok/s 65390
step    850 | loss 1.5087 | lr 8.27e-04 | grad 0.80 | tok/s 66219
step    860 | loss 1.5301 | lr 8.27e-04 | grad 1.04 | tok/s 65935
step    870 | loss 1.6242 | lr 8.27e-04 | grad 1.21 | tok/s 67156
step    880 | loss 1.5194 | lr 8.27e-04 | grad 1.76 | tok/s 65247
step    890 | loss 1.8379 | lr 8.27e-04 | grad 1.16 | tok/s 64876
step    900 | loss 1.4910 | lr 8.27e-04 | grad 1.33 | tok/s 64877
step    910 | loss 1.5820 | lr 8.27e-04 | grad 0.82 | tok/s 65504
step    920 | loss 1.5311 | lr 8.27e-04 | grad 1.14 | tok/s 65170
step    930 | loss 1.6104 | lr 8.27e-04 | grad 1.04 | tok/s 65080
step    940 | loss 1.5890 | lr 8.27e-04 | grad 0.83 | tok/s 66607
step    950 | loss 1.3543 | lr 8.27e-04 | grad 1.11 | tok/s 68557
step    960 | loss 1.2878 | lr 8.27e-04 | grad 0.93 | tok/s 68533
step    970 | loss 1.5253 | lr 8.27e-04 | grad 1.07 | tok/s 66147
step    980 | loss 1.6511 | lr 8.27e-04 | grad 1.74 | tok/s 64864
step    990 | loss 1.6245 | lr 8.27e-04 | grad 1.48 | tok/s 65914
step   1000 | loss 1.5199 | lr 8.27e-04 | grad 0.96 | tok/s 67350
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5199.pt
step   1010 | loss 1.4832 | lr 8.27e-04 | grad 1.02 | tok/s 51738
step   1020 | loss 1.7900 | lr 8.27e-04 | grad 1.03 | tok/s 64739
step   1030 | loss 1.5785 | lr 8.27e-04 | grad 1.30 | tok/s 66357
step   1040 | loss 1.4365 | lr 8.27e-04 | grad 1.23 | tok/s 64650
step   1050 | loss 1.7388 | lr 8.27e-04 | grad 1.71 | tok/s 67886
step   1060 | loss 1.9796 | lr 8.27e-04 | grad 3.11 | tok/s 66064
step   1070 | loss 1.6695 | lr 8.27e-04 | grad 1.45 | tok/s 65349
step   1080 | loss 1.7523 | lr 8.27e-04 | grad 1.04 | tok/s 65908
step   1090 | loss 1.4455 | lr 8.27e-04 | grad 0.97 | tok/s 67273
step   1100 | loss 1.5942 | lr 8.27e-04 | grad 2.69 | tok/s 67098
step   1110 | loss 1.5764 | lr 8.27e-04 | grad 0.93 | tok/s 65797
step   1120 | loss 1.5926 | lr 8.27e-04 | grad 0.98 | tok/s 65545
step   1130 | loss 1.5950 | lr 8.27e-04 | grad 1.50 | tok/s 66295
step   1140 | loss 1.6653 | lr 8.27e-04 | grad 0.91 | tok/s 64412
step   1150 | loss 1.6457 | lr 8.27e-04 | grad 0.78 | tok/s 64764
step   1160 | loss 1.5325 | lr 8.27e-04 | grad 1.08 | tok/s 67142
step   1170 | loss 1.4268 | lr 8.27e-04 | grad 1.00 | tok/s 68542
step   1180 | loss 1.3492 | lr 8.27e-04 | grad 1.23 | tok/s 68537
step   1190 | loss 1.2856 | lr 8.27e-04 | grad 0.86 | tok/s 68542
step   1200 | loss 1.2924 | lr 8.27e-04 | grad 0.98 | tok/s 68558
step   1210 | loss 1.5095 | lr 8.27e-04 | grad 0.82 | tok/s 67407
step   1220 | loss 1.3445 | lr 8.27e-04 | grad 0.88 | tok/s 64519
step   1230 | loss 1.5676 | lr 8.27e-04 | grad 1.71 | tok/s 66564
step   1240 | loss 1.5375 | lr 8.27e-04 | grad 1.26 | tok/s 66269
step   1250 | loss 1.6862 | lr 8.27e-04 | grad 1.17 | tok/s 66695
step   1260 | loss 1.5511 | lr 8.27e-04 | grad 0.90 | tok/s 65405
step   1270 | loss 1.6129 | lr 8.27e-04 | grad 0.84 | tok/s 65104
step   1280 | loss 1.5889 | lr 8.27e-04 | grad 1.88 | tok/s 65382
step   1290 | loss 1.6049 | lr 8.27e-04 | grad 0.82 | tok/s 65446
step   1300 | loss 1.5436 | lr 8.27e-04 | grad 0.78 | tok/s 64354
step   1310 | loss 1.5984 | lr 8.27e-04 | grad 1.44 | tok/s 66151
step   1320 | loss 1.4406 | lr 8.27e-04 | grad 0.79 | tok/s 66527
step   1330 | loss 1.4148 | lr 8.27e-04 | grad 0.86 | tok/s 66135
step   1340 | loss 1.4589 | lr 8.27e-04 | grad 0.69 | tok/s 66077
step   1350 | loss 1.4688 | lr 8.27e-04 | grad 0.81 | tok/s 64710
step   1360 | loss 1.6696 | lr 8.27e-04 | grad 1.25 | tok/s 66420
step   1370 | loss 1.4918 | lr 8.27e-04 | grad 1.00 | tok/s 65407
step   1380 | loss 1.4772 | lr 8.27e-04 | grad 0.76 | tok/s 66846
step   1390 | loss 1.5359 | lr 8.27e-04 | grad 1.06 | tok/s 66338
step   1400 | loss 1.5560 | lr 8.27e-04 | grad 1.07 | tok/s 64872
step   1410 | loss 1.5244 | lr 8.27e-04 | grad 0.86 | tok/s 63765
step   1420 | loss 1.3372 | lr 8.27e-04 | grad 0.77 | tok/s 65041
step   1430 | loss 1.3134 | lr 8.27e-04 | grad 1.20 | tok/s 68083
step   1440 | loss 1.4928 | lr 8.27e-04 | grad 0.65 | tok/s 64562
step   1450 | loss 1.6173 | lr 8.27e-04 | grad 0.96 | tok/s 65392
step   1460 | loss 1.4897 | lr 8.27e-04 | grad 0.94 | tok/s 65878
step   1470 | loss 1.4529 | lr 8.27e-04 | grad 1.17 | tok/s 66263
step   1480 | loss 1.6637 | lr 8.27e-04 | grad 1.10 | tok/s 65293
step   1490 | loss 1.6291 | lr 8.27e-04 | grad 0.85 | tok/s 66223
step   1500 | loss 1.5461 | lr 8.27e-04 | grad 1.03 | tok/s 66596
step   1510 | loss 1.5075 | lr 8.27e-04 | grad 1.20 | tok/s 67171
step   1520 | loss 1.4419 | lr 8.27e-04 | grad 0.80 | tok/s 64734
step   1530 | loss 1.3214 | lr 8.27e-04 | grad 0.66 | tok/s 67262
step   1540 | loss 2.0998 | lr 8.27e-04 | grad 0.85 | tok/s 66203
step   1550 | loss 1.5271 | lr 8.27e-04 | grad 0.98 | tok/s 64436
step   1560 | loss 1.5212 | lr 8.27e-04 | grad 0.86 | tok/s 66959
step   1570 | loss 1.4734 | lr 8.27e-04 | grad 0.93 | tok/s 65296
step   1580 | loss 1.5165 | lr 8.27e-04 | grad 1.17 | tok/s 64704
step   1590 | loss 1.3606 | lr 8.27e-04 | grad 1.05 | tok/s 67805
step   1600 | loss 1.4937 | lr 8.27e-04 | grad 0.86 | tok/s 66387
step   1610 | loss 1.4929 | lr 8.27e-04 | grad 1.09 | tok/s 66941
step   1620 | loss 1.4331 | lr 8.27e-04 | grad 0.80 | tok/s 65254
step   1630 | loss 1.4964 | lr 8.27e-04 | grad 1.91 | tok/s 64299
step   1640 | loss 1.4944 | lr 8.27e-04 | grad 1.11 | tok/s 65194
step   1650 | loss 1.4841 | lr 8.27e-04 | grad 1.88 | tok/s 66770
step   1660 | loss 1.8698 | lr 8.27e-04 | grad 0.87 | tok/s 67256
step   1670 | loss 1.4372 | lr 8.27e-04 | grad 1.12 | tok/s 64847
step   1680 | loss 1.5108 | lr 8.27e-04 | grad 0.84 | tok/s 67192
step   1690 | loss 1.5793 | lr 8.27e-04 | grad 1.02 | tok/s 65737
step   1700 | loss 1.4879 | lr 8.27e-04 | grad 0.97 | tok/s 65413
step   1710 | loss 1.5958 | lr 8.27e-04 | grad 1.25 | tok/s 65258
step   1720 | loss 1.5119 | lr 8.27e-04 | grad 0.83 | tok/s 66853
step   1730 | loss 1.4960 | lr 8.27e-04 | grad 0.86 | tok/s 64482
step   1740 | loss 1.6168 | lr 8.27e-04 | grad 0.71 | tok/s 64674
step   1750 | loss 1.5654 | lr 8.27e-04 | grad 0.71 | tok/s 66425
step   1760 | loss 1.4892 | lr 8.27e-04 | grad 0.83 | tok/s 64085
step   1770 | loss 1.6472 | lr 8.27e-04 | grad 0.99 | tok/s 65127
step   1780 | loss 1.4245 | lr 8.27e-04 | grad 0.88 | tok/s 66889
step   1790 | loss 1.4931 | lr 8.27e-04 | grad 0.75 | tok/s 66381
step   1800 | loss 1.3963 | lr 8.27e-04 | grad 0.91 | tok/s 65253
step   1810 | loss 1.4783 | lr 8.27e-04 | grad 0.94 | tok/s 65299
step   1820 | loss 1.5623 | lr 8.27e-04 | grad 2.31 | tok/s 65266
step   1830 | loss 1.5978 | lr 8.27e-04 | grad 1.23 | tok/s 64971
step   1840 | loss 1.4347 | lr 8.27e-04 | grad 0.73 | tok/s 64712
step   1850 | loss 1.4214 | lr 8.27e-04 | grad 1.39 | tok/s 67725
step   1860 | loss 1.4659 | lr 8.27e-04 | grad 1.08 | tok/s 67021
step   1870 | loss 1.5544 | lr 8.27e-04 | grad 1.51 | tok/s 65368
step   1880 | loss 1.4867 | lr 8.27e-04 | grad 1.63 | tok/s 66721
step   1890 | loss 1.6105 | lr 8.27e-04 | grad 1.33 | tok/s 65627
step   1900 | loss 1.3487 | lr 8.27e-04 | grad 1.09 | tok/s 66708
step   1910 | loss 1.3726 | lr 8.27e-04 | grad 0.71 | tok/s 66579
step   1920 | loss 1.4361 | lr 8.27e-04 | grad 1.45 | tok/s 67834
step   1930 | loss 1.5139 | lr 8.27e-04 | grad 1.01 | tok/s 66866
step   1940 | loss 1.5605 | lr 8.27e-04 | grad 1.09 | tok/s 66913
step   1950 | loss 1.3816 | lr 8.27e-04 | grad 0.72 | tok/s 65996
step   1960 | loss 1.5593 | lr 8.27e-04 | grad 1.12 | tok/s 65971
step   1970 | loss 1.4416 | lr 8.27e-04 | grad 0.73 | tok/s 65942
step   1980 | loss 1.4746 | lr 8.27e-04 | grad 1.16 | tok/s 67061
step   1990 | loss 1.1908 | lr 8.27e-04 | grad 0.68 | tok/s 68857
step   2000 | loss 1.1818 | lr 8.27e-04 | grad 0.48 | tok/s 68734
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1818.pt
step   2010 | loss 1.4434 | lr 8.27e-04 | grad 0.81 | tok/s 54387
step   2020 | loss 1.2562 | lr 8.27e-04 | grad 0.91 | tok/s 68845
step   2030 | loss 1.3230 | lr 8.27e-04 | grad 0.89 | tok/s 67420
step   2040 | loss 1.5589 | lr 8.27e-04 | grad 0.68 | tok/s 65468
step   2050 | loss 1.4352 | lr 8.27e-04 | grad 0.81 | tok/s 67196
step   2060 | loss 1.5552 | lr 8.27e-04 | grad 1.17 | tok/s 66517
step   2070 | loss 1.4550 | lr 8.27e-04 | grad 0.92 | tok/s 66612
step   2080 | loss 1.4804 | lr 8.27e-04 | grad 1.05 | tok/s 64923
step   2090 | loss 1.2991 | lr 8.27e-04 | grad 2.12 | tok/s 67477
step   2100 | loss 1.1655 | lr 8.27e-04 | grad 0.90 | tok/s 66592
step   2110 | loss 1.5608 | lr 8.27e-04 | grad 0.93 | tok/s 65989
step   2120 | loss 1.5409 | lr 8.27e-04 | grad 0.73 | tok/s 65830
step   2130 | loss 1.5238 | lr 8.27e-04 | grad 0.91 | tok/s 64802
step   2140 | loss 1.4592 | lr 8.27e-04 | grad 0.74 | tok/s 66009
step   2150 | loss 1.6264 | lr 8.27e-04 | grad 1.08 | tok/s 66348
step   2160 | loss 1.6455 | lr 8.27e-04 | grad 1.63 | tok/s 67793
step   2170 | loss 1.3434 | lr 8.27e-04 | grad 0.93 | tok/s 67207
step   2180 | loss 1.2103 | lr 8.27e-04 | grad 0.58 | tok/s 68806
step   2190 | loss 1.2282 | lr 8.27e-04 | grad 0.55 | tok/s 68893
step   2200 | loss 1.2144 | lr 8.27e-04 | grad 0.77 | tok/s 68782
step   2210 | loss 1.4208 | lr 8.27e-04 | grad 0.85 | tok/s 66335
step   2220 | loss 1.5522 | lr 8.27e-04 | grad 1.70 | tok/s 68668
step   2230 | loss 1.5428 | lr 8.27e-04 | grad 2.38 | tok/s 67446
step   2240 | loss 1.4282 | lr 8.27e-04 | grad 0.77 | tok/s 66744
step   2250 | loss 1.4458 | lr 8.27e-04 | grad 1.16 | tok/s 66730
step   2260 | loss 1.5194 | lr 8.27e-04 | grad 0.88 | tok/s 64810
step   2270 | loss 1.4207 | lr 8.27e-04 | grad 0.82 | tok/s 65723
step   2280 | loss 1.4633 | lr 8.27e-04 | grad 0.85 | tok/s 66235
step   2290 | loss 1.4074 | lr 8.27e-04 | grad 0.77 | tok/s 68907
step   2300 | loss 1.3367 | lr 8.27e-04 | grad 0.92 | tok/s 68884
step   2310 | loss 1.3246 | lr 8.27e-04 | grad 1.27 | tok/s 68523
step   2320 | loss 1.4946 | lr 8.27e-04 | grad 1.21 | tok/s 66908
step   2330 | loss 1.5288 | lr 8.27e-04 | grad 1.00 | tok/s 66228
step   2340 | loss 1.8169 | lr 8.27e-04 | grad 1.34 | tok/s 67143
step   2350 | loss 1.4262 | lr 8.27e-04 | grad 1.23 | tok/s 67205
step   2360 | loss 1.4270 | lr 8.27e-04 | grad 0.77 | tok/s 65432
step   2370 | loss 1.4102 | lr 8.27e-04 | grad 2.62 | tok/s 65051
step   2380 | loss 1.4999 | lr 8.27e-04 | grad 1.35 | tok/s 66021
step   2390 | loss 1.5910 | lr 8.27e-04 | grad 0.76 | tok/s 65456
step   2400 | loss 1.4220 | lr 8.27e-04 | grad 1.18 | tok/s 64728
step   2410 | loss 1.6017 | lr 8.27e-04 | grad 1.84 | tok/s 67083
step   2420 | loss 1.3814 | lr 8.27e-04 | grad 0.77 | tok/s 65970
step   2430 | loss 1.4024 | lr 8.27e-04 | grad 0.68 | tok/s 66835
step   2440 | loss 1.3975 | lr 8.27e-04 | grad 1.76 | tok/s 68698
step   2450 | loss 1.3632 | lr 8.27e-04 | grad 0.96 | tok/s 67286
step   2460 | loss 1.3587 | lr 8.27e-04 | grad 0.78 | tok/s 64978
step   2470 | loss 1.4091 | lr 8.27e-04 | grad 2.08 | tok/s 67238
step   2480 | loss 1.4463 | lr 8.27e-04 | grad 0.80 | tok/s 66470
step   2490 | loss 1.6153 | lr 8.27e-04 | grad 0.88 | tok/s 67387
step   2500 | loss 1.5203 | lr 8.27e-04 | grad 0.71 | tok/s 64787
step   2510 | loss 1.5144 | lr 8.27e-04 | grad 1.51 | tok/s 65259
step   2520 | loss 1.4469 | lr 8.27e-04 | grad 1.16 | tok/s 65112
step   2530 | loss 1.8458 | lr 8.27e-04 | grad 0.88 | tok/s 67550
step   2540 | loss 1.3884 | lr 8.27e-04 | grad 0.90 | tok/s 66250
step   2550 | loss 1.6445 | lr 8.27e-04 | grad 1.65 | tok/s 66651
step   2560 | loss 1.3524 | lr 8.27e-04 | grad 0.82 | tok/s 65876
step   2570 | loss 1.4769 | lr 8.27e-04 | grad 0.90 | tok/s 67350
step   2580 | loss 1.4351 | lr 8.27e-04 | grad 0.91 | tok/s 67177
step   2590 | loss 1.3809 | lr 8.27e-04 | grad 0.61 | tok/s 68910
step   2600 | loss 1.3143 | lr 8.27e-04 | grad 0.84 | tok/s 69001
step   2610 | loss 1.4861 | lr 8.27e-04 | grad 0.66 | tok/s 64484
step   2620 | loss 1.4576 | lr 8.27e-04 | grad 0.62 | tok/s 64897
step   2630 | loss 1.6914 | lr 8.27e-04 | grad 2.36 | tok/s 66527
step   2640 | loss 1.3630 | lr 8.27e-04 | grad 0.67 | tok/s 68857
step   2650 | loss 1.2852 | lr 8.27e-04 | grad 0.64 | tok/s 68966
step   2660 | loss 1.2900 | lr 8.27e-04 | grad 0.84 | tok/s 68982
step   2670 | loss 1.4021 | lr 8.27e-04 | grad 0.85 | tok/s 66863
step   2680 | loss 1.4510 | lr 8.27e-04 | grad 1.15 | tok/s 64728
step   2690 | loss 1.8326 | lr 8.27e-04 | grad 1.44 | tok/s 68310
step   2700 | loss 1.4974 | lr 8.27e-04 | grad 1.03 | tok/s 66333
step   2710 | loss 1.3149 | lr 8.27e-04 | grad 1.25 | tok/s 66951
step   2720 | loss 1.4444 | lr 8.27e-04 | grad 0.82 | tok/s 66122
step   2730 | loss 1.5204 | lr 8.27e-04 | grad 0.61 | tok/s 65149
step   2740 | loss 1.6218 | lr 8.27e-04 | grad 0.90 | tok/s 66448
step   2750 | loss 1.4013 | lr 8.27e-04 | grad 0.78 | tok/s 65931
step   2760 | loss 1.3331 | lr 8.27e-04 | grad 0.64 | tok/s 65523
step   2770 | loss 1.6785 | lr 8.27e-04 | grad 2.33 | tok/s 66540
step   2780 | loss 1.6072 | lr 8.27e-04 | grad 1.21 | tok/s 66986
step   2790 | loss 1.4712 | lr 8.27e-04 | grad 0.90 | tok/s 68071
step   2800 | loss 1.5200 | lr 8.27e-04 | grad 0.75 | tok/s 67550
step   2810 | loss 1.5131 | lr 8.27e-04 | grad 0.89 | tok/s 66709
step   2820 | loss 1.3611 | lr 8.27e-04 | grad 2.50 | tok/s 67001
step   2830 | loss 1.3446 | lr 8.27e-04 | grad 1.67 | tok/s 66771
step   2840 | loss 1.4659 | lr 8.27e-04 | grad 2.56 | tok/s 66691
step   2850 | loss 1.8167 | lr 8.27e-04 | grad 1.10 | tok/s 67451
step   2860 | loss 1.6045 | lr 8.27e-04 | grad 1.61 | tok/s 67079
step   2870 | loss 1.4204 | lr 8.27e-04 | grad 0.87 | tok/s 64931
step   2880 | loss 1.3933 | lr 8.27e-04 | grad 0.72 | tok/s 65453
step   2890 | loss 1.6213 | lr 8.27e-04 | grad 1.62 | tok/s 67770
step   2900 | loss 1.3895 | lr 8.27e-04 | grad 0.59 | tok/s 66795
step   2910 | loss 1.4653 | lr 8.27e-04 | grad 1.30 | tok/s 65380
step   2920 | loss 1.4578 | lr 8.27e-04 | grad 0.79 | tok/s 65839
step   2930 | loss 1.5765 | lr 8.27e-04 | grad 0.93 | tok/s 66152
step   2940 | loss 1.4203 | lr 8.27e-04 | grad 1.30 | tok/s 65597
step   2950 | loss 1.4782 | lr 8.27e-04 | grad 1.18 | tok/s 66484
step   2960 | loss 1.3932 | lr 8.27e-04 | grad 0.65 | tok/s 66764
step   2970 | loss 1.3143 | lr 8.27e-04 | grad 1.34 | tok/s 67354
step   2980 | loss 1.4463 | lr 8.27e-04 | grad 1.29 | tok/s 66835
step   2990 | loss 1.3844 | lr 8.27e-04 | grad 0.73 | tok/s 66501
step   3000 | loss 1.5091 | lr 8.27e-04 | grad 0.80 | tok/s 66596
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5091.pt
step   3010 | loss 1.4085 | lr 8.27e-04 | grad 1.02 | tok/s 52586
step   3020 | loss 1.4621 | lr 8.27e-04 | grad 1.05 | tok/s 66607
step   3030 | loss 1.3465 | lr 8.27e-04 | grad 0.61 | tok/s 64974
step   3040 | loss 1.3493 | lr 8.27e-04 | grad 0.84 | tok/s 66606
step   3050 | loss 1.3987 | lr 8.27e-04 | grad 1.06 | tok/s 67367
step   3060 | loss 1.3611 | lr 8.27e-04 | grad 0.89 | tok/s 66930
step   3070 | loss 1.4137 | lr 8.27e-04 | grad 1.20 | tok/s 65307
step   3080 | loss 1.3822 | lr 8.27e-04 | grad 1.76 | tok/s 66781
step   3090 | loss 1.3917 | lr 8.27e-04 | grad 1.71 | tok/s 65487
step   3100 | loss 1.9506 | lr 8.27e-04 | grad 2.14 | tok/s 68442
step   3110 | loss 1.7907 | lr 8.27e-04 | grad 2.00 | tok/s 69062
step   3120 | loss 1.6038 | lr 8.27e-04 | grad 1.63 | tok/s 69044
step   3130 | loss 1.4730 | lr 8.27e-04 | grad 0.85 | tok/s 64256
step   3140 | loss 1.9328 | lr 8.27e-04 | grad 0.88 | tok/s 67417
step   3150 | loss 1.5063 | lr 8.27e-04 | grad 1.26 | tok/s 66582
step   3160 | loss 1.5497 | lr 8.27e-04 | grad 0.98 | tok/s 66310
step   3170 | loss 1.4483 | lr 8.27e-04 | grad 2.08 | tok/s 66207
step   3180 | loss 1.5978 | lr 8.27e-04 | grad 0.84 | tok/s 67866
step   3190 | loss 1.4605 | lr 8.27e-04 | grad 0.91 | tok/s 68058
step   3200 | loss 1.5302 | lr 8.27e-04 | grad 0.70 | tok/s 65671
step   3210 | loss 1.4433 | lr 8.27e-04 | grad 1.56 | tok/s 63945
step   3220 | loss 1.4449 | lr 8.27e-04 | grad 0.88 | tok/s 63706
step   3230 | loss 1.2899 | lr 8.27e-04 | grad 0.79 | tok/s 66255
step   3240 | loss 1.6354 | lr 8.27e-04 | grad 1.09 | tok/s 67226
step   3250 | loss 1.4190 | lr 8.27e-04 | grad 1.28 | tok/s 66855
step   3260 | loss 1.5297 | lr 8.27e-04 | grad 1.88 | tok/s 68335
step   3270 | loss 1.4603 | lr 8.27e-04 | grad 0.77 | tok/s 65825
step   3280 | loss 1.4788 | lr 8.27e-04 | grad 0.85 | tok/s 66231
step   3290 | loss 1.5139 | lr 8.27e-04 | grad 0.97 | tok/s 65325
step   3300 | loss 1.4699 | lr 8.27e-04 | grad 1.09 | tok/s 67772
step   3310 | loss 1.4110 | lr 8.27e-04 | grad 0.90 | tok/s 63708
step   3320 | loss 1.4558 | lr 8.27e-04 | grad 0.92 | tok/s 65660
step   3330 | loss 1.4077 | lr 8.27e-04 | grad 0.86 | tok/s 68879
step   3340 | loss 1.3844 | lr 8.27e-04 | grad 1.88 | tok/s 65960
step   3350 | loss 1.3433 | lr 8.27e-04 | grad 1.59 | tok/s 66704
step   3360 | loss 1.6908 | lr 8.27e-04 | grad 1.45 | tok/s 68530
step   3370 | loss 1.4169 | lr 8.27e-04 | grad 0.88 | tok/s 64561
step   3380 | loss 1.3120 | lr 8.27e-04 | grad 0.95 | tok/s 65390
step   3390 | loss 1.4642 | lr 8.27e-04 | grad 0.82 | tok/s 68147
step   3400 | loss 1.4800 | lr 8.27e-04 | grad 1.62 | tok/s 66946
step   3410 | loss 1.9226 | lr 8.27e-04 | grad 0.87 | tok/s 66087
step   3420 | loss 1.4584 | lr 8.27e-04 | grad 0.96 | tok/s 66347
step   3430 | loss 1.4272 | lr 8.27e-04 | grad 1.01 | tok/s 68577
step   3440 | loss 1.4004 | lr 8.27e-04 | grad 0.78 | tok/s 66575
step   3450 | loss 1.5182 | lr 8.27e-04 | grad 0.66 | tok/s 64300
step   3460 | loss 1.4250 | lr 8.27e-04 | grad 0.91 | tok/s 66332
step   3470 | loss 1.4907 | lr 8.27e-04 | grad 2.05 | tok/s 66496
step   3480 | loss 1.5933 | lr 8.27e-04 | grad 1.33 | tok/s 65439
step   3490 | loss 1.4398 | lr 8.27e-04 | grad 0.76 | tok/s 66237
step   3500 | loss 1.2884 | lr 8.27e-04 | grad 0.70 | tok/s 65476
step   3510 | loss 1.4440 | lr 8.27e-04 | grad 0.89 | tok/s 66507
step   3520 | loss 1.4708 | lr 8.27e-04 | grad 0.82 | tok/s 65103
step   3530 | loss 1.5029 | lr 8.27e-04 | grad 0.91 | tok/s 67287
step   3540 | loss 1.3862 | lr 8.27e-04 | grad 0.95 | tok/s 65521
step   3550 | loss 1.4410 | lr 8.27e-04 | grad 0.93 | tok/s 67108
step   3560 | loss 1.5508 | lr 8.27e-04 | grad 1.02 | tok/s 64608
step   3570 | loss 1.4541 | lr 8.27e-04 | grad 1.12 | tok/s 66186
step   3580 | loss 1.4053 | lr 8.27e-04 | grad 0.67 | tok/s 65947
step   3590 | loss 1.4232 | lr 8.27e-04 | grad 1.03 | tok/s 68054
step   3600 | loss 1.4067 | lr 8.27e-04 | grad 0.89 | tok/s 68623
step   3610 | loss 1.3054 | lr 8.27e-04 | grad 0.74 | tok/s 68952
step   3620 | loss 1.2764 | lr 8.27e-04 | grad 0.89 | tok/s 68847
step   3630 | loss 1.2311 | lr 8.27e-04 | grad 0.81 | tok/s 68903
step   3640 | loss 1.2327 | lr 8.27e-04 | grad 1.13 | tok/s 68929
step   3650 | loss 1.2264 | lr 8.27e-04 | grad 0.88 | tok/s 68535
step   3660 | loss 1.3954 | lr 8.27e-04 | grad 1.09 | tok/s 65987
step   3670 | loss 1.5969 | lr 8.27e-04 | grad 0.87 | tok/s 66059
step   3680 | loss 1.2793 | lr 8.27e-04 | grad 1.03 | tok/s 67887
step   3690 | loss 1.3059 | lr 8.27e-04 | grad 1.66 | tok/s 65434
step   3700 | loss 1.3995 | lr 8.27e-04 | grad 0.79 | tok/s 66278
step   3710 | loss 1.3443 | lr 8.27e-04 | grad 1.09 | tok/s 68043
step   3720 | loss 1.4573 | lr 8.27e-04 | grad 0.75 | tok/s 67068
step   3730 | loss 1.5415 | lr 8.27e-04 | grad 1.38 | tok/s 67557
step   3740 | loss 1.5805 | lr 8.27e-04 | grad 2.25 | tok/s 66849
step   3750 | loss 1.3731 | lr 8.27e-04 | grad 0.77 | tok/s 67390
step   3760 | loss 1.4034 | lr 8.27e-04 | grad 1.12 | tok/s 67434
step   3770 | loss 1.3088 | lr 8.27e-04 | grad 0.81 | tok/s 66138
step   3780 | loss 1.5920 | lr 8.27e-04 | grad 0.73 | tok/s 67028
step   3790 | loss 1.3461 | lr 8.27e-04 | grad 2.84 | tok/s 67140
step   3800 | loss 1.3963 | lr 8.27e-04 | grad 1.05 | tok/s 66607
step   3810 | loss 1.4586 | lr 8.27e-04 | grad 2.41 | tok/s 66176
step   3820 | loss 1.2395 | lr 8.27e-04 | grad 0.71 | tok/s 66053
step   3830 | loss 1.3076 | lr 8.27e-04 | grad 1.57 | tok/s 66659
step   3840 | loss 1.2824 | lr 8.27e-04 | grad 0.82 | tok/s 66859
step   3850 | loss 1.3138 | lr 8.27e-04 | grad 1.17 | tok/s 65577
step   3860 | loss 1.4561 | lr 8.27e-04 | grad 1.55 | tok/s 66239
step   3870 | loss 1.4284 | lr 8.27e-04 | grad 1.04 | tok/s 66465
step   3880 | loss 1.3166 | lr 8.27e-04 | grad 1.09 | tok/s 67060
step   3890 | loss 1.3706 | lr 8.27e-04 | grad 1.37 | tok/s 65439
step   3900 | loss 1.3783 | lr 8.27e-04 | grad 0.78 | tok/s 65170
step   3910 | loss 1.4143 | lr 8.27e-04 | grad 0.80 | tok/s 65287
step   3920 | loss 1.3775 | lr 8.27e-04 | grad 1.09 | tok/s 67039
step   3930 | loss 1.3840 | lr 8.27e-04 | grad 1.13 | tok/s 66064
step   3940 | loss 1.4719 | lr 8.27e-04 | grad 1.05 | tok/s 66493
step   3950 | loss 1.3117 | lr 8.27e-04 | grad 3.17 | tok/s 67083
step   3960 | loss 1.4256 | lr 8.27e-04 | grad 0.58 | tok/s 65556
step   3970 | loss 1.3106 | lr 8.27e-04 | grad 0.71 | tok/s 67539
step   3980 | loss 1.3798 | lr 8.27e-04 | grad 0.68 | tok/s 65992
step   3990 | loss 1.2859 | lr 8.27e-04 | grad 0.77 | tok/s 67308
step   4000 | loss 1.3557 | lr 8.27e-04 | grad 0.86 | tok/s 64357
  >>> saved checkpoint: checkpoint_step_004000_loss_1.3557.pt
step   4010 | loss 1.6143 | lr 8.27e-04 | grad 1.92 | tok/s 53627
step   4020 | loss 1.4594 | lr 8.27e-04 | grad 0.96 | tok/s 64108
step   4030 | loss 1.4457 | lr 8.27e-04 | grad 0.77 | tok/s 65447
step   4040 | loss 1.4048 | lr 8.27e-04 | grad 1.29 | tok/s 67680
step   4050 | loss 1.4278 | lr 8.27e-04 | grad 0.89 | tok/s 67443
step   4060 | loss 1.4796 | lr 8.27e-04 | grad 0.75 | tok/s 66498
step   4070 | loss 1.4417 | lr 8.27e-04 | grad 0.80 | tok/s 64465
step   4080 | loss 1.4877 | lr 8.27e-04 | grad 1.33 | tok/s 67049
step   4090 | loss 1.4574 | lr 8.27e-04 | grad 0.60 | tok/s 66521
step   4100 | loss 1.4729 | lr 8.27e-04 | grad 0.79 | tok/s 67751
step   4110 | loss 1.8119 | lr 8.27e-04 | grad 1.48 | tok/s 64827
step   4120 | loss 1.7580 | lr 8.27e-04 | grad 2.69 | tok/s 66606
step   4130 | loss 1.2977 | lr 8.27e-04 | grad 0.88 | tok/s 66524
step   4140 | loss 1.6245 | lr 8.27e-04 | grad 1.75 | tok/s 68379
step   4150 | loss 1.3361 | lr 8.27e-04 | grad 0.88 | tok/s 67186
step   4160 | loss 1.5832 | lr 8.27e-04 | grad 0.82 | tok/s 66825
step   4170 | loss 1.4742 | lr 8.27e-04 | grad 0.96 | tok/s 64798
step   4180 | loss 1.3607 | lr 8.27e-04 | grad 0.64 | tok/s 66013
step   4190 | loss 1.3082 | lr 8.27e-04 | grad 0.80 | tok/s 65795
step   4200 | loss 1.3167 | lr 8.27e-04 | grad 0.74 | tok/s 66709
step   4210 | loss 1.3928 | lr 8.27e-04 | grad 1.15 | tok/s 66016
step   4220 | loss 1.4873 | lr 8.27e-04 | grad 1.67 | tok/s 68862
step   4230 | loss 1.3910 | lr 8.27e-04 | grad 1.00 | tok/s 64464
step   4240 | loss 1.4762 | lr 8.27e-04 | grad 1.09 | tok/s 65543
step   4250 | loss 1.4708 | lr 8.27e-04 | grad 1.16 | tok/s 66474
step   4260 | loss 1.3819 | lr 8.27e-04 | grad 1.16 | tok/s 65258
step   4270 | loss 1.4541 | lr 8.27e-04 | grad 1.05 | tok/s 66301
step   4280 | loss 1.3455 | lr 8.27e-04 | grad 1.37 | tok/s 65514
step   4290 | loss 1.5193 | lr 8.27e-04 | grad 0.77 | tok/s 66468
step   4300 | loss 1.3813 | lr 8.27e-04 | grad 0.75 | tok/s 65719
step   4310 | loss 1.4063 | lr 8.27e-04 | grad 1.44 | tok/s 64315
step   4320 | loss 1.4304 | lr 8.27e-04 | grad 0.63 | tok/s 65445
step   4330 | loss 1.4157 | lr 8.27e-04 | grad 0.73 | tok/s 65538
step   4340 | loss 1.3313 | lr 8.27e-04 | grad 1.32 | tok/s 66643
step   4350 | loss 1.4874 | lr 8.27e-04 | grad 3.06 | tok/s 66359
step   4360 | loss 1.4633 | lr 8.27e-04 | grad 0.82 | tok/s 66064
step   4370 | loss 1.3297 | lr 8.27e-04 | grad 0.79 | tok/s 67285
step   4380 | loss 1.3871 | lr 8.27e-04 | grad 0.93 | tok/s 66782
step   4390 | loss 1.4578 | lr 8.27e-04 | grad 0.78 | tok/s 65553
step   4400 | loss 1.3386 | lr 8.27e-04 | grad 1.05 | tok/s 65268
step   4410 | loss 1.3247 | lr 8.27e-04 | grad 0.78 | tok/s 66608
step   4420 | loss 1.4069 | lr 8.27e-04 | grad 0.85 | tok/s 65334
step   4430 | loss 1.4287 | lr 8.27e-04 | grad 0.70 | tok/s 65757
step   4440 | loss 1.4642 | lr 8.27e-04 | grad 1.77 | tok/s 66926
step   4450 | loss 1.5063 | lr 8.27e-04 | grad 1.00 | tok/s 66410
step   4460 | loss 1.2978 | lr 8.27e-04 | grad 0.60 | tok/s 68799
step   4470 | loss 1.2432 | lr 8.27e-04 | grad 0.84 | tok/s 68713
step   4480 | loss 1.2184 | lr 8.27e-04 | grad 0.70 | tok/s 68603
step   4490 | loss 1.2592 | lr 8.27e-04 | grad 1.27 | tok/s 68257
step   4500 | loss 1.5061 | lr 8.27e-04 | grad 0.76 | tok/s 66385
step   4510 | loss 1.4590 | lr 8.27e-04 | grad 1.11 | tok/s 66791
step   4520 | loss 1.3120 | lr 8.27e-04 | grad 0.73 | tok/s 64897
step   4530 | loss 1.3918 | lr 8.27e-04 | grad 2.14 | tok/s 66906
step   4540 | loss 1.5345 | lr 8.27e-04 | grad 0.70 | tok/s 65419
step   4550 | loss 1.4561 | lr 8.27e-04 | grad 0.77 | tok/s 64993
step   4560 | loss 1.2317 | lr 8.27e-04 | grad 0.63 | tok/s 66079
step   4570 | loss 1.0946 | lr 8.27e-04 | grad 0.81 | tok/s 67669
step   4580 | loss 1.3317 | lr 8.27e-04 | grad 0.72 | tok/s 66007
step   4590 | loss 1.2949 | lr 8.27e-04 | grad 0.71 | tok/s 65586
step   4600 | loss 1.6730 | lr 8.27e-04 | grad 1.24 | tok/s 66805
step   4610 | loss 1.7296 | lr 8.27e-04 | grad 1.34 | tok/s 68584
step   4620 | loss 1.6158 | lr 8.27e-04 | grad 1.88 | tok/s 68541
step   4630 | loss 1.5131 | lr 8.27e-04 | grad 1.08 | tok/s 68589
step   4640 | loss 1.5709 | lr 8.27e-04 | grad 1.38 | tok/s 68540
step   4650 | loss 1.5264 | lr 8.27e-04 | grad 0.80 | tok/s 68553
step   4660 | loss 1.5432 | lr 8.27e-04 | grad 1.05 | tok/s 68534
step   4670 | loss 1.5494 | lr 8.27e-04 | grad 1.22 | tok/s 68533
step   4680 | loss 1.4656 | lr 8.27e-04 | grad 0.89 | tok/s 68540
step   4690 | loss 1.3619 | lr 8.27e-04 | grad 1.05 | tok/s 68445
step   4700 | loss 1.2820 | lr 8.27e-04 | grad 0.78 | tok/s 68549
step   4710 | loss 1.4411 | lr 8.27e-04 | grad 0.97 | tok/s 68517
step   4720 | loss 1.5159 | lr 8.27e-04 | grad 0.98 | tok/s 68540
step   4730 | loss 1.4947 | lr 8.27e-04 | grad 1.09 | tok/s 68541
step   4740 | loss 1.4615 | lr 8.27e-04 | grad 1.08 | tok/s 68593
step   4750 | loss 1.4538 | lr 8.27e-04 | grad 1.37 | tok/s 68533
step   4760 | loss 1.4310 | lr 8.27e-04 | grad 0.81 | tok/s 68587
step   4770 | loss 1.4943 | lr 8.27e-04 | grad 2.17 | tok/s 67142
step   4780 | loss 1.7641 | lr 8.27e-04 | grad 4.81 | tok/s 68783
step   4790 | loss 1.5228 | lr 8.27e-04 | grad 0.68 | tok/s 63637
step   4800 | loss 1.3641 | lr 8.27e-04 | grad 0.94 | tok/s 64629
step   4810 | loss 1.4628 | lr 8.27e-04 | grad 0.85 | tok/s 65389
step   4820 | loss 1.3987 | lr 8.27e-04 | grad 1.02 | tok/s 65671
step   4830 | loss 1.3507 | lr 8.27e-04 | grad 1.53 | tok/s 68057
step   4840 | loss 1.3065 | lr 8.27e-04 | grad 0.72 | tok/s 67012
step   4850 | loss 1.4855 | lr 8.27e-04 | grad 0.82 | tok/s 66240
step   4860 | loss 1.4023 | lr 8.27e-04 | grad 1.11 | tok/s 65252
step   4870 | loss 1.3091 | lr 8.27e-04 | grad 0.89 | tok/s 66419
step   4880 | loss 1.4207 | lr 8.27e-04 | grad 0.88 | tok/s 65915
step   4890 | loss 1.4111 | lr 8.27e-04 | grad 1.27 | tok/s 66100
step   4900 | loss 1.5715 | lr 8.27e-04 | grad 1.23 | tok/s 66739
step   4910 | loss 1.3394 | lr 8.27e-04 | grad 0.55 | tok/s 67583
step   4920 | loss 1.3156 | lr 8.27e-04 | grad 1.42 | tok/s 65669
step   4930 | loss 1.5698 | lr 8.27e-04 | grad 7.62 | tok/s 68082
step   4940 | loss 1.2915 | lr 8.27e-04 | grad 2.06 | tok/s 68787
step   4950 | loss 0.9668 | lr 8.27e-04 | grad 2.34 | tok/s 68651
step   4960 | loss 0.7853 | lr 8.27e-04 | grad 0.80 | tok/s 68739
step   4970 | loss 0.8736 | lr 8.27e-04 | grad 1.30 | tok/s 68716
step   4980 | loss 1.0225 | lr 8.27e-04 | grad 0.88 | tok/s 68099
step   4990 | loss 1.4534 | lr 8.27e-04 | grad 1.23 | tok/s 65104
step   5000 | loss 1.1939 | lr 8.27e-04 | grad 0.65 | tok/s 68644
  >>> saved checkpoint: checkpoint_step_005000_loss_1.1939.pt
step   5010 | loss 1.3777 | lr 8.27e-04 | grad 0.66 | tok/s 53935
step   5020 | loss 1.3146 | lr 8.27e-04 | grad 0.71 | tok/s 66393
step   5030 | loss 1.3086 | lr 8.27e-04 | grad 0.89 | tok/s 66797
step   5040 | loss 1.2024 | lr 8.27e-04 | grad 1.07 | tok/s 68680
step   5050 | loss 1.2928 | lr 8.27e-04 | grad 0.80 | tok/s 67555
step   5060 | loss 1.4216 | lr 8.27e-04 | grad 1.77 | tok/s 67928
step   5070 | loss 1.5489 | lr 8.27e-04 | grad 0.70 | tok/s 65201
step   5080 | loss 1.2792 | lr 8.27e-04 | grad 1.00 | tok/s 66721
step   5090 | loss 1.3508 | lr 8.27e-04 | grad 1.45 | tok/s 65434
step   5100 | loss 1.3200 | lr 8.27e-04 | grad 0.69 | tok/s 66733
step   5110 | loss 1.3597 | lr 8.27e-04 | grad 0.68 | tok/s 66504
step   5120 | loss 1.2702 | lr 8.27e-04 | grad 0.80 | tok/s 66355
step   5130 | loss 1.2388 | lr 8.27e-04 | grad 0.96 | tok/s 66508
step   5140 | loss 1.5214 | lr 8.27e-04 | grad 1.38 | tok/s 65786
step   5150 | loss 1.3234 | lr 8.27e-04 | grad 0.77 | tok/s 65750
step   5160 | loss 1.4417 | lr 8.27e-04 | grad 0.77 | tok/s 65882
step   5170 | loss 1.4062 | lr 8.27e-04 | grad 0.74 | tok/s 67400
step   5180 | loss 1.2827 | lr 8.27e-04 | grad 1.30 | tok/s 66931
step   5190 | loss 1.3206 | lr 8.27e-04 | grad 0.69 | tok/s 67986
step   5200 | loss 1.3259 | lr 8.27e-04 | grad 0.78 | tok/s 68431
step   5210 | loss 1.2915 | lr 8.27e-04 | grad 0.71 | tok/s 66498
step   5220 | loss 1.3472 | lr 8.27e-04 | grad 0.95 | tok/s 67065
step   5230 | loss 1.3775 | lr 8.27e-04 | grad 1.13 | tok/s 66891
step   5240 | loss 1.5396 | lr 8.27e-04 | grad 0.83 | tok/s 66147
step   5250 | loss 1.2713 | lr 8.27e-04 | grad 0.91 | tok/s 68383
step   5260 | loss 1.3852 | lr 8.27e-04 | grad 1.36 | tok/s 65907
step   5270 | loss 1.4010 | lr 8.27e-04 | grad 1.38 | tok/s 64556
step   5280 | loss 1.3819 | lr 8.27e-04 | grad 0.73 | tok/s 66130
step   5290 | loss 1.2571 | lr 8.27e-04 | grad 1.09 | tok/s 67644
step   5300 | loss 1.4226 | lr 8.27e-04 | grad 0.77 | tok/s 66026
step   5310 | loss 1.4342 | lr 8.27e-04 | grad 0.70 | tok/s 65185
step   5320 | loss 1.3806 | lr 8.27e-04 | grad 0.87 | tok/s 66702
step   5330 | loss 1.3799 | lr 8.27e-04 | grad 0.72 | tok/s 66207
step   5340 | loss 1.3076 | lr 8.27e-04 | grad 0.75 | tok/s 66128
step   5350 | loss 1.4357 | lr 8.27e-04 | grad 0.95 | tok/s 66307
step   5360 | loss 1.5364 | lr 8.27e-04 | grad 0.67 | tok/s 68340
step   5370 | loss 1.3816 | lr 8.27e-04 | grad 0.60 | tok/s 66654
step   5380 | loss 1.3737 | lr 8.27e-04 | grad 0.75 | tok/s 65258
step   5390 | loss 1.2789 | lr 8.27e-04 | grad 0.76 | tok/s 66842
step   5400 | loss 1.3726 | lr 8.27e-04 | grad 0.88 | tok/s 65253
step   5410 | loss 1.2634 | lr 8.27e-04 | grad 0.84 | tok/s 67419
step   5420 | loss 1.3562 | lr 8.27e-04 | grad 0.80 | tok/s 65764
step   5430 | loss 1.3359 | lr 8.27e-04 | grad 0.96 | tok/s 65556
step   5440 | loss 1.3245 | lr 8.27e-04 | grad 0.72 | tok/s 66361
step   5450 | loss 1.4099 | lr 8.27e-04 | grad 1.00 | tok/s 66483
step   5460 | loss 1.1585 | lr 8.27e-04 | grad 2.27 | tok/s 67272
step   5470 | loss 1.1247 | lr 8.27e-04 | grad 0.75 | tok/s 67928
step   5480 | loss 1.3810 | lr 8.27e-04 | grad 0.87 | tok/s 66956
step   5490 | loss 1.2963 | lr 8.27e-04 | grad 0.85 | tok/s 68277
step   5500 | loss 1.3933 | lr 8.27e-04 | grad 0.91 | tok/s 65286
step   5510 | loss 1.2825 | lr 8.27e-04 | grad 0.91 | tok/s 65248
step   5520 | loss 1.2285 | lr 8.27e-04 | grad 0.74 | tok/s 65801
step   5530 | loss 1.4557 | lr 8.27e-04 | grad 1.08 | tok/s 64854
step   5540 | loss 1.2437 | lr 8.27e-04 | grad 0.91 | tok/s 66189
step   5550 | loss 1.3639 | lr 8.27e-04 | grad 0.82 | tok/s 64875
step   5560 | loss 1.3593 | lr 8.27e-04 | grad 0.61 | tok/s 65733
step   5570 | loss 1.3536 | lr 8.27e-04 | grad 0.81 | tok/s 66855
step   5580 | loss 1.3377 | lr 8.27e-04 | grad 2.14 | tok/s 66992
step   5590 | loss 1.3651 | lr 8.27e-04 | grad 1.20 | tok/s 65890
step   5600 | loss 1.0076 | lr 8.27e-04 | grad 1.51 | tok/s 68047
step   5610 | loss 1.3021 | lr 8.27e-04 | grad 1.05 | tok/s 65943
step   5620 | loss 1.3412 | lr 8.27e-04 | grad 0.89 | tok/s 66024
step   5630 | loss 1.4496 | lr 8.27e-04 | grad 1.27 | tok/s 64676
step   5640 | loss 1.3873 | lr 8.27e-04 | grad 0.71 | tok/s 66144
step   5650 | loss 1.2847 | lr 8.27e-04 | grad 0.76 | tok/s 66357
step   5660 | loss 1.3695 | lr 8.27e-04 | grad 1.86 | tok/s 66874
step   5670 | loss 1.4300 | lr 8.27e-04 | grad 0.91 | tok/s 67650
step   5680 | loss 1.3652 | lr 8.27e-04 | grad 1.09 | tok/s 67137
step   5690 | loss 1.4867 | lr 8.27e-04 | grad 0.64 | tok/s 66814
step   5700 | loss 1.4038 | lr 8.27e-04 | grad 0.73 | tok/s 64143
step   5710 | loss 1.4362 | lr 8.27e-04 | grad 1.46 | tok/s 67160
step   5720 | loss 0.8585 | lr 8.27e-04 | grad 0.59 | tok/s 68448
step   5730 | loss 1.2687 | lr 8.27e-04 | grad 0.77 | tok/s 64968
step   5740 | loss 1.0965 | lr 8.27e-04 | grad 1.06 | tok/s 67451
step   5750 | loss 1.2751 | lr 8.27e-04 | grad 1.19 | tok/s 67384
step   5760 | loss 1.3316 | lr 8.27e-04 | grad 0.98 | tok/s 66245
step   5770 | loss 1.4370 | lr 8.27e-04 | grad 1.38 | tok/s 65643
step   5780 | loss 1.2411 | lr 8.27e-04 | grad 0.66 | tok/s 65119
step   5790 | loss 1.4661 | lr 8.27e-04 | grad 0.67 | tok/s 65459
step   5800 | loss 1.3465 | lr 8.27e-04 | grad 1.01 | tok/s 65794
step   5810 | loss 1.2850 | lr 8.27e-04 | grad 0.89 | tok/s 67146
step   5820 | loss 1.3507 | lr 8.27e-04 | grad 0.91 | tok/s 66507
step   5830 | loss 1.3289 | lr 8.27e-04 | grad 0.83 | tok/s 66030
step   5840 | loss 1.3185 | lr 8.27e-04 | grad 0.84 | tok/s 65790
step   5850 | loss 1.3850 | lr 8.27e-04 | grad 0.68 | tok/s 64922
step   5860 | loss 1.3991 | lr 8.27e-04 | grad 3.44 | tok/s 66718
step   5870 | loss 1.3674 | lr 8.27e-04 | grad 1.18 | tok/s 65595
step   5880 | loss 1.2417 | lr 8.27e-04 | grad 1.05 | tok/s 66441
step   5890 | loss 1.3554 | lr 8.27e-04 | grad 0.79 | tok/s 68461
step   5900 | loss 1.2857 | lr 8.27e-04 | grad 1.21 | tok/s 68681
step   5910 | loss 1.3083 | lr 8.27e-04 | grad 0.81 | tok/s 68137
step   5920 | loss 1.2878 | lr 8.27e-04 | grad 0.68 | tok/s 66354
step   5930 | loss 1.3146 | lr 8.27e-04 | grad 0.54 | tok/s 66615
step   5940 | loss 1.4244 | lr 8.27e-04 | grad 1.07 | tok/s 63356
step   5950 | loss 1.2150 | lr 8.27e-04 | grad 1.01 | tok/s 66766
step   5960 | loss 1.3504 | lr 8.27e-04 | grad 0.65 | tok/s 65396
step   5970 | loss 1.5444 | lr 8.27e-04 | grad 2.48 | tok/s 66449
step   5980 | loss 1.5351 | lr 8.27e-04 | grad 0.79 | tok/s 67739
step   5990 | loss 1.3575 | lr 8.27e-04 | grad 1.23 | tok/s 65903
step   6000 | loss 1.3281 | lr 8.27e-04 | grad 0.83 | tok/s 67645
  >>> saved checkpoint: checkpoint_step_006000_loss_1.3281.pt
step   6010 | loss 1.7187 | lr 8.27e-04 | grad 1.30 | tok/s 50985
step   6020 | loss 1.2759 | lr 8.27e-04 | grad 1.02 | tok/s 67715
step   6030 | loss 1.3944 | lr 8.27e-04 | grad 0.75 | tok/s 64555
step   6040 | loss 1.3733 | lr 8.27e-04 | grad 1.27 | tok/s 67139
step   6050 | loss 1.3935 | lr 8.27e-04 | grad 0.86 | tok/s 65808
step   6060 | loss 1.4937 | lr 8.27e-04 | grad 0.61 | tok/s 66919
step   6070 | loss 1.3709 | lr 8.27e-04 | grad 0.90 | tok/s 65895
step   6080 | loss 1.2955 | lr 8.27e-04 | grad 0.74 | tok/s 63969
step   6090 | loss 1.2138 | lr 8.27e-04 | grad 0.75 | tok/s 66625
step   6100 | loss 1.4471 | lr 8.27e-04 | grad 1.01 | tok/s 66908
step   6110 | loss 1.4251 | lr 8.27e-04 | grad 0.95 | tok/s 67439
step   6120 | loss 1.4278 | lr 8.27e-04 | grad 0.74 | tok/s 64616
step   6130 | loss 1.3751 | lr 8.27e-04 | grad 0.87 | tok/s 67360
step   6140 | loss 1.3346 | lr 8.27e-04 | grad 1.98 | tok/s 64927
step   6150 | loss 1.2911 | lr 8.27e-04 | grad 1.01 | tok/s 67686
step   6160 | loss 1.3397 | lr 8.27e-04 | grad 1.26 | tok/s 67546
step   6170 | loss 1.4451 | lr 8.27e-04 | grad 0.82 | tok/s 65522
step   6180 | loss 1.3906 | lr 8.27e-04 | grad 0.66 | tok/s 68138
step   6190 | loss 1.5100 | lr 8.27e-04 | grad 3.70 | tok/s 67429
step   6200 | loss 1.6539 | lr 8.27e-04 | grad 0.81 | tok/s 66524
step   6210 | loss 1.3744 | lr 8.27e-04 | grad 0.83 | tok/s 66304
step   6220 | loss 1.2493 | lr 8.27e-04 | grad 0.61 | tok/s 68617
step   6230 | loss 1.2040 | lr 8.27e-04 | grad 0.66 | tok/s 68673
step   6240 | loss 1.1586 | lr 8.27e-04 | grad 0.61 | tok/s 68818
step   6250 | loss 1.1527 | lr 8.27e-04 | grad 0.96 | tok/s 68646
step   6260 | loss 1.1706 | lr 8.27e-04 | grad 0.77 | tok/s 68615
step   6270 | loss 1.2977 | lr 8.27e-04 | grad 1.56 | tok/s 66071
step   6280 | loss 1.4998 | lr 8.27e-04 | grad 0.97 | tok/s 66743
step   6290 | loss 1.3897 | lr 8.27e-04 | grad 0.74 | tok/s 66188
step   6300 | loss 1.2585 | lr 8.27e-04 | grad 0.77 | tok/s 66212
step   6310 | loss 1.3443 | lr 8.27e-04 | grad 1.17 | tok/s 67139
step   6320 | loss 1.3240 | lr 8.27e-04 | grad 0.94 | tok/s 65734
step   6330 | loss 1.5392 | lr 8.27e-04 | grad 1.18 | tok/s 66115
step   6340 | loss 1.6319 | lr 8.27e-04 | grad 0.86 | tok/s 68547
step   6350 | loss 1.4691 | lr 8.27e-04 | grad 0.78 | tok/s 68554
step   6360 | loss 1.4065 | lr 8.27e-04 | grad 1.11 | tok/s 68567
step   6370 | loss 1.3542 | lr 8.27e-04 | grad 1.09 | tok/s 68520
step   6380 | loss 1.3701 | lr 8.27e-04 | grad 0.95 | tok/s 68566
step   6390 | loss 1.3612 | lr 8.27e-04 | grad 1.52 | tok/s 68505
step   6400 | loss 1.3708 | lr 8.27e-04 | grad 0.90 | tok/s 68562
step   6410 | loss 1.2938 | lr 8.27e-04 | grad 0.52 | tok/s 68540
step   6420 | loss 1.2616 | lr 8.27e-04 | grad 0.86 | tok/s 68606
step   6430 | loss 1.2386 | lr 8.27e-04 | grad 1.00 | tok/s 68575
step   6440 | loss 1.2586 | lr 8.27e-04 | grad 0.94 | tok/s 68647
step   6450 | loss 1.3088 | lr 8.27e-04 | grad 0.82 | tok/s 68696
step   6460 | loss 1.3389 | lr 8.27e-04 | grad 0.54 | tok/s 68673
step   6470 | loss 1.2635 | lr 8.27e-04 | grad 1.03 | tok/s 68685
step   6480 | loss 1.2441 | lr 8.27e-04 | grad 0.96 | tok/s 68634
step   6490 | loss 1.2251 | lr 8.27e-04 | grad 0.86 | tok/s 68700
step   6500 | loss 1.2274 | lr 8.27e-04 | grad 0.75 | tok/s 68643
step   6510 | loss 1.2392 | lr 8.27e-04 | grad 0.85 | tok/s 68585
step   6520 | loss 1.1516 | lr 8.27e-04 | grad 0.92 | tok/s 68593
step   6530 | loss 1.1105 | lr 8.27e-04 | grad 0.70 | tok/s 68694
step   6540 | loss 1.0887 | lr 8.27e-04 | grad 1.11 | tok/s 68637
step   6550 | loss 1.0978 | lr 8.27e-04 | grad 0.60 | tok/s 68824
step   6560 | loss 1.2422 | lr 8.27e-04 | grad 0.93 | tok/s 68630
step   6570 | loss 1.1337 | lr 8.27e-04 | grad 0.75 | tok/s 68629
step   6580 | loss 1.0726 | lr 8.27e-04 | grad 0.76 | tok/s 68643
step   6590 | loss 1.1109 | lr 8.27e-04 | grad 0.71 | tok/s 68710
step   6600 | loss 1.1822 | lr 8.27e-04 | grad 0.68 | tok/s 68705
step   6610 | loss 1.2124 | lr 8.27e-04 | grad 0.47 | tok/s 68588
step   6620 | loss 1.1452 | lr 8.27e-04 | grad 0.62 | tok/s 68620
step   6630 | loss 1.1154 | lr 8.27e-04 | grad 0.68 | tok/s 68653
step   6640 | loss 1.1232 | lr 8.27e-04 | grad 0.57 | tok/s 68787
step   6650 | loss 1.0984 | lr 8.27e-04 | grad 0.75 | tok/s 68709
step   6660 | loss 1.1095 | lr 8.27e-04 | grad 0.64 | tok/s 68596
step   6670 | loss 1.2680 | lr 8.27e-04 | grad 1.24 | tok/s 68696
step   6680 | loss 1.1755 | lr 8.27e-04 | grad 0.90 | tok/s 68737
step   6690 | loss 1.1546 | lr 8.27e-04 | grad 0.75 | tok/s 68722
step   6700 | loss 1.1213 | lr 8.27e-04 | grad 0.50 | tok/s 68632
step   6710 | loss 1.1391 | lr 8.27e-04 | grad 0.99 | tok/s 68666
step   6720 | loss 1.1567 | lr 8.27e-04 | grad 0.87 | tok/s 68653
step   6730 | loss 1.0548 | lr 8.27e-04 | grad 0.71 | tok/s 68769
step   6740 | loss 1.0404 | lr 8.27e-04 | grad 0.65 | tok/s 68653
step   6750 | loss 1.0241 | lr 8.27e-04 | grad 0.74 | tok/s 68590
step   6760 | loss 1.0027 | lr 8.27e-04 | grad 0.61 | tok/s 68687
step   6770 | loss 1.0423 | lr 8.27e-04 | grad 0.78 | tok/s 68786
step   6780 | loss 1.2973 | lr 8.27e-04 | grad 0.77 | tok/s 68640
step   6790 | loss 1.2619 | lr 8.27e-04 | grad 0.77 | tok/s 68677
step   6800 | loss 1.2443 | lr 8.27e-04 | grad 0.54 | tok/s 68724
step   6810 | loss 1.2250 | lr 8.27e-04 | grad 0.76 | tok/s 68744
step   6820 | loss 1.2721 | lr 8.27e-04 | grad 1.05 | tok/s 68607
step   6830 | loss 1.2714 | lr 8.27e-04 | grad 0.96 | tok/s 68680
step   6840 | loss 1.2685 | lr 8.27e-04 | grad 0.90 | tok/s 68680
step   6850 | loss 1.2231 | lr 8.27e-04 | grad 0.76 | tok/s 68739
step   6860 | loss 1.2371 | lr 8.27e-04 | grad 0.71 | tok/s 68626
step   6870 | loss 1.1181 | lr 8.27e-04 | grad 0.77 | tok/s 68575
step   6880 | loss 1.1009 | lr 8.27e-04 | grad 0.66 | tok/s 68571
step   6890 | loss 1.0453 | lr 8.27e-04 | grad 0.88 | tok/s 68596
step   6900 | loss 1.0323 | lr 8.27e-04 | grad 0.94 | tok/s 68623
step   6910 | loss 1.1236 | lr 8.27e-04 | grad 0.54 | tok/s 68603
step   6920 | loss 1.1134 | lr 8.27e-04 | grad 0.86 | tok/s 68698
step   6930 | loss 1.0719 | lr 8.27e-04 | grad 0.57 | tok/s 68721
step   6940 | loss 1.0483 | lr 8.27e-04 | grad 0.86 | tok/s 68598
step   6950 | loss 1.0526 | lr 8.27e-04 | grad 0.78 | tok/s 68566
step   6960 | loss 1.0328 | lr 8.27e-04 | grad 0.89 | tok/s 68565
step   6970 | loss 1.0007 | lr 8.27e-04 | grad 0.66 | tok/s 68549
step   6980 | loss 0.9841 | lr 8.27e-04 | grad 0.57 | tok/s 68665
step   6990 | loss 1.1053 | lr 8.27e-04 | grad 0.75 | tok/s 68670
step   7000 | loss 1.1782 | lr 8.27e-04 | grad 0.75 | tok/s 68764
  >>> saved checkpoint: checkpoint_step_007000_loss_1.1782.pt
step   7010 | loss 1.4348 | lr 8.27e-04 | grad 9.12 | tok/s 53083
step   7020 | loss 1.8905 | lr 8.27e-04 | grad 4.72 | tok/s 68666
step   7030 | loss 1.6502 | lr 8.27e-04 | grad 3.84 | tok/s 68696
step   7040 | loss 1.5997 | lr 8.27e-04 | grad 3.92 | tok/s 68780
step   7050 | loss 1.5202 | lr 8.27e-04 | grad 4.38 | tok/s 68624
step   7060 | loss 1.4910 | lr 8.27e-04 | grad 3.36 | tok/s 68581
step   7070 | loss 1.4433 | lr 8.27e-04 | grad 3.02 | tok/s 68718
step   7080 | loss 1.4416 | lr 8.27e-04 | grad 4.22 | tok/s 68797
step   7090 | loss 1.3538 | lr 8.27e-04 | grad 3.48 | tok/s 68653
step   7100 | loss 1.3822 | lr 8.27e-04 | grad 3.55 | tok/s 68647
step   7110 | loss 1.3065 | lr 8.27e-04 | grad 2.64 | tok/s 68859
step   7120 | loss 1.3034 | lr 8.27e-04 | grad 3.73 | tok/s 68764
step   7130 | loss 1.3069 | lr 8.27e-04 | grad 4.03 | tok/s 68758
step   7140 | loss 1.2301 | lr 8.27e-04 | grad 3.55 | tok/s 68821
step   7150 | loss 1.2189 | lr 8.27e-04 | grad 4.16 | tok/s 68685
step   7160 | loss 1.2757 | lr 8.27e-04 | grad 2.95 | tok/s 68711
step   7170 | loss 1.2286 | lr 8.27e-04 | grad 1.39 | tok/s 68788
step   7180 | loss 1.1410 | lr 8.27e-04 | grad 2.28 | tok/s 68667
step   7190 | loss 1.1318 | lr 8.27e-04 | grad 1.74 | tok/s 68643
step   7200 | loss 1.0792 | lr 8.27e-04 | grad 1.66 | tok/s 68773
step   7210 | loss 1.0712 | lr 8.27e-04 | grad 1.55 | tok/s 68703
step   7220 | loss 1.0672 | lr 8.27e-04 | grad 1.14 | tok/s 68583
step   7230 | loss 1.0385 | lr 8.27e-04 | grad 1.34 | tok/s 68634
step   7240 | loss 1.0462 | lr 8.27e-04 | grad 1.58 | tok/s 68641
step   7250 | loss 1.0381 | lr 8.27e-04 | grad 1.22 | tok/s 68702
step   7260 | loss 1.0197 | lr 8.27e-04 | grad 1.45 | tok/s 68671
step   7270 | loss 0.9838 | lr 8.27e-04 | grad 1.60 | tok/s 68661
step   7280 | loss 1.0186 | lr 8.27e-04 | grad 1.52 | tok/s 68616
step   7290 | loss 1.0301 | lr 8.27e-04 | grad 1.58 | tok/s 68664
step   7300 | loss 1.0072 | lr 8.27e-04 | grad 1.66 | tok/s 68772
step   7310 | loss 0.9929 | lr 8.27e-04 | grad 1.44 | tok/s 68673
step   7320 | loss 1.0032 | lr 8.27e-04 | grad 1.50 | tok/s 68594
step   7330 | loss 0.9831 | lr 8.27e-04 | grad 1.16 | tok/s 68630
step   7340 | loss 1.0155 | lr 8.27e-04 | grad 1.03 | tok/s 68604
step   7350 | loss 0.9848 | lr 8.27e-04 | grad 1.30 | tok/s 68681
step   7360 | loss 0.9942 | lr 8.27e-04 | grad 1.36 | tok/s 68719
step   7370 | loss 0.9932 | lr 8.27e-04 | grad 1.14 | tok/s 68660
step   7380 | loss 0.9683 | lr 8.27e-04 | grad 1.19 | tok/s 68702
step   7390 | loss 0.9299 | lr 8.27e-04 | grad 1.05 | tok/s 68742
step   7400 | loss 0.9293 | lr 8.27e-04 | grad 1.23 | tok/s 68772
step   7410 | loss 0.9270 | lr 8.27e-04 | grad 1.42 | tok/s 68675
step   7420 | loss 0.9170 | lr 8.27e-04 | grad 1.34 | tok/s 68777
step   7430 | loss 1.3545 | lr 8.27e-04 | grad 0.99 | tok/s 68706
step   7440 | loss 1.2710 | lr 8.27e-04 | grad 0.90 | tok/s 68556
step   7450 | loss 1.1866 | lr 8.27e-04 | grad 0.51 | tok/s 68582
step   7460 | loss 1.2013 | lr 8.27e-04 | grad 0.69 | tok/s 68627
step   7470 | loss 1.1928 | lr 8.27e-04 | grad 0.64 | tok/s 68616
step   7480 | loss 1.1869 | lr 8.27e-04 | grad 0.76 | tok/s 68587

Training complete! Final step: 7488
