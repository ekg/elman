Using device: cuda
Output directory: benchmark_results/cmaes_4d/mamba2_480M_converge0.01_20260202_091709/eval_28/levelmamba2_100m_20260202_104815
Model: Level mamba2, 691,419,072 parameters
Using schedule-free AdamW (lr=0.0003391267141202523)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 6.8476 | lr 3.39e-04 | grad 25.62 | tok/s 2611
step     20 | loss 2.9212 | lr 3.39e-04 | grad 6.06 | tok/s 17345
step     30 | loss 2.4087 | lr 3.39e-04 | grad 3.38 | tok/s 16214
step     40 | loss 2.6453 | lr 3.39e-04 | grad 11.94 | tok/s 16411
step     50 | loss 2.3310 | lr 3.39e-04 | grad 3.64 | tok/s 17182
step     60 | loss 2.0115 | lr 3.39e-04 | grad 13.00 | tok/s 17220
step     70 | loss 4.5011 | lr 3.39e-04 | grad 7.59 | tok/s 17113
step     80 | loss 4.2540 | lr 3.39e-04 | grad 13.50 | tok/s 17629
step     90 | loss 3.3228 | lr 3.39e-04 | grad 6.06 | tok/s 17457
step    100 | loss 2.8279 | lr 3.39e-04 | grad 3.97 | tok/s 17459
step    110 | loss 2.8054 | lr 3.39e-04 | grad 5.06 | tok/s 17443
step    120 | loss 2.5662 | lr 3.39e-04 | grad 3.27 | tok/s 17405
step    130 | loss 2.1951 | lr 3.39e-04 | grad 5.06 | tok/s 17362
step    140 | loss 2.3192 | lr 3.39e-04 | grad 4.75 | tok/s 17380
step    150 | loss 2.0714 | lr 3.39e-04 | grad 2.81 | tok/s 17351
step    160 | loss 2.1820 | lr 3.39e-04 | grad 9.50 | tok/s 17329
step    170 | loss 2.0425 | lr 3.39e-04 | grad 5.53 | tok/s 17299
step    180 | loss 1.9992 | lr 3.39e-04 | grad 3.45 | tok/s 17294
step    190 | loss 1.8865 | lr 3.39e-04 | grad 2.53 | tok/s 17299
step    200 | loss 1.8889 | lr 3.39e-04 | grad 6.94 | tok/s 17292
step    210 | loss 2.1392 | lr 3.39e-04 | grad 3.58 | tok/s 17073
step    220 | loss 2.5414 | lr 3.39e-04 | grad 6.38 | tok/s 17131
step    230 | loss 2.2451 | lr 3.39e-04 | grad 3.61 | tok/s 15939
step    240 | loss 2.2400 | lr 3.39e-04 | grad 2.33 | tok/s 16431
step    250 | loss 1.7257 | lr 3.39e-04 | grad 2.98 | tok/s 17301
step    260 | loss 2.0690 | lr 3.39e-04 | grad 3.16 | tok/s 16574
step    270 | loss 2.2652 | lr 3.39e-04 | grad 3.06 | tok/s 16957
step    280 | loss 1.8987 | lr 3.39e-04 | grad 3.38 | tok/s 16960
step    290 | loss 0.6862 | lr 3.39e-04 | grad 3.44 | tok/s 17418
step    300 | loss 2.2765 | lr 3.39e-04 | grad 4.97 | tok/s 17120
step    310 | loss 1.9906 | lr 3.39e-04 | grad 4.38 | tok/s 17242
step    320 | loss 1.9831 | lr 3.39e-04 | grad 2.73 | tok/s 15798
step    330 | loss 2.2387 | lr 3.39e-04 | grad 3.61 | tok/s 16481
step    340 | loss 1.9023 | lr 3.39e-04 | grad 4.06 | tok/s 16611
step    350 | loss 1.2746 | lr 3.39e-04 | grad 8.06 | tok/s 17322
step    360 | loss 1.8467 | lr 3.39e-04 | grad 2.41 | tok/s 15804
step    370 | loss 1.7204 | lr 3.39e-04 | grad 2.84 | tok/s 16325
step    380 | loss 1.5462 | lr 3.39e-04 | grad 3.44 | tok/s 17296
step    390 | loss 1.4717 | lr 3.39e-04 | grad 2.53 | tok/s 17153
step    400 | loss 1.3510 | lr 3.39e-04 | grad 1.70 | tok/s 17303
step    410 | loss 1.6125 | lr 3.39e-04 | grad 2.38 | tok/s 15774
step    420 | loss 2.1130 | lr 3.39e-04 | grad 2.17 | tok/s 16889
step    430 | loss 2.0324 | lr 3.39e-04 | grad 2.59 | tok/s 16341
step    440 | loss 1.9410 | lr 3.39e-04 | grad 2.45 | tok/s 16589
step    450 | loss 1.8355 | lr 3.39e-04 | grad 3.17 | tok/s 16258
step    460 | loss 1.7027 | lr 3.39e-04 | grad 2.72 | tok/s 16822
step    470 | loss 1.9988 | lr 3.39e-04 | grad 4.59 | tok/s 16833
step    480 | loss 1.8517 | lr 3.39e-04 | grad 2.17 | tok/s 16328
step    490 | loss 1.5793 | lr 3.39e-04 | grad 3.69 | tok/s 16643
step    500 | loss 1.6763 | lr 3.39e-04 | grad 2.16 | tok/s 17130
step    510 | loss 1.6901 | lr 3.39e-04 | grad 1.91 | tok/s 17152
step    520 | loss 1.8425 | lr 3.39e-04 | grad 3.52 | tok/s 16775
step    530 | loss 1.7152 | lr 3.39e-04 | grad 2.86 | tok/s 16408
step    540 | loss 1.5055 | lr 3.39e-04 | grad 2.53 | tok/s 16693
step    550 | loss 1.6604 | lr 3.39e-04 | grad 2.58 | tok/s 15304
step    560 | loss 1.6228 | lr 3.39e-04 | grad 6.53 | tok/s 16562
step    570 | loss 1.4912 | lr 3.39e-04 | grad 2.00 | tok/s 16112
step    580 | loss 1.6661 | lr 3.39e-04 | grad 3.69 | tok/s 16415
step    590 | loss 1.8409 | lr 3.39e-04 | grad 2.66 | tok/s 15949
step    600 | loss 1.6061 | lr 3.39e-04 | grad 2.14 | tok/s 16911
step    610 | loss 1.5205 | lr 3.39e-04 | grad 2.39 | tok/s 16171
step    620 | loss 1.6209 | lr 3.39e-04 | grad 1.80 | tok/s 16143
step    630 | loss 1.7404 | lr 3.39e-04 | grad 4.50 | tok/s 16523
step    640 | loss 1.6185 | lr 3.39e-04 | grad 3.00 | tok/s 16660
step    650 | loss 1.6995 | lr 3.39e-04 | grad 2.28 | tok/s 16550
step    660 | loss 1.7437 | lr 3.39e-04 | grad 5.72 | tok/s 16695
step    670 | loss 1.7309 | lr 3.39e-04 | grad 2.25 | tok/s 16573
step    680 | loss 1.7459 | lr 3.39e-04 | grad 3.05 | tok/s 16767
step    690 | loss 1.4270 | lr 3.39e-04 | grad 1.83 | tok/s 17312
step    700 | loss 1.5622 | lr 3.39e-04 | grad 2.39 | tok/s 16402
step    710 | loss 1.3927 | lr 3.39e-04 | grad 1.85 | tok/s 15745
step    720 | loss 1.3363 | lr 3.39e-04 | grad 1.69 | tok/s 17325
step    730 | loss 1.5005 | lr 3.39e-04 | grad 1.78 | tok/s 17027
step    740 | loss 1.2479 | lr 3.39e-04 | grad 2.23 | tok/s 17321
step    750 | loss 1.1407 | lr 3.39e-04 | grad 1.68 | tok/s 17322
step    760 | loss 1.0724 | lr 3.39e-04 | grad 2.12 | tok/s 17328
step    770 | loss 1.0246 | lr 3.39e-04 | grad 1.64 | tok/s 17322
step    780 | loss 0.9931 | lr 3.39e-04 | grad 9.19 | tok/s 17080
step    790 | loss 1.6867 | lr 3.39e-04 | grad 3.12 | tok/s 16403
step    800 | loss 1.7678 | lr 3.39e-04 | grad 2.19 | tok/s 16643
step    810 | loss 1.6348 | lr 3.39e-04 | grad 2.38 | tok/s 16161
step    820 | loss 1.5681 | lr 3.39e-04 | grad 2.20 | tok/s 17007
step    830 | loss 1.3588 | lr 3.39e-04 | grad 1.89 | tok/s 17298
step    840 | loss 1.5848 | lr 3.39e-04 | grad 1.98 | tok/s 17222
step    850 | loss 1.3722 | lr 3.39e-04 | grad 5.38 | tok/s 17134
step    860 | loss 1.5109 | lr 3.39e-04 | grad 2.25 | tok/s 16318
step    870 | loss 1.6083 | lr 3.39e-04 | grad 3.62 | tok/s 16680
step    880 | loss 1.6167 | lr 3.39e-04 | grad 2.03 | tok/s 16671
step    890 | loss 1.5148 | lr 3.39e-04 | grad 1.78 | tok/s 16829
step    900 | loss 1.3850 | lr 3.39e-04 | grad 6.25 | tok/s 16318
step    910 | loss 1.5093 | lr 3.39e-04 | grad 1.65 | tok/s 17328
step    920 | loss 1.5597 | lr 3.39e-04 | grad 1.78 | tok/s 16111
step    930 | loss 1.4123 | lr 3.39e-04 | grad 2.16 | tok/s 17084
step    940 | loss 1.4612 | lr 3.39e-04 | grad 2.88 | tok/s 17296
step    950 | loss 1.3098 | lr 3.39e-04 | grad 4.41 | tok/s 17336
step    960 | loss 1.5697 | lr 3.39e-04 | grad 2.31 | tok/s 16284
step    970 | loss 1.6672 | lr 3.39e-04 | grad 1.95 | tok/s 17010
step    980 | loss 1.4090 | lr 3.39e-04 | grad 1.84 | tok/s 16691
step    990 | loss 1.6419 | lr 3.39e-04 | grad 2.34 | tok/s 16338
step   1000 | loss 1.7388 | lr 3.39e-04 | grad 3.05 | tok/s 16918
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7388.pt
step   1010 | loss 1.6088 | lr 3.39e-04 | grad 1.91 | tok/s 4758
step   1020 | loss 1.4243 | lr 3.39e-04 | grad 2.06 | tok/s 16765
step   1030 | loss 1.4503 | lr 3.39e-04 | grad 2.06 | tok/s 17294
step   1040 | loss 1.5430 | lr 3.39e-04 | grad 2.94 | tok/s 16008
step   1050 | loss 1.6707 | lr 3.39e-04 | grad 2.98 | tok/s 17248
step   1060 | loss 1.6093 | lr 3.39e-04 | grad 2.30 | tok/s 17142
step   1070 | loss 1.3500 | lr 3.39e-04 | grad 1.71 | tok/s 15610
step   1080 | loss 1.0766 | lr 3.39e-04 | grad 1.34 | tok/s 17255
step   1090 | loss 1.3755 | lr 3.39e-04 | grad 3.61 | tok/s 16720
step   1100 | loss 1.4249 | lr 3.39e-04 | grad 1.94 | tok/s 17415
step   1110 | loss 1.3185 | lr 3.39e-04 | grad 2.61 | tok/s 17435
step   1120 | loss 1.2642 | lr 3.39e-04 | grad 1.61 | tok/s 17434
step   1130 | loss 1.2493 | lr 3.39e-04 | grad 2.30 | tok/s 17427
step   1140 | loss 1.2618 | lr 3.39e-04 | grad 2.05 | tok/s 17412
step   1150 | loss 1.1874 | lr 3.39e-04 | grad 1.96 | tok/s 17440
step   1160 | loss 1.2117 | lr 3.39e-04 | grad 2.03 | tok/s 17436
step   1170 | loss 1.3282 | lr 3.39e-04 | grad 1.51 | tok/s 17428
step   1180 | loss 1.1941 | lr 3.39e-04 | grad 2.39 | tok/s 17429
step   1190 | loss 1.1849 | lr 3.39e-04 | grad 2.08 | tok/s 17412
step   1200 | loss 1.2375 | lr 3.39e-04 | grad 2.00 | tok/s 17423
step   1210 | loss 1.2506 | lr 3.39e-04 | grad 2.42 | tok/s 17433
step   1220 | loss 1.2191 | lr 3.39e-04 | grad 1.84 | tok/s 17438
step   1230 | loss 1.1843 | lr 3.39e-04 | grad 1.20 | tok/s 17411
step   1240 | loss 1.7279 | lr 3.39e-04 | grad 2.53 | tok/s 16514
step   1250 | loss 1.3120 | lr 3.39e-04 | grad 1.66 | tok/s 16403
step   1260 | loss 1.5900 | lr 3.39e-04 | grad 5.12 | tok/s 16313
step   1270 | loss 1.5828 | lr 3.39e-04 | grad 2.02 | tok/s 16769
step   1280 | loss 1.4282 | lr 3.39e-04 | grad 1.70 | tok/s 16662
step   1290 | loss 1.4785 | lr 3.39e-04 | grad 7.53 | tok/s 16811
step   1300 | loss 1.4353 | lr 3.39e-04 | grad 2.64 | tok/s 17036
step   1310 | loss 1.5301 | lr 3.39e-04 | grad 1.91 | tok/s 17124
step   1320 | loss 1.5350 | lr 3.39e-04 | grad 2.12 | tok/s 17100
step   1330 | loss 1.4344 | lr 3.39e-04 | grad 7.81 | tok/s 16334
step   1340 | loss 1.6356 | lr 3.39e-04 | grad 2.55 | tok/s 15788
step   1350 | loss 1.4624 | lr 3.39e-04 | grad 2.38 | tok/s 16769
step   1360 | loss 1.3904 | lr 3.39e-04 | grad 1.84 | tok/s 16565
step   1370 | loss 1.5374 | lr 3.39e-04 | grad 1.84 | tok/s 15948
step   1380 | loss 1.4878 | lr 3.39e-04 | grad 1.78 | tok/s 16901
step   1390 | loss 1.3386 | lr 3.39e-04 | grad 1.42 | tok/s 16338
step   1400 | loss 1.3833 | lr 3.39e-04 | grad 13.62 | tok/s 16391
step   1410 | loss 1.6271 | lr 3.39e-04 | grad 5.16 | tok/s 16422
step   1420 | loss 1.3178 | lr 3.39e-04 | grad 1.77 | tok/s 16701
step   1430 | loss 1.1106 | lr 3.39e-04 | grad 1.96 | tok/s 17222
step   1440 | loss 1.1270 | lr 3.39e-04 | grad 4.34 | tok/s 17337
step   1450 | loss 1.5482 | lr 3.39e-04 | grad 28.88 | tok/s 16304
step   1460 | loss 1.4982 | lr 3.39e-04 | grad 1.62 | tok/s 16959
step   1470 | loss 1.7400 | lr 3.39e-04 | grad 3.97 | tok/s 17057
step   1480 | loss 1.5083 | lr 3.39e-04 | grad 1.56 | tok/s 17267
step   1490 | loss 1.3629 | lr 3.39e-04 | grad 1.68 | tok/s 17338
step   1500 | loss 1.4382 | lr 3.39e-04 | grad 2.00 | tok/s 17122
step   1510 | loss 1.3791 | lr 3.39e-04 | grad 3.78 | tok/s 16809
step   1520 | loss 1.4042 | lr 3.39e-04 | grad 2.12 | tok/s 17173
step   1530 | loss 1.5274 | lr 3.39e-04 | grad 2.27 | tok/s 16186
step   1540 | loss 1.2704 | lr 3.39e-04 | grad 2.17 | tok/s 17193
step   1550 | loss 1.5238 | lr 3.39e-04 | grad 2.30 | tok/s 16375
step   1560 | loss 1.2776 | lr 3.39e-04 | grad 2.06 | tok/s 17366
step   1570 | loss 1.6062 | lr 3.39e-04 | grad 4.12 | tok/s 16942
step   1580 | loss 1.5230 | lr 3.39e-04 | grad 2.06 | tok/s 16310
step   1590 | loss 0.9832 | lr 3.39e-04 | grad 1.52 | tok/s 17468
step   1600 | loss 0.9920 | lr 3.39e-04 | grad 2.12 | tok/s 16946
step   1610 | loss 1.3642 | lr 3.39e-04 | grad 2.34 | tok/s 15812
step   1620 | loss 1.3396 | lr 3.39e-04 | grad 2.30 | tok/s 16913
step   1630 | loss 1.2839 | lr 3.39e-04 | grad 1.80 | tok/s 16473
step   1640 | loss 1.4460 | lr 3.39e-04 | grad 3.70 | tok/s 15850
step   1650 | loss 1.4061 | lr 3.39e-04 | grad 1.59 | tok/s 16883
step   1660 | loss 1.3088 | lr 3.39e-04 | grad 5.59 | tok/s 16857
step   1670 | loss 1.6275 | lr 3.39e-04 | grad 1.77 | tok/s 16174
step   1680 | loss 1.4104 | lr 3.39e-04 | grad 3.78 | tok/s 16453
step   1690 | loss 1.4028 | lr 3.39e-04 | grad 2.16 | tok/s 16791
step   1700 | loss 1.3589 | lr 3.39e-04 | grad 1.79 | tok/s 16524
step   1710 | loss 1.4512 | lr 3.39e-04 | grad 2.53 | tok/s 17195
step   1720 | loss 1.1592 | lr 3.39e-04 | grad 2.59 | tok/s 17314
step   1730 | loss 1.2700 | lr 3.39e-04 | grad 2.00 | tok/s 16914
step   1740 | loss 1.5085 | lr 3.39e-04 | grad 2.27 | tok/s 16665
step   1750 | loss 1.4680 | lr 3.39e-04 | grad 1.84 | tok/s 16751
step   1760 | loss 1.3872 | lr 3.39e-04 | grad 2.02 | tok/s 16448
step   1770 | loss 1.4560 | lr 3.39e-04 | grad 1.98 | tok/s 17024
step   1780 | loss 1.3379 | lr 3.39e-04 | grad 1.52 | tok/s 16647
step   1790 | loss 1.5517 | lr 3.39e-04 | grad 1.86 | tok/s 16792
step   1800 | loss 1.3623 | lr 3.39e-04 | grad 1.98 | tok/s 16168
step   1810 | loss 1.3944 | lr 3.39e-04 | grad 4.47 | tok/s 16357
step   1820 | loss 1.3346 | lr 3.39e-04 | grad 2.02 | tok/s 17065
step   1830 | loss 1.4638 | lr 3.39e-04 | grad 2.16 | tok/s 16336
step   1840 | loss 1.2713 | lr 3.39e-04 | grad 1.54 | tok/s 17087
step   1850 | loss 1.2887 | lr 3.39e-04 | grad 2.17 | tok/s 16511
step   1860 | loss 1.3561 | lr 3.39e-04 | grad 2.80 | tok/s 16583
step   1870 | loss 1.1813 | lr 3.39e-04 | grad 1.72 | tok/s 16294
step   1880 | loss 1.4425 | lr 3.39e-04 | grad 1.80 | tok/s 15505
step   1890 | loss 1.3530 | lr 3.39e-04 | grad 2.42 | tok/s 16726
step   1900 | loss 1.3923 | lr 3.39e-04 | grad 2.08 | tok/s 15826
step   1910 | loss 1.3587 | lr 3.39e-04 | grad 1.99 | tok/s 17336
step   1920 | loss 1.4070 | lr 3.39e-04 | grad 1.95 | tok/s 16269
step   1930 | loss 1.3979 | lr 3.39e-04 | grad 2.11 | tok/s 16913
step   1940 | loss 1.7775 | lr 3.39e-04 | grad 3.61 | tok/s 17149
step   1950 | loss 1.4532 | lr 3.39e-04 | grad 3.64 | tok/s 17325
step   1960 | loss 1.4491 | lr 3.39e-04 | grad 2.00 | tok/s 16964
step   1970 | loss 1.4627 | lr 3.39e-04 | grad 1.69 | tok/s 16173
step   1980 | loss 1.4939 | lr 3.39e-04 | grad 8.19 | tok/s 16517
step   1990 | loss 1.4312 | lr 3.39e-04 | grad 1.70 | tok/s 16697
step   2000 | loss 1.0960 | lr 3.39e-04 | grad 1.62 | tok/s 17388
  >>> saved checkpoint: checkpoint_step_002000_loss_1.0960.pt
step   2010 | loss 1.1965 | lr 3.39e-04 | grad 2.38 | tok/s 5048
step   2020 | loss 0.9185 | lr 3.39e-04 | grad 3.70 | tok/s 17858
step   2030 | loss 1.3261 | lr 3.39e-04 | grad 2.25 | tok/s 17525
step   2040 | loss 1.2235 | lr 3.39e-04 | grad 1.80 | tok/s 16942
step   2050 | loss 1.5668 | lr 3.39e-04 | grad 1.88 | tok/s 16489
step   2060 | loss 1.7394 | lr 3.39e-04 | grad 5.28 | tok/s 16641
step   2070 | loss 1.9850 | lr 3.39e-04 | grad 3.77 | tok/s 17468
step   2080 | loss 1.5291 | lr 3.39e-04 | grad 2.19 | tok/s 17177
step   2090 | loss 1.3241 | lr 3.39e-04 | grad 2.00 | tok/s 17137
step   2100 | loss 1.4178 | lr 3.39e-04 | grad 2.33 | tok/s 16346
step   2110 | loss 0.8237 | lr 3.39e-04 | grad 2.36 | tok/s 17765
step   2120 | loss 1.2025 | lr 3.39e-04 | grad 61.25 | tok/s 16879
step   2130 | loss 1.3824 | lr 3.39e-04 | grad 1.40 | tok/s 16928
step   2140 | loss 1.2452 | lr 3.39e-04 | grad 2.17 | tok/s 17404
step   2150 | loss 1.1447 | lr 3.39e-04 | grad 2.31 | tok/s 17431
step   2160 | loss 1.2071 | lr 3.39e-04 | grad 1.62 | tok/s 17428
step   2170 | loss 1.1510 | lr 3.39e-04 | grad 1.37 | tok/s 17428
step   2180 | loss 1.1746 | lr 3.39e-04 | grad 1.95 | tok/s 17418
step   2190 | loss 1.1428 | lr 3.39e-04 | grad 1.52 | tok/s 17433
step   2200 | loss 1.1125 | lr 3.39e-04 | grad 1.96 | tok/s 17419
step   2210 | loss 1.0983 | lr 3.39e-04 | grad 1.92 | tok/s 17405
step   2220 | loss 1.3550 | lr 3.39e-04 | grad 2.23 | tok/s 17063
step   2230 | loss 1.2955 | lr 3.39e-04 | grad 1.75 | tok/s 16766
step   2240 | loss 1.4484 | lr 3.39e-04 | grad 5.06 | tok/s 17383
step   2250 | loss 1.4805 | lr 3.39e-04 | grad 2.08 | tok/s 16831
step   2260 | loss 1.8774 | lr 3.39e-04 | grad 3.86 | tok/s 17246
step   2270 | loss 1.3795 | lr 3.39e-04 | grad 2.66 | tok/s 17384
step   2280 | loss 1.4067 | lr 3.39e-04 | grad 4.50 | tok/s 16802
step   2290 | loss 1.4794 | lr 3.39e-04 | grad 2.62 | tok/s 17046
step   2300 | loss 1.3518 | lr 3.39e-04 | grad 2.38 | tok/s 16428
step   2310 | loss 1.7774 | lr 3.39e-04 | grad 3.08 | tok/s 16377
step   2320 | loss 1.5115 | lr 3.39e-04 | grad 2.62 | tok/s 16475
step   2330 | loss 1.3960 | lr 3.39e-04 | grad 2.44 | tok/s 16234
step   2340 | loss 1.3255 | lr 3.39e-04 | grad 2.47 | tok/s 16973
step   2350 | loss 1.2266 | lr 3.39e-04 | grad 1.30 | tok/s 17357
step   2360 | loss 1.4860 | lr 3.39e-04 | grad 3.56 | tok/s 16993
step   2370 | loss 1.4040 | lr 3.39e-04 | grad 2.30 | tok/s 17419
step   2380 | loss 1.0760 | lr 3.39e-04 | grad 1.61 | tok/s 17385
step   2390 | loss 1.0295 | lr 3.39e-04 | grad 1.71 | tok/s 17329
step   2400 | loss 1.1439 | lr 3.39e-04 | grad 1.56 | tok/s 16703
step   2410 | loss 1.4026 | lr 3.39e-04 | grad 1.88 | tok/s 16079
step   2420 | loss 1.2811 | lr 3.39e-04 | grad 1.73 | tok/s 16998
step   2430 | loss 1.2716 | lr 3.39e-04 | grad 1.92 | tok/s 16804
step   2440 | loss 1.4302 | lr 3.39e-04 | grad 1.42 | tok/s 16730
step   2450 | loss 1.1717 | lr 3.39e-04 | grad 1.52 | tok/s 17251
step   2460 | loss 1.1468 | lr 3.39e-04 | grad 1.79 | tok/s 17168
step   2470 | loss 1.1681 | lr 3.39e-04 | grad 2.69 | tok/s 17207
step   2480 | loss 1.3425 | lr 3.39e-04 | grad 2.14 | tok/s 16419
step   2490 | loss 1.4372 | lr 3.39e-04 | grad 3.70 | tok/s 17150
step   2500 | loss 1.0277 | lr 3.39e-04 | grad 2.20 | tok/s 17315
step   2510 | loss 1.4392 | lr 3.39e-04 | grad 1.73 | tok/s 17066
step   2520 | loss 1.2527 | lr 3.39e-04 | grad 2.03 | tok/s 16739
step   2530 | loss 1.3446 | lr 3.39e-04 | grad 2.66 | tok/s 16662
step   2540 | loss 1.1221 | lr 3.39e-04 | grad 1.27 | tok/s 17345
step   2550 | loss 1.4477 | lr 3.39e-04 | grad 2.84 | tok/s 16144
step   2560 | loss 1.2644 | lr 3.39e-04 | grad 2.08 | tok/s 16665
step   2570 | loss 1.2995 | lr 3.39e-04 | grad 2.03 | tok/s 16138
step   2580 | loss 1.3503 | lr 3.39e-04 | grad 1.77 | tok/s 16472
step   2590 | loss 1.5481 | lr 3.39e-04 | grad 4.22 | tok/s 16181
step   2600 | loss 1.1830 | lr 3.39e-04 | grad 2.55 | tok/s 17183
step   2610 | loss 1.4757 | lr 3.39e-04 | grad 2.00 | tok/s 16771
step   2620 | loss 1.3345 | lr 3.39e-04 | grad 1.86 | tok/s 17152
step   2630 | loss 1.4898 | lr 3.39e-04 | grad 2.39 | tok/s 16691
step   2640 | loss 1.3412 | lr 3.39e-04 | grad 1.66 | tok/s 17045
step   2650 | loss 1.2766 | lr 3.39e-04 | grad 166.00 | tok/s 16722
step   2660 | loss 1.3640 | lr 3.39e-04 | grad 1.89 | tok/s 16083
step   2670 | loss 1.4800 | lr 3.39e-04 | grad 1.63 | tok/s 16651
step   2680 | loss 1.2384 | lr 3.39e-04 | grad 2.53 | tok/s 17225
step   2690 | loss 1.4030 | lr 3.39e-04 | grad 2.39 | tok/s 16779
step   2700 | loss 1.4304 | lr 3.39e-04 | grad 1.60 | tok/s 16118
step   2710 | loss 1.2900 | lr 3.39e-04 | grad 2.22 | tok/s 15851
step   2720 | loss 1.0757 | lr 3.39e-04 | grad 2.31 | tok/s 17158
step   2730 | loss 1.6506 | lr 3.39e-04 | grad 3.48 | tok/s 16935
step   2740 | loss 1.4612 | lr 3.39e-04 | grad 1.71 | tok/s 16960
step   2750 | loss 1.2968 | lr 3.39e-04 | grad 2.52 | tok/s 16073
step   2760 | loss 1.3751 | lr 3.39e-04 | grad 2.36 | tok/s 16614
step   2770 | loss 1.0649 | lr 3.39e-04 | grad 1.66 | tok/s 17098
step   2780 | loss 1.6790 | lr 3.39e-04 | grad 2.64 | tok/s 16131
step   2790 | loss 1.1807 | lr 3.39e-04 | grad 1.59 | tok/s 16789
step   2800 | loss 1.2496 | lr 3.39e-04 | grad 2.16 | tok/s 16171
step   2810 | loss 1.3282 | lr 3.39e-04 | grad 1.52 | tok/s 16169
step   2820 | loss 0.9807 | lr 3.39e-04 | grad 2.92 | tok/s 17134
step   2830 | loss 0.8322 | lr 3.39e-04 | grad 2.48 | tok/s 17128
step   2840 | loss 1.7079 | lr 3.39e-04 | grad 2.58 | tok/s 16562
step   2850 | loss 1.5029 | lr 3.39e-04 | grad 1.86 | tok/s 16622
step   2860 | loss 1.3626 | lr 3.39e-04 | grad 1.87 | tok/s 16549
step   2870 | loss 1.3683 | lr 3.39e-04 | grad 2.03 | tok/s 16945
step   2880 | loss 1.2617 | lr 3.39e-04 | grad 10.50 | tok/s 17256
step   2890 | loss 1.3560 | lr 3.39e-04 | grad 1.86 | tok/s 16583
step   2900 | loss 1.3155 | lr 3.39e-04 | grad 2.75 | tok/s 16589
step   2910 | loss 1.5375 | lr 3.39e-04 | grad 4.78 | tok/s 16289
step   2920 | loss 1.4086 | lr 3.39e-04 | grad 6.53 | tok/s 16706
step   2930 | loss 1.2339 | lr 3.39e-04 | grad 2.02 | tok/s 15781
step   2940 | loss 1.2425 | lr 3.39e-04 | grad 1.86 | tok/s 16732
step   2950 | loss 1.2782 | lr 3.39e-04 | grad 2.09 | tok/s 16911
step   2960 | loss 1.3163 | lr 3.39e-04 | grad 2.77 | tok/s 16402
step   2970 | loss 1.7809 | lr 3.39e-04 | grad 5.97 | tok/s 16952
step   2980 | loss 1.6761 | lr 3.39e-04 | grad 2.30 | tok/s 16912
step   2990 | loss 1.2790 | lr 3.39e-04 | grad 1.59 | tok/s 16899
step   3000 | loss 1.1356 | lr 3.39e-04 | grad 3.89 | tok/s 16828
  >>> saved checkpoint: checkpoint_step_003000_loss_1.1356.pt
step   3010 | loss 1.1975 | lr 3.39e-04 | grad 2.06 | tok/s 5077
step   3020 | loss 1.4089 | lr 3.39e-04 | grad 2.62 | tok/s 16867
step   3030 | loss 1.3920 | lr 3.39e-04 | grad 2.81 | tok/s 17031
step   3040 | loss 1.3136 | lr 3.39e-04 | grad 1.59 | tok/s 16834
step   3050 | loss 1.4486 | lr 3.39e-04 | grad 6.00 | tok/s 17218
step   3060 | loss 1.3908 | lr 3.39e-04 | grad 2.72 | tok/s 17347
step   3070 | loss 1.3621 | lr 3.39e-04 | grad 1.90 | tok/s 17058
step   3080 | loss 1.2730 | lr 3.39e-04 | grad 1.85 | tok/s 16669
step   3090 | loss 1.4429 | lr 3.39e-04 | grad 2.86 | tok/s 17034
step   3100 | loss 0.9864 | lr 3.39e-04 | grad 1.50 | tok/s 17461
step   3110 | loss 1.0350 | lr 3.39e-04 | grad 1.98 | tok/s 17473
step   3120 | loss 1.3138 | lr 3.39e-04 | grad 1.48 | tok/s 16501
step   3130 | loss 0.9622 | lr 3.39e-04 | grad 1.70 | tok/s 17427
step   3140 | loss 1.1902 | lr 3.39e-04 | grad 2.84 | tok/s 17264
step   3150 | loss 1.4513 | lr 3.39e-04 | grad 5.41 | tok/s 16286
step   3160 | loss 1.2617 | lr 3.39e-04 | grad 2.23 | tok/s 16603
step   3170 | loss 1.2933 | lr 3.39e-04 | grad 1.60 | tok/s 16694
step   3180 | loss 0.9659 | lr 3.39e-04 | grad 5.09 | tok/s 17257
step   3190 | loss 1.3736 | lr 3.39e-04 | grad 1.98 | tok/s 16830
step   3200 | loss 1.6812 | lr 3.39e-04 | grad 2.06 | tok/s 17122
step   3210 | loss 2.1680 | lr 3.39e-04 | grad 2.91 | tok/s 17206
step   3220 | loss 1.8529 | lr 3.39e-04 | grad 2.42 | tok/s 17426
step   3230 | loss 1.5777 | lr 3.39e-04 | grad 2.78 | tok/s 17410
step   3240 | loss 1.5321 | lr 3.39e-04 | grad 2.73 | tok/s 17397
step   3250 | loss 1.4339 | lr 3.39e-04 | grad 2.84 | tok/s 17356
step   3260 | loss 1.4001 | lr 3.39e-04 | grad 2.19 | tok/s 17398
step   3270 | loss 1.3153 | lr 3.39e-04 | grad 2.05 | tok/s 17402
step   3280 | loss 1.2961 | lr 3.39e-04 | grad 2.25 | tok/s 17344
step   3290 | loss 1.2948 | lr 3.39e-04 | grad 2.50 | tok/s 17366
step   3300 | loss 1.2456 | lr 3.39e-04 | grad 1.98 | tok/s 17333
step   3310 | loss 1.2533 | lr 3.39e-04 | grad 1.68 | tok/s 17329
step   3320 | loss 1.5053 | lr 3.39e-04 | grad 2.77 | tok/s 16936
step   3330 | loss 1.3880 | lr 3.39e-04 | grad 2.02 | tok/s 16727
step   3340 | loss 1.3509 | lr 3.39e-04 | grad 2.83 | tok/s 16449
step   3350 | loss 1.3422 | lr 3.39e-04 | grad 2.66 | tok/s 16128
step   3360 | loss 1.4429 | lr 3.39e-04 | grad 2.41 | tok/s 16349
step   3370 | loss 1.4020 | lr 3.39e-04 | grad 1.59 | tok/s 16767
step   3380 | loss 1.3046 | lr 3.39e-04 | grad 1.57 | tok/s 16766
step   3390 | loss 1.0625 | lr 3.39e-04 | grad 1.83 | tok/s 17347
step   3400 | loss 1.0407 | lr 3.39e-04 | grad 2.06 | tok/s 17272
step   3410 | loss 1.4477 | lr 3.39e-04 | grad 1.55 | tok/s 16234
step   3420 | loss 1.3979 | lr 3.39e-04 | grad 2.69 | tok/s 16854
step   3430 | loss 1.3303 | lr 3.39e-04 | grad 1.75 | tok/s 16458
step   3440 | loss 1.3415 | lr 3.39e-04 | grad 1.64 | tok/s 16796
step   3450 | loss 1.3158 | lr 3.39e-04 | grad 2.30 | tok/s 16886
step   3460 | loss 1.3332 | lr 3.39e-04 | grad 1.56 | tok/s 17018
step   3470 | loss 1.3237 | lr 3.39e-04 | grad 1.90 | tok/s 17337
step   3480 | loss 1.1744 | lr 3.39e-04 | grad 2.11 | tok/s 16094
step   3490 | loss 1.1456 | lr 3.39e-04 | grad 1.69 | tok/s 16901
step   3500 | loss 1.3777 | lr 3.39e-04 | grad 1.62 | tok/s 16604
step   3510 | loss 1.4549 | lr 3.39e-04 | grad 4.28 | tok/s 16594
step   3520 | loss 1.4658 | lr 3.39e-04 | grad 1.81 | tok/s 17285
step   3530 | loss 1.3681 | lr 3.39e-04 | grad 1.51 | tok/s 16504
step   3540 | loss 1.9345 | lr 3.39e-04 | grad 1.84 | tok/s 15850
step   3550 | loss 1.3348 | lr 3.39e-04 | grad 2.02 | tok/s 15790
step   3560 | loss 1.2483 | lr 3.39e-04 | grad 1.68 | tok/s 16912
step   3570 | loss 1.0485 | lr 3.39e-04 | grad 1.74 | tok/s 16536
step   3580 | loss 1.2072 | lr 3.39e-04 | grad 2.03 | tok/s 16860
step   3590 | loss 1.4298 | lr 3.39e-04 | grad 3.02 | tok/s 15621
step   3600 | loss 1.3163 | lr 3.39e-04 | grad 1.42 | tok/s 17009
step   3610 | loss 1.2682 | lr 3.39e-04 | grad 1.94 | tok/s 17021
step   3620 | loss 1.4167 | lr 3.39e-04 | grad 2.69 | tok/s 16506
step   3630 | loss 1.4417 | lr 3.39e-04 | grad 1.57 | tok/s 16310
step   3640 | loss 1.3266 | lr 3.39e-04 | grad 2.28 | tok/s 16523
step   3650 | loss 1.3277 | lr 3.39e-04 | grad 3.00 | tok/s 15924
step   3660 | loss 1.2328 | lr 3.39e-04 | grad 1.59 | tok/s 17148
step   3670 | loss 1.1746 | lr 3.39e-04 | grad 1.59 | tok/s 16417
step   3680 | loss 1.3129 | lr 3.39e-04 | grad 2.84 | tok/s 16402
step   3690 | loss 1.2523 | lr 3.39e-04 | grad 1.95 | tok/s 16122
step   3700 | loss 1.3841 | lr 3.39e-04 | grad 3.75 | tok/s 16948
step   3710 | loss 1.4283 | lr 3.39e-04 | grad 1.55 | tok/s 16755
step   3720 | loss 1.4055 | lr 3.39e-04 | grad 6.00 | tok/s 16384
step   3730 | loss 1.0436 | lr 3.39e-04 | grad 1.82 | tok/s 17141
step   3740 | loss 1.4964 | lr 3.39e-04 | grad 1.84 | tok/s 16737
step   3750 | loss 1.2326 | lr 3.39e-04 | grad 1.55 | tok/s 17290
step   3760 | loss 1.1873 | lr 3.39e-04 | grad 6.38 | tok/s 17316
step   3770 | loss 1.1725 | lr 3.39e-04 | grad 1.98 | tok/s 17313
step   3780 | loss 1.1330 | lr 3.39e-04 | grad 2.36 | tok/s 17298
step   3790 | loss 1.1611 | lr 3.39e-04 | grad 2.16 | tok/s 17318
step   3800 | loss 1.1200 | lr 3.39e-04 | grad 1.83 | tok/s 17312
step   3810 | loss 1.1057 | lr 3.39e-04 | grad 1.84 | tok/s 17294
step   3820 | loss 1.1093 | lr 3.39e-04 | grad 1.33 | tok/s 17298
step   3830 | loss 1.0989 | lr 3.39e-04 | grad 2.08 | tok/s 17315
step   3840 | loss 1.0580 | lr 3.39e-04 | grad 2.45 | tok/s 17312
step   3850 | loss 1.3736 | lr 3.39e-04 | grad 1.95 | tok/s 16782
step   3860 | loss 1.4380 | lr 3.39e-04 | grad 4.78 | tok/s 16370
step   3870 | loss 1.3378 | lr 3.39e-04 | grad 3.73 | tok/s 16274
step   3880 | loss 1.4555 | lr 3.39e-04 | grad 4.62 | tok/s 16201
step   3890 | loss 1.3019 | lr 3.39e-04 | grad 2.22 | tok/s 16815
step   3900 | loss 1.2611 | lr 3.39e-04 | grad 1.79 | tok/s 17074
step   3910 | loss 1.4763 | lr 3.39e-04 | grad 2.03 | tok/s 15904
step   3920 | loss 1.3521 | lr 3.39e-04 | grad 2.19 | tok/s 16971
step   3930 | loss 1.4029 | lr 3.39e-04 | grad 1.96 | tok/s 16673
step   3940 | loss 1.2863 | lr 3.39e-04 | grad 1.77 | tok/s 15824
step   3950 | loss 1.3321 | lr 3.39e-04 | grad 2.59 | tok/s 17313
step   3960 | loss 1.3783 | lr 3.39e-04 | grad 1.80 | tok/s 16606
step   3970 | loss 1.4033 | lr 3.39e-04 | grad 2.02 | tok/s 16915
step   3980 | loss 1.0137 | lr 3.39e-04 | grad 3.75 | tok/s 17572
step   3990 | loss 0.9391 | lr 3.39e-04 | grad 1.62 | tok/s 17422
step   4000 | loss 1.0228 | lr 3.39e-04 | grad 2.58 | tok/s 17319
  >>> saved checkpoint: checkpoint_step_004000_loss_1.0228.pt
step   4010 | loss 1.4187 | lr 3.39e-04 | grad 2.20 | tok/s 4782
step   4020 | loss 1.2232 | lr 3.39e-04 | grad 1.60 | tok/s 16594
step   4030 | loss 1.3526 | lr 3.39e-04 | grad 1.40 | tok/s 16963
step   4040 | loss 1.5088 | lr 3.39e-04 | grad 23.12 | tok/s 16045
step   4050 | loss 1.7848 | lr 3.39e-04 | grad 2.34 | tok/s 16871
step   4060 | loss 1.3489 | lr 3.39e-04 | grad 1.91 | tok/s 16836
step   4070 | loss 1.2976 | lr 3.39e-04 | grad 2.06 | tok/s 17164
step   4080 | loss 1.2627 | lr 3.39e-04 | grad 1.91 | tok/s 16779
step   4090 | loss 1.3512 | lr 3.39e-04 | grad 2.34 | tok/s 16754
step   4100 | loss 1.3656 | lr 3.39e-04 | grad 2.05 | tok/s 16953
step   4110 | loss 1.5877 | lr 3.39e-04 | grad 2.47 | tok/s 16739
step   4120 | loss 1.0495 | lr 3.39e-04 | grad 2.56 | tok/s 16998
step   4130 | loss 1.0278 | lr 3.39e-04 | grad 2.02 | tok/s 16888
step   4140 | loss 1.3000 | lr 3.39e-04 | grad 1.78 | tok/s 15770
step   4150 | loss 0.9391 | lr 3.39e-04 | grad 1.22 | tok/s 17113
step   4160 | loss 1.2100 | lr 3.39e-04 | grad 2.38 | tok/s 16958
step   4170 | loss 1.5720 | lr 3.39e-04 | grad 2.84 | tok/s 17258
step   4180 | loss 1.3758 | lr 3.39e-04 | grad 3.03 | tok/s 17418
step   4190 | loss 1.2880 | lr 3.39e-04 | grad 2.05 | tok/s 16822
step   4200 | loss 1.2319 | lr 3.39e-04 | grad 1.92 | tok/s 16803
step   4210 | loss 1.3728 | lr 3.39e-04 | grad 1.82 | tok/s 16409
step   4220 | loss 2.3378 | lr 3.39e-04 | grad 3.30 | tok/s 17303
step   4230 | loss 1.5577 | lr 3.39e-04 | grad 1.52 | tok/s 16551
step   4240 | loss 1.3383 | lr 3.39e-04 | grad 2.86 | tok/s 16297
step   4250 | loss 1.4170 | lr 3.39e-04 | grad 2.09 | tok/s 16436
step   4260 | loss 1.2271 | lr 3.39e-04 | grad 4.22 | tok/s 17201
step   4270 | loss 1.3771 | lr 3.39e-04 | grad 1.91 | tok/s 16168
step   4280 | loss 1.7088 | lr 3.39e-04 | grad 2.19 | tok/s 17058
step   4290 | loss 1.5025 | lr 3.39e-04 | grad 1.74 | tok/s 17044
step   4300 | loss 1.3728 | lr 3.39e-04 | grad 3.89 | tok/s 16607
step   4310 | loss 1.2566 | lr 3.39e-04 | grad 1.70 | tok/s 16827
step   4320 | loss 1.3569 | lr 3.39e-04 | grad 2.09 | tok/s 17072
step   4330 | loss 1.3281 | lr 3.39e-04 | grad 3.00 | tok/s 17091
step   4340 | loss 0.7803 | lr 3.39e-04 | grad 1.80 | tok/s 17628
step   4350 | loss 1.2012 | lr 3.39e-04 | grad 2.23 | tok/s 17214
step   4360 | loss 1.4544 | lr 3.39e-04 | grad 4.88 | tok/s 16196
step   4370 | loss 1.3052 | lr 3.39e-04 | grad 1.90 | tok/s 17035
step   4380 | loss 1.0039 | lr 3.39e-04 | grad 3.67 | tok/s 17342
step   4390 | loss 1.0438 | lr 3.39e-04 | grad 3.22 | tok/s 17372
step   4400 | loss 1.3517 | lr 3.39e-04 | grad 1.70 | tok/s 16762
step   4410 | loss 1.3209 | lr 3.39e-04 | grad 1.62 | tok/s 16821
step   4420 | loss 1.4009 | lr 3.39e-04 | grad 2.06 | tok/s 16569
step   4430 | loss 1.3404 | lr 3.39e-04 | grad 1.77 | tok/s 15752
step   4440 | loss 1.3981 | lr 3.39e-04 | grad 4.62 | tok/s 16513
step   4450 | loss 1.6337 | lr 3.39e-04 | grad 1.49 | tok/s 16915
step   4460 | loss 1.2021 | lr 3.39e-04 | grad 2.56 | tok/s 16961
step   4470 | loss 1.3881 | lr 3.39e-04 | grad 1.84 | tok/s 16769
step   4480 | loss 1.3007 | lr 3.39e-04 | grad 1.57 | tok/s 16070
step   4490 | loss 1.2671 | lr 3.39e-04 | grad 1.86 | tok/s 16944
step   4500 | loss 1.4748 | lr 3.39e-04 | grad 1.87 | tok/s 17083
step   4510 | loss 1.5120 | lr 3.39e-04 | grad 3.53 | tok/s 16630
step   4520 | loss 1.4979 | lr 3.39e-04 | grad 3.72 | tok/s 15853
step   4530 | loss 1.5121 | lr 3.39e-04 | grad 2.94 | tok/s 16053
step   4540 | loss 1.3744 | lr 3.39e-04 | grad 1.43 | tok/s 16905
step   4550 | loss 1.2888 | lr 3.39e-04 | grad 2.17 | tok/s 16925
step   4560 | loss 1.0874 | lr 3.39e-04 | grad 1.67 | tok/s 16620
step   4570 | loss 1.2938 | lr 3.39e-04 | grad 2.09 | tok/s 15912
step   4580 | loss 1.7068 | lr 3.39e-04 | grad 1.53 | tok/s 16525
step   4590 | loss 1.5490 | lr 3.39e-04 | grad 2.34 | tok/s 16432
step   4600 | loss 1.1207 | lr 3.39e-04 | grad 1.89 | tok/s 16860
step   4610 | loss 1.3608 | lr 3.39e-04 | grad 1.82 | tok/s 17082
step   4620 | loss 1.3228 | lr 3.39e-04 | grad 1.93 | tok/s 17307
step   4630 | loss 1.2724 | lr 3.39e-04 | grad 1.93 | tok/s 17289
step   4640 | loss 1.2421 | lr 3.39e-04 | grad 1.68 | tok/s 17299
step   4650 | loss 1.2209 | lr 3.39e-04 | grad 1.59 | tok/s 17303
step   4660 | loss 1.2087 | lr 3.39e-04 | grad 1.63 | tok/s 17312
step   4670 | loss 1.1903 | lr 3.39e-04 | grad 1.49 | tok/s 17336
step   4680 | loss 1.1790 | lr 3.39e-04 | grad 1.84 | tok/s 17310
step   4690 | loss 1.1903 | lr 3.39e-04 | grad 1.82 | tok/s 17291
step   4700 | loss 1.1411 | lr 3.39e-04 | grad 1.57 | tok/s 17293
step   4710 | loss 1.0925 | lr 3.39e-04 | grad 1.39 | tok/s 17296
step   4720 | loss 1.1226 | lr 3.39e-04 | grad 1.75 | tok/s 17293
step   4730 | loss 1.1441 | lr 3.39e-04 | grad 1.58 | tok/s 17323
step   4740 | loss 1.1210 | lr 3.39e-04 | grad 1.54 | tok/s 17329
step   4750 | loss 1.1142 | lr 3.39e-04 | grad 1.37 | tok/s 17321
step   4760 | loss 1.1129 | lr 3.39e-04 | grad 1.75 | tok/s 17309
step   4770 | loss 1.1445 | lr 3.39e-04 | grad 1.53 | tok/s 17311
step   4780 | loss 1.0743 | lr 3.39e-04 | grad 1.69 | tok/s 17316
step   4790 | loss 1.0788 | lr 3.39e-04 | grad 1.62 | tok/s 17353
step   4800 | loss 1.1694 | lr 3.39e-04 | grad 1.86 | tok/s 17299
step   4810 | loss 1.5754 | lr 3.39e-04 | grad 2.38 | tok/s 16808
step   4820 | loss 1.3377 | lr 3.39e-04 | grad 1.71 | tok/s 16799
step   4830 | loss 0.7479 | lr 3.39e-04 | grad 0.97 | tok/s 17616
step   4840 | loss 1.1619 | lr 3.39e-04 | grad 3.59 | tok/s 16455
step   4850 | loss 1.2936 | lr 3.39e-04 | grad 2.09 | tok/s 16163
step   4860 | loss 1.4441 | lr 3.39e-04 | grad 1.57 | tok/s 16377
step   4870 | loss 1.1421 | lr 3.39e-04 | grad 1.52 | tok/s 16332
step   4880 | loss 1.3106 | lr 3.39e-04 | grad 2.02 | tok/s 16283
step   4890 | loss 1.2366 | lr 3.39e-04 | grad 1.41 | tok/s 17310
step   4900 | loss 1.5083 | lr 3.39e-04 | grad 4.59 | tok/s 16755
step   4910 | loss 1.2757 | lr 3.39e-04 | grad 1.71 | tok/s 17308
step   4920 | loss 1.2180 | lr 3.39e-04 | grad 1.83 | tok/s 16474
step   4930 | loss 1.2777 | lr 3.39e-04 | grad 1.99 | tok/s 16539
step   4940 | loss 1.4086 | lr 3.39e-04 | grad 2.38 | tok/s 16894
step   4950 | loss 1.1631 | lr 3.39e-04 | grad 2.84 | tok/s 17334
step   4960 | loss 1.3427 | lr 3.39e-04 | grad 4.09 | tok/s 16774
step   4970 | loss 1.3626 | lr 3.39e-04 | grad 2.41 | tok/s 16179
step   4980 | loss 1.4198 | lr 3.39e-04 | grad 2.62 | tok/s 17304
step   4990 | loss 1.3710 | lr 3.39e-04 | grad 2.17 | tok/s 16668
step   5000 | loss 1.4455 | lr 3.39e-04 | grad 7.66 | tok/s 16725
  >>> saved checkpoint: checkpoint_step_005000_loss_1.4455.pt
step   5010 | loss 1.2712 | lr 3.39e-04 | grad 2.14 | tok/s 5041
step   5020 | loss 1.2830 | lr 3.39e-04 | grad 5.81 | tok/s 16855
step   5030 | loss 1.4291 | lr 3.39e-04 | grad 4.12 | tok/s 17028
step   5040 | loss 1.3391 | lr 3.39e-04 | grad 1.64 | tok/s 17065
step   5050 | loss 1.4383 | lr 3.39e-04 | grad 1.51 | tok/s 16406
step   5060 | loss 1.2941 | lr 3.39e-04 | grad 1.59 | tok/s 16252
step   5070 | loss 1.3513 | lr 3.39e-04 | grad 2.16 | tok/s 16591
step   5080 | loss 1.1495 | lr 3.39e-04 | grad 2.70 | tok/s 16982
step   5090 | loss 1.4502 | lr 3.39e-04 | grad 1.84 | tok/s 16409
step   5100 | loss 1.3021 | lr 3.39e-04 | grad 1.77 | tok/s 16787
step   5110 | loss 1.2883 | lr 3.39e-04 | grad 1.98 | tok/s 16422
step   5120 | loss 1.2780 | lr 3.39e-04 | grad 1.73 | tok/s 16974
step   5130 | loss 1.5345 | lr 3.39e-04 | grad 4.19 | tok/s 17004
step   5140 | loss 1.2884 | lr 3.39e-04 | grad 2.66 | tok/s 16107
step   5150 | loss 1.3401 | lr 3.39e-04 | grad 1.42 | tok/s 16181
step   5160 | loss 1.1661 | lr 3.39e-04 | grad 1.48 | tok/s 16590
step   5170 | loss 1.3364 | lr 3.39e-04 | grad 3.59 | tok/s 15603
step   5180 | loss 1.4162 | lr 3.39e-04 | grad 1.63 | tok/s 17326
step   5190 | loss 1.3441 | lr 3.39e-04 | grad 1.89 | tok/s 16951
step   5200 | loss 1.1388 | lr 3.39e-04 | grad 1.68 | tok/s 17220
step   5210 | loss 1.2956 | lr 3.39e-04 | grad 3.81 | tok/s 16484
step   5220 | loss 1.4820 | lr 3.39e-04 | grad 2.69 | tok/s 16629
step   5230 | loss 1.1088 | lr 3.39e-04 | grad 2.05 | tok/s 17452
step   5240 | loss 1.1219 | lr 3.39e-04 | grad 2.28 | tok/s 17003
step   5250 | loss 1.1212 | lr 3.39e-04 | grad 1.92 | tok/s 16944
step   5260 | loss 1.3463 | lr 3.39e-04 | grad 1.48 | tok/s 16073
step   5270 | loss 1.2219 | lr 3.39e-04 | grad 1.62 | tok/s 16199
step   5280 | loss 1.0899 | lr 3.39e-04 | grad 1.31 | tok/s 17364
step   5290 | loss 1.1897 | lr 3.39e-04 | grad 2.31 | tok/s 16167
step   5300 | loss 1.2555 | lr 3.39e-04 | grad 1.78 | tok/s 17334
step   5310 | loss 1.1834 | lr 3.39e-04 | grad 2.28 | tok/s 17235
step   5320 | loss 0.6548 | lr 3.39e-04 | grad 1.55 | tok/s 17116
step   5330 | loss 1.2307 | lr 3.39e-04 | grad 2.55 | tok/s 16148
step   5340 | loss 1.3604 | lr 3.39e-04 | grad 2.27 | tok/s 16407
step   5350 | loss 1.2777 | lr 3.39e-04 | grad 2.27 | tok/s 16469
step   5360 | loss 1.2503 | lr 3.39e-04 | grad 1.51 | tok/s 15966
step   5370 | loss 1.4385 | lr 3.39e-04 | grad 1.80 | tok/s 16761
step   5380 | loss 1.1978 | lr 3.39e-04 | grad 2.03 | tok/s 16547
step   5390 | loss 1.3494 | lr 3.39e-04 | grad 3.50 | tok/s 17386
step   5400 | loss 1.6226 | lr 3.39e-04 | grad 5.44 | tok/s 16303
step   5410 | loss 1.3681 | lr 3.39e-04 | grad 1.97 | tok/s 16542
step   5420 | loss 1.1142 | lr 3.39e-04 | grad 1.86 | tok/s 17102
step   5430 | loss 1.2616 | lr 3.39e-04 | grad 1.80 | tok/s 15880
step   5440 | loss 1.1580 | lr 3.39e-04 | grad 1.69 | tok/s 17333
step   5450 | loss 1.4106 | lr 3.39e-04 | grad 1.68 | tok/s 16616
step   5460 | loss 1.2120 | lr 3.39e-04 | grad 1.43 | tok/s 16375
step   5470 | loss 1.3887 | lr 3.39e-04 | grad 3.48 | tok/s 16227
step   5480 | loss 1.2675 | lr 3.39e-04 | grad 1.54 | tok/s 17202
step   5490 | loss 1.0283 | lr 3.39e-04 | grad 1.28 | tok/s 17378
step   5500 | loss 1.2139 | lr 3.39e-04 | grad 1.92 | tok/s 16782
step   5510 | loss 1.3832 | lr 3.39e-04 | grad 4.16 | tok/s 16525
step   5520 | loss 1.0489 | lr 3.39e-04 | grad 2.95 | tok/s 17409
step   5530 | loss 1.1314 | lr 3.39e-04 | grad 1.70 | tok/s 16556
step   5540 | loss 1.2222 | lr 3.39e-04 | grad 1.53 | tok/s 16950
step   5550 | loss 1.3595 | lr 3.39e-04 | grad 2.39 | tok/s 17200
step   5560 | loss 1.3339 | lr 3.39e-04 | grad 1.65 | tok/s 15942
step   5570 | loss 1.5126 | lr 3.39e-04 | grad 1.06 | tok/s 15890
step   5580 | loss 1.2515 | lr 3.39e-04 | grad 1.99 | tok/s 16479
step   5590 | loss 1.1438 | lr 3.39e-04 | grad 1.63 | tok/s 17033
step   5600 | loss 1.2933 | lr 3.39e-04 | grad 2.06 | tok/s 16073
step   5610 | loss 1.3847 | lr 3.39e-04 | grad 2.05 | tok/s 16126
step   5620 | loss 1.2832 | lr 3.39e-04 | grad 1.71 | tok/s 15632
step   5630 | loss 1.1986 | lr 3.39e-04 | grad 1.53 | tok/s 16384
step   5640 | loss 1.1606 | lr 3.39e-04 | grad 1.98 | tok/s 16606
step   5650 | loss 1.2992 | lr 3.39e-04 | grad 2.02 | tok/s 16266
step   5660 | loss 0.9951 | lr 3.39e-04 | grad 1.28 | tok/s 16696
step   5670 | loss 1.1779 | lr 3.39e-04 | grad 1.41 | tok/s 17140
step   5680 | loss 1.0540 | lr 3.39e-04 | grad 1.45 | tok/s 17284
step   5690 | loss 0.9986 | lr 3.39e-04 | grad 1.37 | tok/s 17280
step   5700 | loss 1.1590 | lr 3.39e-04 | grad 3.27 | tok/s 16787
step   5710 | loss 1.2378 | lr 3.39e-04 | grad 4.97 | tok/s 16778
step   5720 | loss 1.3180 | lr 3.39e-04 | grad 1.91 | tok/s 16352
step   5730 | loss 1.2342 | lr 3.39e-04 | grad 1.66 | tok/s 15918
step   5740 | loss 1.3954 | lr 3.39e-04 | grad 2.23 | tok/s 16449
step   5750 | loss 1.4782 | lr 3.39e-04 | grad 1.48 | tok/s 16589
step   5760 | loss 1.3271 | lr 3.39e-04 | grad 3.36 | tok/s 16851
step   5770 | loss 1.5294 | lr 3.39e-04 | grad 1.30 | tok/s 17155
step   5780 | loss 1.2737 | lr 3.39e-04 | grad 1.41 | tok/s 15325
step   5790 | loss 1.1166 | lr 3.39e-04 | grad 1.46 | tok/s 17330
step   5800 | loss 1.2170 | lr 3.39e-04 | grad 2.80 | tok/s 16960
step   5810 | loss 1.2036 | lr 3.39e-04 | grad 1.55 | tok/s 16231
step   5820 | loss 1.3331 | lr 3.39e-04 | grad 2.72 | tok/s 16470
step   5830 | loss 0.9291 | lr 3.39e-04 | grad 1.95 | tok/s 17062
step   5840 | loss 1.3519 | lr 3.39e-04 | grad 2.03 | tok/s 16858
step   5850 | loss 1.0972 | lr 3.39e-04 | grad 2.05 | tok/s 17290
step   5860 | loss 1.2641 | lr 3.39e-04 | grad 1.73 | tok/s 15867
step   5870 | loss 1.6312 | lr 3.39e-04 | grad 4.69 | tok/s 16843
step   5880 | loss 1.4276 | lr 3.39e-04 | grad 1.83 | tok/s 16589
step   5890 | loss 1.1503 | lr 3.39e-04 | grad 1.48 | tok/s 15998
step   5900 | loss 1.5492 | lr 3.39e-04 | grad 4.97 | tok/s 16548
step   5910 | loss 1.5884 | lr 3.39e-04 | grad 3.86 | tok/s 16260
step   5920 | loss 1.1791 | lr 3.39e-04 | grad 1.76 | tok/s 16866
step   5930 | loss 1.3284 | lr 3.39e-04 | grad 3.70 | tok/s 16470
step   5940 | loss 1.1409 | lr 3.39e-04 | grad 1.70 | tok/s 17310
step   5950 | loss 1.2327 | lr 3.39e-04 | grad 3.39 | tok/s 17035
step   5960 | loss 1.3772 | lr 3.39e-04 | grad 2.23 | tok/s 16923
step   5970 | loss 1.3116 | lr 3.39e-04 | grad 2.27 | tok/s 16651
step   5980 | loss 1.2268 | lr 3.39e-04 | grad 1.71 | tok/s 16712
step   5990 | loss 1.1437 | lr 3.39e-04 | grad 1.87 | tok/s 17306
step   6000 | loss 1.3380 | lr 3.39e-04 | grad 1.59 | tok/s 16551
  >>> saved checkpoint: checkpoint_step_006000_loss_1.3380.pt
step   6010 | loss 1.2879 | lr 3.39e-04 | grad 1.88 | tok/s 4650
step   6020 | loss 1.2066 | lr 3.39e-04 | grad 1.48 | tok/s 16601
step   6030 | loss 1.2088 | lr 3.39e-04 | grad 1.47 | tok/s 16693
step   6040 | loss 1.2209 | lr 3.39e-04 | grad 2.42 | tok/s 16005
step   6050 | loss 1.1043 | lr 3.39e-04 | grad 1.56 | tok/s 17485
step   6060 | loss 1.3205 | lr 3.39e-04 | grad 2.06 | tok/s 16642
step   6070 | loss 1.1688 | lr 3.39e-04 | grad 1.88 | tok/s 17007
step   6080 | loss 1.0870 | lr 3.39e-04 | grad 1.48 | tok/s 17427
step   6090 | loss 0.9343 | lr 3.39e-04 | grad 1.16 | tok/s 17531
step   6100 | loss 1.1874 | lr 3.39e-04 | grad 9.31 | tok/s 16853
step   6110 | loss 1.7955 | lr 3.39e-04 | grad 1.55 | tok/s 15982
step   6120 | loss 1.9440 | lr 3.39e-04 | grad 5.53 | tok/s 17301
step   6130 | loss 1.4846 | lr 3.39e-04 | grad 1.42 | tok/s 17142
step   6140 | loss 1.2902 | lr 3.39e-04 | grad 4.78 | tok/s 16827
step   6150 | loss 1.4142 | lr 3.39e-04 | grad 1.57 | tok/s 16638
step   6160 | loss 1.2442 | lr 3.39e-04 | grad 1.93 | tok/s 16044
step   6170 | loss 1.2745 | lr 3.39e-04 | grad 1.66 | tok/s 16069
step   6180 | loss 1.1722 | lr 3.39e-04 | grad 1.52 | tok/s 17115
step   6190 | loss 1.1800 | lr 3.39e-04 | grad 3.70 | tok/s 17395
step   6200 | loss 1.0529 | lr 3.39e-04 | grad 2.66 | tok/s 17299
step   6210 | loss 1.2846 | lr 3.39e-04 | grad 2.66 | tok/s 16339
step   6220 | loss 1.3028 | lr 3.39e-04 | grad 1.37 | tok/s 16659
step   6230 | loss 1.1527 | lr 3.39e-04 | grad 2.00 | tok/s 16559
step   6240 | loss 1.3747 | lr 3.39e-04 | grad 3.97 | tok/s 16137
step   6250 | loss 1.1922 | lr 3.39e-04 | grad 1.59 | tok/s 16375
step   6260 | loss 1.0747 | lr 3.39e-04 | grad 3.02 | tok/s 17324
step   6270 | loss 1.3339 | lr 3.39e-04 | grad 2.64 | tok/s 15891
step   6280 | loss 1.2434 | lr 3.39e-04 | grad 1.41 | tok/s 15537
step   6290 | loss 1.4810 | lr 3.39e-04 | grad 2.61 | tok/s 16932
step   6300 | loss 1.2748 | lr 3.39e-04 | grad 1.49 | tok/s 17326
step   6310 | loss 1.1882 | lr 3.39e-04 | grad 1.49 | tok/s 17154
step   6320 | loss 1.2898 | lr 3.39e-04 | grad 1.35 | tok/s 16955
step   6330 | loss 0.8441 | lr 3.39e-04 | grad 2.25 | tok/s 17553
step   6340 | loss 1.2821 | lr 3.39e-04 | grad 1.46 | tok/s 17281
step   6350 | loss 1.4574 | lr 3.39e-04 | grad 1.75 | tok/s 16815
step   6360 | loss 1.3376 | lr 3.39e-04 | grad 1.56 | tok/s 17034
step   6370 | loss 1.2486 | lr 3.39e-04 | grad 1.17 | tok/s 16225
step   6380 | loss 1.2614 | lr 3.39e-04 | grad 1.51 | tok/s 16857
step   6390 | loss 1.3498 | lr 3.39e-04 | grad 2.03 | tok/s 16533
step   6400 | loss 1.3413 | lr 3.39e-04 | grad 1.40 | tok/s 17280
step   6410 | loss 1.1660 | lr 3.39e-04 | grad 1.73 | tok/s 16708
step   6420 | loss 1.2485 | lr 3.39e-04 | grad 1.43 | tok/s 17302
step   6430 | loss 1.2392 | lr 3.39e-04 | grad 1.53 | tok/s 16130
step   6440 | loss 1.2552 | lr 3.39e-04 | grad 1.33 | tok/s 16582
step   6450 | loss 1.2278 | lr 3.39e-04 | grad 2.03 | tok/s 16103
step   6460 | loss 1.2523 | lr 3.39e-04 | grad 1.52 | tok/s 16367
step   6470 | loss 1.2510 | lr 3.39e-04 | grad 1.30 | tok/s 15689
step   6480 | loss 1.2135 | lr 3.39e-04 | grad 1.57 | tok/s 16847
step   6490 | loss 1.3191 | lr 3.39e-04 | grad 2.39 | tok/s 16169
step   6500 | loss 1.1835 | lr 3.39e-04 | grad 2.58 | tok/s 16894
step   6510 | loss 1.3165 | lr 3.39e-04 | grad 5.69 | tok/s 16436
step   6520 | loss 1.2547 | lr 3.39e-04 | grad 1.66 | tok/s 16260
step   6530 | loss 1.2378 | lr 3.39e-04 | grad 2.86 | tok/s 16582
step   6540 | loss 1.4028 | lr 3.39e-04 | grad 1.95 | tok/s 16439
step   6550 | loss 1.0295 | lr 3.39e-04 | grad 2.83 | tok/s 17308
step   6560 | loss 1.2077 | lr 3.39e-04 | grad 1.55 | tok/s 16140
step   6570 | loss 1.3402 | lr 3.39e-04 | grad 2.77 | tok/s 17146
step   6580 | loss 1.3049 | lr 3.39e-04 | grad 2.16 | tok/s 17330
step   6590 | loss 1.2744 | lr 3.39e-04 | grad 3.55 | tok/s 16973
step   6600 | loss 1.5761 | lr 3.39e-04 | grad 4.03 | tok/s 16597
step   6610 | loss 1.7873 | lr 3.39e-04 | grad 2.64 | tok/s 17080
step   6620 | loss 1.2374 | lr 3.39e-04 | grad 1.96 | tok/s 16413
step   6630 | loss 1.2966 | lr 3.39e-04 | grad 1.45 | tok/s 15583
step   6640 | loss 1.2098 | lr 3.39e-04 | grad 2.03 | tok/s 16367
step   6650 | loss 1.1981 | lr 3.39e-04 | grad 1.90 | tok/s 17094
step   6660 | loss 1.0608 | lr 3.39e-04 | grad 1.46 | tok/s 17246
step   6670 | loss 1.1344 | lr 3.39e-04 | grad 1.62 | tok/s 16904
step   6680 | loss 1.3108 | lr 3.39e-04 | grad 2.38 | tok/s 17299
step   6690 | loss 1.0611 | lr 3.39e-04 | grad 2.55 | tok/s 17039
step   6700 | loss 1.3119 | lr 3.39e-04 | grad 3.31 | tok/s 16012
step   6710 | loss 1.2445 | lr 3.39e-04 | grad 2.17 | tok/s 16479
step   6720 | loss 1.3762 | lr 3.39e-04 | grad 1.54 | tok/s 16363
step   6730 | loss 1.3617 | lr 3.39e-04 | grad 1.73 | tok/s 16889
step   6740 | loss 1.2850 | lr 3.39e-04 | grad 1.65 | tok/s 17011
step   6750 | loss 1.2295 | lr 3.39e-04 | grad 4.50 | tok/s 15801
step   6760 | loss 1.0569 | lr 3.39e-04 | grad 1.34 | tok/s 17020
step   6770 | loss 1.3456 | lr 3.39e-04 | grad 2.14 | tok/s 16142
step   6780 | loss 1.2191 | lr 3.39e-04 | grad 2.89 | tok/s 17172
step   6790 | loss 1.3340 | lr 3.39e-04 | grad 4.16 | tok/s 16012
step   6800 | loss 1.3021 | lr 3.39e-04 | grad 1.70 | tok/s 16498
step   6810 | loss 1.4682 | lr 3.39e-04 | grad 2.94 | tok/s 16578
step   6820 | loss 1.1705 | lr 3.39e-04 | grad 1.69 | tok/s 17077
step   6830 | loss 1.2397 | lr 3.39e-04 | grad 2.20 | tok/s 16696
step   6840 | loss 1.3676 | lr 3.39e-04 | grad 1.64 | tok/s 16353
step   6850 | loss 1.2501 | lr 3.39e-04 | grad 1.73 | tok/s 17326
step   6860 | loss 1.1958 | lr 3.39e-04 | grad 1.52 | tok/s 16088
step   6870 | loss 1.2570 | lr 3.39e-04 | grad 1.64 | tok/s 16320
step   6880 | loss 1.2733 | lr 3.39e-04 | grad 1.52 | tok/s 16241
step   6890 | loss 1.3095 | lr 3.39e-04 | grad 1.57 | tok/s 16714
step   6900 | loss 1.2302 | lr 3.39e-04 | grad 1.82 | tok/s 15891
step   6910 | loss 1.4758 | lr 3.39e-04 | grad 2.89 | tok/s 17268
step   6920 | loss 1.4712 | lr 3.39e-04 | grad 2.06 | tok/s 16487
step   6930 | loss 1.2181 | lr 3.39e-04 | grad 1.88 | tok/s 15703
step   6940 | loss 1.1521 | lr 3.39e-04 | grad 1.44 | tok/s 16846
step   6950 | loss 1.3302 | lr 3.39e-04 | grad 2.08 | tok/s 17125
step   6960 | loss 1.3854 | lr 3.39e-04 | grad 1.45 | tok/s 16575
step   6970 | loss 1.4561 | lr 3.39e-04 | grad 1.34 | tok/s 16104
step   6980 | loss 1.3268 | lr 3.39e-04 | grad 1.73 | tok/s 16282
step   6990 | loss 1.2898 | lr 3.39e-04 | grad 1.57 | tok/s 15609
step   7000 | loss 1.3104 | lr 3.39e-04 | grad 1.48 | tok/s 16238
  >>> saved checkpoint: checkpoint_step_007000_loss_1.3104.pt
step   7010 | loss 1.1745 | lr 3.39e-04 | grad 2.19 | tok/s 4579
step   7020 | loss 1.3551 | lr 3.39e-04 | grad 2.62 | tok/s 17476
step   7030 | loss 1.4523 | lr 3.39e-04 | grad 2.11 | tok/s 16710
step   7040 | loss 1.2727 | lr 3.39e-04 | grad 2.16 | tok/s 16387
step   7050 | loss 1.3562 | lr 3.39e-04 | grad 1.84 | tok/s 16190
step   7060 | loss 1.2417 | lr 3.39e-04 | grad 1.99 | tok/s 16851
step   7070 | loss 1.1373 | lr 3.39e-04 | grad 1.53 | tok/s 17287
step   7080 | loss 1.2990 | lr 3.39e-04 | grad 1.66 | tok/s 16953
step   7090 | loss 1.3858 | lr 3.39e-04 | grad 1.46 | tok/s 17142
step   7100 | loss 1.3731 | lr 3.39e-04 | grad 2.09 | tok/s 16571
step   7110 | loss 1.1032 | lr 3.39e-04 | grad 1.87 | tok/s 17557
step   7120 | loss 1.0788 | lr 3.39e-04 | grad 1.48 | tok/s 17057
step   7130 | loss 1.2086 | lr 3.39e-04 | grad 1.40 | tok/s 16560
step   7140 | loss 1.1845 | lr 3.39e-04 | grad 1.54 | tok/s 16834
step   7150 | loss 1.3068 | lr 3.39e-04 | grad 1.46 | tok/s 16028
step   7160 | loss 1.1737 | lr 3.39e-04 | grad 1.92 | tok/s 16357
step   7170 | loss 1.1412 | lr 3.39e-04 | grad 1.50 | tok/s 17169
step   7180 | loss 1.1687 | lr 3.39e-04 | grad 2.20 | tok/s 16367
step   7190 | loss 1.3536 | lr 3.39e-04 | grad 1.98 | tok/s 16700
step   7200 | loss 1.2654 | lr 3.39e-04 | grad 1.16 | tok/s 16569
step   7210 | loss 1.3144 | lr 3.39e-04 | grad 1.50 | tok/s 16213
step   7220 | loss 1.2434 | lr 3.39e-04 | grad 1.35 | tok/s 16389
step   7230 | loss 1.3233 | lr 3.39e-04 | grad 4.28 | tok/s 16796
step   7240 | loss 1.0968 | lr 3.39e-04 | grad 1.35 | tok/s 16994
step   7250 | loss 1.5324 | lr 3.39e-04 | grad 2.09 | tok/s 16121
step   7260 | loss 1.3745 | lr 3.39e-04 | grad 2.06 | tok/s 16505

Training complete! Final step: 7269
