Using device: cuda
Output directory: benchmark_results/cmaes_4d/mamba2_480M_converge0.01_20260202_091709/eval_33/levelmamba2_100m_20260202_111835
Model: Level mamba2, 404,951,488 parameters
Using schedule-free AdamW (lr=0.0003964924702759186)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 5.6521 | lr 3.96e-04 | grad 7.22 | tok/s 4776
step     20 | loss 3.4214 | lr 3.96e-04 | grad 3.69 | tok/s 25357
step     30 | loss 3.9313 | lr 3.96e-04 | grad 23.62 | tok/s 25871
step     40 | loss 3.3546 | lr 3.96e-04 | grad 7.00 | tok/s 26027
step     50 | loss 2.6096 | lr 3.96e-04 | grad 3.06 | tok/s 25835
step     60 | loss 2.2847 | lr 3.96e-04 | grad 4.28 | tok/s 25718
step     70 | loss 2.0388 | lr 3.96e-04 | grad 1.94 | tok/s 25594
step     80 | loss 1.9655 | lr 3.96e-04 | grad 2.95 | tok/s 25527
step     90 | loss 1.8499 | lr 3.96e-04 | grad 1.34 | tok/s 25452
step    100 | loss 1.9900 | lr 3.96e-04 | grad 3.98 | tok/s 25291
step    110 | loss 2.8278 | lr 3.96e-04 | grad 3.33 | tok/s 24238
step    120 | loss 1.9231 | lr 3.96e-04 | grad 3.14 | tok/s 24641
step    130 | loss 2.3384 | lr 3.96e-04 | grad 6.53 | tok/s 24474
step    140 | loss 1.3943 | lr 3.96e-04 | grad 2.55 | tok/s 25365
step    150 | loss 2.3487 | lr 3.96e-04 | grad 2.98 | tok/s 24757
step    160 | loss 2.1629 | lr 3.96e-04 | grad 2.23 | tok/s 24035
step    170 | loss 1.7819 | lr 3.96e-04 | grad 2.67 | tok/s 24704
step    180 | loss 1.8213 | lr 3.96e-04 | grad 2.41 | tok/s 23720
step    190 | loss 1.5477 | lr 3.96e-04 | grad 3.14 | tok/s 25197
step    200 | loss 1.6808 | lr 3.96e-04 | grad 3.14 | tok/s 23955
step    210 | loss 2.0620 | lr 3.96e-04 | grad 3.78 | tok/s 24374
step    220 | loss 1.7883 | lr 3.96e-04 | grad 1.94 | tok/s 24034
step    230 | loss 2.0604 | lr 3.96e-04 | grad 2.17 | tok/s 24429
step    240 | loss 1.7180 | lr 3.96e-04 | grad 1.67 | tok/s 24334
step    250 | loss 1.7263 | lr 3.96e-04 | grad 2.16 | tok/s 24860
step    260 | loss 1.7408 | lr 3.96e-04 | grad 2.08 | tok/s 24390
step    270 | loss 1.6197 | lr 3.96e-04 | grad 1.66 | tok/s 23066
step    280 | loss 1.5477 | lr 3.96e-04 | grad 1.79 | tok/s 23860
step    290 | loss 1.8372 | lr 3.96e-04 | grad 1.58 | tok/s 23871
step    300 | loss 1.5642 | lr 3.96e-04 | grad 1.34 | tok/s 23730
step    310 | loss 1.7520 | lr 3.96e-04 | grad 3.69 | tok/s 23836
step    320 | loss 1.6329 | lr 3.96e-04 | grad 2.36 | tok/s 24366
step    330 | loss 1.8718 | lr 3.96e-04 | grad 4.19 | tok/s 24125
step    340 | loss 1.6680 | lr 3.96e-04 | grad 3.78 | tok/s 25102
step    350 | loss 1.4955 | lr 3.96e-04 | grad 1.84 | tok/s 23448
step    360 | loss 1.4259 | lr 3.96e-04 | grad 1.36 | tok/s 25051
step    370 | loss 1.2117 | lr 3.96e-04 | grad 1.80 | tok/s 25236
step    380 | loss 1.0797 | lr 3.96e-04 | grad 1.62 | tok/s 25240
step    390 | loss 1.6121 | lr 3.96e-04 | grad 2.14 | tok/s 24170
step    400 | loss 1.6363 | lr 3.96e-04 | grad 5.81 | tok/s 24120
step    410 | loss 1.5717 | lr 3.96e-04 | grad 1.74 | tok/s 25056
step    420 | loss 1.5312 | lr 3.96e-04 | grad 1.42 | tok/s 24906
step    430 | loss 1.5832 | lr 3.96e-04 | grad 2.22 | tok/s 24168
step    440 | loss 1.5677 | lr 3.96e-04 | grad 1.53 | tok/s 24177
step    450 | loss 1.5149 | lr 3.96e-04 | grad 1.79 | tok/s 24584
step    460 | loss 1.4226 | lr 3.96e-04 | grad 1.35 | tok/s 24313
step    470 | loss 1.5907 | lr 3.96e-04 | grad 1.57 | tok/s 25094
step    480 | loss 1.6269 | lr 3.96e-04 | grad 1.62 | tok/s 23910
step    490 | loss 1.7075 | lr 3.96e-04 | grad 2.47 | tok/s 24465
step    500 | loss 1.6057 | lr 3.96e-04 | grad 1.28 | tok/s 23378
step    510 | loss 1.4692 | lr 3.96e-04 | grad 3.08 | tok/s 24530
step    520 | loss 1.6046 | lr 3.96e-04 | grad 2.23 | tok/s 23994
step    530 | loss 1.5579 | lr 3.96e-04 | grad 1.29 | tok/s 24035
step    540 | loss 1.2385 | lr 3.96e-04 | grad 1.43 | tok/s 24212
step    550 | loss 1.4347 | lr 3.96e-04 | grad 1.40 | tok/s 25256
step    560 | loss 1.2923 | lr 3.96e-04 | grad 1.38 | tok/s 25246
step    570 | loss 1.2610 | lr 3.96e-04 | grad 1.73 | tok/s 25286
step    580 | loss 1.2921 | lr 3.96e-04 | grad 1.34 | tok/s 25266
step    590 | loss 1.2089 | lr 3.96e-04 | grad 1.27 | tok/s 25285
step    600 | loss 1.2648 | lr 3.96e-04 | grad 1.57 | tok/s 25289
step    610 | loss 1.2172 | lr 3.96e-04 | grad 0.86 | tok/s 25292
step    620 | loss 1.5984 | lr 3.96e-04 | grad 5.31 | tok/s 23942
step    630 | loss 1.5987 | lr 3.96e-04 | grad 1.92 | tok/s 24082
step    640 | loss 1.4725 | lr 3.96e-04 | grad 1.48 | tok/s 24536
step    650 | loss 1.5197 | lr 3.96e-04 | grad 1.61 | tok/s 24672
step    660 | loss 1.4929 | lr 3.96e-04 | grad 1.63 | tok/s 24380
step    670 | loss 1.6041 | lr 3.96e-04 | grad 1.23 | tok/s 23751
step    680 | loss 1.4899 | lr 3.96e-04 | grad 1.42 | tok/s 23816
step    690 | loss 1.4459 | lr 3.96e-04 | grad 1.62 | tok/s 24069
step    700 | loss 1.5007 | lr 3.96e-04 | grad 2.39 | tok/s 23878
step    710 | loss 1.2838 | lr 3.96e-04 | grad 1.48 | tok/s 24666
step    720 | loss 1.3496 | lr 3.96e-04 | grad 1.55 | tok/s 24588
step    730 | loss 1.6517 | lr 3.96e-04 | grad 4.81 | tok/s 24709
step    740 | loss 1.5519 | lr 3.96e-04 | grad 1.36 | tok/s 25233
step    750 | loss 1.4085 | lr 3.96e-04 | grad 1.26 | tok/s 24720
step    760 | loss 1.4927 | lr 3.96e-04 | grad 1.27 | tok/s 24346
step    770 | loss 1.4441 | lr 3.96e-04 | grad 1.84 | tok/s 24422
step    780 | loss 1.5083 | lr 3.96e-04 | grad 3.33 | tok/s 25001
step    790 | loss 1.4015 | lr 3.96e-04 | grad 1.07 | tok/s 24586
step    800 | loss 1.1725 | lr 3.96e-04 | grad 2.72 | tok/s 23975
step    810 | loss 1.3779 | lr 3.96e-04 | grad 1.97 | tok/s 24675
step    820 | loss 1.4438 | lr 3.96e-04 | grad 1.28 | tok/s 23643
step    830 | loss 1.5196 | lr 3.96e-04 | grad 1.68 | tok/s 24090
step    840 | loss 1.4417 | lr 3.96e-04 | grad 1.90 | tok/s 24320
step    850 | loss 1.4946 | lr 3.96e-04 | grad 2.14 | tok/s 24546
step    860 | loss 1.3251 | lr 3.96e-04 | grad 1.58 | tok/s 25154
step    870 | loss 1.5059 | lr 3.96e-04 | grad 1.83 | tok/s 24250
step    880 | loss 1.4433 | lr 3.96e-04 | grad 1.46 | tok/s 24460
step    890 | loss 1.4585 | lr 3.96e-04 | grad 1.93 | tok/s 24425
step    900 | loss 1.3893 | lr 3.96e-04 | grad 1.50 | tok/s 23891
step    910 | loss 1.4374 | lr 3.96e-04 | grad 1.59 | tok/s 24398
step    920 | loss 1.3208 | lr 3.96e-04 | grad 1.25 | tok/s 24514
step    930 | loss 1.3034 | lr 3.96e-04 | grad 1.88 | tok/s 24103
step    940 | loss 1.4025 | lr 3.96e-04 | grad 1.20 | tok/s 23501
step    950 | loss 1.4036 | lr 3.96e-04 | grad 1.38 | tok/s 24311
step    960 | loss 1.3944 | lr 3.96e-04 | grad 1.33 | tok/s 24293
step    970 | loss 1.8215 | lr 3.96e-04 | grad 2.58 | tok/s 25260
step    980 | loss 1.5330 | lr 3.96e-04 | grad 1.33 | tok/s 24239
step    990 | loss 1.4882 | lr 3.96e-04 | grad 1.36 | tok/s 24497
step   1000 | loss 1.1575 | lr 3.96e-04 | grad 1.46 | tok/s 24772
  >>> saved checkpoint: checkpoint_step_001000_loss_1.1575.pt
step   1010 | loss 1.2136 | lr 3.96e-04 | grad 1.41 | tok/s 12997
step   1020 | loss 1.4143 | lr 3.96e-04 | grad 1.49 | tok/s 24471
step   1030 | loss 1.9966 | lr 3.96e-04 | grad 3.61 | tok/s 25001
step   1040 | loss 1.4796 | lr 3.96e-04 | grad 1.22 | tok/s 25153
step   1050 | loss 1.1496 | lr 3.96e-04 | grad 1.25 | tok/s 25002
step   1060 | loss 1.3052 | lr 3.96e-04 | grad 1.35 | tok/s 24843
step   1070 | loss 1.2169 | lr 3.96e-04 | grad 1.25 | tok/s 25567
step   1080 | loss 1.1968 | lr 3.96e-04 | grad 1.30 | tok/s 25509
step   1090 | loss 1.1707 | lr 3.96e-04 | grad 1.30 | tok/s 25527
step   1100 | loss 1.1160 | lr 3.96e-04 | grad 1.16 | tok/s 25479
step   1110 | loss 1.3358 | lr 3.96e-04 | grad 1.53 | tok/s 24797
step   1120 | loss 1.5583 | lr 3.96e-04 | grad 1.23 | tok/s 25068
step   1130 | loss 1.6926 | lr 3.96e-04 | grad 1.31 | tok/s 25397
step   1140 | loss 1.5855 | lr 3.96e-04 | grad 2.83 | tok/s 24809
step   1150 | loss 1.5899 | lr 3.96e-04 | grad 3.22 | tok/s 23996
step   1160 | loss 1.4777 | lr 3.96e-04 | grad 1.66 | tok/s 23947
step   1170 | loss 1.3079 | lr 3.96e-04 | grad 1.19 | tok/s 25148
step   1180 | loss 1.5127 | lr 3.96e-04 | grad 2.16 | tok/s 25211
step   1190 | loss 1.1166 | lr 3.96e-04 | grad 1.07 | tok/s 25417
step   1200 | loss 1.2729 | lr 3.96e-04 | grad 1.38 | tok/s 23998
step   1210 | loss 1.3122 | lr 3.96e-04 | grad 1.45 | tok/s 24761
step   1220 | loss 1.3466 | lr 3.96e-04 | grad 1.20 | tok/s 24906
step   1230 | loss 1.2058 | lr 3.96e-04 | grad 1.77 | tok/s 25178
step   1240 | loss 1.4246 | lr 3.96e-04 | grad 2.06 | tok/s 24560
step   1250 | loss 1.3015 | lr 3.96e-04 | grad 1.32 | tok/s 25236
step   1260 | loss 1.3172 | lr 3.96e-04 | grad 2.02 | tok/s 24491
step   1270 | loss 1.3226 | lr 3.96e-04 | grad 1.73 | tok/s 24594
step   1280 | loss 1.3048 | lr 3.96e-04 | grad 1.62 | tok/s 24052
step   1290 | loss 1.5209 | lr 3.96e-04 | grad 7.47 | tok/s 23946
step   1300 | loss 1.4642 | lr 3.96e-04 | grad 1.55 | tok/s 24899
step   1310 | loss 1.4308 | lr 3.96e-04 | grad 2.83 | tok/s 24808
step   1320 | loss 1.3709 | lr 3.96e-04 | grad 1.43 | tok/s 24754
step   1330 | loss 1.4574 | lr 3.96e-04 | grad 1.28 | tok/s 23984
step   1340 | loss 1.3650 | lr 3.96e-04 | grad 1.24 | tok/s 24883
step   1350 | loss 1.4182 | lr 3.96e-04 | grad 1.35 | tok/s 23418
step   1360 | loss 1.4522 | lr 3.96e-04 | grad 2.84 | tok/s 24962
step   1370 | loss 1.4216 | lr 3.96e-04 | grad 1.55 | tok/s 24238
step   1380 | loss 1.2774 | lr 3.96e-04 | grad 1.86 | tok/s 24688
step   1390 | loss 1.4795 | lr 3.96e-04 | grad 1.22 | tok/s 24158
step   1400 | loss 1.3030 | lr 3.96e-04 | grad 1.31 | tok/s 23718
step   1410 | loss 1.0711 | lr 3.96e-04 | grad 1.44 | tok/s 25120
step   1420 | loss 1.6419 | lr 3.96e-04 | grad 1.06 | tok/s 24308
step   1430 | loss 1.3953 | lr 3.96e-04 | grad 1.76 | tok/s 24540
step   1440 | loss 1.3536 | lr 3.96e-04 | grad 1.17 | tok/s 24849
step   1450 | loss 1.4603 | lr 3.96e-04 | grad 1.92 | tok/s 24134
step   1460 | loss 1.3339 | lr 3.96e-04 | grad 1.41 | tok/s 23814
step   1470 | loss 1.3183 | lr 3.96e-04 | grad 2.11 | tok/s 24639
step   1480 | loss 1.5757 | lr 3.96e-04 | grad 4.47 | tok/s 24449
step   1490 | loss 1.5217 | lr 3.96e-04 | grad 1.20 | tok/s 24799
step   1500 | loss 1.2333 | lr 3.96e-04 | grad 1.34 | tok/s 24400
step   1510 | loss 1.4108 | lr 3.96e-04 | grad 1.66 | tok/s 24209
step   1520 | loss 1.3340 | lr 3.96e-04 | grad 1.38 | tok/s 24831
step   1530 | loss 1.4458 | lr 3.96e-04 | grad 1.36 | tok/s 24916
step   1540 | loss 1.4133 | lr 3.96e-04 | grad 3.80 | tok/s 24444
step   1550 | loss 1.0983 | lr 3.96e-04 | grad 0.95 | tok/s 25202
step   1560 | loss 1.2658 | lr 3.96e-04 | grad 1.12 | tok/s 24633
step   1570 | loss 1.1793 | lr 3.96e-04 | grad 1.47 | tok/s 24756
step   1580 | loss 1.3855 | lr 3.96e-04 | grad 2.75 | tok/s 23869
step   1590 | loss 1.1961 | lr 3.96e-04 | grad 4.78 | tok/s 25238
step   1600 | loss 1.7721 | lr 3.96e-04 | grad 2.81 | tok/s 24580
step   1610 | loss 1.9932 | lr 3.96e-04 | grad 1.75 | tok/s 25358
step   1620 | loss 1.6281 | lr 3.96e-04 | grad 2.31 | tok/s 25324
step   1630 | loss 1.4700 | lr 3.96e-04 | grad 2.33 | tok/s 25316
step   1640 | loss 1.3689 | lr 3.96e-04 | grad 1.97 | tok/s 25315
step   1650 | loss 1.3249 | lr 3.96e-04 | grad 1.68 | tok/s 25320
step   1660 | loss 1.4398 | lr 3.96e-04 | grad 1.70 | tok/s 24539
step   1670 | loss 1.3451 | lr 3.96e-04 | grad 1.59 | tok/s 24315
step   1680 | loss 1.4184 | lr 3.96e-04 | grad 2.08 | tok/s 23789
step   1690 | loss 1.2785 | lr 3.96e-04 | grad 1.08 | tok/s 24700
step   1700 | loss 1.1797 | lr 3.96e-04 | grad 2.20 | tok/s 24774
step   1710 | loss 1.3953 | lr 3.96e-04 | grad 1.20 | tok/s 24008
step   1720 | loss 1.3643 | lr 3.96e-04 | grad 3.39 | tok/s 24732
step   1730 | loss 1.3499 | lr 3.96e-04 | grad 1.52 | tok/s 24903
step   1740 | loss 1.2105 | lr 3.96e-04 | grad 1.35 | tok/s 24373
step   1750 | loss 1.3548 | lr 3.96e-04 | grad 1.38 | tok/s 24163
step   1760 | loss 1.5163 | lr 3.96e-04 | grad 1.55 | tok/s 24745
step   1770 | loss 1.6864 | lr 3.96e-04 | grad 1.27 | tok/s 23427
step   1780 | loss 1.2603 | lr 3.96e-04 | grad 1.65 | tok/s 23768
step   1790 | loss 1.1742 | lr 3.96e-04 | grad 1.23 | tok/s 24310
step   1800 | loss 1.3679 | lr 3.96e-04 | grad 1.52 | tok/s 24500
step   1810 | loss 1.4589 | lr 3.96e-04 | grad 2.67 | tok/s 24179
step   1820 | loss 1.3329 | lr 3.96e-04 | grad 1.31 | tok/s 23539
step   1830 | loss 1.2781 | lr 3.96e-04 | grad 1.36 | tok/s 24391
step   1840 | loss 1.3573 | lr 3.96e-04 | grad 1.71 | tok/s 24233
step   1850 | loss 1.3838 | lr 3.96e-04 | grad 1.53 | tok/s 24125
step   1860 | loss 1.3622 | lr 3.96e-04 | grad 1.96 | tok/s 24543
step   1870 | loss 1.3489 | lr 3.96e-04 | grad 1.38 | tok/s 24674
step   1880 | loss 1.2125 | lr 3.96e-04 | grad 1.59 | tok/s 25307
step   1890 | loss 1.1570 | lr 3.96e-04 | grad 1.50 | tok/s 25356
step   1900 | loss 1.1369 | lr 3.96e-04 | grad 1.06 | tok/s 25326
step   1910 | loss 1.1137 | lr 3.96e-04 | grad 1.34 | tok/s 25323
step   1920 | loss 1.1568 | lr 3.96e-04 | grad 2.52 | tok/s 25256
step   1930 | loss 1.4433 | lr 3.96e-04 | grad 1.53 | tok/s 24046
step   1940 | loss 1.3181 | lr 3.96e-04 | grad 1.59 | tok/s 23901
step   1950 | loss 1.4065 | lr 3.96e-04 | grad 2.08 | tok/s 24142
step   1960 | loss 1.4667 | lr 3.96e-04 | grad 1.36 | tok/s 24628
step   1970 | loss 1.3518 | lr 3.96e-04 | grad 2.31 | tok/s 23888
step   1980 | loss 1.4313 | lr 3.96e-04 | grad 3.02 | tok/s 24550
step   1990 | loss 1.0975 | lr 3.96e-04 | grad 1.16 | tok/s 25470
step   2000 | loss 1.1589 | lr 3.96e-04 | grad 1.84 | tok/s 24837
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1589.pt
step   2010 | loss 1.3335 | lr 3.96e-04 | grad 2.25 | tok/s 12151
step   2020 | loss 1.6407 | lr 3.96e-04 | grad 1.73 | tok/s 24134
step   2030 | loss 1.3984 | lr 3.96e-04 | grad 1.25 | tok/s 24616
step   2040 | loss 1.2837 | lr 3.96e-04 | grad 2.06 | tok/s 24557
step   2050 | loss 1.4658 | lr 3.96e-04 | grad 1.59 | tok/s 24889
step   2060 | loss 1.1749 | lr 3.96e-04 | grad 1.10 | tok/s 24982
step   2070 | loss 1.2297 | lr 3.96e-04 | grad 1.27 | tok/s 23615
step   2080 | loss 1.3117 | lr 3.96e-04 | grad 2.52 | tok/s 25158
step   2090 | loss 1.4849 | lr 3.96e-04 | grad 2.20 | tok/s 25378
step   2100 | loss 1.3258 | lr 3.96e-04 | grad 1.35 | tok/s 24142
step   2110 | loss 2.0986 | lr 3.96e-04 | grad 2.28 | tok/s 24625
step   2120 | loss 1.3617 | lr 3.96e-04 | grad 1.27 | tok/s 23865
step   2130 | loss 1.4589 | lr 3.96e-04 | grad 1.08 | tok/s 24752
step   2140 | loss 1.6116 | lr 3.96e-04 | grad 1.29 | tok/s 24678
step   2150 | loss 1.3624 | lr 3.96e-04 | grad 1.16 | tok/s 24591
step   2160 | loss 1.3805 | lr 3.96e-04 | grad 1.84 | tok/s 24666
step   2170 | loss 1.1040 | lr 3.96e-04 | grad 2.31 | tok/s 25441
step   2180 | loss 1.3699 | lr 3.96e-04 | grad 1.11 | tok/s 24329
step   2190 | loss 1.1808 | lr 3.96e-04 | grad 1.58 | tok/s 25332
step   2200 | loss 1.3428 | lr 3.96e-04 | grad 2.02 | tok/s 24729
step   2210 | loss 1.3439 | lr 3.96e-04 | grad 2.41 | tok/s 23836
step   2220 | loss 1.5398 | lr 3.96e-04 | grad 1.90 | tok/s 24111
step   2230 | loss 1.2473 | lr 3.96e-04 | grad 1.41 | tok/s 24587
step   2240 | loss 1.3310 | lr 3.96e-04 | grad 1.34 | tok/s 24192
step   2250 | loss 1.4345 | lr 3.96e-04 | grad 1.33 | tok/s 24915
step   2260 | loss 1.5773 | lr 3.96e-04 | grad 2.36 | tok/s 23593
step   2270 | loss 1.3640 | lr 3.96e-04 | grad 1.44 | tok/s 24382
step   2280 | loss 1.1825 | lr 3.96e-04 | grad 1.23 | tok/s 23864
step   2290 | loss 1.5112 | lr 3.96e-04 | grad 1.72 | tok/s 24082
step   2300 | loss 1.3814 | lr 3.96e-04 | grad 1.84 | tok/s 24730
step   2310 | loss 1.3470 | lr 3.96e-04 | grad 1.35 | tok/s 25358
step   2320 | loss 1.2648 | lr 3.96e-04 | grad 1.08 | tok/s 25375
step   2330 | loss 1.2160 | lr 3.96e-04 | grad 1.39 | tok/s 25383
step   2340 | loss 1.1901 | lr 3.96e-04 | grad 1.33 | tok/s 25368
step   2350 | loss 1.1628 | lr 3.96e-04 | grad 1.12 | tok/s 25343
step   2360 | loss 1.1365 | lr 3.96e-04 | grad 1.02 | tok/s 25376
step   2370 | loss 1.1216 | lr 3.96e-04 | grad 1.31 | tok/s 25382
step   2380 | loss 1.1390 | lr 3.96e-04 | grad 1.08 | tok/s 25325
step   2390 | loss 1.1002 | lr 3.96e-04 | grad 1.55 | tok/s 25352
step   2400 | loss 1.2114 | lr 3.96e-04 | grad 1.63 | tok/s 25077
step   2410 | loss 1.3936 | lr 3.96e-04 | grad 1.13 | tok/s 24857
step   2420 | loss 1.0430 | lr 3.96e-04 | grad 1.26 | tok/s 24398
step   2430 | loss 1.3619 | lr 3.96e-04 | grad 1.63 | tok/s 23482
step   2440 | loss 1.2747 | lr 3.96e-04 | grad 1.05 | tok/s 24591
step   2450 | loss 1.4646 | lr 3.96e-04 | grad 1.48 | tok/s 24949
step   2460 | loss 1.2742 | lr 3.96e-04 | grad 1.84 | tok/s 24573
step   2470 | loss 1.3715 | lr 3.96e-04 | grad 2.55 | tok/s 24565
step   2480 | loss 1.4282 | lr 3.96e-04 | grad 1.80 | tok/s 24692
step   2490 | loss 1.4578 | lr 3.96e-04 | grad 1.98 | tok/s 24667
step   2500 | loss 1.3739 | lr 3.96e-04 | grad 1.20 | tok/s 24489
step   2510 | loss 1.3152 | lr 3.96e-04 | grad 3.28 | tok/s 24108
step   2520 | loss 1.4130 | lr 3.96e-04 | grad 1.52 | tok/s 24479
step   2530 | loss 1.3666 | lr 3.96e-04 | grad 1.10 | tok/s 23738
step   2540 | loss 1.2713 | lr 3.96e-04 | grad 1.56 | tok/s 24249
step   2550 | loss 1.4318 | lr 3.96e-04 | grad 1.30 | tok/s 24180
step   2560 | loss 1.3009 | lr 3.96e-04 | grad 1.27 | tok/s 24249
step   2570 | loss 1.5390 | lr 3.96e-04 | grad 6.16 | tok/s 24222
step   2580 | loss 1.2691 | lr 3.96e-04 | grad 1.53 | tok/s 23780
step   2590 | loss 1.3841 | lr 3.96e-04 | grad 1.09 | tok/s 24133
step   2600 | loss 1.2804 | lr 3.96e-04 | grad 1.18 | tok/s 24910
step   2610 | loss 1.4331 | lr 3.96e-04 | grad 1.57 | tok/s 24112
step   2620 | loss 1.1319 | lr 3.96e-04 | grad 1.50 | tok/s 24979
step   2630 | loss 1.2478 | lr 3.96e-04 | grad 1.38 | tok/s 24254
step   2640 | loss 1.1650 | lr 3.96e-04 | grad 0.85 | tok/s 24468
step   2650 | loss 1.2700 | lr 3.96e-04 | grad 1.42 | tok/s 24472
step   2660 | loss 1.0784 | lr 3.96e-04 | grad 1.35 | tok/s 24806
step   2670 | loss 1.3227 | lr 3.96e-04 | grad 1.76 | tok/s 24063
step   2680 | loss 1.2746 | lr 3.96e-04 | grad 1.23 | tok/s 23648
step   2690 | loss 1.3403 | lr 3.96e-04 | grad 1.80 | tok/s 24379
step   2700 | loss 1.5850 | lr 3.96e-04 | grad 3.69 | tok/s 24513
step   2710 | loss 1.2603 | lr 3.96e-04 | grad 1.35 | tok/s 24678
step   2720 | loss 1.2356 | lr 3.96e-04 | grad 1.16 | tok/s 24173
step   2730 | loss 1.3631 | lr 3.96e-04 | grad 1.69 | tok/s 24300
step   2740 | loss 1.3492 | lr 3.96e-04 | grad 1.38 | tok/s 24465
step   2750 | loss 1.1523 | lr 3.96e-04 | grad 1.33 | tok/s 24947
step   2760 | loss 1.2879 | lr 3.96e-04 | grad 2.91 | tok/s 24715
step   2770 | loss 1.2131 | lr 3.96e-04 | grad 1.49 | tok/s 24548
step   2780 | loss 1.3824 | lr 3.96e-04 | grad 1.27 | tok/s 24260
step   2790 | loss 1.4137 | lr 3.96e-04 | grad 1.23 | tok/s 23622
step   2800 | loss 1.2934 | lr 3.96e-04 | grad 2.41 | tok/s 24302
step   2810 | loss 1.3075 | lr 3.96e-04 | grad 1.26 | tok/s 23049
step   2820 | loss 1.2080 | lr 3.96e-04 | grad 1.05 | tok/s 24349
step   2830 | loss 1.1408 | lr 3.96e-04 | grad 1.04 | tok/s 24096
step   2840 | loss 1.1483 | lr 3.96e-04 | grad 1.10 | tok/s 25221
step   2850 | loss 1.1169 | lr 3.96e-04 | grad 1.83 | tok/s 24706
step   2860 | loss 1.2922 | lr 3.96e-04 | grad 1.15 | tok/s 24304
step   2870 | loss 1.3379 | lr 3.96e-04 | grad 1.48 | tok/s 23646
step   2880 | loss 1.4159 | lr 3.96e-04 | grad 3.05 | tok/s 24457
step   2890 | loss 1.4260 | lr 3.96e-04 | grad 1.90 | tok/s 23588
step   2900 | loss 1.2617 | lr 3.96e-04 | grad 1.91 | tok/s 25090
step   2910 | loss 1.2529 | lr 3.96e-04 | grad 2.97 | tok/s 23889
step   2920 | loss 1.2579 | lr 3.96e-04 | grad 1.67 | tok/s 24822
step   2930 | loss 1.1980 | lr 3.96e-04 | grad 1.06 | tok/s 24269
step   2940 | loss 1.5454 | lr 3.96e-04 | grad 1.17 | tok/s 24477
step   2950 | loss 1.4304 | lr 3.96e-04 | grad 4.28 | tok/s 23812
step   2960 | loss 1.3817 | lr 3.96e-04 | grad 1.28 | tok/s 24236
step   2970 | loss 1.2752 | lr 3.96e-04 | grad 1.20 | tok/s 24749
step   2980 | loss 1.3508 | lr 3.96e-04 | grad 1.26 | tok/s 24657
step   2990 | loss 1.2865 | lr 3.96e-04 | grad 1.40 | tok/s 24588
step   3000 | loss 1.3159 | lr 3.96e-04 | grad 1.20 | tok/s 24754
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3159.pt
step   3010 | loss 1.2605 | lr 3.96e-04 | grad 1.19 | tok/s 12666
step   3020 | loss 1.2407 | lr 3.96e-04 | grad 2.12 | tok/s 23999
step   3030 | loss 1.2413 | lr 3.96e-04 | grad 1.31 | tok/s 24842
step   3040 | loss 1.1746 | lr 3.96e-04 | grad 1.15 | tok/s 25411
step   3050 | loss 1.2303 | lr 3.96e-04 | grad 8.94 | tok/s 25175
step   3060 | loss 1.8304 | lr 3.96e-04 | grad 4.84 | tok/s 24367
step   3070 | loss 1.4182 | lr 3.96e-04 | grad 2.97 | tok/s 24745
step   3080 | loss 1.3476 | lr 3.96e-04 | grad 1.23 | tok/s 24036
step   3090 | loss 1.2332 | lr 3.96e-04 | grad 1.09 | tok/s 24428
step   3100 | loss 1.3080 | lr 3.96e-04 | grad 1.94 | tok/s 25327
step   3110 | loss 1.3409 | lr 3.96e-04 | grad 1.45 | tok/s 24291
step   3120 | loss 1.2802 | lr 3.96e-04 | grad 2.20 | tok/s 23821
step   3130 | loss 1.1575 | lr 3.96e-04 | grad 2.34 | tok/s 24750
step   3140 | loss 1.2943 | lr 3.96e-04 | grad 1.24 | tok/s 22966
step   3150 | loss 1.4377 | lr 3.96e-04 | grad 1.33 | tok/s 25147
step   3160 | loss 1.2315 | lr 3.96e-04 | grad 2.23 | tok/s 25074
step   3170 | loss 1.1043 | lr 3.96e-04 | grad 1.11 | tok/s 25354
step   3180 | loss 1.4610 | lr 3.96e-04 | grad 1.30 | tok/s 24944
step   3190 | loss 1.2531 | lr 3.96e-04 | grad 1.26 | tok/s 24262
step   3200 | loss 1.3578 | lr 3.96e-04 | grad 1.91 | tok/s 24740
step   3210 | loss 1.2113 | lr 3.96e-04 | grad 1.20 | tok/s 24993
step   3220 | loss 1.2920 | lr 3.96e-04 | grad 1.50 | tok/s 23971
step   3230 | loss 1.2297 | lr 3.96e-04 | grad 1.09 | tok/s 23689
step   3240 | loss 1.2425 | lr 3.96e-04 | grad 1.00 | tok/s 23933
step   3250 | loss 1.2926 | lr 3.96e-04 | grad 1.18 | tok/s 24145
step   3260 | loss 1.2894 | lr 3.96e-04 | grad 1.16 | tok/s 24012
step   3270 | loss 1.3890 | lr 3.96e-04 | grad 1.23 | tok/s 24213
step   3280 | loss 1.1507 | lr 3.96e-04 | grad 1.30 | tok/s 24507
step   3290 | loss 1.3760 | lr 3.96e-04 | grad 2.33 | tok/s 25265
step   3300 | loss 1.5391 | lr 3.96e-04 | grad 3.34 | tok/s 24588
step   3310 | loss 1.4963 | lr 3.96e-04 | grad 1.52 | tok/s 24549
step   3320 | loss 1.2501 | lr 3.96e-04 | grad 1.78 | tok/s 23437
step   3330 | loss 1.1486 | lr 3.96e-04 | grad 1.30 | tok/s 25176
step   3340 | loss 1.3048 | lr 3.96e-04 | grad 2.53 | tok/s 25058
step   3350 | loss 1.2867 | lr 3.96e-04 | grad 2.72 | tok/s 24177
step   3360 | loss 1.3134 | lr 3.96e-04 | grad 1.29 | tok/s 24033
step   3370 | loss 1.3689 | lr 3.96e-04 | grad 1.31 | tok/s 24742
step   3380 | loss 1.1504 | lr 3.96e-04 | grad 1.32 | tok/s 24111
step   3390 | loss 1.3307 | lr 3.96e-04 | grad 3.45 | tok/s 24288
step   3400 | loss 1.3609 | lr 3.96e-04 | grad 1.30 | tok/s 23855
step   3410 | loss 1.3613 | lr 3.96e-04 | grad 1.32 | tok/s 24662
step   3420 | loss 1.3131 | lr 3.96e-04 | grad 1.20 | tok/s 24196
step   3430 | loss 1.2513 | lr 3.96e-04 | grad 1.19 | tok/s 24293
step   3440 | loss 1.3134 | lr 3.96e-04 | grad 1.05 | tok/s 24036
step   3450 | loss 1.3116 | lr 3.96e-04 | grad 2.11 | tok/s 23927
step   3460 | loss 1.5045 | lr 3.96e-04 | grad 1.48 | tok/s 24717
step   3470 | loss 1.1759 | lr 3.96e-04 | grad 1.23 | tok/s 23917
step   3480 | loss 1.4277 | lr 3.96e-04 | grad 1.11 | tok/s 24675
step   3490 | loss 1.4115 | lr 3.96e-04 | grad 1.39 | tok/s 23626
step   3500 | loss 1.2985 | lr 3.96e-04 | grad 1.07 | tok/s 23373
step   3510 | loss 1.2686 | lr 3.96e-04 | grad 2.28 | tok/s 24733
step   3520 | loss 1.4504 | lr 3.96e-04 | grad 2.25 | tok/s 24321
step   3530 | loss 1.2971 | lr 3.96e-04 | grad 1.28 | tok/s 23718
step   3540 | loss 1.2519 | lr 3.96e-04 | grad 1.66 | tok/s 24798
step   3550 | loss 1.3426 | lr 3.96e-04 | grad 2.20 | tok/s 24531
step   3560 | loss 1.2234 | lr 3.96e-04 | grad 1.45 | tok/s 25444
step   3570 | loss 1.1815 | lr 3.96e-04 | grad 1.38 | tok/s 24206
step   3580 | loss 1.2962 | lr 3.96e-04 | grad 1.34 | tok/s 23630
step   3590 | loss 1.1476 | lr 3.96e-04 | grad 1.12 | tok/s 24387
step   3600 | loss 1.3466 | lr 3.96e-04 | grad 1.12 | tok/s 24642
step   3610 | loss 1.2565 | lr 3.96e-04 | grad 1.08 | tok/s 23553
step   3620 | loss 1.3306 | lr 3.96e-04 | grad 2.53 | tok/s 24679
step   3630 | loss 1.4500 | lr 3.96e-04 | grad 1.61 | tok/s 23668
step   3640 | loss 1.4226 | lr 3.96e-04 | grad 2.03 | tok/s 24678
step   3650 | loss 1.3479 | lr 3.96e-04 | grad 1.06 | tok/s 23351
step   3660 | loss 1.2430 | lr 3.96e-04 | grad 1.67 | tok/s 24627
step   3670 | loss 1.1753 | lr 3.96e-04 | grad 1.08 | tok/s 24090
step   3680 | loss 1.2730 | lr 3.96e-04 | grad 1.14 | tok/s 24867
step   3690 | loss 1.1377 | lr 3.96e-04 | grad 1.88 | tok/s 25007
step   3700 | loss 1.3327 | lr 3.96e-04 | grad 1.12 | tok/s 24606
step   3710 | loss 1.2586 | lr 3.96e-04 | grad 1.19 | tok/s 24835
step   3720 | loss 1.4266 | lr 3.96e-04 | grad 4.22 | tok/s 24400
step   3730 | loss 1.3153 | lr 3.96e-04 | grad 3.25 | tok/s 24574
step   3740 | loss 1.2760 | lr 3.96e-04 | grad 1.41 | tok/s 24514
step   3750 | loss 1.2557 | lr 3.96e-04 | grad 1.15 | tok/s 24615
step   3760 | loss 1.4263 | lr 3.96e-04 | grad 5.56 | tok/s 23740
step   3770 | loss 1.3036 | lr 3.96e-04 | grad 1.29 | tok/s 25073
step   3780 | loss 1.1529 | lr 3.96e-04 | grad 0.93 | tok/s 24617
step   3790 | loss 1.1189 | lr 3.96e-04 | grad 1.27 | tok/s 24923
step   3800 | loss 1.2526 | lr 3.96e-04 | grad 1.46 | tok/s 24416
step   3810 | loss 1.2082 | lr 3.96e-04 | grad 1.23 | tok/s 24995
step   3820 | loss 1.2709 | lr 3.96e-04 | grad 1.23 | tok/s 25413
step   3830 | loss 1.4037 | lr 3.96e-04 | grad 1.00 | tok/s 25001
step   3840 | loss 1.2575 | lr 3.96e-04 | grad 1.66 | tok/s 24635
step   3850 | loss 1.3081 | lr 3.96e-04 | grad 1.70 | tok/s 24715
step   3860 | loss 1.3181 | lr 3.96e-04 | grad 3.08 | tok/s 24977
step   3870 | loss 1.0334 | lr 3.96e-04 | grad 1.49 | tok/s 24724
step   3880 | loss 1.1608 | lr 3.96e-04 | grad 6.31 | tok/s 24469
step   3890 | loss 1.1932 | lr 3.96e-04 | grad 1.19 | tok/s 24424
step   3900 | loss 1.3461 | lr 3.96e-04 | grad 1.55 | tok/s 24013
step   3910 | loss 1.2749 | lr 3.96e-04 | grad 1.44 | tok/s 25465
step   3920 | loss 1.2612 | lr 3.96e-04 | grad 1.27 | tok/s 23984
step   3930 | loss 1.2442 | lr 3.96e-04 | grad 1.81 | tok/s 24711
step   3940 | loss 1.2270 | lr 3.96e-04 | grad 1.12 | tok/s 25179
step   3950 | loss 1.1464 | lr 3.96e-04 | grad 1.31 | tok/s 24904
step   3960 | loss 1.0494 | lr 3.96e-04 | grad 1.09 | tok/s 25491
step   3970 | loss 1.0161 | lr 3.96e-04 | grad 1.30 | tok/s 25482
step   3980 | loss 1.0070 | lr 3.96e-04 | grad 0.99 | tok/s 25468
step   3990 | loss 1.0869 | lr 3.96e-04 | grad 9.06 | tok/s 25460
step   4000 | loss 1.3140 | lr 3.96e-04 | grad 1.23 | tok/s 24981
  >>> saved checkpoint: checkpoint_step_004000_loss_1.3140.pt
step   4010 | loss 1.1604 | lr 3.96e-04 | grad 1.38 | tok/s 13439
step   4020 | loss 1.1144 | lr 3.96e-04 | grad 1.26 | tok/s 25814
step   4030 | loss 1.0988 | lr 3.96e-04 | grad 1.04 | tok/s 25792
step   4040 | loss 1.1916 | lr 3.96e-04 | grad 1.41 | tok/s 25177
step   4050 | loss 1.3249 | lr 3.96e-04 | grad 1.16 | tok/s 24437
step   4060 | loss 1.4296 | lr 3.96e-04 | grad 1.73 | tok/s 24245
step   4070 | loss 1.3224 | lr 3.96e-04 | grad 1.05 | tok/s 25678
step   4080 | loss 1.2391 | lr 3.96e-04 | grad 3.06 | tok/s 25020
step   4090 | loss 1.3171 | lr 3.96e-04 | grad 2.19 | tok/s 24524
step   4100 | loss 1.2738 | lr 3.96e-04 | grad 1.80 | tok/s 24616
step   4110 | loss 1.3703 | lr 3.96e-04 | grad 1.39 | tok/s 25028
step   4120 | loss 1.1896 | lr 3.96e-04 | grad 1.74 | tok/s 24576
step   4130 | loss 1.3160 | lr 3.96e-04 | grad 1.52 | tok/s 24380
step   4140 | loss 1.2412 | lr 3.96e-04 | grad 4.38 | tok/s 24363
step   4150 | loss 1.0320 | lr 3.96e-04 | grad 1.13 | tok/s 25447
step   4160 | loss 1.0662 | lr 3.96e-04 | grad 1.43 | tok/s 24949
step   4170 | loss 1.2702 | lr 3.96e-04 | grad 1.47 | tok/s 24119
step   4180 | loss 0.7665 | lr 3.96e-04 | grad 1.08 | tok/s 25847
step   4190 | loss 1.2572 | lr 3.96e-04 | grad 1.05 | tok/s 24137
step   4200 | loss 1.4602 | lr 3.96e-04 | grad 1.52 | tok/s 24657
step   4210 | loss 1.3436 | lr 3.96e-04 | grad 1.43 | tok/s 24073
step   4220 | loss 1.4122 | lr 3.96e-04 | grad 2.03 | tok/s 24843
step   4230 | loss 1.2575 | lr 3.96e-04 | grad 2.36 | tok/s 24570
step   4240 | loss 1.4138 | lr 3.96e-04 | grad 1.55 | tok/s 24119
step   4250 | loss 1.2425 | lr 3.96e-04 | grad 1.70 | tok/s 24412
step   4260 | loss 1.2799 | lr 3.96e-04 | grad 1.12 | tok/s 24419
step   4270 | loss 1.5391 | lr 3.96e-04 | grad 1.50 | tok/s 25149
step   4280 | loss 1.2540 | lr 3.96e-04 | grad 1.23 | tok/s 24244
step   4290 | loss 1.2719 | lr 3.96e-04 | grad 2.42 | tok/s 24900
step   4300 | loss 1.3701 | lr 3.96e-04 | grad 3.53 | tok/s 25368
step   4310 | loss 1.3088 | lr 3.96e-04 | grad 2.23 | tok/s 25009
step   4320 | loss 1.1844 | lr 3.96e-04 | grad 1.12 | tok/s 24750
step   4330 | loss 1.0754 | lr 3.96e-04 | grad 1.08 | tok/s 25502
step   4340 | loss 1.0707 | lr 3.96e-04 | grad 1.00 | tok/s 25491
step   4350 | loss 1.1320 | lr 3.96e-04 | grad 1.10 | tok/s 25475
step   4360 | loss 1.0987 | lr 3.96e-04 | grad 1.06 | tok/s 25467
step   4370 | loss 1.0715 | lr 3.96e-04 | grad 1.12 | tok/s 25445
step   4380 | loss 1.0869 | lr 3.96e-04 | grad 1.16 | tok/s 25483
step   4390 | loss 1.2163 | lr 3.96e-04 | grad 2.75 | tok/s 24614
step   4400 | loss 1.2254 | lr 3.96e-04 | grad 1.34 | tok/s 24535
step   4410 | loss 1.2460 | lr 3.96e-04 | grad 2.69 | tok/s 25425
step   4420 | loss 1.1544 | lr 3.96e-04 | grad 3.00 | tok/s 25478
step   4430 | loss 1.2433 | lr 3.96e-04 | grad 1.31 | tok/s 24945
step   4440 | loss 1.2684 | lr 3.96e-04 | grad 1.32 | tok/s 25107
step   4450 | loss 1.3469 | lr 3.96e-04 | grad 1.41 | tok/s 24663
step   4460 | loss 1.2193 | lr 3.96e-04 | grad 1.27 | tok/s 24669
step   4470 | loss 1.2069 | lr 3.96e-04 | grad 1.32 | tok/s 24641
step   4480 | loss 1.1712 | lr 3.96e-04 | grad 1.35 | tok/s 24940
step   4490 | loss 1.4455 | lr 3.96e-04 | grad 2.19 | tok/s 24223
step   4500 | loss 1.3254 | lr 3.96e-04 | grad 0.99 | tok/s 23875
step   4510 | loss 1.2301 | lr 3.96e-04 | grad 1.27 | tok/s 24858
step   4520 | loss 1.2519 | lr 3.96e-04 | grad 1.44 | tok/s 24060
step   4530 | loss 1.2826 | lr 3.96e-04 | grad 1.98 | tok/s 24435
step   4540 | loss 1.2597 | lr 3.96e-04 | grad 1.20 | tok/s 24063
step   4550 | loss 1.3102 | lr 3.96e-04 | grad 1.20 | tok/s 25486
step   4560 | loss 1.2576 | lr 3.96e-04 | grad 0.94 | tok/s 25477
step   4570 | loss 1.2360 | lr 3.96e-04 | grad 0.95 | tok/s 25474
step   4580 | loss 1.1983 | lr 3.96e-04 | grad 0.99 | tok/s 25468
step   4590 | loss 1.1684 | lr 3.96e-04 | grad 1.03 | tok/s 25479
step   4600 | loss 1.1652 | lr 3.96e-04 | grad 1.08 | tok/s 25455
step   4610 | loss 1.2951 | lr 3.96e-04 | grad 1.42 | tok/s 24809
step   4620 | loss 1.2983 | lr 3.96e-04 | grad 2.16 | tok/s 24693
step   4630 | loss 1.2733 | lr 3.96e-04 | grad 1.44 | tok/s 24844
step   4640 | loss 1.3110 | lr 3.96e-04 | grad 1.08 | tok/s 24404
step   4650 | loss 1.6675 | lr 3.96e-04 | grad 3.72 | tok/s 24843
step   4660 | loss 1.3904 | lr 3.96e-04 | grad 1.30 | tok/s 24396
step   4670 | loss 1.2706 | lr 3.96e-04 | grad 1.18 | tok/s 25182
step   4680 | loss 1.1520 | lr 3.96e-04 | grad 1.62 | tok/s 24948
step   4690 | loss 1.2761 | lr 3.96e-04 | grad 1.13 | tok/s 23908
step   4700 | loss 1.2672 | lr 3.96e-04 | grad 1.29 | tok/s 24616
step   4710 | loss 1.1997 | lr 3.96e-04 | grad 1.60 | tok/s 24032
step   4720 | loss 1.2348 | lr 3.96e-04 | grad 1.09 | tok/s 24331
step   4730 | loss 1.3690 | lr 3.96e-04 | grad 4.03 | tok/s 24627
step   4740 | loss 1.2493 | lr 3.96e-04 | grad 1.19 | tok/s 23769
step   4750 | loss 1.2712 | lr 3.96e-04 | grad 1.39 | tok/s 24481
step   4760 | loss 1.2965 | lr 3.96e-04 | grad 1.16 | tok/s 24676
step   4770 | loss 1.2860 | lr 3.96e-04 | grad 1.51 | tok/s 24743
step   4780 | loss 1.2197 | lr 3.96e-04 | grad 1.34 | tok/s 23068
step   4790 | loss 1.3256 | lr 3.96e-04 | grad 1.34 | tok/s 24817
step   4800 | loss 1.4724 | lr 3.96e-04 | grad 1.26 | tok/s 24627
step   4810 | loss 1.1637 | lr 3.96e-04 | grad 1.13 | tok/s 24859
step   4820 | loss 1.2021 | lr 3.96e-04 | grad 1.21 | tok/s 24182
step   4830 | loss 1.1531 | lr 3.96e-04 | grad 1.08 | tok/s 25045
step   4840 | loss 1.2834 | lr 3.96e-04 | grad 1.13 | tok/s 24285
step   4850 | loss 1.2583 | lr 3.96e-04 | grad 1.98 | tok/s 25271
step   4860 | loss 0.9781 | lr 3.96e-04 | grad 2.28 | tok/s 25473
step   4870 | loss 0.8492 | lr 3.96e-04 | grad 2.06 | tok/s 25458
step   4880 | loss 1.1837 | lr 3.96e-04 | grad 1.25 | tok/s 24279
step   4890 | loss 1.1230 | lr 3.96e-04 | grad 1.39 | tok/s 24810
step   4900 | loss 1.2619 | lr 3.96e-04 | grad 4.97 | tok/s 24164
step   4910 | loss 1.1974 | lr 3.96e-04 | grad 1.24 | tok/s 24164
step   4920 | loss 1.2200 | lr 3.96e-04 | grad 1.73 | tok/s 24824
step   4930 | loss 1.2436 | lr 3.96e-04 | grad 2.28 | tok/s 24917
step   4940 | loss 1.3192 | lr 3.96e-04 | grad 1.15 | tok/s 24498
step   4950 | loss 1.1276 | lr 3.96e-04 | grad 1.52 | tok/s 25022
step   4960 | loss 1.2624 | lr 3.96e-04 | grad 2.42 | tok/s 24981
step   4970 | loss 1.4774 | lr 3.96e-04 | grad 2.78 | tok/s 23807
step   4980 | loss 1.3663 | lr 3.96e-04 | grad 1.52 | tok/s 24128
step   4990 | loss 1.3274 | lr 3.96e-04 | grad 3.17 | tok/s 24267
step   5000 | loss 1.2013 | lr 3.96e-04 | grad 0.88 | tok/s 24187
  >>> saved checkpoint: checkpoint_step_005000_loss_1.2013.pt
step   5010 | loss 1.3632 | lr 3.96e-04 | grad 1.03 | tok/s 12355
step   5020 | loss 1.2680 | lr 3.96e-04 | grad 2.50 | tok/s 24671
step   5030 | loss 1.8700 | lr 3.96e-04 | grad 1.46 | tok/s 25380
step   5040 | loss 1.3243 | lr 3.96e-04 | grad 1.38 | tok/s 25147
step   5050 | loss 1.3604 | lr 3.96e-04 | grad 1.34 | tok/s 24986
step   5060 | loss 1.0808 | lr 3.96e-04 | grad 1.27 | tok/s 24535
step   5070 | loss 1.5347 | lr 3.96e-04 | grad 1.52 | tok/s 24717
step   5080 | loss 1.3161 | lr 3.96e-04 | grad 1.55 | tok/s 25017
step   5090 | loss 1.1435 | lr 3.96e-04 | grad 1.61 | tok/s 24647
step   5100 | loss 1.2305 | lr 3.96e-04 | grad 1.33 | tok/s 24475
step   5110 | loss 1.3191 | lr 3.96e-04 | grad 1.68 | tok/s 24807
step   5120 | loss 1.2561 | lr 3.96e-04 | grad 0.86 | tok/s 25281
step   5130 | loss 1.3306 | lr 3.96e-04 | grad 1.08 | tok/s 25220
step   5140 | loss 1.1822 | lr 3.96e-04 | grad 1.26 | tok/s 24755
step   5150 | loss 1.2516 | lr 3.96e-04 | grad 1.19 | tok/s 25580
step   5160 | loss 1.1963 | lr 3.96e-04 | grad 1.52 | tok/s 25541
step   5170 | loss 1.1443 | lr 3.96e-04 | grad 1.26 | tok/s 25539
step   5180 | loss 1.2004 | lr 3.96e-04 | grad 1.62 | tok/s 25519
step   5190 | loss 1.3183 | lr 3.96e-04 | grad 1.35 | tok/s 23941
step   5200 | loss 1.3058 | lr 3.96e-04 | grad 1.23 | tok/s 23914
step   5210 | loss 1.2218 | lr 3.96e-04 | grad 1.01 | tok/s 24659
step   5220 | loss 1.3190 | lr 3.96e-04 | grad 1.22 | tok/s 23444
step   5230 | loss 1.2195 | lr 3.96e-04 | grad 1.46 | tok/s 24252
step   5240 | loss 1.7437 | lr 3.96e-04 | grad 2.00 | tok/s 25056
step   5250 | loss 1.2775 | lr 3.96e-04 | grad 0.89 | tok/s 25390
step   5260 | loss 1.1745 | lr 3.96e-04 | grad 0.97 | tok/s 25486
step   5270 | loss 1.1702 | lr 3.96e-04 | grad 1.20 | tok/s 25473
step   5280 | loss 1.1162 | lr 3.96e-04 | grad 0.97 | tok/s 25484
step   5290 | loss 1.1778 | lr 3.96e-04 | grad 1.10 | tok/s 25511
step   5300 | loss 1.1376 | lr 3.96e-04 | grad 1.59 | tok/s 25545
step   5310 | loss 1.1912 | lr 3.96e-04 | grad 3.39 | tok/s 25503
step   5320 | loss 1.2676 | lr 3.96e-04 | grad 1.31 | tok/s 24010
step   5330 | loss 1.3027 | lr 3.96e-04 | grad 1.01 | tok/s 24712
step   5340 | loss 1.2906 | lr 3.96e-04 | grad 1.41 | tok/s 23251
step   5350 | loss 1.3572 | lr 3.96e-04 | grad 1.43 | tok/s 25251
step   5360 | loss 1.5667 | lr 3.96e-04 | grad 1.13 | tok/s 25130
step   5370 | loss 1.3531 | lr 3.96e-04 | grad 1.20 | tok/s 24321
step   5380 | loss 1.2278 | lr 3.96e-04 | grad 2.42 | tok/s 24646
step   5390 | loss 1.1341 | lr 3.96e-04 | grad 1.27 | tok/s 24779
step   5400 | loss 1.0880 | lr 3.96e-04 | grad 1.40 | tok/s 24696
step   5410 | loss 1.1991 | lr 3.96e-04 | grad 1.64 | tok/s 24368
step   5420 | loss 1.2896 | lr 3.96e-04 | grad 2.06 | tok/s 24432
step   5430 | loss 1.3496 | lr 3.96e-04 | grad 1.21 | tok/s 24548
step   5440 | loss 1.2831 | lr 3.96e-04 | grad 1.28 | tok/s 23620
step   5450 | loss 1.5119 | lr 3.96e-04 | grad 2.48 | tok/s 24441

Training complete! Final step: 5457
