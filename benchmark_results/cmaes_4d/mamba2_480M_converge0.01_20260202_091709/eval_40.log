Using device: cuda
Output directory: benchmark_results/cmaes_4d/mamba2_480M_converge0.01_20260202_091709/eval_40/levelmamba2_100m_20260202_111835
Model: Level mamba2, 873,893,448 parameters
Using schedule-free AdamW (lr=0.00020514642671861722)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 7.2382 | lr 2.05e-04 | grad 51.25 | tok/s 2458
step     20 | loss 3.1709 | lr 2.05e-04 | grad 4.72 | tok/s 12416
step     30 | loss 2.3615 | lr 2.05e-04 | grad 5.53 | tok/s 11944
step     40 | loss 2.7391 | lr 2.05e-04 | grad 8.31 | tok/s 11871
step     50 | loss 2.0303 | lr 2.05e-04 | grad 7.38 | tok/s 12466
step     60 | loss 1.6857 | lr 2.05e-04 | grad 2.91 | tok/s 12456
step     70 | loss 4.7146 | lr 2.05e-04 | grad 10.50 | tok/s 12385
step     80 | loss 3.8975 | lr 2.05e-04 | grad 16.12 | tok/s 12725
step     90 | loss 3.0584 | lr 2.05e-04 | grad 11.94 | tok/s 12673
step    100 | loss 2.5847 | lr 2.05e-04 | grad 18.62 | tok/s 12716
step    110 | loss 2.3491 | lr 2.05e-04 | grad 7.31 | tok/s 12645
step    120 | loss 2.1935 | lr 2.05e-04 | grad 4.84 | tok/s 12651
step    130 | loss 2.1451 | lr 2.05e-04 | grad 5.09 | tok/s 12634
step    140 | loss 2.0445 | lr 2.05e-04 | grad 4.09 | tok/s 12572
step    150 | loss 1.8535 | lr 2.05e-04 | grad 4.25 | tok/s 12577
step    160 | loss 1.9459 | lr 2.05e-04 | grad 5.31 | tok/s 12631
step    170 | loss 1.8142 | lr 2.05e-04 | grad 4.78 | tok/s 12668
step    180 | loss 1.8784 | lr 2.05e-04 | grad 3.64 | tok/s 12584
step    190 | loss 1.6687 | lr 2.05e-04 | grad 3.70 | tok/s 12579
step    200 | loss 1.7438 | lr 2.05e-04 | grad 7.62 | tok/s 12562
step    210 | loss 1.9272 | lr 2.05e-04 | grad 5.28 | tok/s 12432
step    220 | loss 2.1665 | lr 2.05e-04 | grad 6.66 | tok/s 12427
step    230 | loss 2.0984 | lr 2.05e-04 | grad 4.06 | tok/s 11535
step    240 | loss 2.0420 | lr 2.05e-04 | grad 4.38 | tok/s 11885
step    250 | loss 1.4872 | lr 2.05e-04 | grad 2.95 | tok/s 12557
step    260 | loss 1.9488 | lr 2.05e-04 | grad 4.56 | tok/s 11994
step    270 | loss 2.1725 | lr 2.05e-04 | grad 3.88 | tok/s 12183
step    280 | loss 1.6628 | lr 2.05e-04 | grad 3.88 | tok/s 12370
step    290 | loss 0.6538 | lr 2.05e-04 | grad 2.66 | tok/s 12612
step    300 | loss 2.3284 | lr 2.05e-04 | grad 5.28 | tok/s 12338
step    310 | loss 1.8003 | lr 2.05e-04 | grad 6.12 | tok/s 12238
step    320 | loss 1.8674 | lr 2.05e-04 | grad 2.80 | tok/s 11551
step    330 | loss 2.1088 | lr 2.05e-04 | grad 3.73 | tok/s 11901
step    340 | loss 1.8057 | lr 2.05e-04 | grad 3.62 | tok/s 12124
step    350 | loss 1.1596 | lr 2.05e-04 | grad 2.91 | tok/s 12470
step    360 | loss 1.7513 | lr 2.05e-04 | grad 2.64 | tok/s 11274
step    370 | loss 1.6538 | lr 2.05e-04 | grad 3.44 | tok/s 12034
step    380 | loss 1.4684 | lr 2.05e-04 | grad 3.19 | tok/s 12543
step    390 | loss 1.4014 | lr 2.05e-04 | grad 3.34 | tok/s 12423
step    400 | loss 1.2908 | lr 2.05e-04 | grad 2.09 | tok/s 12523
step    410 | loss 1.5552 | lr 2.05e-04 | grad 2.98 | tok/s 11325
step    420 | loss 2.0520 | lr 2.05e-04 | grad 2.89 | tok/s 12355
step    430 | loss 2.0096 | lr 2.05e-04 | grad 4.22 | tok/s 11790
step    440 | loss 1.7907 | lr 2.05e-04 | grad 3.69 | tok/s 11990
step    450 | loss 1.7253 | lr 2.05e-04 | grad 3.23 | tok/s 11901
step    460 | loss 1.6659 | lr 2.05e-04 | grad 3.47 | tok/s 12139
step    470 | loss 2.0369 | lr 2.05e-04 | grad 5.56 | tok/s 12193
step    480 | loss 1.7533 | lr 2.05e-04 | grad 2.23 | tok/s 11603
step    490 | loss 1.5484 | lr 2.05e-04 | grad 3.62 | tok/s 12347
step    500 | loss 1.6180 | lr 2.05e-04 | grad 2.98 | tok/s 12442
step    510 | loss 1.6135 | lr 2.05e-04 | grad 2.20 | tok/s 12458
step    520 | loss 1.7914 | lr 2.05e-04 | grad 2.77 | tok/s 12011
step    530 | loss 1.6497 | lr 2.05e-04 | grad 2.28 | tok/s 11995
step    540 | loss 1.4607 | lr 2.05e-04 | grad 2.19 | tok/s 11787
step    550 | loss 1.6312 | lr 2.05e-04 | grad 3.25 | tok/s 11418
step    560 | loss 1.5586 | lr 2.05e-04 | grad 2.62 | tok/s 11935
step    570 | loss 1.4508 | lr 2.05e-04 | grad 2.41 | tok/s 11593
step    580 | loss 1.7318 | lr 2.05e-04 | grad 7.34 | tok/s 12019
step    590 | loss 1.7342 | lr 2.05e-04 | grad 2.91 | tok/s 11559
step    600 | loss 1.5415 | lr 2.05e-04 | grad 2.75 | tok/s 12306
step    610 | loss 1.4807 | lr 2.05e-04 | grad 2.84 | tok/s 11632
step    620 | loss 1.5764 | lr 2.05e-04 | grad 2.83 | tok/s 11514
step    630 | loss 1.6881 | lr 2.05e-04 | grad 3.36 | tok/s 11975
step    640 | loss 1.5912 | lr 2.05e-04 | grad 2.27 | tok/s 12075
step    650 | loss 1.6458 | lr 2.05e-04 | grad 3.84 | tok/s 12154
step    660 | loss 1.7646 | lr 2.05e-04 | grad 3.36 | tok/s 12079
step    670 | loss 1.6611 | lr 2.05e-04 | grad 2.94 | tok/s 11919
step    680 | loss 1.7171 | lr 2.05e-04 | grad 2.92 | tok/s 12275
step    690 | loss 1.3999 | lr 2.05e-04 | grad 3.12 | tok/s 12620
step    700 | loss 1.5084 | lr 2.05e-04 | grad 2.41 | tok/s 11851
step    710 | loss 1.3650 | lr 2.05e-04 | grad 4.16 | tok/s 11488
step    720 | loss 1.2769 | lr 2.05e-04 | grad 2.27 | tok/s 12531
step    730 | loss 1.4831 | lr 2.05e-04 | grad 2.62 | tok/s 12408
step    740 | loss 1.1744 | lr 2.05e-04 | grad 2.58 | tok/s 12564
step    750 | loss 1.0899 | lr 2.05e-04 | grad 1.94 | tok/s 12624
step    760 | loss 1.0337 | lr 2.05e-04 | grad 1.76 | tok/s 12539
step    770 | loss 0.9819 | lr 2.05e-04 | grad 1.82 | tok/s 12543
step    780 | loss 1.0320 | lr 2.05e-04 | grad 2.88 | tok/s 12301
step    790 | loss 1.6681 | lr 2.05e-04 | grad 3.59 | tok/s 12048
step    800 | loss 1.7295 | lr 2.05e-04 | grad 2.42 | tok/s 12074
step    810 | loss 1.5749 | lr 2.05e-04 | grad 2.30 | tok/s 11620
step    820 | loss 1.5089 | lr 2.05e-04 | grad 2.80 | tok/s 12425
step    830 | loss 1.3543 | lr 2.05e-04 | grad 3.31 | tok/s 12544
step    840 | loss 1.5160 | lr 2.05e-04 | grad 2.14 | tok/s 12519
step    850 | loss 1.3413 | lr 2.05e-04 | grad 2.16 | tok/s 12407
step    860 | loss 1.4961 | lr 2.05e-04 | grad 2.48 | tok/s 11818
step    870 | loss 1.5783 | lr 2.05e-04 | grad 3.50 | tok/s 12120
step    880 | loss 1.5742 | lr 2.05e-04 | grad 2.66 | tok/s 12013
step    890 | loss 1.4926 | lr 2.05e-04 | grad 3.89 | tok/s 12124
step    900 | loss 1.3449 | lr 2.05e-04 | grad 3.58 | tok/s 11939
step    910 | loss 1.5014 | lr 2.05e-04 | grad 4.16 | tok/s 12333
step    920 | loss 1.5001 | lr 2.05e-04 | grad 2.36 | tok/s 11831
step    930 | loss 1.3757 | lr 2.05e-04 | grad 2.20 | tok/s 12427
step    940 | loss 1.4446 | lr 2.05e-04 | grad 3.45 | tok/s 12444
step    950 | loss 1.2681 | lr 2.05e-04 | grad 3.50 | tok/s 12561
step    960 | loss 1.5807 | lr 2.05e-04 | grad 4.72 | tok/s 11820
step    970 | loss 1.5933 | lr 2.05e-04 | grad 3.44 | tok/s 12265
step    980 | loss 1.3756 | lr 2.05e-04 | grad 2.56 | tok/s 12227
step    990 | loss 1.6763 | lr 2.05e-04 | grad 5.75 | tok/s 11811
step   1000 | loss 1.6682 | lr 2.05e-04 | grad 3.17 | tok/s 12227
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6682.pt
step   1010 | loss 1.4639 | lr 2.05e-04 | grad 7.47 | tok/s 3100
step   1020 | loss 1.3324 | lr 2.05e-04 | grad 2.28 | tok/s 12721
step   1030 | loss 1.3961 | lr 2.05e-04 | grad 2.50 | tok/s 11827
step   1040 | loss 1.6271 | lr 2.05e-04 | grad 4.88 | tok/s 12557
step   1050 | loss 1.6588 | lr 2.05e-04 | grad 4.88 | tok/s 12603
step   1060 | loss 1.4702 | lr 2.05e-04 | grad 2.62 | tok/s 12028
step   1070 | loss 1.3046 | lr 2.05e-04 | grad 2.59 | tok/s 11743
step   1080 | loss 1.0494 | lr 2.05e-04 | grad 2.48 | tok/s 12667
step   1090 | loss 1.4503 | lr 2.05e-04 | grad 1.96 | tok/s 12428
step   1100 | loss 1.3258 | lr 2.05e-04 | grad 2.61 | tok/s 12735
step   1110 | loss 1.2926 | lr 2.05e-04 | grad 2.33 | tok/s 12736
step   1120 | loss 1.2124 | lr 2.05e-04 | grad 2.16 | tok/s 12719
step   1130 | loss 1.2575 | lr 2.05e-04 | grad 2.05 | tok/s 12700
step   1140 | loss 1.2046 | lr 2.05e-04 | grad 2.17 | tok/s 12706
step   1150 | loss 1.1844 | lr 2.05e-04 | grad 2.20 | tok/s 12697
step   1160 | loss 1.2810 | lr 2.05e-04 | grad 2.61 | tok/s 12666
step   1170 | loss 1.2135 | lr 2.05e-04 | grad 1.63 | tok/s 12660
step   1180 | loss 1.1530 | lr 2.05e-04 | grad 2.58 | tok/s 12643
step   1190 | loss 1.2032 | lr 2.05e-04 | grad 2.28 | tok/s 12646
step   1200 | loss 1.2386 | lr 2.05e-04 | grad 2.48 | tok/s 12628
step   1210 | loss 1.1901 | lr 2.05e-04 | grad 1.70 | tok/s 12623
step   1220 | loss 1.2094 | lr 2.05e-04 | grad 2.23 | tok/s 12639
step   1230 | loss 1.5240 | lr 2.05e-04 | grad 4.62 | tok/s 12194
step   1240 | loss 1.5368 | lr 2.05e-04 | grad 4.94 | tok/s 11825
step   1250 | loss 1.2908 | lr 2.05e-04 | grad 2.22 | tok/s 12219
step   1260 | loss 1.6323 | lr 2.05e-04 | grad 3.84 | tok/s 11675
step   1270 | loss 1.4400 | lr 2.05e-04 | grad 2.72 | tok/s 12331
step   1280 | loss 1.4277 | lr 2.05e-04 | grad 2.25 | tok/s 12395
step   1290 | loss 1.4260 | lr 2.05e-04 | grad 2.81 | tok/s 11996
step   1300 | loss 1.4346 | lr 2.05e-04 | grad 4.16 | tok/s 12368
step   1310 | loss 1.6380 | lr 2.05e-04 | grad 2.42 | tok/s 12589
step   1320 | loss 1.2613 | lr 2.05e-04 | grad 2.77 | tok/s 12052
step   1330 | loss 1.6596 | lr 2.05e-04 | grad 3.56 | tok/s 11597
step   1340 | loss 1.5588 | lr 2.05e-04 | grad 2.97 | tok/s 12009
step   1350 | loss 1.3490 | lr 2.05e-04 | grad 2.75 | tok/s 11931
step   1360 | loss 1.5022 | lr 2.05e-04 | grad 2.89 | tok/s 12326
step   1370 | loss 1.4411 | lr 2.05e-04 | grad 2.61 | tok/s 11513
step   1380 | loss 1.3559 | lr 2.05e-04 | grad 3.77 | tok/s 11866
step   1390 | loss 1.3475 | lr 2.05e-04 | grad 4.34 | tok/s 12060
step   1400 | loss 1.4194 | lr 2.05e-04 | grad 2.84 | tok/s 11722
step   1410 | loss 1.4833 | lr 2.05e-04 | grad 2.05 | tok/s 12297
step   1420 | loss 1.2203 | lr 2.05e-04 | grad 2.45 | tok/s 12001
step   1430 | loss 1.0752 | lr 2.05e-04 | grad 2.61 | tok/s 12633
step   1440 | loss 1.3520 | lr 2.05e-04 | grad 3.19 | tok/s 12210
step   1450 | loss 1.4829 | lr 2.05e-04 | grad 2.69 | tok/s 11867
step   1460 | loss 1.4923 | lr 2.05e-04 | grad 5.88 | tok/s 12328
step   1470 | loss 1.7197 | lr 2.05e-04 | grad 5.28 | tok/s 12564
step   1480 | loss 1.4472 | lr 2.05e-04 | grad 2.36 | tok/s 12523
step   1490 | loss 1.2784 | lr 2.05e-04 | grad 6.84 | tok/s 12440
step   1500 | loss 1.4499 | lr 2.05e-04 | grad 2.48 | tok/s 12521
step   1510 | loss 1.4014 | lr 2.05e-04 | grad 2.39 | tok/s 12188
step   1520 | loss 1.4354 | lr 2.05e-04 | grad 5.22 | tok/s 12101
step   1530 | loss 1.4087 | lr 2.05e-04 | grad 1.90 | tok/s 12124
step   1540 | loss 1.2696 | lr 2.05e-04 | grad 3.69 | tok/s 12404
step   1550 | loss 1.4593 | lr 2.05e-04 | grad 2.75 | tok/s 11912
step   1560 | loss 1.3517 | lr 2.05e-04 | grad 2.62 | tok/s 12265
step   1570 | loss 1.6467 | lr 2.05e-04 | grad 4.56 | tok/s 12461
step   1580 | loss 1.2497 | lr 2.05e-04 | grad 1.88 | tok/s 11899
step   1590 | loss 0.7977 | lr 2.05e-04 | grad 2.19 | tok/s 12729
step   1600 | loss 1.2470 | lr 2.05e-04 | grad 2.45 | tok/s 11296
step   1610 | loss 1.4680 | lr 2.05e-04 | grad 3.34 | tok/s 12020
step   1620 | loss 1.1659 | lr 2.05e-04 | grad 4.69 | tok/s 12506
step   1630 | loss 1.4000 | lr 2.05e-04 | grad 2.25 | tok/s 11503
step   1640 | loss 1.4917 | lr 2.05e-04 | grad 2.23 | tok/s 11646
step   1650 | loss 1.1530 | lr 2.05e-04 | grad 2.20 | tok/s 12418
step   1660 | loss 1.6681 | lr 2.05e-04 | grad 3.14 | tok/s 11644
step   1670 | loss 1.4189 | lr 2.05e-04 | grad 5.84 | tok/s 11886
step   1680 | loss 1.3681 | lr 2.05e-04 | grad 4.16 | tok/s 12393
step   1690 | loss 1.3462 | lr 2.05e-04 | grad 2.28 | tok/s 11794
step   1700 | loss 1.3601 | lr 2.05e-04 | grad 2.91 | tok/s 12269
step   1710 | loss 1.3679 | lr 2.05e-04 | grad 2.69 | tok/s 12607
step   1720 | loss 1.1257 | lr 2.05e-04 | grad 2.56 | tok/s 12556
step   1730 | loss 1.4115 | lr 2.05e-04 | grad 4.00 | tok/s 12034
step   1740 | loss 1.4719 | lr 2.05e-04 | grad 3.03 | tok/s 12062
step   1750 | loss 1.5032 | lr 2.05e-04 | grad 2.12 | tok/s 12119
step   1760 | loss 1.4239 | lr 2.05e-04 | grad 4.50 | tok/s 11969
step   1770 | loss 1.3622 | lr 2.05e-04 | grad 3.50 | tok/s 12146
step   1780 | loss 1.3723 | lr 2.05e-04 | grad 2.22 | tok/s 12102
step   1790 | loss 1.5184 | lr 2.05e-04 | grad 2.14 | tok/s 11847
step   1800 | loss 1.3012 | lr 2.05e-04 | grad 2.23 | tok/s 11847
step   1810 | loss 1.3798 | lr 2.05e-04 | grad 2.39 | tok/s 12333
step   1820 | loss 1.4804 | lr 2.05e-04 | grad 10.69 | tok/s 12132
step   1830 | loss 1.3315 | lr 2.05e-04 | grad 2.23 | tok/s 11932
step   1840 | loss 1.2048 | lr 2.05e-04 | grad 3.22 | tok/s 12270
step   1850 | loss 1.3864 | lr 2.05e-04 | grad 1.95 | tok/s 11780
step   1860 | loss 1.1056 | lr 2.05e-04 | grad 3.42 | tok/s 12286
step   1870 | loss 1.3794 | lr 2.05e-04 | grad 2.00 | tok/s 11246
step   1880 | loss 1.4089 | lr 2.05e-04 | grad 2.05 | tok/s 12104
step   1890 | loss 1.3362 | lr 2.05e-04 | grad 3.08 | tok/s 11591
step   1900 | loss 1.3741 | lr 2.05e-04 | grad 2.17 | tok/s 12022
step   1910 | loss 1.3351 | lr 2.05e-04 | grad 2.00 | tok/s 12333
step   1920 | loss 1.3836 | lr 2.05e-04 | grad 2.44 | tok/s 11839
step   1930 | loss 1.6740 | lr 2.05e-04 | grad 5.62 | tok/s 12434
step   1940 | loss 1.6223 | lr 2.05e-04 | grad 3.69 | tok/s 12535
step   1950 | loss 1.3975 | lr 2.05e-04 | grad 5.75 | tok/s 12234
step   1960 | loss 1.4564 | lr 2.05e-04 | grad 2.25 | tok/s 12274
step   1970 | loss 1.3240 | lr 2.05e-04 | grad 2.05 | tok/s 11962
step   1980 | loss 1.5438 | lr 2.05e-04 | grad 2.58 | tok/s 12018
step   1990 | loss 1.4042 | lr 2.05e-04 | grad 2.02 | tok/s 12161
step   2000 | loss 0.9335 | lr 2.05e-04 | grad 2.34 | tok/s 12430
  >>> saved checkpoint: checkpoint_step_002000_loss_0.9335.pt
step   2010 | loss 1.0735 | lr 2.05e-04 | grad 1.28 | tok/s 3504
step   2020 | loss 1.2154 | lr 2.05e-04 | grad 2.38 | tok/s 12897
step   2030 | loss 1.1652 | lr 2.05e-04 | grad 2.59 | tok/s 12582
step   2040 | loss 1.4724 | lr 2.05e-04 | grad 2.69 | tok/s 11869
step   2050 | loss 1.6104 | lr 2.05e-04 | grad 3.03 | tok/s 12287
step   2060 | loss 2.0907 | lr 2.05e-04 | grad 5.47 | tok/s 12671
step   2070 | loss 1.6236 | lr 2.05e-04 | grad 4.97 | tok/s 12691
step   2080 | loss 1.2952 | lr 2.05e-04 | grad 3.09 | tok/s 12356
step   2090 | loss 1.4490 | lr 2.05e-04 | grad 13.25 | tok/s 12114
step   2100 | loss 0.8515 | lr 2.05e-04 | grad 3.05 | tok/s 12614
step   2110 | loss 0.9996 | lr 2.05e-04 | grad 4.50 | tok/s 12571
step   2120 | loss 1.4560 | lr 2.05e-04 | grad 1.89 | tok/s 12115
step   2130 | loss 1.2423 | lr 2.05e-04 | grad 2.27 | tok/s 12684
step   2140 | loss 1.1508 | lr 2.05e-04 | grad 1.80 | tok/s 12677
step   2150 | loss 1.1956 | lr 2.05e-04 | grad 1.77 | tok/s 12657
step   2160 | loss 1.1528 | lr 2.05e-04 | grad 2.52 | tok/s 12714
step   2170 | loss 1.1645 | lr 2.05e-04 | grad 1.99 | tok/s 12678
step   2180 | loss 1.1524 | lr 2.05e-04 | grad 1.91 | tok/s 12642
step   2190 | loss 1.1070 | lr 2.05e-04 | grad 1.85 | tok/s 12691
step   2200 | loss 1.0999 | lr 2.05e-04 | grad 1.85 | tok/s 12689
step   2210 | loss 1.3018 | lr 2.05e-04 | grad 2.30 | tok/s 12385
step   2220 | loss 1.3001 | lr 2.05e-04 | grad 2.17 | tok/s 12675
step   2230 | loss 1.4156 | lr 2.05e-04 | grad 3.62 | tok/s 12239
step   2240 | loss 1.4578 | lr 2.05e-04 | grad 2.11 | tok/s 12300
step   2250 | loss 1.8525 | lr 2.05e-04 | grad 6.22 | tok/s 12576
step   2260 | loss 1.4345 | lr 2.05e-04 | grad 2.69 | tok/s 12528
step   2270 | loss 1.2464 | lr 2.05e-04 | grad 3.09 | tok/s 12251
step   2280 | loss 1.6028 | lr 2.05e-04 | grad 5.50 | tok/s 12472
step   2290 | loss 1.3016 | lr 2.05e-04 | grad 1.83 | tok/s 11832
step   2300 | loss 1.5168 | lr 2.05e-04 | grad 6.31 | tok/s 11965
step   2310 | loss 1.7500 | lr 2.05e-04 | grad 2.69 | tok/s 12141
step   2320 | loss 1.3691 | lr 2.05e-04 | grad 7.38 | tok/s 11764
step   2330 | loss 1.2802 | lr 2.05e-04 | grad 5.16 | tok/s 12301
step   2340 | loss 1.2583 | lr 2.05e-04 | grad 2.72 | tok/s 12565
step   2350 | loss 1.3824 | lr 2.05e-04 | grad 4.56 | tok/s 12410
step   2360 | loss 1.4406 | lr 2.05e-04 | grad 3.08 | tok/s 12624
step   2370 | loss 1.1315 | lr 2.05e-04 | grad 2.02 | tok/s 12636
step   2380 | loss 1.0670 | lr 2.05e-04 | grad 1.80 | tok/s 12672
step   2390 | loss 1.0374 | lr 2.05e-04 | grad 2.30 | tok/s 12314
step   2400 | loss 1.3912 | lr 2.05e-04 | grad 4.75 | tok/s 11834
step   2410 | loss 1.3406 | lr 2.05e-04 | grad 2.14 | tok/s 12066
step   2420 | loss 1.1683 | lr 2.05e-04 | grad 4.72 | tok/s 12362
step   2430 | loss 1.3978 | lr 2.05e-04 | grad 2.67 | tok/s 12012
step   2440 | loss 1.2648 | lr 2.05e-04 | grad 2.59 | tok/s 12561
step   2450 | loss 1.0921 | lr 2.05e-04 | grad 2.64 | tok/s 12469
step   2460 | loss 1.1777 | lr 2.05e-04 | grad 1.95 | tok/s 12568
step   2470 | loss 1.2575 | lr 2.05e-04 | grad 2.14 | tok/s 11918
step   2480 | loss 1.4678 | lr 2.05e-04 | grad 3.20 | tok/s 12388
step   2490 | loss 1.0703 | lr 2.05e-04 | grad 3.50 | tok/s 12663
step   2500 | loss 1.3257 | lr 2.05e-04 | grad 6.16 | tok/s 12564
step   2510 | loss 1.2836 | lr 2.05e-04 | grad 2.14 | tok/s 12124
step   2520 | loss 1.3246 | lr 2.05e-04 | grad 3.52 | tok/s 12081
step   2530 | loss 1.1301 | lr 2.05e-04 | grad 1.92 | tok/s 12535
step   2540 | loss 1.3627 | lr 2.05e-04 | grad 8.88 | tok/s 11841
step   2550 | loss 1.3354 | lr 2.05e-04 | grad 2.12 | tok/s 12312
step   2560 | loss 1.2837 | lr 2.05e-04 | grad 2.70 | tok/s 11501
step   2570 | loss 1.2591 | lr 2.05e-04 | grad 2.70 | tok/s 12132
step   2580 | loss 1.4962 | lr 2.05e-04 | grad 5.12 | tok/s 11661
step   2590 | loss 1.2623 | lr 2.05e-04 | grad 3.11 | tok/s 12503
step   2600 | loss 1.4685 | lr 2.05e-04 | grad 2.50 | tok/s 12100
step   2610 | loss 1.3684 | lr 2.05e-04 | grad 2.08 | tok/s 12452
step   2620 | loss 1.3707 | lr 2.05e-04 | grad 2.44 | tok/s 12114
step   2630 | loss 1.4405 | lr 2.05e-04 | grad 4.06 | tok/s 12584
step   2640 | loss 1.2636 | lr 2.05e-04 | grad 2.47 | tok/s 12205
step   2650 | loss 1.3382 | lr 2.05e-04 | grad 3.33 | tok/s 11751
step   2660 | loss 1.4436 | lr 2.05e-04 | grad 5.44 | tok/s 11944
step   2670 | loss 1.2407 | lr 2.05e-04 | grad 1.92 | tok/s 12528
step   2680 | loss 1.3713 | lr 2.05e-04 | grad 2.22 | tok/s 12142
step   2690 | loss 1.4695 | lr 2.05e-04 | grad 3.48 | tok/s 12034
step   2700 | loss 1.2717 | lr 2.05e-04 | grad 2.30 | tok/s 11513
step   2710 | loss 1.1058 | lr 2.05e-04 | grad 1.87 | tok/s 12392
step   2720 | loss 1.5549 | lr 2.05e-04 | grad 7.06 | tok/s 12177
step   2730 | loss 1.5140 | lr 2.05e-04 | grad 2.41 | tok/s 12506
step   2740 | loss 1.2527 | lr 2.05e-04 | grad 2.31 | tok/s 11638
step   2750 | loss 1.4319 | lr 2.05e-04 | grad 3.20 | tok/s 12016
step   2760 | loss 1.0383 | lr 2.05e-04 | grad 1.95 | tok/s 12596
step   2770 | loss 1.5496 | lr 2.05e-04 | grad 5.78 | tok/s 11818
step   2780 | loss 1.3315 | lr 2.05e-04 | grad 1.84 | tok/s 12082
step   2790 | loss 1.1858 | lr 2.05e-04 | grad 2.45 | tok/s 12027
step   2800 | loss 1.3351 | lr 2.05e-04 | grad 1.79 | tok/s 11623
step   2810 | loss 1.0726 | lr 2.05e-04 | grad 2.95 | tok/s 12420
step   2820 | loss 0.7023 | lr 2.05e-04 | grad 2.75 | tok/s 12642
step   2830 | loss 1.6793 | lr 2.05e-04 | grad 2.75 | tok/s 12229
step   2840 | loss 1.5171 | lr 2.05e-04 | grad 1.84 | tok/s 12155
step   2850 | loss 1.2895 | lr 2.05e-04 | grad 2.19 | tok/s 11907
step   2860 | loss 1.4235 | lr 2.05e-04 | grad 3.78 | tok/s 12246
step   2870 | loss 1.1903 | lr 2.05e-04 | grad 2.52 | tok/s 12596
step   2880 | loss 1.3753 | lr 2.05e-04 | grad 2.06 | tok/s 12133
step   2890 | loss 1.2744 | lr 2.05e-04 | grad 1.86 | tok/s 12115
step   2900 | loss 1.4571 | lr 2.05e-04 | grad 2.69 | tok/s 11796
step   2910 | loss 1.4901 | lr 2.05e-04 | grad 2.14 | tok/s 12290
step   2920 | loss 1.2242 | lr 2.05e-04 | grad 2.58 | tok/s 11340
step   2930 | loss 1.2926 | lr 2.05e-04 | grad 2.66 | tok/s 12139
step   2940 | loss 1.2338 | lr 2.05e-04 | grad 3.50 | tok/s 12298
step   2950 | loss 1.2499 | lr 2.05e-04 | grad 2.83 | tok/s 12334
step   2960 | loss 1.6419 | lr 2.05e-04 | grad 2.02 | tok/s 11938
step   2970 | loss 1.8175 | lr 2.05e-04 | grad 3.14 | tok/s 12250
step   2980 | loss 1.2916 | lr 2.05e-04 | grad 4.84 | tok/s 12303
step   2990 | loss 1.1934 | lr 2.05e-04 | grad 3.05 | tok/s 12260
step   3000 | loss 1.0485 | lr 2.05e-04 | grad 2.77 | tok/s 12022
  >>> saved checkpoint: checkpoint_step_003000_loss_1.0485.pt
step   3010 | loss 1.3492 | lr 2.05e-04 | grad 3.05 | tok/s 3362
step   3020 | loss 1.3777 | lr 2.05e-04 | grad 2.67 | tok/s 12510
step   3030 | loss 1.2580 | lr 2.05e-04 | grad 1.89 | tok/s 12432
step   3040 | loss 1.4715 | lr 2.05e-04 | grad 3.45 | tok/s 12635
step   3050 | loss 1.3985 | lr 2.05e-04 | grad 1.73 | tok/s 12752
step   3060 | loss 1.3514 | lr 2.05e-04 | grad 2.59 | tok/s 12318
step   3070 | loss 1.2653 | lr 2.05e-04 | grad 2.06 | tok/s 12236
step   3080 | loss 1.4349 | lr 2.05e-04 | grad 3.34 | tok/s 12478
step   3090 | loss 0.9459 | lr 2.05e-04 | grad 2.00 | tok/s 12741
step   3100 | loss 1.0555 | lr 2.05e-04 | grad 2.50 | tok/s 12779
step   3110 | loss 1.2874 | lr 2.05e-04 | grad 2.05 | tok/s 12065
step   3120 | loss 0.9781 | lr 2.05e-04 | grad 2.33 | tok/s 12734
step   3130 | loss 1.1722 | lr 2.05e-04 | grad 2.64 | tok/s 12550
step   3140 | loss 1.4435 | lr 2.05e-04 | grad 2.14 | tok/s 11772
step   3150 | loss 1.2572 | lr 2.05e-04 | grad 2.98 | tok/s 12013
step   3160 | loss 1.2611 | lr 2.05e-04 | grad 2.75 | tok/s 12297
step   3170 | loss 0.9236 | lr 2.05e-04 | grad 4.50 | tok/s 12660
step   3180 | loss 1.4075 | lr 2.05e-04 | grad 2.33 | tok/s 12269
step   3190 | loss 1.6331 | lr 2.05e-04 | grad 2.47 | tok/s 12321
step   3200 | loss 2.1948 | lr 2.05e-04 | grad 3.78 | tok/s 12644
step   3210 | loss 1.7666 | lr 2.05e-04 | grad 2.62 | tok/s 12639
step   3220 | loss 1.5361 | lr 2.05e-04 | grad 2.61 | tok/s 12652
step   3230 | loss 1.4645 | lr 2.05e-04 | grad 3.16 | tok/s 12625
step   3240 | loss 1.3985 | lr 2.05e-04 | grad 2.72 | tok/s 12637
step   3250 | loss 1.3541 | lr 2.05e-04 | grad 2.94 | tok/s 12662
step   3260 | loss 1.2847 | lr 2.05e-04 | grad 2.75 | tok/s 12572
step   3270 | loss 1.2543 | lr 2.05e-04 | grad 2.52 | tok/s 12630
step   3280 | loss 1.2686 | lr 2.05e-04 | grad 3.06 | tok/s 12592
step   3290 | loss 1.2263 | lr 2.05e-04 | grad 2.11 | tok/s 12632
step   3300 | loss 1.2304 | lr 2.05e-04 | grad 2.81 | tok/s 12622
step   3310 | loss 1.5278 | lr 2.05e-04 | grad 3.84 | tok/s 12223
step   3320 | loss 1.3217 | lr 2.05e-04 | grad 2.47 | tok/s 12169
step   3330 | loss 1.3459 | lr 2.05e-04 | grad 2.25 | tok/s 11834
step   3340 | loss 1.3571 | lr 2.05e-04 | grad 4.16 | tok/s 11776
step   3350 | loss 1.4105 | lr 2.05e-04 | grad 2.30 | tok/s 12036
step   3360 | loss 1.4158 | lr 2.05e-04 | grad 3.09 | tok/s 12176
step   3370 | loss 1.2509 | lr 2.05e-04 | grad 1.95 | tok/s 12256
step   3380 | loss 1.0452 | lr 2.05e-04 | grad 2.53 | tok/s 12655
step   3390 | loss 1.1007 | lr 2.05e-04 | grad 3.31 | tok/s 12557
step   3400 | loss 1.4204 | lr 2.05e-04 | grad 2.09 | tok/s 11775
step   3410 | loss 1.3693 | lr 2.05e-04 | grad 3.20 | tok/s 11924
step   3420 | loss 1.3186 | lr 2.05e-04 | grad 2.25 | tok/s 12263
step   3430 | loss 1.3601 | lr 2.05e-04 | grad 2.19 | tok/s 12159
step   3440 | loss 1.2897 | lr 2.05e-04 | grad 2.06 | tok/s 12266
step   3450 | loss 1.3529 | lr 2.05e-04 | grad 2.16 | tok/s 12374
step   3460 | loss 1.2952 | lr 2.05e-04 | grad 1.96 | tok/s 12529
step   3470 | loss 1.1679 | lr 2.05e-04 | grad 1.91 | tok/s 11768
step   3480 | loss 1.1637 | lr 2.05e-04 | grad 2.52 | tok/s 12188
step   3490 | loss 1.3647 | lr 2.05e-04 | grad 2.42 | tok/s 12148
step   3500 | loss 1.4756 | lr 2.05e-04 | grad 4.00 | tok/s 12080
step   3510 | loss 1.4921 | lr 2.05e-04 | grad 2.75 | tok/s 12387
step   3520 | loss 1.3286 | lr 2.05e-04 | grad 2.14 | tok/s 11934
step   3530 | loss 1.9210 | lr 2.05e-04 | grad 2.70 | tok/s 11502
step   3540 | loss 1.4085 | lr 2.05e-04 | grad 4.16 | tok/s 11656
step   3550 | loss 1.1584 | lr 2.05e-04 | grad 2.45 | tok/s 12327
step   3560 | loss 1.0369 | lr 2.05e-04 | grad 2.83 | tok/s 12049
step   3570 | loss 1.2217 | lr 2.05e-04 | grad 2.72 | tok/s 12198
step   3580 | loss 1.4217 | lr 2.05e-04 | grad 2.70 | tok/s 11469
step   3590 | loss 1.2879 | lr 2.05e-04 | grad 1.97 | tok/s 12349
step   3600 | loss 1.3316 | lr 2.05e-04 | grad 3.39 | tok/s 12271
step   3610 | loss 1.3854 | lr 2.05e-04 | grad 3.95 | tok/s 12138
step   3620 | loss 1.4013 | lr 2.05e-04 | grad 3.00 | tok/s 11856
step   3630 | loss 1.2962 | lr 2.05e-04 | grad 2.50 | tok/s 11863
step   3640 | loss 1.3245 | lr 2.05e-04 | grad 2.80 | tok/s 11657
step   3650 | loss 1.1926 | lr 2.05e-04 | grad 2.33 | tok/s 12605
step   3660 | loss 1.2076 | lr 2.05e-04 | grad 2.34 | tok/s 11945
step   3670 | loss 1.2995 | lr 2.05e-04 | grad 4.38 | tok/s 11973
step   3680 | loss 1.2800 | lr 2.05e-04 | grad 2.86 | tok/s 11496
step   3690 | loss 1.4331 | lr 2.05e-04 | grad 3.16 | tok/s 12568
step   3700 | loss 1.3921 | lr 2.05e-04 | grad 4.50 | tok/s 12198
step   3710 | loss 1.3654 | lr 2.05e-04 | grad 2.72 | tok/s 12023
step   3720 | loss 1.0275 | lr 2.05e-04 | grad 2.27 | tok/s 12193
step   3730 | loss 1.5148 | lr 2.05e-04 | grad 1.86 | tok/s 12440
step   3740 | loss 1.2266 | lr 2.05e-04 | grad 1.58 | tok/s 12678
step   3750 | loss 1.1863 | lr 2.05e-04 | grad 1.97 | tok/s 12617
step   3760 | loss 1.1642 | lr 2.05e-04 | grad 1.91 | tok/s 12673
step   3770 | loss 1.1362 | lr 2.05e-04 | grad 2.69 | tok/s 12608
step   3780 | loss 1.1487 | lr 2.05e-04 | grad 2.11 | tok/s 12609
step   3790 | loss 1.1086 | lr 2.05e-04 | grad 2.06 | tok/s 12594
step   3800 | loss 1.0988 | lr 2.05e-04 | grad 1.96 | tok/s 12618
step   3810 | loss 1.0973 | lr 2.05e-04 | grad 1.80 | tok/s 12565
step   3820 | loss 1.0915 | lr 2.05e-04 | grad 1.81 | tok/s 12658
step   3830 | loss 1.0480 | lr 2.05e-04 | grad 2.03 | tok/s 12598
step   3840 | loss 1.3804 | lr 2.05e-04 | grad 2.78 | tok/s 12116
step   3850 | loss 1.4721 | lr 2.05e-04 | grad 4.88 | tok/s 12002
step   3860 | loss 1.2757 | lr 2.05e-04 | grad 2.84 | tok/s 11658
step   3870 | loss 1.3953 | lr 2.05e-04 | grad 3.62 | tok/s 11994
step   3880 | loss 1.3269 | lr 2.05e-04 | grad 2.77 | tok/s 12223
step   3890 | loss 1.1983 | lr 2.05e-04 | grad 1.80 | tok/s 12032
step   3900 | loss 1.5183 | lr 2.05e-04 | grad 2.27 | tok/s 11963
step   3910 | loss 1.3447 | lr 2.05e-04 | grad 2.97 | tok/s 12371
step   3920 | loss 1.3903 | lr 2.05e-04 | grad 2.27 | tok/s 12172
step   3930 | loss 1.3041 | lr 2.05e-04 | grad 3.84 | tok/s 11568
step   3940 | loss 1.3149 | lr 2.05e-04 | grad 4.62 | tok/s 12634
step   3950 | loss 1.3710 | lr 2.05e-04 | grad 3.89 | tok/s 11960
step   3960 | loss 1.4294 | lr 2.05e-04 | grad 4.28 | tok/s 12432
step   3970 | loss 0.8893 | lr 2.05e-04 | grad 3.14 | tok/s 12884
step   3980 | loss 0.9862 | lr 2.05e-04 | grad 2.02 | tok/s 12649
step   3990 | loss 1.0653 | lr 2.05e-04 | grad 2.92 | tok/s 12515
step   4000 | loss 1.3789 | lr 2.05e-04 | grad 2.23 | tok/s 11133
  >>> saved checkpoint: checkpoint_step_004000_loss_1.3789.pt
step   4010 | loss 1.3222 | lr 2.05e-04 | grad 2.05 | tok/s 3416
step   4020 | loss 1.3364 | lr 2.05e-04 | grad 2.19 | tok/s 11994
step   4030 | loss 1.9674 | lr 2.05e-04 | grad 4.38 | tok/s 12311
step   4040 | loss 1.4257 | lr 2.05e-04 | grad 4.28 | tok/s 12232
step   4050 | loss 1.3128 | lr 2.05e-04 | grad 2.23 | tok/s 12392
step   4060 | loss 1.2284 | lr 2.05e-04 | grad 2.27 | tok/s 12359
step   4070 | loss 1.2642 | lr 2.05e-04 | grad 1.89 | tok/s 12248
step   4080 | loss 1.2951 | lr 2.05e-04 | grad 2.05 | tok/s 12763
step   4090 | loss 1.5667 | lr 2.05e-04 | grad 3.34 | tok/s 12210
step   4100 | loss 1.4598 | lr 2.05e-04 | grad 3.08 | tok/s 11939
step   4110 | loss 0.8470 | lr 2.05e-04 | grad 1.77 | tok/s 12930
step   4120 | loss 1.2461 | lr 2.05e-04 | grad 2.39 | tok/s 11534
step   4130 | loss 1.1230 | lr 2.05e-04 | grad 2.19 | tok/s 12007
step   4140 | loss 0.8920 | lr 2.05e-04 | grad 2.31 | tok/s 12490
step   4150 | loss 1.5619 | lr 2.05e-04 | grad 4.00 | tok/s 12567
step   4160 | loss 1.5928 | lr 2.05e-04 | grad 6.09 | tok/s 12585
step   4170 | loss 1.1047 | lr 2.05e-04 | grad 3.97 | tok/s 12671
step   4180 | loss 1.3844 | lr 2.05e-04 | grad 3.78 | tok/s 12132
step   4190 | loss 1.2145 | lr 2.05e-04 | grad 2.36 | tok/s 11922
step   4200 | loss 2.0094 | lr 2.05e-04 | grad 3.47 | tok/s 12267
step   4210 | loss 1.7794 | lr 2.05e-04 | grad 3.23 | tok/s 12249
step   4220 | loss 1.4390 | lr 2.05e-04 | grad 1.98 | tok/s 11930
step   4230 | loss 1.2467 | lr 2.05e-04 | grad 1.91 | tok/s 11774
step   4240 | loss 1.3759 | lr 2.05e-04 | grad 2.12 | tok/s 12547
step   4250 | loss 1.3918 | lr 2.05e-04 | grad 1.99 | tok/s 12117
step   4260 | loss 1.4387 | lr 2.05e-04 | grad 4.47 | tok/s 11862
step   4270 | loss 1.7104 | lr 2.05e-04 | grad 2.52 | tok/s 12632
step   4280 | loss 1.3203 | lr 2.05e-04 | grad 1.73 | tok/s 11965
step   4290 | loss 1.3778 | lr 2.05e-04 | grad 2.34 | tok/s 12399
step   4300 | loss 1.2973 | lr 2.05e-04 | grad 3.17 | tok/s 12042
step   4310 | loss 1.2972 | lr 2.05e-04 | grad 3.33 | tok/s 12454
step   4320 | loss 1.1127 | lr 2.05e-04 | grad 2.17 | tok/s 12672
step   4330 | loss 0.9429 | lr 2.05e-04 | grad 4.03 | tok/s 12561
step   4340 | loss 1.2876 | lr 2.05e-04 | grad 2.12 | tok/s 12271
step   4350 | loss 1.3618 | lr 2.05e-04 | grad 2.06 | tok/s 11948
step   4360 | loss 1.2008 | lr 2.05e-04 | grad 2.06 | tok/s 12448
step   4370 | loss 1.0530 | lr 2.05e-04 | grad 2.94 | tok/s 12603
step   4380 | loss 1.1486 | lr 2.05e-04 | grad 3.30 | tok/s 12579
step   4390 | loss 1.3523 | lr 2.05e-04 | grad 2.31 | tok/s 12083
step   4400 | loss 1.1857 | lr 2.05e-04 | grad 3.06 | tok/s 12021
step   4410 | loss 1.4548 | lr 2.05e-04 | grad 2.09 | tok/s 11632
step   4420 | loss 1.3740 | lr 2.05e-04 | grad 1.98 | tok/s 11540
step   4430 | loss 1.7133 | lr 2.05e-04 | grad 4.34 | tok/s 12323
step   4440 | loss 1.1909 | lr 2.05e-04 | grad 2.70 | tok/s 12561
step   4450 | loss 1.2851 | lr 2.05e-04 | grad 1.81 | tok/s 12029
step   4460 | loss 1.4190 | lr 2.05e-04 | grad 4.41 | tok/s 12030
step   4470 | loss 1.2054 | lr 2.05e-04 | grad 2.38 | tok/s 11914
step   4480 | loss 1.3932 | lr 2.05e-04 | grad 6.56 | tok/s 12422
step   4490 | loss 1.4404 | lr 2.05e-04 | grad 2.91 | tok/s 12517
step   4500 | loss 1.5384 | lr 2.05e-04 | grad 2.06 | tok/s 11642
step   4510 | loss 1.5506 | lr 2.05e-04 | grad 5.81 | tok/s 11700
step   4520 | loss 1.4390 | lr 2.05e-04 | grad 2.12 | tok/s 11755
step   4530 | loss 1.2966 | lr 2.05e-04 | grad 2.64 | tok/s 12393
step   4540 | loss 1.1042 | lr 2.05e-04 | grad 1.80 | tok/s 12380
step   4550 | loss 1.2409 | lr 2.05e-04 | grad 2.69 | tok/s 11606
step   4560 | loss 1.6478 | lr 2.05e-04 | grad 3.03 | tok/s 11629
step   4570 | loss 1.2692 | lr 2.05e-04 | grad 4.66 | tok/s 12071
step   4580 | loss 1.5723 | lr 2.05e-04 | grad 2.11 | tok/s 12099
step   4590 | loss 1.1273 | lr 2.05e-04 | grad 2.97 | tok/s 12336
step   4600 | loss 1.3667 | lr 2.05e-04 | grad 2.12 | tok/s 12588
step   4610 | loss 1.2806 | lr 2.05e-04 | grad 2.19 | tok/s 12616
step   4620 | loss 1.2339 | lr 2.05e-04 | grad 1.98 | tok/s 12614
step   4630 | loss 1.2247 | lr 2.05e-04 | grad 1.84 | tok/s 12610
step   4640 | loss 1.2071 | lr 2.05e-04 | grad 1.94 | tok/s 12572
step   4650 | loss 1.1799 | lr 2.05e-04 | grad 2.08 | tok/s 12595
step   4660 | loss 1.1869 | lr 2.05e-04 | grad 1.86 | tok/s 12613
step   4670 | loss 1.1526 | lr 2.05e-04 | grad 1.77 | tok/s 12583
step   4680 | loss 1.1978 | lr 2.05e-04 | grad 1.93 | tok/s 12600
step   4690 | loss 1.0878 | lr 2.05e-04 | grad 1.84 | tok/s 12590
step   4700 | loss 1.0900 | lr 2.05e-04 | grad 2.03 | tok/s 12538
step   4710 | loss 1.1571 | lr 2.05e-04 | grad 1.71 | tok/s 12561
step   4720 | loss 1.1302 | lr 2.05e-04 | grad 1.85 | tok/s 12597
step   4730 | loss 1.0820 | lr 2.05e-04 | grad 1.85 | tok/s 12590
step   4740 | loss 1.1166 | lr 2.05e-04 | grad 1.88 | tok/s 12626
step   4750 | loss 1.1179 | lr 2.05e-04 | grad 2.11 | tok/s 12575
step   4760 | loss 1.0921 | lr 2.05e-04 | grad 1.92 | tok/s 12592
step   4770 | loss 1.0809 | lr 2.05e-04 | grad 1.98 | tok/s 12589
step   4780 | loss 1.0606 | lr 2.05e-04 | grad 2.08 | tok/s 12613
step   4790 | loss 1.2760 | lr 2.05e-04 | grad 2.53 | tok/s 12449
step   4800 | loss 1.6152 | lr 2.05e-04 | grad 2.11 | tok/s 12088
step   4810 | loss 1.1307 | lr 2.05e-04 | grad 1.76 | tok/s 12471
step   4820 | loss 0.7245 | lr 2.05e-04 | grad 6.78 | tok/s 12506
step   4830 | loss 1.2965 | lr 2.05e-04 | grad 2.38 | tok/s 12029
step   4840 | loss 1.3837 | lr 2.05e-04 | grad 5.91 | tok/s 11652
step   4850 | loss 1.2900 | lr 2.05e-04 | grad 2.61 | tok/s 11423
step   4860 | loss 1.2439 | lr 2.05e-04 | grad 3.20 | tok/s 12381
step   4870 | loss 1.2378 | lr 2.05e-04 | grad 1.88 | tok/s 12022
step   4880 | loss 1.4040 | lr 2.05e-04 | grad 3.25 | tok/s 12345
step   4890 | loss 1.4356 | lr 2.05e-04 | grad 2.38 | tok/s 12406
step   4900 | loss 1.1540 | lr 2.05e-04 | grad 2.86 | tok/s 12601
step   4910 | loss 1.2732 | lr 2.05e-04 | grad 2.94 | tok/s 11886
step   4920 | loss 1.3078 | lr 2.05e-04 | grad 4.34 | tok/s 11902
step   4930 | loss 1.3796 | lr 2.05e-04 | grad 6.16 | tok/s 12501
step   4940 | loss 1.1409 | lr 2.05e-04 | grad 2.22 | tok/s 12493
step   4950 | loss 1.4484 | lr 2.05e-04 | grad 2.88 | tok/s 12183
step   4960 | loss 1.2821 | lr 2.05e-04 | grad 2.34 | tok/s 11851
step   4970 | loss 1.4449 | lr 2.05e-04 | grad 3.48 | tok/s 12512
step   4980 | loss 1.3590 | lr 2.05e-04 | grad 1.83 | tok/s 11976
step   4990 | loss 1.3775 | lr 2.05e-04 | grad 1.87 | tok/s 12426
step   5000 | loss 1.2382 | lr 2.05e-04 | grad 2.56 | tok/s 11955
  >>> saved checkpoint: checkpoint_step_005000_loss_1.2382.pt
step   5010 | loss 1.3138 | lr 2.05e-04 | grad 3.17 | tok/s 3322
step   5020 | loss 1.3868 | lr 2.05e-04 | grad 3.30 | tok/s 12575
step   5030 | loss 1.4467 | lr 2.05e-04 | grad 3.20 | tok/s 12217
step   5040 | loss 1.2707 | lr 2.05e-04 | grad 2.44 | tok/s 11825
step   5050 | loss 1.3678 | lr 2.05e-04 | grad 2.23 | tok/s 12179
step   5060 | loss 1.1078 | lr 2.05e-04 | grad 2.72 | tok/s 12626
step   5070 | loss 1.4821 | lr 2.05e-04 | grad 2.84 | tok/s 11920
step   5080 | loss 1.2763 | lr 2.05e-04 | grad 3.78 | tok/s 12334
step   5090 | loss 1.2772 | lr 2.05e-04 | grad 2.66 | tok/s 11982
step   5100 | loss 1.2794 | lr 2.05e-04 | grad 2.31 | tok/s 12387
step   5110 | loss 1.5552 | lr 2.05e-04 | grad 7.25 | tok/s 12487
step   5120 | loss 1.2860 | lr 2.05e-04 | grad 2.27 | tok/s 11999
step   5130 | loss 1.3795 | lr 2.05e-04 | grad 2.22 | tok/s 11719
step   5140 | loss 1.1719 | lr 2.05e-04 | grad 2.67 | tok/s 12419
step   5150 | loss 1.3070 | lr 2.05e-04 | grad 1.85 | tok/s 11099
step   5160 | loss 1.4364 | lr 2.05e-04 | grad 2.20 | tok/s 12768
step   5170 | loss 1.2947 | lr 2.05e-04 | grad 4.38 | tok/s 12433
step   5180 | loss 1.1845 | lr 2.05e-04 | grad 1.95 | tok/s 12674
step   5190 | loss 1.2190 | lr 2.05e-04 | grad 2.91 | tok/s 12020
step   5200 | loss 1.4957 | lr 2.05e-04 | grad 2.53 | tok/s 12123
step   5210 | loss 1.1679 | lr 2.05e-04 | grad 2.00 | tok/s 12687
step   5220 | loss 1.0707 | lr 2.05e-04 | grad 1.79 | tok/s 12500
step   5230 | loss 1.0967 | lr 2.05e-04 | grad 2.73 | tok/s 12331
step   5240 | loss 1.3513 | lr 2.05e-04 | grad 2.20 | tok/s 11777
step   5250 | loss 1.2392 | lr 2.05e-04 | grad 1.73 | tok/s 11940
step   5260 | loss 1.1107 | lr 2.05e-04 | grad 1.98 | tok/s 12485
step   5270 | loss 1.1620 | lr 2.05e-04 | grad 2.34 | tok/s 11954
step   5280 | loss 1.2293 | lr 2.05e-04 | grad 1.88 | tok/s 12527

Training complete! Final step: 5285
