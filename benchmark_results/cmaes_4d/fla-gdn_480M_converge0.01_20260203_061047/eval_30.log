Using device: cuda
Output directory: benchmark_results/cmaes_4d/fla-gdn_480M_converge0.01_20260203_061047/eval_30/levelfla-gdn_100m_20260203_074155
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 473,801,056 parameters
Using schedule-free AdamW (lr=0.0006374165881246004)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 4.2966 | lr 6.37e-04 | grad 9.88 | tok/s 10652
step     20 | loss 2.6116 | lr 6.37e-04 | grad 3.64 | tok/s 23387
step     30 | loss 2.8248 | lr 6.37e-04 | grad 4.53 | tok/s 24652
step     40 | loss 3.8533 | lr 6.37e-04 | grad 17.50 | tok/s 25071
step     50 | loss 3.6033 | lr 6.37e-04 | grad 12.06 | tok/s 25262
step     60 | loss 3.0935 | lr 6.37e-04 | grad 5.66 | tok/s 25110
step     70 | loss 2.7858 | lr 6.37e-04 | grad 4.22 | tok/s 25012
step     80 | loss 2.2616 | lr 6.37e-04 | grad 3.12 | tok/s 24963
step     90 | loss 2.0839 | lr 6.37e-04 | grad 2.77 | tok/s 24881
step    100 | loss 1.9480 | lr 6.37e-04 | grad 2.48 | tok/s 24862
step    110 | loss 1.9211 | lr 6.37e-04 | grad 3.55 | tok/s 24663
step    120 | loss 2.5693 | lr 6.37e-04 | grad 3.03 | tok/s 23493
step    130 | loss 1.8631 | lr 6.37e-04 | grad 4.97 | tok/s 24019
step    140 | loss 2.1743 | lr 6.37e-04 | grad 6.81 | tok/s 24132
step    150 | loss 1.2638 | lr 6.37e-04 | grad 5.19 | tok/s 24615
step    160 | loss 2.0568 | lr 6.37e-04 | grad 2.12 | tok/s 23781
step    170 | loss 2.0844 | lr 6.37e-04 | grad 1.81 | tok/s 23402
step    180 | loss 1.5379 | lr 6.37e-04 | grad 2.69 | tok/s 23957
step    190 | loss 1.7159 | lr 6.37e-04 | grad 2.38 | tok/s 23520
step    200 | loss 1.4586 | lr 6.37e-04 | grad 1.51 | tok/s 24520
step    210 | loss 1.6689 | lr 6.37e-04 | grad 3.92 | tok/s 23321
step    220 | loss 2.0016 | lr 6.37e-04 | grad 2.25 | tok/s 23569
step    230 | loss 1.7296 | lr 6.37e-04 | grad 2.25 | tok/s 23526
step    240 | loss 2.0459 | lr 6.37e-04 | grad 4.88 | tok/s 23827
step    250 | loss 1.5920 | lr 6.37e-04 | grad 1.64 | tok/s 23688
step    260 | loss 1.7017 | lr 6.37e-04 | grad 2.25 | tok/s 24339
step    270 | loss 1.6518 | lr 6.37e-04 | grad 1.80 | tok/s 23771
step    280 | loss 1.6143 | lr 6.37e-04 | grad 1.70 | tok/s 22376
step    290 | loss 1.5023 | lr 6.37e-04 | grad 1.83 | tok/s 23145
step    300 | loss 1.7746 | lr 6.37e-04 | grad 1.80 | tok/s 23356
step    310 | loss 1.5240 | lr 6.37e-04 | grad 1.40 | tok/s 23199
step    320 | loss 1.7230 | lr 6.37e-04 | grad 3.28 | tok/s 23491
step    330 | loss 1.5610 | lr 6.37e-04 | grad 1.85 | tok/s 23726
step    340 | loss 1.8734 | lr 6.37e-04 | grad 2.20 | tok/s 23635
step    350 | loss 1.5563 | lr 6.37e-04 | grad 1.65 | tok/s 24262
step    360 | loss 1.4470 | lr 6.37e-04 | grad 1.53 | tok/s 23261
step    370 | loss 1.3361 | lr 6.37e-04 | grad 1.30 | tok/s 24471
step    380 | loss 1.0676 | lr 6.37e-04 | grad 1.02 | tok/s 24640
step    390 | loss 0.9727 | lr 6.37e-04 | grad 1.32 | tok/s 24657
step    400 | loss 1.6046 | lr 6.37e-04 | grad 1.42 | tok/s 23372
step    410 | loss 1.6070 | lr 6.37e-04 | grad 1.93 | tok/s 23607
step    420 | loss 1.4660 | lr 6.37e-04 | grad 1.95 | tok/s 24578
step    430 | loss 1.4389 | lr 6.37e-04 | grad 1.59 | tok/s 24166
step    440 | loss 1.5509 | lr 6.37e-04 | grad 1.93 | tok/s 23463
step    450 | loss 1.4998 | lr 6.37e-04 | grad 1.16 | tok/s 23720
step    460 | loss 1.4706 | lr 6.37e-04 | grad 1.21 | tok/s 24055
step    470 | loss 1.4420 | lr 6.37e-04 | grad 2.91 | tok/s 23910
step    480 | loss 1.4750 | lr 6.37e-04 | grad 2.30 | tok/s 24415
step    490 | loss 1.5562 | lr 6.37e-04 | grad 1.92 | tok/s 23437
step    500 | loss 1.6658 | lr 6.37e-04 | grad 1.05 | tok/s 23808
step    510 | loss 1.5541 | lr 6.37e-04 | grad 1.09 | tok/s 22780
step    520 | loss 1.4129 | lr 6.37e-04 | grad 1.59 | tok/s 23814
step    530 | loss 1.5739 | lr 6.37e-04 | grad 1.55 | tok/s 23420
step    540 | loss 1.4515 | lr 6.37e-04 | grad 1.24 | tok/s 22946
step    550 | loss 1.2375 | lr 6.37e-04 | grad 2.75 | tok/s 24017
step    560 | loss 1.3235 | lr 6.37e-04 | grad 1.66 | tok/s 24605
step    570 | loss 1.2277 | lr 6.37e-04 | grad 1.46 | tok/s 24618
step    580 | loss 1.1871 | lr 6.37e-04 | grad 1.24 | tok/s 24628
step    590 | loss 1.2209 | lr 6.37e-04 | grad 1.24 | tok/s 24587
step    600 | loss 1.1463 | lr 6.37e-04 | grad 1.20 | tok/s 24606
step    610 | loss 1.1975 | lr 6.37e-04 | grad 1.42 | tok/s 24574
step    620 | loss 1.1700 | lr 6.37e-04 | grad 1.26 | tok/s 24510
step    630 | loss 1.5159 | lr 6.37e-04 | grad 4.19 | tok/s 23265
step    640 | loss 1.6115 | lr 6.37e-04 | grad 1.19 | tok/s 23487
step    650 | loss 1.4236 | lr 6.37e-04 | grad 1.28 | tok/s 23503
step    660 | loss 1.4756 | lr 6.37e-04 | grad 1.37 | tok/s 24364
step    670 | loss 1.4811 | lr 6.37e-04 | grad 3.47 | tok/s 23548
step    680 | loss 1.4867 | lr 6.37e-04 | grad 1.62 | tok/s 23207
step    690 | loss 1.4356 | lr 6.37e-04 | grad 1.27 | tok/s 23016
step    700 | loss 1.3428 | lr 6.37e-04 | grad 0.93 | tok/s 23511
step    710 | loss 1.4844 | lr 6.37e-04 | grad 3.61 | tok/s 23165
step    720 | loss 1.1946 | lr 6.37e-04 | grad 1.19 | tok/s 24045
step    730 | loss 1.3190 | lr 6.37e-04 | grad 1.14 | tok/s 23686
step    740 | loss 1.6289 | lr 6.37e-04 | grad 3.02 | tok/s 24295
step    750 | loss 1.3897 | lr 6.37e-04 | grad 1.39 | tok/s 24592
step    760 | loss 1.3836 | lr 6.37e-04 | grad 2.95 | tok/s 24074
step    770 | loss 1.4424 | lr 6.37e-04 | grad 1.42 | tok/s 23664
step    780 | loss 1.3654 | lr 6.37e-04 | grad 1.16 | tok/s 23811
step    790 | loss 1.4650 | lr 6.37e-04 | grad 3.53 | tok/s 24315
step    800 | loss 1.2120 | lr 6.37e-04 | grad 1.34 | tok/s 24003
step    810 | loss 1.1994 | lr 6.37e-04 | grad 1.69 | tok/s 23202
step    820 | loss 1.2973 | lr 6.37e-04 | grad 1.19 | tok/s 23601
step    830 | loss 1.3771 | lr 6.37e-04 | grad 1.05 | tok/s 23321
step    840 | loss 1.4908 | lr 6.37e-04 | grad 1.34 | tok/s 23234
step    850 | loss 1.3769 | lr 6.37e-04 | grad 0.93 | tok/s 23683
step    860 | loss 1.4172 | lr 6.37e-04 | grad 2.45 | tok/s 24042
step    870 | loss 1.2225 | lr 6.37e-04 | grad 1.16 | tok/s 24254
step    880 | loss 1.4622 | lr 6.37e-04 | grad 1.34 | tok/s 23725
step    890 | loss 1.3749 | lr 6.37e-04 | grad 1.10 | tok/s 23660
step    900 | loss 1.4099 | lr 6.37e-04 | grad 1.06 | tok/s 23541
step    910 | loss 1.3773 | lr 6.37e-04 | grad 4.47 | tok/s 23311
step    920 | loss 1.3470 | lr 6.37e-04 | grad 1.30 | tok/s 23578
step    930 | loss 1.2686 | lr 6.37e-04 | grad 1.34 | tok/s 23839
step    940 | loss 1.2267 | lr 6.37e-04 | grad 0.95 | tok/s 23326
step    950 | loss 1.3731 | lr 6.37e-04 | grad 1.71 | tok/s 22976
step    960 | loss 1.3304 | lr 6.37e-04 | grad 1.27 | tok/s 23539
step    970 | loss 1.3661 | lr 6.37e-04 | grad 1.17 | tok/s 23598
step    980 | loss 1.6992 | lr 6.37e-04 | grad 2.64 | tok/s 24494
step    990 | loss 1.4226 | lr 6.37e-04 | grad 1.34 | tok/s 23537
step   1000 | loss 1.4497 | lr 6.37e-04 | grad 1.84 | tok/s 23577
  >>> saved checkpoint: checkpoint_step_001000_loss_1.4497.pt
step   1010 | loss 1.2443 | lr 6.37e-04 | grad 1.24 | tok/s 11240
step   1020 | loss 1.0912 | lr 6.37e-04 | grad 1.02 | tok/s 24985
step   1030 | loss 1.4616 | lr 6.37e-04 | grad 1.30 | tok/s 23502
step   1040 | loss 1.9527 | lr 6.37e-04 | grad 2.44 | tok/s 24259
step   1050 | loss 1.3134 | lr 6.37e-04 | grad 1.19 | tok/s 23964
step   1060 | loss 0.9919 | lr 6.37e-04 | grad 0.90 | tok/s 24513
step   1070 | loss 1.3364 | lr 6.37e-04 | grad 1.19 | tok/s 23914
step   1080 | loss 1.1552 | lr 6.37e-04 | grad 1.19 | tok/s 24692
step   1090 | loss 1.1355 | lr 6.37e-04 | grad 1.15 | tok/s 24735
step   1100 | loss 1.0955 | lr 6.37e-04 | grad 1.18 | tok/s 24707
step   1110 | loss 1.0765 | lr 6.37e-04 | grad 0.84 | tok/s 24688
step   1120 | loss 1.3702 | lr 6.37e-04 | grad 3.06 | tok/s 24043
step   1130 | loss 1.4798 | lr 6.37e-04 | grad 1.77 | tok/s 24282
step   1140 | loss 1.5580 | lr 6.37e-04 | grad 0.91 | tok/s 24569
step   1150 | loss 1.5039 | lr 6.37e-04 | grad 3.05 | tok/s 23393
step   1160 | loss 1.6132 | lr 6.37e-04 | grad 5.12 | tok/s 23731
step   1170 | loss 1.3279 | lr 6.37e-04 | grad 1.37 | tok/s 23345
step   1180 | loss 1.2278 | lr 6.37e-04 | grad 1.41 | tok/s 24182
step   1190 | loss 1.3826 | lr 6.37e-04 | grad 8.81 | tok/s 24625
step   1200 | loss 1.0254 | lr 6.37e-04 | grad 2.08 | tok/s 24649
step   1210 | loss 1.3288 | lr 6.37e-04 | grad 1.63 | tok/s 22993
step   1220 | loss 1.2339 | lr 6.37e-04 | grad 1.06 | tok/s 23910
step   1230 | loss 1.1994 | lr 6.37e-04 | grad 0.80 | tok/s 24513
step   1240 | loss 1.2082 | lr 6.37e-04 | grad 1.05 | tok/s 24106
step   1250 | loss 1.3328 | lr 6.37e-04 | grad 2.58 | tok/s 24134
step   1260 | loss 1.2426 | lr 6.37e-04 | grad 1.39 | tok/s 24328
step   1270 | loss 1.2476 | lr 6.37e-04 | grad 1.06 | tok/s 23859
step   1280 | loss 1.2944 | lr 6.37e-04 | grad 1.41 | tok/s 23500
step   1290 | loss 1.2010 | lr 6.37e-04 | grad 1.06 | tok/s 23568
step   1300 | loss 1.4452 | lr 6.37e-04 | grad 3.28 | tok/s 23212
step   1310 | loss 1.3662 | lr 6.37e-04 | grad 1.10 | tok/s 23996
step   1320 | loss 1.3765 | lr 6.37e-04 | grad 2.42 | tok/s 24164
step   1330 | loss 1.2729 | lr 6.37e-04 | grad 1.56 | tok/s 23856
step   1340 | loss 1.4090 | lr 6.37e-04 | grad 1.21 | tok/s 23438
step   1350 | loss 1.3130 | lr 6.37e-04 | grad 2.91 | tok/s 23738
step   1360 | loss 1.2634 | lr 6.37e-04 | grad 0.99 | tok/s 23169
step   1370 | loss 1.5002 | lr 6.37e-04 | grad 1.96 | tok/s 24268
step   1380 | loss 1.2847 | lr 6.37e-04 | grad 1.63 | tok/s 23117
step   1390 | loss 1.1910 | lr 6.37e-04 | grad 1.55 | tok/s 24303
step   1400 | loss 1.3276 | lr 6.37e-04 | grad 0.83 | tok/s 23511
step   1410 | loss 1.3062 | lr 6.37e-04 | grad 5.91 | tok/s 22978
step   1420 | loss 1.0656 | lr 6.37e-04 | grad 4.25 | tok/s 24400
step   1430 | loss 1.4170 | lr 6.37e-04 | grad 1.25 | tok/s 23450
step   1440 | loss 1.2860 | lr 6.37e-04 | grad 1.26 | tok/s 24173
step   1450 | loss 1.2762 | lr 6.37e-04 | grad 1.27 | tok/s 24011
step   1460 | loss 1.4432 | lr 6.37e-04 | grad 2.22 | tok/s 23482
step   1470 | loss 1.2115 | lr 6.37e-04 | grad 1.02 | tok/s 22690
step   1480 | loss 1.2417 | lr 6.37e-04 | grad 1.41 | tok/s 24263
step   1490 | loss 1.7159 | lr 6.37e-04 | grad 2.45 | tok/s 23697
step   1500 | loss 1.2968 | lr 6.37e-04 | grad 1.09 | tok/s 23882
step   1510 | loss 1.1197 | lr 6.37e-04 | grad 0.99 | tok/s 23687
step   1520 | loss 1.3549 | lr 6.37e-04 | grad 1.42 | tok/s 23769
step   1530 | loss 1.2733 | lr 6.37e-04 | grad 1.77 | tok/s 23958
step   1540 | loss 1.3824 | lr 6.37e-04 | grad 0.98 | tok/s 24209
step   1550 | loss 1.3376 | lr 6.37e-04 | grad 1.80 | tok/s 23721
step   1560 | loss 0.9986 | lr 6.37e-04 | grad 1.08 | tok/s 24611
step   1570 | loss 1.1524 | lr 6.37e-04 | grad 0.96 | tok/s 23955
step   1580 | loss 1.2440 | lr 6.37e-04 | grad 4.56 | tok/s 23801
step   1590 | loss 1.2619 | lr 6.37e-04 | grad 1.30 | tok/s 23455
step   1600 | loss 1.1436 | lr 6.37e-04 | grad 1.49 | tok/s 24026
step   1610 | loss 1.8375 | lr 6.37e-04 | grad 2.36 | tok/s 24285
step   1620 | loss 1.7808 | lr 6.37e-04 | grad 1.69 | tok/s 24625
step   1630 | loss 1.5083 | lr 6.37e-04 | grad 1.84 | tok/s 24613
step   1640 | loss 1.3571 | lr 6.37e-04 | grad 1.53 | tok/s 24625
step   1650 | loss 1.2829 | lr 6.37e-04 | grad 1.91 | tok/s 24610
step   1660 | loss 1.2368 | lr 6.37e-04 | grad 1.51 | tok/s 24611
step   1670 | loss 1.3325 | lr 6.37e-04 | grad 1.15 | tok/s 23857
step   1680 | loss 1.2854 | lr 6.37e-04 | grad 1.06 | tok/s 23194
step   1690 | loss 1.3567 | lr 6.37e-04 | grad 0.92 | tok/s 23352
step   1700 | loss 1.1664 | lr 6.37e-04 | grad 0.99 | tok/s 24224
step   1710 | loss 1.1558 | lr 6.37e-04 | grad 1.27 | tok/s 22754
step   1720 | loss 1.3302 | lr 6.37e-04 | grad 1.31 | tok/s 23617
step   1730 | loss 1.2729 | lr 6.37e-04 | grad 0.93 | tok/s 23845
step   1740 | loss 1.2831 | lr 6.37e-04 | grad 1.10 | tok/s 24333
step   1750 | loss 1.1183 | lr 6.37e-04 | grad 1.16 | tok/s 23370
step   1760 | loss 1.3660 | lr 6.37e-04 | grad 2.34 | tok/s 23493
step   1770 | loss 1.4223 | lr 6.37e-04 | grad 1.70 | tok/s 24022
step   1780 | loss 1.6023 | lr 6.37e-04 | grad 1.83 | tok/s 22614
step   1790 | loss 1.1204 | lr 6.37e-04 | grad 1.74 | tok/s 23357
step   1800 | loss 1.2240 | lr 6.37e-04 | grad 1.21 | tok/s 23299
step   1810 | loss 1.2515 | lr 6.37e-04 | grad 1.31 | tok/s 23776
step   1820 | loss 1.3914 | lr 6.37e-04 | grad 1.19 | tok/s 23243
step   1830 | loss 1.2789 | lr 6.37e-04 | grad 1.00 | tok/s 23009
step   1840 | loss 1.1787 | lr 6.37e-04 | grad 0.81 | tok/s 23814
step   1850 | loss 1.2671 | lr 6.37e-04 | grad 2.06 | tok/s 23093
step   1860 | loss 1.3578 | lr 6.37e-04 | grad 2.05 | tok/s 23768
step   1870 | loss 1.2064 | lr 6.37e-04 | grad 0.82 | tok/s 23887
step   1880 | loss 1.3085 | lr 6.37e-04 | grad 1.06 | tok/s 24070
step   1890 | loss 1.1370 | lr 6.37e-04 | grad 1.55 | tok/s 24597
step   1900 | loss 1.0935 | lr 6.37e-04 | grad 1.34 | tok/s 24631
step   1910 | loss 1.0653 | lr 6.37e-04 | grad 1.23 | tok/s 24596
step   1920 | loss 1.0517 | lr 6.37e-04 | grad 1.29 | tok/s 24540
step   1930 | loss 1.1448 | lr 6.37e-04 | grad 1.27 | tok/s 24201
step   1940 | loss 1.3612 | lr 6.37e-04 | grad 1.05 | tok/s 23313
step   1950 | loss 1.3014 | lr 6.37e-04 | grad 1.62 | tok/s 23268
step   1960 | loss 1.3230 | lr 6.37e-04 | grad 2.62 | tok/s 23397
step   1970 | loss 1.3342 | lr 6.37e-04 | grad 1.04 | tok/s 23786
step   1980 | loss 1.2578 | lr 6.37e-04 | grad 1.43 | tok/s 23491
step   1990 | loss 1.3480 | lr 6.37e-04 | grad 1.79 | tok/s 23745
step   2000 | loss 0.9768 | lr 6.37e-04 | grad 1.09 | tok/s 24725
  >>> saved checkpoint: checkpoint_step_002000_loss_0.9768.pt
step   2010 | loss 1.2105 | lr 6.37e-04 | grad 1.34 | tok/s 11856
step   2020 | loss 1.2457 | lr 6.37e-04 | grad 1.12 | tok/s 23574
step   2030 | loss 1.7419 | lr 6.37e-04 | grad 1.64 | tok/s 23219
step   2040 | loss 1.2708 | lr 6.37e-04 | grad 0.95 | tok/s 24053
step   2050 | loss 1.2600 | lr 6.37e-04 | grad 1.49 | tok/s 23694
step   2060 | loss 1.4494 | lr 6.37e-04 | grad 1.34 | tok/s 23819
step   2070 | loss 0.9931 | lr 6.37e-04 | grad 0.85 | tok/s 23901
step   2080 | loss 1.1024 | lr 6.37e-04 | grad 0.78 | tok/s 23344
step   2090 | loss 1.3983 | lr 6.37e-04 | grad 2.05 | tok/s 24238
step   2100 | loss 1.3487 | lr 6.37e-04 | grad 1.20 | tok/s 24222
step   2110 | loss 1.2523 | lr 6.37e-04 | grad 1.20 | tok/s 23538
step   2120 | loss 1.9879 | lr 6.37e-04 | grad 1.32 | tok/s 23995
step   2130 | loss 1.3290 | lr 6.37e-04 | grad 1.80 | tok/s 23231
step   2140 | loss 1.2972 | lr 6.37e-04 | grad 1.25 | tok/s 23670
step   2150 | loss 1.5372 | lr 6.37e-04 | grad 1.17 | tok/s 24139
step   2160 | loss 1.2754 | lr 6.37e-04 | grad 1.27 | tok/s 23704
step   2170 | loss 1.3375 | lr 6.37e-04 | grad 1.81 | tok/s 24228
step   2180 | loss 0.9949 | lr 6.37e-04 | grad 1.59 | tok/s 24660
step   2190 | loss 1.3560 | lr 6.37e-04 | grad 1.66 | tok/s 23575
step   2200 | loss 1.0364 | lr 6.37e-04 | grad 1.73 | tok/s 24608
step   2210 | loss 1.2985 | lr 6.37e-04 | grad 1.28 | tok/s 23802
step   2220 | loss 1.3158 | lr 6.37e-04 | grad 1.26 | tok/s 22910
step   2230 | loss 1.4659 | lr 6.37e-04 | grad 0.87 | tok/s 23693
step   2240 | loss 1.2549 | lr 6.37e-04 | grad 1.59 | tok/s 23912
step   2250 | loss 1.2373 | lr 6.37e-04 | grad 1.04 | tok/s 23462
step   2260 | loss 1.4358 | lr 6.37e-04 | grad 3.09 | tok/s 23917
step   2270 | loss 1.4275 | lr 6.37e-04 | grad 1.25 | tok/s 22610
step   2280 | loss 1.2734 | lr 6.37e-04 | grad 1.88 | tok/s 24013
step   2290 | loss 1.1350 | lr 6.37e-04 | grad 1.23 | tok/s 23123
step   2300 | loss 1.6065 | lr 6.37e-04 | grad 1.77 | tok/s 23433
step   2310 | loss 1.2089 | lr 6.37e-04 | grad 1.30 | tok/s 24137
step   2320 | loss 1.2447 | lr 6.37e-04 | grad 0.94 | tok/s 24640
step   2330 | loss 1.1876 | lr 6.37e-04 | grad 0.86 | tok/s 24648
step   2340 | loss 1.1498 | lr 6.37e-04 | grad 1.02 | tok/s 24610
step   2350 | loss 1.1341 | lr 6.37e-04 | grad 1.02 | tok/s 24642
step   2360 | loss 1.0712 | lr 6.37e-04 | grad 0.77 | tok/s 24656
step   2370 | loss 1.0806 | lr 6.37e-04 | grad 1.31 | tok/s 24624
step   2380 | loss 1.0598 | lr 6.37e-04 | grad 1.07 | tok/s 24624
step   2390 | loss 1.0765 | lr 6.37e-04 | grad 0.86 | tok/s 24600
step   2400 | loss 1.0292 | lr 6.37e-04 | grad 0.89 | tok/s 24619
step   2410 | loss 1.3406 | lr 6.37e-04 | grad 5.56 | tok/s 24222
step   2420 | loss 0.9952 | lr 6.37e-04 | grad 0.46 | tok/s 24419
step   2430 | loss 1.1679 | lr 6.37e-04 | grad 1.26 | tok/s 23175
step   2440 | loss 1.2491 | lr 6.37e-04 | grad 0.99 | tok/s 23216
step   2450 | loss 1.2379 | lr 6.37e-04 | grad 1.21 | tok/s 23930
step   2460 | loss 1.3619 | lr 6.37e-04 | grad 1.06 | tok/s 24234
step   2470 | loss 1.2180 | lr 6.37e-04 | grad 1.11 | tok/s 23459
step   2480 | loss 1.2671 | lr 6.37e-04 | grad 2.22 | tok/s 24324
step   2490 | loss 1.3335 | lr 6.37e-04 | grad 2.86 | tok/s 23402
step   2500 | loss 1.3956 | lr 6.37e-04 | grad 1.42 | tok/s 24116
step   2510 | loss 1.2749 | lr 6.37e-04 | grad 0.95 | tok/s 23645
step   2520 | loss 1.2403 | lr 6.37e-04 | grad 1.36 | tok/s 23736
step   2530 | loss 1.3945 | lr 6.37e-04 | grad 1.31 | tok/s 23912
step   2540 | loss 1.3189 | lr 6.37e-04 | grad 4.44 | tok/s 22990
step   2550 | loss 1.2507 | lr 6.37e-04 | grad 3.41 | tok/s 23674
step   2560 | loss 1.2863 | lr 6.37e-04 | grad 0.91 | tok/s 23362
step   2570 | loss 1.2592 | lr 6.37e-04 | grad 0.85 | tok/s 23719
step   2580 | loss 1.4076 | lr 6.37e-04 | grad 0.96 | tok/s 23285
step   2590 | loss 1.2076 | lr 6.37e-04 | grad 0.77 | tok/s 22925
step   2600 | loss 1.3103 | lr 6.37e-04 | grad 0.82 | tok/s 23930
step   2610 | loss 1.1422 | lr 6.37e-04 | grad 1.02 | tok/s 24175
step   2620 | loss 1.3604 | lr 6.37e-04 | grad 0.89 | tok/s 23570
step   2630 | loss 1.0129 | lr 6.37e-04 | grad 1.16 | tok/s 24200
step   2640 | loss 1.2438 | lr 6.37e-04 | grad 1.13 | tok/s 23151
step   2650 | loss 1.0785 | lr 6.37e-04 | grad 0.88 | tok/s 23812
step   2660 | loss 1.2334 | lr 6.37e-04 | grad 0.70 | tok/s 24270
step   2670 | loss 0.9495 | lr 6.37e-04 | grad 1.23 | tok/s 23782
step   2680 | loss 1.2380 | lr 6.37e-04 | grad 0.96 | tok/s 23418
step   2690 | loss 1.2277 | lr 6.37e-04 | grad 1.02 | tok/s 23063
step   2700 | loss 1.2795 | lr 6.37e-04 | grad 2.25 | tok/s 23998
step   2710 | loss 1.5218 | lr 6.37e-04 | grad 1.39 | tok/s 23383
step   2720 | loss 1.1387 | lr 6.37e-04 | grad 1.06 | tok/s 23856
step   2730 | loss 1.1962 | lr 6.37e-04 | grad 1.68 | tok/s 23946
step   2740 | loss 1.2491 | lr 6.37e-04 | grad 0.78 | tok/s 23166
step   2750 | loss 1.2218 | lr 6.37e-04 | grad 2.27 | tok/s 24321
step   2760 | loss 1.1251 | lr 6.37e-04 | grad 1.05 | tok/s 23764
step   2770 | loss 1.2334 | lr 6.37e-04 | grad 1.15 | tok/s 24109
step   2780 | loss 1.1858 | lr 6.37e-04 | grad 1.36 | tok/s 24121
step   2790 | loss 1.3309 | lr 6.37e-04 | grad 0.99 | tok/s 23412
step   2800 | loss 1.3046 | lr 6.37e-04 | grad 2.20 | tok/s 23001
step   2810 | loss 1.2231 | lr 6.37e-04 | grad 1.16 | tok/s 23408
step   2820 | loss 1.2289 | lr 6.37e-04 | grad 0.90 | tok/s 22603
step   2830 | loss 1.1736 | lr 6.37e-04 | grad 1.00 | tok/s 23497
step   2840 | loss 1.0703 | lr 6.37e-04 | grad 1.00 | tok/s 23594
step   2850 | loss 1.0352 | lr 6.37e-04 | grad 0.85 | tok/s 24633
step   2860 | loss 1.0961 | lr 6.37e-04 | grad 0.86 | tok/s 23950
step   2870 | loss 1.2200 | lr 6.37e-04 | grad 1.19 | tok/s 23174
step   2880 | loss 1.2621 | lr 6.37e-04 | grad 0.94 | tok/s 23185
step   2890 | loss 1.4755 | lr 6.37e-04 | grad 1.18 | tok/s 24076
step   2900 | loss 1.2571 | lr 6.37e-04 | grad 2.28 | tok/s 23194
step   2910 | loss 1.1482 | lr 6.37e-04 | grad 1.09 | tok/s 24025
step   2920 | loss 1.0696 | lr 6.37e-04 | grad 3.11 | tok/s 23694
step   2930 | loss 1.3012 | lr 6.37e-04 | grad 0.90 | tok/s 24108
step   2940 | loss 1.1387 | lr 6.37e-04 | grad 1.06 | tok/s 23574
step   2950 | loss 1.4135 | lr 6.37e-04 | grad 1.04 | tok/s 23480
step   2960 | loss 1.4145 | lr 6.37e-04 | grad 1.16 | tok/s 23236
step   2970 | loss 1.2922 | lr 6.37e-04 | grad 0.85 | tok/s 24006
step   2980 | loss 1.1868 | lr 6.37e-04 | grad 1.01 | tok/s 24075
step   2990 | loss 1.2830 | lr 6.37e-04 | grad 1.30 | tok/s 23887
step   3000 | loss 1.2311 | lr 6.37e-04 | grad 1.18 | tok/s 24057
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2311.pt
step   3010 | loss 1.3051 | lr 6.37e-04 | grad 1.18 | tok/s 12526
step   3020 | loss 1.1969 | lr 6.37e-04 | grad 1.05 | tok/s 23559
step   3030 | loss 1.1086 | lr 6.37e-04 | grad 1.02 | tok/s 23507
step   3040 | loss 1.1722 | lr 6.37e-04 | grad 1.03 | tok/s 24016
step   3050 | loss 1.0733 | lr 6.37e-04 | grad 0.75 | tok/s 24677
step   3060 | loss 1.4520 | lr 6.37e-04 | grad 1.19 | tok/s 24134
step   3070 | loss 1.7039 | lr 6.37e-04 | grad 4.94 | tok/s 23905
step   3080 | loss 1.2518 | lr 6.37e-04 | grad 1.17 | tok/s 23739
step   3090 | loss 1.2403 | lr 6.37e-04 | grad 0.81 | tok/s 22988
step   3100 | loss 1.1280 | lr 6.37e-04 | grad 0.84 | tok/s 24327
step   3110 | loss 1.1986 | lr 6.37e-04 | grad 1.34 | tok/s 24366
step   3120 | loss 1.2307 | lr 6.37e-04 | grad 1.20 | tok/s 23605
step   3130 | loss 1.1821 | lr 6.37e-04 | grad 1.04 | tok/s 23403
step   3140 | loss 1.1611 | lr 6.37e-04 | grad 1.13 | tok/s 23439
step   3150 | loss 1.2763 | lr 6.37e-04 | grad 3.27 | tok/s 22774
step   3160 | loss 1.2850 | lr 6.37e-04 | grad 1.13 | tok/s 24468
step   3170 | loss 1.0600 | lr 6.37e-04 | grad 0.86 | tok/s 24573
step   3180 | loss 1.2118 | lr 6.37e-04 | grad 2.34 | tok/s 24268
step   3190 | loss 1.3575 | lr 6.37e-04 | grad 1.09 | tok/s 23888
step   3200 | loss 1.1991 | lr 6.37e-04 | grad 1.33 | tok/s 23881
step   3210 | loss 1.2769 | lr 6.37e-04 | grad 1.25 | tok/s 23971
step   3220 | loss 1.1652 | lr 6.37e-04 | grad 0.99 | tok/s 24547
step   3230 | loss 1.1798 | lr 6.37e-04 | grad 1.02 | tok/s 22658
step   3240 | loss 1.1975 | lr 6.37e-04 | grad 1.62 | tok/s 23312
step   3250 | loss 1.2130 | lr 6.37e-04 | grad 4.41 | tok/s 23353
step   3260 | loss 1.1634 | lr 6.37e-04 | grad 0.72 | tok/s 23532
step   3270 | loss 1.2410 | lr 6.37e-04 | grad 2.62 | tok/s 23351
step   3280 | loss 1.2316 | lr 6.37e-04 | grad 0.91 | tok/s 23734
step   3290 | loss 1.1021 | lr 6.37e-04 | grad 0.94 | tok/s 23802
step   3300 | loss 1.2658 | lr 6.37e-04 | grad 1.23 | tok/s 24488
step   3310 | loss 1.7127 | lr 6.37e-04 | grad 2.30 | tok/s 23840
step   3320 | loss 1.2327 | lr 6.37e-04 | grad 0.88 | tok/s 23590
step   3330 | loss 1.1786 | lr 6.37e-04 | grad 1.04 | tok/s 23112
step   3340 | loss 1.0136 | lr 6.37e-04 | grad 1.31 | tok/s 24438
step   3350 | loss 1.2201 | lr 6.37e-04 | grad 2.33 | tok/s 24441
step   3360 | loss 1.2327 | lr 6.37e-04 | grad 0.93 | tok/s 23187
step   3370 | loss 1.2925 | lr 6.37e-04 | grad 0.75 | tok/s 23546
step   3380 | loss 1.2375 | lr 6.37e-04 | grad 1.22 | tok/s 23505
step   3390 | loss 1.1297 | lr 6.37e-04 | grad 1.70 | tok/s 23793
step   3400 | loss 1.1963 | lr 6.37e-04 | grad 0.80 | tok/s 23593
step   3410 | loss 1.3032 | lr 6.37e-04 | grad 1.07 | tok/s 23442
step   3420 | loss 1.2693 | lr 6.37e-04 | grad 0.96 | tok/s 23847
step   3430 | loss 1.2838 | lr 6.37e-04 | grad 2.75 | tok/s 23845
step   3440 | loss 1.1081 | lr 6.37e-04 | grad 1.09 | tok/s 23094
step   3450 | loss 1.2622 | lr 6.37e-04 | grad 1.48 | tok/s 23698
step   3460 | loss 1.2473 | lr 6.37e-04 | grad 2.11 | tok/s 23372
step   3470 | loss 1.3906 | lr 6.37e-04 | grad 0.88 | tok/s 23660
step   3480 | loss 1.1393 | lr 6.37e-04 | grad 1.29 | tok/s 23403
step   3490 | loss 1.4071 | lr 6.37e-04 | grad 3.06 | tok/s 23672
step   3500 | loss 1.2695 | lr 6.37e-04 | grad 1.03 | tok/s 22986
step   3510 | loss 1.2116 | lr 6.37e-04 | grad 0.88 | tok/s 22848
step   3520 | loss 1.2253 | lr 6.37e-04 | grad 2.69 | tok/s 24189
step   3530 | loss 1.3141 | lr 6.37e-04 | grad 1.82 | tok/s 23352
step   3540 | loss 1.2373 | lr 6.37e-04 | grad 1.30 | tok/s 23100
step   3550 | loss 1.1760 | lr 6.37e-04 | grad 0.91 | tok/s 24100
step   3560 | loss 1.2897 | lr 6.37e-04 | grad 2.06 | tok/s 23782
step   3570 | loss 1.1034 | lr 6.37e-04 | grad 1.12 | tok/s 24616
step   3580 | loss 1.1432 | lr 6.37e-04 | grad 1.20 | tok/s 23386
step   3590 | loss 1.1948 | lr 6.37e-04 | grad 0.94 | tok/s 22940
step   3600 | loss 1.1014 | lr 6.37e-04 | grad 0.92 | tok/s 23729
step   3610 | loss 1.2827 | lr 6.37e-04 | grad 1.04 | tok/s 23851
step   3620 | loss 1.2105 | lr 6.37e-04 | grad 1.00 | tok/s 22777
step   3630 | loss 1.2168 | lr 6.37e-04 | grad 1.24 | tok/s 24041
step   3640 | loss 1.4183 | lr 6.37e-04 | grad 0.93 | tok/s 22964
step   3650 | loss 1.3153 | lr 6.37e-04 | grad 1.11 | tok/s 23600
step   3660 | loss 1.2767 | lr 6.37e-04 | grad 1.04 | tok/s 22986
step   3670 | loss 1.1268 | lr 6.37e-04 | grad 0.77 | tok/s 23888
step   3680 | loss 1.1415 | lr 6.37e-04 | grad 0.98 | tok/s 23139
step   3690 | loss 1.1752 | lr 6.37e-04 | grad 0.76 | tok/s 24292
step   3700 | loss 1.1212 | lr 6.37e-04 | grad 0.77 | tok/s 24035
step   3710 | loss 1.2182 | lr 6.37e-04 | grad 0.93 | tok/s 24006
step   3720 | loss 1.2326 | lr 6.37e-04 | grad 0.93 | tok/s 24030
step   3730 | loss 1.2791 | lr 6.37e-04 | grad 1.46 | tok/s 22592
step   3740 | loss 1.2763 | lr 6.37e-04 | grad 1.27 | tok/s 23536
step   3750 | loss 1.1812 | lr 6.37e-04 | grad 1.13 | tok/s 24058
step   3760 | loss 1.1986 | lr 6.37e-04 | grad 1.35 | tok/s 23595
step   3770 | loss 1.4354 | lr 6.37e-04 | grad 1.43 | tok/s 23188
step   3780 | loss 1.1115 | lr 6.37e-04 | grad 0.85 | tok/s 24223
step   3790 | loss 1.0522 | lr 6.37e-04 | grad 0.88 | tok/s 23871
step   3800 | loss 1.0667 | lr 6.37e-04 | grad 1.46 | tok/s 23747
step   3810 | loss 1.1924 | lr 6.37e-04 | grad 0.74 | tok/s 24006
step   3820 | loss 1.1888 | lr 6.37e-04 | grad 0.78 | tok/s 24213
step   3830 | loss 1.2174 | lr 6.37e-04 | grad 1.18 | tok/s 24283
step   3840 | loss 1.3561 | lr 6.37e-04 | grad 0.92 | tok/s 24267
step   3850 | loss 1.2182 | lr 6.37e-04 | grad 1.20 | tok/s 23850
step   3860 | loss 1.2231 | lr 6.37e-04 | grad 2.75 | tok/s 24150
step   3870 | loss 1.1103 | lr 6.37e-04 | grad 1.81 | tok/s 24152
step   3880 | loss 1.0385 | lr 6.37e-04 | grad 0.77 | tok/s 23731
step   3890 | loss 1.1254 | lr 6.37e-04 | grad 1.17 | tok/s 23441
step   3900 | loss 1.1479 | lr 6.37e-04 | grad 1.62 | tok/s 23785
step   3910 | loss 1.2936 | lr 6.37e-04 | grad 2.00 | tok/s 23487
step   3920 | loss 1.0884 | lr 6.37e-04 | grad 1.36 | tok/s 24310
step   3930 | loss 1.2132 | lr 6.37e-04 | grad 0.91 | tok/s 23371
step   3940 | loss 1.1389 | lr 6.37e-04 | grad 1.60 | tok/s 24050
step   3950 | loss 1.1180 | lr 6.37e-04 | grad 1.05 | tok/s 24324
step   3960 | loss 1.0910 | lr 6.37e-04 | grad 0.91 | tok/s 24075
step   3970 | loss 0.9819 | lr 6.37e-04 | grad 0.79 | tok/s 24643
step   3980 | loss 0.9681 | lr 6.37e-04 | grad 0.77 | tok/s 24650
step   3990 | loss 0.9420 | lr 6.37e-04 | grad 0.71 | tok/s 24626
step   4000 | loss 1.0709 | lr 6.37e-04 | grad 1.03 | tok/s 24303
  >>> saved checkpoint: checkpoint_step_004000_loss_1.0709.pt
step   4010 | loss 1.2061 | lr 6.37e-04 | grad 0.93 | tok/s 12689
step   4020 | loss 1.0480 | lr 6.37e-04 | grad 0.75 | tok/s 24835
step   4030 | loss 1.0350 | lr 6.37e-04 | grad 0.98 | tok/s 24801
step   4040 | loss 1.0122 | lr 6.37e-04 | grad 0.80 | tok/s 24721
step   4050 | loss 1.1750 | lr 6.37e-04 | grad 0.85 | tok/s 23791
step   4060 | loss 1.3182 | lr 6.37e-04 | grad 1.02 | tok/s 23571
step   4070 | loss 1.3261 | lr 6.37e-04 | grad 0.73 | tok/s 23660
step   4080 | loss 1.2533 | lr 6.37e-04 | grad 0.81 | tok/s 24680
step   4090 | loss 1.1341 | lr 6.37e-04 | grad 0.90 | tok/s 23618
step   4100 | loss 1.2484 | lr 6.37e-04 | grad 0.92 | tok/s 23786
step   4110 | loss 1.2189 | lr 6.37e-04 | grad 1.12 | tok/s 23901
step   4120 | loss 1.2786 | lr 6.37e-04 | grad 1.11 | tok/s 23908
step   4130 | loss 1.1530 | lr 6.37e-04 | grad 1.19 | tok/s 23908
step   4140 | loss 1.2265 | lr 6.37e-04 | grad 0.89 | tok/s 23324
step   4150 | loss 1.1691 | lr 6.37e-04 | grad 1.37 | tok/s 23267
step   4160 | loss 0.9122 | lr 6.37e-04 | grad 1.65 | tok/s 24808
step   4170 | loss 1.0947 | lr 6.37e-04 | grad 2.00 | tok/s 23689
step   4180 | loss 1.0646 | lr 6.37e-04 | grad 0.89 | tok/s 23540
step   4190 | loss 0.7694 | lr 6.37e-04 | grad 1.03 | tok/s 24427
step   4200 | loss 1.2589 | lr 6.37e-04 | grad 0.95 | tok/s 23576
step   4210 | loss 1.3630 | lr 6.37e-04 | grad 1.13 | tok/s 23829
step   4220 | loss 1.2476 | lr 6.37e-04 | grad 1.28 | tok/s 23108
step   4230 | loss 1.3349 | lr 6.37e-04 | grad 0.76 | tok/s 24065
step   4240 | loss 1.2110 | lr 6.37e-04 | grad 0.99 | tok/s 23118
step   4250 | loss 1.3301 | lr 6.37e-04 | grad 1.30 | tok/s 23614
step   4260 | loss 1.2136 | lr 6.37e-04 | grad 1.11 | tok/s 23557
step   4270 | loss 1.2469 | lr 6.37e-04 | grad 1.05 | tok/s 23576
step   4280 | loss 1.3581 | lr 6.37e-04 | grad 0.75 | tok/s 24011
step   4290 | loss 1.1982 | lr 6.37e-04 | grad 1.14 | tok/s 23533
step   4300 | loss 1.1392 | lr 6.37e-04 | grad 0.95 | tok/s 24080
step   4310 | loss 1.3685 | lr 6.37e-04 | grad 2.27 | tok/s 24489
step   4320 | loss 1.1604 | lr 6.37e-04 | grad 1.02 | tok/s 23740
step   4330 | loss 1.0762 | lr 6.37e-04 | grad 0.69 | tok/s 24283
step   4340 | loss 1.0399 | lr 6.37e-04 | grad 0.71 | tok/s 24619
step   4350 | loss 1.0233 | lr 6.37e-04 | grad 0.82 | tok/s 24572
step   4360 | loss 1.0661 | lr 6.37e-04 | grad 0.86 | tok/s 24586
step   4370 | loss 1.0332 | lr 6.37e-04 | grad 0.72 | tok/s 24574
step   4380 | loss 1.0078 | lr 6.37e-04 | grad 0.86 | tok/s 24579
step   4390 | loss 1.0439 | lr 6.37e-04 | grad 0.84 | tok/s 24575
step   4400 | loss 1.2134 | lr 6.37e-04 | grad 1.56 | tok/s 23635
step   4410 | loss 1.0778 | lr 6.37e-04 | grad 0.89 | tok/s 23824
step   4420 | loss 1.2071 | lr 6.37e-04 | grad 2.72 | tok/s 24535
step   4430 | loss 1.0657 | lr 6.37e-04 | grad 3.19 | tok/s 24576
step   4440 | loss 1.1762 | lr 6.37e-04 | grad 1.20 | tok/s 23982
step   4450 | loss 1.2266 | lr 6.37e-04 | grad 2.73 | tok/s 24170
step   4460 | loss 1.2392 | lr 6.37e-04 | grad 0.96 | tok/s 23835
step   4470 | loss 1.0836 | lr 6.37e-04 | grad 0.82 | tok/s 23873
step   4480 | loss 1.1698 | lr 6.37e-04 | grad 1.37 | tok/s 23534
step   4490 | loss 1.1211 | lr 6.37e-04 | grad 1.30 | tok/s 24129
step   4500 | loss 1.3636 | lr 6.37e-04 | grad 1.57 | tok/s 23144
step   4510 | loss 1.2132 | lr 6.37e-04 | grad 0.83 | tok/s 23121
step   4520 | loss 1.2107 | lr 6.37e-04 | grad 1.37 | tok/s 24013
step   4530 | loss 1.1348 | lr 6.37e-04 | grad 0.89 | tok/s 23124
step   4540 | loss 1.2422 | lr 6.37e-04 | grad 0.85 | tok/s 23428
step   4550 | loss 1.2471 | lr 6.37e-04 | grad 0.84 | tok/s 23761
step   4560 | loss 1.2129 | lr 6.37e-04 | grad 0.73 | tok/s 24590
step   4570 | loss 1.2102 | lr 6.37e-04 | grad 0.88 | tok/s 24544
step   4580 | loss 1.1673 | lr 6.37e-04 | grad 0.71 | tok/s 24563
step   4590 | loss 1.1340 | lr 6.37e-04 | grad 0.95 | tok/s 24533
step   4600 | loss 1.1209 | lr 6.37e-04 | grad 0.83 | tok/s 24566
step   4610 | loss 1.0977 | lr 6.37e-04 | grad 0.66 | tok/s 24562
step   4620 | loss 1.2578 | lr 6.37e-04 | grad 0.90 | tok/s 23902
step   4630 | loss 1.2185 | lr 6.37e-04 | grad 1.18 | tok/s 23503
step   4640 | loss 1.2038 | lr 6.37e-04 | grad 1.10 | tok/s 23811
step   4650 | loss 1.2010 | lr 6.37e-04 | grad 1.83 | tok/s 23806
step   4660 | loss 1.5963 | lr 6.37e-04 | grad 1.74 | tok/s 23952
step   4670 | loss 1.2350 | lr 6.37e-04 | grad 1.59 | tok/s 23763
step   4680 | loss 1.2045 | lr 6.37e-04 | grad 1.03 | tok/s 24023
step   4690 | loss 1.0743 | lr 6.37e-04 | grad 2.42 | tok/s 24171
step   4700 | loss 1.1941 | lr 6.37e-04 | grad 0.94 | tok/s 23203
step   4710 | loss 1.1922 | lr 6.37e-04 | grad 0.94 | tok/s 23634
step   4720 | loss 1.1205 | lr 6.37e-04 | grad 0.89 | tok/s 23323
step   4730 | loss 1.1928 | lr 6.37e-04 | grad 1.32 | tok/s 23241
step   4740 | loss 1.2943 | lr 6.37e-04 | grad 0.95 | tok/s 23672
step   4750 | loss 1.1726 | lr 6.37e-04 | grad 1.28 | tok/s 23261
step   4760 | loss 1.2242 | lr 6.37e-04 | grad 1.14 | tok/s 23589
step   4770 | loss 1.1943 | lr 6.37e-04 | grad 0.81 | tok/s 23260
step   4780 | loss 1.1980 | lr 6.37e-04 | grad 0.74 | tok/s 23893
step   4790 | loss 1.1958 | lr 6.37e-04 | grad 1.37 | tok/s 22337
step   4800 | loss 1.3259 | lr 6.37e-04 | grad 2.34 | tok/s 24186
step   4810 | loss 1.2863 | lr 6.37e-04 | grad 2.66 | tok/s 23770
step   4820 | loss 1.1158 | lr 6.37e-04 | grad 0.85 | tok/s 23891
step   4830 | loss 1.1812 | lr 6.37e-04 | grad 1.17 | tok/s 23144
step   4840 | loss 1.1127 | lr 6.37e-04 | grad 1.39 | tok/s 23982
step   4850 | loss 1.1384 | lr 6.37e-04 | grad 0.75 | tok/s 23789
step   4860 | loss 1.1899 | lr 6.37e-04 | grad 2.41 | tok/s 24408
step   4870 | loss 0.7811 | lr 6.37e-04 | grad 1.51 | tok/s 24601
step   4880 | loss 0.8510 | lr 6.37e-04 | grad 1.24 | tok/s 24407
step   4890 | loss 1.1324 | lr 6.37e-04 | grad 0.99 | tok/s 23633
step   4900 | loss 1.0905 | lr 6.37e-04 | grad 0.91 | tok/s 23857
step   4910 | loss 1.1442 | lr 6.37e-04 | grad 0.98 | tok/s 23096
step   4920 | loss 1.1073 | lr 6.37e-04 | grad 0.60 | tok/s 23711
step   4930 | loss 1.1914 | lr 6.37e-04 | grad 1.81 | tok/s 23910
step   4940 | loss 1.1609 | lr 6.37e-04 | grad 0.84 | tok/s 23957
step   4950 | loss 1.1690 | lr 6.37e-04 | grad 1.08 | tok/s 23791
step   4960 | loss 1.0781 | lr 6.37e-04 | grad 1.31 | tok/s 24165
step   4970 | loss 1.3410 | lr 6.37e-04 | grad 1.62 | tok/s 23925
step   4980 | loss 1.3996 | lr 6.37e-04 | grad 4.09 | tok/s 22881
step   4990 | loss 1.1432 | lr 6.37e-04 | grad 1.04 | tok/s 23382
step   5000 | loss 1.2940 | lr 6.37e-04 | grad 0.92 | tok/s 23260
  >>> saved checkpoint: checkpoint_step_005000_loss_1.2940.pt
step   5010 | loss 1.1698 | lr 6.37e-04 | grad 0.68 | tok/s 12070
step   5020 | loss 1.2266 | lr 6.37e-04 | grad 1.22 | tok/s 23030
step   5030 | loss 1.4279 | lr 6.37e-04 | grad 3.14 | tok/s 24120
step   5040 | loss 1.5650 | lr 6.37e-04 | grad 0.99 | tok/s 24324
step   5050 | loss 1.2373 | lr 6.37e-04 | grad 0.84 | tok/s 24110
step   5060 | loss 1.3069 | lr 6.37e-04 | grad 0.99 | tok/s 23786
step   5070 | loss 1.0462 | lr 6.37e-04 | grad 1.18 | tok/s 23292
step   5080 | loss 1.4332 | lr 6.37e-04 | grad 0.82 | tok/s 24573
step   5090 | loss 1.2116 | lr 6.37e-04 | grad 1.75 | tok/s 23954
step   5100 | loss 1.0612 | lr 6.37e-04 | grad 0.92 | tok/s 23568
step   5110 | loss 1.1682 | lr 6.37e-04 | grad 0.88 | tok/s 23716
step   5120 | loss 1.2429 | lr 6.37e-04 | grad 0.85 | tok/s 23920
step   5130 | loss 1.1676 | lr 6.37e-04 | grad 0.83 | tok/s 24485
step   5140 | loss 1.2698 | lr 6.37e-04 | grad 0.81 | tok/s 23940
step   5150 | loss 1.1177 | lr 6.37e-04 | grad 1.11 | tok/s 24370
step   5160 | loss 1.1859 | lr 6.37e-04 | grad 1.09 | tok/s 24714
step   5170 | loss 1.1271 | lr 6.37e-04 | grad 0.77 | tok/s 24667
step   5180 | loss 1.0804 | lr 6.37e-04 | grad 0.82 | tok/s 24686
step   5190 | loss 1.1550 | lr 6.37e-04 | grad 0.84 | tok/s 24433
step   5200 | loss 1.2199 | lr 6.37e-04 | grad 0.98 | tok/s 23139
step   5210 | loss 1.2383 | lr 6.37e-04 | grad 1.09 | tok/s 23194
step   5220 | loss 1.2036 | lr 6.37e-04 | grad 0.96 | tok/s 23936
step   5230 | loss 1.1942 | lr 6.37e-04 | grad 0.89 | tok/s 22571
step   5240 | loss 1.0674 | lr 6.37e-04 | grad 0.62 | tok/s 23695
step   5250 | loss 1.7770 | lr 6.37e-04 | grad 1.26 | tok/s 24153
step   5260 | loss 1.1538 | lr 6.37e-04 | grad 0.82 | tok/s 24655
step   5270 | loss 1.1363 | lr 6.37e-04 | grad 0.86 | tok/s 24645
step   5280 | loss 1.0985 | lr 6.37e-04 | grad 0.61 | tok/s 24674
step   5290 | loss 1.0874 | lr 6.37e-04 | grad 0.92 | tok/s 24692
step   5300 | loss 1.0887 | lr 6.37e-04 | grad 0.84 | tok/s 24701

Training complete! Final step: 5305
