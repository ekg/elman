Using device: cuda
Output directory: benchmark_results/cmaes_4d/fla-gdn_480M_converge0.01_20260203_061047/eval_15/levelfla-gdn_100m_20260203_064115
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 724,617,572 parameters
Using schedule-free AdamW (lr=0.0003106839913965935)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 4.1350 | lr 3.11e-04 | grad 23.50 | tok/s 5812
step     20 | loss 2.6309 | lr 3.11e-04 | grad 7.75 | tok/s 14195
step     30 | loss 2.4711 | lr 3.11e-04 | grad 6.97 | tok/s 14352
step     40 | loss 2.3387 | lr 3.11e-04 | grad 4.97 | tok/s 13673
step     50 | loss 2.8239 | lr 3.11e-04 | grad 23.62 | tok/s 13850
step     60 | loss 2.0968 | lr 3.11e-04 | grad 4.88 | tok/s 14247
step     70 | loss 1.7636 | lr 3.11e-04 | grad 5.41 | tok/s 14389
step     80 | loss 4.9222 | lr 3.11e-04 | grad 31.88 | tok/s 14422
step     90 | loss 4.2491 | lr 3.11e-04 | grad 7.59 | tok/s 14631
step    100 | loss 3.4117 | lr 3.11e-04 | grad 9.06 | tok/s 14564
step    110 | loss 3.1763 | lr 3.11e-04 | grad 20.50 | tok/s 14535
step    120 | loss 2.9195 | lr 3.11e-04 | grad 13.75 | tok/s 14499
step    130 | loss 2.9531 | lr 3.11e-04 | grad 13.88 | tok/s 14496
step    140 | loss 2.4682 | lr 3.11e-04 | grad 10.38 | tok/s 14490
step    150 | loss 2.5022 | lr 3.11e-04 | grad 15.38 | tok/s 14450
step    160 | loss 2.3548 | lr 3.11e-04 | grad 10.12 | tok/s 14419
step    170 | loss 2.1541 | lr 3.11e-04 | grad 11.81 | tok/s 14420
step    180 | loss 2.1276 | lr 3.11e-04 | grad 7.69 | tok/s 14398
step    190 | loss 2.2339 | lr 3.11e-04 | grad 6.16 | tok/s 14375
step    200 | loss 1.8934 | lr 3.11e-04 | grad 4.91 | tok/s 14359
step    210 | loss 1.9365 | lr 3.11e-04 | grad 10.75 | tok/s 14344
step    220 | loss 1.9909 | lr 3.11e-04 | grad 4.22 | tok/s 14180
step    230 | loss 2.0630 | lr 3.11e-04 | grad 4.81 | tok/s 13995
step    240 | loss 2.1979 | lr 3.11e-04 | grad 5.28 | tok/s 13343
step    250 | loss 1.9780 | lr 3.11e-04 | grad 2.89 | tok/s 13647
step    260 | loss 1.4403 | lr 3.11e-04 | grad 3.80 | tok/s 14088
step    270 | loss 1.9715 | lr 3.11e-04 | grad 3.23 | tok/s 13914
step    280 | loss 2.1528 | lr 3.11e-04 | grad 5.31 | tok/s 13669
step    290 | loss 1.4634 | lr 3.11e-04 | grad 4.53 | tok/s 14406
step    300 | loss 0.5769 | lr 3.11e-04 | grad 4.09 | tok/s 14393
step    310 | loss 2.3924 | lr 3.11e-04 | grad 4.78 | tok/s 14100
step    320 | loss 1.8300 | lr 3.11e-04 | grad 7.59 | tok/s 13830
step    330 | loss 1.8226 | lr 3.11e-04 | grad 3.19 | tok/s 13326
step    340 | loss 2.0886 | lr 3.11e-04 | grad 3.05 | tok/s 13572
step    350 | loss 1.7380 | lr 3.11e-04 | grad 5.91 | tok/s 13879
step    360 | loss 1.0794 | lr 3.11e-04 | grad 9.19 | tok/s 14175
step    370 | loss 1.6619 | lr 3.11e-04 | grad 2.61 | tok/s 12897
step    380 | loss 1.6617 | lr 3.11e-04 | grad 3.34 | tok/s 13737
step    390 | loss 1.4376 | lr 3.11e-04 | grad 2.44 | tok/s 14299
step    400 | loss 1.3986 | lr 3.11e-04 | grad 2.88 | tok/s 14193
step    410 | loss 1.1849 | lr 3.11e-04 | grad 2.30 | tok/s 13858
step    420 | loss 1.6838 | lr 3.11e-04 | grad 4.81 | tok/s 13235
step    430 | loss 1.9907 | lr 3.11e-04 | grad 3.23 | tok/s 14114
step    440 | loss 2.0461 | lr 3.11e-04 | grad 3.89 | tok/s 13374
step    450 | loss 1.7716 | lr 3.11e-04 | grad 2.67 | tok/s 13810
step    460 | loss 1.6267 | lr 3.11e-04 | grad 2.56 | tok/s 13513
step    470 | loss 1.6910 | lr 3.11e-04 | grad 3.05 | tok/s 13922
step    480 | loss 2.1033 | lr 3.11e-04 | grad 6.66 | tok/s 13914
step    490 | loss 1.6702 | lr 3.11e-04 | grad 2.34 | tok/s 13167
step    500 | loss 1.5604 | lr 3.11e-04 | grad 3.84 | tok/s 14014
step    510 | loss 1.5830 | lr 3.11e-04 | grad 2.45 | tok/s 14208
step    520 | loss 1.5515 | lr 3.11e-04 | grad 2.36 | tok/s 14172
step    530 | loss 1.7599 | lr 3.11e-04 | grad 2.16 | tok/s 13654
step    540 | loss 1.6133 | lr 3.11e-04 | grad 2.55 | tok/s 13633
step    550 | loss 1.4772 | lr 3.11e-04 | grad 2.91 | tok/s 13383
step    560 | loss 1.5970 | lr 3.11e-04 | grad 2.73 | tok/s 13039
step    570 | loss 1.5241 | lr 3.11e-04 | grad 2.91 | tok/s 13414
step    580 | loss 1.4385 | lr 3.11e-04 | grad 2.55 | tok/s 13336
step    590 | loss 1.7318 | lr 3.11e-04 | grad 3.08 | tok/s 13665
step    600 | loss 1.6906 | lr 3.11e-04 | grad 2.25 | tok/s 13236
step    610 | loss 1.5188 | lr 3.11e-04 | grad 2.41 | tok/s 13901
step    620 | loss 1.4517 | lr 3.11e-04 | grad 2.33 | tok/s 13184
step    630 | loss 1.5344 | lr 3.11e-04 | grad 3.89 | tok/s 13291
step    640 | loss 1.6743 | lr 3.11e-04 | grad 2.28 | tok/s 13621
step    650 | loss 1.5751 | lr 3.11e-04 | grad 2.61 | tok/s 13730
step    660 | loss 1.5747 | lr 3.11e-04 | grad 1.95 | tok/s 13762
step    670 | loss 1.7914 | lr 3.11e-04 | grad 17.50 | tok/s 13842
step    680 | loss 1.6148 | lr 3.11e-04 | grad 2.52 | tok/s 13606
step    690 | loss 1.6823 | lr 3.11e-04 | grad 3.28 | tok/s 14023
step    700 | loss 1.2955 | lr 3.11e-04 | grad 2.58 | tok/s 14302
step    710 | loss 1.4687 | lr 3.11e-04 | grad 2.28 | tok/s 13378
step    720 | loss 1.3566 | lr 3.11e-04 | grad 3.58 | tok/s 13239
step    730 | loss 1.2067 | lr 3.11e-04 | grad 2.75 | tok/s 14298
step    740 | loss 1.3994 | lr 3.11e-04 | grad 2.36 | tok/s 14131
step    750 | loss 1.1066 | lr 3.11e-04 | grad 2.42 | tok/s 14340
step    760 | loss 1.0156 | lr 3.11e-04 | grad 2.11 | tok/s 14347
step    770 | loss 0.9680 | lr 3.11e-04 | grad 2.03 | tok/s 14326
step    780 | loss 0.9135 | lr 3.11e-04 | grad 1.73 | tok/s 14337
step    790 | loss 1.0324 | lr 3.11e-04 | grad 2.88 | tok/s 13897
step    800 | loss 1.6687 | lr 3.11e-04 | grad 5.03 | tok/s 13858
step    810 | loss 1.6002 | lr 3.11e-04 | grad 2.02 | tok/s 13795
step    820 | loss 1.5714 | lr 3.11e-04 | grad 3.36 | tok/s 13269
step    830 | loss 1.4154 | lr 3.11e-04 | grad 2.28 | tok/s 14192
step    840 | loss 1.2737 | lr 3.11e-04 | grad 2.11 | tok/s 14305
step    850 | loss 1.4168 | lr 3.11e-04 | grad 1.96 | tok/s 14262
step    860 | loss 1.3600 | lr 3.11e-04 | grad 4.09 | tok/s 14108
step    870 | loss 1.3913 | lr 3.11e-04 | grad 2.56 | tok/s 13607
step    880 | loss 1.5307 | lr 3.11e-04 | grad 2.59 | tok/s 13648
step    890 | loss 1.5587 | lr 3.11e-04 | grad 2.91 | tok/s 13823
step    900 | loss 1.4468 | lr 3.11e-04 | grad 2.58 | tok/s 13840
step    910 | loss 1.3311 | lr 3.11e-04 | grad 3.34 | tok/s 13569
step    920 | loss 1.4278 | lr 3.11e-04 | grad 3.44 | tok/s 14067
step    930 | loss 1.4838 | lr 3.11e-04 | grad 2.89 | tok/s 13475
step    940 | loss 1.2686 | lr 3.11e-04 | grad 1.82 | tok/s 14180
step    950 | loss 1.3894 | lr 3.11e-04 | grad 2.16 | tok/s 14251
step    960 | loss 1.2304 | lr 3.11e-04 | grad 2.78 | tok/s 14248
step    970 | loss 1.6191 | lr 3.11e-04 | grad 3.36 | tok/s 13427
step    980 | loss 1.5177 | lr 3.11e-04 | grad 2.16 | tok/s 13803
step    990 | loss 1.3516 | lr 3.11e-04 | grad 2.08 | tok/s 14040
step   1000 | loss 1.7115 | lr 3.11e-04 | grad 11.38 | tok/s 13497
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7115.pt
step   1010 | loss 1.6006 | lr 3.11e-04 | grad 3.95 | tok/s 5035
step   1020 | loss 1.5412 | lr 3.11e-04 | grad 2.31 | tok/s 13291
step   1030 | loss 1.3011 | lr 3.11e-04 | grad 2.14 | tok/s 14049
step   1040 | loss 1.4153 | lr 3.11e-04 | grad 2.11 | tok/s 13937
step   1050 | loss 1.5202 | lr 3.11e-04 | grad 3.16 | tok/s 13553
step   1060 | loss 1.5604 | lr 3.11e-04 | grad 1.98 | tok/s 14136
step   1070 | loss 1.5465 | lr 3.11e-04 | grad 2.36 | tok/s 13829
step   1080 | loss 1.2957 | lr 3.11e-04 | grad 2.50 | tok/s 13066
step   1090 | loss 0.9314 | lr 3.11e-04 | grad 4.31 | tok/s 14499
step   1100 | loss 1.4214 | lr 3.11e-04 | grad 2.41 | tok/s 13828
step   1110 | loss 1.3139 | lr 3.11e-04 | grad 2.06 | tok/s 14431
step   1120 | loss 1.2424 | lr 3.11e-04 | grad 2.55 | tok/s 14443
step   1130 | loss 1.1908 | lr 3.11e-04 | grad 2.06 | tok/s 14422
step   1140 | loss 1.1955 | lr 3.11e-04 | grad 2.23 | tok/s 14429
step   1150 | loss 1.1859 | lr 3.11e-04 | grad 2.16 | tok/s 14402
step   1160 | loss 1.1262 | lr 3.11e-04 | grad 2.05 | tok/s 14405
step   1170 | loss 1.1904 | lr 3.11e-04 | grad 2.17 | tok/s 14399
step   1180 | loss 1.2166 | lr 3.11e-04 | grad 2.53 | tok/s 14403
step   1190 | loss 1.1112 | lr 3.11e-04 | grad 1.91 | tok/s 14413
step   1200 | loss 1.1337 | lr 3.11e-04 | grad 1.88 | tok/s 14388
step   1210 | loss 1.1699 | lr 3.11e-04 | grad 2.06 | tok/s 14390
step   1220 | loss 1.1847 | lr 3.11e-04 | grad 1.86 | tok/s 14409
step   1230 | loss 1.1524 | lr 3.11e-04 | grad 1.77 | tok/s 14408
step   1240 | loss 1.2346 | lr 3.11e-04 | grad 5.44 | tok/s 14093
step   1250 | loss 1.5730 | lr 3.11e-04 | grad 1.94 | tok/s 13724
step   1260 | loss 1.2024 | lr 3.11e-04 | grad 2.12 | tok/s 13551
step   1270 | loss 1.6143 | lr 3.11e-04 | grad 2.50 | tok/s 13328
step   1280 | loss 1.4782 | lr 3.11e-04 | grad 2.08 | tok/s 14089
step   1290 | loss 1.4086 | lr 3.11e-04 | grad 2.50 | tok/s 13903
step   1300 | loss 1.3967 | lr 3.11e-04 | grad 3.53 | tok/s 13646
step   1310 | loss 1.3572 | lr 3.11e-04 | grad 3.48 | tok/s 14288
step   1320 | loss 1.5056 | lr 3.11e-04 | grad 4.22 | tok/s 14147
step   1330 | loss 1.2851 | lr 3.11e-04 | grad 2.30 | tok/s 14103
step   1340 | loss 1.5040 | lr 3.11e-04 | grad 1.88 | tok/s 13104
step   1350 | loss 1.5963 | lr 3.11e-04 | grad 3.22 | tok/s 13368
step   1360 | loss 1.3278 | lr 3.11e-04 | grad 1.77 | tok/s 13961
step   1370 | loss 1.4095 | lr 3.11e-04 | grad 7.62 | tok/s 13696
step   1380 | loss 1.4522 | lr 3.11e-04 | grad 2.66 | tok/s 13159
step   1390 | loss 1.3165 | lr 3.11e-04 | grad 2.47 | tok/s 13641
step   1400 | loss 1.2531 | lr 3.11e-04 | grad 1.87 | tok/s 13783
step   1410 | loss 1.4086 | lr 3.11e-04 | grad 3.38 | tok/s 13499
step   1420 | loss 1.4810 | lr 3.11e-04 | grad 1.97 | tok/s 13508
step   1430 | loss 1.2154 | lr 3.11e-04 | grad 2.05 | tok/s 13679
step   1440 | loss 1.0602 | lr 3.11e-04 | grad 2.09 | tok/s 14377
step   1450 | loss 1.1680 | lr 3.11e-04 | grad 7.38 | tok/s 14158
step   1460 | loss 1.5149 | lr 3.11e-04 | grad 5.16 | tok/s 13414
step   1470 | loss 1.3282 | lr 3.11e-04 | grad 1.77 | tok/s 14229
step   1480 | loss 1.6467 | lr 3.11e-04 | grad 3.94 | tok/s 14073
step   1490 | loss 1.4181 | lr 3.11e-04 | grad 4.38 | tok/s 14271
step   1500 | loss 1.1833 | lr 3.11e-04 | grad 2.12 | tok/s 14364
step   1510 | loss 1.4111 | lr 3.11e-04 | grad 1.97 | tok/s 14145
step   1520 | loss 1.3449 | lr 3.11e-04 | grad 2.03 | tok/s 13876
step   1530 | loss 1.3093 | lr 3.11e-04 | grad 1.77 | tok/s 13947
step   1540 | loss 1.4909 | lr 3.11e-04 | grad 2.11 | tok/s 13684
step   1550 | loss 1.1622 | lr 3.11e-04 | grad 2.33 | tok/s 14273
step   1560 | loss 1.4839 | lr 3.11e-04 | grad 2.44 | tok/s 13519
step   1570 | loss 1.2224 | lr 3.11e-04 | grad 3.22 | tok/s 14231
step   1580 | loss 1.4771 | lr 3.11e-04 | grad 3.95 | tok/s 14181
step   1590 | loss 1.4238 | lr 3.11e-04 | grad 1.71 | tok/s 13484
step   1600 | loss 0.7846 | lr 3.11e-04 | grad 1.42 | tok/s 14523
step   1610 | loss 1.0998 | lr 3.11e-04 | grad 1.89 | tok/s 13350
step   1620 | loss 1.1943 | lr 3.11e-04 | grad 2.92 | tok/s 13658
step   1630 | loss 1.2690 | lr 3.11e-04 | grad 2.36 | tok/s 13947
step   1640 | loss 1.3324 | lr 3.11e-04 | grad 4.25 | tok/s 13552
step   1650 | loss 1.4274 | lr 3.11e-04 | grad 4.06 | tok/s 12823
step   1660 | loss 1.1552 | lr 3.11e-04 | grad 1.61 | tok/s 14323
step   1670 | loss 1.4544 | lr 3.11e-04 | grad 7.94 | tok/s 13640
step   1680 | loss 1.4310 | lr 3.11e-04 | grad 2.16 | tok/s 13320
step   1690 | loss 1.2911 | lr 3.11e-04 | grad 4.19 | tok/s 12729
step   1700 | loss 1.3734 | lr 3.11e-04 | grad 1.89 | tok/s 13517
step   1710 | loss 1.3125 | lr 3.11e-04 | grad 2.25 | tok/s 13918
step   1720 | loss 1.3447 | lr 3.11e-04 | grad 2.58 | tok/s 14346
step   1730 | loss 1.0351 | lr 3.11e-04 | grad 4.00 | tok/s 14326
step   1740 | loss 1.2707 | lr 3.11e-04 | grad 2.48 | tok/s 13737
step   1750 | loss 1.4134 | lr 3.11e-04 | grad 2.02 | tok/s 13993
step   1760 | loss 1.4633 | lr 3.11e-04 | grad 2.55 | tok/s 13798
step   1770 | loss 1.3324 | lr 3.11e-04 | grad 1.68 | tok/s 13578
step   1780 | loss 1.3821 | lr 3.11e-04 | grad 2.58 | tok/s 13874
step   1790 | loss 1.3019 | lr 3.11e-04 | grad 1.96 | tok/s 13778
step   1800 | loss 1.4512 | lr 3.11e-04 | grad 2.09 | tok/s 13472
step   1810 | loss 1.3247 | lr 3.11e-04 | grad 3.64 | tok/s 13632
step   1820 | loss 1.3485 | lr 3.11e-04 | grad 5.56 | tok/s 13755
step   1830 | loss 1.3234 | lr 3.11e-04 | grad 2.14 | tok/s 13994
step   1840 | loss 1.3152 | lr 3.11e-04 | grad 1.76 | tok/s 13343
step   1850 | loss 1.1855 | lr 3.11e-04 | grad 1.72 | tok/s 14193
step   1860 | loss 1.2580 | lr 3.11e-04 | grad 2.03 | tok/s 13347
step   1870 | loss 1.2057 | lr 3.11e-04 | grad 1.38 | tok/s 14087
step   1880 | loss 1.1803 | lr 3.11e-04 | grad 2.31 | tok/s 12748
step   1890 | loss 1.4328 | lr 3.11e-04 | grad 1.70 | tok/s 13449
step   1900 | loss 1.2786 | lr 3.11e-04 | grad 1.68 | tok/s 13642
step   1910 | loss 1.3688 | lr 3.11e-04 | grad 1.70 | tok/s 13294
step   1920 | loss 1.2728 | lr 3.11e-04 | grad 1.92 | tok/s 14202
step   1930 | loss 1.3735 | lr 3.11e-04 | grad 1.96 | tok/s 13356
step   1940 | loss 1.3657 | lr 3.11e-04 | grad 2.88 | tok/s 14072
step   1950 | loss 1.6560 | lr 3.11e-04 | grad 3.97 | tok/s 14313
step   1960 | loss 1.3134 | lr 3.11e-04 | grad 3.36 | tok/s 14311
step   1970 | loss 1.3943 | lr 3.11e-04 | grad 5.16 | tok/s 13836
step   1980 | loss 1.3644 | lr 3.11e-04 | grad 1.56 | tok/s 13493
step   1990 | loss 1.4649 | lr 3.11e-04 | grad 1.80 | tok/s 13609
step   2000 | loss 1.3922 | lr 3.11e-04 | grad 2.22 | tok/s 13801
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3922.pt
step   2010 | loss 1.0888 | lr 3.11e-04 | grad 2.05 | tok/s 5262
step   2020 | loss 1.2112 | lr 3.11e-04 | grad 2.56 | tok/s 14170
step   2030 | loss 0.9070 | lr 3.11e-04 | grad 2.42 | tok/s 14692
step   2040 | loss 1.1258 | lr 3.11e-04 | grad 1.46 | tok/s 14504
step   2050 | loss 1.2356 | lr 3.11e-04 | grad 2.62 | tok/s 13912
step   2060 | loss 1.5327 | lr 3.11e-04 | grad 3.52 | tok/s 13679
step   2070 | loss 1.7753 | lr 3.11e-04 | grad 5.78 | tok/s 13753
step   2080 | loss 1.8847 | lr 3.11e-04 | grad 3.73 | tok/s 14440
step   2090 | loss 1.4116 | lr 3.11e-04 | grad 4.16 | tok/s 14083
step   2100 | loss 1.1133 | lr 3.11e-04 | grad 1.87 | tok/s 14292
step   2110 | loss 1.3423 | lr 3.11e-04 | grad 1.95 | tok/s 13490
step   2120 | loss 0.6648 | lr 3.11e-04 | grad 1.59 | tok/s 14711
step   2130 | loss 1.2794 | lr 3.11e-04 | grad 2.05 | tok/s 13641
step   2140 | loss 1.3088 | lr 3.11e-04 | grad 1.89 | tok/s 14282
step   2150 | loss 1.1742 | lr 3.11e-04 | grad 1.65 | tok/s 14393
step   2160 | loss 1.1143 | lr 3.11e-04 | grad 1.95 | tok/s 14398
step   2170 | loss 1.1077 | lr 3.11e-04 | grad 1.58 | tok/s 14407
step   2180 | loss 1.1154 | lr 3.11e-04 | grad 1.72 | tok/s 14380
step   2190 | loss 1.1356 | lr 3.11e-04 | grad 1.51 | tok/s 14376
step   2200 | loss 1.0707 | lr 3.11e-04 | grad 1.41 | tok/s 14360
step   2210 | loss 1.0519 | lr 3.11e-04 | grad 1.54 | tok/s 14370
step   2220 | loss 1.0345 | lr 3.11e-04 | grad 1.55 | tok/s 14355
step   2230 | loss 1.3444 | lr 3.11e-04 | grad 2.17 | tok/s 14096
step   2240 | loss 1.2607 | lr 3.11e-04 | grad 2.66 | tok/s 13867
step   2250 | loss 1.3169 | lr 3.11e-04 | grad 2.56 | tok/s 14337
step   2260 | loss 1.4559 | lr 3.11e-04 | grad 1.78 | tok/s 13858
step   2270 | loss 1.8159 | lr 3.11e-04 | grad 2.05 | tok/s 14247
step   2280 | loss 1.2621 | lr 3.11e-04 | grad 2.20 | tok/s 14356
step   2290 | loss 1.4143 | lr 3.11e-04 | grad 2.12 | tok/s 13744
step   2300 | loss 1.2278 | lr 3.11e-04 | grad 3.20 | tok/s 13988
step   2310 | loss 1.3243 | lr 3.11e-04 | grad 3.97 | tok/s 13672
step   2320 | loss 1.7911 | lr 3.11e-04 | grad 4.00 | tok/s 13609
step   2330 | loss 1.3093 | lr 3.11e-04 | grad 2.44 | tok/s 13259
step   2340 | loss 1.3723 | lr 3.11e-04 | grad 2.52 | tok/s 13663
step   2350 | loss 1.2375 | lr 3.11e-04 | grad 2.45 | tok/s 14043
step   2360 | loss 1.1278 | lr 3.11e-04 | grad 1.91 | tok/s 14196
step   2370 | loss 1.4574 | lr 3.11e-04 | grad 2.94 | tok/s 14174
step   2380 | loss 1.2162 | lr 3.11e-04 | grad 3.75 | tok/s 14339
step   2390 | loss 1.0252 | lr 3.11e-04 | grad 1.45 | tok/s 14346
step   2400 | loss 0.9337 | lr 3.11e-04 | grad 3.02 | tok/s 14328
step   2410 | loss 1.1469 | lr 3.11e-04 | grad 2.44 | tok/s 13726
step   2420 | loss 1.3900 | lr 3.11e-04 | grad 2.56 | tok/s 13061
step   2430 | loss 1.1020 | lr 3.11e-04 | grad 2.03 | tok/s 14264
step   2440 | loss 1.3089 | lr 3.11e-04 | grad 1.95 | tok/s 13786
step   2450 | loss 1.3661 | lr 3.11e-04 | grad 2.45 | tok/s 13764
step   2460 | loss 0.9723 | lr 3.11e-04 | grad 1.89 | tok/s 14403
step   2470 | loss 1.1283 | lr 3.11e-04 | grad 2.20 | tok/s 14163
step   2480 | loss 1.1796 | lr 3.11e-04 | grad 2.17 | tok/s 14123
step   2490 | loss 1.3290 | lr 3.11e-04 | grad 1.87 | tok/s 13673
step   2500 | loss 1.2319 | lr 3.11e-04 | grad 2.67 | tok/s 14117
step   2510 | loss 0.9087 | lr 3.11e-04 | grad 2.64 | tok/s 14329
step   2520 | loss 1.4328 | lr 3.11e-04 | grad 2.33 | tok/s 14109
step   2530 | loss 1.2048 | lr 3.11e-04 | grad 2.02 | tok/s 13722
step   2540 | loss 1.2304 | lr 3.11e-04 | grad 1.76 | tok/s 13901
step   2550 | loss 1.0552 | lr 3.11e-04 | grad 1.84 | tok/s 14188
step   2560 | loss 1.4026 | lr 3.11e-04 | grad 2.02 | tok/s 13176
step   2570 | loss 1.1911 | lr 3.11e-04 | grad 1.80 | tok/s 13451
step   2580 | loss 1.1889 | lr 3.11e-04 | grad 2.55 | tok/s 13962
step   2590 | loss 1.3101 | lr 3.11e-04 | grad 1.77 | tok/s 13135
step   2600 | loss 1.4968 | lr 3.11e-04 | grad 4.16 | tok/s 13862
step   2610 | loss 1.1011 | lr 3.11e-04 | grad 3.73 | tok/s 13969
step   2620 | loss 1.4298 | lr 3.11e-04 | grad 3.41 | tok/s 14036
step   2630 | loss 1.2610 | lr 3.11e-04 | grad 4.47 | tok/s 14234
step   2640 | loss 1.3775 | lr 3.11e-04 | grad 1.84 | tok/s 13821
step   2650 | loss 1.2781 | lr 3.11e-04 | grad 2.03 | tok/s 14023
step   2660 | loss 1.2046 | lr 3.11e-04 | grad 1.99 | tok/s 13759
step   2670 | loss 1.3307 | lr 3.11e-04 | grad 1.64 | tok/s 13452
step   2680 | loss 1.3786 | lr 3.11e-04 | grad 1.52 | tok/s 13793
step   2690 | loss 1.1649 | lr 3.11e-04 | grad 2.69 | tok/s 14247
step   2700 | loss 1.3084 | lr 3.11e-04 | grad 2.59 | tok/s 13550
step   2710 | loss 1.3095 | lr 3.11e-04 | grad 2.36 | tok/s 13481
step   2720 | loss 1.2377 | lr 3.11e-04 | grad 1.95 | tok/s 13329
step   2730 | loss 1.0105 | lr 3.11e-04 | grad 2.86 | tok/s 14169
step   2740 | loss 1.6386 | lr 3.11e-04 | grad 2.88 | tok/s 13992
step   2750 | loss 1.3311 | lr 3.11e-04 | grad 5.34 | tok/s 14003
step   2760 | loss 1.2521 | lr 3.11e-04 | grad 2.50 | tok/s 12999
step   2770 | loss 1.2138 | lr 3.11e-04 | grad 1.42 | tok/s 14104
step   2780 | loss 1.0351 | lr 3.11e-04 | grad 1.74 | tok/s 14166
step   2790 | loss 1.6571 | lr 3.11e-04 | grad 2.64 | tok/s 12947
step   2800 | loss 1.0354 | lr 3.11e-04 | grad 1.94 | tok/s 14322
step   2810 | loss 1.2485 | lr 3.11e-04 | grad 1.77 | tok/s 13242
step   2820 | loss 1.2906 | lr 3.11e-04 | grad 4.28 | tok/s 13441
step   2830 | loss 0.7036 | lr 3.11e-04 | grad 5.25 | tok/s 14343
step   2840 | loss 0.9224 | lr 3.11e-04 | grad 6.75 | tok/s 14053
step   2850 | loss 1.5527 | lr 3.11e-04 | grad 4.25 | tok/s 13789
step   2860 | loss 1.3870 | lr 3.11e-04 | grad 2.41 | tok/s 13643
step   2870 | loss 1.3172 | lr 3.11e-04 | grad 3.38 | tok/s 13908
step   2880 | loss 1.1736 | lr 3.11e-04 | grad 1.99 | tok/s 14197
step   2890 | loss 1.2438 | lr 3.11e-04 | grad 2.44 | tok/s 14015
step   2900 | loss 1.2299 | lr 3.11e-04 | grad 4.19 | tok/s 14038
step   2910 | loss 1.2705 | lr 3.11e-04 | grad 2.38 | tok/s 13448
step   2920 | loss 1.5423 | lr 3.11e-04 | grad 5.25 | tok/s 13840
step   2930 | loss 1.2431 | lr 3.11e-04 | grad 1.89 | tok/s 13564
step   2940 | loss 1.1920 | lr 3.11e-04 | grad 1.72 | tok/s 13087
step   2950 | loss 1.1642 | lr 3.11e-04 | grad 2.56 | tok/s 14070
step   2960 | loss 1.1893 | lr 3.11e-04 | grad 2.11 | tok/s 14012
step   2970 | loss 1.5322 | lr 3.11e-04 | grad 9.56 | tok/s 13593
step   2980 | loss 1.7801 | lr 3.11e-04 | grad 10.88 | tok/s 14033
step   2990 | loss 1.3406 | lr 3.11e-04 | grad 2.09 | tok/s 14013
step   3000 | loss 1.2209 | lr 3.11e-04 | grad 2.27 | tok/s 13659
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2209.pt
step   3010 | loss 1.1796 | lr 3.11e-04 | grad 2.31 | tok/s 5144
step   3020 | loss 1.3261 | lr 3.11e-04 | grad 1.97 | tok/s 14121
step   3030 | loss 1.2899 | lr 3.11e-04 | grad 1.98 | tok/s 13574
step   3040 | loss 1.3306 | lr 3.11e-04 | grad 1.61 | tok/s 14391
step   3050 | loss 1.2004 | lr 3.11e-04 | grad 3.08 | tok/s 14015
step   3060 | loss 1.3866 | lr 3.11e-04 | grad 2.78 | tok/s 14262
step   3070 | loss 1.3248 | lr 3.11e-04 | grad 2.28 | tok/s 14448
step   3080 | loss 1.2924 | lr 3.11e-04 | grad 2.19 | tok/s 13949
step   3090 | loss 1.2359 | lr 3.11e-04 | grad 3.34 | tok/s 13836
step   3100 | loss 1.3320 | lr 3.11e-04 | grad 2.42 | tok/s 14127
step   3110 | loss 0.8392 | lr 3.11e-04 | grad 1.68 | tok/s 14431
step   3120 | loss 1.0262 | lr 3.11e-04 | grad 1.76 | tok/s 14073
step   3130 | loss 1.2098 | lr 3.11e-04 | grad 1.58 | tok/s 14058
step   3140 | loss 0.9659 | lr 3.11e-04 | grad 2.12 | tok/s 14438
step   3150 | loss 1.1014 | lr 3.11e-04 | grad 2.83 | tok/s 14151
step   3160 | loss 1.3977 | lr 3.11e-04 | grad 1.45 | tok/s 13522
step   3170 | loss 1.2217 | lr 3.11e-04 | grad 2.52 | tok/s 13529
step   3180 | loss 1.1942 | lr 3.11e-04 | grad 2.84 | tok/s 13950
step   3190 | loss 0.8328 | lr 3.11e-04 | grad 10.25 | tok/s 14493
step   3200 | loss 1.4035 | lr 3.11e-04 | grad 2.16 | tok/s 13917
step   3210 | loss 1.6502 | lr 3.11e-04 | grad 3.78 | tok/s 14006
step   3220 | loss 2.0884 | lr 3.11e-04 | grad 3.50 | tok/s 14387
step   3230 | loss 1.6671 | lr 3.11e-04 | grad 2.94 | tok/s 14387
step   3240 | loss 1.4759 | lr 3.11e-04 | grad 2.66 | tok/s 14394
step   3250 | loss 1.3984 | lr 3.11e-04 | grad 2.94 | tok/s 14403
step   3260 | loss 1.3435 | lr 3.11e-04 | grad 2.75 | tok/s 14373
step   3270 | loss 1.2948 | lr 3.11e-04 | grad 2.44 | tok/s 14362
step   3280 | loss 1.2345 | lr 3.11e-04 | grad 2.05 | tok/s 14355
step   3290 | loss 1.1976 | lr 3.11e-04 | grad 2.23 | tok/s 14356
step   3300 | loss 1.2103 | lr 3.11e-04 | grad 2.08 | tok/s 14380
step   3310 | loss 1.1808 | lr 3.11e-04 | grad 1.91 | tok/s 14358
step   3320 | loss 1.1645 | lr 3.11e-04 | grad 2.14 | tok/s 14371
step   3330 | loss 1.4344 | lr 3.11e-04 | grad 2.05 | tok/s 13487
step   3340 | loss 1.2825 | lr 3.11e-04 | grad 2.59 | tok/s 14148
step   3350 | loss 1.2553 | lr 3.11e-04 | grad 1.92 | tok/s 13581
step   3360 | loss 1.3005 | lr 3.11e-04 | grad 1.91 | tok/s 13347
step   3370 | loss 1.3679 | lr 3.11e-04 | grad 2.14 | tok/s 13693
step   3380 | loss 1.3651 | lr 3.11e-04 | grad 1.98 | tok/s 13797
step   3390 | loss 1.1481 | lr 3.11e-04 | grad 1.95 | tok/s 13971
step   3400 | loss 0.9639 | lr 3.11e-04 | grad 2.12 | tok/s 14348
step   3410 | loss 1.0574 | lr 3.11e-04 | grad 2.17 | tok/s 14193
step   3420 | loss 1.3230 | lr 3.11e-04 | grad 2.12 | tok/s 13302
step   3430 | loss 1.3461 | lr 3.11e-04 | grad 1.97 | tok/s 13803
step   3440 | loss 1.2125 | lr 3.11e-04 | grad 1.79 | tok/s 13972
step   3450 | loss 1.3243 | lr 3.11e-04 | grad 2.02 | tok/s 13854
step   3460 | loss 1.2280 | lr 3.11e-04 | grad 1.79 | tok/s 13979
step   3470 | loss 1.3161 | lr 3.11e-04 | grad 1.62 | tok/s 14060
step   3480 | loss 1.2222 | lr 3.11e-04 | grad 2.30 | tok/s 14106
step   3490 | loss 1.0697 | lr 3.11e-04 | grad 1.80 | tok/s 13525
step   3500 | loss 1.1292 | lr 3.11e-04 | grad 1.97 | tok/s 13794
step   3510 | loss 1.3091 | lr 3.11e-04 | grad 1.62 | tok/s 13931
step   3520 | loss 1.4098 | lr 3.11e-04 | grad 4.75 | tok/s 13721
step   3530 | loss 1.4172 | lr 3.11e-04 | grad 2.30 | tok/s 14138
step   3540 | loss 1.2776 | lr 3.11e-04 | grad 1.44 | tok/s 13350
step   3550 | loss 1.9150 | lr 3.11e-04 | grad 5.97 | tok/s 13133
step   3560 | loss 1.2867 | lr 3.11e-04 | grad 2.11 | tok/s 13295
step   3570 | loss 1.0789 | lr 3.11e-04 | grad 1.48 | tok/s 14026
step   3580 | loss 1.0007 | lr 3.11e-04 | grad 1.68 | tok/s 13647
step   3590 | loss 1.1980 | lr 3.11e-04 | grad 2.06 | tok/s 13628
step   3600 | loss 1.3697 | lr 3.11e-04 | grad 2.62 | tok/s 13060
step   3610 | loss 1.2339 | lr 3.11e-04 | grad 3.00 | tok/s 14195
step   3620 | loss 1.2776 | lr 3.11e-04 | grad 1.70 | tok/s 13813
step   3630 | loss 1.3514 | lr 3.11e-04 | grad 2.27 | tok/s 13860
step   3640 | loss 1.3410 | lr 3.11e-04 | grad 2.22 | tok/s 13313
step   3650 | loss 1.2450 | lr 3.11e-04 | grad 2.30 | tok/s 13423
step   3660 | loss 1.2837 | lr 3.11e-04 | grad 3.50 | tok/s 13336
step   3670 | loss 1.0164 | lr 3.11e-04 | grad 1.62 | tok/s 14223
step   3680 | loss 1.1797 | lr 3.11e-04 | grad 1.98 | tok/s 13253
step   3690 | loss 1.2222 | lr 3.11e-04 | grad 3.19 | tok/s 13372
step   3700 | loss 1.2244 | lr 3.11e-04 | grad 1.97 | tok/s 13057
step   3710 | loss 1.3813 | lr 3.11e-04 | grad 1.84 | tok/s 14161
step   3720 | loss 1.3066 | lr 3.11e-04 | grad 2.30 | tok/s 13747
step   3730 | loss 1.3033 | lr 3.11e-04 | grad 4.25 | tok/s 13689
step   3740 | loss 1.0578 | lr 3.11e-04 | grad 7.47 | tok/s 13804
step   3750 | loss 1.3740 | lr 3.11e-04 | grad 1.90 | tok/s 14117
step   3760 | loss 1.1655 | lr 3.11e-04 | grad 1.76 | tok/s 14338
step   3770 | loss 1.1157 | lr 3.11e-04 | grad 1.84 | tok/s 14333
step   3780 | loss 1.1011 | lr 3.11e-04 | grad 1.59 | tok/s 14345
step   3790 | loss 1.0806 | lr 3.11e-04 | grad 1.54 | tok/s 14342
step   3800 | loss 1.0928 | lr 3.11e-04 | grad 1.70 | tok/s 14305
step   3810 | loss 1.0445 | lr 3.11e-04 | grad 1.70 | tok/s 14336
step   3820 | loss 1.0478 | lr 3.11e-04 | grad 1.56 | tok/s 14332
step   3830 | loss 1.0264 | lr 3.11e-04 | grad 1.60 | tok/s 14340
step   3840 | loss 1.0402 | lr 3.11e-04 | grad 1.77 | tok/s 14329
step   3850 | loss 1.0030 | lr 3.11e-04 | grad 1.69 | tok/s 14336
step   3860 | loss 1.3329 | lr 3.11e-04 | grad 1.83 | tok/s 13690
step   3870 | loss 1.3928 | lr 3.11e-04 | grad 2.19 | tok/s 13439
step   3880 | loss 1.2580 | lr 3.11e-04 | grad 2.86 | tok/s 13416
step   3890 | loss 1.2441 | lr 3.11e-04 | grad 3.70 | tok/s 13735
step   3900 | loss 1.3123 | lr 3.11e-04 | grad 1.80 | tok/s 13851
step   3910 | loss 1.1582 | lr 3.11e-04 | grad 2.19 | tok/s 13592
step   3920 | loss 1.4168 | lr 3.11e-04 | grad 1.89 | tok/s 13568
step   3930 | loss 1.2559 | lr 3.11e-04 | grad 1.99 | tok/s 14041
step   3940 | loss 1.3426 | lr 3.11e-04 | grad 2.03 | tok/s 13630
step   3950 | loss 1.2636 | lr 3.11e-04 | grad 2.45 | tok/s 13242
step   3960 | loss 1.2035 | lr 3.11e-04 | grad 3.53 | tok/s 14335
step   3970 | loss 1.3079 | lr 3.11e-04 | grad 2.45 | tok/s 13568
step   3980 | loss 1.3322 | lr 3.11e-04 | grad 2.22 | tok/s 14081
step   3990 | loss 0.7865 | lr 3.11e-04 | grad 2.56 | tok/s 14540
step   4000 | loss 0.9282 | lr 3.11e-04 | grad 1.65 | tok/s 14279
  >>> saved checkpoint: checkpoint_step_004000_loss_0.9282.pt
step   4010 | loss 1.1471 | lr 3.11e-04 | grad 1.85 | tok/s 4979
step   4020 | loss 1.3297 | lr 3.11e-04 | grad 2.02 | tok/s 13381
step   4030 | loss 1.1738 | lr 3.11e-04 | grad 2.16 | tok/s 13880
step   4040 | loss 1.2732 | lr 3.11e-04 | grad 2.44 | tok/s 13792
step   4050 | loss 1.8108 | lr 3.11e-04 | grad 28.00 | tok/s 13492
step   4060 | loss 1.5828 | lr 3.11e-04 | grad 2.33 | tok/s 13773
step   4070 | loss 1.2738 | lr 3.11e-04 | grad 2.56 | tok/s 14042
step   4080 | loss 1.1973 | lr 3.11e-04 | grad 1.77 | tok/s 14215
step   4090 | loss 1.2409 | lr 3.11e-04 | grad 1.88 | tok/s 13769
step   4100 | loss 1.2487 | lr 3.11e-04 | grad 1.95 | tok/s 14009
step   4110 | loss 1.2955 | lr 3.11e-04 | grad 1.91 | tok/s 13821
step   4120 | loss 1.5329 | lr 3.11e-04 | grad 1.77 | tok/s 13986
step   4130 | loss 0.9004 | lr 3.11e-04 | grad 1.66 | tok/s 14053
step   4140 | loss 0.9975 | lr 3.11e-04 | grad 1.90 | tok/s 13433
step   4150 | loss 1.2039 | lr 3.11e-04 | grad 1.81 | tok/s 13218
step   4160 | loss 0.8686 | lr 3.11e-04 | grad 1.49 | tok/s 14372
step   4170 | loss 1.2650 | lr 3.11e-04 | grad 3.30 | tok/s 14022
step   4180 | loss 1.5491 | lr 3.11e-04 | grad 5.69 | tok/s 14233
step   4190 | loss 1.1377 | lr 3.11e-04 | grad 2.75 | tok/s 14363
step   4200 | loss 1.2833 | lr 3.11e-04 | grad 2.00 | tok/s 13756
step   4210 | loss 1.2181 | lr 3.11e-04 | grad 2.27 | tok/s 13951
step   4220 | loss 1.5691 | lr 3.11e-04 | grad 6.94 | tok/s 13527
step   4230 | loss 1.9843 | lr 3.11e-04 | grad 3.58 | tok/s 14373
step   4240 | loss 1.3848 | lr 3.11e-04 | grad 2.66 | tok/s 13437
step   4250 | loss 1.2405 | lr 3.11e-04 | grad 1.77 | tok/s 13395
step   4260 | loss 1.3584 | lr 3.11e-04 | grad 2.27 | tok/s 13872
step   4270 | loss 1.2014 | lr 3.11e-04 | grad 4.94 | tok/s 14205
step   4280 | loss 1.2488 | lr 3.11e-04 | grad 5.38 | tok/s 13014
step   4290 | loss 1.6852 | lr 3.11e-04 | grad 2.50 | tok/s 14338
step   4300 | loss 1.3670 | lr 3.11e-04 | grad 1.80 | tok/s 13793
step   4310 | loss 1.3253 | lr 3.11e-04 | grad 2.31 | tok/s 13870
step   4320 | loss 1.2067 | lr 3.11e-04 | grad 1.66 | tok/s 13882
step   4330 | loss 1.2359 | lr 3.11e-04 | grad 5.34 | tok/s 14162
step   4340 | loss 1.2887 | lr 3.11e-04 | grad 1.84 | tok/s 14012
step   4350 | loss 0.6643 | lr 3.11e-04 | grad 1.52 | tok/s 14486
step   4360 | loss 1.2892 | lr 3.11e-04 | grad 4.72 | tok/s 14173
step   4370 | loss 1.2931 | lr 3.11e-04 | grad 1.72 | tok/s 13298
step   4380 | loss 1.2313 | lr 3.11e-04 | grad 2.17 | tok/s 14001
step   4390 | loss 0.9430 | lr 3.11e-04 | grad 3.03 | tok/s 14345
step   4400 | loss 0.9534 | lr 3.11e-04 | grad 1.83 | tok/s 14306
step   4410 | loss 1.3725 | lr 3.11e-04 | grad 1.81 | tok/s 13790
step   4420 | loss 1.1904 | lr 3.11e-04 | grad 1.62 | tok/s 13911
step   4430 | loss 1.3739 | lr 3.11e-04 | grad 2.34 | tok/s 13226
step   4440 | loss 1.2970 | lr 3.11e-04 | grad 1.54 | tok/s 13242
step   4450 | loss 1.6008 | lr 3.11e-04 | grad 4.06 | tok/s 13668
step   4460 | loss 1.2581 | lr 3.11e-04 | grad 1.45 | tok/s 14023
step   4470 | loss 1.1750 | lr 3.11e-04 | grad 2.20 | tok/s 13669
step   4480 | loss 1.3378 | lr 3.11e-04 | grad 1.68 | tok/s 13924
step   4490 | loss 1.1971 | lr 3.11e-04 | grad 1.39 | tok/s 13360
step   4500 | loss 1.2879 | lr 3.11e-04 | grad 2.30 | tok/s 14122
step   4510 | loss 1.3838 | lr 3.11e-04 | grad 1.70 | tok/s 14149
step   4520 | loss 1.4947 | lr 3.11e-04 | grad 1.91 | tok/s 13461
step   4530 | loss 1.4641 | lr 3.11e-04 | grad 3.62 | tok/s 13057
step   4540 | loss 1.4211 | lr 3.11e-04 | grad 2.48 | tok/s 13366
step   4550 | loss 1.2692 | lr 3.11e-04 | grad 1.84 | tok/s 14050
step   4560 | loss 1.1585 | lr 3.11e-04 | grad 8.31 | tok/s 14011
step   4570 | loss 1.0694 | lr 3.11e-04 | grad 1.70 | tok/s 13338
step   4580 | loss 1.5063 | lr 3.11e-04 | grad 4.38 | tok/s 13460
step   4590 | loss 1.4081 | lr 3.11e-04 | grad 2.19 | tok/s 13646
step   4600 | loss 1.4793 | lr 3.11e-04 | grad 1.93 | tok/s 13373
step   4610 | loss 1.0092 | lr 3.11e-04 | grad 1.39 | tok/s 13971
step   4620 | loss 1.3679 | lr 3.11e-04 | grad 1.87 | tok/s 14178
step   4630 | loss 1.2341 | lr 3.11e-04 | grad 1.83 | tok/s 14305
step   4640 | loss 1.1886 | lr 3.11e-04 | grad 2.00 | tok/s 14295
step   4650 | loss 1.1572 | lr 3.11e-04 | grad 1.34 | tok/s 14268
step   4660 | loss 1.1610 | lr 3.11e-04 | grad 1.74 | tok/s 14284
step   4670 | loss 1.1375 | lr 3.11e-04 | grad 1.52 | tok/s 14280
step   4680 | loss 1.1109 | lr 3.11e-04 | grad 1.78 | tok/s 14254
step   4690 | loss 1.1129 | lr 3.11e-04 | grad 1.49 | tok/s 14299
step   4700 | loss 1.1275 | lr 3.11e-04 | grad 1.75 | tok/s 14253
step   4710 | loss 1.0615 | lr 3.11e-04 | grad 1.55 | tok/s 14267
step   4720 | loss 1.0199 | lr 3.11e-04 | grad 1.34 | tok/s 14281
step   4730 | loss 1.0738 | lr 3.11e-04 | grad 1.55 | tok/s 14285
step   4740 | loss 1.0764 | lr 3.11e-04 | grad 1.66 | tok/s 14283
step   4750 | loss 1.0457 | lr 3.11e-04 | grad 1.82 | tok/s 14272
step   4760 | loss 1.0572 | lr 3.11e-04 | grad 1.61 | tok/s 14296
step   4770 | loss 1.0435 | lr 3.11e-04 | grad 1.57 | tok/s 14265
step   4780 | loss 1.0719 | lr 3.11e-04 | grad 1.66 | tok/s 14284
step   4790 | loss 1.0162 | lr 3.11e-04 | grad 1.44 | tok/s 14285
step   4800 | loss 1.0050 | lr 3.11e-04 | grad 1.70 | tok/s 14323
step   4810 | loss 1.1416 | lr 3.11e-04 | grad 1.59 | tok/s 14283
step   4820 | loss 1.5332 | lr 3.11e-04 | grad 2.11 | tok/s 13847
step   4830 | loss 1.1916 | lr 3.11e-04 | grad 1.58 | tok/s 13854
step   4840 | loss 0.6369 | lr 3.11e-04 | grad 3.33 | tok/s 14484
step   4850 | loss 1.2185 | lr 3.11e-04 | grad 1.59 | tok/s 13591
step   4860 | loss 1.2329 | lr 3.11e-04 | grad 1.65 | tok/s 13171
step   4870 | loss 1.3561 | lr 3.11e-04 | grad 2.27 | tok/s 13259
step   4880 | loss 1.0737 | lr 3.11e-04 | grad 2.14 | tok/s 13885
step   4890 | loss 1.2587 | lr 3.11e-04 | grad 1.46 | tok/s 13438
step   4900 | loss 1.2516 | lr 3.11e-04 | grad 2.89 | tok/s 14154
step   4910 | loss 1.4268 | lr 3.11e-04 | grad 2.75 | tok/s 13960
step   4920 | loss 1.0803 | lr 3.11e-04 | grad 1.57 | tok/s 14317
step   4930 | loss 1.2486 | lr 3.11e-04 | grad 3.08 | tok/s 13628
step   4940 | loss 1.1970 | lr 3.11e-04 | grad 1.78 | tok/s 13506
step   4950 | loss 1.3573 | lr 3.11e-04 | grad 2.03 | tok/s 14065
step   4960 | loss 0.9962 | lr 3.11e-04 | grad 2.05 | tok/s 14240
step   4970 | loss 1.3868 | lr 3.11e-04 | grad 6.00 | tok/s 13894
step   4980 | loss 1.2715 | lr 3.11e-04 | grad 1.97 | tok/s 13313
step   4990 | loss 1.2791 | lr 3.11e-04 | grad 1.66 | tok/s 14340
step   5000 | loss 1.3324 | lr 3.11e-04 | grad 1.95 | tok/s 13592
  >>> saved checkpoint: checkpoint_step_005000_loss_1.3324.pt
step   5010 | loss 1.3220 | lr 3.11e-04 | grad 1.95 | tok/s 5063
step   5020 | loss 1.1718 | lr 3.11e-04 | grad 1.77 | tok/s 14074
step   5030 | loss 1.2630 | lr 3.11e-04 | grad 2.02 | tok/s 13713
step   5040 | loss 1.3742 | lr 3.11e-04 | grad 3.30 | tok/s 14155
step   5050 | loss 1.3169 | lr 3.11e-04 | grad 3.42 | tok/s 14089
step   5060 | loss 1.2769 | lr 3.11e-04 | grad 2.19 | tok/s 13300
step   5070 | loss 1.2629 | lr 3.11e-04 | grad 1.97 | tok/s 13636
step   5080 | loss 1.2835 | lr 3.11e-04 | grad 2.02 | tok/s 14011
step   5090 | loss 1.1015 | lr 3.11e-04 | grad 1.89 | tok/s 13901
step   5100 | loss 1.3059 | lr 3.11e-04 | grad 2.03 | tok/s 13756
step   5110 | loss 1.3148 | lr 3.11e-04 | grad 2.62 | tok/s 13727
step   5120 | loss 1.2157 | lr 3.11e-04 | grad 2.33 | tok/s 13617
step   5130 | loss 1.2514 | lr 3.11e-04 | grad 2.81 | tok/s 13947
step   5140 | loss 1.4084 | lr 3.11e-04 | grad 4.06 | tok/s 14338
step   5150 | loss 1.2723 | lr 3.11e-04 | grad 2.11 | tok/s 13345
step   5160 | loss 1.1861 | lr 3.11e-04 | grad 1.63 | tok/s 13451
step   5170 | loss 1.1777 | lr 3.11e-04 | grad 1.94 | tok/s 13612
step   5180 | loss 1.2772 | lr 3.11e-04 | grad 1.84 | tok/s 13125
step   5190 | loss 1.2842 | lr 3.11e-04 | grad 1.47 | tok/s 14413
step   5200 | loss 1.3107 | lr 3.11e-04 | grad 2.19 | tok/s 13900
step   5210 | loss 0.9324 | lr 3.11e-04 | grad 1.70 | tok/s 14434
step   5220 | loss 1.3596 | lr 3.11e-04 | grad 10.38 | tok/s 13432
step   5230 | loss 1.3209 | lr 3.11e-04 | grad 1.84 | tok/s 13959
step   5240 | loss 0.9619 | lr 3.11e-04 | grad 1.43 | tok/s 14452
step   5250 | loss 1.1056 | lr 3.11e-04 | grad 1.76 | tok/s 13923
step   5260 | loss 1.0688 | lr 3.11e-04 | grad 8.38 | tok/s 14165
step   5270 | loss 1.2922 | lr 3.11e-04 | grad 2.11 | tok/s 13307
step   5280 | loss 1.1253 | lr 3.11e-04 | grad 1.69 | tok/s 13567
step   5290 | loss 1.0431 | lr 3.11e-04 | grad 2.17 | tok/s 14282
step   5300 | loss 1.1663 | lr 3.11e-04 | grad 3.00 | tok/s 13527
step   5310 | loss 1.1985 | lr 3.11e-04 | grad 1.79 | tok/s 14369
step   5320 | loss 0.9451 | lr 3.11e-04 | grad 2.02 | tok/s 14310
step   5330 | loss 0.6457 | lr 3.11e-04 | grad 1.93 | tok/s 13590
step   5340 | loss 1.2448 | lr 3.11e-04 | grad 3.02 | tok/s 13993
step   5350 | loss 1.2426 | lr 3.11e-04 | grad 1.60 | tok/s 13497
step   5360 | loss 1.1808 | lr 3.11e-04 | grad 3.22 | tok/s 13672
step   5370 | loss 1.2403 | lr 3.11e-04 | grad 1.86 | tok/s 13114
step   5380 | loss 1.3165 | lr 3.11e-04 | grad 2.20 | tok/s 14057
step   5390 | loss 1.1791 | lr 3.11e-04 | grad 2.02 | tok/s 13756
step   5400 | loss 1.2911 | lr 3.11e-04 | grad 2.70 | tok/s 14076
step   5410 | loss 1.5273 | lr 3.11e-04 | grad 1.82 | tok/s 13564
step   5420 | loss 1.2470 | lr 3.11e-04 | grad 1.70 | tok/s 13911
step   5430 | loss 1.0243 | lr 3.11e-04 | grad 1.45 | tok/s 14029
step   5440 | loss 1.2084 | lr 3.11e-04 | grad 2.12 | tok/s 13306
step   5450 | loss 1.1093 | lr 3.11e-04 | grad 4.44 | tok/s 14089
step   5460 | loss 1.2811 | lr 3.11e-04 | grad 3.30 | tok/s 13863
step   5470 | loss 1.2445 | lr 3.11e-04 | grad 2.33 | tok/s 13578
step   5480 | loss 1.2112 | lr 3.11e-04 | grad 3.30 | tok/s 13566
step   5490 | loss 1.1973 | lr 3.11e-04 | grad 1.76 | tok/s 14260
step   5500 | loss 0.9114 | lr 3.11e-04 | grad 1.52 | tok/s 14415
step   5510 | loss 1.2149 | lr 3.11e-04 | grad 1.52 | tok/s 13753
step   5520 | loss 1.3235 | lr 3.11e-04 | grad 5.09 | tok/s 13885
step   5530 | loss 0.9817 | lr 3.11e-04 | grad 2.09 | tok/s 13903
step   5540 | loss 1.0790 | lr 3.11e-04 | grad 1.92 | tok/s 14103
step   5550 | loss 1.1736 | lr 3.11e-04 | grad 3.06 | tok/s 14006
step   5560 | loss 1.2742 | lr 3.11e-04 | grad 1.77 | tok/s 14232
step   5570 | loss 1.3117 | lr 3.11e-04 | grad 3.05 | tok/s 13170
step   5580 | loss 1.3923 | lr 3.11e-04 | grad 1.37 | tok/s 13252
step   5590 | loss 1.1979 | lr 3.11e-04 | grad 2.44 | tok/s 13390
step   5600 | loss 1.0884 | lr 3.11e-04 | grad 2.67 | tok/s 14384
step   5610 | loss 1.2541 | lr 3.11e-04 | grad 2.23 | tok/s 13331
step   5620 | loss 1.2581 | lr 3.11e-04 | grad 2.97 | tok/s 12822
step   5630 | loss 1.2196 | lr 3.11e-04 | grad 3.52 | tok/s 13261
step   5640 | loss 1.0709 | lr 3.11e-04 | grad 3.47 | tok/s 13824
step   5650 | loss 1.1939 | lr 3.11e-04 | grad 1.58 | tok/s 13707
step   5660 | loss 1.2107 | lr 3.11e-04 | grad 1.84 | tok/s 13115
step   5670 | loss 0.9164 | lr 3.11e-04 | grad 1.38 | tok/s 14043
step   5680 | loss 1.1261 | lr 3.11e-04 | grad 1.38 | tok/s 14303
step   5690 | loss 0.9581 | lr 3.11e-04 | grad 1.53 | tok/s 13815
step   5700 | loss 0.9292 | lr 3.11e-04 | grad 1.26 | tok/s 14332
step   5710 | loss 1.1359 | lr 3.11e-04 | grad 2.05 | tok/s 13581
step   5720 | loss 1.1934 | lr 3.11e-04 | grad 2.28 | tok/s 14020
step   5730 | loss 1.2233 | lr 3.11e-04 | grad 2.05 | tok/s 13422
step   5740 | loss 1.1951 | lr 3.11e-04 | grad 2.72 | tok/s 13242
step   5750 | loss 1.3401 | lr 3.11e-04 | grad 1.61 | tok/s 13514
step   5760 | loss 1.3971 | lr 3.11e-04 | grad 1.73 | tok/s 13805
step   5770 | loss 1.3411 | lr 3.11e-04 | grad 4.84 | tok/s 14055
step   5780 | loss 1.3663 | lr 3.11e-04 | grad 2.83 | tok/s 13881
step   5790 | loss 1.2500 | lr 3.11e-04 | grad 2.12 | tok/s 12954
step   5800 | loss 0.9724 | lr 3.11e-04 | grad 1.69 | tok/s 14395
step   5810 | loss 1.1897 | lr 3.11e-04 | grad 1.64 | tok/s 14062
step   5820 | loss 1.1658 | lr 3.11e-04 | grad 2.03 | tok/s 13113
step   5830 | loss 1.1105 | lr 3.11e-04 | grad 4.16 | tok/s 13931
step   5840 | loss 1.0313 | lr 3.11e-04 | grad 3.00 | tok/s 14111
step   5850 | loss 1.2386 | lr 3.11e-04 | grad 2.39 | tok/s 13998
step   5860 | loss 1.0086 | lr 3.11e-04 | grad 2.98 | tok/s 13928
step   5870 | loss 1.1705 | lr 3.11e-04 | grad 1.60 | tok/s 13561
step   5880 | loss 1.6417 | lr 3.11e-04 | grad 1.95 | tok/s 13753
step   5890 | loss 1.2051 | lr 3.11e-04 | grad 1.55 | tok/s 13974
step   5900 | loss 1.1063 | lr 3.11e-04 | grad 2.11 | tok/s 12985
step   5910 | loss 1.6255 | lr 3.11e-04 | grad 2.41 | tok/s 13891
step   5920 | loss 1.3487 | lr 3.11e-04 | grad 2.38 | tok/s 13577
step   5930 | loss 1.1008 | lr 3.11e-04 | grad 1.74 | tok/s 14007
step   5940 | loss 1.2979 | lr 3.11e-04 | grad 1.86 | tok/s 13664
step   5950 | loss 1.0129 | lr 3.11e-04 | grad 1.40 | tok/s 14342
step   5960 | loss 1.2059 | lr 3.11e-04 | grad 1.85 | tok/s 14047
step   5970 | loss 1.2740 | lr 3.11e-04 | grad 1.88 | tok/s 13763
step   5980 | loss 1.2572 | lr 3.11e-04 | grad 2.33 | tok/s 13718
step   5990 | loss 1.1291 | lr 3.11e-04 | grad 2.27 | tok/s 14195
step   6000 | loss 1.0220 | lr 3.11e-04 | grad 1.37 | tok/s 14328
  >>> saved checkpoint: checkpoint_step_006000_loss_1.0220.pt
step   6010 | loss 1.3490 | lr 3.11e-04 | grad 2.31 | tok/s 4759
step   6020 | loss 1.1877 | lr 3.11e-04 | grad 3.17 | tok/s 14063
step   6030 | loss 1.1267 | lr 3.11e-04 | grad 1.68 | tok/s 13644
step   6040 | loss 1.1271 | lr 3.11e-04 | grad 1.52 | tok/s 13938
step   6050 | loss 1.1638 | lr 3.11e-04 | grad 2.31 | tok/s 13248
step   6060 | loss 1.0146 | lr 3.11e-04 | grad 2.47 | tok/s 14439
step   6070 | loss 1.2507 | lr 3.11e-04 | grad 1.48 | tok/s 13724
step   6080 | loss 1.1009 | lr 3.11e-04 | grad 1.44 | tok/s 14283
step   6090 | loss 1.0360 | lr 3.11e-04 | grad 1.77 | tok/s 14488

Training complete! Final step: 6090
