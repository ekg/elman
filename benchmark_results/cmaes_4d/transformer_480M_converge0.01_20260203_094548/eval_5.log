Using device: cuda
Output directory: benchmark_results/cmaes_4d/transformer_480M_converge0.01_20260203_094548/eval_5/levelllama_100m_20260203_094554
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 289,740,800 parameters
Using schedule-free AdamW (lr=0.00010925013437140596)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 7.7658 | lr 1.09e-04 | grad 2.97 | tok/s 10099
step     20 | loss 3.3514 | lr 1.09e-04 | grad 1.04 | tok/s 20383
step     30 | loss 3.7409 | lr 1.09e-04 | grad 1.51 | tok/s 21596
step     40 | loss 7.0710 | lr 1.09e-04 | grad 19.25 | tok/s 22028
step     50 | loss 8.4023 | lr 1.09e-04 | grad 7.19 | tok/s 22241
step     60 | loss 6.5904 | lr 1.09e-04 | grad 5.25 | tok/s 22305
step     70 | loss 5.5133 | lr 1.09e-04 | grad 3.72 | tok/s 22287
step     80 | loss 5.0884 | lr 1.09e-04 | grad 3.53 | tok/s 22264
step     90 | loss 4.4144 | lr 1.09e-04 | grad 2.44 | tok/s 22250
step    100 | loss 4.1562 | lr 1.09e-04 | grad 2.28 | tok/s 22213
step    110 | loss 3.7588 | lr 1.09e-04 | grad 3.16 | tok/s 22028
step    120 | loss 3.6736 | lr 1.09e-04 | grad 2.06 | tok/s 20935
step    130 | loss 3.1353 | lr 1.09e-04 | grad 2.41 | tok/s 21433
step    140 | loss 3.3952 | lr 1.09e-04 | grad 7.25 | tok/s 21459
step    150 | loss 3.8178 | lr 1.09e-04 | grad 5.09 | tok/s 21970
step    160 | loss 3.1461 | lr 1.09e-04 | grad 1.31 | tok/s 21204
step    170 | loss 3.0104 | lr 1.09e-04 | grad 0.77 | tok/s 20892
step    180 | loss 3.4431 | lr 1.09e-04 | grad 1.45 | tok/s 21379
step    190 | loss 2.8173 | lr 1.09e-04 | grad 1.12 | tok/s 20970
step    200 | loss 2.7727 | lr 1.09e-04 | grad 1.05 | tok/s 21915
step    210 | loss 2.8261 | lr 1.09e-04 | grad 5.44 | tok/s 20790
step    220 | loss 3.1215 | lr 1.09e-04 | grad 2.09 | tok/s 21012
step    230 | loss 3.0470 | lr 1.09e-04 | grad 1.75 | tok/s 20984
step    240 | loss 3.2727 | lr 1.09e-04 | grad 3.31 | tok/s 21254
step    250 | loss 2.7215 | lr 1.09e-04 | grad 0.83 | tok/s 21123
step    260 | loss 2.8781 | lr 1.09e-04 | grad 3.88 | tok/s 21722
step    270 | loss 2.7622 | lr 1.09e-04 | grad 0.80 | tok/s 21219
step    280 | loss 2.6163 | lr 1.09e-04 | grad 0.72 | tok/s 19918
step    290 | loss 2.5955 | lr 1.09e-04 | grad 0.89 | tok/s 20593
step    300 | loss 2.9189 | lr 1.09e-04 | grad 1.48 | tok/s 20748
step    310 | loss 2.5796 | lr 1.09e-04 | grad 0.75 | tok/s 20658
step    320 | loss 2.8213 | lr 1.09e-04 | grad 2.81 | tok/s 20893
step    330 | loss 2.6452 | lr 1.09e-04 | grad 0.77 | tok/s 21119
step    340 | loss 3.0294 | lr 1.09e-04 | grad 1.69 | tok/s 21017
step    350 | loss 3.0494 | lr 1.09e-04 | grad 1.28 | tok/s 21634
step    360 | loss 2.5622 | lr 1.09e-04 | grad 1.13 | tok/s 20682
step    370 | loss 2.7073 | lr 1.09e-04 | grad 1.45 | tok/s 21815
step    380 | loss 2.6558 | lr 1.09e-04 | grad 0.93 | tok/s 21993
step    390 | loss 2.6427 | lr 1.09e-04 | grad 0.86 | tok/s 21990
step    400 | loss 2.7693 | lr 1.09e-04 | grad 1.41 | tok/s 20835
step    410 | loss 2.5848 | lr 1.09e-04 | grad 1.06 | tok/s 21021
step    420 | loss 2.8803 | lr 1.09e-04 | grad 1.18 | tok/s 21953
step    430 | loss 2.6731 | lr 1.09e-04 | grad 0.84 | tok/s 21571
step    440 | loss 2.6238 | lr 1.09e-04 | grad 1.20 | tok/s 20893
step    450 | loss 2.5243 | lr 1.09e-04 | grad 0.96 | tok/s 21130
step    460 | loss 2.6803 | lr 1.09e-04 | grad 0.78 | tok/s 21447
step    470 | loss 2.6705 | lr 1.09e-04 | grad 3.00 | tok/s 21275
step    480 | loss 2.7816 | lr 1.09e-04 | grad 1.35 | tok/s 21749
step    490 | loss 2.5684 | lr 1.09e-04 | grad 0.96 | tok/s 20880
step    500 | loss 2.6872 | lr 1.09e-04 | grad 0.86 | tok/s 21157
step    510 | loss 2.5556 | lr 1.09e-04 | grad 1.27 | tok/s 20270
step    520 | loss 2.4297 | lr 1.09e-04 | grad 1.38 | tok/s 21229
step    530 | loss 2.5512 | lr 1.09e-04 | grad 1.14 | tok/s 20879
step    540 | loss 2.5526 | lr 1.09e-04 | grad 0.57 | tok/s 20439
step    550 | loss 2.2352 | lr 1.09e-04 | grad 1.84 | tok/s 21346
step    560 | loss 2.5122 | lr 1.09e-04 | grad 0.86 | tok/s 21985
step    570 | loss 2.4280 | lr 1.09e-04 | grad 0.70 | tok/s 21973
step    580 | loss 2.3918 | lr 1.09e-04 | grad 0.60 | tok/s 21974
step    590 | loss 2.4244 | lr 1.09e-04 | grad 0.62 | tok/s 21968
step    600 | loss 2.4326 | lr 1.09e-04 | grad 0.91 | tok/s 21959
step    610 | loss 2.3409 | lr 1.09e-04 | grad 0.58 | tok/s 21975
step    620 | loss 2.3407 | lr 1.09e-04 | grad 0.70 | tok/s 21884
step    630 | loss 2.3536 | lr 1.09e-04 | grad 2.30 | tok/s 20681
step    640 | loss 2.6035 | lr 1.09e-04 | grad 2.42 | tok/s 20953
step    650 | loss 2.3748 | lr 1.09e-04 | grad 0.84 | tok/s 20919
step    660 | loss 2.4576 | lr 1.09e-04 | grad 1.23 | tok/s 21724
step    670 | loss 2.5341 | lr 1.09e-04 | grad 2.62 | tok/s 21003
step    680 | loss 2.4543 | lr 1.09e-04 | grad 1.16 | tok/s 20676
step    690 | loss 2.4763 | lr 1.09e-04 | grad 0.80 | tok/s 20523
step    700 | loss 2.3675 | lr 1.09e-04 | grad 1.23 | tok/s 20977
step    710 | loss 2.4928 | lr 1.09e-04 | grad 2.36 | tok/s 20638
step    720 | loss 2.3494 | lr 1.09e-04 | grad 0.80 | tok/s 21439
step    730 | loss 2.3949 | lr 1.09e-04 | grad 0.64 | tok/s 21091
step    740 | loss 2.8513 | lr 1.09e-04 | grad 2.52 | tok/s 21671
step    750 | loss 2.7297 | lr 1.09e-04 | grad 0.89 | tok/s 21912
step    760 | loss 2.3931 | lr 1.09e-04 | grad 1.75 | tok/s 21440
step    770 | loss 2.4229 | lr 1.09e-04 | grad 0.79 | tok/s 21104
step    780 | loss 2.3394 | lr 1.09e-04 | grad 1.12 | tok/s 21226
step    790 | loss 2.7711 | lr 1.09e-04 | grad 3.48 | tok/s 21677
step    800 | loss 2.2711 | lr 1.09e-04 | grad 1.87 | tok/s 21331
step    810 | loss 2.1184 | lr 1.09e-04 | grad 2.16 | tok/s 20614
step    820 | loss 2.3464 | lr 1.09e-04 | grad 1.22 | tok/s 21033
step    830 | loss 2.3135 | lr 1.09e-04 | grad 0.71 | tok/s 20751
step    840 | loss 2.4837 | lr 1.09e-04 | grad 0.85 | tok/s 20664
step    850 | loss 2.5224 | lr 1.09e-04 | grad 0.84 | tok/s 21089
step    860 | loss 2.5566 | lr 1.09e-04 | grad 1.81 | tok/s 21447
step    870 | loss 2.8211 | lr 1.09e-04 | grad 0.68 | tok/s 21618
step    880 | loss 2.3627 | lr 1.09e-04 | grad 0.79 | tok/s 21200
step    890 | loss 2.2540 | lr 1.09e-04 | grad 0.71 | tok/s 21102
step    900 | loss 2.3092 | lr 1.09e-04 | grad 0.98 | tok/s 21014
step    910 | loss 2.3936 | lr 1.09e-04 | grad 3.39 | tok/s 20780
step    920 | loss 2.3051 | lr 1.09e-04 | grad 0.74 | tok/s 21002
step    930 | loss 2.2961 | lr 1.09e-04 | grad 0.98 | tok/s 21289
step    940 | loss 2.2590 | lr 1.09e-04 | grad 0.72 | tok/s 20803
step    950 | loss 2.2839 | lr 1.09e-04 | grad 1.04 | tok/s 20459
step    960 | loss 2.2517 | lr 1.09e-04 | grad 0.67 | tok/s 21019
step    970 | loss 2.1987 | lr 1.09e-04 | grad 0.79 | tok/s 21018
step    980 | loss 3.5144 | lr 1.09e-04 | grad 2.48 | tok/s 21865
step    990 | loss 2.4879 | lr 1.09e-04 | grad 0.94 | tok/s 20949
step   1000 | loss 2.3830 | lr 1.09e-04 | grad 0.93 | tok/s 21007
  >>> saved checkpoint: checkpoint_step_001000_loss_2.3830.pt
step   1010 | loss 2.1177 | lr 1.09e-04 | grad 1.00 | tok/s 14073
step   1020 | loss 2.2146 | lr 1.09e-04 | grad 1.12 | tok/s 22020
step   1030 | loss 2.3762 | lr 1.09e-04 | grad 1.03 | tok/s 20948
step   1040 | loss 2.7867 | lr 1.09e-04 | grad 3.06 | tok/s 21456
step   1050 | loss 2.5085 | lr 1.09e-04 | grad 0.83 | tok/s 21609
step   1060 | loss 2.0128 | lr 1.09e-04 | grad 0.85 | tok/s 21292
step   1070 | loss 2.1861 | lr 1.09e-04 | grad 0.96 | tok/s 21267
step   1080 | loss 2.1410 | lr 1.09e-04 | grad 0.92 | tok/s 21995
step   1090 | loss 2.1415 | lr 1.09e-04 | grad 0.71 | tok/s 21991
step   1100 | loss 2.1171 | lr 1.09e-04 | grad 1.09 | tok/s 21979
step   1110 | loss 2.1006 | lr 1.09e-04 | grad 0.88 | tok/s 21967
step   1120 | loss 2.2028 | lr 1.09e-04 | grad 0.74 | tok/s 21401
step   1130 | loss 2.8100 | lr 1.09e-04 | grad 1.16 | tok/s 21626
step   1140 | loss 2.5061 | lr 1.09e-04 | grad 1.04 | tok/s 21868
step   1150 | loss 2.8997 | lr 1.09e-04 | grad 2.69 | tok/s 21387
step   1160 | loss 2.4193 | lr 1.09e-04 | grad 3.56 | tok/s 20687
step   1170 | loss 2.3249 | lr 1.09e-04 | grad 1.37 | tok/s 20649
step   1180 | loss 2.2914 | lr 1.09e-04 | grad 0.97 | tok/s 21722
step   1190 | loss 2.6635 | lr 1.09e-04 | grad 2.19 | tok/s 21755
step   1200 | loss 2.2205 | lr 1.09e-04 | grad 0.84 | tok/s 21972
step   1210 | loss 2.0988 | lr 1.09e-04 | grad 0.84 | tok/s 20695
step   1220 | loss 2.2509 | lr 1.09e-04 | grad 1.27 | tok/s 21380
step   1230 | loss 2.2528 | lr 1.09e-04 | grad 1.01 | tok/s 21521
step   1240 | loss 2.2843 | lr 1.09e-04 | grad 1.33 | tok/s 21755
step   1250 | loss 2.3946 | lr 1.09e-04 | grad 2.06 | tok/s 21241
step   1260 | loss 2.8813 | lr 1.09e-04 | grad 0.69 | tok/s 21830
step   1270 | loss 2.1871 | lr 1.09e-04 | grad 1.64 | tok/s 21167
step   1280 | loss 2.2746 | lr 1.09e-04 | grad 1.36 | tok/s 21222
step   1290 | loss 2.2136 | lr 1.09e-04 | grad 1.12 | tok/s 20740
step   1300 | loss 2.5028 | lr 1.09e-04 | grad 2.80 | tok/s 20676
step   1310 | loss 2.6177 | lr 1.09e-04 | grad 0.76 | tok/s 21543
step   1320 | loss 2.3249 | lr 1.09e-04 | grad 1.80 | tok/s 21469
step   1330 | loss 2.4298 | lr 1.09e-04 | grad 0.94 | tok/s 21440
step   1340 | loss 2.3846 | lr 1.09e-04 | grad 0.93 | tok/s 20765
step   1350 | loss 2.3068 | lr 1.09e-04 | grad 0.87 | tok/s 21588
step   1360 | loss 2.3533 | lr 1.09e-04 | grad 0.74 | tok/s 20281
step   1370 | loss 2.5927 | lr 1.09e-04 | grad 3.36 | tok/s 21663
step   1380 | loss 2.3360 | lr 1.09e-04 | grad 0.91 | tok/s 20986
step   1390 | loss 2.4479 | lr 1.09e-04 | grad 1.16 | tok/s 21401
step   1400 | loss 2.3218 | lr 1.09e-04 | grad 0.84 | tok/s 20918
step   1410 | loss 2.1532 | lr 1.09e-04 | grad 1.04 | tok/s 20554
step   1420 | loss 2.6656 | lr 1.09e-04 | grad 1.06 | tok/s 21822
step   1430 | loss 2.5431 | lr 1.09e-04 | grad 0.71 | tok/s 21108
step   1440 | loss 2.2632 | lr 1.09e-04 | grad 1.17 | tok/s 21277
step   1450 | loss 2.2923 | lr 1.09e-04 | grad 1.01 | tok/s 21511
step   1460 | loss 2.3083 | lr 1.09e-04 | grad 1.20 | tok/s 20876
step   1470 | loss 2.1669 | lr 1.09e-04 | grad 1.31 | tok/s 20599
step   1480 | loss 2.2561 | lr 1.09e-04 | grad 1.64 | tok/s 21320
step   1490 | loss 2.4210 | lr 1.09e-04 | grad 3.91 | tok/s 21130
step   1500 | loss 2.5607 | lr 1.09e-04 | grad 1.34 | tok/s 21507
step   1510 | loss 2.1369 | lr 1.09e-04 | grad 0.86 | tok/s 21073
step   1520 | loss 2.2061 | lr 1.09e-04 | grad 1.29 | tok/s 20991
step   1530 | loss 2.1847 | lr 1.09e-04 | grad 1.09 | tok/s 21563
step   1540 | loss 2.3337 | lr 1.09e-04 | grad 1.27 | tok/s 21592
step   1550 | loss 2.2671 | lr 1.09e-04 | grad 1.98 | tok/s 21156
step   1560 | loss 2.3087 | lr 1.09e-04 | grad 0.97 | tok/s 21846
step   1570 | loss 2.3452 | lr 1.09e-04 | grad 1.13 | tok/s 21359
step   1580 | loss 2.2168 | lr 1.09e-04 | grad 0.83 | tok/s 21501
step   1590 | loss 2.2517 | lr 1.09e-04 | grad 1.53 | tok/s 20681
step   1600 | loss 2.1846 | lr 1.09e-04 | grad 3.75 | tok/s 21824
step   1610 | loss 2.6034 | lr 1.09e-04 | grad 2.97 | tok/s 21302
step   1620 | loss 2.9548 | lr 1.09e-04 | grad 1.98 | tok/s 22005
step   1630 | loss 2.8506 | lr 1.09e-04 | grad 1.72 | tok/s 22002
step   1640 | loss 2.7651 | lr 1.09e-04 | grad 1.57 | tok/s 22005
step   1650 | loss 2.7151 | lr 1.09e-04 | grad 1.26 | tok/s 21995
step   1660 | loss 2.6848 | lr 1.09e-04 | grad 1.31 | tok/s 22000
step   1670 | loss 2.5390 | lr 1.09e-04 | grad 2.73 | tok/s 21319
step   1680 | loss 2.2082 | lr 1.09e-04 | grad 1.02 | tok/s 21120
step   1690 | loss 2.1954 | lr 1.09e-04 | grad 1.23 | tok/s 20629
step   1700 | loss 2.1497 | lr 1.09e-04 | grad 1.12 | tok/s 21425
step   1710 | loss 2.2220 | lr 1.09e-04 | grad 1.35 | tok/s 21520
step   1720 | loss 2.1314 | lr 1.09e-04 | grad 0.88 | tok/s 20837
step   1730 | loss 2.4024 | lr 1.09e-04 | grad 3.36 | tok/s 21501
step   1740 | loss 2.2031 | lr 1.09e-04 | grad 1.35 | tok/s 21611
step   1750 | loss 2.1899 | lr 1.09e-04 | grad 1.19 | tok/s 21170
step   1760 | loss 2.0988 | lr 1.09e-04 | grad 1.12 | tok/s 20948
step   1770 | loss 2.6631 | lr 1.09e-04 | grad 1.25 | tok/s 21453
step   1780 | loss 2.4119 | lr 1.09e-04 | grad 0.99 | tok/s 20244
step   1790 | loss 2.0970 | lr 1.09e-04 | grad 0.95 | tok/s 20578
step   1800 | loss 2.2275 | lr 1.09e-04 | grad 0.85 | tok/s 21081
step   1810 | loss 2.1919 | lr 1.09e-04 | grad 1.41 | tok/s 21261
step   1820 | loss 2.2633 | lr 1.09e-04 | grad 1.29 | tok/s 20970
step   1830 | loss 2.0886 | lr 1.09e-04 | grad 0.71 | tok/s 20384
step   1840 | loss 2.3483 | lr 1.09e-04 | grad 0.75 | tok/s 21122
step   1850 | loss 2.2343 | lr 1.09e-04 | grad 0.98 | tok/s 20976
step   1860 | loss 2.1654 | lr 1.09e-04 | grad 1.06 | tok/s 20899
step   1870 | loss 2.1435 | lr 1.09e-04 | grad 1.00 | tok/s 21243
step   1880 | loss 2.3028 | lr 1.09e-04 | grad 1.31 | tok/s 21419
step   1890 | loss 2.1408 | lr 1.09e-04 | grad 1.01 | tok/s 22003
step   1900 | loss 2.0918 | lr 1.09e-04 | grad 0.71 | tok/s 21998
step   1910 | loss 2.0570 | lr 1.09e-04 | grad 0.99 | tok/s 22004
step   1920 | loss 2.0605 | lr 1.09e-04 | grad 0.77 | tok/s 21984
step   1930 | loss 2.0780 | lr 1.09e-04 | grad 1.48 | tok/s 21901
step   1940 | loss 2.2839 | lr 1.09e-04 | grad 1.14 | tok/s 20829
step   1950 | loss 2.1970 | lr 1.09e-04 | grad 0.90 | tok/s 20673
step   1960 | loss 2.3613 | lr 1.09e-04 | grad 1.45 | tok/s 20930
step   1970 | loss 2.3640 | lr 1.09e-04 | grad 1.06 | tok/s 21359
step   1980 | loss 2.2990 | lr 1.09e-04 | grad 1.71 | tok/s 20673
step   1990 | loss 2.5978 | lr 1.09e-04 | grad 2.36 | tok/s 21285
step   2000 | loss 1.9691 | lr 1.09e-04 | grad 1.12 | tok/s 21992
  >>> saved checkpoint: checkpoint_step_002000_loss_1.9691.pt
step   2010 | loss 2.2738 | lr 1.09e-04 | grad 1.69 | tok/s 13400
step   2020 | loss 2.1243 | lr 1.09e-04 | grad 1.15 | tok/s 20882
step   2030 | loss 2.4350 | lr 1.09e-04 | grad 6.84 | tok/s 20637
step   2040 | loss 2.1954 | lr 1.09e-04 | grad 1.33 | tok/s 21003
step   2050 | loss 2.0501 | lr 1.09e-04 | grad 0.92 | tok/s 21310
step   2060 | loss 2.4401 | lr 1.09e-04 | grad 1.99 | tok/s 21324
step   2070 | loss 1.8886 | lr 1.09e-04 | grad 1.44 | tok/s 21318
step   2080 | loss 2.1220 | lr 1.09e-04 | grad 1.24 | tok/s 20314
step   2090 | loss 2.4381 | lr 1.09e-04 | grad 2.81 | tok/s 21692
step   2100 | loss 3.1384 | lr 1.09e-04 | grad 1.84 | tok/s 21927
step   2110 | loss 2.2249 | lr 1.09e-04 | grad 0.92 | tok/s 20963
step   2120 | loss 3.0096 | lr 1.09e-04 | grad 3.03 | tok/s 21457
step   2130 | loss 2.0903 | lr 1.09e-04 | grad 0.86 | tok/s 20419
step   2140 | loss 2.5150 | lr 1.09e-04 | grad 0.83 | tok/s 21557
step   2150 | loss 2.4530 | lr 1.09e-04 | grad 1.48 | tok/s 21099
step   2160 | loss 2.2332 | lr 1.09e-04 | grad 1.39 | tok/s 21187
step   2170 | loss 2.1096 | lr 1.09e-04 | grad 3.64 | tok/s 21373
step   2180 | loss 1.9525 | lr 1.09e-04 | grad 1.19 | tok/s 21825
step   2190 | loss 2.4459 | lr 1.09e-04 | grad 1.19 | tok/s 21125
step   2200 | loss 2.5420 | lr 1.09e-04 | grad 2.55 | tok/s 21848
step   2210 | loss 2.5421 | lr 1.09e-04 | grad 1.15 | tok/s 21503
step   2220 | loss 2.0847 | lr 1.09e-04 | grad 0.85 | tok/s 20681
step   2230 | loss 2.2783 | lr 1.09e-04 | grad 1.72 | tok/s 20820
step   2240 | loss 2.0842 | lr 1.09e-04 | grad 1.09 | tok/s 21264
step   2250 | loss 2.1519 | lr 1.09e-04 | grad 1.13 | tok/s 20836
step   2260 | loss 2.3368 | lr 1.09e-04 | grad 2.08 | tok/s 21740
step   2270 | loss 2.3459 | lr 1.09e-04 | grad 1.48 | tok/s 20273
step   2280 | loss 2.1263 | lr 1.09e-04 | grad 0.84 | tok/s 21122
step   2290 | loss 2.0134 | lr 1.09e-04 | grad 0.81 | tok/s 20869
step   2300 | loss 2.3271 | lr 1.09e-04 | grad 0.98 | tok/s 20748
step   2310 | loss 2.1086 | lr 1.09e-04 | grad 0.89 | tok/s 21096
step   2320 | loss 2.0548 | lr 1.09e-04 | grad 1.20 | tok/s 21977
step   2330 | loss 2.0579 | lr 1.09e-04 | grad 1.00 | tok/s 21950
step   2340 | loss 2.0463 | lr 1.09e-04 | grad 1.03 | tok/s 21982
step   2350 | loss 2.0268 | lr 1.09e-04 | grad 0.93 | tok/s 21992
step   2360 | loss 2.0130 | lr 1.09e-04 | grad 0.84 | tok/s 21987
step   2370 | loss 1.9870 | lr 1.09e-04 | grad 0.85 | tok/s 21976
step   2380 | loss 1.9931 | lr 1.09e-04 | grad 1.08 | tok/s 21977
step   2390 | loss 2.0238 | lr 1.09e-04 | grad 1.06 | tok/s 21994
step   2400 | loss 2.0237 | lr 1.09e-04 | grad 1.28 | tok/s 21995
step   2410 | loss 2.0580 | lr 1.09e-04 | grad 0.88 | tok/s 21979
step   2420 | loss 2.2822 | lr 1.09e-04 | grad 0.98 | tok/s 21294
step   2430 | loss 1.6831 | lr 1.09e-04 | grad 0.97 | tok/s 21339
step   2440 | loss 2.0810 | lr 1.09e-04 | grad 1.01 | tok/s 20124
step   2450 | loss 2.1253 | lr 1.09e-04 | grad 1.33 | tok/s 21161
step   2460 | loss 2.3296 | lr 1.09e-04 | grad 1.40 | tok/s 21585
step   2470 | loss 2.0867 | lr 1.09e-04 | grad 3.06 | tok/s 21261
step   2480 | loss 2.2316 | lr 1.09e-04 | grad 2.16 | tok/s 21223
step   2490 | loss 2.3075 | lr 1.09e-04 | grad 2.64 | tok/s 21505
step   2500 | loss 2.4363 | lr 1.09e-04 | grad 1.65 | tok/s 21296
step   2510 | loss 2.2247 | lr 1.09e-04 | grad 1.26 | tok/s 21084
step   2520 | loss 2.0985 | lr 1.09e-04 | grad 1.05 | tok/s 20884
step   2530 | loss 2.3401 | lr 1.09e-04 | grad 1.29 | tok/s 21333
step   2540 | loss 2.1322 | lr 1.09e-04 | grad 1.09 | tok/s 20454
step   2550 | loss 2.1201 | lr 1.09e-04 | grad 0.95 | tok/s 21197
step   2560 | loss 2.2586 | lr 1.09e-04 | grad 0.95 | tok/s 20794
step   2570 | loss 2.0778 | lr 1.09e-04 | grad 0.88 | tok/s 20971
step   2580 | loss 2.4669 | lr 1.09e-04 | grad 1.05 | tok/s 21049
step   2590 | loss 2.0931 | lr 1.09e-04 | grad 1.16 | tok/s 20797
step   2600 | loss 2.1748 | lr 1.09e-04 | grad 0.83 | tok/s 20531
step   2610 | loss 2.2877 | lr 1.09e-04 | grad 1.30 | tok/s 21571
step   2620 | loss 2.2551 | lr 1.09e-04 | grad 1.20 | tok/s 20886
step   2630 | loss 2.1145 | lr 1.09e-04 | grad 0.92 | tok/s 21808
step   2640 | loss 2.1533 | lr 1.09e-04 | grad 0.93 | tok/s 20883
step   2650 | loss 2.1140 | lr 1.09e-04 | grad 1.22 | tok/s 21207
step   2660 | loss 2.1244 | lr 1.09e-04 | grad 1.02 | tok/s 21231
step   2670 | loss 2.3312 | lr 1.09e-04 | grad 1.32 | tok/s 21851
step   2680 | loss 2.1436 | lr 1.09e-04 | grad 0.96 | tok/s 20566
step   2690 | loss 2.0130 | lr 1.09e-04 | grad 0.82 | tok/s 20538
step   2700 | loss 2.1574 | lr 1.09e-04 | grad 1.19 | tok/s 20952
step   2710 | loss 2.4331 | lr 1.09e-04 | grad 2.80 | tok/s 21300
step   2720 | loss 2.3241 | lr 1.09e-04 | grad 1.38 | tok/s 21297
step   2730 | loss 2.1610 | lr 1.09e-04 | grad 1.05 | tok/s 21033
step   2740 | loss 2.1581 | lr 1.09e-04 | grad 1.18 | tok/s 20934
step   2750 | loss 2.2918 | lr 1.09e-04 | grad 1.31 | tok/s 21190
step   2760 | loss 2.0838 | lr 1.09e-04 | grad 1.11 | tok/s 21714
step   2770 | loss 2.5168 | lr 1.09e-04 | grad 3.00 | tok/s 21354
step   2780 | loss 2.1541 | lr 1.09e-04 | grad 1.37 | tok/s 21229
step   2790 | loss 2.1239 | lr 1.09e-04 | grad 2.20 | tok/s 21161
step   2800 | loss 2.2023 | lr 1.09e-04 | grad 1.40 | tok/s 20420
step   2810 | loss 2.1810 | lr 1.09e-04 | grad 1.02 | tok/s 20887
step   2820 | loss 2.1489 | lr 1.09e-04 | grad 1.05 | tok/s 20058
step   2830 | loss 1.9075 | lr 1.09e-04 | grad 0.93 | tok/s 20901
step   2840 | loss 1.9513 | lr 1.09e-04 | grad 0.98 | tok/s 20816
step   2850 | loss 2.0888 | lr 1.09e-04 | grad 1.05 | tok/s 21888
step   2860 | loss 2.0777 | lr 1.09e-04 | grad 2.06 | tok/s 21706
step   2870 | loss 2.1749 | lr 1.09e-04 | grad 1.14 | tok/s 20973
step   2880 | loss 2.0897 | lr 1.09e-04 | grad 1.13 | tok/s 20367
step   2890 | loss 2.0933 | lr 1.09e-04 | grad 0.87 | tok/s 21269
step   2900 | loss 2.2858 | lr 1.09e-04 | grad 1.04 | tok/s 20679
step   2910 | loss 2.2082 | lr 1.09e-04 | grad 3.31 | tok/s 21544
step   2920 | loss 2.0286 | lr 1.09e-04 | grad 1.10 | tok/s 20738
step   2930 | loss 2.2004 | lr 1.09e-04 | grad 1.13 | tok/s 21504
step   2940 | loss 2.1964 | lr 1.09e-04 | grad 1.23 | tok/s 21060
step   2950 | loss 2.4044 | lr 1.09e-04 | grad 1.10 | tok/s 21229
step   2960 | loss 2.0714 | lr 1.09e-04 | grad 1.98 | tok/s 20628
step   2970 | loss 2.3608 | lr 1.09e-04 | grad 0.98 | tok/s 20958
step   2980 | loss 2.2289 | lr 1.09e-04 | grad 1.38 | tok/s 21463
step   2990 | loss 2.4401 | lr 1.09e-04 | grad 1.24 | tok/s 21569
step   3000 | loss 2.1293 | lr 1.09e-04 | grad 1.41 | tok/s 21179
  >>> saved checkpoint: checkpoint_step_003000_loss_2.1293.pt
step   3010 | loss 2.1637 | lr 1.09e-04 | grad 1.20 | tok/s 14179
step   3020 | loss 2.1960 | lr 1.09e-04 | grad 1.38 | tok/s 21233
step   3030 | loss 2.0371 | lr 1.09e-04 | grad 1.24 | tok/s 20283
step   3040 | loss 2.3012 | lr 1.09e-04 | grad 1.10 | tok/s 21678
step   3050 | loss 2.0904 | lr 1.09e-04 | grad 1.17 | tok/s 21428
step   3060 | loss 1.9613 | lr 1.09e-04 | grad 1.40 | tok/s 21782
step   3070 | loss 2.7283 | lr 1.09e-04 | grad 4.31 | tok/s 20804
step   3080 | loss 2.6377 | lr 1.09e-04 | grad 1.71 | tok/s 21646
step   3090 | loss 2.1247 | lr 1.09e-04 | grad 0.98 | tok/s 20666
step   3100 | loss 2.1351 | lr 1.09e-04 | grad 1.30 | tok/s 20646
step   3110 | loss 2.3575 | lr 1.09e-04 | grad 3.39 | tok/s 21928
step   3120 | loss 2.3216 | lr 1.09e-04 | grad 2.23 | tok/s 20842
step   3130 | loss 1.9782 | lr 1.09e-04 | grad 1.47 | tok/s 20985
step   3140 | loss 2.1020 | lr 1.09e-04 | grad 1.27 | tok/s 20943
step   3150 | loss 1.9918 | lr 1.09e-04 | grad 0.89 | tok/s 20040
step   3160 | loss 2.1977 | lr 1.09e-04 | grad 1.22 | tok/s 21445
step   3170 | loss 2.1485 | lr 1.09e-04 | grad 1.24 | tok/s 21695
step   3180 | loss 1.7508 | lr 1.09e-04 | grad 1.23 | tok/s 21789
step   3190 | loss 2.1611 | lr 1.09e-04 | grad 1.24 | tok/s 21464
step   3200 | loss 2.0076 | lr 1.09e-04 | grad 1.38 | tok/s 21099
step   3210 | loss 2.1497 | lr 1.09e-04 | grad 2.00 | tok/s 21328
step   3220 | loss 2.1556 | lr 1.09e-04 | grad 1.78 | tok/s 21564
step   3230 | loss 2.0614 | lr 1.09e-04 | grad 1.84 | tok/s 20988
step   3240 | loss 2.0250 | lr 1.09e-04 | grad 0.84 | tok/s 20720
step   3250 | loss 2.0468 | lr 1.09e-04 | grad 0.93 | tok/s 20206
step   3260 | loss 2.2116 | lr 1.09e-04 | grad 1.99 | tok/s 20909
step   3270 | loss 1.9777 | lr 1.09e-04 | grad 1.14 | tok/s 20764
step   3280 | loss 2.2456 | lr 1.09e-04 | grad 1.04 | tok/s 21011
step   3290 | loss 2.0800 | lr 1.09e-04 | grad 0.98 | tok/s 21333
step   3300 | loss 2.3863 | lr 1.09e-04 | grad 1.80 | tok/s 21657
step   3310 | loss 2.3641 | lr 1.09e-04 | grad 1.02 | tok/s 21377
step   3320 | loss 2.8218 | lr 1.09e-04 | grad 1.72 | tok/s 21391
step   3330 | loss 2.0508 | lr 1.09e-04 | grad 1.17 | tok/s 20191
step   3340 | loss 2.1949 | lr 1.09e-04 | grad 1.55 | tok/s 21852
step   3350 | loss 2.3959 | lr 1.09e-04 | grad 2.34 | tok/s 21752
step   3360 | loss 2.5933 | lr 1.09e-04 | grad 1.09 | tok/s 21068
step   3370 | loss 2.1346 | lr 1.09e-04 | grad 1.77 | tok/s 20733
step   3380 | loss 2.2178 | lr 1.09e-04 | grad 1.45 | tok/s 21592
step   3390 | loss 2.1913 | lr 1.09e-04 | grad 1.28 | tok/s 20771
step   3400 | loss 2.1929 | lr 1.09e-04 | grad 1.39 | tok/s 21270
step   3410 | loss 2.2966 | lr 1.09e-04 | grad 1.29 | tok/s 20656
step   3420 | loss 2.2172 | lr 1.09e-04 | grad 1.30 | tok/s 21216
step   3430 | loss 2.1329 | lr 1.09e-04 | grad 2.02 | tok/s 21384
step   3440 | loss 2.2494 | lr 1.09e-04 | grad 1.45 | tok/s 21007
step   3450 | loss 2.1004 | lr 1.09e-04 | grad 1.52 | tok/s 20668
step   3460 | loss 2.0458 | lr 1.09e-04 | grad 1.16 | tok/s 20685
step   3470 | loss 2.6548 | lr 1.09e-04 | grad 1.51 | tok/s 21648
step   3480 | loss 2.0191 | lr 1.09e-04 | grad 1.35 | tok/s 20173
step   3490 | loss 2.3332 | lr 1.09e-04 | grad 1.68 | tok/s 21429
step   3500 | loss 2.1689 | lr 1.09e-04 | grad 1.73 | tok/s 20842
step   3510 | loss 2.0550 | lr 1.09e-04 | grad 0.77 | tok/s 19984
step   3520 | loss 2.0914 | lr 1.09e-04 | grad 1.74 | tok/s 21290
step   3530 | loss 2.4618 | lr 1.09e-04 | grad 1.24 | tok/s 21263
step   3540 | loss 2.1577 | lr 1.09e-04 | grad 1.26 | tok/s 20487
step   3550 | loss 1.9871 | lr 1.09e-04 | grad 1.27 | tok/s 21335
step   3560 | loss 2.0974 | lr 1.09e-04 | grad 0.92 | tok/s 21336
step   3570 | loss 2.1426 | lr 1.09e-04 | grad 1.03 | tok/s 21666
step   3580 | loss 1.9417 | lr 1.09e-04 | grad 1.11 | tok/s 21152
step   3590 | loss 2.0399 | lr 1.09e-04 | grad 1.09 | tok/s 20681
step   3600 | loss 2.0555 | lr 1.09e-04 | grad 1.13 | tok/s 21217
step   3610 | loss 2.0722 | lr 1.09e-04 | grad 1.28 | tok/s 20854
step   3620 | loss 2.1235 | lr 1.09e-04 | grad 0.97 | tok/s 20626
step   3630 | loss 2.0983 | lr 1.09e-04 | grad 2.64 | tok/s 20995
step   3640 | loss 2.1995 | lr 1.09e-04 | grad 1.09 | tok/s 20863
step   3650 | loss 2.3284 | lr 1.09e-04 | grad 1.14 | tok/s 21077
step   3660 | loss 2.1195 | lr 1.09e-04 | grad 1.58 | tok/s 20339
step   3670 | loss 1.9839 | lr 1.09e-04 | grad 1.20 | tok/s 21062
step   3680 | loss 2.1469 | lr 1.09e-04 | grad 1.66 | tok/s 20816
step   3690 | loss 2.1683 | lr 1.09e-04 | grad 0.88 | tok/s 21618
step   3700 | loss 2.1744 | lr 1.09e-04 | grad 1.02 | tok/s 21824
step   3710 | loss 2.0299 | lr 1.09e-04 | grad 0.99 | tok/s 20934
step   3720 | loss 2.1441 | lr 1.09e-04 | grad 1.10 | tok/s 21911
step   3730 | loss 2.1236 | lr 1.09e-04 | grad 2.12 | tok/s 20812
step   3740 | loss 2.4129 | lr 1.09e-04 | grad 2.44 | tok/s 21160
step   3750 | loss 2.2276 | lr 1.09e-04 | grad 2.33 | tok/s 21148
step   3760 | loss 2.0456 | lr 1.09e-04 | grad 1.70 | tok/s 21636
step   3770 | loss 2.0981 | lr 1.09e-04 | grad 1.80 | tok/s 20372
step   3780 | loss 2.3012 | lr 1.09e-04 | grad 1.35 | tok/s 21703
step   3790 | loss 2.0300 | lr 1.09e-04 | grad 1.53 | tok/s 21063
step   3800 | loss 2.0086 | lr 1.09e-04 | grad 2.06 | tok/s 21518
step   3810 | loss 2.0238 | lr 1.09e-04 | grad 1.03 | tok/s 21117
step   3820 | loss 2.1040 | lr 1.09e-04 | grad 0.97 | tok/s 21645
step   3830 | loss 1.8888 | lr 1.09e-04 | grad 1.95 | tok/s 22003
step   3840 | loss 2.1245 | lr 1.09e-04 | grad 2.39 | tok/s 21644
step   3850 | loss 1.9734 | lr 1.09e-04 | grad 0.91 | tok/s 21422
step   3860 | loss 2.0764 | lr 1.09e-04 | grad 1.81 | tok/s 21119
step   3870 | loss 2.4899 | lr 1.09e-04 | grad 5.06 | tok/s 21563
step   3880 | loss 2.5867 | lr 1.09e-04 | grad 1.12 | tok/s 21331
step   3890 | loss 2.0459 | lr 1.09e-04 | grad 1.43 | tok/s 21277
step   3900 | loss 2.0128 | lr 1.09e-04 | grad 1.67 | tok/s 21069
step   3910 | loss 2.0654 | lr 1.09e-04 | grad 1.35 | tok/s 20670
step   3920 | loss 2.5076 | lr 1.09e-04 | grad 1.41 | tok/s 21929
step   3930 | loss 2.1359 | lr 1.09e-04 | grad 1.30 | tok/s 20761
step   3940 | loss 2.0758 | lr 1.09e-04 | grad 2.33 | tok/s 21405
step   3950 | loss 2.1572 | lr 1.09e-04 | grad 2.00 | tok/s 21642
step   3960 | loss 2.1641 | lr 1.09e-04 | grad 1.58 | tok/s 21503
step   3970 | loss 1.9221 | lr 1.09e-04 | grad 1.24 | tok/s 22022
step   3980 | loss 1.8855 | lr 1.09e-04 | grad 1.20 | tok/s 22025
step   3990 | loss 1.8750 | lr 1.09e-04 | grad 1.19 | tok/s 22024
step   4000 | loss 2.0178 | lr 1.09e-04 | grad 1.20 | tok/s 22028
  >>> saved checkpoint: checkpoint_step_004000_loss_2.0178.pt
step   4010 | loss 2.1821 | lr 1.09e-04 | grad 1.61 | tok/s 14419
step   4020 | loss 1.9619 | lr 1.09e-04 | grad 1.69 | tok/s 22060
step   4030 | loss 1.9533 | lr 1.09e-04 | grad 1.54 | tok/s 22053
step   4040 | loss 1.9270 | lr 1.09e-04 | grad 1.16 | tok/s 22056
step   4050 | loss 1.9375 | lr 1.09e-04 | grad 1.77 | tok/s 21763
step   4060 | loss 2.0893 | lr 1.09e-04 | grad 1.70 | tok/s 21025
step   4070 | loss 2.0407 | lr 1.09e-04 | grad 1.47 | tok/s 20760
step   4080 | loss 1.9344 | lr 1.09e-04 | grad 1.28 | tok/s 21706
step   4090 | loss 2.0242 | lr 1.09e-04 | grad 1.40 | tok/s 21902
step   4100 | loss 2.1996 | lr 1.09e-04 | grad 2.11 | tok/s 20937
step   4110 | loss 2.2177 | lr 1.09e-04 | grad 3.44 | tok/s 20819
step   4120 | loss 2.2244 | lr 1.09e-04 | grad 2.27 | tok/s 21725
step   4130 | loss 2.0257 | lr 1.09e-04 | grad 1.67 | tok/s 21144
step   4140 | loss 2.0977 | lr 1.09e-04 | grad 1.59 | tok/s 21118
step   4150 | loss 2.0751 | lr 1.09e-04 | grad 1.29 | tok/s 20869
step   4160 | loss 1.9771 | lr 1.09e-04 | grad 1.52 | tok/s 21316
step   4170 | loss 1.9727 | lr 1.09e-04 | grad 1.12 | tok/s 21893
step   4180 | loss 2.1127 | lr 1.09e-04 | grad 1.73 | tok/s 20721
step   4190 | loss 1.7100 | lr 1.09e-04 | grad 1.27 | tok/s 21660
step   4200 | loss 2.0314 | lr 1.09e-04 | grad 1.89 | tok/s 21391
step   4210 | loss 2.1784 | lr 1.09e-04 | grad 0.93 | tok/s 20838
step   4220 | loss 2.0388 | lr 1.09e-04 | grad 1.15 | tok/s 21158
step   4230 | loss 2.2863 | lr 1.09e-04 | grad 2.00 | tok/s 20783
step   4240 | loss 2.2160 | lr 1.09e-04 | grad 1.38 | tok/s 21329
step   4250 | loss 2.0159 | lr 1.09e-04 | grad 1.26 | tok/s 20794
step   4260 | loss 2.1191 | lr 1.09e-04 | grad 1.59 | tok/s 20989
step   4270 | loss 2.0612 | lr 1.09e-04 | grad 1.20 | tok/s 20986
step   4280 | loss 2.3497 | lr 1.09e-04 | grad 2.86 | tok/s 21623
step   4290 | loss 2.1048 | lr 1.09e-04 | grad 1.09 | tok/s 20716
step   4300 | loss 2.1209 | lr 1.09e-04 | grad 1.23 | tok/s 21339
step   4310 | loss 2.1766 | lr 1.09e-04 | grad 1.77 | tok/s 21915
step   4320 | loss 2.6929 | lr 1.09e-04 | grad 1.20 | tok/s 21794
step   4330 | loss 2.1027 | lr 1.09e-04 | grad 1.22 | tok/s 21199
step   4340 | loss 1.9585 | lr 1.09e-04 | grad 1.42 | tok/s 22041
step   4350 | loss 1.9475 | lr 1.09e-04 | grad 0.95 | tok/s 22038
step   4360 | loss 1.9827 | lr 1.09e-04 | grad 1.17 | tok/s 22038
step   4370 | loss 1.9587 | lr 1.09e-04 | grad 1.16 | tok/s 22034
step   4380 | loss 1.9736 | lr 1.09e-04 | grad 1.29 | tok/s 22034
step   4390 | loss 1.9726 | lr 1.09e-04 | grad 1.24 | tok/s 22005
step   4400 | loss 1.9823 | lr 1.09e-04 | grad 1.21 | tok/s 21472
step   4410 | loss 2.1700 | lr 1.09e-04 | grad 1.36 | tok/s 21248
step   4420 | loss 2.1846 | lr 1.09e-04 | grad 1.81 | tok/s 21655
step   4430 | loss 2.7917 | lr 1.09e-04 | grad 2.17 | tok/s 22056
step   4440 | loss 2.6896 | lr 1.09e-04 | grad 1.30 | tok/s 21880
step   4450 | loss 2.0109 | lr 1.09e-04 | grad 1.58 | tok/s 21362
step   4460 | loss 2.4514 | lr 1.09e-04 | grad 2.27 | tok/s 21731
step   4470 | loss 1.8881 | lr 1.09e-04 | grad 1.26 | tok/s 20988
step   4480 | loss 2.2094 | lr 1.09e-04 | grad 1.22 | tok/s 21668
step   4490 | loss 2.0436 | lr 1.09e-04 | grad 1.34 | tok/s 21266
step   4500 | loss 2.1288 | lr 1.09e-04 | grad 1.32 | tok/s 21232
step   4510 | loss 2.1980 | lr 1.09e-04 | grad 1.60 | tok/s 20502
step   4520 | loss 2.0102 | lr 1.09e-04 | grad 3.25 | tok/s 21142
step   4530 | loss 2.0778 | lr 1.09e-04 | grad 1.48 | tok/s 21133
step   4540 | loss 1.9334 | lr 1.09e-04 | grad 1.18 | tok/s 20877
step   4550 | loss 2.0089 | lr 1.09e-04 | grad 1.86 | tok/s 20741
step   4560 | loss 2.0056 | lr 1.09e-04 | grad 1.54 | tok/s 21779
step   4570 | loss 1.9945 | lr 1.09e-04 | grad 1.39 | tok/s 22021
step   4580 | loss 2.0062 | lr 1.09e-04 | grad 1.45 | tok/s 22023
step   4590 | loss 1.9871 | lr 1.09e-04 | grad 1.29 | tok/s 22007
step   4600 | loss 1.9515 | lr 1.09e-04 | grad 0.92 | tok/s 22024
step   4610 | loss 1.9802 | lr 1.09e-04 | grad 1.01 | tok/s 22018
step   4620 | loss 2.0933 | lr 1.09e-04 | grad 1.95 | tok/s 21611
step   4630 | loss 1.9520 | lr 1.09e-04 | grad 1.65 | tok/s 21416
step   4640 | loss 2.1920 | lr 1.09e-04 | grad 1.70 | tok/s 21346
step   4650 | loss 2.0893 | lr 1.09e-04 | grad 2.22 | tok/s 21022
step   4660 | loss 2.5906 | lr 1.09e-04 | grad 3.00 | tok/s 21265
step   4670 | loss 2.5881 | lr 1.09e-04 | grad 2.53 | tok/s 21317
step   4680 | loss 2.0865 | lr 1.09e-04 | grad 1.29 | tok/s 21558
step   4690 | loss 2.1007 | lr 1.09e-04 | grad 1.59 | tok/s 21459
step   4700 | loss 2.1026 | lr 1.09e-04 | grad 0.98 | tok/s 21037
step   4710 | loss 2.0214 | lr 1.09e-04 | grad 2.95 | tok/s 21061
step   4720 | loss 1.8834 | lr 1.09e-04 | grad 1.21 | tok/s 20545
step   4730 | loss 2.0412 | lr 1.09e-04 | grad 1.46 | tok/s 20874
step   4740 | loss 2.1276 | lr 1.09e-04 | grad 1.63 | tok/s 21509
step   4750 | loss 2.1376 | lr 1.09e-04 | grad 1.29 | tok/s 20573
step   4760 | loss 2.0916 | lr 1.09e-04 | grad 1.03 | tok/s 21084
step   4770 | loss 2.0900 | lr 1.09e-04 | grad 2.11 | tok/s 21252

Training complete! Final step: 4775
