Using device: cuda
Output directory: benchmark_results/cmaes_4d/transformer_480M_converge0.01_20260203_094548/eval_33/levelllama_100m_20260203_114735
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 434,991,232 parameters
Using schedule-free AdamW (lr=0.00012719727353711064)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 7.6588 | lr 1.27e-04 | grad 2.36 | tok/s 6284
step     20 | loss 2.9078 | lr 1.27e-04 | grad 1.04 | tok/s 16786
step     30 | loss 2.8686 | lr 1.27e-04 | grad 1.11 | tok/s 16978
step     40 | loss 3.1694 | lr 1.27e-04 | grad 1.80 | tok/s 16234
step     50 | loss 3.9121 | lr 1.27e-04 | grad 8.94 | tok/s 16481
step     60 | loss 2.8486 | lr 1.27e-04 | grad 13.12 | tok/s 17009
step     70 | loss 2.6830 | lr 1.27e-04 | grad 1.73 | tok/s 17211
step     80 | loss 10.8201 | lr 1.27e-04 | grad 86.00 | tok/s 17274
step     90 | loss 8.5876 | lr 1.27e-04 | grad 2.69 | tok/s 17575
step    100 | loss 6.2646 | lr 1.27e-04 | grad 3.75 | tok/s 17564
step    110 | loss 5.7560 | lr 1.27e-04 | grad 10.19 | tok/s 17542
step    120 | loss 4.8557 | lr 1.27e-04 | grad 8.50 | tok/s 17525
step    130 | loss 4.5266 | lr 1.27e-04 | grad 5.06 | tok/s 17529
step    140 | loss 3.7503 | lr 1.27e-04 | grad 4.38 | tok/s 17507
step    150 | loss 4.2470 | lr 1.27e-04 | grad 6.16 | tok/s 17505
step    160 | loss 3.6163 | lr 1.27e-04 | grad 6.06 | tok/s 17496
step    170 | loss 3.5917 | lr 1.27e-04 | grad 5.53 | tok/s 17484
step    180 | loss 3.5068 | lr 1.27e-04 | grad 3.95 | tok/s 17467
step    190 | loss 3.6549 | lr 1.27e-04 | grad 3.41 | tok/s 17451
step    200 | loss 3.3062 | lr 1.27e-04 | grad 3.50 | tok/s 17453
step    210 | loss 3.2449 | lr 1.27e-04 | grad 3.52 | tok/s 17428
step    220 | loss 3.0924 | lr 1.27e-04 | grad 2.61 | tok/s 17192
step    230 | loss 4.1150 | lr 1.27e-04 | grad 3.39 | tok/s 16988
step    240 | loss 2.8474 | lr 1.27e-04 | grad 2.58 | tok/s 16120
step    250 | loss 2.6724 | lr 1.27e-04 | grad 1.04 | tok/s 16565
step    260 | loss 2.5202 | lr 1.27e-04 | grad 1.54 | tok/s 17091
step    270 | loss 2.8826 | lr 1.27e-04 | grad 1.03 | tok/s 16865
step    280 | loss 2.9194 | lr 1.27e-04 | grad 2.78 | tok/s 16522
step    290 | loss 3.9393 | lr 1.27e-04 | grad 4.62 | tok/s 17406
step    300 | loss 2.9809 | lr 1.27e-04 | grad 2.17 | tok/s 17408
step    310 | loss 3.1339 | lr 1.27e-04 | grad 2.41 | tok/s 17106
step    320 | loss 2.9232 | lr 1.27e-04 | grad 3.27 | tok/s 16751
step    330 | loss 2.6116 | lr 1.27e-04 | grad 1.97 | tok/s 16179
step    340 | loss 2.9115 | lr 1.27e-04 | grad 1.37 | tok/s 16421
step    350 | loss 2.7460 | lr 1.27e-04 | grad 2.94 | tok/s 16840
step    360 | loss 3.3566 | lr 1.27e-04 | grad 2.28 | tok/s 17206
step    370 | loss 2.4625 | lr 1.27e-04 | grad 1.04 | tok/s 15606
step    380 | loss 2.4955 | lr 1.27e-04 | grad 1.48 | tok/s 16610
step    390 | loss 2.3946 | lr 1.27e-04 | grad 0.87 | tok/s 17352
step    400 | loss 2.3971 | lr 1.27e-04 | grad 1.72 | tok/s 17197
step    410 | loss 2.3805 | lr 1.27e-04 | grad 0.73 | tok/s 16815
step    420 | loss 2.4509 | lr 1.27e-04 | grad 2.91 | tok/s 16050
step    430 | loss 2.7853 | lr 1.27e-04 | grad 1.34 | tok/s 17092
step    440 | loss 2.7140 | lr 1.27e-04 | grad 1.70 | tok/s 16122
step    450 | loss 2.8994 | lr 1.27e-04 | grad 0.95 | tok/s 16693
step    460 | loss 2.5018 | lr 1.27e-04 | grad 2.03 | tok/s 16348
step    470 | loss 2.5867 | lr 1.27e-04 | grad 0.99 | tok/s 16821
step    480 | loss 3.0796 | lr 1.27e-04 | grad 3.88 | tok/s 16859
step    490 | loss 2.4854 | lr 1.27e-04 | grad 1.93 | tok/s 15912
step    500 | loss 2.4382 | lr 1.27e-04 | grad 1.66 | tok/s 16983
step    510 | loss 2.4596 | lr 1.27e-04 | grad 1.20 | tok/s 17215
step    520 | loss 2.4589 | lr 1.27e-04 | grad 1.09 | tok/s 17197
step    530 | loss 2.5845 | lr 1.27e-04 | grad 1.17 | tok/s 16547
step    540 | loss 2.3125 | lr 1.27e-04 | grad 0.97 | tok/s 16521
step    550 | loss 2.1917 | lr 1.27e-04 | grad 1.38 | tok/s 16177
step    560 | loss 2.3633 | lr 1.27e-04 | grad 1.50 | tok/s 15777
step    570 | loss 2.3234 | lr 1.27e-04 | grad 1.61 | tok/s 16202
step    580 | loss 2.2028 | lr 1.27e-04 | grad 1.34 | tok/s 16136
step    590 | loss 2.6237 | lr 1.27e-04 | grad 1.84 | tok/s 16559
step    600 | loss 2.4183 | lr 1.27e-04 | grad 1.41 | tok/s 15998
step    610 | loss 2.2794 | lr 1.27e-04 | grad 1.14 | tok/s 16807
step    620 | loss 2.1259 | lr 1.27e-04 | grad 0.97 | tok/s 15919
step    630 | loss 2.3115 | lr 1.27e-04 | grad 1.84 | tok/s 16046
step    640 | loss 2.4633 | lr 1.27e-04 | grad 1.27 | tok/s 16469
step    650 | loss 2.4001 | lr 1.27e-04 | grad 1.40 | tok/s 16563
step    660 | loss 2.3019 | lr 1.27e-04 | grad 0.98 | tok/s 16640
step    670 | loss 2.6277 | lr 1.27e-04 | grad 4.56 | tok/s 16765
step    680 | loss 2.3885 | lr 1.27e-04 | grad 1.21 | tok/s 16420
step    690 | loss 2.6781 | lr 1.27e-04 | grad 2.03 | tok/s 16978
step    700 | loss 2.6934 | lr 1.27e-04 | grad 2.77 | tok/s 17303
step    710 | loss 2.2836 | lr 1.27e-04 | grad 1.11 | tok/s 16166
step    720 | loss 2.0616 | lr 1.27e-04 | grad 1.39 | tok/s 15932
step    730 | loss 2.3713 | lr 1.27e-04 | grad 1.45 | tok/s 17284
step    740 | loss 2.2598 | lr 1.27e-04 | grad 1.42 | tok/s 17040
step    750 | loss 2.2416 | lr 1.27e-04 | grad 1.31 | tok/s 17303
step    760 | loss 2.1199 | lr 1.27e-04 | grad 1.20 | tok/s 17302
step    770 | loss 2.1424 | lr 1.27e-04 | grad 1.30 | tok/s 17308
step    780 | loss 2.1209 | lr 1.27e-04 | grad 1.22 | tok/s 17300
step    790 | loss 2.0711 | lr 1.27e-04 | grad 1.27 | tok/s 16776
step    800 | loss 2.6209 | lr 1.27e-04 | grad 2.73 | tok/s 16706
step    810 | loss 2.2719 | lr 1.27e-04 | grad 1.20 | tok/s 16604
step    820 | loss 2.2306 | lr 1.27e-04 | grad 2.09 | tok/s 15947
step    830 | loss 2.4571 | lr 1.27e-04 | grad 1.47 | tok/s 17126
step    840 | loss 2.4460 | lr 1.27e-04 | grad 1.12 | tok/s 17287
step    850 | loss 2.4042 | lr 1.27e-04 | grad 1.77 | tok/s 17199
step    860 | loss 2.3700 | lr 1.27e-04 | grad 2.20 | tok/s 17022
step    870 | loss 2.1557 | lr 1.27e-04 | grad 1.49 | tok/s 16407
step    880 | loss 2.3485 | lr 1.27e-04 | grad 1.27 | tok/s 16459
step    890 | loss 2.2700 | lr 1.27e-04 | grad 1.49 | tok/s 16691
step    900 | loss 2.1864 | lr 1.27e-04 | grad 1.29 | tok/s 16691
step    910 | loss 2.1207 | lr 1.27e-04 | grad 1.98 | tok/s 16341
step    920 | loss 2.3862 | lr 1.27e-04 | grad 1.92 | tok/s 16991
step    930 | loss 2.1891 | lr 1.27e-04 | grad 1.89 | tok/s 16217
step    940 | loss 2.3277 | lr 1.27e-04 | grad 1.31 | tok/s 17120
step    950 | loss 2.4593 | lr 1.27e-04 | grad 1.62 | tok/s 17198
step    960 | loss 2.4269 | lr 1.27e-04 | grad 1.39 | tok/s 17203
step    970 | loss 2.2514 | lr 1.27e-04 | grad 1.60 | tok/s 16189
step    980 | loss 2.2590 | lr 1.27e-04 | grad 1.28 | tok/s 16627
step    990 | loss 2.1573 | lr 1.27e-04 | grad 1.05 | tok/s 16918
step   1000 | loss 2.4303 | lr 1.27e-04 | grad 7.09 | tok/s 16217
  >>> saved checkpoint: checkpoint_step_001000_loss_2.4303.pt
step   1010 | loss 2.4348 | lr 1.27e-04 | grad 1.41 | tok/s 6773
step   1020 | loss 2.1620 | lr 1.27e-04 | grad 1.30 | tok/s 15891
step   1030 | loss 2.1014 | lr 1.27e-04 | grad 1.14 | tok/s 16541
step   1040 | loss 2.0807 | lr 1.27e-04 | grad 1.22 | tok/s 17075
step   1050 | loss 2.1408 | lr 1.27e-04 | grad 1.35 | tok/s 15794
step   1060 | loss 2.3648 | lr 1.27e-04 | grad 1.95 | tok/s 17064
step   1070 | loss 2.5280 | lr 1.27e-04 | grad 1.59 | tok/s 16990
step   1080 | loss 1.9647 | lr 1.27e-04 | grad 1.04 | tok/s 15425
step   1090 | loss 1.8004 | lr 1.27e-04 | grad 0.84 | tok/s 16981
step   1100 | loss 1.9886 | lr 1.27e-04 | grad 2.36 | tok/s 16486
step   1110 | loss 2.1640 | lr 1.27e-04 | grad 1.08 | tok/s 17329
step   1120 | loss 2.1048 | lr 1.27e-04 | grad 1.89 | tok/s 17324
step   1130 | loss 2.0289 | lr 1.27e-04 | grad 1.09 | tok/s 17312
step   1140 | loss 2.0037 | lr 1.27e-04 | grad 1.26 | tok/s 17300
step   1150 | loss 2.0054 | lr 1.27e-04 | grad 1.18 | tok/s 17311
step   1160 | loss 1.9083 | lr 1.27e-04 | grad 1.20 | tok/s 17303
step   1170 | loss 1.9597 | lr 1.27e-04 | grad 1.17 | tok/s 17321
step   1180 | loss 2.0761 | lr 1.27e-04 | grad 1.19 | tok/s 17300
step   1190 | loss 2.0051 | lr 1.27e-04 | grad 1.45 | tok/s 17295
step   1200 | loss 1.9897 | lr 1.27e-04 | grad 1.65 | tok/s 17303
step   1210 | loss 1.9637 | lr 1.27e-04 | grad 1.60 | tok/s 17297
step   1220 | loss 1.9389 | lr 1.27e-04 | grad 1.36 | tok/s 17312
step   1230 | loss 1.9366 | lr 1.27e-04 | grad 1.27 | tok/s 17311
step   1240 | loss 1.8982 | lr 1.27e-04 | grad 0.89 | tok/s 17300
step   1250 | loss 2.4099 | lr 1.27e-04 | grad 1.99 | tok/s 16385
step   1260 | loss 1.8689 | lr 1.27e-04 | grad 3.44 | tok/s 16214
step   1270 | loss 2.1498 | lr 1.27e-04 | grad 3.28 | tok/s 16174
step   1280 | loss 2.3103 | lr 1.27e-04 | grad 2.36 | tok/s 16641
step   1290 | loss 2.0851 | lr 1.27e-04 | grad 1.38 | tok/s 16553
step   1300 | loss 2.1315 | lr 1.27e-04 | grad 1.49 | tok/s 16656
step   1310 | loss 2.0549 | lr 1.27e-04 | grad 1.84 | tok/s 16925
step   1320 | loss 2.2015 | lr 1.27e-04 | grad 1.38 | tok/s 16994
step   1330 | loss 2.3068 | lr 1.27e-04 | grad 1.86 | tok/s 17019
step   1340 | loss 2.1221 | lr 1.27e-04 | grad 5.47 | tok/s 16247
step   1350 | loss 2.2280 | lr 1.27e-04 | grad 1.85 | tok/s 15700
step   1360 | loss 2.1573 | lr 1.27e-04 | grad 1.55 | tok/s 16669
step   1370 | loss 2.0289 | lr 1.27e-04 | grad 1.14 | tok/s 16478
step   1380 | loss 2.2798 | lr 1.27e-04 | grad 1.11 | tok/s 15828
step   1390 | loss 2.0796 | lr 1.27e-04 | grad 1.10 | tok/s 16793
step   1400 | loss 2.0789 | lr 1.27e-04 | grad 1.43 | tok/s 16205
step   1410 | loss 2.0686 | lr 1.27e-04 | grad 1.71 | tok/s 16269
step   1420 | loss 2.3361 | lr 1.27e-04 | grad 4.12 | tok/s 16290
step   1430 | loss 2.0718 | lr 1.27e-04 | grad 1.27 | tok/s 16587
step   1440 | loss 1.9360 | lr 1.27e-04 | grad 1.23 | tok/s 17126
step   1450 | loss 1.9095 | lr 1.27e-04 | grad 2.66 | tok/s 17241
step   1460 | loss 2.2269 | lr 1.27e-04 | grad 1.12 | tok/s 16273
step   1470 | loss 2.1857 | lr 1.27e-04 | grad 1.19 | tok/s 16864
step   1480 | loss 2.8024 | lr 1.27e-04 | grad 3.02 | tok/s 16974
step   1490 | loss 2.6966 | lr 1.27e-04 | grad 1.19 | tok/s 17238
step   1500 | loss 2.1388 | lr 1.27e-04 | grad 1.10 | tok/s 17304
step   1510 | loss 2.1659 | lr 1.27e-04 | grad 1.32 | tok/s 17074
step   1520 | loss 1.9834 | lr 1.27e-04 | grad 2.28 | tok/s 16724
step   1530 | loss 2.0350 | lr 1.27e-04 | grad 1.03 | tok/s 17130
step   1540 | loss 2.1493 | lr 1.27e-04 | grad 1.38 | tok/s 16094
step   1550 | loss 1.9853 | lr 1.27e-04 | grad 1.86 | tok/s 17177
step   1560 | loss 2.0842 | lr 1.27e-04 | grad 2.00 | tok/s 16274
step   1570 | loss 2.0238 | lr 1.27e-04 | grad 1.62 | tok/s 17300
step   1580 | loss 2.6467 | lr 1.27e-04 | grad 2.94 | tok/s 16866
step   1590 | loss 2.4543 | lr 1.27e-04 | grad 1.34 | tok/s 16223
step   1600 | loss 1.7256 | lr 1.27e-04 | grad 1.50 | tok/s 17324
step   1610 | loss 1.5093 | lr 1.27e-04 | grad 1.73 | tok/s 16751
step   1620 | loss 2.0309 | lr 1.27e-04 | grad 2.11 | tok/s 15702
step   1630 | loss 2.1911 | lr 1.27e-04 | grad 1.73 | tok/s 16810
step   1640 | loss 1.9324 | lr 1.27e-04 | grad 1.42 | tok/s 16448
step   1650 | loss 2.0024 | lr 1.27e-04 | grad 1.66 | tok/s 15736
step   1660 | loss 2.1026 | lr 1.27e-04 | grad 1.20 | tok/s 16787
step   1670 | loss 2.2014 | lr 1.27e-04 | grad 3.59 | tok/s 16763
step   1680 | loss 2.2145 | lr 1.27e-04 | grad 1.34 | tok/s 16078
step   1690 | loss 2.1094 | lr 1.27e-04 | grad 3.66 | tok/s 16365
step   1700 | loss 2.2857 | lr 1.27e-04 | grad 1.67 | tok/s 16745
step   1710 | loss 2.1002 | lr 1.27e-04 | grad 1.12 | tok/s 16420
step   1720 | loss 2.2819 | lr 1.27e-04 | grad 1.73 | tok/s 17126
step   1730 | loss 2.5151 | lr 1.27e-04 | grad 1.95 | tok/s 17299
step   1740 | loss 2.2367 | lr 1.27e-04 | grad 1.64 | tok/s 16834
step   1750 | loss 2.1673 | lr 1.27e-04 | grad 1.64 | tok/s 16541
step   1760 | loss 2.0105 | lr 1.27e-04 | grad 1.50 | tok/s 16601
step   1770 | loss 1.9499 | lr 1.27e-04 | grad 1.52 | tok/s 16316
step   1780 | loss 1.9988 | lr 1.27e-04 | grad 1.25 | tok/s 16997
step   1790 | loss 1.9699 | lr 1.27e-04 | grad 1.19 | tok/s 16532
step   1800 | loss 2.1174 | lr 1.27e-04 | grad 1.48 | tok/s 16692
step   1810 | loss 2.0069 | lr 1.27e-04 | grad 1.13 | tok/s 16087
step   1820 | loss 2.1345 | lr 1.27e-04 | grad 2.75 | tok/s 16300
step   1830 | loss 2.0674 | lr 1.27e-04 | grad 1.55 | tok/s 16970
step   1840 | loss 2.0551 | lr 1.27e-04 | grad 1.46 | tok/s 16238
step   1850 | loss 2.0752 | lr 1.27e-04 | grad 1.30 | tok/s 17012
step   1860 | loss 1.8567 | lr 1.27e-04 | grad 1.45 | tok/s 16459
step   1870 | loss 2.0111 | lr 1.27e-04 | grad 2.02 | tok/s 16533
step   1880 | loss 1.8987 | lr 1.27e-04 | grad 1.12 | tok/s 16191
step   1890 | loss 2.0984 | lr 1.27e-04 | grad 1.41 | tok/s 15401
step   1900 | loss 1.8831 | lr 1.27e-04 | grad 1.55 | tok/s 16640
step   1910 | loss 1.9639 | lr 1.27e-04 | grad 1.27 | tok/s 15776
step   1920 | loss 1.9594 | lr 1.27e-04 | grad 1.23 | tok/s 17264
step   1930 | loss 1.9368 | lr 1.27e-04 | grad 1.69 | tok/s 16216
step   1940 | loss 1.9094 | lr 1.27e-04 | grad 1.28 | tok/s 16863
step   1950 | loss 2.9769 | lr 1.27e-04 | grad 2.81 | tok/s 17115
step   1960 | loss 2.9498 | lr 1.27e-04 | grad 2.38 | tok/s 17293
step   1970 | loss 2.3199 | lr 1.27e-04 | grad 1.58 | tok/s 16867
step   1980 | loss 2.1209 | lr 1.27e-04 | grad 1.38 | tok/s 16128
step   1990 | loss 2.2330 | lr 1.27e-04 | grad 6.25 | tok/s 16446
step   2000 | loss 1.9572 | lr 1.27e-04 | grad 1.34 | tok/s 16656
  >>> saved checkpoint: checkpoint_step_002000_loss_1.9572.pt
step   2010 | loss 1.5256 | lr 1.27e-04 | grad 1.45 | tok/s 7304
step   2020 | loss 1.8216 | lr 1.27e-04 | grad 1.31 | tok/s 16567
step   2030 | loss 1.7473 | lr 1.27e-04 | grad 0.55 | tok/s 17422
step   2040 | loss 1.9974 | lr 1.27e-04 | grad 1.40 | tok/s 17371
step   2050 | loss 2.1213 | lr 1.27e-04 | grad 1.41 | tok/s 17026
step   2060 | loss 2.0789 | lr 1.27e-04 | grad 1.59 | tok/s 16054
step   2070 | loss 2.0929 | lr 1.27e-04 | grad 1.72 | tok/s 16660
step   2080 | loss 2.8014 | lr 1.27e-04 | grad 2.30 | tok/s 17217
step   2090 | loss 2.3438 | lr 1.27e-04 | grad 1.74 | tok/s 17252
step   2100 | loss 2.0969 | lr 1.27e-04 | grad 1.65 | tok/s 16792
step   2110 | loss 2.2046 | lr 1.27e-04 | grad 6.03 | tok/s 16509
step   2120 | loss 1.5490 | lr 1.27e-04 | grad 1.02 | tok/s 17064
step   2130 | loss 1.6589 | lr 1.27e-04 | grad 2.03 | tok/s 17047
step   2140 | loss 2.0349 | lr 1.27e-04 | grad 1.35 | tok/s 16515
step   2150 | loss 1.8130 | lr 1.27e-04 | grad 1.38 | tok/s 17344
step   2160 | loss 1.7641 | lr 1.27e-04 | grad 1.19 | tok/s 17352
step   2170 | loss 1.7976 | lr 1.27e-04 | grad 1.19 | tok/s 17311
step   2180 | loss 1.7613 | lr 1.27e-04 | grad 1.29 | tok/s 17340
step   2190 | loss 1.7450 | lr 1.27e-04 | grad 1.27 | tok/s 17339
step   2200 | loss 1.7592 | lr 1.27e-04 | grad 1.34 | tok/s 17312
step   2210 | loss 1.6979 | lr 1.27e-04 | grad 1.23 | tok/s 17309
step   2220 | loss 1.6937 | lr 1.27e-04 | grad 1.41 | tok/s 17311
step   2230 | loss 1.8509 | lr 1.27e-04 | grad 1.38 | tok/s 17008
step   2240 | loss 1.9314 | lr 1.27e-04 | grad 1.27 | tok/s 17273
step   2250 | loss 2.4303 | lr 1.27e-04 | grad 2.52 | tok/s 16688
step   2260 | loss 2.4324 | lr 1.27e-04 | grad 1.49 | tok/s 16880
step   2270 | loss 2.4386 | lr 1.27e-04 | grad 2.27 | tok/s 17165
step   2280 | loss 2.0798 | lr 1.27e-04 | grad 1.78 | tok/s 17105
step   2290 | loss 1.9977 | lr 1.27e-04 | grad 1.66 | tok/s 16683
step   2300 | loss 2.9054 | lr 1.27e-04 | grad 4.06 | tok/s 17099
step   2310 | loss 2.2081 | lr 1.27e-04 | grad 1.61 | tok/s 16228
step   2320 | loss 2.1727 | lr 1.27e-04 | grad 3.83 | tok/s 16253
step   2330 | loss 2.1932 | lr 1.27e-04 | grad 1.62 | tok/s 16544
step   2340 | loss 1.9904 | lr 1.27e-04 | grad 4.09 | tok/s 16088
step   2350 | loss 1.9343 | lr 1.27e-04 | grad 2.53 | tok/s 16906
step   2360 | loss 2.0065 | lr 1.27e-04 | grad 1.54 | tok/s 17124
step   2370 | loss 2.0839 | lr 1.27e-04 | grad 3.09 | tok/s 16942
step   2380 | loss 2.3974 | lr 1.27e-04 | grad 2.11 | tok/s 17324
step   2390 | loss 2.0540 | lr 1.27e-04 | grad 1.54 | tok/s 17266
step   2400 | loss 1.7895 | lr 1.27e-04 | grad 1.46 | tok/s 17306
step   2410 | loss 1.6540 | lr 1.27e-04 | grad 1.35 | tok/s 16740
step   2420 | loss 1.9371 | lr 1.27e-04 | grad 2.28 | tok/s 16207
step   2430 | loss 1.9669 | lr 1.27e-04 | grad 1.62 | tok/s 16482
step   2440 | loss 1.8740 | lr 1.27e-04 | grad 2.52 | tok/s 16931
step   2450 | loss 1.9291 | lr 1.27e-04 | grad 1.51 | tok/s 16503
step   2460 | loss 1.9514 | lr 1.27e-04 | grad 1.96 | tok/s 17132
step   2470 | loss 1.8264 | lr 1.27e-04 | grad 1.95 | tok/s 17056
step   2480 | loss 1.9645 | lr 1.27e-04 | grad 1.34 | tok/s 17317
step   2490 | loss 1.8402 | lr 1.27e-04 | grad 1.61 | tok/s 16386
step   2500 | loss 2.1756 | lr 1.27e-04 | grad 2.03 | tok/s 16927
step   2510 | loss 2.4559 | lr 1.27e-04 | grad 2.23 | tok/s 17302
step   2520 | loss 2.3929 | lr 1.27e-04 | grad 2.44 | tok/s 17253
step   2530 | loss 1.8392 | lr 1.27e-04 | grad 1.52 | tok/s 16659
step   2540 | loss 1.9247 | lr 1.27e-04 | grad 2.30 | tok/s 16553
step   2550 | loss 1.8680 | lr 1.27e-04 | grad 1.36 | tok/s 17210
step   2560 | loss 1.9835 | lr 1.27e-04 | grad 4.75 | tok/s 16150
step   2570 | loss 2.0246 | lr 1.27e-04 | grad 1.46 | tok/s 16823
step   2580 | loss 1.8548 | lr 1.27e-04 | grad 1.53 | tok/s 15757
step   2590 | loss 1.9963 | lr 1.27e-04 | grad 1.59 | tok/s 16641
step   2600 | loss 2.1883 | lr 1.27e-04 | grad 3.81 | tok/s 15985
step   2610 | loss 2.6647 | lr 1.27e-04 | grad 1.98 | tok/s 17192
step   2620 | loss 2.0095 | lr 1.27e-04 | grad 1.22 | tok/s 16577
step   2630 | loss 1.9302 | lr 1.27e-04 | grad 1.48 | tok/s 17126
step   2640 | loss 1.9829 | lr 1.27e-04 | grad 1.61 | tok/s 16662
step   2650 | loss 2.4130 | lr 1.27e-04 | grad 2.00 | tok/s 17283
step   2660 | loss 1.8734 | lr 1.27e-04 | grad 1.34 | tok/s 16702
step   2670 | loss 1.9147 | lr 1.27e-04 | grad 1.73 | tok/s 16036
step   2680 | loss 2.2410 | lr 1.27e-04 | grad 5.41 | tok/s 16362
step   2690 | loss 1.8984 | lr 1.27e-04 | grad 1.27 | tok/s 17147
step   2700 | loss 2.0366 | lr 1.27e-04 | grad 1.55 | tok/s 16683
step   2710 | loss 2.3219 | lr 1.27e-04 | grad 2.14 | tok/s 16438
step   2720 | loss 1.8207 | lr 1.27e-04 | grad 1.50 | tok/s 15751
step   2730 | loss 1.9593 | lr 1.27e-04 | grad 1.41 | tok/s 16937
step   2740 | loss 2.2221 | lr 1.27e-04 | grad 4.53 | tok/s 16739
step   2750 | loss 2.4268 | lr 1.27e-04 | grad 1.60 | tok/s 17160
step   2760 | loss 1.7856 | lr 1.27e-04 | grad 1.90 | tok/s 15946
step   2770 | loss 2.0539 | lr 1.27e-04 | grad 1.92 | tok/s 16451
step   2780 | loss 1.9937 | lr 1.27e-04 | grad 1.28 | tok/s 17295
step   2790 | loss 2.1943 | lr 1.27e-04 | grad 3.30 | tok/s 16116
step   2800 | loss 1.9236 | lr 1.27e-04 | grad 1.47 | tok/s 16574
step   2810 | loss 1.8134 | lr 1.27e-04 | grad 1.61 | tok/s 16531
step   2820 | loss 1.8546 | lr 1.27e-04 | grad 1.34 | tok/s 15923
step   2830 | loss 2.1187 | lr 1.27e-04 | grad 2.02 | tok/s 16998
step   2840 | loss 2.0802 | lr 1.27e-04 | grad 1.61 | tok/s 17299
step   2850 | loss 2.3458 | lr 1.27e-04 | grad 1.78 | tok/s 16721
step   2860 | loss 2.2516 | lr 1.27e-04 | grad 1.46 | tok/s 16630
step   2870 | loss 1.7901 | lr 1.27e-04 | grad 1.29 | tok/s 16281
step   2880 | loss 2.0431 | lr 1.27e-04 | grad 2.27 | tok/s 16793
step   2890 | loss 2.1255 | lr 1.27e-04 | grad 1.61 | tok/s 17269
step   2900 | loss 1.8927 | lr 1.27e-04 | grad 1.27 | tok/s 16619
step   2910 | loss 1.9767 | lr 1.27e-04 | grad 1.25 | tok/s 16593
step   2920 | loss 1.9243 | lr 1.27e-04 | grad 1.79 | tok/s 16108
step   2930 | loss 2.1400 | lr 1.27e-04 | grad 1.55 | tok/s 16893
step   2940 | loss 1.7304 | lr 1.27e-04 | grad 1.95 | tok/s 15512
step   2950 | loss 1.8929 | lr 1.27e-04 | grad 2.22 | tok/s 16691
step   2960 | loss 1.9061 | lr 1.27e-04 | grad 2.41 | tok/s 16835
step   2970 | loss 1.8636 | lr 1.27e-04 | grad 1.43 | tok/s 16954
step   2980 | loss 2.1328 | lr 1.27e-04 | grad 1.34 | tok/s 16434
step   2990 | loss 2.6971 | lr 1.27e-04 | grad 1.84 | tok/s 16859
step   3000 | loss 1.9658 | lr 1.27e-04 | grad 2.98 | tok/s 16860
  >>> saved checkpoint: checkpoint_step_003000_loss_1.9658.pt
step   3010 | loss 1.7775 | lr 1.27e-04 | grad 2.05 | tok/s 7097
step   3020 | loss 1.8049 | lr 1.27e-04 | grad 1.38 | tok/s 16326
step   3030 | loss 1.9100 | lr 1.27e-04 | grad 2.70 | tok/s 16435
step   3040 | loss 1.9395 | lr 1.27e-04 | grad 1.66 | tok/s 16852
step   3050 | loss 1.8462 | lr 1.27e-04 | grad 1.44 | tok/s 16685
step   3060 | loss 1.8891 | lr 1.27e-04 | grad 1.36 | tok/s 17171
step   3070 | loss 2.0934 | lr 1.27e-04 | grad 2.80 | tok/s 17184
step   3080 | loss 1.8659 | lr 1.27e-04 | grad 1.78 | tok/s 16834
step   3090 | loss 1.9190 | lr 1.27e-04 | grad 1.27 | tok/s 16962
step   3100 | loss 2.0276 | lr 1.27e-04 | grad 1.73 | tok/s 16609
step   3110 | loss 1.9227 | lr 1.27e-04 | grad 1.42 | tok/s 17148
step   3120 | loss 1.7364 | lr 1.27e-04 | grad 1.70 | tok/s 17309
step   3130 | loss 1.9008 | lr 1.27e-04 | grad 2.28 | tok/s 16376
step   3140 | loss 1.9474 | lr 1.27e-04 | grad 1.64 | tok/s 17314
step   3150 | loss 1.8202 | lr 1.27e-04 | grad 1.37 | tok/s 17298
step   3160 | loss 1.8194 | lr 1.27e-04 | grad 2.42 | tok/s 16338
step   3170 | loss 2.0169 | lr 1.27e-04 | grad 1.28 | tok/s 16280
step   3180 | loss 1.8535 | lr 1.27e-04 | grad 1.81 | tok/s 16512
step   3190 | loss 1.7027 | lr 1.27e-04 | grad 2.31 | tok/s 17025
step   3200 | loss 1.9723 | lr 1.27e-04 | grad 2.98 | tok/s 17217
step   3210 | loss 1.9790 | lr 1.27e-04 | grad 1.45 | tok/s 16848
step   3220 | loss 2.7088 | lr 1.27e-04 | grad 3.06 | tok/s 16808
step   3230 | loss 2.5930 | lr 1.27e-04 | grad 2.14 | tok/s 17318
step   3240 | loss 2.3984 | lr 1.27e-04 | grad 1.71 | tok/s 17311
step   3250 | loss 2.2842 | lr 1.27e-04 | grad 1.73 | tok/s 17310
step   3260 | loss 2.2285 | lr 1.27e-04 | grad 1.84 | tok/s 17305
step   3270 | loss 2.1339 | lr 1.27e-04 | grad 1.53 | tok/s 17292
step   3280 | loss 2.0811 | lr 1.27e-04 | grad 1.33 | tok/s 17307
step   3290 | loss 2.0470 | lr 1.27e-04 | grad 1.39 | tok/s 17310
step   3300 | loss 2.0172 | lr 1.27e-04 | grad 1.65 | tok/s 17306
step   3310 | loss 1.9979 | lr 1.27e-04 | grad 1.49 | tok/s 17307
step   3320 | loss 1.9775 | lr 1.27e-04 | grad 1.12 | tok/s 17309
step   3330 | loss 1.9747 | lr 1.27e-04 | grad 1.57 | tok/s 17296
step   3340 | loss 2.2995 | lr 1.27e-04 | grad 3.19 | tok/s 16207
step   3350 | loss 1.9900 | lr 1.27e-04 | grad 1.55 | tok/s 16744
step   3360 | loss 1.8853 | lr 1.27e-04 | grad 1.65 | tok/s 16443
step   3370 | loss 1.8399 | lr 1.27e-04 | grad 1.80 | tok/s 15976
step   3380 | loss 1.9913 | lr 1.27e-04 | grad 1.64 | tok/s 16211
step   3390 | loss 1.8880 | lr 1.27e-04 | grad 2.09 | tok/s 16580
step   3400 | loss 1.7297 | lr 1.27e-04 | grad 1.36 | tok/s 17275
step   3410 | loss 1.7457 | lr 1.27e-04 | grad 1.35 | tok/s 17290
step   3420 | loss 1.9195 | lr 1.27e-04 | grad 1.73 | tok/s 16391
step   3430 | loss 1.8633 | lr 1.27e-04 | grad 1.42 | tok/s 16700
step   3440 | loss 1.9084 | lr 1.27e-04 | grad 1.72 | tok/s 16175
step   3450 | loss 1.8355 | lr 1.27e-04 | grad 2.22 | tok/s 16902
step   3460 | loss 2.2095 | lr 1.27e-04 | grad 2.20 | tok/s 16654
step   3470 | loss 1.8371 | lr 1.27e-04 | grad 1.40 | tok/s 17081
step   3480 | loss 1.9179 | lr 1.27e-04 | grad 1.70 | tok/s 17173
step   3490 | loss 1.7304 | lr 1.27e-04 | grad 1.70 | tok/s 15953
step   3500 | loss 1.8610 | lr 1.27e-04 | grad 1.37 | tok/s 17278
step   3510 | loss 1.8040 | lr 1.27e-04 | grad 2.03 | tok/s 16162
step   3520 | loss 1.8689 | lr 1.27e-04 | grad 1.34 | tok/s 16402
step   3530 | loss 2.5679 | lr 1.27e-04 | grad 1.84 | tok/s 17300
step   3540 | loss 2.0433 | lr 1.27e-04 | grad 1.48 | tok/s 16653
step   3550 | loss 2.3870 | lr 1.27e-04 | grad 2.34 | tok/s 16359
step   3560 | loss 1.9127 | lr 1.27e-04 | grad 1.62 | tok/s 15627
step   3570 | loss 1.8653 | lr 1.27e-04 | grad 1.60 | tok/s 15907
step   3580 | loss 1.6633 | lr 1.27e-04 | grad 1.91 | tok/s 16440
step   3590 | loss 1.9568 | lr 1.27e-04 | grad 1.30 | tok/s 17217
step   3600 | loss 1.7802 | lr 1.27e-04 | grad 1.38 | tok/s 15878
step   3610 | loss 1.9746 | lr 1.27e-04 | grad 1.81 | tok/s 16167
step   3620 | loss 1.7251 | lr 1.27e-04 | grad 1.55 | tok/s 17264
step   3630 | loss 1.8862 | lr 1.27e-04 | grad 1.52 | tok/s 16377
step   3640 | loss 2.0707 | lr 1.27e-04 | grad 1.52 | tok/s 16559
step   3650 | loss 1.8111 | lr 1.27e-04 | grad 1.50 | tok/s 15940
step   3660 | loss 1.7893 | lr 1.27e-04 | grad 1.23 | tok/s 15946
step   3670 | loss 2.0933 | lr 1.27e-04 | grad 1.48 | tok/s 16710
step   3680 | loss 1.8384 | lr 1.27e-04 | grad 1.93 | tok/s 16520
step   3690 | loss 1.7881 | lr 1.27e-04 | grad 1.41 | tok/s 16342
step   3700 | loss 2.0581 | lr 1.27e-04 | grad 1.51 | tok/s 16326
step   3710 | loss 1.7683 | lr 1.27e-04 | grad 1.70 | tok/s 16284
step   3720 | loss 1.9995 | lr 1.27e-04 | grad 1.69 | tok/s 16673
step   3730 | loss 2.0256 | lr 1.27e-04 | grad 1.76 | tok/s 16342
step   3740 | loss 1.6544 | lr 1.27e-04 | grad 1.30 | tok/s 17203
step   3750 | loss 2.1332 | lr 1.27e-04 | grad 2.17 | tok/s 16368
step   3760 | loss 1.7823 | lr 1.27e-04 | grad 1.45 | tok/s 17266
step   3770 | loss 1.7369 | lr 1.27e-04 | grad 1.30 | tok/s 17269
step   3780 | loss 1.7005 | lr 1.27e-04 | grad 1.28 | tok/s 17287
step   3790 | loss 1.6479 | lr 1.27e-04 | grad 1.17 | tok/s 17266
step   3800 | loss 1.6641 | lr 1.27e-04 | grad 1.28 | tok/s 17264
step   3810 | loss 1.6287 | lr 1.27e-04 | grad 1.30 | tok/s 17262
step   3820 | loss 1.6124 | lr 1.27e-04 | grad 1.23 | tok/s 17250
step   3830 | loss 1.6411 | lr 1.27e-04 | grad 1.13 | tok/s 17253
step   3840 | loss 1.6004 | lr 1.27e-04 | grad 1.09 | tok/s 17281
step   3850 | loss 1.5657 | lr 1.27e-04 | grad 1.10 | tok/s 17257
step   3860 | loss 1.7762 | lr 1.27e-04 | grad 2.11 | tok/s 17071
step   3870 | loss 1.7791 | lr 1.27e-04 | grad 1.30 | tok/s 16067
step   3880 | loss 2.1596 | lr 1.27e-04 | grad 2.06 | tok/s 16727
step   3890 | loss 1.9377 | lr 1.27e-04 | grad 1.56 | tok/s 15484
step   3900 | loss 1.9176 | lr 1.27e-04 | grad 3.16 | tok/s 16944
step   3910 | loss 2.0416 | lr 1.27e-04 | grad 1.59 | tok/s 16981
step   3920 | loss 1.9976 | lr 1.27e-04 | grad 3.48 | tok/s 15887
step   3930 | loss 1.9325 | lr 1.27e-04 | grad 1.36 | tok/s 16498
step   3940 | loss 2.0484 | lr 1.27e-04 | grad 1.41 | tok/s 16952
step   3950 | loss 1.7523 | lr 1.27e-04 | grad 1.89 | tok/s 15893
step   3960 | loss 2.2360 | lr 1.27e-04 | grad 2.17 | tok/s 16804
step   3970 | loss 2.3577 | lr 1.27e-04 | grad 2.09 | tok/s 17271
step   3980 | loss 1.9871 | lr 1.27e-04 | grad 2.36 | tok/s 16173
step   3990 | loss 1.7331 | lr 1.27e-04 | grad 1.71 | tok/s 17225
step   4000 | loss 1.5158 | lr 1.27e-04 | grad 2.00 | tok/s 17296
  >>> saved checkpoint: checkpoint_step_004000_loss_1.5158.pt
step   4010 | loss 1.8694 | lr 1.27e-04 | grad 1.79 | tok/s 7133
step   4020 | loss 1.9246 | lr 1.27e-04 | grad 3.50 | tok/s 15514
step   4030 | loss 1.7039 | lr 1.27e-04 | grad 1.34 | tok/s 15722
step   4040 | loss 1.9288 | lr 1.27e-04 | grad 1.66 | tok/s 17181
step   4050 | loss 1.8371 | lr 1.27e-04 | grad 1.54 | tok/s 16081
step   4060 | loss 2.4694 | lr 1.27e-04 | grad 5.12 | tok/s 16430
step   4070 | loss 1.8897 | lr 1.27e-04 | grad 1.33 | tok/s 16376
step   4080 | loss 1.8783 | lr 1.27e-04 | grad 1.62 | tok/s 16733
step   4090 | loss 1.7110 | lr 1.27e-04 | grad 1.52 | tok/s 16963
step   4100 | loss 1.7843 | lr 1.27e-04 | grad 1.47 | tok/s 16598
step   4110 | loss 2.0272 | lr 1.27e-04 | grad 1.68 | tok/s 17011
step   4120 | loss 2.1314 | lr 1.27e-04 | grad 2.42 | tok/s 16574
step   4130 | loss 1.9326 | lr 1.27e-04 | grad 1.41 | tok/s 16196
step   4140 | loss 1.3604 | lr 1.27e-04 | grad 1.46 | tok/s 17385
step   4150 | loss 1.8703 | lr 1.27e-04 | grad 3.75 | tok/s 15921
step   4160 | loss 1.6950 | lr 1.27e-04 | grad 1.48 | tok/s 16069
step   4170 | loss 1.6497 | lr 1.27e-04 | grad 1.70 | tok/s 17315
step   4180 | loss 2.3144 | lr 1.27e-04 | grad 2.56 | tok/s 16826
step   4190 | loss 2.6511 | lr 1.27e-04 | grad 3.86 | tok/s 17176
step   4200 | loss 2.4723 | lr 1.27e-04 | grad 2.81 | tok/s 17314
step   4210 | loss 1.9956 | lr 1.27e-04 | grad 1.98 | tok/s 16560
step   4220 | loss 1.7837 | lr 1.27e-04 | grad 2.69 | tok/s 16427
step   4230 | loss 2.4388 | lr 1.27e-04 | grad 5.12 | tok/s 16609
step   4240 | loss 2.8670 | lr 1.27e-04 | grad 1.93 | tok/s 17148
step   4250 | loss 1.9320 | lr 1.27e-04 | grad 1.60 | tok/s 16012
step   4260 | loss 1.7177 | lr 1.27e-04 | grad 1.41 | tok/s 16074
step   4270 | loss 2.0408 | lr 1.27e-04 | grad 1.70 | tok/s 17005
step   4280 | loss 2.2110 | lr 1.27e-04 | grad 1.61 | tok/s 16904
step   4290 | loss 1.8585 | lr 1.27e-04 | grad 3.31 | tok/s 15878
step   4300 | loss 2.4880 | lr 1.27e-04 | grad 1.77 | tok/s 17312
step   4310 | loss 1.8415 | lr 1.27e-04 | grad 1.41 | tok/s 16602
step   4320 | loss 1.9891 | lr 1.27e-04 | grad 1.53 | tok/s 16729
step   4330 | loss 1.7713 | lr 1.27e-04 | grad 1.56 | tok/s 16512
step   4340 | loss 1.8545 | lr 1.27e-04 | grad 1.77 | tok/s 17122
step   4350 | loss 1.7207 | lr 1.27e-04 | grad 1.94 | tok/s 17161
step   4360 | loss 1.4654 | lr 1.27e-04 | grad 2.00 | tok/s 17153
step   4370 | loss 2.2748 | lr 1.27e-04 | grad 1.94 | tok/s 17133
step   4380 | loss 1.8094 | lr 1.27e-04 | grad 1.52 | tok/s 16095
step   4390 | loss 1.9398 | lr 1.27e-04 | grad 1.75 | tok/s 17075
step   4400 | loss 1.9995 | lr 1.27e-04 | grad 1.68 | tok/s 17302
step   4410 | loss 2.0459 | lr 1.27e-04 | grad 2.31 | tok/s 17297
step   4420 | loss 2.0959 | lr 1.27e-04 | grad 1.66 | tok/s 16571
step   4430 | loss 1.6153 | lr 1.27e-04 | grad 2.00 | tok/s 16581
step   4440 | loss 1.9384 | lr 1.27e-04 | grad 1.78 | tok/s 15967
step   4450 | loss 1.8442 | lr 1.27e-04 | grad 1.75 | tok/s 15854
step   4460 | loss 2.1521 | lr 1.27e-04 | grad 1.73 | tok/s 16871
step   4470 | loss 1.7153 | lr 1.27e-04 | grad 1.73 | tok/s 16945
step   4480 | loss 1.7672 | lr 1.27e-04 | grad 2.02 | tok/s 16458
step   4490 | loss 1.8749 | lr 1.27e-04 | grad 1.99 | tok/s 16369
step   4500 | loss 1.7735 | lr 1.27e-04 | grad 2.05 | tok/s 16342
step   4510 | loss 1.9545 | lr 1.27e-04 | grad 3.14 | tok/s 17177
step   4520 | loss 2.0161 | lr 1.27e-04 | grad 3.20 | tok/s 16984
step   4530 | loss 2.0811 | lr 1.27e-04 | grad 2.02 | tok/s 16123
step   4540 | loss 2.0342 | lr 1.27e-04 | grad 2.22 | tok/s 15717
step   4550 | loss 1.9005 | lr 1.27e-04 | grad 1.37 | tok/s 16104
step   4560 | loss 1.7618 | lr 1.27e-04 | grad 1.80 | tok/s 17081
step   4570 | loss 1.6827 | lr 1.27e-04 | grad 1.88 | tok/s 16895
step   4580 | loss 1.6940 | lr 1.27e-04 | grad 1.54 | tok/s 15873
step   4590 | loss 2.3359 | lr 1.27e-04 | grad 3.00 | tok/s 16301
step   4600 | loss 1.7168 | lr 1.27e-04 | grad 1.92 | tok/s 16320
step   4610 | loss 2.0122 | lr 1.27e-04 | grad 1.35 | tok/s 16344
step   4620 | loss 1.5685 | lr 1.27e-04 | grad 2.03 | tok/s 16837
step   4630 | loss 1.8288 | lr 1.27e-04 | grad 1.38 | tok/s 17300
step   4640 | loss 1.7589 | lr 1.27e-04 | grad 1.26 | tok/s 17269
step   4650 | loss 1.7675 | lr 1.27e-04 | grad 1.34 | tok/s 17267
step   4660 | loss 1.7627 | lr 1.27e-04 | grad 1.39 | tok/s 17263
step   4670 | loss 1.7257 | lr 1.27e-04 | grad 1.40 | tok/s 17258
step   4680 | loss 1.7440 | lr 1.27e-04 | grad 1.46 | tok/s 17293
step   4690 | loss 1.6963 | lr 1.27e-04 | grad 1.55 | tok/s 17261
step   4700 | loss 1.6707 | lr 1.27e-04 | grad 1.27 | tok/s 17261
step   4710 | loss 1.7152 | lr 1.27e-04 | grad 1.37 | tok/s 17273
step   4720 | loss 1.6705 | lr 1.27e-04 | grad 1.45 | tok/s 17284
step   4730 | loss 1.6318 | lr 1.27e-04 | grad 1.54 | tok/s 17261
step   4740 | loss 1.6601 | lr 1.27e-04 | grad 1.42 | tok/s 17284
step   4750 | loss 1.6375 | lr 1.27e-04 | grad 1.25 | tok/s 17269
step   4760 | loss 1.5995 | lr 1.27e-04 | grad 1.58 | tok/s 17296
step   4770 | loss 1.6417 | lr 1.27e-04 | grad 1.50 | tok/s 17280
step   4780 | loss 1.6316 | lr 1.27e-04 | grad 1.48 | tok/s 17261
step   4790 | loss 1.6455 | lr 1.27e-04 | grad 1.36 | tok/s 17294
step   4800 | loss 1.6263 | lr 1.27e-04 | grad 1.30 | tok/s 17271
step   4810 | loss 1.6183 | lr 1.27e-04 | grad 1.51 | tok/s 17264
step   4820 | loss 1.7464 | lr 1.27e-04 | grad 2.00 | tok/s 17235
step   4830 | loss 2.2057 | lr 1.27e-04 | grad 2.02 | tok/s 16510
step   4840 | loss 1.7138 | lr 1.27e-04 | grad 1.55 | tok/s 16922
step   4850 | loss 1.0407 | lr 1.27e-04 | grad 1.67 | tok/s 16875
step   4860 | loss 1.7866 | lr 1.27e-04 | grad 1.99 | tok/s 16624
step   4870 | loss 1.7847 | lr 1.27e-04 | grad 2.77 | tok/s 15759
step   4880 | loss 1.7760 | lr 1.27e-04 | grad 1.49 | tok/s 15823
step   4890 | loss 1.8668 | lr 1.27e-04 | grad 2.55 | tok/s 16797
step   4900 | loss 1.6892 | lr 1.27e-04 | grad 1.45 | tok/s 16454
step   4910 | loss 1.7891 | lr 1.27e-04 | grad 1.49 | tok/s 16834
step   4920 | loss 2.1512 | lr 1.27e-04 | grad 1.71 | tok/s 17060
step   4930 | loss 1.6797 | lr 1.27e-04 | grad 1.75 | tok/s 17237
step   4940 | loss 1.7984 | lr 1.27e-04 | grad 5.97 | tok/s 16242
step   4950 | loss 1.7210 | lr 1.27e-04 | grad 1.53 | tok/s 16287
step   4960 | loss 2.0611 | lr 1.27e-04 | grad 2.45 | tok/s 17149
step   4970 | loss 1.8067 | lr 1.27e-04 | grad 1.64 | tok/s 17133
step   4980 | loss 2.0698 | lr 1.27e-04 | grad 2.41 | tok/s 16703
step   4990 | loss 1.9760 | lr 1.27e-04 | grad 1.78 | tok/s 16199
step   5000 | loss 2.1482 | lr 1.27e-04 | grad 3.83 | tok/s 17303
  >>> saved checkpoint: checkpoint_step_005000_loss_2.1482.pt
step   5010 | loss 1.8071 | lr 1.27e-04 | grad 1.61 | tok/s 6756
step   5020 | loss 2.0567 | lr 1.27e-04 | grad 1.24 | tok/s 17049
step   5030 | loss 1.7574 | lr 1.27e-04 | grad 1.66 | tok/s 16767
step   5040 | loss 1.8566 | lr 1.27e-04 | grad 1.83 | tok/s 16386
step   5050 | loss 2.1117 | lr 1.27e-04 | grad 3.00 | tok/s 16939
step   5060 | loss 1.8712 | lr 1.27e-04 | grad 2.92 | tok/s 16785
step   5070 | loss 1.7899 | lr 1.27e-04 | grad 1.90 | tok/s 15860
step   5080 | loss 1.7360 | lr 1.27e-04 | grad 1.53 | tok/s 16294
step   5090 | loss 1.8653 | lr 1.27e-04 | grad 1.86 | tok/s 16747
step   5100 | loss 1.7091 | lr 1.27e-04 | grad 1.73 | tok/s 16664
step   5110 | loss 1.9752 | lr 1.27e-04 | grad 1.70 | tok/s 16499
step   5120 | loss 1.9438 | lr 1.27e-04 | grad 1.90 | tok/s 16395
step   5130 | loss 1.6803 | lr 1.27e-04 | grad 2.06 | tok/s 16318
step   5140 | loss 1.8525 | lr 1.27e-04 | grad 2.06 | tok/s 16715
step   5150 | loss 2.3055 | lr 1.27e-04 | grad 3.09 | tok/s 17217
step   5160 | loss 1.9564 | lr 1.27e-04 | grad 1.95 | tok/s 15990
step   5170 | loss 1.6944 | lr 1.27e-04 | grad 1.62 | tok/s 16110
step   5180 | loss 1.7599 | lr 1.27e-04 | grad 1.92 | tok/s 16324
step   5190 | loss 1.7861 | lr 1.27e-04 | grad 1.87 | tok/s 15674
step   5200 | loss 1.9489 | lr 1.27e-04 | grad 1.31 | tok/s 17275
step   5210 | loss 1.9518 | lr 1.27e-04 | grad 1.73 | tok/s 16685
step   5220 | loss 1.8589 | lr 1.27e-04 | grad 1.38 | tok/s 17317
step   5230 | loss 1.9642 | lr 1.27e-04 | grad 5.19 | tok/s 16126
step   5240 | loss 1.9336 | lr 1.27e-04 | grad 1.85 | tok/s 16782
step   5250 | loss 1.7293 | lr 1.27e-04 | grad 1.43 | tok/s 17332
step   5260 | loss 1.6200 | lr 1.27e-04 | grad 1.67 | tok/s 16684
step   5270 | loss 1.7768 | lr 1.27e-04 | grad 4.66 | tok/s 17032
step   5280 | loss 1.8703 | lr 1.27e-04 | grad 1.79 | tok/s 16001
step   5290 | loss 1.6421 | lr 1.27e-04 | grad 1.61 | tok/s 16268
step   5300 | loss 1.7038 | lr 1.27e-04 | grad 1.95 | tok/s 17185
step   5310 | loss 1.8007 | lr 1.27e-04 | grad 1.98 | tok/s 16252
step   5320 | loss 1.7739 | lr 1.27e-04 | grad 1.71 | tok/s 17293
step   5330 | loss 1.8286 | lr 1.27e-04 | grad 2.03 | tok/s 17201
step   5340 | loss 1.7706 | lr 1.27e-04 | grad 1.62 | tok/s 16319
step   5350 | loss 1.8960 | lr 1.27e-04 | grad 2.39 | tok/s 16794
step   5360 | loss 1.7544 | lr 1.27e-04 | grad 1.41 | tok/s 16190
step   5370 | loss 1.6583 | lr 1.27e-04 | grad 3.19 | tok/s 16444
step   5380 | loss 1.7108 | lr 1.27e-04 | grad 1.70 | tok/s 15739
step   5390 | loss 1.9673 | lr 1.27e-04 | grad 1.76 | tok/s 16885
step   5400 | loss 1.6977 | lr 1.27e-04 | grad 1.78 | tok/s 16491
step   5410 | loss 2.0394 | lr 1.27e-04 | grad 2.53 | tok/s 16955
step   5420 | loss 2.2832 | lr 1.27e-04 | grad 1.59 | tok/s 16311
step   5430 | loss 1.9203 | lr 1.27e-04 | grad 1.67 | tok/s 16762
step   5440 | loss 1.7915 | lr 1.27e-04 | grad 1.28 | tok/s 16878
step   5450 | loss 1.7235 | lr 1.27e-04 | grad 1.83 | tok/s 15973
step   5460 | loss 1.8293 | lr 1.27e-04 | grad 3.31 | tok/s 16977
step   5470 | loss 1.9729 | lr 1.27e-04 | grad 3.52 | tok/s 16707
step   5480 | loss 1.7079 | lr 1.27e-04 | grad 1.55 | tok/s 16336
step   5490 | loss 1.9614 | lr 1.27e-04 | grad 2.98 | tok/s 16332
step   5500 | loss 1.8500 | lr 1.27e-04 | grad 1.92 | tok/s 17210
step   5510 | loss 1.6140 | lr 1.27e-04 | grad 1.51 | tok/s 17293
step   5520 | loss 1.7326 | lr 1.27e-04 | grad 1.57 | tok/s 16508
step   5530 | loss 2.0435 | lr 1.27e-04 | grad 3.83 | tok/s 16640
step   5540 | loss 1.9956 | lr 1.27e-04 | grad 1.74 | tok/s 16736
step   5550 | loss 1.7284 | lr 1.27e-04 | grad 2.02 | tok/s 16957
step   5560 | loss 1.7083 | lr 1.27e-04 | grad 2.48 | tok/s 16865
step   5570 | loss 1.7165 | lr 1.27e-04 | grad 1.61 | tok/s 17168
step   5580 | loss 1.9232 | lr 1.27e-04 | grad 2.58 | tok/s 15858
step   5590 | loss 1.9441 | lr 1.27e-04 | grad 1.53 | tok/s 15955
step   5600 | loss 1.7449 | lr 1.27e-04 | grad 1.85 | tok/s 16119
step   5610 | loss 1.9085 | lr 1.27e-04 | grad 1.74 | tok/s 17317
step   5620 | loss 1.9267 | lr 1.27e-04 | grad 2.34 | tok/s 16035
step   5630 | loss 1.7359 | lr 1.27e-04 | grad 2.27 | tok/s 15396
step   5640 | loss 1.7465 | lr 1.27e-04 | grad 2.53 | tok/s 15934
step   5650 | loss 1.5674 | lr 1.27e-04 | grad 2.34 | tok/s 16592
step   5660 | loss 1.6514 | lr 1.27e-04 | grad 1.62 | tok/s 16492
step   5670 | loss 1.7200 | lr 1.27e-04 | grad 1.72 | tok/s 15797
step   5680 | loss 1.4784 | lr 1.27e-04 | grad 1.24 | tok/s 16825
step   5690 | loss 1.7452 | lr 1.27e-04 | grad 1.54 | tok/s 17284
step   5700 | loss 1.6295 | lr 1.27e-04 | grad 1.35 | tok/s 17291
step   5710 | loss 1.5759 | lr 1.27e-04 | grad 1.30 | tok/s 17275
step   5720 | loss 1.7126 | lr 1.27e-04 | grad 2.03 | tok/s 16335
step   5730 | loss 1.8936 | lr 1.27e-04 | grad 2.25 | tok/s 16862
step   5740 | loss 1.7633 | lr 1.27e-04 | grad 1.81 | tok/s 16136
step   5750 | loss 1.7487 | lr 1.27e-04 | grad 1.64 | tok/s 15909
step   5760 | loss 1.8216 | lr 1.27e-04 | grad 1.53 | tok/s 16291
step   5770 | loss 1.8396 | lr 1.27e-04 | grad 1.35 | tok/s 16613
step   5780 | loss 1.9205 | lr 1.27e-04 | grad 3.25 | tok/s 16952
step   5790 | loss 1.9175 | lr 1.27e-04 | grad 2.02 | tok/s 16747
step   5800 | loss 1.8060 | lr 1.27e-04 | grad 1.88 | tok/s 15595
step   5810 | loss 1.8490 | lr 1.27e-04 | grad 1.93 | tok/s 17313
step   5820 | loss 1.8810 | lr 1.27e-04 | grad 1.88 | tok/s 16945
step   5830 | loss 1.6349 | lr 1.27e-04 | grad 1.74 | tok/s 15790
step   5840 | loss 1.6589 | lr 1.27e-04 | grad 2.55 | tok/s 16796
step   5850 | loss 1.7803 | lr 1.27e-04 | grad 1.95 | tok/s 16978
step   5860 | loss 1.8537 | lr 1.27e-04 | grad 1.97 | tok/s 16834
step   5870 | loss 1.7284 | lr 1.27e-04 | grad 2.31 | tok/s 16807
step   5880 | loss 1.7606 | lr 1.27e-04 | grad 1.61 | tok/s 16309
step   5890 | loss 2.2600 | lr 1.27e-04 | grad 1.99 | tok/s 16520
step   5900 | loss 1.9313 | lr 1.27e-04 | grad 2.16 | tok/s 16851
step   5910 | loss 1.5757 | lr 1.27e-04 | grad 1.58 | tok/s 15599
step   5920 | loss 2.1949 | lr 1.27e-04 | grad 2.73 | tok/s 16727
step   5930 | loss 2.0558 | lr 1.27e-04 | grad 2.30 | tok/s 16311
step   5940 | loss 1.7170 | lr 1.27e-04 | grad 1.90 | tok/s 16845
step   5950 | loss 1.8211 | lr 1.27e-04 | grad 1.94 | tok/s 16455
step   5960 | loss 1.8375 | lr 1.27e-04 | grad 1.63 | tok/s 17289
step   5970 | loss 2.0763 | lr 1.27e-04 | grad 1.89 | tok/s 16939
step   5980 | loss 1.9287 | lr 1.27e-04 | grad 1.50 | tok/s 16605
step   5990 | loss 1.7815 | lr 1.27e-04 | grad 1.87 | tok/s 16547
step   6000 | loss 1.7305 | lr 1.27e-04 | grad 2.16 | tok/s 17166
  >>> saved checkpoint: checkpoint_step_006000_loss_1.7305.pt
step   6010 | loss 1.8311 | lr 1.27e-04 | grad 2.66 | tok/s 6303
step   6020 | loss 1.8036 | lr 1.27e-04 | grad 1.72 | tok/s 17241
step   6030 | loss 1.8350 | lr 1.27e-04 | grad 1.72 | tok/s 16767
step   6040 | loss 1.7505 | lr 1.27e-04 | grad 1.53 | tok/s 16406
step   6050 | loss 1.7207 | lr 1.27e-04 | grad 2.00 | tok/s 16503
step   6060 | loss 1.7330 | lr 1.27e-04 | grad 1.88 | tok/s 15799
step   6070 | loss 1.9176 | lr 1.27e-04 | grad 1.54 | tok/s 17386
step   6080 | loss 1.7597 | lr 1.27e-04 | grad 1.76 | tok/s 16488
step   6090 | loss 1.7238 | lr 1.27e-04 | grad 2.02 | tok/s 16899
step   6100 | loss 1.7163 | lr 1.27e-04 | grad 1.68 | tok/s 17357
step   6110 | loss 1.5083 | lr 1.27e-04 | grad 1.45 | tok/s 17375
step   6120 | loss 1.6647 | lr 1.27e-04 | grad 3.91 | tok/s 16740
step   6130 | loss 2.2973 | lr 1.27e-04 | grad 1.53 | tok/s 15900
step   6140 | loss 2.6599 | lr 1.27e-04 | grad 3.14 | tok/s 17138
step   6150 | loss 2.1814 | lr 1.27e-04 | grad 1.88 | tok/s 17064
step   6160 | loss 1.7800 | lr 1.27e-04 | grad 3.20 | tok/s 16737
step   6170 | loss 1.9131 | lr 1.27e-04 | grad 1.57 | tok/s 16566
step   6180 | loss 1.7080 | lr 1.27e-04 | grad 1.91 | tok/s 15953
step   6190 | loss 1.7073 | lr 1.27e-04 | grad 1.62 | tok/s 16002
step   6200 | loss 1.7873 | lr 1.27e-04 | grad 1.55 | tok/s 17068
step   6210 | loss 1.8829 | lr 1.27e-04 | grad 2.33 | tok/s 17315
step   6220 | loss 2.1573 | lr 1.27e-04 | grad 2.75 | tok/s 17237
step   6230 | loss 1.7566 | lr 1.27e-04 | grad 2.16 | tok/s 16277
step   6240 | loss 1.8851 | lr 1.27e-04 | grad 1.89 | tok/s 16585
step   6250 | loss 1.5892 | lr 1.27e-04 | grad 1.67 | tok/s 16475
step   6260 | loss 1.7554 | lr 1.27e-04 | grad 3.19 | tok/s 16030
step   6270 | loss 1.7217 | lr 1.27e-04 | grad 1.67 | tok/s 16287
step   6280 | loss 1.6361 | lr 1.27e-04 | grad 2.95 | tok/s 17277
step   6290 | loss 1.7746 | lr 1.27e-04 | grad 1.93 | tok/s 15838
step   6300 | loss 1.6172 | lr 1.27e-04 | grad 1.59 | tok/s 15453
step   6310 | loss 2.0702 | lr 1.27e-04 | grad 2.03 | tok/s 16849
step   6320 | loss 1.6711 | lr 1.27e-04 | grad 1.34 | tok/s 17226
step   6330 | loss 1.6389 | lr 1.27e-04 | grad 1.58 | tok/s 17137
step   6340 | loss 1.8565 | lr 1.27e-04 | grad 1.55 | tok/s 16871
step   6350 | loss 1.3685 | lr 1.27e-04 | grad 2.12 | tok/s 17248
step   6360 | loss 1.6292 | lr 1.27e-04 | grad 1.61 | tok/s 17178
step   6370 | loss 1.9861 | lr 1.27e-04 | grad 2.20 | tok/s 16767
step   6380 | loss 1.7604 | lr 1.27e-04 | grad 1.68 | tok/s 17019
step   6390 | loss 1.6256 | lr 1.27e-04 | grad 1.34 | tok/s 16172
step   6400 | loss 1.6813 | lr 1.27e-04 | grad 1.85 | tok/s 16838
step   6410 | loss 1.7917 | lr 1.27e-04 | grad 2.92 | tok/s 16502
step   6420 | loss 1.8025 | lr 1.27e-04 | grad 2.06 | tok/s 17303
step   6430 | loss 1.7451 | lr 1.27e-04 | grad 1.70 | tok/s 16670
step   6440 | loss 1.6758 | lr 1.27e-04 | grad 1.46 | tok/s 17297
step   6450 | loss 1.6363 | lr 1.27e-04 | grad 1.34 | tok/s 16072
step   6460 | loss 1.8022 | lr 1.27e-04 | grad 1.41 | tok/s 16516
step   6470 | loss 1.6884 | lr 1.27e-04 | grad 1.86 | tok/s 16058
step   6480 | loss 1.6990 | lr 1.27e-04 | grad 1.40 | tok/s 16313
step   6490 | loss 1.7247 | lr 1.27e-04 | grad 1.66 | tok/s 15639
step   6500 | loss 1.6722 | lr 1.27e-04 | grad 1.70 | tok/s 16783
step   6510 | loss 1.8399 | lr 1.27e-04 | grad 1.95 | tok/s 16100
step   6520 | loss 1.7586 | lr 1.27e-04 | grad 2.58 | tok/s 16823
step   6530 | loss 1.7400 | lr 1.27e-04 | grad 3.41 | tok/s 16371
step   6540 | loss 1.6713 | lr 1.27e-04 | grad 1.66 | tok/s 16199
step   6550 | loss 1.9384 | lr 1.27e-04 | grad 2.31 | tok/s 16556
step   6560 | loss 1.8341 | lr 1.27e-04 | grad 2.06 | tok/s 16407
step   6570 | loss 1.6333 | lr 1.27e-04 | grad 2.38 | tok/s 17305
step   6580 | loss 1.6249 | lr 1.27e-04 | grad 2.05 | tok/s 16083
step   6590 | loss 1.9409 | lr 1.27e-04 | grad 2.53 | tok/s 17145
step   6600 | loss 2.0514 | lr 1.27e-04 | grad 2.33 | tok/s 17315
step   6610 | loss 1.9520 | lr 1.27e-04 | grad 3.19 | tok/s 16968
step   6620 | loss 2.1248 | lr 1.27e-04 | grad 4.16 | tok/s 16589
step   6630 | loss 2.7597 | lr 1.27e-04 | grad 2.66 | tok/s 17102
step   6640 | loss 1.8483 | lr 1.27e-04 | grad 1.82 | tok/s 16422
step   6650 | loss 1.7004 | lr 1.27e-04 | grad 1.79 | tok/s 15546
step   6660 | loss 1.6565 | lr 1.27e-04 | grad 1.93 | tok/s 16339
step   6670 | loss 1.8215 | lr 1.27e-04 | grad 1.72 | tok/s 17123
step   6680 | loss 1.6216 | lr 1.27e-04 | grad 1.47 | tok/s 17252
step   6690 | loss 1.6299 | lr 1.27e-04 | grad 1.94 | tok/s 16899
step   6700 | loss 2.3426 | lr 1.27e-04 | grad 2.27 | tok/s 17304
step   6710 | loss 2.1753 | lr 1.27e-04 | grad 2.36 | tok/s 16991
step   6720 | loss 1.7006 | lr 1.27e-04 | grad 3.50 | tok/s 15964
step   6730 | loss 1.8058 | lr 1.27e-04 | grad 1.64 | tok/s 16435
step   6740 | loss 1.8557 | lr 1.27e-04 | grad 1.95 | tok/s 16329
step   6750 | loss 1.8234 | lr 1.27e-04 | grad 1.88 | tok/s 16879
step   6760 | loss 1.8782 | lr 1.27e-04 | grad 1.52 | tok/s 16988
step   6770 | loss 1.7650 | lr 1.27e-04 | grad 2.23 | tok/s 15758
step   6780 | loss 1.7579 | lr 1.27e-04 | grad 1.79 | tok/s 16956
step   6790 | loss 1.8465 | lr 1.27e-04 | grad 1.84 | tok/s 16114
step   6800 | loss 1.7780 | lr 1.27e-04 | grad 2.42 | tok/s 17167
step   6810 | loss 1.8773 | lr 1.27e-04 | grad 3.23 | tok/s 15938
step   6820 | loss 1.9060 | lr 1.27e-04 | grad 1.87 | tok/s 16416
step   6830 | loss 1.9689 | lr 1.27e-04 | grad 2.27 | tok/s 16558
step   6840 | loss 1.8152 | lr 1.27e-04 | grad 1.62 | tok/s 17037
step   6850 | loss 1.7001 | lr 1.27e-04 | grad 2.30 | tok/s 16613
step   6860 | loss 1.8001 | lr 1.27e-04 | grad 1.59 | tok/s 16306
step   6870 | loss 2.0160 | lr 1.27e-04 | grad 1.59 | tok/s 17289
step   6880 | loss 1.6612 | lr 1.27e-04 | grad 1.63 | tok/s 16014
step   6890 | loss 1.7267 | lr 1.27e-04 | grad 1.74 | tok/s 16228
step   6900 | loss 1.7084 | lr 1.27e-04 | grad 1.60 | tok/s 16223
step   6910 | loss 1.8190 | lr 1.27e-04 | grad 1.51 | tok/s 16705
step   6920 | loss 1.6191 | lr 1.27e-04 | grad 1.55 | tok/s 15818
step   6930 | loss 2.2549 | lr 1.27e-04 | grad 2.12 | tok/s 17282
step   6940 | loss 2.1421 | lr 1.27e-04 | grad 1.80 | tok/s 16472
step   6950 | loss 1.6602 | lr 1.27e-04 | grad 1.91 | tok/s 15606
step   6960 | loss 1.7283 | lr 1.27e-04 | grad 1.84 | tok/s 16831
step   6970 | loss 1.9639 | lr 1.27e-04 | grad 1.75 | tok/s 17149
step   6980 | loss 1.8984 | lr 1.27e-04 | grad 1.60 | tok/s 16576
step   6990 | loss 1.8381 | lr 1.27e-04 | grad 1.43 | tok/s 16044
step   7000 | loss 1.9071 | lr 1.27e-04 | grad 1.70 | tok/s 16271
  >>> saved checkpoint: checkpoint_step_007000_loss_1.9071.pt
step   7010 | loss 1.6787 | lr 1.27e-04 | grad 1.84 | tok/s 5703
step   7020 | loss 1.6448 | lr 1.27e-04 | grad 1.42 | tok/s 16761
step   7030 | loss 1.8218 | lr 1.27e-04 | grad 4.59 | tok/s 17152
step   7040 | loss 1.9548 | lr 1.27e-04 | grad 2.20 | tok/s 17047
step   7050 | loss 2.0577 | lr 1.27e-04 | grad 2.38 | tok/s 16635
step   7060 | loss 1.8828 | lr 1.27e-04 | grad 4.72 | tok/s 16451
step   7070 | loss 1.8510 | lr 1.27e-04 | grad 2.22 | tok/s 15881
step   7080 | loss 1.6427 | lr 1.27e-04 | grad 2.48 | tok/s 16487
step   7090 | loss 1.5512 | lr 1.27e-04 | grad 1.53 | tok/s 17356
step   7100 | loss 1.7965 | lr 1.27e-04 | grad 1.70 | tok/s 16631
step   7110 | loss 1.7498 | lr 1.27e-04 | grad 1.70 | tok/s 17024
step   7120 | loss 1.9753 | lr 1.27e-04 | grad 2.91 | tok/s 16499
step   7130 | loss 1.6919 | lr 1.27e-04 | grad 1.59 | tok/s 17334
step   7140 | loss 1.5929 | lr 1.27e-04 | grad 1.43 | tok/s 17252
step   7150 | loss 1.6519 | lr 1.27e-04 | grad 1.57 | tok/s 16098
step   7160 | loss 1.5493 | lr 1.27e-04 | grad 1.88 | tok/s 16745
step   7170 | loss 1.7907 | lr 1.27e-04 | grad 2.80 | tok/s 16217
step   7180 | loss 1.6821 | lr 1.27e-04 | grad 1.78 | tok/s 15987
step   7190 | loss 1.6546 | lr 1.27e-04 | grad 1.90 | tok/s 17095
step   7200 | loss 1.5563 | lr 1.27e-04 | grad 1.70 | tok/s 16366
step   7210 | loss 1.8030 | lr 1.27e-04 | grad 1.62 | tok/s 16838
step   7220 | loss 1.9082 | lr 1.27e-04 | grad 2.38 | tok/s 16768
step   7230 | loss 1.6851 | lr 1.27e-04 | grad 1.59 | tok/s 15877
step   7240 | loss 1.6066 | lr 1.27e-04 | grad 1.58 | tok/s 15888
step   7250 | loss 1.7198 | lr 1.27e-04 | grad 3.22 | tok/s 16677
step   7260 | loss 1.8835 | lr 1.27e-04 | grad 2.44 | tok/s 17128
step   7270 | loss 1.9488 | lr 1.27e-04 | grad 2.73 | tok/s 16204
step   7280 | loss 1.7873 | lr 1.27e-04 | grad 1.71 | tok/s 16181
step   7290 | loss 2.0260 | lr 1.27e-04 | grad 3.61 | tok/s 16732
step   7300 | loss 1.8522 | lr 1.27e-04 | grad 1.53 | tok/s 16266
step   7310 | loss 1.7931 | lr 1.27e-04 | grad 1.35 | tok/s 16058
step   7320 | loss 1.7169 | lr 1.27e-04 | grad 1.75 | tok/s 16259
step   7330 | loss 1.6565 | lr 1.27e-04 | grad 1.48 | tok/s 16619
step   7340 | loss 1.7455 | lr 1.27e-04 | grad 1.59 | tok/s 17060
step   7350 | loss 1.6031 | lr 1.27e-04 | grad 2.27 | tok/s 15453
step   7360 | loss 1.7605 | lr 1.27e-04 | grad 2.00 | tok/s 17076
step   7370 | loss 1.8077 | lr 1.27e-04 | grad 1.45 | tok/s 16944
step   7380 | loss 1.7006 | lr 1.27e-04 | grad 1.86 | tok/s 17104
step   7390 | loss 1.6961 | lr 1.27e-04 | grad 1.75 | tok/s 17326

Training complete! Final step: 7390
