Using device: cuda
Output directory: benchmark_results/cmaes_4d/transformer_480M_converge0.01_20260203_094548/eval_9/levelllama_100m_20260203_101626
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 1,208,120,832 parameters
Using schedule-free AdamW (lr=0.0007339603024725283)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 10.5756 | lr 7.34e-04 | grad 14.25 | tok/s 4548
step     20 | loss 3.6428 | lr 7.34e-04 | grad 4.41 | tok/s 8449
step     30 | loss 3.1638 | lr 7.34e-04 | grad 4.28 | tok/s 8503
step     40 | loss 3.0750 | lr 7.34e-04 | grad 3.89 | tok/s 8044
step     50 | loss 3.5268 | lr 7.34e-04 | grad 4.69 | tok/s 8131
step     60 | loss 3.1860 | lr 7.34e-04 | grad 17.62 | tok/s 8330
step     70 | loss 2.8316 | lr 7.34e-04 | grad 5.34 | tok/s 8400
step     80 | loss 6.5518 | lr 7.34e-04 | grad 12.81 | tok/s 8453
step     90 | loss 4.9226 | lr 7.34e-04 | grad 4.47 | tok/s 8595
step    100 | loss 4.0782 | lr 7.34e-04 | grad 3.98 | tok/s 8562
step    110 | loss 4.0343 | lr 7.34e-04 | grad 11.31 | tok/s 8544
step    120 | loss 3.8649 | lr 7.34e-04 | grad 12.12 | tok/s 8508
step    130 | loss 3.8295 | lr 7.34e-04 | grad 7.03 | tok/s 8501
step    140 | loss 3.3293 | lr 7.34e-04 | grad 5.44 | tok/s 8485
step    150 | loss 3.6483 | lr 7.34e-04 | grad 10.44 | tok/s 8476
step    160 | loss 3.1055 | lr 7.34e-04 | grad 7.91 | tok/s 8418
step    170 | loss 3.1338 | lr 7.34e-04 | grad 10.94 | tok/s 8426
step    180 | loss 2.9368 | lr 7.34e-04 | grad 10.00 | tok/s 8401
step    190 | loss 3.0774 | lr 7.34e-04 | grad 8.44 | tok/s 8383
step    200 | loss 2.7933 | lr 7.34e-04 | grad 5.47 | tok/s 8390
step    210 | loss 2.6837 | lr 7.34e-04 | grad 3.47 | tok/s 8390
step    220 | loss 3.0132 | lr 7.34e-04 | grad 3.00 | tok/s 8281
step    230 | loss 3.4177 | lr 7.34e-04 | grad 3.77 | tok/s 8214
step    240 | loss 2.8620 | lr 7.34e-04 | grad 4.47 | tok/s 7799
step    250 | loss 2.6960 | lr 7.34e-04 | grad 2.81 | tok/s 8014
step    260 | loss 2.5242 | lr 7.34e-04 | grad 3.34 | tok/s 8264
step    270 | loss 2.8570 | lr 7.34e-04 | grad 2.69 | tok/s 8144
step    280 | loss 2.8242 | lr 7.34e-04 | grad 3.31 | tok/s 7967
step    290 | loss 2.7871 | lr 7.34e-04 | grad 6.38 | tok/s 8422
step    300 | loss 2.0685 | lr 7.34e-04 | grad 3.52 | tok/s 8404
step    310 | loss 2.9854 | lr 7.34e-04 | grad 2.81 | tok/s 8240
step    320 | loss 2.7364 | lr 7.34e-04 | grad 5.59 | tok/s 8093
step    330 | loss 2.5586 | lr 7.34e-04 | grad 2.38 | tok/s 7817
step    340 | loss 2.8798 | lr 7.34e-04 | grad 2.72 | tok/s 7939
step    350 | loss 2.7094 | lr 7.34e-04 | grad 4.97 | tok/s 8145
step    360 | loss 3.0148 | lr 7.34e-04 | grad 3.73 | tok/s 8322
step    370 | loss 2.5606 | lr 7.34e-04 | grad 3.48 | tok/s 7542
step    380 | loss 2.5088 | lr 7.34e-04 | grad 3.44 | tok/s 8000
step    390 | loss 2.3855 | lr 7.34e-04 | grad 3.70 | tok/s 8383
step    400 | loss 2.4144 | lr 7.34e-04 | grad 3.66 | tok/s 8309
step    410 | loss 2.3579 | lr 7.34e-04 | grad 2.41 | tok/s 8128
step    420 | loss 2.4525 | lr 7.34e-04 | grad 3.62 | tok/s 7734
step    430 | loss 2.7065 | lr 7.34e-04 | grad 3.69 | tok/s 8254
step    440 | loss 2.7692 | lr 7.34e-04 | grad 3.56 | tok/s 7815
step    450 | loss 3.2766 | lr 7.34e-04 | grad 1.59 | tok/s 8083
step    460 | loss 2.4438 | lr 7.34e-04 | grad 4.03 | tok/s 7910
step    470 | loss 2.5931 | lr 7.34e-04 | grad 3.09 | tok/s 8146
step    480 | loss 2.9795 | lr 7.34e-04 | grad 3.70 | tok/s 8161
step    490 | loss 2.4649 | lr 7.34e-04 | grad 3.38 | tok/s 7688
step    500 | loss 2.4696 | lr 7.34e-04 | grad 3.50 | tok/s 8199
step    510 | loss 2.4501 | lr 7.34e-04 | grad 2.41 | tok/s 8313
step    520 | loss 2.4370 | lr 7.34e-04 | grad 2.38 | tok/s 8292
step    530 | loss 2.5367 | lr 7.34e-04 | grad 2.03 | tok/s 8004
step    540 | loss 2.3061 | lr 7.34e-04 | grad 3.89 | tok/s 7993
step    550 | loss 2.1849 | lr 7.34e-04 | grad 3.14 | tok/s 7825
step    560 | loss 2.3322 | lr 7.34e-04 | grad 2.28 | tok/s 7621
step    570 | loss 2.3043 | lr 7.34e-04 | grad 3.50 | tok/s 7805
step    580 | loss 2.1860 | lr 7.34e-04 | grad 2.20 | tok/s 7785
step    590 | loss 2.5429 | lr 7.34e-04 | grad 2.66 | tok/s 8014
step    600 | loss 2.3836 | lr 7.34e-04 | grad 2.03 | tok/s 7728
step    610 | loss 2.2408 | lr 7.34e-04 | grad 3.53 | tok/s 8113
step    620 | loss 2.0981 | lr 7.34e-04 | grad 1.95 | tok/s 7686
step    630 | loss 2.2378 | lr 7.34e-04 | grad 2.86 | tok/s 7742
step    640 | loss 2.4609 | lr 7.34e-04 | grad 2.59 | tok/s 7974
step    650 | loss 2.2988 | lr 7.34e-04 | grad 3.64 | tok/s 8009
step    660 | loss 2.2645 | lr 7.34e-04 | grad 2.22 | tok/s 8045
step    670 | loss 2.5965 | lr 7.34e-04 | grad 7.56 | tok/s 8103
step    680 | loss 2.2640 | lr 7.34e-04 | grad 1.95 | tok/s 7930
step    690 | loss 2.5843 | lr 7.34e-04 | grad 2.52 | tok/s 8190
step    700 | loss 2.3942 | lr 7.34e-04 | grad 1.87 | tok/s 8345
step    710 | loss 2.1925 | lr 7.34e-04 | grad 2.61 | tok/s 7787
step    720 | loss 2.0127 | lr 7.34e-04 | grad 4.09 | tok/s 7671
step    730 | loss 2.2020 | lr 7.34e-04 | grad 2.73 | tok/s 8322
step    740 | loss 2.1653 | lr 7.34e-04 | grad 2.08 | tok/s 8215
step    750 | loss 2.0247 | lr 7.34e-04 | grad 1.62 | tok/s 8337
step    760 | loss 1.8762 | lr 7.34e-04 | grad 2.44 | tok/s 8339
step    770 | loss 1.8526 | lr 7.34e-04 | grad 2.61 | tok/s 8342
step    780 | loss 1.7920 | lr 7.34e-04 | grad 2.62 | tok/s 8330
step    790 | loss 1.8284 | lr 7.34e-04 | grad 1.78 | tok/s 8079
step    800 | loss 2.4968 | lr 7.34e-04 | grad 3.44 | tok/s 8060
step    810 | loss 2.1756 | lr 7.34e-04 | grad 2.08 | tok/s 8020
step    820 | loss 2.1835 | lr 7.34e-04 | grad 3.02 | tok/s 7702
step    830 | loss 2.2631 | lr 7.34e-04 | grad 1.76 | tok/s 8282
step    840 | loss 2.2059 | lr 7.34e-04 | grad 1.99 | tok/s 8349
step    850 | loss 2.2520 | lr 7.34e-04 | grad 2.72 | tok/s 8325
step    860 | loss 2.1605 | lr 7.34e-04 | grad 3.00 | tok/s 8216
step    870 | loss 2.0740 | lr 7.34e-04 | grad 2.09 | tok/s 7918
step    880 | loss 2.2395 | lr 7.34e-04 | grad 2.91 | tok/s 7956
step    890 | loss 2.1961 | lr 7.34e-04 | grad 1.89 | tok/s 8051
step    900 | loss 2.0712 | lr 7.34e-04 | grad 1.70 | tok/s 8060
step    910 | loss 1.9778 | lr 7.34e-04 | grad 2.06 | tok/s 7885
step    920 | loss 2.1647 | lr 7.34e-04 | grad 3.27 | tok/s 8207
step    930 | loss 2.1170 | lr 7.34e-04 | grad 2.91 | tok/s 7830
step    940 | loss 2.0928 | lr 7.34e-04 | grad 1.81 | tok/s 8273
step    950 | loss 2.2628 | lr 7.34e-04 | grad 2.20 | tok/s 8313
step    960 | loss 2.0701 | lr 7.34e-04 | grad 2.59 | tok/s 8320
step    970 | loss 2.1765 | lr 7.34e-04 | grad 2.64 | tok/s 7828
step    980 | loss 2.1162 | lr 7.34e-04 | grad 1.37 | tok/s 8028
step    990 | loss 2.0209 | lr 7.34e-04 | grad 1.74 | tok/s 8161
step   1000 | loss 2.3026 | lr 7.34e-04 | grad 6.28 | tok/s 7850
  >>> saved checkpoint: checkpoint_step_001000_loss_2.3026.pt
step   1010 | loss 2.1594 | lr 7.34e-04 | grad 2.14 | tok/s 2740
step   1020 | loss 1.9340 | lr 7.34e-04 | grad 2.23 | tok/s 7913
step   1030 | loss 1.9472 | lr 7.34e-04 | grad 2.50 | tok/s 8378
step   1040 | loss 1.9348 | lr 7.34e-04 | grad 2.03 | tok/s 7648
step   1050 | loss 2.1970 | lr 7.34e-04 | grad 2.00 | tok/s 8389
step   1060 | loss 2.2871 | lr 7.34e-04 | grad 2.27 | tok/s 8310
step   1070 | loss 2.0746 | lr 7.34e-04 | grad 1.85 | tok/s 7911
step   1080 | loss 1.8292 | lr 7.34e-04 | grad 2.03 | tok/s 7702
step   1090 | loss 1.4842 | lr 7.34e-04 | grad 2.05 | tok/s 8177
step   1100 | loss 2.0282 | lr 7.34e-04 | grad 3.06 | tok/s 8226
step   1110 | loss 1.8620 | lr 7.34e-04 | grad 2.00 | tok/s 8375
step   1120 | loss 1.8280 | lr 7.34e-04 | grad 2.78 | tok/s 8366
step   1130 | loss 1.7566 | lr 7.34e-04 | grad 2.17 | tok/s 8343
step   1140 | loss 1.7692 | lr 7.34e-04 | grad 2.12 | tok/s 8346
step   1150 | loss 1.6813 | lr 7.34e-04 | grad 2.30 | tok/s 8340
step   1160 | loss 1.6561 | lr 7.34e-04 | grad 1.69 | tok/s 8341
step   1170 | loss 1.7810 | lr 7.34e-04 | grad 2.62 | tok/s 8342
step   1180 | loss 1.7474 | lr 7.34e-04 | grad 2.23 | tok/s 8336
step   1190 | loss 1.6068 | lr 7.34e-04 | grad 1.41 | tok/s 8323
step   1200 | loss 1.7067 | lr 7.34e-04 | grad 2.16 | tok/s 8326
step   1210 | loss 1.7065 | lr 7.34e-04 | grad 2.19 | tok/s 8329
step   1220 | loss 1.6195 | lr 7.34e-04 | grad 2.36 | tok/s 8345
step   1230 | loss 1.6547 | lr 7.34e-04 | grad 2.27 | tok/s 8340
step   1240 | loss 2.2473 | lr 7.34e-04 | grad 2.73 | tok/s 8051
step   1250 | loss 2.0436 | lr 7.34e-04 | grad 1.34 | tok/s 7791
step   1260 | loss 1.7588 | lr 7.34e-04 | grad 1.71 | tok/s 7998
step   1270 | loss 2.1317 | lr 7.34e-04 | grad 3.52 | tok/s 7682
step   1280 | loss 1.9229 | lr 7.34e-04 | grad 1.97 | tok/s 8136
step   1290 | loss 2.0025 | lr 7.34e-04 | grad 2.52 | tok/s 8186
step   1300 | loss 1.8355 | lr 7.34e-04 | grad 2.53 | tok/s 7907
step   1310 | loss 1.9310 | lr 7.34e-04 | grad 2.73 | tok/s 8145
step   1320 | loss 2.0893 | lr 7.34e-04 | grad 2.06 | tok/s 8291
step   1330 | loss 1.7631 | lr 7.34e-04 | grad 2.55 | tok/s 7863
step   1340 | loss 2.1378 | lr 7.34e-04 | grad 1.55 | tok/s 7671
step   1350 | loss 2.1029 | lr 7.34e-04 | grad 1.44 | tok/s 7998
step   1360 | loss 1.7841 | lr 7.34e-04 | grad 0.97 | tok/s 7875
step   1370 | loss 2.0538 | lr 7.34e-04 | grad 1.77 | tok/s 8014
step   1380 | loss 1.9307 | lr 7.34e-04 | grad 2.00 | tok/s 7640
step   1390 | loss 1.8264 | lr 7.34e-04 | grad 2.89 | tok/s 7761
step   1400 | loss 1.8606 | lr 7.34e-04 | grad 2.06 | tok/s 8071
step   1410 | loss 1.9836 | lr 7.34e-04 | grad 2.17 | tok/s 7751
step   1420 | loss 1.9928 | lr 7.34e-04 | grad 1.84 | tok/s 8151
step   1430 | loss 1.7000 | lr 7.34e-04 | grad 1.70 | tok/s 7914
step   1440 | loss 1.5361 | lr 7.34e-04 | grad 2.08 | tok/s 8302
step   1450 | loss 1.9381 | lr 7.34e-04 | grad 1.91 | tok/s 7998
step   1460 | loss 1.9677 | lr 7.34e-04 | grad 1.95 | tok/s 7871
step   1470 | loss 2.1096 | lr 7.34e-04 | grad 3.56 | tok/s 8163
step   1480 | loss 2.6346 | lr 7.34e-04 | grad 2.27 | tok/s 8307
step   1490 | loss 1.8566 | lr 7.34e-04 | grad 1.66 | tok/s 8269
step   1500 | loss 1.8280 | lr 7.34e-04 | grad 3.14 | tok/s 8185
step   1510 | loss 1.8733 | lr 7.34e-04 | grad 1.79 | tok/s 8288
step   1520 | loss 1.7779 | lr 7.34e-04 | grad 1.46 | tok/s 8058
step   1530 | loss 1.8830 | lr 7.34e-04 | grad 1.37 | tok/s 7785
step   1540 | loss 1.8731 | lr 7.34e-04 | grad 1.90 | tok/s 8138
step   1550 | loss 1.6898 | lr 7.34e-04 | grad 1.15 | tok/s 7984
step   1560 | loss 1.8923 | lr 7.34e-04 | grad 1.38 | tok/s 8068
step   1570 | loss 1.9228 | lr 7.34e-04 | grad 3.27 | tok/s 8102
step   1580 | loss 2.4793 | lr 7.34e-04 | grad 1.20 | tok/s 8087
step   1590 | loss 1.6830 | lr 7.34e-04 | grad 1.52 | tok/s 7990
step   1600 | loss 1.1334 | lr 7.34e-04 | grad 1.72 | tok/s 8233
step   1610 | loss 1.6434 | lr 7.34e-04 | grad 1.45 | tok/s 7498
step   1620 | loss 2.0338 | lr 7.34e-04 | grad 1.97 | tok/s 7958
step   1630 | loss 1.6007 | lr 7.34e-04 | grad 1.81 | tok/s 8267
step   1640 | loss 1.8661 | lr 7.34e-04 | grad 3.47 | tok/s 7474
step   1650 | loss 1.8559 | lr 7.34e-04 | grad 2.14 | tok/s 7749
step   1660 | loss 1.6201 | lr 7.34e-04 | grad 1.59 | tok/s 8103
step   1670 | loss 2.2260 | lr 7.34e-04 | grad 1.90 | tok/s 7704
step   1680 | loss 1.8389 | lr 7.34e-04 | grad 2.56 | tok/s 7866
step   1690 | loss 1.8653 | lr 7.34e-04 | grad 1.39 | tok/s 8154
step   1700 | loss 1.8072 | lr 7.34e-04 | grad 3.66 | tok/s 7798
step   1710 | loss 1.8793 | lr 7.34e-04 | grad 3.52 | tok/s 8103
step   1720 | loss 1.9123 | lr 7.34e-04 | grad 2.38 | tok/s 8287
step   1730 | loss 1.7963 | lr 7.34e-04 | grad 1.62 | tok/s 8224
step   1740 | loss 1.8586 | lr 7.34e-04 | grad 1.49 | tok/s 8017
step   1750 | loss 1.8434 | lr 7.34e-04 | grad 1.54 | tok/s 7876
step   1760 | loss 1.9080 | lr 7.34e-04 | grad 1.95 | tok/s 8060
step   1770 | loss 1.7783 | lr 7.34e-04 | grad 1.55 | tok/s 7820
step   1780 | loss 1.7582 | lr 7.34e-04 | grad 2.38 | tok/s 8050
step   1790 | loss 1.7493 | lr 7.34e-04 | grad 1.48 | tok/s 7965
step   1800 | loss 1.9441 | lr 7.34e-04 | grad 1.89 | tok/s 7874
step   1810 | loss 1.8096 | lr 7.34e-04 | grad 1.59 | tok/s 7754
step   1820 | loss 1.7748 | lr 7.34e-04 | grad 1.62 | tok/s 8100
step   1830 | loss 1.9063 | lr 7.34e-04 | grad 1.81 | tok/s 7918
step   1840 | loss 1.7468 | lr 7.34e-04 | grad 1.46 | tok/s 7973
step   1850 | loss 1.6538 | lr 7.34e-04 | grad 1.40 | tok/s 8120
step   1860 | loss 1.7335 | lr 7.34e-04 | grad 1.82 | tok/s 7716
step   1870 | loss 1.5284 | lr 7.34e-04 | grad 1.62 | tok/s 8020
step   1880 | loss 1.8686 | lr 7.34e-04 | grad 1.57 | tok/s 7337
step   1890 | loss 1.7174 | lr 7.34e-04 | grad 1.51 | tok/s 8087
step   1900 | loss 1.6820 | lr 7.34e-04 | grad 2.28 | tok/s 7554
step   1910 | loss 1.7011 | lr 7.34e-04 | grad 1.63 | tok/s 8013
step   1920 | loss 1.6958 | lr 7.34e-04 | grad 1.77 | tok/s 8052
step   1930 | loss 1.7060 | lr 7.34e-04 | grad 1.27 | tok/s 7855
step   1940 | loss 2.1435 | lr 7.34e-04 | grad 2.88 | tok/s 8186
step   1950 | loss 2.1943 | lr 7.34e-04 | grad 2.64 | tok/s 8312
step   1960 | loss 1.9887 | lr 7.34e-04 | grad 1.51 | tok/s 8096
step   1970 | loss 1.9196 | lr 7.34e-04 | grad 1.34 | tok/s 7903
step   1980 | loss 1.6824 | lr 7.34e-04 | grad 1.65 | tok/s 7939
step   1990 | loss 2.1389 | lr 7.34e-04 | grad 1.98 | tok/s 8006
step   2000 | loss 1.6738 | lr 7.34e-04 | grad 4.59 | tok/s 8056
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6738.pt
step   2010 | loss 1.5261 | lr 7.34e-04 | grad 2.05 | tok/s 2751
step   2020 | loss 1.2753 | lr 7.34e-04 | grad 2.45 | tok/s 8539
step   2030 | loss 1.7520 | lr 7.34e-04 | grad 1.52 | tok/s 8470
step   2040 | loss 1.6606 | lr 7.34e-04 | grad 1.88 | tok/s 8111
step   2050 | loss 1.9686 | lr 7.34e-04 | grad 1.45 | tok/s 7965
step   2060 | loss 2.0775 | lr 7.34e-04 | grad 2.66 | tok/s 7984
step   2070 | loss 2.2886 | lr 7.34e-04 | grad 2.28 | tok/s 8416
step   2080 | loss 1.8675 | lr 7.34e-04 | grad 1.31 | tok/s 8225
step   2090 | loss 1.8033 | lr 7.34e-04 | grad 1.77 | tok/s 8230
step   2100 | loss 1.8287 | lr 7.34e-04 | grad 1.27 | tok/s 7803
step   2110 | loss 1.0107 | lr 7.34e-04 | grad 0.82 | tok/s 8431
step   2120 | loss 1.6296 | lr 7.34e-04 | grad 1.45 | tok/s 7971
step   2130 | loss 1.7073 | lr 7.34e-04 | grad 1.75 | tok/s 8162
step   2140 | loss 1.5438 | lr 7.34e-04 | grad 1.67 | tok/s 8346
step   2150 | loss 1.4384 | lr 7.34e-04 | grad 1.49 | tok/s 8320
step   2160 | loss 1.4642 | lr 7.34e-04 | grad 1.77 | tok/s 8337
step   2170 | loss 1.4343 | lr 7.34e-04 | grad 1.89 | tok/s 8329
step   2180 | loss 1.4630 | lr 7.34e-04 | grad 1.52 | tok/s 8330
step   2190 | loss 1.4031 | lr 7.34e-04 | grad 1.96 | tok/s 8332
step   2200 | loss 1.3820 | lr 7.34e-04 | grad 1.30 | tok/s 8314
step   2210 | loss 1.3452 | lr 7.34e-04 | grad 1.47 | tok/s 8325
step   2220 | loss 1.6794 | lr 7.34e-04 | grad 1.72 | tok/s 8169
step   2230 | loss 1.6601 | lr 7.34e-04 | grad 2.44 | tok/s 8009
step   2240 | loss 2.0222 | lr 7.34e-04 | grad 3.20 | tok/s 8295
step   2250 | loss 1.9133 | lr 7.34e-04 | grad 1.74 | tok/s 8035
step   2260 | loss 2.3005 | lr 7.34e-04 | grad 1.91 | tok/s 8233
step   2270 | loss 1.6970 | lr 7.34e-04 | grad 1.42 | tok/s 8310
step   2280 | loss 1.8641 | lr 7.34e-04 | grad 1.41 | tok/s 7933
step   2290 | loss 2.1390 | lr 7.34e-04 | grad 1.86 | tok/s 8148
step   2300 | loss 1.8745 | lr 7.34e-04 | grad 1.23 | tok/s 7890
step   2310 | loss 2.1618 | lr 7.34e-04 | grad 1.93 | tok/s 7806
step   2320 | loss 1.7439 | lr 7.34e-04 | grad 1.76 | tok/s 7739
step   2330 | loss 1.8870 | lr 7.34e-04 | grad 1.56 | tok/s 7813
step   2340 | loss 1.6586 | lr 7.34e-04 | grad 1.73 | tok/s 8104
step   2350 | loss 1.5737 | lr 7.34e-04 | grad 1.95 | tok/s 8234
step   2360 | loss 1.9306 | lr 7.34e-04 | grad 2.56 | tok/s 8204
step   2370 | loss 1.9271 | lr 7.34e-04 | grad 2.97 | tok/s 8300
step   2380 | loss 1.4473 | lr 7.34e-04 | grad 3.45 | tok/s 8273
step   2390 | loss 1.2549 | lr 7.34e-04 | grad 1.35 | tok/s 8283
step   2400 | loss 1.4745 | lr 7.34e-04 | grad 2.03 | tok/s 7957
step   2410 | loss 1.7571 | lr 7.34e-04 | grad 1.58 | tok/s 7611
step   2420 | loss 1.5911 | lr 7.34e-04 | grad 1.34 | tok/s 8135
step   2430 | loss 1.6762 | lr 7.34e-04 | grad 2.55 | tok/s 8024
step   2440 | loss 1.7198 | lr 7.34e-04 | grad 1.64 | tok/s 8003
step   2450 | loss 1.4261 | lr 7.34e-04 | grad 0.99 | tok/s 8230
step   2460 | loss 1.4947 | lr 7.34e-04 | grad 1.12 | tok/s 8174
step   2470 | loss 1.4951 | lr 7.34e-04 | grad 1.54 | tok/s 8167
step   2480 | loss 1.7129 | lr 7.34e-04 | grad 2.27 | tok/s 7922
step   2490 | loss 1.8431 | lr 7.34e-04 | grad 2.77 | tok/s 8179
step   2500 | loss 1.4760 | lr 7.34e-04 | grad 1.29 | tok/s 8280
step   2510 | loss 1.8805 | lr 7.34e-04 | grad 2.38 | tok/s 8155
step   2520 | loss 1.5605 | lr 7.34e-04 | grad 2.08 | tok/s 8012
step   2530 | loss 1.6667 | lr 7.34e-04 | grad 1.30 | tok/s 7962
step   2540 | loss 1.3823 | lr 7.34e-04 | grad 1.35 | tok/s 8293
step   2550 | loss 1.8579 | lr 7.34e-04 | grad 1.44 | tok/s 7566
step   2560 | loss 1.5862 | lr 7.34e-04 | grad 1.48 | tok/s 7837
step   2570 | loss 1.6579 | lr 7.34e-04 | grad 1.28 | tok/s 7934
step   2580 | loss 1.7145 | lr 7.34e-04 | grad 1.31 | tok/s 7781
step   2590 | loss 2.0835 | lr 7.34e-04 | grad 2.64 | tok/s 7788
step   2600 | loss 1.6173 | lr 7.34e-04 | grad 1.36 | tok/s 8189
step   2610 | loss 1.7948 | lr 7.34e-04 | grad 1.36 | tok/s 8032
step   2620 | loss 1.5890 | lr 7.34e-04 | grad 1.95 | tok/s 8199
step   2630 | loss 1.8677 | lr 7.34e-04 | grad 1.23 | tok/s 7976
step   2640 | loss 1.8131 | lr 7.34e-04 | grad 1.68 | tok/s 8115
step   2650 | loss 1.5652 | lr 7.34e-04 | grad 1.35 | tok/s 7993
step   2660 | loss 1.6807 | lr 7.34e-04 | grad 1.72 | tok/s 7660
step   2670 | loss 1.9480 | lr 7.34e-04 | grad 2.41 | tok/s 7950
step   2680 | loss 1.5781 | lr 7.34e-04 | grad 1.63 | tok/s 8218
step   2690 | loss 1.7166 | lr 7.34e-04 | grad 1.05 | tok/s 7904
step   2700 | loss 1.8548 | lr 7.34e-04 | grad 1.64 | tok/s 7664
step   2710 | loss 1.6185 | lr 7.34e-04 | grad 1.94 | tok/s 7655
step   2720 | loss 1.4584 | lr 7.34e-04 | grad 1.24 | tok/s 8191
step   2730 | loss 2.0832 | lr 7.34e-04 | grad 1.77 | tok/s 8070
step   2740 | loss 1.8299 | lr 7.34e-04 | grad 2.06 | tok/s 8081
step   2750 | loss 1.5674 | lr 7.34e-04 | grad 1.32 | tok/s 7637
step   2760 | loss 1.6857 | lr 7.34e-04 | grad 1.32 | tok/s 7966
step   2770 | loss 1.4212 | lr 7.34e-04 | grad 1.80 | tok/s 8172
step   2780 | loss 2.2122 | lr 7.34e-04 | grad 1.30 | tok/s 7612
step   2790 | loss 1.4005 | lr 7.34e-04 | grad 1.26 | tok/s 8118
step   2800 | loss 1.5673 | lr 7.34e-04 | grad 1.90 | tok/s 7702
step   2810 | loss 1.6553 | lr 7.34e-04 | grad 1.53 | tok/s 7678
step   2820 | loss 1.3940 | lr 7.34e-04 | grad 2.11 | tok/s 8277
step   2830 | loss 1.2986 | lr 7.34e-04 | grad 1.39 | tok/s 8179
step   2840 | loss 2.0341 | lr 7.34e-04 | grad 2.55 | tok/s 7851
step   2850 | loss 1.8876 | lr 7.34e-04 | grad 1.28 | tok/s 7917
step   2860 | loss 1.6569 | lr 7.34e-04 | grad 1.36 | tok/s 7942
step   2870 | loss 1.6846 | lr 7.34e-04 | grad 1.30 | tok/s 8188
step   2880 | loss 1.6567 | lr 7.34e-04 | grad 1.73 | tok/s 8160
step   2890 | loss 1.7162 | lr 7.34e-04 | grad 4.19 | tok/s 8024
step   2900 | loss 1.6177 | lr 7.34e-04 | grad 1.97 | tok/s 7743
step   2910 | loss 1.9084 | lr 7.34e-04 | grad 2.69 | tok/s 7945
step   2920 | loss 1.6306 | lr 7.34e-04 | grad 1.52 | tok/s 7916
step   2930 | loss 1.4967 | lr 7.34e-04 | grad 1.12 | tok/s 7498
step   2940 | loss 1.5124 | lr 7.34e-04 | grad 1.23 | tok/s 8079
step   2950 | loss 1.5838 | lr 7.34e-04 | grad 1.45 | tok/s 8062
step   2960 | loss 1.7315 | lr 7.34e-04 | grad 3.36 | tok/s 7831
step   2970 | loss 2.3599 | lr 7.34e-04 | grad 11.62 | tok/s 8126
step   2980 | loss 2.0081 | lr 7.34e-04 | grad 1.38 | tok/s 8105
step   2990 | loss 1.5693 | lr 7.34e-04 | grad 1.29 | tok/s 7967
step   3000 | loss 1.3681 | lr 7.34e-04 | grad 1.84 | tok/s 8158
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3681.pt
step   3010 | loss 1.6524 | lr 7.34e-04 | grad 1.98 | tok/s 2716
step   3020 | loss 1.6782 | lr 7.34e-04 | grad 1.29 | tok/s 8215
step   3030 | loss 1.6266 | lr 7.34e-04 | grad 1.34 | tok/s 8226
step   3040 | loss 1.5748 | lr 7.34e-04 | grad 1.56 | tok/s 8292
step   3050 | loss 1.8350 | lr 7.34e-04 | grad 2.86 | tok/s 8243
step   3060 | loss 1.5696 | lr 7.34e-04 | grad 1.19 | tok/s 8230
step   3070 | loss 1.6641 | lr 7.34e-04 | grad 1.34 | tok/s 8228
step   3080 | loss 1.7309 | lr 7.34e-04 | grad 1.59 | tok/s 7888
step   3090 | loss 1.5241 | lr 7.34e-04 | grad 1.11 | tok/s 8256
step   3100 | loss 1.1031 | lr 7.34e-04 | grad 1.28 | tok/s 8332
step   3110 | loss 1.6635 | lr 7.34e-04 | grad 6.44 | tok/s 7882
step   3120 | loss 1.4268 | lr 7.34e-04 | grad 1.22 | tok/s 8336
step   3130 | loss 1.3480 | lr 7.34e-04 | grad 0.85 | tok/s 8334
step   3140 | loss 1.5159 | lr 7.34e-04 | grad 1.47 | tok/s 7958
step   3150 | loss 1.7789 | lr 7.34e-04 | grad 1.39 | tok/s 7817
step   3160 | loss 1.6121 | lr 7.34e-04 | grad 2.48 | tok/s 7848
step   3170 | loss 1.3796 | lr 7.34e-04 | grad 1.96 | tok/s 8197
step   3180 | loss 1.3727 | lr 7.34e-04 | grad 3.39 | tok/s 8324
step   3190 | loss 1.6968 | lr 7.34e-04 | grad 1.47 | tok/s 8023
step   3200 | loss 2.4133 | lr 7.34e-04 | grad 1.41 | tok/s 8095
step   3210 | loss 2.2195 | lr 7.34e-04 | grad 2.20 | tok/s 8319
step   3220 | loss 1.9833 | lr 7.34e-04 | grad 2.55 | tok/s 8311
step   3230 | loss 1.8549 | lr 7.34e-04 | grad 1.79 | tok/s 8293
step   3240 | loss 1.7789 | lr 7.34e-04 | grad 1.78 | tok/s 8311
step   3250 | loss 1.6964 | lr 7.34e-04 | grad 1.93 | tok/s 8297
step   3260 | loss 1.6507 | lr 7.34e-04 | grad 1.95 | tok/s 8286
step   3270 | loss 1.6006 | lr 7.34e-04 | grad 2.28 | tok/s 8279
step   3280 | loss 1.5569 | lr 7.34e-04 | grad 1.95 | tok/s 8289
step   3290 | loss 1.5415 | lr 7.34e-04 | grad 2.36 | tok/s 8283
step   3300 | loss 1.5290 | lr 7.34e-04 | grad 2.62 | tok/s 8292
step   3310 | loss 1.5542 | lr 7.34e-04 | grad 1.72 | tok/s 8284
step   3320 | loss 1.9191 | lr 7.34e-04 | grad 2.06 | tok/s 7763
step   3330 | loss 1.6433 | lr 7.34e-04 | grad 1.23 | tok/s 8097
step   3340 | loss 1.6089 | lr 7.34e-04 | grad 1.34 | tok/s 7813
step   3350 | loss 1.5981 | lr 7.34e-04 | grad 1.46 | tok/s 7715
step   3360 | loss 1.7683 | lr 7.34e-04 | grad 2.61 | tok/s 7830
step   3370 | loss 1.6467 | lr 7.34e-04 | grad 1.34 | tok/s 7881
step   3380 | loss 1.3569 | lr 7.34e-04 | grad 3.77 | tok/s 8252
step   3390 | loss 1.2815 | lr 7.34e-04 | grad 1.21 | tok/s 8275
step   3400 | loss 1.6090 | lr 7.34e-04 | grad 1.42 | tok/s 7923
step   3410 | loss 1.6290 | lr 7.34e-04 | grad 1.21 | tok/s 7927
step   3420 | loss 1.6703 | lr 7.34e-04 | grad 1.05 | tok/s 7762
step   3430 | loss 1.5086 | lr 7.34e-04 | grad 1.31 | tok/s 8135
step   3440 | loss 1.8799 | lr 7.34e-04 | grad 2.36 | tok/s 8061
step   3450 | loss 1.5441 | lr 7.34e-04 | grad 1.19 | tok/s 8153
step   3460 | loss 1.6175 | lr 7.34e-04 | grad 1.32 | tok/s 8120
step   3470 | loss 1.4538 | lr 7.34e-04 | grad 1.12 | tok/s 7644
step   3480 | loss 1.3679 | lr 7.34e-04 | grad 1.05 | tok/s 8271
step   3490 | loss 1.5112 | lr 7.34e-04 | grad 1.30 | tok/s 7728
step   3500 | loss 1.6670 | lr 7.34e-04 | grad 1.29 | tok/s 8026
step   3510 | loss 1.9210 | lr 7.34e-04 | grad 4.53 | tok/s 8112
step   3520 | loss 1.8150 | lr 7.34e-04 | grad 0.99 | tok/s 8041
step   3530 | loss 2.0874 | lr 7.34e-04 | grad 5.72 | tok/s 7776

Training complete! Final step: 3539
