Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_185612/eval_50/level42_100m_20260202_215809
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 216,488,064 parameters
Using schedule-free AdamW (lr=0.00022542372209235551)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 5.0240 | lr 2.25e-04 | grad 15.31 | tok/s 17031
step     20 | loss 4.6912 | lr 2.25e-04 | grad 7.84 | tok/s 34891
step     30 | loss 4.7072 | lr 2.25e-04 | grad 5.84 | tok/s 35287
step     40 | loss 3.7511 | lr 2.25e-04 | grad 5.50 | tok/s 34614
step     50 | loss 3.0119 | lr 2.25e-04 | grad 3.52 | tok/s 34992
step     60 | loss 3.2521 | lr 2.25e-04 | grad 6.72 | tok/s 34100
step     70 | loss 2.9116 | lr 2.25e-04 | grad 5.34 | tok/s 34661
step     80 | loss 2.8266 | lr 2.25e-04 | grad 2.39 | tok/s 34504
step     90 | loss 2.7941 | lr 2.25e-04 | grad 2.08 | tok/s 33381
step    100 | loss 2.3830 | lr 2.25e-04 | grad 2.38 | tok/s 34769
step    110 | loss 2.6897 | lr 2.25e-04 | grad 2.27 | tok/s 33682
step    120 | loss 2.5778 | lr 2.25e-04 | grad 2.22 | tok/s 33929
step    130 | loss 2.3967 | lr 2.25e-04 | grad 2.92 | tok/s 34747
step    140 | loss 2.2046 | lr 2.25e-04 | grad 2.22 | tok/s 33095
step    150 | loss 2.2701 | lr 2.25e-04 | grad 1.32 | tok/s 33476
step    160 | loss 2.2502 | lr 2.25e-04 | grad 1.72 | tok/s 33461
step    170 | loss 2.4289 | lr 2.25e-04 | grad 2.81 | tok/s 34033
step    180 | loss 2.1841 | lr 2.25e-04 | grad 1.74 | tok/s 34218
step    190 | loss 2.0012 | lr 2.25e-04 | grad 1.59 | tok/s 35358
step    200 | loss 2.1306 | lr 2.25e-04 | grad 1.45 | tok/s 34083
step    210 | loss 2.2573 | lr 2.25e-04 | grad 1.62 | tok/s 34851
step    220 | loss 2.1607 | lr 2.25e-04 | grad 1.70 | tok/s 34100
step    230 | loss 2.0460 | lr 2.25e-04 | grad 1.74 | tok/s 33921
step    240 | loss 2.1650 | lr 2.25e-04 | grad 1.96 | tok/s 34774
step    250 | loss 2.1903 | lr 2.25e-04 | grad 1.43 | tok/s 33919
step    260 | loss 1.9927 | lr 2.25e-04 | grad 1.80 | tok/s 33211
step    270 | loss 2.0377 | lr 2.25e-04 | grad 3.52 | tok/s 33955
step    280 | loss 1.8759 | lr 2.25e-04 | grad 1.85 | tok/s 35043
step    290 | loss 1.7627 | lr 2.25e-04 | grad 2.44 | tok/s 35514
step    300 | loss 1.7894 | lr 2.25e-04 | grad 1.79 | tok/s 35363
step    310 | loss 1.8489 | lr 2.25e-04 | grad 2.39 | tok/s 35160
step    320 | loss 1.9961 | lr 2.25e-04 | grad 1.38 | tok/s 33606
step    330 | loss 2.0328 | lr 2.25e-04 | grad 2.61 | tok/s 34590
step    340 | loss 1.9783 | lr 2.25e-04 | grad 2.28 | tok/s 33494
step    350 | loss 1.9628 | lr 2.25e-04 | grad 1.73 | tok/s 33456
step    360 | loss 1.8925 | lr 2.25e-04 | grad 2.02 | tok/s 34540
step    370 | loss 2.3101 | lr 2.25e-04 | grad 2.98 | tok/s 34279
step    380 | loss 1.9275 | lr 2.25e-04 | grad 1.80 | tok/s 34986
step    390 | loss 1.8872 | lr 2.25e-04 | grad 1.35 | tok/s 34228
step    400 | loss 1.9024 | lr 2.25e-04 | grad 1.59 | tok/s 34524
step    410 | loss 1.8888 | lr 2.25e-04 | grad 1.73 | tok/s 33375
step    420 | loss 1.9701 | lr 2.25e-04 | grad 1.88 | tok/s 33591
step    430 | loss 2.0902 | lr 2.25e-04 | grad 4.16 | tok/s 34486
step    440 | loss 1.9343 | lr 2.25e-04 | grad 1.38 | tok/s 34045
step    450 | loss 1.8495 | lr 2.25e-04 | grad 1.40 | tok/s 34169
step    460 | loss 1.8878 | lr 2.25e-04 | grad 2.22 | tok/s 34205
step    470 | loss 1.7733 | lr 2.25e-04 | grad 2.17 | tok/s 32999
step    480 | loss 1.7438 | lr 2.25e-04 | grad 1.42 | tok/s 33999
step    490 | loss 2.3457 | lr 2.25e-04 | grad 2.62 | tok/s 34771
step    500 | loss 1.8110 | lr 2.25e-04 | grad 5.12 | tok/s 34069
step    510 | loss 1.6452 | lr 2.25e-04 | grad 2.09 | tok/s 34991
step    520 | loss 2.2313 | lr 2.25e-04 | grad 2.55 | tok/s 34047
step    530 | loss 1.6673 | lr 2.25e-04 | grad 1.39 | tok/s 34721
step    540 | loss 1.6758 | lr 2.25e-04 | grad 1.64 | tok/s 34933
step    550 | loss 1.5217 | lr 2.25e-04 | grad 1.80 | tok/s 35544
step    560 | loss 1.6785 | lr 2.25e-04 | grad 4.84 | tok/s 35090
step    570 | loss 2.1328 | lr 2.25e-04 | grad 1.89 | tok/s 35244
step    580 | loss 2.2407 | lr 2.25e-04 | grad 3.31 | tok/s 33699
step    590 | loss 1.7255 | lr 2.25e-04 | grad 2.12 | tok/s 34288
step    600 | loss 1.8099 | lr 2.25e-04 | grad 1.85 | tok/s 35491
step    610 | loss 1.6959 | lr 2.25e-04 | grad 1.88 | tok/s 33979
step    620 | loss 1.6365 | lr 2.25e-04 | grad 1.85 | tok/s 35008
step    630 | loss 1.9418 | lr 2.25e-04 | grad 1.73 | tok/s 34961
step    640 | loss 1.7150 | lr 2.25e-04 | grad 2.00 | tok/s 34110
step    650 | loss 1.9188 | lr 2.25e-04 | grad 9.81 | tok/s 33704
step    660 | loss 1.8480 | lr 2.25e-04 | grad 2.38 | tok/s 34662
step    670 | loss 1.8408 | lr 2.25e-04 | grad 2.20 | tok/s 34049
step    680 | loss 1.7889 | lr 2.25e-04 | grad 2.47 | tok/s 33832
step    690 | loss 1.8736 | lr 2.25e-04 | grad 2.94 | tok/s 34110
step    700 | loss 1.7821 | lr 2.25e-04 | grad 1.80 | tok/s 34474
step    710 | loss 1.8280 | lr 2.25e-04 | grad 4.22 | tok/s 34145
step    720 | loss 1.8550 | lr 2.25e-04 | grad 2.02 | tok/s 34373
step    730 | loss 1.8416 | lr 2.25e-04 | grad 3.78 | tok/s 34256
step    740 | loss 1.6286 | lr 2.25e-04 | grad 1.63 | tok/s 33750
step    750 | loss 1.8870 | lr 2.25e-04 | grad 1.73 | tok/s 34292
step    760 | loss 1.6712 | lr 2.25e-04 | grad 1.48 | tok/s 34235
step    770 | loss 1.7338 | lr 2.25e-04 | grad 1.76 | tok/s 34807
step    780 | loss 1.6265 | lr 2.25e-04 | grad 1.73 | tok/s 35145
step    790 | loss 1.6506 | lr 2.25e-04 | grad 3.72 | tok/s 34533
step    800 | loss 1.6236 | lr 2.25e-04 | grad 1.59 | tok/s 34166
step    810 | loss 2.3638 | lr 2.25e-04 | grad 2.91 | tok/s 35326
step    820 | loss 2.0271 | lr 2.25e-04 | grad 2.42 | tok/s 35569
step    830 | loss 1.8193 | lr 2.25e-04 | grad 2.38 | tok/s 35608
step    840 | loss 1.7870 | lr 2.25e-04 | grad 1.45 | tok/s 33943
step    850 | loss 1.6097 | lr 2.25e-04 | grad 1.43 | tok/s 34355
step    860 | loss 1.6349 | lr 2.25e-04 | grad 2.12 | tok/s 34234
step    870 | loss 1.7135 | lr 2.25e-04 | grad 1.45 | tok/s 34892
step    880 | loss 1.6289 | lr 2.25e-04 | grad 3.09 | tok/s 33812
step    890 | loss 1.9887 | lr 2.25e-04 | grad 1.60 | tok/s 33684
step    900 | loss 1.5940 | lr 2.25e-04 | grad 1.97 | tok/s 33687
step    910 | loss 1.6794 | lr 2.25e-04 | grad 1.27 | tok/s 34081
step    920 | loss 1.6594 | lr 2.25e-04 | grad 1.94 | tok/s 33832
step    930 | loss 1.7020 | lr 2.25e-04 | grad 1.84 | tok/s 33804
step    940 | loss 1.6802 | lr 2.25e-04 | grad 1.83 | tok/s 34632
step    950 | loss 1.4571 | lr 2.25e-04 | grad 1.87 | tok/s 35680
step    960 | loss 1.3869 | lr 2.25e-04 | grad 1.51 | tok/s 35842
step    970 | loss 1.6171 | lr 2.25e-04 | grad 1.68 | tok/s 34347
step    980 | loss 1.7573 | lr 2.25e-04 | grad 2.22 | tok/s 33682
step    990 | loss 1.7559 | lr 2.25e-04 | grad 3.17 | tok/s 34205
step   1000 | loss 1.6523 | lr 2.25e-04 | grad 2.02 | tok/s 34919
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6523.pt
step   1010 | loss 1.5892 | lr 2.25e-04 | grad 1.45 | tok/s 24281
step   1020 | loss 1.8091 | lr 2.25e-04 | grad 1.76 | tok/s 34015
step   1030 | loss 1.7591 | lr 2.25e-04 | grad 2.12 | tok/s 33882
step   1040 | loss 1.4001 | lr 2.25e-04 | grad 1.47 | tok/s 33907
step   1050 | loss 2.0464 | lr 2.25e-04 | grad 1.37 | tok/s 34806
step   1060 | loss 2.1418 | lr 2.25e-04 | grad 2.45 | tok/s 34327
step   1070 | loss 1.7137 | lr 2.25e-04 | grad 2.06 | tok/s 33662
step   1080 | loss 1.8653 | lr 2.25e-04 | grad 1.15 | tok/s 34586
step   1090 | loss 1.6373 | lr 2.25e-04 | grad 4.22 | tok/s 35199
step   1100 | loss 1.6157 | lr 2.25e-04 | grad 2.03 | tok/s 34872
step   1110 | loss 1.6816 | lr 2.25e-04 | grad 1.50 | tok/s 33563
step   1120 | loss 1.6723 | lr 2.25e-04 | grad 1.88 | tok/s 34213
step   1130 | loss 1.7212 | lr 2.25e-04 | grad 3.16 | tok/s 33997
step   1140 | loss 1.6709 | lr 2.25e-04 | grad 3.84 | tok/s 33721
step   1150 | loss 1.7383 | lr 2.25e-04 | grad 1.96 | tok/s 33359
step   1160 | loss 1.5311 | lr 2.25e-04 | grad 1.76 | tok/s 35200
step   1170 | loss 1.4994 | lr 2.25e-04 | grad 1.38 | tok/s 35475
step   1180 | loss 1.4294 | lr 2.25e-04 | grad 1.70 | tok/s 35692
step   1190 | loss 1.3815 | lr 2.25e-04 | grad 1.67 | tok/s 35375
step   1200 | loss 1.3677 | lr 2.25e-04 | grad 1.59 | tok/s 35504
step   1210 | loss 1.4676 | lr 2.25e-04 | grad 0.96 | tok/s 34964
step   1220 | loss 1.5522 | lr 2.25e-04 | grad 1.35 | tok/s 33590
step   1230 | loss 1.6375 | lr 2.25e-04 | grad 1.42 | tok/s 34648
step   1240 | loss 1.6374 | lr 2.25e-04 | grad 3.31 | tok/s 34227
step   1250 | loss 1.8107 | lr 2.25e-04 | grad 1.66 | tok/s 34034
step   1260 | loss 1.6536 | lr 2.25e-04 | grad 1.88 | tok/s 34154
step   1270 | loss 1.6739 | lr 2.25e-04 | grad 2.23 | tok/s 33608
step   1280 | loss 1.6320 | lr 2.25e-04 | grad 1.59 | tok/s 33809
step   1290 | loss 1.7175 | lr 2.25e-04 | grad 1.36 | tok/s 33623
step   1300 | loss 1.6147 | lr 2.25e-04 | grad 2.23 | tok/s 33764
step   1310 | loss 1.6625 | lr 2.25e-04 | grad 1.68 | tok/s 34446
step   1320 | loss 1.4820 | lr 2.25e-04 | grad 1.34 | tok/s 33954
step   1330 | loss 1.4780 | lr 2.25e-04 | grad 1.48 | tok/s 34703
step   1340 | loss 1.5905 | lr 2.25e-04 | grad 1.35 | tok/s 33994
step   1350 | loss 1.5383 | lr 2.25e-04 | grad 2.00 | tok/s 33926
step   1360 | loss 1.7435 | lr 2.25e-04 | grad 1.51 | tok/s 33805
step   1370 | loss 1.5751 | lr 2.25e-04 | grad 1.89 | tok/s 33778
step   1380 | loss 1.5454 | lr 2.25e-04 | grad 1.39 | tok/s 34779
step   1390 | loss 1.6224 | lr 2.25e-04 | grad 1.88 | tok/s 34703
step   1400 | loss 1.6181 | lr 2.25e-04 | grad 3.23 | tok/s 33388
step   1410 | loss 1.5564 | lr 2.25e-04 | grad 1.32 | tok/s 32903
step   1420 | loss 1.4050 | lr 2.25e-04 | grad 1.44 | tok/s 34035
step   1430 | loss 1.3963 | lr 2.25e-04 | grad 1.29 | tok/s 34945
step   1440 | loss 1.6051 | lr 2.25e-04 | grad 2.16 | tok/s 33428
step   1450 | loss 1.6424 | lr 2.25e-04 | grad 1.91 | tok/s 34003
step   1460 | loss 1.5118 | lr 2.25e-04 | grad 3.83 | tok/s 34345
step   1470 | loss 1.5866 | lr 2.25e-04 | grad 2.42 | tok/s 33962
step   1480 | loss 1.8333 | lr 2.25e-04 | grad 2.55 | tok/s 33654
step   1490 | loss 1.5805 | lr 2.25e-04 | grad 1.86 | tok/s 34721
step   1500 | loss 1.6062 | lr 2.25e-04 | grad 1.73 | tok/s 34474
step   1510 | loss 1.5515 | lr 2.25e-04 | grad 1.38 | tok/s 34168
step   1520 | loss 1.5250 | lr 2.25e-04 | grad 1.27 | tok/s 33781
step   1530 | loss 1.4897 | lr 2.25e-04 | grad 4.00 | tok/s 35015
step   1540 | loss 2.0427 | lr 2.25e-04 | grad 2.06 | tok/s 34039
step   1550 | loss 1.5512 | lr 2.25e-04 | grad 1.51 | tok/s 33704
step   1560 | loss 1.6669 | lr 2.25e-04 | grad 2.00 | tok/s 34573
step   1570 | loss 1.4476 | lr 2.25e-04 | grad 1.67 | tok/s 33846
step   1580 | loss 1.5920 | lr 2.25e-04 | grad 1.52 | tok/s 33660
step   1590 | loss 1.3992 | lr 2.25e-04 | grad 1.20 | tok/s 35181
step   1600 | loss 1.5780 | lr 2.25e-04 | grad 2.09 | tok/s 34484
step   1610 | loss 1.5324 | lr 2.25e-04 | grad 1.35 | tok/s 34895
step   1620 | loss 1.4904 | lr 2.25e-04 | grad 1.51 | tok/s 33413
step   1630 | loss 1.5497 | lr 2.25e-04 | grad 3.28 | tok/s 33691
step   1640 | loss 1.5656 | lr 2.25e-04 | grad 2.42 | tok/s 33749
step   1650 | loss 1.5631 | lr 2.25e-04 | grad 2.67 | tok/s 34945
step   1660 | loss 1.8397 | lr 2.25e-04 | grad 2.55 | tok/s 34406
step   1670 | loss 1.4285 | lr 2.25e-04 | grad 1.87 | tok/s 34069
step   1680 | loss 1.6919 | lr 2.25e-04 | grad 1.96 | tok/s 34417
step   1690 | loss 1.6345 | lr 2.25e-04 | grad 1.66 | tok/s 34171
step   1700 | loss 1.5347 | lr 2.25e-04 | grad 2.59 | tok/s 33933
step   1710 | loss 1.6517 | lr 2.25e-04 | grad 1.34 | tok/s 33968
step   1720 | loss 1.5596 | lr 2.25e-04 | grad 1.55 | tok/s 33922
step   1730 | loss 1.5420 | lr 2.25e-04 | grad 2.09 | tok/s 33617
step   1740 | loss 1.6646 | lr 2.25e-04 | grad 1.62 | tok/s 33905
step   1750 | loss 1.6945 | lr 2.25e-04 | grad 2.25 | tok/s 33741
step   1760 | loss 1.5250 | lr 2.25e-04 | grad 2.52 | tok/s 33746
step   1770 | loss 1.6764 | lr 2.25e-04 | grad 2.27 | tok/s 33579
step   1780 | loss 1.5237 | lr 2.25e-04 | grad 2.72 | tok/s 34482
step   1790 | loss 1.4372 | lr 2.25e-04 | grad 5.06 | tok/s 34720
step   1800 | loss 1.4483 | lr 2.25e-04 | grad 1.16 | tok/s 33551
step   1810 | loss 1.5249 | lr 2.25e-04 | grad 1.23 | tok/s 33543
step   1820 | loss 1.6136 | lr 2.25e-04 | grad 1.57 | tok/s 33798
step   1830 | loss 1.6307 | lr 2.25e-04 | grad 2.36 | tok/s 33566
step   1840 | loss 1.4500 | lr 2.25e-04 | grad 1.76 | tok/s 34351
step   1850 | loss 1.4680 | lr 2.25e-04 | grad 1.87 | tok/s 34856
step   1860 | loss 1.5237 | lr 2.25e-04 | grad 1.30 | tok/s 34576
step   1870 | loss 1.6601 | lr 2.25e-04 | grad 2.75 | tok/s 34026
step   1880 | loss 1.4987 | lr 2.25e-04 | grad 1.59 | tok/s 34408
step   1890 | loss 1.6322 | lr 2.25e-04 | grad 1.47 | tok/s 34036
step   1900 | loss 1.3824 | lr 2.25e-04 | grad 2.42 | tok/s 34614
step   1910 | loss 1.4480 | lr 2.25e-04 | grad 1.35 | tok/s 34574
step   1920 | loss 1.5351 | lr 2.25e-04 | grad 1.58 | tok/s 35279
step   1930 | loss 1.4882 | lr 2.25e-04 | grad 2.11 | tok/s 34462
step   1940 | loss 1.6515 | lr 2.25e-04 | grad 2.50 | tok/s 34600
step   1950 | loss 1.4160 | lr 2.25e-04 | grad 1.87 | tok/s 33879
step   1960 | loss 1.6807 | lr 2.25e-04 | grad 4.38 | tok/s 34498
step   1970 | loss 1.4636 | lr 2.25e-04 | grad 2.66 | tok/s 33918
step   1980 | loss 1.4565 | lr 2.25e-04 | grad 1.73 | tok/s 34815
step   1990 | loss 1.2215 | lr 2.25e-04 | grad 1.55 | tok/s 35426
step   2000 | loss 1.2863 | lr 2.25e-04 | grad 4.84 | tok/s 35544
  >>> saved checkpoint: checkpoint_step_002000_loss_1.2863.pt
step   2010 | loss 1.3872 | lr 2.25e-04 | grad 1.25 | tok/s 25610
step   2020 | loss 1.2836 | lr 2.25e-04 | grad 1.56 | tok/s 35013
step   2030 | loss 1.5280 | lr 2.25e-04 | grad 2.00 | tok/s 33532
step   2040 | loss 1.5181 | lr 2.25e-04 | grad 1.40 | tok/s 34538
step   2050 | loss 1.5723 | lr 2.25e-04 | grad 3.08 | tok/s 34266
step   2060 | loss 1.5713 | lr 2.25e-04 | grad 1.33 | tok/s 34245
step   2070 | loss 1.4762 | lr 2.25e-04 | grad 1.55 | tok/s 33810
step   2080 | loss 1.3646 | lr 2.25e-04 | grad 1.72 | tok/s 34375
step   2090 | loss 1.4123 | lr 2.25e-04 | grad 2.09 | tok/s 33829
step   2100 | loss 1.2625 | lr 2.25e-04 | grad 2.23 | tok/s 34427
step   2110 | loss 1.5720 | lr 2.25e-04 | grad 1.71 | tok/s 33894
step   2120 | loss 1.6140 | lr 2.25e-04 | grad 2.70 | tok/s 34235
step   2130 | loss 1.5663 | lr 2.25e-04 | grad 3.12 | tok/s 33962
step   2140 | loss 1.6702 | lr 2.25e-04 | grad 1.84 | tok/s 34308
step   2150 | loss 1.4806 | lr 2.25e-04 | grad 2.05 | tok/s 34234
step   2160 | loss 1.6859 | lr 2.25e-04 | grad 2.20 | tok/s 34885
step   2170 | loss 1.2963 | lr 2.25e-04 | grad 1.55 | tok/s 34977
step   2180 | loss 1.2550 | lr 2.25e-04 | grad 1.03 | tok/s 35559
step   2190 | loss 1.2496 | lr 2.25e-04 | grad 1.12 | tok/s 35567
step   2200 | loss 1.3794 | lr 2.25e-04 | grad 5.09 | tok/s 34902
step   2210 | loss 1.5041 | lr 2.25e-04 | grad 3.02 | tok/s 34785
step   2220 | loss 1.5309 | lr 2.25e-04 | grad 1.91 | tok/s 35036
step   2230 | loss 1.5959 | lr 2.25e-04 | grad 1.45 | tok/s 34779
step   2240 | loss 1.4318 | lr 2.25e-04 | grad 1.39 | tok/s 34139
step   2250 | loss 1.5662 | lr 2.25e-04 | grad 3.06 | tok/s 34297
step   2260 | loss 1.4694 | lr 2.25e-04 | grad 1.73 | tok/s 33736
step   2270 | loss 1.4702 | lr 2.25e-04 | grad 1.45 | tok/s 33487
step   2280 | loss 1.4604 | lr 2.25e-04 | grad 1.87 | tok/s 34763
step   2290 | loss 1.4216 | lr 2.25e-04 | grad 1.41 | tok/s 35582
step   2300 | loss 1.3491 | lr 2.25e-04 | grad 1.32 | tok/s 35485
step   2310 | loss 1.4326 | lr 2.25e-04 | grad 1.51 | tok/s 35100
step   2320 | loss 1.5534 | lr 2.25e-04 | grad 1.48 | tok/s 34343
step   2330 | loss 1.8619 | lr 2.25e-04 | grad 3.16 | tok/s 34409
step   2340 | loss 1.5507 | lr 2.25e-04 | grad 1.98 | tok/s 34487
step   2350 | loss 1.4394 | lr 2.25e-04 | grad 1.70 | tok/s 34183
step   2360 | loss 1.4199 | lr 2.25e-04 | grad 2.02 | tok/s 33943
step   2370 | loss 1.5531 | lr 2.25e-04 | grad 3.17 | tok/s 33945
step   2380 | loss 1.4552 | lr 2.25e-04 | grad 2.28 | tok/s 33811
step   2390 | loss 1.5568 | lr 2.25e-04 | grad 1.59 | tok/s 34424
step   2400 | loss 1.4547 | lr 2.25e-04 | grad 2.22 | tok/s 33499
step   2410 | loss 1.6022 | lr 2.25e-04 | grad 1.65 | tok/s 34375
step   2420 | loss 1.3687 | lr 2.25e-04 | grad 2.64 | tok/s 34207
step   2430 | loss 1.5307 | lr 2.25e-04 | grad 3.92 | tok/s 34640
step   2440 | loss 1.3354 | lr 2.25e-04 | grad 2.89 | tok/s 35588
step   2450 | loss 1.4171 | lr 2.25e-04 | grad 1.43 | tok/s 34374
step   2460 | loss 1.3947 | lr 2.25e-04 | grad 1.55 | tok/s 33803
step   2470 | loss 1.4791 | lr 2.25e-04 | grad 2.16 | tok/s 34525
step   2480 | loss 1.5036 | lr 2.25e-04 | grad 1.54 | tok/s 34599
step   2490 | loss 1.6822 | lr 2.25e-04 | grad 2.39 | tok/s 33965
step   2500 | loss 1.5463 | lr 2.25e-04 | grad 2.34 | tok/s 33516
step   2510 | loss 1.5146 | lr 2.25e-04 | grad 1.74 | tok/s 33652
step   2520 | loss 1.8889 | lr 2.25e-04 | grad 7.12 | tok/s 34169
step   2530 | loss 1.5710 | lr 2.25e-04 | grad 2.53 | tok/s 34769
step   2540 | loss 1.5276 | lr 2.25e-04 | grad 3.92 | tok/s 33879
step   2550 | loss 1.4964 | lr 2.25e-04 | grad 1.54 | tok/s 34467
step   2560 | loss 1.3999 | lr 2.25e-04 | grad 2.31 | tok/s 33870
step   2570 | loss 1.5341 | lr 2.25e-04 | grad 1.38 | tok/s 34916
step   2580 | loss 1.4407 | lr 2.25e-04 | grad 1.52 | tok/s 34888
step   2590 | loss 1.3303 | lr 2.25e-04 | grad 1.58 | tok/s 35742
step   2600 | loss 1.4456 | lr 2.25e-04 | grad 2.08 | tok/s 34571
step   2610 | loss 1.4741 | lr 2.25e-04 | grad 1.65 | tok/s 33889
step   2620 | loss 1.4726 | lr 2.25e-04 | grad 2.84 | tok/s 32930
step   2630 | loss 1.7570 | lr 2.25e-04 | grad 1.13 | tok/s 35137
step   2640 | loss 1.3487 | lr 2.25e-04 | grad 1.57 | tok/s 35362
step   2650 | loss 1.3064 | lr 2.25e-04 | grad 1.19 | tok/s 35585
step   2660 | loss 1.2971 | lr 2.25e-04 | grad 2.16 | tok/s 35551
step   2670 | loss 1.4732 | lr 2.25e-04 | grad 1.41 | tok/s 34022
step   2680 | loss 1.6320 | lr 2.25e-04 | grad 3.38 | tok/s 33705
step   2690 | loss 1.8237 | lr 2.25e-04 | grad 4.66 | tok/s 34628
step   2700 | loss 1.4199 | lr 2.25e-04 | grad 1.43 | tok/s 34124
step   2710 | loss 1.3520 | lr 2.25e-04 | grad 1.27 | tok/s 34517
step   2720 | loss 1.5622 | lr 2.25e-04 | grad 1.86 | tok/s 34020
step   2730 | loss 1.6135 | lr 2.25e-04 | grad 1.40 | tok/s 33505
step   2740 | loss 1.4909 | lr 2.25e-04 | grad 1.55 | tok/s 34822
step   2750 | loss 1.4120 | lr 2.25e-04 | grad 1.17 | tok/s 33696
step   2760 | loss 1.3424 | lr 2.25e-04 | grad 1.91 | tok/s 33983
step   2770 | loss 1.8682 | lr 2.25e-04 | grad 3.94 | tok/s 34317
step   2780 | loss 1.3880 | lr 2.25e-04 | grad 1.59 | tok/s 34931
step   2790 | loss 1.7591 | lr 2.25e-04 | grad 2.28 | tok/s 34359
step   2800 | loss 1.5213 | lr 2.25e-04 | grad 1.92 | tok/s 34748
step   2810 | loss 1.4452 | lr 2.25e-04 | grad 1.44 | tok/s 34369
step   2820 | loss 1.3842 | lr 2.25e-04 | grad 2.66 | tok/s 34705
step   2830 | loss 1.4160 | lr 2.25e-04 | grad 3.06 | tok/s 34180
step   2840 | loss 1.6298 | lr 2.25e-04 | grad 6.75 | tok/s 34642
step   2850 | loss 1.7041 | lr 2.25e-04 | grad 2.08 | tok/s 34380
step   2860 | loss 1.6359 | lr 2.25e-04 | grad 1.98 | tok/s 34797
step   2870 | loss 1.4017 | lr 2.25e-04 | grad 1.59 | tok/s 33760
step   2880 | loss 1.6253 | lr 2.25e-04 | grad 4.38 | tok/s 33715
step   2890 | loss 1.4723 | lr 2.25e-04 | grad 1.32 | tok/s 34597
step   2900 | loss 1.4702 | lr 2.25e-04 | grad 1.35 | tok/s 34129
step   2910 | loss 1.4826 | lr 2.25e-04 | grad 2.62 | tok/s 33874
step   2920 | loss 1.4726 | lr 2.25e-04 | grad 2.02 | tok/s 34089
step   2930 | loss 1.6119 | lr 2.25e-04 | grad 2.67 | tok/s 33695
step   2940 | loss 1.4427 | lr 2.25e-04 | grad 1.29 | tok/s 34038
step   2950 | loss 1.4730 | lr 2.25e-04 | grad 1.29 | tok/s 34762
step   2960 | loss 1.3870 | lr 2.25e-04 | grad 1.66 | tok/s 34377
step   2970 | loss 1.4148 | lr 2.25e-04 | grad 5.06 | tok/s 34387
step   2980 | loss 1.4278 | lr 2.25e-04 | grad 2.11 | tok/s 34246
step   2990 | loss 1.5095 | lr 2.25e-04 | grad 2.66 | tok/s 34308
step   3000 | loss 1.4565 | lr 2.25e-04 | grad 1.38 | tok/s 34136
  >>> saved checkpoint: checkpoint_step_003000_loss_1.4565.pt
step   3010 | loss 1.5386 | lr 2.25e-04 | grad 3.12 | tok/s 24128
step   3020 | loss 1.3945 | lr 2.25e-04 | grad 1.82 | tok/s 34201
step   3030 | loss 1.3726 | lr 2.25e-04 | grad 2.17 | tok/s 33972
step   3040 | loss 1.4126 | lr 2.25e-04 | grad 1.33 | tok/s 34175
step   3050 | loss 1.3583 | lr 2.25e-04 | grad 1.52 | tok/s 34942
step   3060 | loss 1.4416 | lr 2.25e-04 | grad 1.38 | tok/s 34142
step   3070 | loss 1.3832 | lr 2.25e-04 | grad 1.13 | tok/s 34106
step   3080 | loss 1.4067 | lr 2.25e-04 | grad 1.05 | tok/s 34107
step   3090 | loss 1.7174 | lr 2.25e-04 | grad 2.81 | tok/s 34505
step   3100 | loss 1.7761 | lr 2.25e-04 | grad 3.12 | tok/s 35585
step   3110 | loss 1.4781 | lr 2.25e-04 | grad 2.78 | tok/s 35557
step   3120 | loss 1.5617 | lr 2.25e-04 | grad 2.12 | tok/s 34013
step   3130 | loss 2.0598 | lr 2.25e-04 | grad 1.39 | tok/s 34012
step   3140 | loss 1.3061 | lr 2.25e-04 | grad 1.52 | tok/s 34448
step   3150 | loss 1.7180 | lr 2.25e-04 | grad 5.53 | tok/s 34372
step   3160 | loss 1.4225 | lr 2.25e-04 | grad 1.73 | tok/s 33927
step   3170 | loss 1.7694 | lr 2.25e-04 | grad 1.84 | tok/s 34854
step   3180 | loss 1.4583 | lr 2.25e-04 | grad 2.12 | tok/s 34859
step   3190 | loss 1.4644 | lr 2.25e-04 | grad 1.73 | tok/s 34416
step   3200 | loss 1.5457 | lr 2.25e-04 | grad 2.20 | tok/s 33359
step   3210 | loss 1.4803 | lr 2.25e-04 | grad 1.30 | tok/s 32409
step   3220 | loss 1.2791 | lr 2.25e-04 | grad 1.42 | tok/s 34041
step   3230 | loss 1.5572 | lr 2.25e-04 | grad 2.62 | tok/s 34309
step   3240 | loss 1.5035 | lr 2.25e-04 | grad 1.35 | tok/s 34266
step   3250 | loss 1.5131 | lr 2.25e-04 | grad 3.16 | tok/s 35234
step   3260 | loss 1.5073 | lr 2.25e-04 | grad 1.27 | tok/s 33635
step   3270 | loss 1.4708 | lr 2.25e-04 | grad 1.55 | tok/s 34454
step   3280 | loss 1.5269 | lr 2.25e-04 | grad 2.53 | tok/s 34112
step   3290 | loss 1.4960 | lr 2.25e-04 | grad 1.84 | tok/s 34550
step   3300 | loss 1.4625 | lr 2.25e-04 | grad 2.11 | tok/s 33416
step   3310 | loss 1.4794 | lr 2.25e-04 | grad 2.02 | tok/s 32791
step   3320 | loss 1.4578 | lr 2.25e-04 | grad 1.34 | tok/s 35648
step   3330 | loss 1.4048 | lr 2.25e-04 | grad 1.75 | tok/s 35349
step   3340 | loss 1.3519 | lr 2.25e-04 | grad 2.62 | tok/s 34141
step   3350 | loss 1.5653 | lr 2.25e-04 | grad 3.47 | tok/s 34707
step   3360 | loss 1.5090 | lr 2.25e-04 | grad 1.23 | tok/s 34010
step   3370 | loss 1.3174 | lr 2.25e-04 | grad 1.38 | tok/s 33504
step   3380 | loss 1.4333 | lr 2.25e-04 | grad 3.06 | tok/s 34369
step   3390 | loss 1.4699 | lr 2.25e-04 | grad 1.52 | tok/s 34539
step   3400 | loss 1.9747 | lr 2.25e-04 | grad 3.42 | tok/s 34369
step   3410 | loss 1.4115 | lr 2.25e-04 | grad 1.69 | tok/s 34261
step   3420 | loss 1.5720 | lr 2.25e-04 | grad 1.49 | tok/s 34354
step   3430 | loss 1.2802 | lr 2.25e-04 | grad 3.39 | tok/s 35111
step   3440 | loss 1.4581 | lr 2.25e-04 | grad 1.40 | tok/s 33167
step   3450 | loss 1.5283 | lr 2.25e-04 | grad 1.38 | tok/s 33759
step   3460 | loss 1.4348 | lr 2.25e-04 | grad 1.99 | tok/s 34698
step   3470 | loss 1.7308 | lr 2.25e-04 | grad 1.43 | tok/s 33812
step   3480 | loss 1.4779 | lr 2.25e-04 | grad 2.78 | tok/s 33977
step   3490 | loss 1.3445 | lr 2.25e-04 | grad 1.68 | tok/s 33963
step   3500 | loss 1.4598 | lr 2.25e-04 | grad 2.12 | tok/s 33998
step   3510 | loss 1.4724 | lr 2.25e-04 | grad 1.20 | tok/s 33529
step   3520 | loss 1.4469 | lr 2.25e-04 | grad 1.20 | tok/s 34648
step   3530 | loss 1.4654 | lr 2.25e-04 | grad 1.34 | tok/s 34319
step   3540 | loss 1.4099 | lr 2.25e-04 | grad 1.71 | tok/s 34006
step   3550 | loss 1.5889 | lr 2.25e-04 | grad 1.48 | tok/s 34209
step   3560 | loss 1.5176 | lr 2.25e-04 | grad 1.57 | tok/s 33427
step   3570 | loss 1.4457 | lr 2.25e-04 | grad 1.72 | tok/s 34253
step   3580 | loss 1.4185 | lr 2.25e-04 | grad 5.22 | tok/s 34451
step   3590 | loss 1.4538 | lr 2.25e-04 | grad 1.63 | tok/s 35343
step   3600 | loss 1.3168 | lr 2.25e-04 | grad 1.20 | tok/s 35524
step   3610 | loss 1.2881 | lr 2.25e-04 | grad 1.48 | tok/s 35508
step   3620 | loss 1.2464 | lr 2.25e-04 | grad 1.36 | tok/s 35416
step   3630 | loss 1.2277 | lr 2.25e-04 | grad 1.24 | tok/s 35496
step   3640 | loss 1.2361 | lr 2.25e-04 | grad 1.20 | tok/s 35488
step   3650 | loss 1.3475 | lr 2.25e-04 | grad 2.52 | tok/s 34179
step   3660 | loss 1.6396 | lr 2.25e-04 | grad 1.52 | tok/s 34275
step   3670 | loss 1.3612 | lr 2.25e-04 | grad 1.39 | tok/s 34812
step   3680 | loss 1.3364 | lr 2.25e-04 | grad 2.42 | tok/s 33638
step   3690 | loss 1.3441 | lr 2.25e-04 | grad 2.02 | tok/s 34092
step   3700 | loss 1.3871 | lr 2.25e-04 | grad 2.34 | tok/s 34632
step   3710 | loss 1.4558 | lr 2.25e-04 | grad 5.34 | tok/s 35177
step   3720 | loss 1.4008 | lr 2.25e-04 | grad 4.62 | tok/s 34188
step   3730 | loss 1.4401 | lr 2.25e-04 | grad 2.23 | tok/s 34797
step   3740 | loss 1.5856 | lr 2.25e-04 | grad 1.42 | tok/s 34380
step   3750 | loss 1.4029 | lr 2.25e-04 | grad 1.56 | tok/s 35141
step   3760 | loss 1.3658 | lr 2.25e-04 | grad 2.14 | tok/s 34310
step   3770 | loss 1.5039 | lr 2.25e-04 | grad 6.66 | tok/s 34335
step   3780 | loss 1.3609 | lr 2.25e-04 | grad 1.66 | tok/s 34135
step   3790 | loss 1.4193 | lr 2.25e-04 | grad 2.72 | tok/s 34822
step   3800 | loss 1.4003 | lr 2.25e-04 | grad 1.30 | tok/s 33978
step   3810 | loss 1.3660 | lr 2.25e-04 | grad 1.49 | tok/s 34862
step   3820 | loss 1.3265 | lr 2.25e-04 | grad 1.56 | tok/s 33721
step   3830 | loss 1.3109 | lr 2.25e-04 | grad 1.43 | tok/s 34248
step   3840 | loss 1.2868 | lr 2.25e-04 | grad 3.11 | tok/s 34548
step   3850 | loss 1.4018 | lr 2.25e-04 | grad 3.23 | tok/s 34078
step   3860 | loss 1.4479 | lr 2.25e-04 | grad 1.25 | tok/s 34250

Training complete! Final step: 3864
