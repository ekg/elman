Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_185612/eval_15/level42_100m_20260202_192640
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 405,242,112 parameters
Using schedule-free AdamW (lr=4.245663692047824e-05)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 5.8420 | lr 4.25e-05 | grad 31.00 | tok/s 8546
step     20 | loss 3.1096 | lr 4.25e-05 | grad 21.62 | tok/s 14810
step     30 | loss 3.2661 | lr 4.25e-05 | grad 17.50 | tok/s 15621
step     40 | loss 4.1448 | lr 4.25e-05 | grad 30.62 | tok/s 15925
step     50 | loss 3.8946 | lr 4.25e-05 | grad 27.12 | tok/s 16105
step     60 | loss 3.2327 | lr 4.25e-05 | grad 28.00 | tok/s 16068
step     70 | loss 2.7266 | lr 4.25e-05 | grad 19.75 | tok/s 16041
step     80 | loss 2.4205 | lr 4.25e-05 | grad 15.94 | tok/s 16031
step     90 | loss 2.3375 | lr 4.25e-05 | grad 9.56 | tok/s 16016
step    100 | loss 2.1612 | lr 4.25e-05 | grad 9.88 | tok/s 16004
step    110 | loss 2.3318 | lr 4.25e-05 | grad 14.94 | tok/s 15884
step    120 | loss 3.0719 | lr 4.25e-05 | grad 11.06 | tok/s 15114
step    130 | loss 2.2958 | lr 4.25e-05 | grad 16.00 | tok/s 15473
step    140 | loss 2.5402 | lr 4.25e-05 | grad 21.88 | tok/s 15505
step    150 | loss 1.9628 | lr 4.25e-05 | grad 24.25 | tok/s 15876
step    160 | loss 2.6353 | lr 4.25e-05 | grad 7.72 | tok/s 15358
step    170 | loss 2.4021 | lr 4.25e-05 | grad 7.44 | tok/s 15107
step    180 | loss 2.3962 | lr 4.25e-05 | grad 9.38 | tok/s 15478
step    190 | loss 2.0974 | lr 4.25e-05 | grad 9.69 | tok/s 15192
step    200 | loss 1.9350 | lr 4.25e-05 | grad 6.88 | tok/s 15890
step    210 | loss 2.0568 | lr 4.25e-05 | grad 11.88 | tok/s 15066
step    220 | loss 2.3909 | lr 4.25e-05 | grad 14.50 | tok/s 15226
step    230 | loss 2.1550 | lr 4.25e-05 | grad 8.06 | tok/s 15202
step    240 | loss 2.4548 | lr 4.25e-05 | grad 17.75 | tok/s 15404
step    250 | loss 1.9728 | lr 4.25e-05 | grad 6.94 | tok/s 15313
step    260 | loss 2.1125 | lr 4.25e-05 | grad 11.44 | tok/s 15733
step    270 | loss 2.0220 | lr 4.25e-05 | grad 10.00 | tok/s 15365
step    280 | loss 1.9594 | lr 4.25e-05 | grad 6.91 | tok/s 14435
step    290 | loss 1.8725 | lr 4.25e-05 | grad 7.78 | tok/s 14930
step    300 | loss 2.1471 | lr 4.25e-05 | grad 9.62 | tok/s 15052
step    310 | loss 1.8420 | lr 4.25e-05 | grad 6.94 | tok/s 14980
step    320 | loss 2.0713 | lr 4.25e-05 | grad 11.69 | tok/s 15167
step    330 | loss 1.8983 | lr 4.25e-05 | grad 7.31 | tok/s 15329
step    340 | loss 2.2206 | lr 4.25e-05 | grad 8.81 | tok/s 15254
step    350 | loss 2.0502 | lr 4.25e-05 | grad 7.28 | tok/s 15699
step    360 | loss 1.7689 | lr 4.25e-05 | grad 8.56 | tok/s 15013
step    370 | loss 1.7556 | lr 4.25e-05 | grad 6.97 | tok/s 15813
step    380 | loss 1.5076 | lr 4.25e-05 | grad 9.19 | tok/s 15963
step    390 | loss 1.4030 | lr 4.25e-05 | grad 7.47 | tok/s 15974
step    400 | loss 1.9846 | lr 4.25e-05 | grad 8.12 | tok/s 15115
step    410 | loss 1.9444 | lr 4.25e-05 | grad 9.06 | tok/s 15267
step    420 | loss 1.9172 | lr 4.25e-05 | grad 10.19 | tok/s 15915
step    430 | loss 1.7893 | lr 4.25e-05 | grad 8.12 | tok/s 15653
step    440 | loss 1.8970 | lr 4.25e-05 | grad 9.75 | tok/s 15163
step    450 | loss 1.7867 | lr 4.25e-05 | grad 6.84 | tok/s 15335
step    460 | loss 1.7838 | lr 4.25e-05 | grad 8.44 | tok/s 15557
step    470 | loss 1.7612 | lr 4.25e-05 | grad 12.94 | tok/s 15450
step    480 | loss 1.7585 | lr 4.25e-05 | grad 12.50 | tok/s 15797
step    490 | loss 1.8406 | lr 4.25e-05 | grad 10.56 | tok/s 15165
step    500 | loss 1.9919 | lr 4.25e-05 | grad 8.12 | tok/s 15402
step    510 | loss 1.8675 | lr 4.25e-05 | grad 7.72 | tok/s 14714
step    520 | loss 1.6998 | lr 4.25e-05 | grad 7.72 | tok/s 15412
step    530 | loss 1.8774 | lr 4.25e-05 | grad 10.25 | tok/s 15150
step    540 | loss 1.7950 | lr 4.25e-05 | grad 6.97 | tok/s 14836
step    550 | loss 1.4987 | lr 4.25e-05 | grad 13.06 | tok/s 15519
step    560 | loss 1.6208 | lr 4.25e-05 | grad 9.75 | tok/s 15970
step    570 | loss 1.5072 | lr 4.25e-05 | grad 9.50 | tok/s 15966
step    580 | loss 1.4662 | lr 4.25e-05 | grad 7.53 | tok/s 15942
step    590 | loss 1.5011 | lr 4.25e-05 | grad 7.56 | tok/s 15957
step    600 | loss 1.4387 | lr 4.25e-05 | grad 8.25 | tok/s 15975
step    610 | loss 1.4550 | lr 4.25e-05 | grad 7.16 | tok/s 15976
step    620 | loss 1.4466 | lr 4.25e-05 | grad 8.38 | tok/s 15895
step    630 | loss 1.8064 | lr 4.25e-05 | grad 22.25 | tok/s 15029
step    640 | loss 1.8748 | lr 4.25e-05 | grad 8.88 | tok/s 15222
step    650 | loss 1.6934 | lr 4.25e-05 | grad 7.91 | tok/s 15206
step    660 | loss 1.7435 | lr 4.25e-05 | grad 8.50 | tok/s 15791
step    670 | loss 1.7759 | lr 4.25e-05 | grad 21.25 | tok/s 15275
step    680 | loss 1.7940 | lr 4.25e-05 | grad 10.69 | tok/s 15033
step    690 | loss 1.7379 | lr 4.25e-05 | grad 7.97 | tok/s 14933
step    700 | loss 1.6265 | lr 4.25e-05 | grad 7.81 | tok/s 15246
step    710 | loss 1.8028 | lr 4.25e-05 | grad 17.25 | tok/s 15010
step    720 | loss 1.4766 | lr 4.25e-05 | grad 8.44 | tok/s 15598
step    730 | loss 1.6164 | lr 4.25e-05 | grad 6.69 | tok/s 15340
step    740 | loss 2.0169 | lr 4.25e-05 | grad 18.12 | tok/s 15749
step    750 | loss 1.7742 | lr 4.25e-05 | grad 7.41 | tok/s 15942
step    760 | loss 1.6754 | lr 4.25e-05 | grad 12.56 | tok/s 15608
step    770 | loss 1.7012 | lr 4.25e-05 | grad 8.88 | tok/s 15356
step    780 | loss 1.6219 | lr 4.25e-05 | grad 9.44 | tok/s 15440
step    790 | loss 1.8836 | lr 4.25e-05 | grad 26.12 | tok/s 15792
step    800 | loss 1.4867 | lr 4.25e-05 | grad 6.34 | tok/s 15517
step    810 | loss 1.4675 | lr 4.25e-05 | grad 15.38 | tok/s 15004
step    820 | loss 1.5916 | lr 4.25e-05 | grad 9.81 | tok/s 15276
step    830 | loss 1.6623 | lr 4.25e-05 | grad 7.06 | tok/s 15083
step    840 | loss 1.7830 | lr 4.25e-05 | grad 8.31 | tok/s 15022
step    850 | loss 1.7156 | lr 4.25e-05 | grad 8.38 | tok/s 15353
step    860 | loss 1.7709 | lr 4.25e-05 | grad 10.06 | tok/s 15621
step    870 | loss 1.6757 | lr 4.25e-05 | grad 9.06 | tok/s 15722
step    880 | loss 1.7143 | lr 4.25e-05 | grad 9.00 | tok/s 15424
step    890 | loss 1.5998 | lr 4.25e-05 | grad 6.44 | tok/s 15330
step    900 | loss 1.6555 | lr 4.25e-05 | grad 9.19 | tok/s 15293
step    910 | loss 1.6615 | lr 4.25e-05 | grad 29.62 | tok/s 15107
step    920 | loss 1.6022 | lr 4.25e-05 | grad 8.19 | tok/s 15287
step    930 | loss 1.5299 | lr 4.25e-05 | grad 9.69 | tok/s 15494
step    940 | loss 1.4903 | lr 4.25e-05 | grad 10.44 | tok/s 15107
step    950 | loss 1.6221 | lr 4.25e-05 | grad 11.19 | tok/s 14883
step    960 | loss 1.5674 | lr 4.25e-05 | grad 7.31 | tok/s 15286
step    970 | loss 1.5718 | lr 4.25e-05 | grad 8.25 | tok/s 15291
step    980 | loss 2.1684 | lr 4.25e-05 | grad 20.50 | tok/s 15903
step    990 | loss 1.7238 | lr 4.25e-05 | grad 8.50 | tok/s 15245
step   1000 | loss 1.6623 | lr 4.25e-05 | grad 8.38 | tok/s 15298
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6623.pt
step   1010 | loss 1.4805 | lr 4.25e-05 | grad 13.31 | tok/s 10192
step   1020 | loss 1.4014 | lr 4.25e-05 | grad 7.28 | tok/s 16078
step   1030 | loss 1.6755 | lr 4.25e-05 | grad 9.62 | tok/s 15251
step   1040 | loss 2.2359 | lr 4.25e-05 | grad 18.38 | tok/s 15604
step   1050 | loss 1.6800 | lr 4.25e-05 | grad 13.69 | tok/s 15720
step   1060 | loss 1.2650 | lr 4.25e-05 | grad 9.94 | tok/s 15543
step   1070 | loss 1.5625 | lr 4.25e-05 | grad 9.62 | tok/s 15478
step   1080 | loss 1.3805 | lr 4.25e-05 | grad 7.47 | tok/s 16012
step   1090 | loss 1.3388 | lr 4.25e-05 | grad 7.09 | tok/s 16005
step   1100 | loss 1.3272 | lr 4.25e-05 | grad 5.81 | tok/s 15995
step   1110 | loss 1.2634 | lr 4.25e-05 | grad 6.78 | tok/s 15994
step   1120 | loss 1.5732 | lr 4.25e-05 | grad 19.25 | tok/s 15561
step   1130 | loss 1.8525 | lr 4.25e-05 | grad 8.25 | tok/s 15730
step   1140 | loss 1.9199 | lr 4.25e-05 | grad 10.12 | tok/s 15913
step   1150 | loss 1.9376 | lr 4.25e-05 | grad 10.38 | tok/s 15411
step   1160 | loss 1.8726 | lr 4.25e-05 | grad 10.69 | tok/s 15188
step   1170 | loss 1.6016 | lr 4.25e-05 | grad 9.69 | tok/s 15011
step   1180 | loss 1.4703 | lr 4.25e-05 | grad 14.12 | tok/s 15764
step   1190 | loss 1.8175 | lr 4.25e-05 | grad 14.81 | tok/s 15908
step   1200 | loss 1.2657 | lr 4.25e-05 | grad 8.19 | tok/s 15976
step   1210 | loss 1.4889 | lr 4.25e-05 | grad 9.00 | tok/s 14892
step   1220 | loss 1.5168 | lr 4.25e-05 | grad 9.44 | tok/s 15661
step   1230 | loss 1.4558 | lr 4.25e-05 | grad 6.59 | tok/s 15685
step   1240 | loss 1.4127 | lr 4.25e-05 | grad 9.12 | tok/s 15748
step   1250 | loss 1.6267 | lr 4.25e-05 | grad 13.19 | tok/s 15524
step   1260 | loss 1.5364 | lr 4.25e-05 | grad 10.88 | tok/s 15859
step   1270 | loss 1.4979 | lr 4.25e-05 | grad 11.62 | tok/s 15411
step   1280 | loss 1.5181 | lr 4.25e-05 | grad 8.81 | tok/s 15232
step   1290 | loss 1.4902 | lr 4.25e-05 | grad 12.50 | tok/s 15290
step   1300 | loss 1.8170 | lr 4.25e-05 | grad 27.38 | tok/s 15024
step   1310 | loss 1.6545 | lr 4.25e-05 | grad 9.88 | tok/s 15612
step   1320 | loss 1.6104 | lr 4.25e-05 | grad 11.50 | tok/s 15644
step   1330 | loss 1.6106 | lr 4.25e-05 | grad 9.38 | tok/s 15491
step   1340 | loss 1.7194 | lr 4.25e-05 | grad 11.94 | tok/s 15175
step   1350 | loss 1.5451 | lr 4.25e-05 | grad 7.81 | tok/s 15484
step   1360 | loss 1.6267 | lr 4.25e-05 | grad 9.62 | tok/s 14927
step   1370 | loss 1.7115 | lr 4.25e-05 | grad 11.69 | tok/s 15732
step   1380 | loss 1.5659 | lr 4.25e-05 | grad 8.50 | tok/s 15042
step   1390 | loss 1.5058 | lr 4.25e-05 | grad 14.00 | tok/s 15753
step   1400 | loss 1.6257 | lr 4.25e-05 | grad 8.75 | tok/s 15192
step   1410 | loss 1.5322 | lr 4.25e-05 | grad 18.12 | tok/s 14860
step   1420 | loss 1.3757 | lr 4.25e-05 | grad 39.25 | tok/s 15828
step   1430 | loss 1.8550 | lr 4.25e-05 | grad 9.75 | tok/s 15249
step   1440 | loss 1.5743 | lr 4.25e-05 | grad 11.44 | tok/s 15656
step   1450 | loss 1.6288 | lr 4.25e-05 | grad 43.00 | tok/s 15655
step   1460 | loss 1.6671 | lr 4.25e-05 | grad 18.62 | tok/s 15194
step   1470 | loss 1.4634 | lr 4.25e-05 | grad 11.00 | tok/s 14829
step   1480 | loss 1.4905 | lr 4.25e-05 | grad 8.81 | tok/s 15665
step   1490 | loss 1.9082 | lr 4.25e-05 | grad 29.38 | tok/s 15412
step   1500 | loss 1.5685 | lr 4.25e-05 | grad 9.62 | tok/s 15438
step   1510 | loss 1.3933 | lr 4.25e-05 | grad 9.38 | tok/s 15448
step   1520 | loss 1.5898 | lr 4.25e-05 | grad 9.38 | tok/s 15340
step   1530 | loss 1.5051 | lr 4.25e-05 | grad 8.25 | tok/s 15587
step   1540 | loss 1.6271 | lr 4.25e-05 | grad 8.62 | tok/s 15724
step   1550 | loss 1.6143 | lr 4.25e-05 | grad 11.88 | tok/s 15408
step   1560 | loss 1.2648 | lr 4.25e-05 | grad 9.25 | tok/s 15985
step   1570 | loss 1.4093 | lr 4.25e-05 | grad 7.53 | tok/s 15542
step   1580 | loss 1.4055 | lr 4.25e-05 | grad 10.88 | tok/s 15492
step   1590 | loss 1.5613 | lr 4.25e-05 | grad 9.56 | tok/s 15184
step   1600 | loss 1.4518 | lr 4.25e-05 | grad 15.56 | tok/s 15757
step   1610 | loss 2.0538 | lr 4.25e-05 | grad 13.00 | tok/s 15618
step   1620 | loss 2.0520 | lr 4.25e-05 | grad 11.88 | tok/s 15992
step   1630 | loss 1.7689 | lr 4.25e-05 | grad 10.94 | tok/s 16002
step   1640 | loss 1.5977 | lr 4.25e-05 | grad 9.69 | tok/s 16000
step   1650 | loss 1.5141 | lr 4.25e-05 | grad 10.94 | tok/s 15998
step   1660 | loss 1.4690 | lr 4.25e-05 | grad 10.94 | tok/s 16004
step   1670 | loss 1.6901 | lr 4.25e-05 | grad 12.56 | tok/s 15517
step   1680 | loss 1.5389 | lr 4.25e-05 | grad 10.69 | tok/s 15363
step   1690 | loss 1.5637 | lr 4.25e-05 | grad 10.00 | tok/s 14916
step   1700 | loss 1.4045 | lr 4.25e-05 | grad 6.91 | tok/s 15695
step   1710 | loss 1.3934 | lr 4.25e-05 | grad 9.94 | tok/s 15518
step   1720 | loss 1.5721 | lr 4.25e-05 | grad 9.38 | tok/s 15309
step   1730 | loss 1.5851 | lr 4.25e-05 | grad 13.50 | tok/s 15536
step   1740 | loss 1.5097 | lr 4.25e-05 | grad 8.62 | tok/s 15860
step   1750 | loss 1.3384 | lr 4.25e-05 | grad 7.00 | tok/s 15358
step   1760 | loss 1.5508 | lr 4.25e-05 | grad 9.19 | tok/s 15149
step   1770 | loss 1.7563 | lr 4.25e-05 | grad 9.38 | tok/s 15716
step   1780 | loss 1.8302 | lr 4.25e-05 | grad 7.38 | tok/s 14606
step   1790 | loss 1.4393 | lr 4.25e-05 | grad 10.50 | tok/s 15185
step   1800 | loss 1.4041 | lr 4.25e-05 | grad 7.78 | tok/s 15306
step   1810 | loss 1.4914 | lr 4.25e-05 | grad 8.31 | tok/s 15396
step   1820 | loss 1.6620 | lr 4.25e-05 | grad 9.62 | tok/s 15319
step   1830 | loss 1.4805 | lr 4.25e-05 | grad 7.22 | tok/s 14798
step   1840 | loss 1.4964 | lr 4.25e-05 | grad 9.94 | tok/s 15439
step   1850 | loss 1.5593 | lr 4.25e-05 | grad 8.25 | tok/s 15098
step   1860 | loss 1.5598 | lr 4.25e-05 | grad 7.56 | tok/s 15362
step   1870 | loss 1.5162 | lr 4.25e-05 | grad 9.44 | tok/s 15570
step   1880 | loss 1.6183 | lr 4.25e-05 | grad 9.81 | tok/s 15587
step   1890 | loss 1.3591 | lr 4.25e-05 | grad 8.25 | tok/s 16031
step   1900 | loss 1.2905 | lr 4.25e-05 | grad 7.25 | tok/s 16012
step   1910 | loss 1.2613 | lr 4.25e-05 | grad 7.31 | tok/s 16020
step   1920 | loss 1.2527 | lr 4.25e-05 | grad 7.12 | tok/s 16041
step   1930 | loss 1.3236 | lr 4.25e-05 | grad 9.12 | tok/s 15810
step   1940 | loss 1.6308 | lr 4.25e-05 | grad 13.19 | tok/s 15361
step   1950 | loss 1.5488 | lr 4.25e-05 | grad 16.12 | tok/s 14994
step   1960 | loss 1.5886 | lr 4.25e-05 | grad 15.31 | tok/s 15193
step   1970 | loss 1.6448 | lr 4.25e-05 | grad 9.19 | tok/s 15614
step   1980 | loss 1.5726 | lr 4.25e-05 | grad 15.06 | tok/s 15246
step   1990 | loss 1.6549 | lr 4.25e-05 | grad 10.69 | tok/s 15516
step   2000 | loss 1.2581 | lr 4.25e-05 | grad 10.44 | tok/s 16039
  >>> saved checkpoint: checkpoint_step_002000_loss_1.2581.pt
step   2010 | loss 1.4593 | lr 4.25e-05 | grad 8.00 | tok/s 9664
step   2020 | loss 1.4941 | lr 4.25e-05 | grad 9.25 | tok/s 15284
step   2030 | loss 1.7826 | lr 4.25e-05 | grad 11.12 | tok/s 15134
step   2040 | loss 1.5276 | lr 4.25e-05 | grad 9.50 | tok/s 15479
step   2050 | loss 1.4452 | lr 4.25e-05 | grad 12.19 | tok/s 15398
step   2060 | loss 1.7709 | lr 4.25e-05 | grad 22.75 | tok/s 15552
step   2070 | loss 1.2496 | lr 4.25e-05 | grad 10.00 | tok/s 15597
step   2080 | loss 1.3626 | lr 4.25e-05 | grad 7.19 | tok/s 14982
step   2090 | loss 1.6021 | lr 4.25e-05 | grad 12.44 | tok/s 15843
step   2100 | loss 1.7085 | lr 4.25e-05 | grad 10.19 | tok/s 15969
step   2110 | loss 1.4987 | lr 4.25e-05 | grad 13.94 | tok/s 15177
step   2120 | loss 2.3679 | lr 4.25e-05 | grad 16.12 | tok/s 15496
step   2130 | loss 1.5454 | lr 4.25e-05 | grad 12.75 | tok/s 15115
step   2140 | loss 1.6619 | lr 4.25e-05 | grad 8.69 | tok/s 15637
step   2150 | loss 1.8380 | lr 4.25e-05 | grad 9.69 | tok/s 15551
step   2160 | loss 1.5528 | lr 4.25e-05 | grad 7.31 | tok/s 15494
step   2170 | loss 1.5686 | lr 4.25e-05 | grad 8.06 | tok/s 15551
step   2180 | loss 1.2869 | lr 4.25e-05 | grad 13.69 | tok/s 15998
step   2190 | loss 1.5999 | lr 4.25e-05 | grad 15.81 | tok/s 15310
step   2200 | loss 1.3193 | lr 4.25e-05 | grad 8.25 | tok/s 16031
step   2210 | loss 1.5967 | lr 4.25e-05 | grad 8.69 | tok/s 15501
step   2220 | loss 1.5458 | lr 4.25e-05 | grad 8.44 | tok/s 14995
step   2230 | loss 1.6938 | lr 4.25e-05 | grad 8.44 | tok/s 15315
step   2240 | loss 1.4257 | lr 4.25e-05 | grad 12.19 | tok/s 15576
step   2250 | loss 1.4500 | lr 4.25e-05 | grad 7.56 | tok/s 15278
step   2260 | loss 1.6238 | lr 4.25e-05 | grad 9.00 | tok/s 15567
step   2270 | loss 1.8203 | lr 4.25e-05 | grad 8.69 | tok/s 14933
step   2280 | loss 1.4907 | lr 4.25e-05 | grad 8.38 | tok/s 15366
step   2290 | loss 1.3376 | lr 4.25e-05 | grad 10.19 | tok/s 15099
step   2300 | loss 1.7391 | lr 4.25e-05 | grad 14.00 | tok/s 15215
step   2310 | loss 1.4686 | lr 4.25e-05 | grad 9.25 | tok/s 15607
step   2320 | loss 1.4691 | lr 4.25e-05 | grad 9.88 | tok/s 16039
step   2330 | loss 1.3890 | lr 4.25e-05 | grad 7.69 | tok/s 16042
step   2340 | loss 1.3527 | lr 4.25e-05 | grad 8.06 | tok/s 16041
step   2350 | loss 1.3358 | lr 4.25e-05 | grad 8.50 | tok/s 16042
step   2360 | loss 1.2785 | lr 4.25e-05 | grad 8.00 | tok/s 16040
step   2370 | loss 1.2763 | lr 4.25e-05 | grad 8.50 | tok/s 16019
step   2380 | loss 1.2614 | lr 4.25e-05 | grad 8.06 | tok/s 16040
step   2390 | loss 1.2768 | lr 4.25e-05 | grad 8.12 | tok/s 16041
step   2400 | loss 1.2307 | lr 4.25e-05 | grad 8.19 | tok/s 16027
step   2410 | loss 1.4518 | lr 4.25e-05 | grad 41.75 | tok/s 15834
step   2420 | loss 1.3637 | lr 4.25e-05 | grad 5.75 | tok/s 15756
step   2430 | loss 1.2799 | lr 4.25e-05 | grad 12.12 | tok/s 15149
step   2440 | loss 1.5017 | lr 4.25e-05 | grad 10.44 | tok/s 14973
step   2450 | loss 1.4358 | lr 4.25e-05 | grad 7.91 | tok/s 15538
step   2460 | loss 1.6324 | lr 4.25e-05 | grad 8.38 | tok/s 15741
step   2470 | loss 1.4266 | lr 4.25e-05 | grad 8.50 | tok/s 15307
step   2480 | loss 1.5971 | lr 4.25e-05 | grad 13.31 | tok/s 15733
step   2490 | loss 1.6334 | lr 4.25e-05 | grad 9.75 | tok/s 15265
step   2500 | loss 1.6761 | lr 4.25e-05 | grad 9.00 | tok/s 15652
step   2510 | loss 1.5586 | lr 4.25e-05 | grad 7.56 | tok/s 15508
step   2520 | loss 1.4943 | lr 4.25e-05 | grad 9.88 | tok/s 15258
step   2530 | loss 1.6409 | lr 4.25e-05 | grad 14.25 | tok/s 15609
step   2540 | loss 1.5322 | lr 4.25e-05 | grad 26.25 | tok/s 14908
step   2550 | loss 1.3969 | lr 4.25e-05 | grad 11.50 | tok/s 15416
step   2560 | loss 1.6838 | lr 4.25e-05 | grad 8.94 | tok/s 15169
step   2570 | loss 1.4549 | lr 4.25e-05 | grad 8.56 | tok/s 15345
step   2580 | loss 1.7532 | lr 4.25e-05 | grad 10.06 | tok/s 15290
step   2590 | loss 1.4189 | lr 4.25e-05 | grad 9.00 | tok/s 14972
step   2600 | loss 1.5488 | lr 4.25e-05 | grad 7.03 | tok/s 15396
step   2610 | loss 1.4732 | lr 4.25e-05 | grad 8.25 | tok/s 15748
step   2620 | loss 1.6618 | lr 4.25e-05 | grad 10.00 | tok/s 15232
step   2630 | loss 1.2663 | lr 4.25e-05 | grad 12.06 | tok/s 15765
step   2640 | loss 1.4284 | lr 4.25e-05 | grad 8.88 | tok/s 15193
step   2650 | loss 1.3381 | lr 4.25e-05 | grad 10.38 | tok/s 15506
step   2660 | loss 1.4242 | lr 4.25e-05 | grad 7.06 | tok/s 15608
step   2670 | loss 1.3552 | lr 4.25e-05 | grad 8.56 | tok/s 15528
step   2680 | loss 1.4884 | lr 4.25e-05 | grad 9.50 | tok/s 15237
step   2690 | loss 1.4042 | lr 4.25e-05 | grad 9.44 | tok/s 14974
step   2700 | loss 1.5061 | lr 4.25e-05 | grad 9.62 | tok/s 15470
step   2710 | loss 1.8000 | lr 4.25e-05 | grad 11.25 | tok/s 15346
step   2720 | loss 1.4646 | lr 4.25e-05 | grad 9.06 | tok/s 15591
step   2730 | loss 1.4115 | lr 4.25e-05 | grad 17.25 | tok/s 15369
step   2740 | loss 1.5453 | lr 4.25e-05 | grad 11.94 | tok/s 15296
step   2750 | loss 1.5166 | lr 4.25e-05 | grad 9.88 | tok/s 15563
step   2760 | loss 1.3146 | lr 4.25e-05 | grad 9.31 | tok/s 15689
step   2770 | loss 1.5362 | lr 4.25e-05 | grad 9.00 | tok/s 15451
step   2780 | loss 1.4098 | lr 4.25e-05 | grad 15.38 | tok/s 15717
step   2790 | loss 1.5283 | lr 4.25e-05 | grad 16.50 | tok/s 15295
step   2800 | loss 1.5443 | lr 4.25e-05 | grad 15.31 | tok/s 14876
step   2810 | loss 1.5132 | lr 4.25e-05 | grad 10.62 | tok/s 15458
step   2820 | loss 1.4421 | lr 4.25e-05 | grad 14.00 | tok/s 14482
step   2830 | loss 1.3447 | lr 4.25e-05 | grad 7.03 | tok/s 15364
step   2840 | loss 1.2826 | lr 4.25e-05 | grad 9.56 | tok/s 15167
step   2850 | loss 1.2655 | lr 4.25e-05 | grad 7.38 | tok/s 16033
step   2860 | loss 1.3016 | lr 4.25e-05 | grad 14.06 | tok/s 15602
step   2870 | loss 1.4692 | lr 4.25e-05 | grad 8.19 | tok/s 15213
step   2880 | loss 1.4908 | lr 4.25e-05 | grad 8.94 | tok/s 15041
step   2890 | loss 1.6686 | lr 4.25e-05 | grad 26.25 | tok/s 15501
step   2900 | loss 1.5113 | lr 4.25e-05 | grad 11.88 | tok/s 15025
step   2910 | loss 1.4747 | lr 4.25e-05 | grad 9.69 | tok/s 15771
step   2920 | loss 1.3355 | lr 4.25e-05 | grad 18.38 | tok/s 15193
step   2930 | loss 1.5045 | lr 4.25e-05 | grad 10.38 | tok/s 15673
step   2940 | loss 1.3580 | lr 4.25e-05 | grad 7.81 | tok/s 15356
step   2950 | loss 1.7907 | lr 4.25e-05 | grad 7.69 | tok/s 15479
step   2960 | loss 1.6431 | lr 4.25e-05 | grad 13.88 | tok/s 14906
step   2970 | loss 1.5520 | lr 4.25e-05 | grad 8.50 | tok/s 15434
step   2980 | loss 1.4307 | lr 4.25e-05 | grad 7.78 | tok/s 15643
step   2990 | loss 1.6007 | lr 4.25e-05 | grad 11.81 | tok/s 15532
step   3000 | loss 1.4253 | lr 4.25e-05 | grad 12.69 | tok/s 15610
  >>> saved checkpoint: checkpoint_step_003000_loss_1.4253.pt
step   3010 | loss 1.5591 | lr 4.25e-05 | grad 20.88 | tok/s 10254
step   3020 | loss 1.4210 | lr 4.25e-05 | grad 10.38 | tok/s 15286
step   3030 | loss 1.3839 | lr 4.25e-05 | grad 10.50 | tok/s 15012
step   3040 | loss 1.4093 | lr 4.25e-05 | grad 9.19 | tok/s 15508
step   3050 | loss 1.2852 | lr 4.25e-05 | grad 7.62 | tok/s 15960
step   3060 | loss 1.4777 | lr 4.25e-05 | grad 15.81 | tok/s 15685
step   3070 | loss 2.0934 | lr 4.25e-05 | grad 30.00 | tok/s 15359
step   3080 | loss 1.5944 | lr 4.25e-05 | grad 16.88 | tok/s 15503
step   3090 | loss 1.4785 | lr 4.25e-05 | grad 12.31 | tok/s 14919
step   3100 | loss 1.3697 | lr 4.25e-05 | grad 8.88 | tok/s 15525
step   3110 | loss 1.5354 | lr 4.25e-05 | grad 11.75 | tok/s 15885
step   3120 | loss 1.4901 | lr 4.25e-05 | grad 8.19 | tok/s 15232
step   3130 | loss 1.4282 | lr 4.25e-05 | grad 11.75 | tok/s 15038
step   3140 | loss 1.3418 | lr 4.25e-05 | grad 16.88 | tok/s 15309
step   3150 | loss 1.4246 | lr 4.25e-05 | grad 11.31 | tok/s 14612
step   3160 | loss 1.6004 | lr 4.25e-05 | grad 7.81 | tok/s 15943
step   3170 | loss 1.3019 | lr 4.25e-05 | grad 6.22 | tok/s 15786
step   3180 | loss 1.3270 | lr 4.25e-05 | grad 11.44 | tok/s 15708
step   3190 | loss 1.6250 | lr 4.25e-05 | grad 18.62 | tok/s 15652
step   3200 | loss 1.3565 | lr 4.25e-05 | grad 7.31 | tok/s 15431
step   3210 | loss 1.5296 | lr 4.25e-05 | grad 10.69 | tok/s 15506
step   3220 | loss 1.3478 | lr 4.25e-05 | grad 7.81 | tok/s 15879
step   3230 | loss 1.4552 | lr 4.25e-05 | grad 8.06 | tok/s 14930
step   3240 | loss 1.3789 | lr 4.25e-05 | grad 9.25 | tok/s 14843
step   3250 | loss 1.4217 | lr 4.25e-05 | grad 14.38 | tok/s 15146
step   3260 | loss 1.4720 | lr 4.25e-05 | grad 9.19 | tok/s 15380
step   3270 | loss 1.4203 | lr 4.25e-05 | grad 9.75 | tok/s 14995
step   3280 | loss 1.5465 | lr 4.25e-05 | grad 7.41 | tok/s 15391
step   3290 | loss 1.3338 | lr 4.25e-05 | grad 10.50 | tok/s 15438
step   3300 | loss 1.5956 | lr 4.25e-05 | grad 13.88 | tok/s 15939
step   3310 | loss 1.8719 | lr 4.25e-05 | grad 31.38 | tok/s 15522
step   3320 | loss 1.5990 | lr 4.25e-05 | grad 11.31 | tok/s 15415
step   3330 | loss 1.3644 | lr 4.25e-05 | grad 12.38 | tok/s 14863
step   3340 | loss 1.2320 | lr 4.25e-05 | grad 6.62 | tok/s 15892
step   3350 | loss 1.5562 | lr 4.25e-05 | grad 15.12 | tok/s 15831
step   3360 | loss 1.4882 | lr 4.25e-05 | grad 9.62 | tok/s 15186
step   3370 | loss 1.6124 | lr 4.25e-05 | grad 16.75 | tok/s 15156
step   3380 | loss 1.4423 | lr 4.25e-05 | grad 9.25 | tok/s 15437
step   3390 | loss 1.3664 | lr 4.25e-05 | grad 13.00 | tok/s 15179
step   3400 | loss 1.4897 | lr 4.25e-05 | grad 8.81 | tok/s 15410
step   3410 | loss 1.5583 | lr 4.25e-05 | grad 9.56 | tok/s 15187
step   3420 | loss 1.5856 | lr 4.25e-05 | grad 10.12 | tok/s 15372
step   3430 | loss 1.4803 | lr 4.25e-05 | grad 12.81 | tok/s 15403
step   3440 | loss 1.4362 | lr 4.25e-05 | grad 14.75 | tok/s 15184
step   3450 | loss 1.4769 | lr 4.25e-05 | grad 9.19 | tok/s 15152
step   3460 | loss 1.4618 | lr 4.25e-05 | grad 11.00 | tok/s 15150
step   3470 | loss 1.7144 | lr 4.25e-05 | grad 7.53 | tok/s 15502

Training complete! Final step: 3472
