Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_185612/eval_5/level42_100m_20260202_185619
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 405,242,112 parameters
Using schedule-free AdamW (lr=0.00036418971922824234)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 8.0272 | lr 3.64e-04 | grad 18.00 | tok/s 8646
step     20 | loss 3.3918 | lr 3.64e-04 | grad 7.03 | tok/s 15113
step     30 | loss 3.6759 | lr 3.64e-04 | grad 5.09 | tok/s 15966
step     40 | loss 5.2005 | lr 3.64e-04 | grad 12.62 | tok/s 16272
step     50 | loss 5.0054 | lr 3.64e-04 | grad 10.56 | tok/s 16426
step     60 | loss 4.0694 | lr 3.64e-04 | grad 7.28 | tok/s 16375
step     70 | loss 3.5762 | lr 3.64e-04 | grad 7.94 | tok/s 16346
step     80 | loss 3.3453 | lr 3.64e-04 | grad 6.88 | tok/s 16299
step     90 | loss 3.1128 | lr 3.64e-04 | grad 4.81 | tok/s 16262
step    100 | loss 2.9298 | lr 3.64e-04 | grad 5.09 | tok/s 16214
step    110 | loss 3.0746 | lr 3.64e-04 | grad 7.09 | tok/s 16094
step    120 | loss 3.8301 | lr 3.64e-04 | grad 6.72 | tok/s 15328
step    130 | loss 2.8112 | lr 3.64e-04 | grad 7.28 | tok/s 15682
step    140 | loss 3.0847 | lr 3.64e-04 | grad 8.00 | tok/s 15713
step    150 | loss 2.8009 | lr 3.64e-04 | grad 6.25 | tok/s 16096
step    160 | loss 2.9518 | lr 3.64e-04 | grad 4.91 | tok/s 15532
step    170 | loss 2.7787 | lr 3.64e-04 | grad 3.86 | tok/s 15291
step    180 | loss 2.9861 | lr 3.64e-04 | grad 3.88 | tok/s 15656
step    190 | loss 2.4796 | lr 3.64e-04 | grad 3.95 | tok/s 15361
step    200 | loss 2.3866 | lr 3.64e-04 | grad 2.70 | tok/s 16062
step    210 | loss 2.4295 | lr 3.64e-04 | grad 3.56 | tok/s 15237
step    220 | loss 2.7577 | lr 3.64e-04 | grad 4.56 | tok/s 15391
step    230 | loss 2.5836 | lr 3.64e-04 | grad 3.20 | tok/s 15380
step    240 | loss 2.8369 | lr 3.64e-04 | grad 4.34 | tok/s 15579
step    250 | loss 2.3385 | lr 3.64e-04 | grad 2.91 | tok/s 15473
step    260 | loss 2.4969 | lr 3.64e-04 | grad 3.41 | tok/s 15906
step    270 | loss 2.3358 | lr 3.64e-04 | grad 3.03 | tok/s 15541
step    280 | loss 2.2814 | lr 3.64e-04 | grad 2.03 | tok/s 14609
step    290 | loss 2.2159 | lr 3.64e-04 | grad 2.86 | tok/s 15097
step    300 | loss 2.4954 | lr 3.64e-04 | grad 3.72 | tok/s 15210
step    310 | loss 2.1465 | lr 3.64e-04 | grad 3.02 | tok/s 15155
step    320 | loss 2.4279 | lr 3.64e-04 | grad 3.86 | tok/s 15319
step    330 | loss 2.2135 | lr 3.64e-04 | grad 2.36 | tok/s 15478
step    340 | loss 2.6102 | lr 3.64e-04 | grad 2.78 | tok/s 15411
step    350 | loss 2.4849 | lr 3.64e-04 | grad 2.66 | tok/s 15869
step    360 | loss 2.1349 | lr 3.64e-04 | grad 2.55 | tok/s 15183
step    370 | loss 2.1673 | lr 3.64e-04 | grad 2.45 | tok/s 15989
step    380 | loss 1.9669 | lr 3.64e-04 | grad 3.22 | tok/s 16130
step    390 | loss 1.8974 | lr 3.64e-04 | grad 2.92 | tok/s 16121
step    400 | loss 2.3504 | lr 3.64e-04 | grad 2.02 | tok/s 15266
step    410 | loss 2.2296 | lr 3.64e-04 | grad 2.31 | tok/s 15412
step    420 | loss 2.3458 | lr 3.64e-04 | grad 2.41 | tok/s 16071
step    430 | loss 2.1782 | lr 3.64e-04 | grad 2.75 | tok/s 15808
step    440 | loss 2.2336 | lr 3.64e-04 | grad 3.62 | tok/s 15324
step    450 | loss 2.1087 | lr 3.64e-04 | grad 2.03 | tok/s 15495
step    460 | loss 2.1927 | lr 3.64e-04 | grad 1.98 | tok/s 15728
step    470 | loss 2.1885 | lr 3.64e-04 | grad 3.12 | tok/s 15609
step    480 | loss 2.2507 | lr 3.64e-04 | grad 3.59 | tok/s 15955
step    490 | loss 2.1566 | lr 3.64e-04 | grad 2.70 | tok/s 15322
step    500 | loss 2.3295 | lr 3.64e-04 | grad 2.83 | tok/s 15582
step    510 | loss 2.1420 | lr 3.64e-04 | grad 3.16 | tok/s 14873
step    520 | loss 2.0212 | lr 3.64e-04 | grad 1.80 | tok/s 15586
step    530 | loss 2.1776 | lr 3.64e-04 | grad 2.06 | tok/s 15326
step    540 | loss 2.1231 | lr 3.64e-04 | grad 1.24 | tok/s 15004
step    550 | loss 1.7960 | lr 3.64e-04 | grad 3.53 | tok/s 15677
step    560 | loss 1.9656 | lr 3.64e-04 | grad 2.47 | tok/s 16122
step    570 | loss 1.8556 | lr 3.64e-04 | grad 1.71 | tok/s 16139
step    580 | loss 1.7838 | lr 3.64e-04 | grad 1.47 | tok/s 16139
step    590 | loss 1.8540 | lr 3.64e-04 | grad 2.70 | tok/s 16128
step    600 | loss 1.7964 | lr 3.64e-04 | grad 2.81 | tok/s 16142
step    610 | loss 1.7750 | lr 3.64e-04 | grad 2.09 | tok/s 16135
step    620 | loss 1.7576 | lr 3.64e-04 | grad 2.64 | tok/s 16065
step    630 | loss 2.1592 | lr 3.64e-04 | grad 6.78 | tok/s 15185
step    640 | loss 2.1550 | lr 3.64e-04 | grad 2.34 | tok/s 15384
step    650 | loss 1.9871 | lr 3.64e-04 | grad 1.96 | tok/s 15369
step    660 | loss 2.0486 | lr 3.64e-04 | grad 1.97 | tok/s 15953
step    670 | loss 2.1200 | lr 3.64e-04 | grad 4.19 | tok/s 15437
step    680 | loss 2.0857 | lr 3.64e-04 | grad 1.96 | tok/s 15186
step    690 | loss 2.0497 | lr 3.64e-04 | grad 2.08 | tok/s 15075
step    700 | loss 1.9435 | lr 3.64e-04 | grad 1.45 | tok/s 15403
step    710 | loss 2.1393 | lr 3.64e-04 | grad 3.20 | tok/s 15176
step    720 | loss 1.8437 | lr 3.64e-04 | grad 2.00 | tok/s 15746
step    730 | loss 1.9536 | lr 3.64e-04 | grad 1.51 | tok/s 15491
step    740 | loss 2.4090 | lr 3.64e-04 | grad 3.84 | tok/s 15915
step    750 | loss 2.1597 | lr 3.64e-04 | grad 2.50 | tok/s 16109
step    760 | loss 1.9852 | lr 3.64e-04 | grad 3.09 | tok/s 15760
step    770 | loss 1.9865 | lr 3.64e-04 | grad 2.22 | tok/s 15497
step    780 | loss 1.9138 | lr 3.64e-04 | grad 2.33 | tok/s 15615
step    790 | loss 2.2516 | lr 3.64e-04 | grad 2.88 | tok/s 15944
step    800 | loss 1.8023 | lr 3.64e-04 | grad 1.10 | tok/s 15668
step    810 | loss 1.7414 | lr 3.64e-04 | grad 2.61 | tok/s 15159
step    820 | loss 1.9005 | lr 3.64e-04 | grad 2.11 | tok/s 15437
step    830 | loss 1.9544 | lr 3.64e-04 | grad 2.61 | tok/s 15244
step    840 | loss 2.1096 | lr 3.64e-04 | grad 1.65 | tok/s 15182
step    850 | loss 2.0340 | lr 3.64e-04 | grad 2.39 | tok/s 15497
step    860 | loss 2.1035 | lr 3.64e-04 | grad 1.88 | tok/s 15749
step    870 | loss 2.0750 | lr 3.64e-04 | grad 1.85 | tok/s 15875
step    880 | loss 1.9798 | lr 3.64e-04 | grad 1.82 | tok/s 15581
step    890 | loss 1.8544 | lr 3.64e-04 | grad 1.72 | tok/s 15487
step    900 | loss 1.9246 | lr 3.64e-04 | grad 1.64 | tok/s 15424
step    910 | loss 1.9870 | lr 3.64e-04 | grad 5.31 | tok/s 15267
step    920 | loss 1.8877 | lr 3.64e-04 | grad 2.48 | tok/s 15451
step    930 | loss 1.8212 | lr 3.64e-04 | grad 1.95 | tok/s 15649
step    940 | loss 1.7999 | lr 3.64e-04 | grad 2.11 | tok/s 15286
step    950 | loss 1.8857 | lr 3.64e-04 | grad 2.95 | tok/s 15021
step    960 | loss 1.8284 | lr 3.64e-04 | grad 2.25 | tok/s 15428
step    970 | loss 1.8049 | lr 3.64e-04 | grad 1.78 | tok/s 15442
step    980 | loss 2.4795 | lr 3.64e-04 | grad 2.91 | tok/s 16081
step    990 | loss 2.0455 | lr 3.64e-04 | grad 2.64 | tok/s 15411
step   1000 | loss 1.9649 | lr 3.64e-04 | grad 2.62 | tok/s 15446
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9649.pt
step   1010 | loss 1.7540 | lr 3.64e-04 | grad 2.77 | tok/s 9803
step   1020 | loss 1.6839 | lr 3.64e-04 | grad 2.50 | tok/s 16233
step   1030 | loss 1.9652 | lr 3.64e-04 | grad 3.20 | tok/s 15415
step   1040 | loss 2.3815 | lr 3.64e-04 | grad 4.38 | tok/s 15755
step   1050 | loss 2.0052 | lr 3.64e-04 | grad 2.33 | tok/s 15887
step   1060 | loss 1.5037 | lr 3.64e-04 | grad 1.58 | tok/s 15703
step   1070 | loss 1.8428 | lr 3.64e-04 | grad 2.17 | tok/s 15635
step   1080 | loss 1.6294 | lr 3.64e-04 | grad 2.00 | tok/s 16169
step   1090 | loss 1.5900 | lr 3.64e-04 | grad 1.83 | tok/s 16165
step   1100 | loss 1.5723 | lr 3.64e-04 | grad 2.80 | tok/s 16178
step   1110 | loss 1.4953 | lr 3.64e-04 | grad 2.05 | tok/s 16166
step   1120 | loss 1.8300 | lr 3.64e-04 | grad 3.03 | tok/s 15719
step   1130 | loss 2.1669 | lr 3.64e-04 | grad 2.19 | tok/s 15883
step   1140 | loss 2.1883 | lr 3.64e-04 | grad 2.88 | tok/s 16064
step   1150 | loss 2.3306 | lr 3.64e-04 | grad 4.16 | tok/s 15572
step   1160 | loss 2.1248 | lr 3.64e-04 | grad 3.81 | tok/s 15330
step   1170 | loss 1.8819 | lr 3.64e-04 | grad 2.00 | tok/s 15161
step   1180 | loss 1.7506 | lr 3.64e-04 | grad 2.58 | tok/s 15934
step   1190 | loss 2.1483 | lr 3.64e-04 | grad 3.38 | tok/s 16077
step   1200 | loss 1.5486 | lr 3.64e-04 | grad 2.41 | tok/s 16143
step   1210 | loss 1.7345 | lr 3.64e-04 | grad 1.84 | tok/s 15069
step   1220 | loss 1.7799 | lr 3.64e-04 | grad 2.08 | tok/s 15827
step   1230 | loss 1.7152 | lr 3.64e-04 | grad 1.45 | tok/s 15851
step   1240 | loss 1.6713 | lr 3.64e-04 | grad 3.12 | tok/s 15922
step   1250 | loss 1.9377 | lr 3.64e-04 | grad 1.92 | tok/s 15680
step   1260 | loss 1.8930 | lr 3.64e-04 | grad 2.98 | tok/s 16014
step   1270 | loss 1.7503 | lr 3.64e-04 | grad 3.23 | tok/s 15565
step   1280 | loss 1.7969 | lr 3.64e-04 | grad 1.76 | tok/s 15384
step   1290 | loss 1.7593 | lr 3.64e-04 | grad 1.83 | tok/s 15444
step   1300 | loss 2.0761 | lr 3.64e-04 | grad 4.03 | tok/s 15186
step   1310 | loss 1.9044 | lr 3.64e-04 | grad 2.78 | tok/s 15798
step   1320 | loss 1.8737 | lr 3.64e-04 | grad 1.75 | tok/s 15812
step   1330 | loss 1.8738 | lr 3.64e-04 | grad 2.30 | tok/s 15647
step   1340 | loss 1.9986 | lr 3.64e-04 | grad 2.38 | tok/s 15317
step   1350 | loss 1.8064 | lr 3.64e-04 | grad 1.45 | tok/s 15646
step   1360 | loss 1.9224 | lr 3.64e-04 | grad 2.14 | tok/s 15083
step   1370 | loss 1.9607 | lr 3.64e-04 | grad 2.25 | tok/s 15898
step   1380 | loss 1.8049 | lr 3.64e-04 | grad 2.31 | tok/s 15200
step   1390 | loss 1.7849 | lr 3.64e-04 | grad 2.81 | tok/s 15910
step   1400 | loss 1.9506 | lr 3.64e-04 | grad 2.53 | tok/s 15363
step   1410 | loss 1.7645 | lr 3.64e-04 | grad 3.70 | tok/s 15012
step   1420 | loss 1.7055 | lr 3.64e-04 | grad 4.72 | tok/s 15999
step   1430 | loss 2.1210 | lr 3.64e-04 | grad 2.33 | tok/s 15413
step   1440 | loss 1.8383 | lr 3.64e-04 | grad 2.19 | tok/s 15831
step   1450 | loss 1.8955 | lr 3.64e-04 | grad 6.50 | tok/s 15798
step   1460 | loss 1.8796 | lr 3.64e-04 | grad 4.56 | tok/s 15350
step   1470 | loss 1.6968 | lr 3.64e-04 | grad 2.06 | tok/s 14985
step   1480 | loss 1.7193 | lr 3.64e-04 | grad 1.67 | tok/s 15807
step   1490 | loss 2.1801 | lr 3.64e-04 | grad 6.88 | tok/s 15565
step   1500 | loss 1.8175 | lr 3.64e-04 | grad 2.02 | tok/s 15611
step   1510 | loss 1.6524 | lr 3.64e-04 | grad 2.58 | tok/s 15606
step   1520 | loss 1.8069 | lr 3.64e-04 | grad 2.11 | tok/s 15485
step   1530 | loss 1.7291 | lr 3.64e-04 | grad 2.14 | tok/s 15713
step   1540 | loss 1.8306 | lr 3.64e-04 | grad 2.42 | tok/s 15862
step   1550 | loss 1.8299 | lr 3.64e-04 | grad 2.06 | tok/s 15538
step   1560 | loss 1.5292 | lr 3.64e-04 | grad 1.95 | tok/s 16147
step   1570 | loss 1.6684 | lr 3.64e-04 | grad 1.99 | tok/s 15697
step   1580 | loss 1.6407 | lr 3.64e-04 | grad 2.16 | tok/s 15652
step   1590 | loss 1.7934 | lr 3.64e-04 | grad 1.55 | tok/s 15331
step   1600 | loss 1.6441 | lr 3.64e-04 | grad 2.02 | tok/s 15895
step   1610 | loss 2.3033 | lr 3.64e-04 | grad 3.20 | tok/s 15755
step   1620 | loss 2.2549 | lr 3.64e-04 | grad 3.39 | tok/s 16152
step   1630 | loss 2.0231 | lr 3.64e-04 | grad 4.34 | tok/s 16153
step   1640 | loss 1.8806 | lr 3.64e-04 | grad 2.92 | tok/s 16157
step   1650 | loss 1.8115 | lr 3.64e-04 | grad 2.72 | tok/s 16154
step   1660 | loss 1.7725 | lr 3.64e-04 | grad 2.27 | tok/s 16156
step   1670 | loss 1.9415 | lr 3.64e-04 | grad 1.88 | tok/s 15655
step   1680 | loss 1.7589 | lr 3.64e-04 | grad 2.69 | tok/s 15496
step   1690 | loss 1.7832 | lr 3.64e-04 | grad 1.77 | tok/s 15053
step   1700 | loss 1.6192 | lr 3.64e-04 | grad 1.52 | tok/s 15821
step   1710 | loss 1.6303 | lr 3.64e-04 | grad 1.95 | tok/s 15659
step   1720 | loss 1.7754 | lr 3.64e-04 | grad 1.91 | tok/s 15449
step   1730 | loss 1.8290 | lr 3.64e-04 | grad 2.56 | tok/s 15663
step   1740 | loss 1.7206 | lr 3.64e-04 | grad 2.14 | tok/s 16007
step   1750 | loss 1.5655 | lr 3.64e-04 | grad 1.68 | tok/s 15491
step   1760 | loss 1.7552 | lr 3.64e-04 | grad 1.89 | tok/s 15283
step   1770 | loss 2.0763 | lr 3.64e-04 | grad 1.60 | tok/s 15862
step   1780 | loss 2.0394 | lr 3.64e-04 | grad 1.95 | tok/s 14736
step   1790 | loss 1.6559 | lr 3.64e-04 | grad 2.05 | tok/s 15313
step   1800 | loss 1.6837 | lr 3.64e-04 | grad 2.27 | tok/s 15423
step   1810 | loss 1.6906 | lr 3.64e-04 | grad 2.14 | tok/s 15525
step   1820 | loss 1.8775 | lr 3.64e-04 | grad 1.57 | tok/s 15456
step   1830 | loss 1.6723 | lr 3.64e-04 | grad 1.78 | tok/s 14919
step   1840 | loss 1.7513 | lr 3.64e-04 | grad 2.38 | tok/s 15569
step   1850 | loss 1.7531 | lr 3.64e-04 | grad 1.62 | tok/s 15225
step   1860 | loss 1.7615 | lr 3.64e-04 | grad 1.83 | tok/s 15494
step   1870 | loss 1.7272 | lr 3.64e-04 | grad 2.19 | tok/s 15712
step   1880 | loss 1.8486 | lr 3.64e-04 | grad 2.59 | tok/s 15730
step   1890 | loss 1.5414 | lr 3.64e-04 | grad 2.39 | tok/s 16143
step   1900 | loss 1.4740 | lr 3.64e-04 | grad 2.06 | tok/s 16161
step   1910 | loss 1.4525 | lr 3.64e-04 | grad 2.33 | tok/s 16157
step   1920 | loss 1.4451 | lr 3.64e-04 | grad 3.14 | tok/s 16138
step   1930 | loss 1.5181 | lr 3.64e-04 | grad 2.06 | tok/s 15913
step   1940 | loss 1.8661 | lr 3.64e-04 | grad 2.20 | tok/s 15453
step   1950 | loss 1.7853 | lr 3.64e-04 | grad 2.69 | tok/s 15096
step   1960 | loss 1.8150 | lr 3.64e-04 | grad 1.96 | tok/s 15301
step   1970 | loss 1.8627 | lr 3.64e-04 | grad 2.16 | tok/s 15732
step   1980 | loss 1.7995 | lr 3.64e-04 | grad 2.58 | tok/s 15349
step   1990 | loss 1.9270 | lr 3.64e-04 | grad 2.62 | tok/s 15645
step   2000 | loss 1.4738 | lr 3.64e-04 | grad 2.53 | tok/s 16152
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4738.pt
step   2010 | loss 1.6840 | lr 3.64e-04 | grad 1.90 | tok/s 9519
step   2020 | loss 1.6947 | lr 3.64e-04 | grad 1.62 | tok/s 15370
step   2030 | loss 2.1067 | lr 3.64e-04 | grad 2.09 | tok/s 15231
step   2040 | loss 1.7064 | lr 3.64e-04 | grad 2.36 | tok/s 15571
step   2050 | loss 1.6366 | lr 3.64e-04 | grad 2.09 | tok/s 15501
step   2060 | loss 1.9616 | lr 3.64e-04 | grad 3.55 | tok/s 15630
step   2070 | loss 1.4190 | lr 3.64e-04 | grad 2.64 | tok/s 15691
step   2080 | loss 1.5960 | lr 3.64e-04 | grad 2.30 | tok/s 15068
step   2090 | loss 1.8917 | lr 3.64e-04 | grad 3.34 | tok/s 15928
step   2100 | loss 2.0170 | lr 3.64e-04 | grad 1.92 | tok/s 16043
step   2110 | loss 1.7108 | lr 3.64e-04 | grad 2.80 | tok/s 15259
step   2120 | loss 2.5491 | lr 3.64e-04 | grad 2.66 | tok/s 15579
step   2130 | loss 1.7507 | lr 3.64e-04 | grad 2.25 | tok/s 15215
step   2140 | loss 1.8951 | lr 3.64e-04 | grad 3.28 | tok/s 15731
step   2150 | loss 2.0520 | lr 3.64e-04 | grad 3.12 | tok/s 15653
step   2160 | loss 1.7637 | lr 3.64e-04 | grad 2.23 | tok/s 15594
step   2170 | loss 1.7515 | lr 3.64e-04 | grad 1.95 | tok/s 15654
step   2180 | loss 1.5114 | lr 3.64e-04 | grad 2.00 | tok/s 16093
step   2190 | loss 1.8832 | lr 3.64e-04 | grad 2.67 | tok/s 15407
step   2200 | loss 1.5806 | lr 3.64e-04 | grad 1.22 | tok/s 16152
step   2210 | loss 1.8404 | lr 3.64e-04 | grad 1.20 | tok/s 15610
step   2220 | loss 1.7114 | lr 3.64e-04 | grad 1.88 | tok/s 15105
step   2230 | loss 1.8932 | lr 3.64e-04 | grad 2.02 | tok/s 15417
step   2240 | loss 1.6026 | lr 3.64e-04 | grad 2.42 | tok/s 15684
step   2250 | loss 1.6390 | lr 3.64e-04 | grad 2.00 | tok/s 15385
step   2260 | loss 1.8307 | lr 3.64e-04 | grad 1.88 | tok/s 15671
step   2270 | loss 2.0082 | lr 3.64e-04 | grad 1.68 | tok/s 15043
step   2280 | loss 1.6603 | lr 3.64e-04 | grad 1.68 | tok/s 15485
step   2290 | loss 1.5198 | lr 3.64e-04 | grad 2.47 | tok/s 15212
step   2300 | loss 2.1044 | lr 3.64e-04 | grad 2.50 | tok/s 15312
step   2310 | loss 1.6400 | lr 3.64e-04 | grad 1.96 | tok/s 15710
step   2320 | loss 1.6475 | lr 3.64e-04 | grad 2.38 | tok/s 16165
step   2330 | loss 1.5902 | lr 3.64e-04 | grad 2.69 | tok/s 16147
step   2340 | loss 1.5571 | lr 3.64e-04 | grad 2.53 | tok/s 16149
step   2350 | loss 1.5201 | lr 3.64e-04 | grad 1.95 | tok/s 16157
step   2360 | loss 1.4815 | lr 3.64e-04 | grad 3.06 | tok/s 16153
step   2370 | loss 1.4667 | lr 3.64e-04 | grad 2.69 | tok/s 16156
step   2380 | loss 1.4384 | lr 3.64e-04 | grad 2.19 | tok/s 16157
step   2390 | loss 1.4654 | lr 3.64e-04 | grad 3.27 | tok/s 16146
step   2400 | loss 1.4266 | lr 3.64e-04 | grad 2.42 | tok/s 16147
step   2410 | loss 1.6429 | lr 3.64e-04 | grad 4.72 | tok/s 15926
step   2420 | loss 1.5405 | lr 3.64e-04 | grad 0.64 | tok/s 15852
step   2430 | loss 1.4435 | lr 3.64e-04 | grad 1.96 | tok/s 15246
step   2440 | loss 1.6692 | lr 3.64e-04 | grad 1.94 | tok/s 15080
step   2450 | loss 1.6140 | lr 3.64e-04 | grad 2.73 | tok/s 15635
step   2460 | loss 1.8056 | lr 3.64e-04 | grad 2.41 | tok/s 15838
step   2470 | loss 1.5887 | lr 3.64e-04 | grad 1.95 | tok/s 15409
step   2480 | loss 1.7803 | lr 3.64e-04 | grad 2.39 | tok/s 15812
step   2490 | loss 1.8170 | lr 3.64e-04 | grad 1.97 | tok/s 15365
step   2500 | loss 1.8943 | lr 3.64e-04 | grad 2.00 | tok/s 15757
step   2510 | loss 1.7412 | lr 3.64e-04 | grad 2.38 | tok/s 15591
step   2520 | loss 1.6838 | lr 3.64e-04 | grad 1.64 | tok/s 15359
step   2530 | loss 1.8346 | lr 3.64e-04 | grad 1.91 | tok/s 15708
step   2540 | loss 1.7120 | lr 3.64e-04 | grad 5.31 | tok/s 14994
step   2550 | loss 1.5755 | lr 3.64e-04 | grad 1.62 | tok/s 15507
step   2560 | loss 1.8862 | lr 3.64e-04 | grad 1.89 | tok/s 15267
step   2570 | loss 1.6364 | lr 3.64e-04 | grad 2.53 | tok/s 15443
step   2580 | loss 1.9595 | lr 3.64e-04 | grad 2.56 | tok/s 15382
step   2590 | loss 1.5943 | lr 3.64e-04 | grad 1.67 | tok/s 15059
step   2600 | loss 1.7419 | lr 3.64e-04 | grad 1.44 | tok/s 15482
step   2610 | loss 1.7164 | lr 3.64e-04 | grad 2.30 | tok/s 15833
step   2620 | loss 1.8546 | lr 3.64e-04 | grad 2.14 | tok/s 15331
step   2630 | loss 1.4427 | lr 3.64e-04 | grad 2.02 | tok/s 15864
step   2640 | loss 1.6469 | lr 3.64e-04 | grad 2.05 | tok/s 15294
step   2650 | loss 1.5305 | lr 3.64e-04 | grad 3.41 | tok/s 15617
step   2660 | loss 1.6153 | lr 3.64e-04 | grad 1.69 | tok/s 15709
step   2670 | loss 1.5472 | lr 3.64e-04 | grad 2.03 | tok/s 15629
step   2680 | loss 1.6821 | lr 3.64e-04 | grad 1.72 | tok/s 15331
step   2690 | loss 1.5558 | lr 3.64e-04 | grad 1.80 | tok/s 15062
step   2700 | loss 1.6621 | lr 3.64e-04 | grad 1.45 | tok/s 15567
step   2710 | loss 1.9930 | lr 3.64e-04 | grad 1.89 | tok/s 15438
step   2720 | loss 1.6941 | lr 3.64e-04 | grad 1.62 | tok/s 15686
step   2730 | loss 1.5888 | lr 3.64e-04 | grad 3.41 | tok/s 15449
step   2740 | loss 1.7152 | lr 3.64e-04 | grad 1.89 | tok/s 15404
step   2750 | loss 1.7234 | lr 3.64e-04 | grad 2.00 | tok/s 15654
step   2760 | loss 1.4903 | lr 3.64e-04 | grad 1.88 | tok/s 15791
step   2770 | loss 1.7003 | lr 3.64e-04 | grad 2.47 | tok/s 15545
step   2780 | loss 1.6006 | lr 3.64e-04 | grad 3.53 | tok/s 15803
step   2790 | loss 1.7387 | lr 3.64e-04 | grad 3.80 | tok/s 15390
step   2800 | loss 1.7064 | lr 3.64e-04 | grad 2.05 | tok/s 14975
step   2810 | loss 1.7298 | lr 3.64e-04 | grad 2.16 | tok/s 15548
step   2820 | loss 1.6065 | lr 3.64e-04 | grad 2.56 | tok/s 14577
step   2830 | loss 1.4923 | lr 3.64e-04 | grad 1.98 | tok/s 15462
step   2840 | loss 1.4431 | lr 3.64e-04 | grad 2.33 | tok/s 15277
step   2850 | loss 1.4471 | lr 3.64e-04 | grad 2.06 | tok/s 16149
step   2860 | loss 1.4840 | lr 3.64e-04 | grad 2.70 | tok/s 15711
step   2870 | loss 1.6604 | lr 3.64e-04 | grad 2.00 | tok/s 15304
step   2880 | loss 1.6694 | lr 3.64e-04 | grad 1.80 | tok/s 15151
step   2890 | loss 1.8322 | lr 3.64e-04 | grad 3.67 | tok/s 15627
step   2900 | loss 1.6826 | lr 3.64e-04 | grad 3.45 | tok/s 15122
step   2910 | loss 1.6781 | lr 3.64e-04 | grad 1.98 | tok/s 15889
step   2920 | loss 1.5029 | lr 3.64e-04 | grad 3.39 | tok/s 15313
step   2930 | loss 1.6716 | lr 3.64e-04 | grad 2.45 | tok/s 15786
step   2940 | loss 1.5619 | lr 3.64e-04 | grad 2.27 | tok/s 15461
step   2950 | loss 1.9910 | lr 3.64e-04 | grad 1.93 | tok/s 15578
step   2960 | loss 1.8051 | lr 3.64e-04 | grad 2.14 | tok/s 15032
step   2970 | loss 1.7446 | lr 3.64e-04 | grad 1.85 | tok/s 15575
step   2980 | loss 1.6105 | lr 3.64e-04 | grad 1.55 | tok/s 15767
step   2990 | loss 1.8374 | lr 3.64e-04 | grad 2.55 | tok/s 15665
step   3000 | loss 1.5895 | lr 3.64e-04 | grad 2.39 | tok/s 15719
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5895.pt
step   3010 | loss 1.7251 | lr 3.64e-04 | grad 3.33 | tok/s 10037
step   3020 | loss 1.5774 | lr 3.64e-04 | grad 1.41 | tok/s 15416
step   3030 | loss 1.5632 | lr 3.64e-04 | grad 1.36 | tok/s 15130
step   3040 | loss 1.5813 | lr 3.64e-04 | grad 2.44 | tok/s 15632
step   3050 | loss 1.4733 | lr 3.64e-04 | grad 1.66 | tok/s 16090
step   3060 | loss 1.7532 | lr 3.64e-04 | grad 2.73 | tok/s 15803
step   3070 | loss 2.2231 | lr 3.64e-04 | grad 6.59 | tok/s 15486
step   3080 | loss 1.7603 | lr 3.64e-04 | grad 2.38 | tok/s 15612
step   3090 | loss 1.6553 | lr 3.64e-04 | grad 2.25 | tok/s 15030
step   3100 | loss 1.5301 | lr 3.64e-04 | grad 2.30 | tok/s 15669
step   3110 | loss 1.7515 | lr 3.64e-04 | grad 3.42 | tok/s 16006
step   3120 | loss 1.6561 | lr 3.64e-04 | grad 2.47 | tok/s 15357
step   3130 | loss 1.5840 | lr 3.64e-04 | grad 1.86 | tok/s 15154
step   3140 | loss 1.5055 | lr 3.64e-04 | grad 3.05 | tok/s 15440
step   3150 | loss 1.5768 | lr 3.64e-04 | grad 1.91 | tok/s 14729
step   3160 | loss 1.7576 | lr 3.64e-04 | grad 2.52 | tok/s 16065
step   3170 | loss 1.4645 | lr 3.64e-04 | grad 0.86 | tok/s 15909
step   3180 | loss 1.4670 | lr 3.64e-04 | grad 2.08 | tok/s 15837
step   3190 | loss 1.7745 | lr 3.64e-04 | grad 2.39 | tok/s 15774
step   3200 | loss 1.4994 | lr 3.64e-04 | grad 1.66 | tok/s 15569
step   3210 | loss 1.6964 | lr 3.64e-04 | grad 1.99 | tok/s 15650
step   3220 | loss 1.5102 | lr 3.64e-04 | grad 2.61 | tok/s 16005
step   3230 | loss 1.6263 | lr 3.64e-04 | grad 1.80 | tok/s 15059
step   3240 | loss 1.5332 | lr 3.64e-04 | grad 1.73 | tok/s 14953
step   3250 | loss 1.5815 | lr 3.64e-04 | grad 2.53 | tok/s 15279
step   3260 | loss 1.6456 | lr 3.64e-04 | grad 1.41 | tok/s 15508
step   3270 | loss 1.5679 | lr 3.64e-04 | grad 2.17 | tok/s 15133
step   3280 | loss 1.7253 | lr 3.64e-04 | grad 1.81 | tok/s 15518
step   3290 | loss 1.5004 | lr 3.64e-04 | grad 1.83 | tok/s 15579
step   3300 | loss 1.8205 | lr 3.64e-04 | grad 2.59 | tok/s 16066
step   3310 | loss 2.1017 | lr 3.64e-04 | grad 5.38 | tok/s 15656
step   3320 | loss 1.8073 | lr 3.64e-04 | grad 1.84 | tok/s 15532
step   3330 | loss 1.5116 | lr 3.64e-04 | grad 2.25 | tok/s 15008
step   3340 | loss 1.3975 | lr 3.64e-04 | grad 1.22 | tok/s 16034
step   3350 | loss 1.7840 | lr 3.64e-04 | grad 2.19 | tok/s 15965
step   3360 | loss 1.6805 | lr 3.64e-04 | grad 1.99 | tok/s 15326
step   3370 | loss 1.7920 | lr 3.64e-04 | grad 2.55 | tok/s 15301
step   3380 | loss 1.5918 | lr 3.64e-04 | grad 1.70 | tok/s 15567
step   3390 | loss 1.5611 | lr 3.64e-04 | grad 1.98 | tok/s 15316
step   3400 | loss 1.6791 | lr 3.64e-04 | grad 2.44 | tok/s 15546
step   3410 | loss 1.7498 | lr 3.64e-04 | grad 2.59 | tok/s 15322
step   3420 | loss 1.7684 | lr 3.64e-04 | grad 1.91 | tok/s 15525
step   3430 | loss 1.6277 | lr 3.64e-04 | grad 1.92 | tok/s 15546
step   3440 | loss 1.5938 | lr 3.64e-04 | grad 2.08 | tok/s 15332
step   3450 | loss 1.6466 | lr 3.64e-04 | grad 2.20 | tok/s 15274
step   3460 | loss 1.6183 | lr 3.64e-04 | grad 1.75 | tok/s 15294
step   3470 | loss 1.9263 | lr 3.64e-04 | grad 2.03 | tok/s 15652
step   3480 | loss 1.5078 | lr 3.64e-04 | grad 2.02 | tok/s 15183
step   3490 | loss 1.7644 | lr 3.64e-04 | grad 1.47 | tok/s 15671
step   3500 | loss 1.7822 | lr 3.64e-04 | grad 1.44 | tok/s 14956

Training complete! Final step: 3502
