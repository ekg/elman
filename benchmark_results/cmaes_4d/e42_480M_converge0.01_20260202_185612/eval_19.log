Using device: cuda
Output directory: benchmark_results/cmaes_4d/e42_480M_converge0.01_20260202_185612/eval_19/level42_100m_20260202_195700
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 825,538,560 parameters
Using schedule-free AdamW (lr=5.110150713619061e-05)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 5.6082 | lr 5.11e-05 | grad 18.12 | tok/s 3995
step     20 | loss 2.8237 | lr 5.11e-05 | grad 11.00 | tok/s 6544
step     30 | loss 2.5979 | lr 5.11e-05 | grad 10.06 | tok/s 6586
step     40 | loss 2.3993 | lr 5.11e-05 | grad 9.38 | tok/s 6281
step     50 | loss 3.0951 | lr 5.11e-05 | grad 21.88 | tok/s 6361
step     60 | loss 2.1886 | lr 5.11e-05 | grad 7.31 | tok/s 6551
step     70 | loss 2.1128 | lr 5.11e-05 | grad 9.38 | tok/s 6633
step     80 | loss 4.9392 | lr 5.11e-05 | grad 27.12 | tok/s 6674
step     90 | loss 4.4819 | lr 5.11e-05 | grad 10.06 | tok/s 6787
step    100 | loss 3.6941 | lr 5.11e-05 | grad 9.62 | tok/s 6782
step    110 | loss 3.4417 | lr 5.11e-05 | grad 24.62 | tok/s 6779
step    120 | loss 3.1248 | lr 5.11e-05 | grad 36.75 | tok/s 6772
step    130 | loss 2.9625 | lr 5.11e-05 | grad 15.06 | tok/s 6766
step    140 | loss 2.5838 | lr 5.11e-05 | grad 10.75 | tok/s 6767
step    150 | loss 2.7130 | lr 5.11e-05 | grad 17.12 | tok/s 6762
step    160 | loss 2.3587 | lr 5.11e-05 | grad 18.00 | tok/s 6762
step    170 | loss 2.4336 | lr 5.11e-05 | grad 17.62 | tok/s 6759
step    180 | loss 2.2330 | lr 5.11e-05 | grad 11.94 | tok/s 6756
step    190 | loss 2.4137 | lr 5.11e-05 | grad 12.12 | tok/s 6754
step    200 | loss 2.1710 | lr 5.11e-05 | grad 9.00 | tok/s 6745
step    210 | loss 2.1611 | lr 5.11e-05 | grad 11.44 | tok/s 6746
step    220 | loss 2.3866 | lr 5.11e-05 | grad 7.22 | tok/s 6661
step    230 | loss 3.0662 | lr 5.11e-05 | grad 9.44 | tok/s 6581
step    240 | loss 2.4476 | lr 5.11e-05 | grad 7.06 | tok/s 6248
step    250 | loss 2.2545 | lr 5.11e-05 | grad 5.66 | tok/s 6424
step    260 | loss 1.9142 | lr 5.11e-05 | grad 5.66 | tok/s 6625
step    270 | loss 2.2886 | lr 5.11e-05 | grad 5.91 | tok/s 6539
step    280 | loss 2.4927 | lr 5.11e-05 | grad 6.09 | tok/s 6413
step    290 | loss 2.2613 | lr 5.11e-05 | grad 6.97 | tok/s 6750
step    300 | loss 1.0957 | lr 5.11e-05 | grad 6.06 | tok/s 6739
step    310 | loss 2.9581 | lr 5.11e-05 | grad 8.25 | tok/s 6631
step    320 | loss 2.4917 | lr 5.11e-05 | grad 12.31 | tok/s 6499
step    330 | loss 2.1938 | lr 5.11e-05 | grad 5.00 | tok/s 6271
step    340 | loss 2.4467 | lr 5.11e-05 | grad 4.41 | tok/s 6374
step    350 | loss 2.2184 | lr 5.11e-05 | grad 5.38 | tok/s 6534
step    360 | loss 2.0875 | lr 5.11e-05 | grad 10.94 | tok/s 6676
step    370 | loss 2.0942 | lr 5.11e-05 | grad 4.81 | tok/s 6054
step    380 | loss 2.0221 | lr 5.11e-05 | grad 4.75 | tok/s 6448
step    390 | loss 1.8154 | lr 5.11e-05 | grad 4.59 | tok/s 6736
step    400 | loss 1.8077 | lr 5.11e-05 | grad 5.19 | tok/s 6676
step    410 | loss 1.7059 | lr 5.11e-05 | grad 3.42 | tok/s 6528
step    420 | loss 2.0358 | lr 5.11e-05 | grad 7.59 | tok/s 6236
step    430 | loss 2.3714 | lr 5.11e-05 | grad 4.75 | tok/s 6635
step    440 | loss 2.3751 | lr 5.11e-05 | grad 5.66 | tok/s 6270
step    450 | loss 2.3025 | lr 5.11e-05 | grad 3.78 | tok/s 6485
step    460 | loss 2.0600 | lr 5.11e-05 | grad 6.88 | tok/s 6352
step    470 | loss 2.1073 | lr 5.11e-05 | grad 4.38 | tok/s 6550
step    480 | loss 2.5832 | lr 5.11e-05 | grad 10.50 | tok/s 6551
step    490 | loss 2.0324 | lr 5.11e-05 | grad 3.77 | tok/s 6192
step    500 | loss 1.9855 | lr 5.11e-05 | grad 5.91 | tok/s 6610
step    510 | loss 1.9781 | lr 5.11e-05 | grad 3.81 | tok/s 6702
step    520 | loss 1.9907 | lr 5.11e-05 | grad 3.39 | tok/s 6689
step    530 | loss 2.2170 | lr 5.11e-05 | grad 3.62 | tok/s 6429
step    540 | loss 1.9574 | lr 5.11e-05 | grad 3.97 | tok/s 6432
step    550 | loss 1.7902 | lr 5.11e-05 | grad 4.84 | tok/s 6293
step    560 | loss 1.9775 | lr 5.11e-05 | grad 4.00 | tok/s 6133
step    570 | loss 1.9217 | lr 5.11e-05 | grad 5.94 | tok/s 6295
step    580 | loss 1.8156 | lr 5.11e-05 | grad 4.16 | tok/s 6279
step    590 | loss 2.1713 | lr 5.11e-05 | grad 5.03 | tok/s 6443
step    600 | loss 2.0537 | lr 5.11e-05 | grad 3.95 | tok/s 6223
step    610 | loss 1.8944 | lr 5.11e-05 | grad 3.39 | tok/s 6540
step    620 | loss 1.7575 | lr 5.11e-05 | grad 3.88 | tok/s 6197
step    630 | loss 1.9241 | lr 5.11e-05 | grad 6.25 | tok/s 6249
step    640 | loss 2.0858 | lr 5.11e-05 | grad 4.41 | tok/s 6418
step    650 | loss 1.9021 | lr 5.11e-05 | grad 4.34 | tok/s 6450
step    660 | loss 1.9576 | lr 5.11e-05 | grad 3.25 | tok/s 6478
step    670 | loss 2.2060 | lr 5.11e-05 | grad 20.75 | tok/s 6517
step    680 | loss 1.9492 | lr 5.11e-05 | grad 3.97 | tok/s 6393
step    690 | loss 2.2273 | lr 5.11e-05 | grad 5.50 | tok/s 6610
step    700 | loss 1.9415 | lr 5.11e-05 | grad 5.03 | tok/s 6745
step    710 | loss 1.8449 | lr 5.11e-05 | grad 3.56 | tok/s 6292
step    720 | loss 1.6891 | lr 5.11e-05 | grad 4.62 | tok/s 6200
step    730 | loss 1.7018 | lr 5.11e-05 | grad 4.97 | tok/s 6726
step    740 | loss 1.8561 | lr 5.11e-05 | grad 4.69 | tok/s 6638
step    750 | loss 1.6186 | lr 5.11e-05 | grad 4.12 | tok/s 6740
step    760 | loss 1.4683 | lr 5.11e-05 | grad 4.06 | tok/s 6739
step    770 | loss 1.4300 | lr 5.11e-05 | grad 3.53 | tok/s 6744
step    780 | loss 1.3827 | lr 5.11e-05 | grad 3.44 | tok/s 6745
step    790 | loss 1.4568 | lr 5.11e-05 | grad 5.81 | tok/s 6530
step    800 | loss 2.2106 | lr 5.11e-05 | grad 8.56 | tok/s 6505
step    810 | loss 1.9301 | lr 5.11e-05 | grad 3.86 | tok/s 6475
step    820 | loss 1.9388 | lr 5.11e-05 | grad 6.34 | tok/s 6218
step    830 | loss 1.9677 | lr 5.11e-05 | grad 4.59 | tok/s 6670
step    840 | loss 1.8241 | lr 5.11e-05 | grad 3.81 | tok/s 6733
step    850 | loss 1.8333 | lr 5.11e-05 | grad 3.70 | tok/s 6703
step    860 | loss 1.8661 | lr 5.11e-05 | grad 6.38 | tok/s 6631
step    870 | loss 1.7811 | lr 5.11e-05 | grad 4.66 | tok/s 6396
step    880 | loss 1.9718 | lr 5.11e-05 | grad 4.59 | tok/s 6420
step    890 | loss 1.9160 | lr 5.11e-05 | grad 5.28 | tok/s 6512
step    900 | loss 1.8102 | lr 5.11e-05 | grad 4.28 | tok/s 6519
step    910 | loss 1.6554 | lr 5.11e-05 | grad 5.62 | tok/s 6380
step    920 | loss 1.8452 | lr 5.11e-05 | grad 6.56 | tok/s 6630
step    930 | loss 1.8334 | lr 5.11e-05 | grad 6.03 | tok/s 6332
step    940 | loss 1.7388 | lr 5.11e-05 | grad 4.03 | tok/s 6672
step    950 | loss 1.8259 | lr 5.11e-05 | grad 4.56 | tok/s 6702
step    960 | loss 1.7039 | lr 5.11e-05 | grad 4.78 | tok/s 6716
step    970 | loss 1.9300 | lr 5.11e-05 | grad 5.22 | tok/s 6316
step    980 | loss 1.8586 | lr 5.11e-05 | grad 3.91 | tok/s 6484
step    990 | loss 1.7599 | lr 5.11e-05 | grad 3.78 | tok/s 6591
step   1000 | loss 2.1304 | lr 5.11e-05 | grad 20.62 | tok/s 6334
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1304.pt
step   1010 | loss 1.9367 | lr 5.11e-05 | grad 4.94 | tok/s 2901
step   1020 | loss 1.7756 | lr 5.11e-05 | grad 4.09 | tok/s 6146
step   1030 | loss 1.6734 | lr 5.11e-05 | grad 5.16 | tok/s 6672
step   1040 | loss 1.7164 | lr 5.11e-05 | grad 3.67 | tok/s 6354
step   1050 | loss 1.8735 | lr 5.11e-05 | grad 3.78 | tok/s 6501
step   1060 | loss 2.0017 | lr 5.11e-05 | grad 5.25 | tok/s 6665
step   1070 | loss 1.9523 | lr 5.11e-05 | grad 5.81 | tok/s 6411
step   1080 | loss 1.6294 | lr 5.11e-05 | grad 4.16 | tok/s 6140
step   1090 | loss 1.2952 | lr 5.11e-05 | grad 5.75 | tok/s 6640
step   1100 | loss 1.7739 | lr 5.11e-05 | grad 4.12 | tok/s 6572
step   1110 | loss 1.6140 | lr 5.11e-05 | grad 3.69 | tok/s 6759
step   1120 | loss 1.5875 | lr 5.11e-05 | grad 4.03 | tok/s 6751
step   1130 | loss 1.4916 | lr 5.11e-05 | grad 3.72 | tok/s 6744
step   1140 | loss 1.5289 | lr 5.11e-05 | grad 4.22 | tok/s 6745
step   1150 | loss 1.5063 | lr 5.11e-05 | grad 3.70 | tok/s 6748
step   1160 | loss 1.4327 | lr 5.11e-05 | grad 3.84 | tok/s 6745
step   1170 | loss 1.5239 | lr 5.11e-05 | grad 3.67 | tok/s 6741
step   1180 | loss 1.5536 | lr 5.11e-05 | grad 4.12 | tok/s 6746
step   1190 | loss 1.4261 | lr 5.11e-05 | grad 4.59 | tok/s 6738
step   1200 | loss 1.4879 | lr 5.11e-05 | grad 4.06 | tok/s 6735
step   1210 | loss 1.4964 | lr 5.11e-05 | grad 3.69 | tok/s 6740
step   1220 | loss 1.4446 | lr 5.11e-05 | grad 3.89 | tok/s 6741
step   1230 | loss 1.4775 | lr 5.11e-05 | grad 3.66 | tok/s 6737
step   1240 | loss 1.7431 | lr 5.11e-05 | grad 11.44 | tok/s 6499
step   1250 | loss 1.8843 | lr 5.11e-05 | grad 3.97 | tok/s 6296
step   1260 | loss 1.7066 | lr 5.11e-05 | grad 5.62 | tok/s 6491
step   1270 | loss 1.8966 | lr 5.11e-05 | grad 6.84 | tok/s 6243
step   1280 | loss 1.7713 | lr 5.11e-05 | grad 3.80 | tok/s 6566
step   1290 | loss 1.7179 | lr 5.11e-05 | grad 4.19 | tok/s 6558
step   1300 | loss 1.7373 | lr 5.11e-05 | grad 5.47 | tok/s 6387
step   1310 | loss 1.7102 | lr 5.11e-05 | grad 4.03 | tok/s 6652
step   1320 | loss 1.9502 | lr 5.11e-05 | grad 6.38 | tok/s 6647
step   1330 | loss 1.5970 | lr 5.11e-05 | grad 4.34 | tok/s 6495
step   1340 | loss 1.9284 | lr 5.11e-05 | grad 9.44 | tok/s 6109
step   1350 | loss 1.8949 | lr 5.11e-05 | grad 4.91 | tok/s 6372
step   1360 | loss 1.6473 | lr 5.11e-05 | grad 4.44 | tok/s 6360
step   1370 | loss 1.8983 | lr 5.11e-05 | grad 6.91 | tok/s 6587
step   1380 | loss 1.7245 | lr 5.11e-05 | grad 3.78 | tok/s 6096
step   1390 | loss 1.6111 | lr 5.11e-05 | grad 4.31 | tok/s 6380
step   1400 | loss 1.6821 | lr 5.11e-05 | grad 6.28 | tok/s 6477
step   1410 | loss 1.8369 | lr 5.11e-05 | grad 5.47 | tok/s 6267
step   1420 | loss 1.8684 | lr 5.11e-05 | grad 5.12 | tok/s 6479
step   1430 | loss 1.5433 | lr 5.11e-05 | grad 4.75 | tok/s 6406
step   1440 | loss 1.3628 | lr 5.11e-05 | grad 4.25 | tok/s 6739
step   1450 | loss 1.6711 | lr 5.11e-05 | grad 5.59 | tok/s 6576
step   1460 | loss 1.8265 | lr 5.11e-05 | grad 4.34 | tok/s 6294
step   1470 | loss 1.7149 | lr 5.11e-05 | grad 5.16 | tok/s 6602
step   1480 | loss 2.4769 | lr 5.11e-05 | grad 11.44 | tok/s 6740
step   1490 | loss 1.8479 | lr 5.11e-05 | grad 5.09 | tok/s 6699
step   1500 | loss 1.4918 | lr 5.11e-05 | grad 4.88 | tok/s 6652
step   1510 | loss 1.8631 | lr 5.11e-05 | grad 4.31 | tok/s 6734
step   1520 | loss 1.6668 | lr 5.11e-05 | grad 4.72 | tok/s 6514
step   1530 | loss 1.6580 | lr 5.11e-05 | grad 9.31 | tok/s 6443
step   1540 | loss 1.8293 | lr 5.11e-05 | grad 4.12 | tok/s 6500
step   1550 | loss 1.4785 | lr 5.11e-05 | grad 5.28 | tok/s 6659
step   1560 | loss 1.8116 | lr 5.11e-05 | grad 3.80 | tok/s 6373
step   1570 | loss 1.6830 | lr 5.11e-05 | grad 4.66 | tok/s 6675
step   1580 | loss 2.2952 | lr 5.11e-05 | grad 6.22 | tok/s 6637
step   1590 | loss 1.6270 | lr 5.11e-05 | grad 3.69 | tok/s 6340
step   1600 | loss 0.9618 | lr 5.11e-05 | grad 5.00 | tok/s 6788
step   1610 | loss 1.4831 | lr 5.11e-05 | grad 3.83 | tok/s 6103
step   1620 | loss 1.8886 | lr 5.11e-05 | grad 9.25 | tok/s 6403
step   1630 | loss 1.4968 | lr 5.11e-05 | grad 3.81 | tok/s 6666
step   1640 | loss 1.7474 | lr 5.11e-05 | grad 4.44 | tok/s 6280
step   1650 | loss 1.7549 | lr 5.11e-05 | grad 4.22 | tok/s 6100
step   1660 | loss 1.5091 | lr 5.11e-05 | grad 3.89 | tok/s 6751
step   1670 | loss 2.0284 | lr 5.11e-05 | grad 6.06 | tok/s 6241
step   1680 | loss 1.6915 | lr 5.11e-05 | grad 4.53 | tok/s 6274
step   1690 | loss 1.8094 | lr 5.11e-05 | grad 8.00 | tok/s 6639
step   1700 | loss 1.6935 | lr 5.11e-05 | grad 4.69 | tok/s 6340
step   1710 | loss 1.7276 | lr 5.11e-05 | grad 5.31 | tok/s 6569
step   1720 | loss 1.8916 | lr 5.11e-05 | grad 4.16 | tok/s 6751
step   1730 | loss 1.7164 | lr 5.11e-05 | grad 5.50 | tok/s 6751
step   1740 | loss 1.7093 | lr 5.11e-05 | grad 5.38 | tok/s 6464
step   1750 | loss 1.7608 | lr 5.11e-05 | grad 4.28 | tok/s 6481
step   1760 | loss 1.7757 | lr 5.11e-05 | grad 4.25 | tok/s 6500
step   1770 | loss 1.6338 | lr 5.11e-05 | grad 4.03 | tok/s 6406
step   1780 | loss 1.6667 | lr 5.11e-05 | grad 5.09 | tok/s 6560
step   1790 | loss 1.6597 | lr 5.11e-05 | grad 4.97 | tok/s 6463
step   1800 | loss 1.8058 | lr 5.11e-05 | grad 6.31 | tok/s 6363
step   1810 | loss 1.6475 | lr 5.11e-05 | grad 5.12 | tok/s 6363
step   1820 | loss 1.7027 | lr 5.11e-05 | grad 6.97 | tok/s 6575
step   1830 | loss 1.6631 | lr 5.11e-05 | grad 5.59 | tok/s 6491
step   1840 | loss 1.6884 | lr 5.11e-05 | grad 4.47 | tok/s 6382
step   1850 | loss 1.5370 | lr 5.11e-05 | grad 5.22 | tok/s 6605
step   1860 | loss 1.6543 | lr 5.11e-05 | grad 5.53 | tok/s 6341
step   1870 | loss 1.4250 | lr 5.11e-05 | grad 3.33 | tok/s 6647
step   1880 | loss 1.7461 | lr 5.11e-05 | grad 6.84 | tok/s 5964
step   1890 | loss 1.6169 | lr 5.11e-05 | grad 4.06 | tok/s 6390
step   1900 | loss 1.5597 | lr 5.11e-05 | grad 3.95 | tok/s 6343
step   1910 | loss 1.6523 | lr 5.11e-05 | grad 3.80 | tok/s 6309
step   1920 | loss 1.5931 | lr 5.11e-05 | grad 4.03 | tok/s 6656
step   1930 | loss 1.6217 | lr 5.11e-05 | grad 3.95 | tok/s 6305
step   1940 | loss 1.9113 | lr 5.11e-05 | grad 9.00 | tok/s 6640
step   1950 | loss 2.2195 | lr 5.11e-05 | grad 8.94 | tok/s 6759
step   1960 | loss 1.8538 | lr 5.11e-05 | grad 5.34 | tok/s 6594
step   1970 | loss 1.9259 | lr 5.11e-05 | grad 9.44 | tok/s 6629
step   1980 | loss 1.5732 | lr 5.11e-05 | grad 4.97 | tok/s 6396
step   1990 | loss 1.8231 | lr 5.11e-05 | grad 4.41 | tok/s 6364
step   2000 | loss 1.6487 | lr 5.11e-05 | grad 4.50 | tok/s 6529
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6487.pt
step   2010 | loss 1.4655 | lr 5.11e-05 | grad 3.92 | tok/s 2990
step   2020 | loss 1.5117 | lr 5.11e-05 | grad 4.25 | tok/s 6741
step   2030 | loss 1.3168 | lr 5.11e-05 | grad 4.69 | tok/s 6840
step   2040 | loss 1.5858 | lr 5.11e-05 | grad 5.31 | tok/s 6792
step   2050 | loss 1.7224 | lr 5.11e-05 | grad 4.94 | tok/s 6133
step   2060 | loss 1.8819 | lr 5.11e-05 | grad 5.25 | tok/s 6641
step   2070 | loss 2.2484 | lr 5.11e-05 | grad 7.41 | tok/s 6573
step   2080 | loss 2.0466 | lr 5.11e-05 | grad 4.94 | tok/s 6767
step   2090 | loss 1.6808 | lr 5.11e-05 | grad 4.91 | tok/s 6537
step   2100 | loss 1.7610 | lr 5.11e-05 | grad 5.03 | tok/s 6472
step   2110 | loss 1.3784 | lr 5.11e-05 | grad 4.31 | tok/s 6624
step   2120 | loss 0.9977 | lr 5.11e-05 | grad 5.75 | tok/s 6726
step   2130 | loss 1.8492 | lr 5.11e-05 | grad 4.22 | tok/s 6379
step   2140 | loss 1.4826 | lr 5.11e-05 | grad 3.97 | tok/s 6762
step   2150 | loss 1.3936 | lr 5.11e-05 | grad 3.58 | tok/s 6759
step   2160 | loss 1.4014 | lr 5.11e-05 | grad 4.22 | tok/s 6758
step   2170 | loss 1.3822 | lr 5.11e-05 | grad 3.78 | tok/s 6754
step   2180 | loss 1.3894 | lr 5.11e-05 | grad 3.62 | tok/s 6757
step   2190 | loss 1.3803 | lr 5.11e-05 | grad 3.84 | tok/s 6758
step   2200 | loss 1.3146 | lr 5.11e-05 | grad 3.89 | tok/s 6754
step   2210 | loss 1.3279 | lr 5.11e-05 | grad 3.95 | tok/s 6749
step   2220 | loss 1.4491 | lr 5.11e-05 | grad 5.81 | tok/s 6687
step   2230 | loss 1.6133 | lr 5.11e-05 | grad 3.59 | tok/s 6686
step   2240 | loss 1.8169 | lr 5.11e-05 | grad 6.69 | tok/s 6520
step   2250 | loss 1.8942 | lr 5.11e-05 | grad 8.00 | tok/s 6616
step   2260 | loss 2.0203 | lr 5.11e-05 | grad 12.12 | tok/s 6654
step   2270 | loss 1.8842 | lr 5.11e-05 | grad 6.50 | tok/s 6677
step   2280 | loss 1.5698 | lr 5.11e-05 | grad 3.91 | tok/s 6756
step   2290 | loss 2.2775 | lr 5.11e-05 | grad 11.75 | tok/s 6412
step   2300 | loss 1.6913 | lr 5.11e-05 | grad 8.50 | tok/s 6315
step   2310 | loss 1.7911 | lr 5.11e-05 | grad 16.38 | tok/s 6520
step   2320 | loss 2.0988 | lr 5.11e-05 | grad 4.31 | tok/s 6269
step   2330 | loss 1.5594 | lr 5.11e-05 | grad 4.66 | tok/s 6327
step   2340 | loss 1.6247 | lr 5.11e-05 | grad 3.72 | tok/s 6614
step   2350 | loss 1.5911 | lr 5.11e-05 | grad 4.16 | tok/s 6615
step   2360 | loss 1.6357 | lr 5.11e-05 | grad 7.84 | tok/s 6608
step   2370 | loss 1.9387 | lr 5.11e-05 | grad 7.12 | tok/s 6759
step   2380 | loss 1.5710 | lr 5.11e-05 | grad 5.09 | tok/s 6739
step   2390 | loss 1.3491 | lr 5.11e-05 | grad 4.06 | tok/s 6751
step   2400 | loss 1.2161 | lr 5.11e-05 | grad 6.16 | tok/s 6686
step   2410 | loss 1.5993 | lr 5.11e-05 | grad 7.97 | tok/s 6281
step   2420 | loss 1.6886 | lr 5.11e-05 | grad 4.81 | tok/s 6367
step   2430 | loss 1.3944 | lr 5.11e-05 | grad 5.16 | tok/s 6643
step   2440 | loss 1.6428 | lr 5.11e-05 | grad 5.00 | tok/s 6388
step   2450 | loss 1.6412 | lr 5.11e-05 | grad 4.19 | tok/s 6676
step   2460 | loss 1.3213 | lr 5.11e-05 | grad 5.66 | tok/s 6709
step   2470 | loss 1.5007 | lr 5.11e-05 | grad 5.91 | tok/s 6709
step   2480 | loss 1.4553 | lr 5.11e-05 | grad 6.41 | tok/s 6391
step   2490 | loss 1.7097 | lr 5.11e-05 | grad 8.06 | tok/s 6607
step   2500 | loss 1.6355 | lr 5.11e-05 | grad 5.09 | tok/s 6748
step   2510 | loss 1.5395 | lr 5.11e-05 | grad 6.38 | tok/s 6753
step   2520 | loss 1.6727 | lr 5.11e-05 | grad 3.70 | tok/s 6575
step   2530 | loss 1.5048 | lr 5.11e-05 | grad 6.00 | tok/s 6353
step   2540 | loss 1.5402 | lr 5.11e-05 | grad 4.22 | tok/s 6719
step   2550 | loss 1.3832 | lr 5.11e-05 | grad 11.56 | tok/s 6297
step   2560 | loss 1.8807 | lr 5.11e-05 | grad 3.94 | tok/s 6561
step   2570 | loss 1.5026 | lr 5.11e-05 | grad 5.50 | tok/s 6151
step   2580 | loss 1.5963 | lr 5.11e-05 | grad 7.00 | tok/s 6660
step   2590 | loss 1.6889 | lr 5.11e-05 | grad 7.62 | tok/s 6081
step   2600 | loss 1.8919 | lr 5.11e-05 | grad 6.06 | tok/s 6719
step   2610 | loss 1.7576 | lr 5.11e-05 | grad 4.34 | tok/s 6477
step   2620 | loss 1.6520 | lr 5.11e-05 | grad 4.03 | tok/s 6688
step   2630 | loss 1.6602 | lr 5.11e-05 | grad 5.12 | tok/s 6565
step   2640 | loss 1.7944 | lr 5.11e-05 | grad 7.56 | tok/s 6691
step   2650 | loss 1.6352 | lr 5.11e-05 | grad 4.28 | tok/s 6543
step   2660 | loss 1.5234 | lr 5.11e-05 | grad 6.22 | tok/s 6386
step   2670 | loss 1.7559 | lr 5.11e-05 | grad 11.00 | tok/s 6277
step   2680 | loss 1.7096 | lr 5.11e-05 | grad 4.28 | tok/s 6703
step   2690 | loss 1.6004 | lr 5.11e-05 | grad 8.50 | tok/s 6599
step   2700 | loss 1.8493 | lr 5.11e-05 | grad 15.38 | tok/s 6414
step   2710 | loss 1.5718 | lr 5.11e-05 | grad 8.88 | tok/s 6116
step   2720 | loss 1.5189 | lr 5.11e-05 | grad 4.56 | tok/s 6572
step   2730 | loss 1.5896 | lr 5.11e-05 | grad 8.81 | tok/s 6536
step   2740 | loss 2.0880 | lr 5.11e-05 | grad 5.19 | tok/s 6698
step   2750 | loss 1.5370 | lr 5.11e-05 | grad 4.31 | tok/s 6377
step   2760 | loss 1.6816 | lr 5.11e-05 | grad 5.81 | tok/s 6264
step   2770 | loss 1.3966 | lr 5.11e-05 | grad 5.09 | tok/s 6753
step   2780 | loss 1.7184 | lr 5.11e-05 | grad 10.88 | tok/s 6409
step   2790 | loss 1.7390 | lr 5.11e-05 | grad 3.75 | tok/s 6357
step   2800 | loss 1.3868 | lr 5.11e-05 | grad 4.84 | tok/s 6567
step   2810 | loss 1.5676 | lr 5.11e-05 | grad 4.84 | tok/s 6160
step   2820 | loss 1.6163 | lr 5.11e-05 | grad 5.41 | tok/s 6578
step   2830 | loss 1.2003 | lr 5.11e-05 | grad 5.69 | tok/s 6758
step   2840 | loss 1.8926 | lr 5.11e-05 | grad 7.59 | tok/s 6593
step   2850 | loss 1.9252 | lr 5.11e-05 | grad 5.75 | tok/s 6452
step   2860 | loss 1.5362 | lr 5.11e-05 | grad 4.53 | tok/s 6421
step   2870 | loss 1.6418 | lr 5.11e-05 | grad 4.66 | tok/s 6514
step   2880 | loss 1.6416 | lr 5.11e-05 | grad 4.12 | tok/s 6741
step   2890 | loss 1.6367 | lr 5.11e-05 | grad 6.50 | tok/s 6489
step   2900 | loss 1.7056 | lr 5.11e-05 | grad 5.31 | tok/s 6630

Training complete! Final step: 2907
