Using device: cuda
Output directory: benchmark_results/cmaes_e88_tight/e88_480M_20gen_20260126_044421/eval_22/levelE88_100m_20260126_045104
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 476,521,112 parameters
Using schedule-free AdamW (lr=0.0003936063714359485)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 3.0 minutes
step     10 | loss 4.2129 | lr 3.94e-04 | grad 14.56 | tok/s 8463
step     20 | loss 2.9391 | lr 3.94e-04 | grad 6.12 | tok/s 14325
step     30 | loss 3.1451 | lr 3.94e-04 | grad 7.84 | tok/s 15085
step     40 | loss 4.5984 | lr 3.94e-04 | grad 68.50 | tok/s 15358
step     50 | loss 4.9855 | lr 3.94e-04 | grad 22.25 | tok/s 15489
step     60 | loss 3.7329 | lr 3.94e-04 | grad 15.69 | tok/s 15447
step     70 | loss 3.0111 | lr 3.94e-04 | grad 8.06 | tok/s 15412
step     80 | loss 2.6814 | lr 3.94e-04 | grad 6.09 | tok/s 15373
step     90 | loss 2.4282 | lr 3.94e-04 | grad 4.94 | tok/s 15319
step    100 | loss 2.2881 | lr 3.94e-04 | grad 2.91 | tok/s 15309
step    110 | loss 2.2645 | lr 3.94e-04 | grad 3.20 | tok/s 15165
step    120 | loss 2.7324 | lr 3.94e-04 | grad 1.93 | tok/s 14440
step    130 | loss 2.0764 | lr 3.94e-04 | grad 5.81 | tok/s 14531
step    140 | loss 2.3285 | lr 3.94e-04 | grad 6.84 | tok/s 14830
step    150 | loss 1.4050 | lr 3.94e-04 | grad 4.88 | tok/s 15178
step    160 | loss 2.2665 | lr 3.94e-04 | grad 2.16 | tok/s 14666
step    170 | loss 2.2817 | lr 3.94e-04 | grad 1.82 | tok/s 14481
step    180 | loss 1.7434 | lr 3.94e-04 | grad 3.06 | tok/s 14823
step    190 | loss 1.8835 | lr 3.94e-04 | grad 2.55 | tok/s 14552
step    200 | loss 1.6102 | lr 3.94e-04 | grad 1.61 | tok/s 15219
step    210 | loss 1.8666 | lr 3.94e-04 | grad 4.78 | tok/s 14447
step    220 | loss 2.1712 | lr 3.94e-04 | grad 3.27 | tok/s 14616
step    230 | loss 1.9602 | lr 3.94e-04 | grad 2.62 | tok/s 14586
step    240 | loss 2.2439 | lr 3.94e-04 | grad 5.06 | tok/s 14788
step    250 | loss 1.7457 | lr 3.94e-04 | grad 1.55 | tok/s 14686
step    260 | loss 1.8623 | lr 3.94e-04 | grad 2.89 | tok/s 15128
step    270 | loss 1.7988 | lr 3.94e-04 | grad 1.88 | tok/s 14595
step    280 | loss 1.7659 | lr 3.94e-04 | grad 1.71 | tok/s 13877
step    290 | loss 1.6558 | lr 3.94e-04 | grad 2.09 | tok/s 14348
step    300 | loss 1.9547 | lr 3.94e-04 | grad 1.97 | tok/s 14467
step    310 | loss 1.6498 | lr 3.94e-04 | grad 1.63 | tok/s 14400
step    320 | loss 1.8670 | lr 3.94e-04 | grad 3.12 | tok/s 14581

Training complete! Final step: 328
