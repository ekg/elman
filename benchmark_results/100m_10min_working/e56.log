Using device: cuda
Output directory: benchmark_results/100m_10min_working/e56/level56_100m_20260114_185053
Auto r_h_mode: spectral_norm (level 56 has full W_h)
Model: Level 56, 114,890,880 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.6398 | lr 2.70e-06 | grad 24.62 | tok/s 13491
step     20 | loss 5.5987 | lr 5.70e-06 | grad 3.64 | tok/s 25600
step     30 | loss 5.6511 | lr 8.70e-06 | grad 3.47 | tok/s 28837
step     40 | loss 5.6342 | lr 1.17e-05 | grad 3.58 | tok/s 28732
step     50 | loss 5.5907 | lr 1.47e-05 | grad 3.47 | tok/s 25803
step     60 | loss 5.4816 | lr 1.77e-05 | grad 12.81 | tok/s 25791
step     70 | loss 5.2396 | lr 2.07e-05 | grad 4.81 | tok/s 24790
step     80 | loss 4.9628 | lr 2.37e-05 | grad 3.58 | tok/s 24143
step     90 | loss 4.9809 | lr 2.67e-05 | grad 10.06 | tok/s 21786
step    100 | loss 4.6733 | lr 2.97e-05 | grad 4.25 | tok/s 21258
step    110 | loss 4.0459 | lr 3.27e-05 | grad 2.98 | tok/s 20311
step    120 | loss 3.6303 | lr 3.57e-05 | grad 2.64 | tok/s 23358
step    130 | loss 3.3921 | lr 3.87e-05 | grad 2.16 | tok/s 26457
step    140 | loss 2.9947 | lr 4.17e-05 | grad 1.55 | tok/s 24985
step    150 | loss 2.7493 | lr 4.47e-05 | grad 2.38 | tok/s 23658
step    160 | loss 2.5774 | lr 4.77e-05 | grad 2.34 | tok/s 23485
step    170 | loss 2.6854 | lr 5.07e-05 | grad 5.50 | tok/s 22788
step    180 | loss 2.6999 | lr 5.37e-05 | grad 1.67 | tok/s 26088
step    190 | loss 2.3897 | lr 5.67e-05 | grad 2.19 | tok/s 22539
step    200 | loss 2.1409 | lr 5.97e-05 | grad 1.52 | tok/s 19003
step    210 | loss 2.4776 | lr 6.27e-05 | grad 2.83 | tok/s 22223
step    220 | loss 2.3983 | lr 6.57e-05 | grad 1.70 | tok/s 26513
step    230 | loss 2.1968 | lr 6.87e-05 | grad 2.81 | tok/s 26262
step    240 | loss 2.2322 | lr 7.17e-05 | grad 2.94 | tok/s 27414
step    250 | loss 2.1658 | lr 7.47e-05 | grad 2.19 | tok/s 27546
step    260 | loss 2.2260 | lr 7.77e-05 | grad 1.47 | tok/s 26582
step    270 | loss 2.0534 | lr 8.07e-05 | grad 1.94 | tok/s 27751
step    280 | loss 1.9480 | lr 8.37e-05 | grad 2.83 | tok/s 27568
step    290 | loss 1.8396 | lr 8.67e-05 | grad 1.87 | tok/s 27106
step    300 | loss 1.7106 | lr 8.97e-05 | grad 1.84 | tok/s 26101
step    310 | loss 1.6481 | lr 9.27e-05 | grad 1.52 | tok/s 27319
step    320 | loss 1.8778 | lr 9.57e-05 | grad 3.09 | tok/s 26293
step    330 | loss 1.9965 | lr 9.87e-05 | grad 1.88 | tok/s 25882
step    340 | loss 1.9632 | lr 1.02e-04 | grad 3.72 | tok/s 26737
step    350 | loss 1.9567 | lr 1.05e-04 | grad 1.91 | tok/s 26181
step    360 | loss 1.9318 | lr 1.08e-04 | grad 4.12 | tok/s 26894
step    370 | loss 1.7363 | lr 1.11e-04 | grad 1.84 | tok/s 27613
step    380 | loss 2.3004 | lr 1.14e-04 | grad 2.16 | tok/s 28437
step    390 | loss 1.8623 | lr 1.17e-04 | grad 1.72 | tok/s 27753
step    400 | loss 1.9897 | lr 1.20e-04 | grad 3.97 | tok/s 27622
step    410 | loss 1.7270 | lr 1.23e-04 | grad 3.38 | tok/s 26947
step    420 | loss 1.8630 | lr 1.26e-04 | grad 2.58 | tok/s 27347
step    430 | loss 2.0147 | lr 1.29e-04 | grad 2.70 | tok/s 27397
step    440 | loss 2.0435 | lr 1.32e-04 | grad 1.77 | tok/s 28477
step    450 | loss 1.8398 | lr 1.35e-04 | grad 1.38 | tok/s 28001
step    460 | loss 1.8054 | lr 1.38e-04 | grad 1.45 | tok/s 28230
step    470 | loss 1.7922 | lr 1.41e-04 | grad 2.27 | tok/s 28593
step    480 | loss 1.7059 | lr 1.44e-04 | grad 1.34 | tok/s 27700
step    490 | loss 1.6548 | lr 1.47e-04 | grad 1.21 | tok/s 28059
step    500 | loss 2.4327 | lr 1.50e-04 | grad 2.31 | tok/s 29004
step    510 | loss 1.7451 | lr 1.53e-04 | grad 1.41 | tok/s 28089
step    520 | loss 1.6713 | lr 1.56e-04 | grad 1.41 | tok/s 28800
step    530 | loss 2.2859 | lr 1.59e-04 | grad 2.86 | tok/s 26733
step    540 | loss 1.7474 | lr 1.62e-04 | grad 2.02 | tok/s 27082
step    550 | loss 1.5765 | lr 1.65e-04 | grad 0.98 | tok/s 27891
step    560 | loss 1.3845 | lr 1.68e-04 | grad 0.95 | tok/s 28962
step    570 | loss 1.7441 | lr 1.71e-04 | grad 2.83 | tok/s 26942
step    580 | loss 2.0513 | lr 1.74e-04 | grad 1.38 | tok/s 27102
step    590 | loss 2.2744 | lr 1.77e-04 | grad 1.64 | tok/s 26502
step    600 | loss 1.7786 | lr 1.80e-04 | grad 1.90 | tok/s 26640
step    610 | loss 1.8031 | lr 1.83e-04 | grad 1.55 | tok/s 28108
step    620 | loss 1.7247 | lr 1.86e-04 | grad 1.13 | tok/s 26850
step    630 | loss 1.6117 | lr 1.89e-04 | grad 1.09 | tok/s 27521
step    640 | loss 1.8981 | lr 1.92e-04 | grad 1.23 | tok/s 27437
step    650 | loss 1.6901 | lr 1.95e-04 | grad 1.67 | tok/s 24446
step    660 | loss 1.9478 | lr 1.98e-04 | grad 4.81 | tok/s 24475
step    670 | loss 1.8570 | lr 2.01e-04 | grad 1.86 | tok/s 25579
step    680 | loss 1.8168 | lr 2.04e-04 | grad 1.43 | tok/s 25170
step    690 | loss 1.8213 | lr 2.07e-04 | grad 1.87 | tok/s 26746
step    700 | loss 1.8948 | lr 2.10e-04 | grad 1.98 | tok/s 25924
step    710 | loss 1.7761 | lr 2.13e-04 | grad 1.08 | tok/s 25428
step    720 | loss 1.7171 | lr 2.16e-04 | grad 3.98 | tok/s 20360
step    730 | loss 1.9427 | lr 2.19e-04 | grad 1.50 | tok/s 25735
step    740 | loss 1.8341 | lr 2.22e-04 | grad 1.78 | tok/s 22279
step    750 | loss 1.6149 | lr 2.25e-04 | grad 1.43 | tok/s 20488
step    760 | loss 2.0037 | lr 2.28e-04 | grad 0.81 | tok/s 18814
step    770 | loss 1.6398 | lr 2.31e-04 | grad 1.16 | tok/s 18557
step    780 | loss 1.7183 | lr 2.34e-04 | grad 0.88 | tok/s 16701
step    790 | loss 1.6064 | lr 2.37e-04 | grad 0.75 | tok/s 22263
step    800 | loss 1.5792 | lr 2.40e-04 | grad 1.07 | tok/s 21778
step    810 | loss 1.6825 | lr 2.43e-04 | grad 1.82 | tok/s 23349
step    820 | loss 2.3363 | lr 2.46e-04 | grad 1.29 | tok/s 24538
step    830 | loss 1.7728 | lr 2.49e-04 | grad 0.79 | tok/s 25080
step    840 | loss 1.4575 | lr 2.52e-04 | grad 0.71 | tok/s 25223
step    850 | loss 1.9477 | lr 2.55e-04 | grad 1.20 | tok/s 25241
step    860 | loss 1.6858 | lr 2.58e-04 | grad 0.86 | tok/s 23080
step    870 | loss 1.6092 | lr 2.61e-04 | grad 0.94 | tok/s 22178
step    880 | loss 1.7180 | lr 2.64e-04 | grad 0.97 | tok/s 21694
step    890 | loss 1.5979 | lr 2.67e-04 | grad 0.90 | tok/s 22415
step    900 | loss 2.0403 | lr 2.70e-04 | grad 1.01 | tok/s 22745
step    910 | loss 1.6356 | lr 2.73e-04 | grad 0.83 | tok/s 19736
step    920 | loss 1.6444 | lr 2.76e-04 | grad 0.81 | tok/s 21815
step    930 | loss 1.6992 | lr 2.79e-04 | grad 1.24 | tok/s 20162
step    940 | loss 1.6279 | lr 2.82e-04 | grad 1.58 | tok/s 22189

Training complete! Final step: 940
