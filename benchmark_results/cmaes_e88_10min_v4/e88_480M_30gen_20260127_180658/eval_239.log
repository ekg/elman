Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_239/levelE88_100m_20260127_230720
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 483,851,102 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3019 | lr 3.00e-04 | grad 18.25 | tok/s 6219
step     20 | loss 3.1090 | lr 3.00e-04 | grad 9.69 | tok/s 17230
step     30 | loss 2.6395 | lr 3.00e-04 | grad 6.84 | tok/s 17396
step     40 | loss 2.4217 | lr 3.00e-04 | grad 5.06 | tok/s 16637
step     50 | loss 2.9864 | lr 3.00e-04 | grad 17.88 | tok/s 16897
step     60 | loss 2.0446 | lr 3.00e-04 | grad 3.95 | tok/s 17395
step     70 | loss 1.8089 | lr 3.00e-04 | grad 5.22 | tok/s 17614
step     80 | loss 5.9172 | lr 3.00e-04 | grad 40.75 | tok/s 17698
step     90 | loss 4.8656 | lr 3.00e-04 | grad 7.84 | tok/s 17987
step    100 | loss 4.0551 | lr 3.00e-04 | grad 7.97 | tok/s 17921
step    110 | loss 3.4083 | lr 3.00e-04 | grad 15.75 | tok/s 17926
step    120 | loss 3.1249 | lr 3.00e-04 | grad 12.31 | tok/s 17863
step    130 | loss 2.9437 | lr 3.00e-04 | grad 11.44 | tok/s 17833
step    140 | loss 2.7754 | lr 3.00e-04 | grad 9.38 | tok/s 17789
step    150 | loss 2.8250 | lr 3.00e-04 | grad 8.25 | tok/s 17798
step    160 | loss 2.3792 | lr 3.00e-04 | grad 8.06 | tok/s 17753
step    170 | loss 2.4264 | lr 3.00e-04 | grad 12.12 | tok/s 17707
step    180 | loss 2.3068 | lr 3.00e-04 | grad 8.62 | tok/s 17734
step    190 | loss 2.3832 | lr 3.00e-04 | grad 6.38 | tok/s 17728
step    200 | loss 2.0953 | lr 3.00e-04 | grad 4.56 | tok/s 17695
step    210 | loss 2.1082 | lr 3.00e-04 | grad 7.69 | tok/s 17666
step    220 | loss 2.1262 | lr 3.00e-04 | grad 3.97 | tok/s 17463
step    230 | loss 2.0581 | lr 3.00e-04 | grad 4.88 | tok/s 15880
step    240 | loss 2.2810 | lr 3.00e-04 | grad 4.91 | tok/s 16398
step    250 | loss 2.0679 | lr 3.00e-04 | grad 2.84 | tok/s 16848
step    260 | loss 1.4964 | lr 3.00e-04 | grad 3.22 | tok/s 17357
step    270 | loss 2.0515 | lr 3.00e-04 | grad 3.23 | tok/s 17111
step    280 | loss 2.2156 | lr 3.00e-04 | grad 6.00 | tok/s 16785
step    290 | loss 1.4492 | lr 3.00e-04 | grad 2.62 | tok/s 17670
step    300 | loss 0.6037 | lr 3.00e-04 | grad 2.22 | tok/s 17659
step    310 | loss 2.4164 | lr 3.00e-04 | grad 4.41 | tok/s 17385
step    320 | loss 1.9118 | lr 3.00e-04 | grad 5.91 | tok/s 17019
step    330 | loss 1.9296 | lr 3.00e-04 | grad 3.12 | tok/s 16451
step    340 | loss 2.2683 | lr 3.00e-04 | grad 3.25 | tok/s 16723
step    350 | loss 1.8263 | lr 3.00e-04 | grad 3.38 | tok/s 17124
step    360 | loss 1.1591 | lr 3.00e-04 | grad 8.12 | tok/s 17501
step    370 | loss 1.7830 | lr 3.00e-04 | grad 2.78 | tok/s 15878
step    380 | loss 1.7337 | lr 3.00e-04 | grad 2.89 | tok/s 16889
step    390 | loss 1.5038 | lr 3.00e-04 | grad 2.56 | tok/s 17623
step    400 | loss 1.4623 | lr 3.00e-04 | grad 2.81 | tok/s 17499
step    410 | loss 1.2510 | lr 3.00e-04 | grad 2.12 | tok/s 17124
step    420 | loss 1.7924 | lr 3.00e-04 | grad 4.69 | tok/s 16345
step    430 | loss 2.1653 | lr 3.00e-04 | grad 3.17 | tok/s 17379
step    440 | loss 2.1356 | lr 3.00e-04 | grad 4.25 | tok/s 16424
step    450 | loss 1.9892 | lr 3.00e-04 | grad 2.86 | tok/s 17015
step    460 | loss 1.6914 | lr 3.00e-04 | grad 2.97 | tok/s 16629
step    470 | loss 1.8172 | lr 3.00e-04 | grad 2.94 | tok/s 17116
step    480 | loss 2.2191 | lr 3.00e-04 | grad 6.56 | tok/s 17145
step    490 | loss 1.7794 | lr 3.00e-04 | grad 2.64 | tok/s 16228
step    500 | loss 1.6505 | lr 3.00e-04 | grad 3.77 | tok/s 17297
step    510 | loss 1.6915 | lr 3.00e-04 | grad 2.94 | tok/s 17520
step    520 | loss 1.6355 | lr 3.00e-04 | grad 2.28 | tok/s 17485
step    530 | loss 1.8790 | lr 3.00e-04 | grad 2.53 | tok/s 16826
step    540 | loss 1.7191 | lr 3.00e-04 | grad 2.58 | tok/s 16819
step    550 | loss 1.5558 | lr 3.00e-04 | grad 3.02 | tok/s 16448
step    560 | loss 1.7063 | lr 3.00e-04 | grad 2.83 | tok/s 16048
step    570 | loss 1.6479 | lr 3.00e-04 | grad 3.59 | tok/s 16449
step    580 | loss 1.5293 | lr 3.00e-04 | grad 2.47 | tok/s 16416
step    590 | loss 1.8377 | lr 3.00e-04 | grad 3.34 | tok/s 16857
step    600 | loss 1.8157 | lr 3.00e-04 | grad 2.36 | tok/s 16271
step    610 | loss 1.6083 | lr 3.00e-04 | grad 2.66 | tok/s 17086
step    620 | loss 1.5379 | lr 3.00e-04 | grad 2.55 | tok/s 16192
step    630 | loss 1.6315 | lr 3.00e-04 | grad 4.59 | tok/s 16315
step    640 | loss 1.7973 | lr 3.00e-04 | grad 2.59 | tok/s 16807
step    650 | loss 1.6608 | lr 3.00e-04 | grad 2.91 | tok/s 16849
step    660 | loss 1.6829 | lr 3.00e-04 | grad 2.25 | tok/s 16922
step    670 | loss 1.8778 | lr 3.00e-04 | grad 3.44 | tok/s 17022
step    680 | loss 1.7176 | lr 3.00e-04 | grad 2.67 | tok/s 16719
step    690 | loss 1.8153 | lr 3.00e-04 | grad 3.16 | tok/s 17299
step    700 | loss 1.4008 | lr 3.00e-04 | grad 3.23 | tok/s 17640
step    710 | loss 1.5773 | lr 3.00e-04 | grad 2.66 | tok/s 16484
step    720 | loss 1.4641 | lr 3.00e-04 | grad 3.53 | tok/s 16252
step    730 | loss 1.2789 | lr 3.00e-04 | grad 3.03 | tok/s 17596
step    740 | loss 1.4893 | lr 3.00e-04 | grad 2.47 | tok/s 17367
step    750 | loss 1.1863 | lr 3.00e-04 | grad 2.69 | tok/s 17614
step    760 | loss 1.0941 | lr 3.00e-04 | grad 2.31 | tok/s 17630
step    770 | loss 1.0373 | lr 3.00e-04 | grad 2.20 | tok/s 17655
step    780 | loss 0.9837 | lr 3.00e-04 | grad 2.25 | tok/s 17634
step    790 | loss 1.1153 | lr 3.00e-04 | grad 3.38 | tok/s 17100
step    800 | loss 1.8015 | lr 3.00e-04 | grad 5.44 | tok/s 17023
step    810 | loss 1.7004 | lr 3.00e-04 | grad 2.38 | tok/s 16939
step    820 | loss 1.6993 | lr 3.00e-04 | grad 3.94 | tok/s 16299
step    830 | loss 1.4894 | lr 3.00e-04 | grad 2.39 | tok/s 17449
step    840 | loss 1.3409 | lr 3.00e-04 | grad 2.34 | tok/s 17637
step    850 | loss 1.5897 | lr 3.00e-04 | grad 2.30 | tok/s 17531
step    860 | loss 1.4542 | lr 3.00e-04 | grad 4.22 | tok/s 17348
step    870 | loss 1.4930 | lr 3.00e-04 | grad 2.78 | tok/s 15695
step    880 | loss 1.6719 | lr 3.00e-04 | grad 2.78 | tok/s 16845
step    890 | loss 1.6753 | lr 3.00e-04 | grad 3.27 | tok/s 17044
step    900 | loss 1.5553 | lr 3.00e-04 | grad 2.67 | tok/s 17065
step    910 | loss 1.4233 | lr 3.00e-04 | grad 4.28 | tok/s 16684
step    920 | loss 1.5234 | lr 3.00e-04 | grad 3.66 | tok/s 17363
step    930 | loss 1.5870 | lr 3.00e-04 | grad 3.31 | tok/s 16578
step    940 | loss 1.3772 | lr 3.00e-04 | grad 2.05 | tok/s 17464
step    950 | loss 1.4943 | lr 3.00e-04 | grad 3.53 | tok/s 17554
step    960 | loss 1.3209 | lr 3.00e-04 | grad 2.73 | tok/s 17564
step    970 | loss 1.7374 | lr 3.00e-04 | grad 3.67 | tok/s 16513
step    980 | loss 1.6309 | lr 3.00e-04 | grad 2.61 | tok/s 16940
step    990 | loss 1.4376 | lr 3.00e-04 | grad 2.33 | tok/s 17208
step   1000 | loss 1.8297 | lr 3.00e-04 | grad 10.31 | tok/s 16530
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8297.pt
step   1010 | loss 1.7301 | lr 3.00e-04 | grad 2.56 | tok/s 5579
step   1020 | loss 1.6754 | lr 3.00e-04 | grad 2.95 | tok/s 16339
step   1030 | loss 1.3935 | lr 3.00e-04 | grad 1.79 | tok/s 17020
step   1040 | loss 1.5146 | lr 3.00e-04 | grad 4.28 | tok/s 17336
step   1050 | loss 1.5874 | lr 3.00e-04 | grad 2.42 | tok/s 16309
step   1060 | loss 1.6848 | lr 3.00e-04 | grad 2.58 | tok/s 17424
step   1070 | loss 1.6406 | lr 3.00e-04 | grad 3.62 | tok/s 17154
step   1080 | loss 1.4005 | lr 3.00e-04 | grad 2.56 | tok/s 15876
step   1090 | loss 0.9935 | lr 3.00e-04 | grad 2.91 | tok/s 17601
step   1100 | loss 1.5615 | lr 3.00e-04 | grad 3.30 | tok/s 16860
step   1110 | loss 1.4205 | lr 3.00e-04 | grad 2.52 | tok/s 17731
step   1120 | loss 1.3256 | lr 3.00e-04 | grad 2.53 | tok/s 17715
step   1130 | loss 1.2729 | lr 3.00e-04 | grad 2.39 | tok/s 17709
step   1140 | loss 1.2795 | lr 3.00e-04 | grad 2.14 | tok/s 17702
step   1150 | loss 1.2794 | lr 3.00e-04 | grad 2.41 | tok/s 17694
step   1160 | loss 1.2018 | lr 3.00e-04 | grad 2.27 | tok/s 16672
step   1170 | loss 1.2436 | lr 3.00e-04 | grad 2.41 | tok/s 17682
step   1180 | loss 1.2983 | lr 3.00e-04 | grad 2.09 | tok/s 17675
step   1190 | loss 1.2026 | lr 3.00e-04 | grad 2.53 | tok/s 17666
step   1200 | loss 1.2055 | lr 3.00e-04 | grad 2.05 | tok/s 17659
step   1210 | loss 1.2443 | lr 3.00e-04 | grad 1.83 | tok/s 17662
step   1220 | loss 1.2699 | lr 3.00e-04 | grad 2.02 | tok/s 17666
step   1230 | loss 1.2450 | lr 3.00e-04 | grad 2.02 | tok/s 17650
step   1240 | loss 1.2508 | lr 3.00e-04 | grad 3.12 | tok/s 17496
step   1250 | loss 1.7913 | lr 3.00e-04 | grad 2.62 | tok/s 16748
step   1260 | loss 1.3175 | lr 3.00e-04 | grad 3.80 | tok/s 16499
step   1270 | loss 1.7567 | lr 3.00e-04 | grad 3.05 | tok/s 16467
step   1280 | loss 1.5681 | lr 3.00e-04 | grad 2.73 | tok/s 17218
step   1290 | loss 1.4795 | lr 3.00e-04 | grad 2.86 | tok/s 16897
step   1300 | loss 1.5035 | lr 3.00e-04 | grad 2.41 | tok/s 16760
step   1310 | loss 1.4440 | lr 3.00e-04 | grad 2.12 | tok/s 17550
step   1320 | loss 1.5827 | lr 3.00e-04 | grad 2.66 | tok/s 17359
step   1330 | loss 1.5205 | lr 3.00e-04 | grad 2.52 | tok/s 17358
step   1340 | loss 1.5625 | lr 3.00e-04 | grad 3.47 | tok/s 16404
step   1350 | loss 1.7157 | lr 3.00e-04 | grad 2.62 | tok/s 16233
step   1360 | loss 1.4647 | lr 3.00e-04 | grad 1.93 | tok/s 17018
step   1370 | loss 1.5101 | lr 3.00e-04 | grad 8.19 | tok/s 16820
step   1380 | loss 1.5829 | lr 3.00e-04 | grad 3.80 | tok/s 16189
step   1390 | loss 1.4758 | lr 3.00e-04 | grad 6.34 | tok/s 17049
step   1400 | loss 1.3667 | lr 3.00e-04 | grad 1.84 | tok/s 16645
step   1410 | loss 1.5090 | lr 3.00e-04 | grad 8.12 | tok/s 16587
step   1420 | loss 1.6193 | lr 3.00e-04 | grad 2.28 | tok/s 16577
step   1430 | loss 1.3350 | lr 3.00e-04 | grad 2.50 | tok/s 16813
step   1440 | loss 1.1253 | lr 3.00e-04 | grad 2.33 | tok/s 17631
step   1450 | loss 1.1569 | lr 3.00e-04 | grad 2.67 | tok/s 17423
step   1460 | loss 1.6845 | lr 3.00e-04 | grad 2.52 | tok/s 16479
step   1470 | loss 1.5060 | lr 3.00e-04 | grad 2.34 | tok/s 17517
step   1480 | loss 1.8318 | lr 3.00e-04 | grad 3.98 | tok/s 17336
step   1490 | loss 1.5656 | lr 3.00e-04 | grad 3.11 | tok/s 17592
step   1500 | loss 1.3066 | lr 3.00e-04 | grad 2.19 | tok/s 17670
step   1510 | loss 1.5217 | lr 3.00e-04 | grad 3.12 | tok/s 17414
step   1520 | loss 1.4234 | lr 3.00e-04 | grad 3.28 | tok/s 17098
step   1530 | loss 1.4326 | lr 3.00e-04 | grad 3.81 | tok/s 17441
step   1540 | loss 1.6155 | lr 3.00e-04 | grad 2.95 | tok/s 16435
step   1550 | loss 1.2598 | lr 3.00e-04 | grad 2.86 | tok/s 17546
step   1560 | loss 1.5804 | lr 3.00e-04 | grad 2.20 | tok/s 16634
step   1570 | loss 1.2655 | lr 3.00e-04 | grad 2.52 | tok/s 17517
step   1580 | loss 1.6899 | lr 3.00e-04 | grad 5.22 | tok/s 17425
step   1590 | loss 1.5805 | lr 3.00e-04 | grad 2.41 | tok/s 16559
step   1600 | loss 0.9059 | lr 3.00e-04 | grad 2.97 | tok/s 17681
step   1610 | loss 1.1014 | lr 3.00e-04 | grad 2.20 | tok/s 16698
step   1620 | loss 1.3728 | lr 3.00e-04 | grad 3.30 | tok/s 16404
step   1630 | loss 1.3440 | lr 3.00e-04 | grad 2.11 | tok/s 17169
step   1640 | loss 1.3505 | lr 3.00e-04 | grad 2.36 | tok/s 16649
step   1650 | loss 1.5488 | lr 3.00e-04 | grad 2.78 | tok/s 15774
step   1660 | loss 1.3100 | lr 3.00e-04 | grad 1.95 | tok/s 17595
step   1670 | loss 1.3926 | lr 3.00e-04 | grad 3.89 | tok/s 16975
step   1680 | loss 1.6728 | lr 3.00e-04 | grad 2.05 | tok/s 16234
step   1690 | loss 1.4803 | lr 3.00e-04 | grad 4.38 | tok/s 17018
step   1700 | loss 1.5059 | lr 3.00e-04 | grad 2.30 | tok/s 16856
step   1710 | loss 1.4173 | lr 3.00e-04 | grad 2.31 | tok/s 16863
step   1720 | loss 1.5166 | lr 3.00e-04 | grad 2.97 | tok/s 17580
step   1730 | loss 1.1554 | lr 3.00e-04 | grad 2.66 | tok/s 17624
step   1740 | loss 1.3818 | lr 3.00e-04 | grad 2.70 | tok/s 17045
step   1750 | loss 1.5398 | lr 3.00e-04 | grad 3.17 | tok/s 17046
step   1760 | loss 1.5629 | lr 3.00e-04 | grad 2.42 | tok/s 16973
step   1770 | loss 1.4392 | lr 3.00e-04 | grad 2.62 | tok/s 16653
step   1780 | loss 1.4754 | lr 3.00e-04 | grad 2.17 | tok/s 17162
step   1790 | loss 1.4198 | lr 3.00e-04 | grad 3.44 | tok/s 17014
step   1800 | loss 1.5663 | lr 3.00e-04 | grad 2.22 | tok/s 15881
step   1810 | loss 1.4464 | lr 3.00e-04 | grad 3.72 | tok/s 16407
step   1820 | loss 1.4633 | lr 3.00e-04 | grad 6.69 | tok/s 16897
step   1830 | loss 1.4475 | lr 3.00e-04 | grad 4.09 | tok/s 17290
step   1840 | loss 1.4907 | lr 3.00e-04 | grad 2.00 | tok/s 16457
step   1850 | loss 1.2613 | lr 3.00e-04 | grad 2.25 | tok/s 17532
step   1860 | loss 1.3585 | lr 3.00e-04 | grad 2.88 | tok/s 16638
step   1870 | loss 1.3608 | lr 3.00e-04 | grad 1.91 | tok/s 17032
step   1880 | loss 1.2621 | lr 3.00e-04 | grad 2.94 | tok/s 16350
step   1890 | loss 1.5192 | lr 3.00e-04 | grad 2.39 | tok/s 15845
step   1900 | loss 1.3862 | lr 3.00e-04 | grad 2.64 | tok/s 16953
step   1910 | loss 1.4709 | lr 3.00e-04 | grad 2.33 | tok/s 16065
step   1920 | loss 1.3705 | lr 3.00e-04 | grad 2.28 | tok/s 17610
step   1930 | loss 1.4475 | lr 3.00e-04 | grad 3.42 | tok/s 16235
step   1940 | loss 1.4459 | lr 3.00e-04 | grad 2.42 | tok/s 17498
step   1950 | loss 1.8266 | lr 3.00e-04 | grad 3.50 | tok/s 17443
step   1960 | loss 1.4256 | lr 3.00e-04 | grad 4.28 | tok/s 17620
step   1970 | loss 1.4761 | lr 3.00e-04 | grad 2.53 | tok/s 17176
step   1980 | loss 1.5549 | lr 3.00e-04 | grad 2.72 | tok/s 16434
step   1990 | loss 1.6070 | lr 3.00e-04 | grad 2.97 | tok/s 16744
step   2000 | loss 1.4903 | lr 3.00e-04 | grad 2.84 | tok/s 16985
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4903.pt
step   2010 | loss 1.2037 | lr 3.00e-04 | grad 2.70 | tok/s 5618
step   2020 | loss 1.3177 | lr 3.00e-04 | grad 2.73 | tok/s 17387
step   2030 | loss 0.9747 | lr 3.00e-04 | grad 4.88 | tok/s 17854
step   2040 | loss 1.2429 | lr 3.00e-04 | grad 1.80 | tok/s 17797
step   2050 | loss 1.2939 | lr 3.00e-04 | grad 3.09 | tok/s 17076
step   2060 | loss 1.6532 | lr 3.00e-04 | grad 2.52 | tok/s 16761
step   2070 | loss 1.8867 | lr 3.00e-04 | grad 10.06 | tok/s 16856
step   2080 | loss 2.1071 | lr 3.00e-04 | grad 4.25 | tok/s 17755
step   2090 | loss 1.5710 | lr 3.00e-04 | grad 2.44 | tok/s 17384
step   2100 | loss 1.3488 | lr 3.00e-04 | grad 3.31 | tok/s 17418
step   2110 | loss 1.4554 | lr 3.00e-04 | grad 2.45 | tok/s 15888
step   2120 | loss 0.8077 | lr 3.00e-04 | grad 1.98 | tok/s 17809
step   2130 | loss 1.3202 | lr 3.00e-04 | grad 2.50 | tok/s 16925
step   2140 | loss 1.4414 | lr 3.00e-04 | grad 1.94 | tok/s 17346
step   2150 | loss 1.2795 | lr 3.00e-04 | grad 2.48 | tok/s 17691
step   2160 | loss 1.1812 | lr 3.00e-04 | grad 2.09 | tok/s 17711
step   2170 | loss 1.2107 | lr 3.00e-04 | grad 2.09 | tok/s 17698
step   2180 | loss 1.1825 | lr 3.00e-04 | grad 2.08 | tok/s 17681
step   2190 | loss 1.2169 | lr 3.00e-04 | grad 2.16 | tok/s 17665
step   2200 | loss 1.1510 | lr 3.00e-04 | grad 2.02 | tok/s 17678
step   2210 | loss 1.1446 | lr 3.00e-04 | grad 2.09 | tok/s 17662
step   2220 | loss 1.1104 | lr 3.00e-04 | grad 2.14 | tok/s 17683
step   2230 | loss 1.4184 | lr 3.00e-04 | grad 2.58 | tok/s 17337
step   2240 | loss 1.3453 | lr 3.00e-04 | grad 5.06 | tok/s 17043
step   2250 | loss 1.5341 | lr 3.00e-04 | grad 4.75 | tok/s 17648
step   2260 | loss 1.5796 | lr 3.00e-04 | grad 2.56 | tok/s 17055
step   2270 | loss 1.9428 | lr 3.00e-04 | grad 3.86 | tok/s 17459
step   2280 | loss 1.3788 | lr 3.00e-04 | grad 2.81 | tok/s 17626
step   2290 | loss 1.4850 | lr 3.00e-04 | grad 2.64 | tok/s 16840
step   2300 | loss 1.4263 | lr 3.00e-04 | grad 2.73 | tok/s 17336
step   2310 | loss 1.4180 | lr 3.00e-04 | grad 2.02 | tok/s 16791
step   2320 | loss 1.9352 | lr 3.00e-04 | grad 3.64 | tok/s 16577
step   2330 | loss 1.5013 | lr 3.00e-04 | grad 2.89 | tok/s 16469
step   2340 | loss 1.4529 | lr 3.00e-04 | grad 3.28 | tok/s 16624
step   2350 | loss 1.3561 | lr 3.00e-04 | grad 2.84 | tok/s 17290
step   2360 | loss 1.2314 | lr 3.00e-04 | grad 3.53 | tok/s 17508
step   2370 | loss 1.5629 | lr 3.00e-04 | grad 3.03 | tok/s 17432
step   2380 | loss 1.3813 | lr 3.00e-04 | grad 3.58 | tok/s 17671
step   2390 | loss 1.1207 | lr 3.00e-04 | grad 5.34 | tok/s 17609
step   2400 | loss 0.9877 | lr 3.00e-04 | grad 1.92 | tok/s 17639
step   2410 | loss 1.2582 | lr 3.00e-04 | grad 2.72 | tok/s 16905
step   2420 | loss 1.4965 | lr 3.00e-04 | grad 2.97 | tok/s 16216
step   2430 | loss 1.2739 | lr 3.00e-04 | grad 3.78 | tok/s 17322
step   2440 | loss 1.3787 | lr 3.00e-04 | grad 3.61 | tok/s 17042
step   2450 | loss 1.4664 | lr 3.00e-04 | grad 2.75 | tok/s 16993
step   2460 | loss 1.1306 | lr 3.00e-04 | grad 1.52 | tok/s 17521
step   2470 | loss 1.2052 | lr 3.00e-04 | grad 1.69 | tok/s 17411
step   2480 | loss 1.1919 | lr 3.00e-04 | grad 2.47 | tok/s 17341
step   2490 | loss 1.4573 | lr 3.00e-04 | grad 4.06 | tok/s 16812

Training complete! Final step: 2492
