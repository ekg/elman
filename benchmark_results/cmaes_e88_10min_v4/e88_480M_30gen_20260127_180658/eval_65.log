Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_65/levelE88_100m_20260127_193024
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 481,601,304 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1481 | lr 3.00e-04 | grad 17.38 | tok/s 5995
step     20 | loss 2.8457 | lr 3.00e-04 | grad 9.62 | tok/s 16020
step     30 | loss 2.6734 | lr 3.00e-04 | grad 6.56 | tok/s 16164
step     40 | loss 2.4396 | lr 3.00e-04 | grad 4.56 | tok/s 15445
step     50 | loss 2.9741 | lr 3.00e-04 | grad 11.06 | tok/s 15679
step     60 | loss 2.0651 | lr 3.00e-04 | grad 3.81 | tok/s 16164
step     70 | loss 1.8668 | lr 3.00e-04 | grad 5.47 | tok/s 16347
step     80 | loss 6.1285 | lr 3.00e-04 | grad 79.00 | tok/s 16456
step     90 | loss 5.6488 | lr 3.00e-04 | grad 11.12 | tok/s 16683
step    100 | loss 4.2678 | lr 3.00e-04 | grad 9.56 | tok/s 16680
step    110 | loss 3.6474 | lr 3.00e-04 | grad 22.50 | tok/s 16655
step    120 | loss 3.2198 | lr 3.00e-04 | grad 14.25 | tok/s 16577
step    130 | loss 2.9828 | lr 3.00e-04 | grad 16.25 | tok/s 16603
step    140 | loss 2.7407 | lr 3.00e-04 | grad 11.12 | tok/s 16562
step    150 | loss 2.7823 | lr 3.00e-04 | grad 13.94 | tok/s 16598
step    160 | loss 2.3555 | lr 3.00e-04 | grad 13.50 | tok/s 16566
step    170 | loss 2.3743 | lr 3.00e-04 | grad 13.62 | tok/s 16529
step    180 | loss 2.2649 | lr 3.00e-04 | grad 6.06 | tok/s 16521
step    190 | loss 2.3663 | lr 3.00e-04 | grad 11.00 | tok/s 16519
step    200 | loss 2.0543 | lr 3.00e-04 | grad 6.34 | tok/s 16535
step    210 | loss 2.1249 | lr 3.00e-04 | grad 7.25 | tok/s 16514
step    220 | loss 2.1522 | lr 3.00e-04 | grad 3.75 | tok/s 16280
step    230 | loss 2.0392 | lr 3.00e-04 | grad 4.78 | tok/s 14721
step    240 | loss 2.2967 | lr 3.00e-04 | grad 5.03 | tok/s 15319
step    250 | loss 2.1069 | lr 3.00e-04 | grad 2.73 | tok/s 15710
step    260 | loss 1.5448 | lr 3.00e-04 | grad 3.06 | tok/s 16195
step    270 | loss 2.0725 | lr 3.00e-04 | grad 2.91 | tok/s 15996
step    280 | loss 2.2474 | lr 3.00e-04 | grad 5.16 | tok/s 15661
step    290 | loss 1.3495 | lr 3.00e-04 | grad 3.12 | tok/s 16501
step    300 | loss 0.5628 | lr 3.00e-04 | grad 2.47 | tok/s 16489
step    310 | loss 2.4073 | lr 3.00e-04 | grad 3.75 | tok/s 16192
step    320 | loss 1.9162 | lr 3.00e-04 | grad 6.06 | tok/s 15859
step    330 | loss 1.9514 | lr 3.00e-04 | grad 2.98 | tok/s 15313
step    340 | loss 2.2868 | lr 3.00e-04 | grad 2.95 | tok/s 15551
step    350 | loss 1.8617 | lr 3.00e-04 | grad 4.34 | tok/s 15942
step    360 | loss 1.1904 | lr 3.00e-04 | grad 8.56 | tok/s 16306
step    370 | loss 1.7966 | lr 3.00e-04 | grad 2.67 | tok/s 14806
step    380 | loss 1.7624 | lr 3.00e-04 | grad 2.75 | tok/s 15752
step    390 | loss 1.5296 | lr 3.00e-04 | grad 2.33 | tok/s 16430
step    400 | loss 1.4853 | lr 3.00e-04 | grad 2.70 | tok/s 16280
step    410 | loss 1.2716 | lr 3.00e-04 | grad 2.08 | tok/s 15913
step    420 | loss 1.8162 | lr 3.00e-04 | grad 4.53 | tok/s 14327
step    430 | loss 2.1386 | lr 3.00e-04 | grad 3.09 | tok/s 16220
step    440 | loss 2.1522 | lr 3.00e-04 | grad 4.12 | tok/s 15310
step    450 | loss 2.0536 | lr 3.00e-04 | grad 2.83 | tok/s 15847
step    460 | loss 1.7175 | lr 3.00e-04 | grad 3.20 | tok/s 15540
step    470 | loss 1.8289 | lr 3.00e-04 | grad 2.61 | tok/s 16006
step    480 | loss 2.2302 | lr 3.00e-04 | grad 6.62 | tok/s 16025
step    490 | loss 1.7873 | lr 3.00e-04 | grad 2.59 | tok/s 15134
step    500 | loss 1.6791 | lr 3.00e-04 | grad 3.55 | tok/s 16113
step    510 | loss 1.7071 | lr 3.00e-04 | grad 2.48 | tok/s 16385
step    520 | loss 1.6569 | lr 3.00e-04 | grad 2.16 | tok/s 16339
step    530 | loss 1.9073 | lr 3.00e-04 | grad 2.52 | tok/s 15694
step    540 | loss 1.7370 | lr 3.00e-04 | grad 2.36 | tok/s 15709
step    550 | loss 1.5717 | lr 3.00e-04 | grad 2.97 | tok/s 15412
step    560 | loss 1.7305 | lr 3.00e-04 | grad 2.72 | tok/s 15009
step    570 | loss 1.6716 | lr 3.00e-04 | grad 3.67 | tok/s 14489
step    580 | loss 1.5483 | lr 3.00e-04 | grad 2.19 | tok/s 15425
step    590 | loss 1.8612 | lr 3.00e-04 | grad 3.16 | tok/s 15855
step    600 | loss 1.8275 | lr 3.00e-04 | grad 2.38 | tok/s 15332
step    610 | loss 1.6257 | lr 3.00e-04 | grad 2.53 | tok/s 16092
step    620 | loss 1.5474 | lr 3.00e-04 | grad 2.42 | tok/s 15284
step    630 | loss 1.6656 | lr 3.00e-04 | grad 4.53 | tok/s 15362
step    640 | loss 1.8122 | lr 3.00e-04 | grad 2.48 | tok/s 15787
step    650 | loss 1.6705 | lr 3.00e-04 | grad 2.58 | tok/s 15869
step    660 | loss 1.7005 | lr 3.00e-04 | grad 2.16 | tok/s 15959
step    670 | loss 1.9091 | lr 3.00e-04 | grad 3.48 | tok/s 16036
step    680 | loss 1.7341 | lr 3.00e-04 | grad 2.47 | tok/s 15676
step    690 | loss 1.8324 | lr 3.00e-04 | grad 3.34 | tok/s 16239
step    700 | loss 1.4203 | lr 3.00e-04 | grad 3.08 | tok/s 16562
step    710 | loss 1.5909 | lr 3.00e-04 | grad 2.44 | tok/s 15474
step    720 | loss 1.4806 | lr 3.00e-04 | grad 3.27 | tok/s 15209
step    730 | loss 1.2908 | lr 3.00e-04 | grad 2.86 | tok/s 16527
step    740 | loss 1.4958 | lr 3.00e-04 | grad 2.44 | tok/s 16302
step    750 | loss 1.2037 | lr 3.00e-04 | grad 2.66 | tok/s 16488
step    760 | loss 1.1125 | lr 3.00e-04 | grad 2.30 | tok/s 16519
step    770 | loss 1.0617 | lr 3.00e-04 | grad 2.12 | tok/s 16530
step    780 | loss 0.9991 | lr 3.00e-04 | grad 2.33 | tok/s 16528
step    790 | loss 1.1324 | lr 3.00e-04 | grad 3.31 | tok/s 16036
step    800 | loss 1.8195 | lr 3.00e-04 | grad 5.59 | tok/s 15956
step    810 | loss 1.7052 | lr 3.00e-04 | grad 2.12 | tok/s 15914
step    820 | loss 1.7208 | lr 3.00e-04 | grad 3.92 | tok/s 15281
step    830 | loss 1.4940 | lr 3.00e-04 | grad 2.30 | tok/s 16410
step    840 | loss 1.3545 | lr 3.00e-04 | grad 2.22 | tok/s 16556
step    850 | loss 1.5765 | lr 3.00e-04 | grad 2.16 | tok/s 16372
step    860 | loss 1.4741 | lr 3.00e-04 | grad 3.58 | tok/s 16045
step    870 | loss 1.5059 | lr 3.00e-04 | grad 2.75 | tok/s 15516
step    880 | loss 1.6896 | lr 3.00e-04 | grad 2.70 | tok/s 15604
step    890 | loss 1.6919 | lr 3.00e-04 | grad 3.03 | tok/s 15819
step    900 | loss 1.5731 | lr 3.00e-04 | grad 2.55 | tok/s 15839
step    910 | loss 1.4330 | lr 3.00e-04 | grad 4.00 | tok/s 15492
step    920 | loss 1.5261 | lr 3.00e-04 | grad 3.58 | tok/s 16107
step    930 | loss 1.6078 | lr 3.00e-04 | grad 3.59 | tok/s 15377
step    940 | loss 1.3914 | lr 3.00e-04 | grad 1.89 | tok/s 16196
step    950 | loss 1.4810 | lr 3.00e-04 | grad 2.36 | tok/s 16289
step    960 | loss 1.3264 | lr 3.00e-04 | grad 2.56 | tok/s 16332
step    970 | loss 1.7499 | lr 3.00e-04 | grad 3.47 | tok/s 15357
step    980 | loss 1.6487 | lr 3.00e-04 | grad 2.45 | tok/s 15759
step    990 | loss 1.4539 | lr 3.00e-04 | grad 2.16 | tok/s 16033
step   1000 | loss 1.8448 | lr 3.00e-04 | grad 9.25 | tok/s 15412
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8448.pt
step   1010 | loss 1.7384 | lr 3.00e-04 | grad 2.45 | tok/s 5709
step   1020 | loss 1.6904 | lr 3.00e-04 | grad 2.61 | tok/s 14133
step   1030 | loss 1.4115 | lr 3.00e-04 | grad 1.80 | tok/s 15820
step   1040 | loss 1.5247 | lr 3.00e-04 | grad 4.09 | tok/s 16130
step   1050 | loss 1.6137 | lr 3.00e-04 | grad 2.38 | tok/s 15211
step   1060 | loss 1.7094 | lr 3.00e-04 | grad 2.44 | tok/s 16248
step   1070 | loss 1.6526 | lr 3.00e-04 | grad 3.52 | tok/s 15995
step   1080 | loss 1.4120 | lr 3.00e-04 | grad 2.52 | tok/s 14772
step   1090 | loss 1.0070 | lr 3.00e-04 | grad 1.21 | tok/s 16390
step   1100 | loss 1.5779 | lr 3.00e-04 | grad 2.91 | tok/s 15708
step   1110 | loss 1.4238 | lr 3.00e-04 | grad 2.14 | tok/s 16541
step   1120 | loss 1.3377 | lr 3.00e-04 | grad 2.28 | tok/s 16507
step   1130 | loss 1.2845 | lr 3.00e-04 | grad 2.17 | tok/s 16489
step   1140 | loss 1.2903 | lr 3.00e-04 | grad 1.94 | tok/s 16497
step   1150 | loss 1.2946 | lr 3.00e-04 | grad 2.12 | tok/s 16490
step   1160 | loss 1.2114 | lr 3.00e-04 | grad 1.99 | tok/s 16489
step   1170 | loss 1.2567 | lr 3.00e-04 | grad 2.20 | tok/s 16483
step   1180 | loss 1.3117 | lr 3.00e-04 | grad 1.81 | tok/s 16485
step   1190 | loss 1.2166 | lr 3.00e-04 | grad 2.23 | tok/s 16490
step   1200 | loss 1.2197 | lr 3.00e-04 | grad 1.88 | tok/s 16488
step   1210 | loss 1.2583 | lr 3.00e-04 | grad 1.77 | tok/s 16480
step   1220 | loss 1.2854 | lr 3.00e-04 | grad 1.88 | tok/s 16497
step   1230 | loss 1.2557 | lr 3.00e-04 | grad 1.77 | tok/s 16462
step   1240 | loss 1.2630 | lr 3.00e-04 | grad 3.00 | tok/s 16329
step   1250 | loss 1.8006 | lr 3.00e-04 | grad 2.59 | tok/s 15625
step   1260 | loss 1.3375 | lr 3.00e-04 | grad 14.75 | tok/s 15412
step   1270 | loss 1.7804 | lr 3.00e-04 | grad 3.17 | tok/s 15343
step   1280 | loss 1.5826 | lr 3.00e-04 | grad 2.66 | tok/s 15153
step   1290 | loss 1.4990 | lr 3.00e-04 | grad 2.75 | tok/s 15775
step   1300 | loss 1.5186 | lr 3.00e-04 | grad 2.17 | tok/s 15633
step   1310 | loss 1.4549 | lr 3.00e-04 | grad 2.00 | tok/s 16432
step   1320 | loss 1.5975 | lr 3.00e-04 | grad 2.48 | tok/s 16213
step   1330 | loss 1.5347 | lr 3.00e-04 | grad 2.28 | tok/s 16236
step   1340 | loss 1.5901 | lr 3.00e-04 | grad 3.45 | tok/s 15324
step   1350 | loss 1.7236 | lr 3.00e-04 | grad 2.38 | tok/s 15145
step   1360 | loss 1.4780 | lr 3.00e-04 | grad 1.87 | tok/s 15927
step   1370 | loss 1.5165 | lr 3.00e-04 | grad 6.91 | tok/s 15724
step   1380 | loss 1.5979 | lr 3.00e-04 | grad 3.19 | tok/s 15123
step   1390 | loss 1.4877 | lr 3.00e-04 | grad 4.44 | tok/s 15926
step   1400 | loss 1.3807 | lr 3.00e-04 | grad 1.69 | tok/s 15482
step   1410 | loss 1.5259 | lr 3.00e-04 | grad 7.72 | tok/s 15487
step   1420 | loss 1.6462 | lr 3.00e-04 | grad 2.19 | tok/s 15453
step   1430 | loss 1.3404 | lr 3.00e-04 | grad 2.33 | tok/s 15675
step   1440 | loss 1.1400 | lr 3.00e-04 | grad 2.11 | tok/s 16459
step   1450 | loss 1.1683 | lr 3.00e-04 | grad 2.42 | tok/s 16253
step   1460 | loss 1.6976 | lr 3.00e-04 | grad 2.34 | tok/s 14588
step   1470 | loss 1.5215 | lr 3.00e-04 | grad 2.12 | tok/s 16301
step   1480 | loss 1.8387 | lr 3.00e-04 | grad 3.33 | tok/s 16149
step   1490 | loss 1.5608 | lr 3.00e-04 | grad 2.75 | tok/s 16370
step   1500 | loss 1.3009 | lr 3.00e-04 | grad 2.11 | tok/s 16452
step   1510 | loss 1.5405 | lr 3.00e-04 | grad 2.75 | tok/s 16228
step   1520 | loss 1.4402 | lr 3.00e-04 | grad 2.84 | tok/s 15891
step   1530 | loss 1.4568 | lr 3.00e-04 | grad 2.95 | tok/s 16291
step   1540 | loss 1.6366 | lr 3.00e-04 | grad 2.70 | tok/s 15311
step   1550 | loss 1.2707 | lr 3.00e-04 | grad 2.73 | tok/s 16331
step   1560 | loss 1.5940 | lr 3.00e-04 | grad 2.05 | tok/s 15472
step   1570 | loss 1.2762 | lr 3.00e-04 | grad 2.30 | tok/s 16268
step   1580 | loss 1.7093 | lr 3.00e-04 | grad 4.59 | tok/s 16229
step   1590 | loss 1.5923 | lr 3.00e-04 | grad 2.25 | tok/s 15452
step   1600 | loss 0.9164 | lr 3.00e-04 | grad 1.14 | tok/s 16488
step   1610 | loss 1.1078 | lr 3.00e-04 | grad 1.93 | tok/s 14636
step   1620 | loss 1.4016 | lr 3.00e-04 | grad 3.12 | tok/s 15455
step   1630 | loss 1.3572 | lr 3.00e-04 | grad 1.83 | tok/s 16128
step   1640 | loss 1.3601 | lr 3.00e-04 | grad 2.16 | tok/s 15657
step   1650 | loss 1.5681 | lr 3.00e-04 | grad 2.78 | tok/s 14803
step   1660 | loss 1.3311 | lr 3.00e-04 | grad 1.72 | tok/s 16559
step   1670 | loss 1.4157 | lr 3.00e-04 | grad 3.59 | tok/s 15945
step   1680 | loss 1.6839 | lr 3.00e-04 | grad 1.85 | tok/s 15252
step   1690 | loss 1.5054 | lr 3.00e-04 | grad 3.50 | tok/s 15980
step   1700 | loss 1.5195 | lr 3.00e-04 | grad 2.03 | tok/s 15834
step   1710 | loss 1.4250 | lr 3.00e-04 | grad 2.22 | tok/s 15857
step   1720 | loss 1.5142 | lr 3.00e-04 | grad 2.78 | tok/s 16539
step   1730 | loss 1.1888 | lr 3.00e-04 | grad 2.52 | tok/s 16592
step   1740 | loss 1.3962 | lr 3.00e-04 | grad 2.59 | tok/s 16063
step   1750 | loss 1.5556 | lr 3.00e-04 | grad 2.73 | tok/s 16035
step   1760 | loss 1.5758 | lr 3.00e-04 | grad 2.20 | tok/s 15924
step   1770 | loss 1.4546 | lr 3.00e-04 | grad 2.41 | tok/s 15648
step   1780 | loss 1.4923 | lr 3.00e-04 | grad 2.00 | tok/s 16191
step   1790 | loss 1.4320 | lr 3.00e-04 | grad 3.03 | tok/s 15997
step   1800 | loss 1.5818 | lr 3.00e-04 | grad 1.97 | tok/s 15643
step   1810 | loss 1.4609 | lr 3.00e-04 | grad 3.52 | tok/s 15422
step   1820 | loss 1.4771 | lr 3.00e-04 | grad 7.28 | tok/s 15852
step   1830 | loss 1.4416 | lr 3.00e-04 | grad 3.73 | tok/s 16226
step   1840 | loss 1.4942 | lr 3.00e-04 | grad 1.86 | tok/s 15439
step   1850 | loss 1.2765 | lr 3.00e-04 | grad 1.99 | tok/s 16479
step   1860 | loss 1.3664 | lr 3.00e-04 | grad 2.64 | tok/s 15614
step   1870 | loss 1.3698 | lr 3.00e-04 | grad 1.73 | tok/s 15963
step   1880 | loss 1.2806 | lr 3.00e-04 | grad 2.94 | tok/s 15349
step   1890 | loss 1.5346 | lr 3.00e-04 | grad 2.09 | tok/s 14861
step   1900 | loss 1.3955 | lr 3.00e-04 | grad 2.28 | tok/s 15932
step   1910 | loss 1.4902 | lr 3.00e-04 | grad 2.17 | tok/s 15120
step   1920 | loss 1.3832 | lr 3.00e-04 | grad 1.94 | tok/s 16571
step   1930 | loss 1.4587 | lr 3.00e-04 | grad 3.17 | tok/s 15239
step   1940 | loss 1.4568 | lr 3.00e-04 | grad 2.25 | tok/s 16373
step   1950 | loss 1.8645 | lr 3.00e-04 | grad 3.52 | tok/s 16371
step   1960 | loss 1.4465 | lr 3.00e-04 | grad 4.28 | tok/s 16535
step   1970 | loss 1.4920 | lr 3.00e-04 | grad 2.39 | tok/s 16106
step   1980 | loss 1.5643 | lr 3.00e-04 | grad 2.28 | tok/s 15404
step   1990 | loss 1.6110 | lr 3.00e-04 | grad 2.66 | tok/s 15683
step   2000 | loss 1.5073 | lr 3.00e-04 | grad 2.53 | tok/s 15958
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5073.pt
step   2010 | loss 1.1694 | lr 3.00e-04 | grad 2.17 | tok/s 6427
step   2020 | loss 1.3213 | lr 3.00e-04 | grad 2.86 | tok/s 16144
step   2030 | loss 0.9463 | lr 3.00e-04 | grad 4.56 | tok/s 16582
step   2040 | loss 1.3342 | lr 3.00e-04 | grad 2.48 | tok/s 15655
step   2050 | loss 1.2469 | lr 3.00e-04 | grad 2.20 | tok/s 15976
step   2060 | loss 1.6342 | lr 3.00e-04 | grad 2.34 | tok/s 15565
step   2070 | loss 1.8283 | lr 3.00e-04 | grad 6.28 | tok/s 15695
step   2080 | loss 2.1640 | lr 3.00e-04 | grad 4.19 | tok/s 16548
step   2090 | loss 1.6316 | lr 3.00e-04 | grad 2.47 | tok/s 16228
step   2100 | loss 1.3995 | lr 3.00e-04 | grad 2.61 | tok/s 16242
step   2110 | loss 1.4678 | lr 3.00e-04 | grad 2.16 | tok/s 15408
step   2120 | loss 0.8586 | lr 3.00e-04 | grad 1.84 | tok/s 16598
step   2130 | loss 1.2628 | lr 3.00e-04 | grad 3.81 | tok/s 15901
step   2140 | loss 1.4564 | lr 3.00e-04 | grad 1.85 | tok/s 16061
step   2150 | loss 1.2925 | lr 3.00e-04 | grad 2.06 | tok/s 16515
step   2160 | loss 1.1800 | lr 3.00e-04 | grad 2.27 | tok/s 16533
step   2170 | loss 1.2410 | lr 3.00e-04 | grad 1.67 | tok/s 16518
step   2180 | loss 1.1881 | lr 3.00e-04 | grad 1.72 | tok/s 16489
step   2190 | loss 1.2114 | lr 3.00e-04 | grad 1.96 | tok/s 16484
step   2200 | loss 1.1766 | lr 3.00e-04 | grad 1.70 | tok/s 16477
step   2210 | loss 1.1427 | lr 3.00e-04 | grad 1.95 | tok/s 16512
step   2220 | loss 1.1359 | lr 3.00e-04 | grad 1.82 | tok/s 16486
step   2230 | loss 1.4019 | lr 3.00e-04 | grad 2.61 | tok/s 15542
step   2240 | loss 1.3114 | lr 3.00e-04 | grad 2.14 | tok/s 15863
step   2250 | loss 1.6021 | lr 3.00e-04 | grad 7.34 | tok/s 16439
step   2260 | loss 1.5934 | lr 3.00e-04 | grad 2.33 | tok/s 15882
step   2270 | loss 1.9281 | lr 3.00e-04 | grad 2.36 | tok/s 16284
step   2280 | loss 1.4266 | lr 3.00e-04 | grad 2.69 | tok/s 16442
step   2290 | loss 1.4568 | lr 3.00e-04 | grad 5.53 | tok/s 15867
step   2300 | loss 1.4406 | lr 3.00e-04 | grad 3.09 | tok/s 16128
step   2310 | loss 1.4172 | lr 3.00e-04 | grad 2.72 | tok/s 15519
step   2320 | loss 1.8790 | lr 3.00e-04 | grad 3.39 | tok/s 15471
step   2330 | loss 1.5955 | lr 3.00e-04 | grad 3.67 | tok/s 15555

Training complete! Final step: 2333
