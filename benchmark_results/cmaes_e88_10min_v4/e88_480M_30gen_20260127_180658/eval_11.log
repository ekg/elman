Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_11/levelE88_100m_20260127_181737
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 486,391,568 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1252 | lr 3.00e-04 | grad 18.62 | tok/s 5726
step     20 | loss 2.8311 | lr 3.00e-04 | grad 10.31 | tok/s 16310
step     30 | loss 2.6873 | lr 3.00e-04 | grad 7.19 | tok/s 16475
step     40 | loss 2.4555 | lr 3.00e-04 | grad 4.84 | tok/s 15747
step     50 | loss 3.0327 | lr 3.00e-04 | grad 16.62 | tok/s 15884
step     60 | loss 2.0540 | lr 3.00e-04 | grad 4.56 | tok/s 16414
step     70 | loss 1.8996 | lr 3.00e-04 | grad 5.28 | tok/s 16570
step     80 | loss 6.5681 | lr 3.00e-04 | grad 71.00 | tok/s 16714
step     90 | loss 5.7222 | lr 3.00e-04 | grad 10.19 | tok/s 17002
step    100 | loss 4.2327 | lr 3.00e-04 | grad 9.44 | tok/s 16945
step    110 | loss 3.5207 | lr 3.00e-04 | grad 18.38 | tok/s 16975
step    120 | loss 3.1805 | lr 3.00e-04 | grad 12.88 | tok/s 16896
step    130 | loss 2.9950 | lr 3.00e-04 | grad 16.62 | tok/s 16833
step    140 | loss 2.7666 | lr 3.00e-04 | grad 11.38 | tok/s 16684
step    150 | loss 2.7625 | lr 3.00e-04 | grad 11.56 | tok/s 16547
step    160 | loss 2.3801 | lr 3.00e-04 | grad 10.75 | tok/s 16697
step    170 | loss 2.4359 | lr 3.00e-04 | grad 12.56 | tok/s 16805
step    180 | loss 2.2554 | lr 3.00e-04 | grad 8.81 | tok/s 16724
step    190 | loss 2.4018 | lr 3.00e-04 | grad 6.53 | tok/s 16879
step    200 | loss 2.1210 | lr 3.00e-04 | grad 5.75 | tok/s 16052
step    210 | loss 2.1598 | lr 3.00e-04 | grad 7.25 | tok/s 16620
step    220 | loss 2.1727 | lr 3.00e-04 | grad 3.94 | tok/s 16598
step    230 | loss 2.0606 | lr 3.00e-04 | grad 3.83 | tok/s 16367
step    240 | loss 2.3076 | lr 3.00e-04 | grad 5.12 | tok/s 15282
step    250 | loss 2.1132 | lr 3.00e-04 | grad 2.88 | tok/s 15835
step    260 | loss 1.5380 | lr 3.00e-04 | grad 3.27 | tok/s 16364
step    270 | loss 2.0773 | lr 3.00e-04 | grad 3.20 | tok/s 16282
step    280 | loss 2.2386 | lr 3.00e-04 | grad 6.94 | tok/s 15860
step    290 | loss 1.3884 | lr 3.00e-04 | grad 3.53 | tok/s 16764
step    300 | loss 0.5526 | lr 3.00e-04 | grad 2.72 | tok/s 16759
step    310 | loss 2.4275 | lr 3.00e-04 | grad 4.06 | tok/s 16456
step    320 | loss 1.9160 | lr 3.00e-04 | grad 5.97 | tok/s 16184
step    330 | loss 1.9432 | lr 3.00e-04 | grad 3.19 | tok/s 15548
step    340 | loss 2.2958 | lr 3.00e-04 | grad 3.12 | tok/s 15779
step    350 | loss 1.8434 | lr 3.00e-04 | grad 3.92 | tok/s 16143
step    360 | loss 1.1852 | lr 3.00e-04 | grad 8.88 | tok/s 16597
step    370 | loss 1.8016 | lr 3.00e-04 | grad 2.78 | tok/s 14962
step    380 | loss 1.7701 | lr 3.00e-04 | grad 2.94 | tok/s 15915
step    390 | loss 1.5311 | lr 3.00e-04 | grad 2.44 | tok/s 16703
step    400 | loss 1.4849 | lr 3.00e-04 | grad 2.92 | tok/s 16538
step    410 | loss 1.2618 | lr 3.00e-04 | grad 2.20 | tok/s 16193
step    420 | loss 1.8139 | lr 3.00e-04 | grad 4.75 | tok/s 15424
step    430 | loss 2.1616 | lr 3.00e-04 | grad 3.38 | tok/s 16445
step    440 | loss 2.1538 | lr 3.00e-04 | grad 4.31 | tok/s 15557
step    450 | loss 2.0555 | lr 3.00e-04 | grad 2.89 | tok/s 16147
step    460 | loss 1.7191 | lr 3.00e-04 | grad 3.31 | tok/s 15782
step    470 | loss 1.8345 | lr 3.00e-04 | grad 2.80 | tok/s 16216
step    480 | loss 2.2599 | lr 3.00e-04 | grad 7.00 | tok/s 16228
step    490 | loss 1.7909 | lr 3.00e-04 | grad 2.75 | tok/s 15379
step    500 | loss 1.6812 | lr 3.00e-04 | grad 3.77 | tok/s 16315
step    510 | loss 1.7075 | lr 3.00e-04 | grad 2.80 | tok/s 16590
step    520 | loss 1.6570 | lr 3.00e-04 | grad 2.23 | tok/s 16634
step    530 | loss 1.9069 | lr 3.00e-04 | grad 2.59 | tok/s 15972
step    540 | loss 1.7377 | lr 3.00e-04 | grad 2.56 | tok/s 14742
step    550 | loss 1.5721 | lr 3.00e-04 | grad 3.14 | tok/s 15633
step    560 | loss 1.7256 | lr 3.00e-04 | grad 2.81 | tok/s 15242
step    570 | loss 1.6687 | lr 3.00e-04 | grad 3.86 | tok/s 15654
step    580 | loss 1.5507 | lr 3.00e-04 | grad 2.42 | tok/s 15615
step    590 | loss 1.8593 | lr 3.00e-04 | grad 3.34 | tok/s 16001
step    600 | loss 1.8269 | lr 3.00e-04 | grad 2.39 | tok/s 15431
step    610 | loss 1.6190 | lr 3.00e-04 | grad 2.61 | tok/s 15891
step    620 | loss 1.5498 | lr 3.00e-04 | grad 2.50 | tok/s 14461
step    630 | loss 1.6589 | lr 3.00e-04 | grad 4.50 | tok/s 14966
step    640 | loss 1.8118 | lr 3.00e-04 | grad 2.56 | tok/s 15792
step    650 | loss 1.6776 | lr 3.00e-04 | grad 2.70 | tok/s 15929
step    660 | loss 1.7008 | lr 3.00e-04 | grad 2.25 | tok/s 15987
step    670 | loss 1.9342 | lr 3.00e-04 | grad 3.41 | tok/s 16109
step    680 | loss 1.7350 | lr 3.00e-04 | grad 2.56 | tok/s 15773
step    690 | loss 1.8233 | lr 3.00e-04 | grad 3.34 | tok/s 16297
step    700 | loss 1.4107 | lr 3.00e-04 | grad 3.14 | tok/s 16625
step    710 | loss 1.5933 | lr 3.00e-04 | grad 2.62 | tok/s 15565
step    720 | loss 1.4750 | lr 3.00e-04 | grad 4.00 | tok/s 15348
step    730 | loss 1.2859 | lr 3.00e-04 | grad 3.03 | tok/s 16633
step    740 | loss 1.4993 | lr 3.00e-04 | grad 2.53 | tok/s 16425
step    750 | loss 1.1993 | lr 3.00e-04 | grad 2.70 | tok/s 16668
step    760 | loss 1.1042 | lr 3.00e-04 | grad 2.34 | tok/s 16635
step    770 | loss 1.0563 | lr 3.00e-04 | grad 2.20 | tok/s 16651
step    780 | loss 0.9903 | lr 3.00e-04 | grad 2.22 | tok/s 16697
step    790 | loss 1.1289 | lr 3.00e-04 | grad 3.47 | tok/s 16175
step    800 | loss 1.8243 | lr 3.00e-04 | grad 5.62 | tok/s 16105
step    810 | loss 1.7092 | lr 3.00e-04 | grad 2.23 | tok/s 15992
step    820 | loss 1.7180 | lr 3.00e-04 | grad 4.22 | tok/s 15335
step    830 | loss 1.5329 | lr 3.00e-04 | grad 2.47 | tok/s 16451
step    840 | loss 1.3535 | lr 3.00e-04 | grad 2.34 | tok/s 16601
step    850 | loss 1.5818 | lr 3.00e-04 | grad 2.25 | tok/s 16565
step    860 | loss 1.4711 | lr 3.00e-04 | grad 3.97 | tok/s 16380
step    870 | loss 1.5079 | lr 3.00e-04 | grad 2.94 | tok/s 15828
step    880 | loss 1.6834 | lr 3.00e-04 | grad 2.70 | tok/s 15903
step    890 | loss 1.6860 | lr 3.00e-04 | grad 3.20 | tok/s 16140
step    900 | loss 1.5749 | lr 3.00e-04 | grad 2.66 | tok/s 16139
step    910 | loss 1.4320 | lr 3.00e-04 | grad 4.09 | tok/s 15791
step    920 | loss 1.5333 | lr 3.00e-04 | grad 3.72 | tok/s 16407
step    930 | loss 1.6095 | lr 3.00e-04 | grad 3.62 | tok/s 15655
step    940 | loss 1.3932 | lr 3.00e-04 | grad 2.08 | tok/s 16502
step    950 | loss 1.5189 | lr 3.00e-04 | grad 3.16 | tok/s 16585
step    960 | loss 1.3326 | lr 3.00e-04 | grad 2.72 | tok/s 16613
step    970 | loss 1.7611 | lr 3.00e-04 | grad 3.84 | tok/s 15652
step    980 | loss 1.6484 | lr 3.00e-04 | grad 2.59 | tok/s 16049
step    990 | loss 1.4522 | lr 3.00e-04 | grad 2.28 | tok/s 16270
step   1000 | loss 1.8446 | lr 3.00e-04 | grad 9.62 | tok/s 15605
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8446.pt
step   1010 | loss 1.7153 | lr 3.00e-04 | grad 4.00 | tok/s 5010
step   1020 | loss 1.6671 | lr 3.00e-04 | grad 2.48 | tok/s 15348
step   1030 | loss 1.4042 | lr 3.00e-04 | grad 2.34 | tok/s 16272
step   1040 | loss 1.5209 | lr 3.00e-04 | grad 2.41 | tok/s 16154
step   1050 | loss 1.6390 | lr 3.00e-04 | grad 2.89 | tok/s 15715
step   1060 | loss 1.6855 | lr 3.00e-04 | grad 2.38 | tok/s 14034
step   1070 | loss 1.6700 | lr 3.00e-04 | grad 2.59 | tok/s 16051
step   1080 | loss 1.4074 | lr 3.00e-04 | grad 2.64 | tok/s 15119
step   1090 | loss 1.0299 | lr 3.00e-04 | grad 5.62 | tok/s 16725
step   1100 | loss 1.5615 | lr 3.00e-04 | grad 2.72 | tok/s 16071
step   1110 | loss 1.4057 | lr 3.00e-04 | grad 2.23 | tok/s 16775
step   1120 | loss 1.3345 | lr 3.00e-04 | grad 2.56 | tok/s 16749
step   1130 | loss 1.2785 | lr 3.00e-04 | grad 2.33 | tok/s 16740
step   1140 | loss 1.2879 | lr 3.00e-04 | grad 2.23 | tok/s 16745
step   1150 | loss 1.2776 | lr 3.00e-04 | grad 2.03 | tok/s 16709
step   1160 | loss 1.2071 | lr 3.00e-04 | grad 2.09 | tok/s 16721
step   1170 | loss 1.2827 | lr 3.00e-04 | grad 2.22 | tok/s 16775
step   1180 | loss 1.2962 | lr 3.00e-04 | grad 2.62 | tok/s 16705
step   1190 | loss 1.2067 | lr 3.00e-04 | grad 1.94 | tok/s 16736
step   1200 | loss 1.2304 | lr 3.00e-04 | grad 1.92 | tok/s 16737
step   1210 | loss 1.2607 | lr 3.00e-04 | grad 2.09 | tok/s 16714
step   1220 | loss 1.2755 | lr 3.00e-04 | grad 2.14 | tok/s 16726
step   1230 | loss 1.2522 | lr 3.00e-04 | grad 1.87 | tok/s 16740
step   1240 | loss 1.3826 | lr 3.00e-04 | grad 7.16 | tok/s 16327
step   1250 | loss 1.7157 | lr 3.00e-04 | grad 2.34 | tok/s 15939
step   1260 | loss 1.3465 | lr 3.00e-04 | grad 2.48 | tok/s 15651
step   1270 | loss 1.7440 | lr 3.00e-04 | grad 2.58 | tok/s 15450
step   1280 | loss 1.5766 | lr 3.00e-04 | grad 2.23 | tok/s 16377
step   1290 | loss 1.5317 | lr 3.00e-04 | grad 2.75 | tok/s 16106
step   1300 | loss 1.5113 | lr 3.00e-04 | grad 3.58 | tok/s 12744
step   1310 | loss 1.4518 | lr 3.00e-04 | grad 3.70 | tok/s 16370
step   1320 | loss 1.6342 | lr 3.00e-04 | grad 4.06 | tok/s 16244
step   1330 | loss 1.4150 | lr 3.00e-04 | grad 2.41 | tok/s 16322
step   1340 | loss 1.6471 | lr 3.00e-04 | grad 2.20 | tok/s 15093
step   1350 | loss 1.7691 | lr 3.00e-04 | grad 3.38 | tok/s 15337
step   1360 | loss 1.4427 | lr 3.00e-04 | grad 2.02 | tok/s 16079
step   1370 | loss 1.5563 | lr 3.00e-04 | grad 4.47 | tok/s 15870
step   1380 | loss 1.5799 | lr 3.00e-04 | grad 3.11 | tok/s 15263
step   1390 | loss 1.4396 | lr 3.00e-04 | grad 2.09 | tok/s 15813
step   1400 | loss 1.3880 | lr 3.00e-04 | grad 2.16 | tok/s 15726
step   1410 | loss 1.5732 | lr 3.00e-04 | grad 3.95 | tok/s 15538
step   1420 | loss 1.6145 | lr 3.00e-04 | grad 2.69 | tok/s 15289
step   1430 | loss 1.3303 | lr 3.00e-04 | grad 2.42 | tok/s 15815
step   1440 | loss 1.1352 | lr 3.00e-04 | grad 2.19 | tok/s 16693
step   1450 | loss 1.2942 | lr 3.00e-04 | grad 7.22 | tok/s 16436
step   1460 | loss 1.6918 | lr 3.00e-04 | grad 5.84 | tok/s 15541
step   1470 | loss 1.4278 | lr 3.00e-04 | grad 1.96 | tok/s 16518
step   1480 | loss 1.8567 | lr 3.00e-04 | grad 4.03 | tok/s 16360
step   1490 | loss 1.5737 | lr 3.00e-04 | grad 4.91 | tok/s 16588
step   1500 | loss 1.2751 | lr 3.00e-04 | grad 2.06 | tok/s 16646
step   1510 | loss 1.5727 | lr 3.00e-04 | grad 2.27 | tok/s 16415
step   1520 | loss 1.4670 | lr 3.00e-04 | grad 2.64 | tok/s 16114
step   1530 | loss 1.4269 | lr 3.00e-04 | grad 2.20 | tok/s 16189
step   1540 | loss 1.6581 | lr 3.00e-04 | grad 2.44 | tok/s 15872
step   1550 | loss 1.2512 | lr 3.00e-04 | grad 2.45 | tok/s 12842
step   1560 | loss 1.6078 | lr 3.00e-04 | grad 2.42 | tok/s 10768
step   1570 | loss 1.3312 | lr 3.00e-04 | grad 3.36 | tok/s 11132
step   1580 | loss 1.6744 | lr 3.00e-04 | grad 3.56 | tok/s 11148
step   1590 | loss 1.5607 | lr 3.00e-04 | grad 2.05 | tok/s 14713
step   1600 | loss 0.8520 | lr 3.00e-04 | grad 1.56 | tok/s 14825
step   1610 | loss 1.1946 | lr 3.00e-04 | grad 2.08 | tok/s 15552
step   1620 | loss 1.3420 | lr 3.00e-04 | grad 2.91 | tok/s 15796
step   1630 | loss 1.3754 | lr 3.00e-04 | grad 2.23 | tok/s 16213
step   1640 | loss 1.4577 | lr 3.00e-04 | grad 4.75 | tok/s 15625
step   1650 | loss 1.5747 | lr 3.00e-04 | grad 4.09 | tok/s 14896
step   1660 | loss 1.2311 | lr 3.00e-04 | grad 1.84 | tok/s 16809
step   1670 | loss 1.6203 | lr 3.00e-04 | grad 8.06 | tok/s 15836
step   1680 | loss 1.5536 | lr 3.00e-04 | grad 2.75 | tok/s 15519
step   1690 | loss 1.4455 | lr 3.00e-04 | grad 3.48 | tok/s 16166
step   1700 | loss 1.5324 | lr 3.00e-04 | grad 2.31 | tok/s 15521
step   1710 | loss 1.4471 | lr 3.00e-04 | grad 2.52 | tok/s 16212
step   1720 | loss 1.5013 | lr 3.00e-04 | grad 3.17 | tok/s 16710
step   1730 | loss 1.1983 | lr 3.00e-04 | grad 3.95 | tok/s 16648
step   1740 | loss 1.4037 | lr 3.00e-04 | grad 2.58 | tok/s 16016
step   1750 | loss 1.5149 | lr 3.00e-04 | grad 2.45 | tok/s 16311
step   1760 | loss 1.6059 | lr 3.00e-04 | grad 2.80 | tok/s 16123
step   1770 | loss 1.4375 | lr 3.00e-04 | grad 2.02 | tok/s 15656
step   1780 | loss 1.4960 | lr 3.00e-04 | grad 2.89 | tok/s 16023
step   1790 | loss 1.4238 | lr 3.00e-04 | grad 2.12 | tok/s 12639
step   1800 | loss 1.5684 | lr 3.00e-04 | grad 2.44 | tok/s 15539
step   1810 | loss 1.4793 | lr 3.00e-04 | grad 3.08 | tok/s 15624
step   1820 | loss 1.4969 | lr 3.00e-04 | grad 5.84 | tok/s 15231
step   1830 | loss 1.4516 | lr 3.00e-04 | grad 2.52 | tok/s 16345
step   1840 | loss 1.4464 | lr 3.00e-04 | grad 1.75 | tok/s 15596
step   1850 | loss 1.2889 | lr 3.00e-04 | grad 2.02 | tok/s 16610
step   1860 | loss 1.3635 | lr 3.00e-04 | grad 2.44 | tok/s 15427
step   1870 | loss 1.3424 | lr 3.00e-04 | grad 1.58 | tok/s 15838
step   1880 | loss 1.3138 | lr 3.00e-04 | grad 2.62 | tok/s 14685
step   1890 | loss 1.5585 | lr 3.00e-04 | grad 2.02 | tok/s 15349
step   1900 | loss 1.3724 | lr 3.00e-04 | grad 2.11 | tok/s 15599
step   1910 | loss 1.4984 | lr 3.00e-04 | grad 1.98 | tok/s 15088
step   1920 | loss 1.3616 | lr 3.00e-04 | grad 2.06 | tok/s 16482
step   1930 | loss 1.4853 | lr 3.00e-04 | grad 2.19 | tok/s 15544
step   1940 | loss 1.4748 | lr 3.00e-04 | grad 3.28 | tok/s 16251
step   1950 | loss 1.8109 | lr 3.00e-04 | grad 3.39 | tok/s 16567
step   1960 | loss 1.4393 | lr 3.00e-04 | grad 3.77 | tok/s 16471
step   1970 | loss 1.5403 | lr 3.00e-04 | grad 5.16 | tok/s 15610
step   1980 | loss 1.4961 | lr 3.00e-04 | grad 1.81 | tok/s 15545
step   1990 | loss 1.6396 | lr 3.00e-04 | grad 2.11 | tok/s 15795
step   2000 | loss 1.5041 | lr 3.00e-04 | grad 2.30 | tok/s 16120
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5041.pt
step   2010 | loss 1.2054 | lr 3.00e-04 | grad 2.67 | tok/s 4894
step   2020 | loss 1.3210 | lr 3.00e-04 | grad 2.81 | tok/s 16263
step   2030 | loss 1.0003 | lr 3.00e-04 | grad 2.83 | tok/s 14035
step   2040 | loss 1.2108 | lr 3.00e-04 | grad 1.92 | tok/s 17004
step   2050 | loss 1.3592 | lr 3.00e-04 | grad 3.05 | tok/s 16320
step   2060 | loss 1.6645 | lr 3.00e-04 | grad 2.78 | tok/s 16083
step   2070 | loss 1.9898 | lr 3.00e-04 | grad 5.31 | tok/s 16064
step   2080 | loss 2.0576 | lr 3.00e-04 | grad 4.31 | tok/s 16946
step   2090 | loss 1.5864 | lr 3.00e-04 | grad 4.22 | tok/s 16496
step   2100 | loss 1.2957 | lr 3.00e-04 | grad 2.73 | tok/s 16768
step   2110 | loss 1.5012 | lr 3.00e-04 | grad 1.99 | tok/s 15716
step   2120 | loss 0.7180 | lr 3.00e-04 | grad 1.39 | tok/s 16068
step   2130 | loss 1.4451 | lr 3.00e-04 | grad 2.38 | tok/s 15849
step   2140 | loss 1.4347 | lr 3.00e-04 | grad 2.55 | tok/s 16532
step   2150 | loss 1.2708 | lr 3.00e-04 | grad 1.93 | tok/s 15741
step   2160 | loss 1.2045 | lr 3.00e-04 | grad 2.03 | tok/s 14763
step   2170 | loss 1.1964 | lr 3.00e-04 | grad 2.00 | tok/s 16486
step   2180 | loss 1.2010 | lr 3.00e-04 | grad 1.93 | tok/s 15301
step   2190 | loss 1.2246 | lr 3.00e-04 | grad 1.84 | tok/s 16527
step   2200 | loss 1.1561 | lr 3.00e-04 | grad 1.81 | tok/s 16402
step   2210 | loss 1.1353 | lr 3.00e-04 | grad 1.66 | tok/s 16726
step   2220 | loss 1.1238 | lr 3.00e-04 | grad 1.66 | tok/s 16747
step   2230 | loss 1.4556 | lr 3.00e-04 | grad 2.22 | tok/s 16476
step   2240 | loss 1.3671 | lr 3.00e-04 | grad 3.17 | tok/s 16027
step   2250 | loss 1.5297 | lr 3.00e-04 | grad 3.34 | tok/s 16496
step   2260 | loss 1.6115 | lr 3.00e-04 | grad 1.86 | tok/s 15954
step   2270 | loss 1.9436 | lr 3.00e-04 | grad 2.45 | tok/s 16325
step   2280 | loss 1.3734 | lr 3.00e-04 | grad 2.44 | tok/s 12934
step   2290 | loss 1.5334 | lr 3.00e-04 | grad 2.34 | tok/s 15828
step   2300 | loss 1.4539 | lr 3.00e-04 | grad 4.03 | tok/s 16062
step   2310 | loss 1.4593 | lr 3.00e-04 | grad 4.53 | tok/s 15706

Training complete! Final step: 2316
