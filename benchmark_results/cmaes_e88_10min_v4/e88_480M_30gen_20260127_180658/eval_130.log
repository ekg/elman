Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_130/levelE88_100m_20260127_205307
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 475,548,460 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.5762 | lr 3.00e-04 | grad 20.38 | tok/s 9828
step     20 | loss 3.3125 | lr 3.00e-04 | grad 6.53 | tok/s 19352
step     30 | loss 3.1797 | lr 3.00e-04 | grad 7.16 | tok/s 20438
step     40 | loss 4.3656 | lr 3.00e-04 | grad 20.25 | tok/s 20811
step     50 | loss 4.2512 | lr 3.00e-04 | grad 14.69 | tok/s 21029
step     60 | loss 3.3260 | lr 3.00e-04 | grad 8.19 | tok/s 20928
step     70 | loss 2.8720 | lr 3.00e-04 | grad 5.34 | tok/s 20894
step     80 | loss 2.5979 | lr 3.00e-04 | grad 4.84 | tok/s 20870
step     90 | loss 2.4848 | lr 3.00e-04 | grad 4.94 | tok/s 20826
step    100 | loss 2.2434 | lr 3.00e-04 | grad 3.70 | tok/s 20798
step    110 | loss 2.2112 | lr 3.00e-04 | grad 5.19 | tok/s 20648
step    120 | loss 2.7103 | lr 3.00e-04 | grad 2.98 | tok/s 19690
step    130 | loss 2.0255 | lr 3.00e-04 | grad 6.44 | tok/s 20081
step    140 | loss 2.3240 | lr 3.00e-04 | grad 8.12 | tok/s 20173
step    150 | loss 1.3281 | lr 3.00e-04 | grad 6.91 | tok/s 20679
step    160 | loss 2.2920 | lr 3.00e-04 | grad 3.00 | tok/s 19982
step    170 | loss 2.2766 | lr 3.00e-04 | grad 2.55 | tok/s 19659
step    180 | loss 1.7858 | lr 3.00e-04 | grad 3.84 | tok/s 20100
step    190 | loss 1.8483 | lr 3.00e-04 | grad 3.38 | tok/s 19757
step    200 | loss 1.5909 | lr 3.00e-04 | grad 2.25 | tok/s 20627
step    210 | loss 1.8450 | lr 3.00e-04 | grad 6.31 | tok/s 19602
step    220 | loss 2.1725 | lr 3.00e-04 | grad 3.75 | tok/s 19819
step    230 | loss 1.9610 | lr 3.00e-04 | grad 3.36 | tok/s 19803
step    240 | loss 2.2393 | lr 3.00e-04 | grad 7.41 | tok/s 20048
step    250 | loss 1.7293 | lr 3.00e-04 | grad 2.14 | tok/s 19885
step    260 | loss 1.8593 | lr 3.00e-04 | grad 3.89 | tok/s 20451
step    270 | loss 1.7925 | lr 3.00e-04 | grad 2.75 | tok/s 19994
step    280 | loss 1.7532 | lr 3.00e-04 | grad 2.27 | tok/s 18804
step    290 | loss 1.6489 | lr 3.00e-04 | grad 2.78 | tok/s 19435
step    300 | loss 1.9735 | lr 3.00e-04 | grad 2.98 | tok/s 19606
step    310 | loss 1.6485 | lr 3.00e-04 | grad 2.22 | tok/s 19494
step    320 | loss 1.8718 | lr 3.00e-04 | grad 4.94 | tok/s 19681
step    330 | loss 1.7084 | lr 3.00e-04 | grad 2.31 | tok/s 19911
step    340 | loss 2.0326 | lr 3.00e-04 | grad 3.31 | tok/s 19806
step    350 | loss 1.7025 | lr 3.00e-04 | grad 2.47 | tok/s 20363
step    360 | loss 1.5695 | lr 3.00e-04 | grad 2.31 | tok/s 19523
step    370 | loss 1.4692 | lr 3.00e-04 | grad 2.36 | tok/s 20520
step    380 | loss 1.2013 | lr 3.00e-04 | grad 2.08 | tok/s 20721
step    390 | loss 1.1133 | lr 3.00e-04 | grad 1.84 | tok/s 20752
step    400 | loss 1.7436 | lr 3.00e-04 | grad 2.14 | tok/s 19669
step    410 | loss 1.7693 | lr 3.00e-04 | grad 2.83 | tok/s 19856
step    420 | loss 1.5838 | lr 3.00e-04 | grad 4.38 | tok/s 20679
step    430 | loss 1.5885 | lr 3.00e-04 | grad 2.31 | tok/s 20350
step    440 | loss 1.7034 | lr 3.00e-04 | grad 3.00 | tok/s 19698
step    450 | loss 1.6312 | lr 3.00e-04 | grad 2.14 | tok/s 19953
step    460 | loss 1.6016 | lr 3.00e-04 | grad 2.38 | tok/s 20214
step    470 | loss 1.5615 | lr 3.00e-04 | grad 4.41 | tok/s 20096
step    480 | loss 1.5776 | lr 3.00e-04 | grad 3.52 | tok/s 20534
step    490 | loss 1.7025 | lr 3.00e-04 | grad 2.91 | tok/s 19711
step    500 | loss 1.8166 | lr 3.00e-04 | grad 2.05 | tok/s 20001
step    510 | loss 1.6791 | lr 3.00e-04 | grad 2.09 | tok/s 19146
step    520 | loss 1.5374 | lr 3.00e-04 | grad 2.62 | tok/s 20063
step    530 | loss 1.7151 | lr 3.00e-04 | grad 2.31 | tok/s 19693
step    540 | loss 1.5875 | lr 3.00e-04 | grad 1.94 | tok/s 19306
step    550 | loss 1.3733 | lr 3.00e-04 | grad 3.91 | tok/s 20223
step    560 | loss 1.4459 | lr 3.00e-04 | grad 2.36 | tok/s 20760
step    570 | loss 1.3461 | lr 3.00e-04 | grad 2.28 | tok/s 20740
step    580 | loss 1.3035 | lr 3.00e-04 | grad 1.76 | tok/s 20729
step    590 | loss 1.3345 | lr 3.00e-04 | grad 1.78 | tok/s 20712
step    600 | loss 1.2724 | lr 3.00e-04 | grad 2.06 | tok/s 20722
step    610 | loss 1.3088 | lr 3.00e-04 | grad 2.06 | tok/s 20737
step    620 | loss 1.2987 | lr 3.00e-04 | grad 2.12 | tok/s 20670
step    630 | loss 1.7018 | lr 3.00e-04 | grad 5.91 | tok/s 19576
step    640 | loss 1.7539 | lr 3.00e-04 | grad 2.58 | tok/s 19773
step    650 | loss 1.5590 | lr 3.00e-04 | grad 2.08 | tok/s 19779
step    660 | loss 1.6006 | lr 3.00e-04 | grad 2.22 | tok/s 20498
step    670 | loss 1.6493 | lr 3.00e-04 | grad 5.91 | tok/s 19862
step    680 | loss 1.6541 | lr 3.00e-04 | grad 2.77 | tok/s 19575
step    690 | loss 1.6014 | lr 3.00e-04 | grad 2.20 | tok/s 19386
step    700 | loss 1.4822 | lr 3.00e-04 | grad 1.60 | tok/s 19800
step    710 | loss 1.6543 | lr 3.00e-04 | grad 3.19 | tok/s 19462
step    720 | loss 1.3220 | lr 3.00e-04 | grad 2.19 | tok/s 20202
step    730 | loss 1.4916 | lr 3.00e-04 | grad 1.77 | tok/s 19888
step    740 | loss 1.7873 | lr 3.00e-04 | grad 4.38 | tok/s 20436
step    750 | loss 1.5284 | lr 3.00e-04 | grad 2.11 | tok/s 20675
step    760 | loss 1.5550 | lr 3.00e-04 | grad 4.34 | tok/s 20237
step    770 | loss 1.5960 | lr 3.00e-04 | grad 2.36 | tok/s 19905
step    780 | loss 1.4948 | lr 3.00e-04 | grad 2.38 | tok/s 20099
step    790 | loss 1.6339 | lr 3.00e-04 | grad 5.03 | tok/s 20475
step    800 | loss 1.3347 | lr 3.00e-04 | grad 1.38 | tok/s 20132
step    810 | loss 1.3373 | lr 3.00e-04 | grad 3.09 | tok/s 19487
step    820 | loss 1.4383 | lr 3.00e-04 | grad 2.34 | tok/s 19804
step    830 | loss 1.5122 | lr 3.00e-04 | grad 1.84 | tok/s 19575
step    840 | loss 1.6491 | lr 3.00e-04 | grad 2.22 | tok/s 19469
step    850 | loss 1.5708 | lr 3.00e-04 | grad 1.79 | tok/s 19851
step    860 | loss 1.6126 | lr 3.00e-04 | grad 3.02 | tok/s 20191
step    870 | loss 1.4091 | lr 3.00e-04 | grad 2.09 | tok/s 20366
step    880 | loss 1.6170 | lr 3.00e-04 | grad 2.34 | tok/s 19992
step    890 | loss 1.5100 | lr 3.00e-04 | grad 1.79 | tok/s 19862
step    900 | loss 1.5591 | lr 3.00e-04 | grad 1.87 | tok/s 19135
step    910 | loss 1.5570 | lr 3.00e-04 | grad 7.69 | tok/s 19587
step    920 | loss 1.5090 | lr 3.00e-04 | grad 2.45 | tok/s 19788
step    930 | loss 1.3978 | lr 3.00e-04 | grad 2.62 | tok/s 20064
step    940 | loss 1.3784 | lr 3.00e-04 | grad 2.25 | tok/s 19618
step    950 | loss 1.5094 | lr 3.00e-04 | grad 2.84 | tok/s 19310
step    960 | loss 1.4616 | lr 3.00e-04 | grad 2.09 | tok/s 19796
step    970 | loss 1.4889 | lr 3.00e-04 | grad 2.14 | tok/s 19795
step    980 | loss 1.9287 | lr 3.00e-04 | grad 4.06 | tok/s 20569
step    990 | loss 1.6028 | lr 3.00e-04 | grad 2.06 | tok/s 19749
step   1000 | loss 1.6091 | lr 3.00e-04 | grad 2.47 | tok/s 19837
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6091.pt
step   1010 | loss 1.3808 | lr 3.00e-04 | grad 2.14 | tok/s 10544
step   1020 | loss 1.2062 | lr 3.00e-04 | grad 1.77 | tok/s 20917
step   1030 | loss 1.6207 | lr 3.00e-04 | grad 2.28 | tok/s 19710
step   1040 | loss 2.2070 | lr 3.00e-04 | grad 5.00 | tok/s 20405
step   1050 | loss 1.4996 | lr 3.00e-04 | grad 2.34 | tok/s 20106
step   1060 | loss 1.1298 | lr 3.00e-04 | grad 1.58 | tok/s 20520
step   1070 | loss 1.5067 | lr 3.00e-04 | grad 2.12 | tok/s 20093
step   1080 | loss 1.2774 | lr 3.00e-04 | grad 2.06 | tok/s 20767
step   1090 | loss 1.2528 | lr 3.00e-04 | grad 1.93 | tok/s 20733
step   1100 | loss 1.2065 | lr 3.00e-04 | grad 2.22 | tok/s 20748
step   1110 | loss 1.1959 | lr 3.00e-04 | grad 1.99 | tok/s 20731
step   1120 | loss 1.5182 | lr 3.00e-04 | grad 4.09 | tok/s 20205
step   1130 | loss 1.6767 | lr 3.00e-04 | grad 3.67 | tok/s 20384
step   1140 | loss 1.7280 | lr 3.00e-04 | grad 1.64 | tok/s 20632
step   1150 | loss 1.6737 | lr 3.00e-04 | grad 2.55 | tok/s 19646
step   1160 | loss 1.8035 | lr 3.00e-04 | grad 8.00 | tok/s 19908
step   1170 | loss 1.4650 | lr 3.00e-04 | grad 2.22 | tok/s 19553
step   1180 | loss 1.3689 | lr 3.00e-04 | grad 2.55 | tok/s 20319
step   1190 | loss 1.5661 | lr 3.00e-04 | grad 4.50 | tok/s 20708
step   1200 | loss 1.1500 | lr 3.00e-04 | grad 5.59 | tok/s 20758
step   1210 | loss 1.4902 | lr 3.00e-04 | grad 2.72 | tok/s 19271
step   1220 | loss 1.3765 | lr 3.00e-04 | grad 1.92 | tok/s 20049
step   1230 | loss 1.3387 | lr 3.00e-04 | grad 1.56 | tok/s 20546
step   1240 | loss 1.3298 | lr 3.00e-04 | grad 1.77 | tok/s 20221
step   1250 | loss 1.5350 | lr 3.00e-04 | grad 6.09 | tok/s 20301
step   1260 | loss 1.4258 | lr 3.00e-04 | grad 3.11 | tok/s 20443
step   1270 | loss 1.4037 | lr 3.00e-04 | grad 1.98 | tok/s 20038
step   1280 | loss 1.4558 | lr 3.00e-04 | grad 2.22 | tok/s 19703
step   1290 | loss 1.3492 | lr 3.00e-04 | grad 2.03 | tok/s 19767
step   1300 | loss 1.6675 | lr 3.00e-04 | grad 11.00 | tok/s 19446
step   1310 | loss 1.5266 | lr 3.00e-04 | grad 2.08 | tok/s 20143
step   1320 | loss 1.5441 | lr 3.00e-04 | grad 3.25 | tok/s 20291
step   1330 | loss 1.4166 | lr 3.00e-04 | grad 2.61 | tok/s 20016
step   1340 | loss 1.6358 | lr 3.00e-04 | grad 2.28 | tok/s 19644
step   1350 | loss 1.4884 | lr 3.00e-04 | grad 4.66 | tok/s 19913
step   1360 | loss 1.4187 | lr 3.00e-04 | grad 1.88 | tok/s 19405
step   1370 | loss 1.6865 | lr 3.00e-04 | grad 3.34 | tok/s 20338
step   1380 | loss 1.4374 | lr 3.00e-04 | grad 2.70 | tok/s 19365
step   1390 | loss 1.3598 | lr 3.00e-04 | grad 2.91 | tok/s 20390
step   1400 | loss 1.5160 | lr 3.00e-04 | grad 1.75 | tok/s 19722
step   1410 | loss 1.4672 | lr 3.00e-04 | grad 5.88 | tok/s 19243
step   1420 | loss 1.2593 | lr 3.00e-04 | grad 8.75 | tok/s 20474
step   1430 | loss 1.6102 | lr 3.00e-04 | grad 2.83 | tok/s 19731
step   1440 | loss 1.4534 | lr 3.00e-04 | grad 2.38 | tok/s 19580
step   1450 | loss 1.5038 | lr 3.00e-04 | grad 2.31 | tok/s 20195
step   1460 | loss 1.6151 | lr 3.00e-04 | grad 4.53 | tok/s 19717
step   1470 | loss 1.3579 | lr 3.00e-04 | grad 1.99 | tok/s 19107
step   1480 | loss 1.4063 | lr 3.00e-04 | grad 2.98 | tok/s 20397

Training complete! Final step: 1486
