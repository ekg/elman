Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_167/levelE88_100m_20260127_213422
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 479,893,404 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.6499 | lr 3.00e-04 | grad 17.12 | tok/s 9376
step     20 | loss 3.6422 | lr 3.00e-04 | grad 7.38 | tok/s 18178
step     30 | loss 3.2226 | lr 3.00e-04 | grad 8.81 | tok/s 19160
step     40 | loss 4.5565 | lr 3.00e-04 | grad 21.00 | tok/s 19460
step     50 | loss 4.3014 | lr 3.00e-04 | grad 11.62 | tok/s 19615
step     60 | loss 3.2971 | lr 3.00e-04 | grad 7.41 | tok/s 19561
step     70 | loss 2.9341 | lr 3.00e-04 | grad 5.78 | tok/s 19447
step     80 | loss 2.6044 | lr 3.00e-04 | grad 5.72 | tok/s 19360
step     90 | loss 2.5039 | lr 3.00e-04 | grad 6.22 | tok/s 19301
step    100 | loss 2.2145 | lr 3.00e-04 | grad 4.00 | tok/s 19289
step    110 | loss 2.2406 | lr 3.00e-04 | grad 5.00 | tok/s 19112
step    120 | loss 2.6983 | lr 3.00e-04 | grad 3.16 | tok/s 18195
step    130 | loss 2.0764 | lr 3.00e-04 | grad 6.66 | tok/s 18598
step    140 | loss 2.3637 | lr 3.00e-04 | grad 8.94 | tok/s 18605
step    150 | loss 1.3449 | lr 3.00e-04 | grad 7.19 | tok/s 19057
step    160 | loss 2.3169 | lr 3.00e-04 | grad 3.12 | tok/s 18394
step    170 | loss 2.2970 | lr 3.00e-04 | grad 2.56 | tok/s 18135
step    180 | loss 1.7763 | lr 3.00e-04 | grad 4.00 | tok/s 18571
step    190 | loss 1.8759 | lr 3.00e-04 | grad 3.45 | tok/s 18231
step    200 | loss 1.6141 | lr 3.00e-04 | grad 2.48 | tok/s 19032
step    210 | loss 1.8713 | lr 3.00e-04 | grad 7.03 | tok/s 18098
step    220 | loss 2.1748 | lr 3.00e-04 | grad 3.88 | tok/s 18270
step    230 | loss 2.0222 | lr 3.00e-04 | grad 3.48 | tok/s 18243
step    240 | loss 2.2629 | lr 3.00e-04 | grad 7.59 | tok/s 18494
step    250 | loss 1.7437 | lr 3.00e-04 | grad 2.31 | tok/s 18384
step    260 | loss 1.8838 | lr 3.00e-04 | grad 4.16 | tok/s 18910
step    270 | loss 1.8102 | lr 3.00e-04 | grad 3.06 | tok/s 18472
step    280 | loss 1.7639 | lr 3.00e-04 | grad 2.25 | tok/s 17370
step    290 | loss 1.6610 | lr 3.00e-04 | grad 2.91 | tok/s 17935
step    300 | loss 1.9726 | lr 3.00e-04 | grad 3.05 | tok/s 18063
step    310 | loss 1.6603 | lr 3.00e-04 | grad 2.22 | tok/s 17994
step    320 | loss 1.8803 | lr 3.00e-04 | grad 4.81 | tok/s 18211
step    330 | loss 1.7161 | lr 3.00e-04 | grad 2.59 | tok/s 18411
step    340 | loss 2.0417 | lr 3.00e-04 | grad 3.05 | tok/s 18338
step    350 | loss 1.7039 | lr 3.00e-04 | grad 2.58 | tok/s 18869
step    360 | loss 1.5837 | lr 3.00e-04 | grad 2.39 | tok/s 18019
step    370 | loss 1.4768 | lr 3.00e-04 | grad 2.53 | tok/s 19013
step    380 | loss 1.2067 | lr 3.00e-04 | grad 2.05 | tok/s 19190
step    390 | loss 1.1214 | lr 3.00e-04 | grad 1.84 | tok/s 19162
step    400 | loss 1.7535 | lr 3.00e-04 | grad 2.16 | tok/s 18149
step    410 | loss 1.7724 | lr 3.00e-04 | grad 3.00 | tok/s 18350
step    420 | loss 1.5889 | lr 3.00e-04 | grad 4.59 | tok/s 19072
step    430 | loss 1.6094 | lr 3.00e-04 | grad 2.58 | tok/s 18794
step    440 | loss 1.7219 | lr 3.00e-04 | grad 3.02 | tok/s 18194
step    450 | loss 1.6406 | lr 3.00e-04 | grad 2.19 | tok/s 18425
step    460 | loss 1.5998 | lr 3.00e-04 | grad 2.55 | tok/s 18698
step    470 | loss 1.5695 | lr 3.00e-04 | grad 4.72 | tok/s 18542
step    480 | loss 1.5754 | lr 3.00e-04 | grad 3.70 | tok/s 18954
step    490 | loss 1.7135 | lr 3.00e-04 | grad 3.05 | tok/s 18192
step    500 | loss 1.8248 | lr 3.00e-04 | grad 2.20 | tok/s 18458
step    510 | loss 1.6845 | lr 3.00e-04 | grad 2.17 | tok/s 17663
step    520 | loss 1.5324 | lr 3.00e-04 | grad 2.72 | tok/s 18502
step    530 | loss 1.7201 | lr 3.00e-04 | grad 2.41 | tok/s 18243
step    540 | loss 1.5925 | lr 3.00e-04 | grad 2.06 | tok/s 17804
step    550 | loss 1.3767 | lr 3.00e-04 | grad 4.19 | tok/s 18634
step    560 | loss 1.4531 | lr 3.00e-04 | grad 2.45 | tok/s 19155
step    570 | loss 1.3551 | lr 3.00e-04 | grad 2.41 | tok/s 19144
step    580 | loss 1.3065 | lr 3.00e-04 | grad 1.89 | tok/s 19186
step    590 | loss 1.3374 | lr 3.00e-04 | grad 1.88 | tok/s 19175
step    600 | loss 1.2762 | lr 3.00e-04 | grad 2.16 | tok/s 19187
step    610 | loss 1.3111 | lr 3.00e-04 | grad 2.16 | tok/s 19163
step    620 | loss 1.3038 | lr 3.00e-04 | grad 2.39 | tok/s 19081
step    630 | loss 1.7409 | lr 3.00e-04 | grad 6.56 | tok/s 18022
step    640 | loss 1.7564 | lr 3.00e-04 | grad 2.61 | tok/s 18261
step    650 | loss 1.5644 | lr 3.00e-04 | grad 2.27 | tok/s 18249
step    660 | loss 1.6045 | lr 3.00e-04 | grad 2.33 | tok/s 18936
step    670 | loss 1.6476 | lr 3.00e-04 | grad 5.91 | tok/s 18361
step    680 | loss 1.6664 | lr 3.00e-04 | grad 3.00 | tok/s 18067
step    690 | loss 1.6126 | lr 3.00e-04 | grad 2.30 | tok/s 17935
step    700 | loss 1.4903 | lr 3.00e-04 | grad 1.70 | tok/s 18300
step    710 | loss 1.6904 | lr 3.00e-04 | grad 3.39 | tok/s 18034
step    720 | loss 1.3195 | lr 3.00e-04 | grad 2.38 | tok/s 18719
step    730 | loss 1.5003 | lr 3.00e-04 | grad 1.89 | tok/s 18445
step    740 | loss 1.7903 | lr 3.00e-04 | grad 4.34 | tok/s 18942
step    750 | loss 1.5331 | lr 3.00e-04 | grad 2.20 | tok/s 19160
step    760 | loss 1.5609 | lr 3.00e-04 | grad 4.72 | tok/s 18737
step    770 | loss 1.6101 | lr 3.00e-04 | grad 2.45 | tok/s 18419
step    780 | loss 1.5017 | lr 3.00e-04 | grad 2.33 | tok/s 18542
step    790 | loss 1.6393 | lr 3.00e-04 | grad 5.41 | tok/s 18967
step    800 | loss 1.3333 | lr 3.00e-04 | grad 1.60 | tok/s 18653
step    810 | loss 1.3351 | lr 3.00e-04 | grad 3.25 | tok/s 18016
step    820 | loss 1.4382 | lr 3.00e-04 | grad 2.41 | tok/s 18367
step    830 | loss 1.5145 | lr 3.00e-04 | grad 1.87 | tok/s 18141
step    840 | loss 1.6544 | lr 3.00e-04 | grad 2.34 | tok/s 18066
step    850 | loss 1.5674 | lr 3.00e-04 | grad 1.94 | tok/s 18452
step    860 | loss 1.6094 | lr 3.00e-04 | grad 3.00 | tok/s 18720
step    870 | loss 1.4063 | lr 3.00e-04 | grad 2.23 | tok/s 18897
step    880 | loss 1.6177 | lr 3.00e-04 | grad 2.44 | tok/s 18528
step    890 | loss 1.5146 | lr 3.00e-04 | grad 1.84 | tok/s 17929
step    900 | loss 1.5609 | lr 3.00e-04 | grad 1.88 | tok/s 18384
step    910 | loss 1.5571 | lr 3.00e-04 | grad 7.47 | tok/s 18237
step    920 | loss 1.5201 | lr 3.00e-04 | grad 2.75 | tok/s 18430
step    930 | loss 1.3979 | lr 3.00e-04 | grad 2.48 | tok/s 18682
step    940 | loss 1.3794 | lr 3.00e-04 | grad 2.25 | tok/s 18257
step    950 | loss 1.5160 | lr 3.00e-04 | grad 2.95 | tok/s 17938
step    960 | loss 1.4677 | lr 3.00e-04 | grad 2.23 | tok/s 18452
step    970 | loss 1.4949 | lr 3.00e-04 | grad 2.25 | tok/s 18457
step    980 | loss 1.9416 | lr 3.00e-04 | grad 4.06 | tok/s 19207
step    990 | loss 1.6046 | lr 3.00e-04 | grad 2.08 | tok/s 18404
step   1000 | loss 1.6208 | lr 3.00e-04 | grad 2.47 | tok/s 18439
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6208.pt
step   1010 | loss 1.3882 | lr 3.00e-04 | grad 3.20 | tok/s 8840
step   1020 | loss 1.2287 | lr 3.00e-04 | grad 2.22 | tok/s 19574
step   1030 | loss 1.6671 | lr 3.00e-04 | grad 3.02 | tok/s 18388
step   1040 | loss 2.2008 | lr 3.00e-04 | grad 4.34 | tok/s 19190
step   1050 | loss 1.5230 | lr 3.00e-04 | grad 2.64 | tok/s 18719
step   1060 | loss 1.0846 | lr 3.00e-04 | grad 2.38 | tok/s 19187
step   1070 | loss 1.5249 | lr 3.00e-04 | grad 2.69 | tok/s 18912
step   1080 | loss 1.2697 | lr 3.00e-04 | grad 1.77 | tok/s 19406
step   1090 | loss 1.2573 | lr 3.00e-04 | grad 2.19 | tok/s 19416
step   1100 | loss 1.2040 | lr 3.00e-04 | grad 1.91 | tok/s 19432
step   1110 | loss 1.2564 | lr 3.00e-04 | grad 3.00 | tok/s 19324
step   1120 | loss 1.5206 | lr 3.00e-04 | grad 3.81 | tok/s 18966
step   1130 | loss 1.8005 | lr 3.00e-04 | grad 9.50 | tok/s 19068
step   1140 | loss 1.5419 | lr 3.00e-04 | grad 1.95 | tok/s 19283
step   1150 | loss 1.7476 | lr 3.00e-04 | grad 3.44 | tok/s 18265
step   1160 | loss 1.7756 | lr 3.00e-04 | grad 2.41 | tok/s 18378
step   1170 | loss 1.4549 | lr 3.00e-04 | grad 1.72 | tok/s 18585
step   1180 | loss 1.4299 | lr 3.00e-04 | grad 3.62 | tok/s 18973
step   1190 | loss 1.5141 | lr 3.00e-04 | grad 3.45 | tok/s 19367
step   1200 | loss 1.1377 | lr 3.00e-04 | grad 2.58 | tok/s 19290
step   1210 | loss 1.5096 | lr 3.00e-04 | grad 2.05 | tok/s 18151
step   1220 | loss 1.3792 | lr 3.00e-04 | grad 2.61 | tok/s 18721
step   1230 | loss 1.3450 | lr 3.00e-04 | grad 2.11 | tok/s 19222
step   1240 | loss 1.3378 | lr 3.00e-04 | grad 2.17 | tok/s 18822
step   1250 | loss 1.5052 | lr 3.00e-04 | grad 2.92 | tok/s 19195
step   1260 | loss 1.4542 | lr 3.00e-04 | grad 2.50 | tok/s 19158
step   1270 | loss 1.3771 | lr 3.00e-04 | grad 1.84 | tok/s 18776
step   1280 | loss 1.4814 | lr 3.00e-04 | grad 1.86 | tok/s 18470
step   1290 | loss 1.3794 | lr 3.00e-04 | grad 2.45 | tok/s 18385
step   1300 | loss 1.6289 | lr 3.00e-04 | grad 4.75 | tok/s 18339
step   1310 | loss 1.5496 | lr 3.00e-04 | grad 2.27 | tok/s 18876
step   1320 | loss 1.5677 | lr 3.00e-04 | grad 2.33 | tok/s 19007
step   1330 | loss 1.4275 | lr 3.00e-04 | grad 2.81 | tok/s 18550
step   1340 | loss 1.6110 | lr 3.00e-04 | grad 1.78 | tok/s 18629
step   1350 | loss 1.5480 | lr 3.00e-04 | grad 8.31 | tok/s 18637
step   1360 | loss 1.3571 | lr 3.00e-04 | grad 1.94 | tok/s 18202
step   1370 | loss 1.7352 | lr 3.00e-04 | grad 2.78 | tok/s 18980

Training complete! Final step: 1378
