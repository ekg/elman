Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_5/levelE88_100m_20260127_180705
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,174,952 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1274 | lr 3.00e-04 | grad 20.50 | tok/s 3660
step     20 | loss 2.8971 | lr 3.00e-04 | grad 12.44 | tok/s 7162
step     30 | loss 2.6212 | lr 3.00e-04 | grad 5.97 | tok/s 7171
step     40 | loss 2.4900 | lr 3.00e-04 | grad 22.88 | tok/s 6852
step     50 | loss 3.1454 | lr 3.00e-04 | grad 14.75 | tok/s 7145
step     60 | loss 2.0182 | lr 3.00e-04 | grad 5.84 | tok/s 7233
step     70 | loss 1.8500 | lr 3.00e-04 | grad 3.30 | tok/s 7365
step     80 | loss 7.6786 | lr 3.00e-04 | grad 138.00 | tok/s 7560
step     90 | loss 6.3346 | lr 3.00e-04 | grad 41.75 | tok/s 7580
step    100 | loss 4.7045 | lr 3.00e-04 | grad 47.00 | tok/s 7582
step    110 | loss 4.0984 | lr 3.00e-04 | grad 38.25 | tok/s 7573
step    120 | loss 3.3848 | lr 3.00e-04 | grad 22.38 | tok/s 7579
step    130 | loss 3.1729 | lr 3.00e-04 | grad 6.50 | tok/s 7267
step    140 | loss 2.8690 | lr 3.00e-04 | grad 19.00 | tok/s 7568
step    150 | loss 2.9774 | lr 3.00e-04 | grad 9.19 | tok/s 7470
step    160 | loss 2.4437 | lr 3.00e-04 | grad 9.69 | tok/s 7517
step    170 | loss 2.6085 | lr 3.00e-04 | grad 12.88 | tok/s 7454
step    180 | loss 2.3206 | lr 3.00e-04 | grad 6.22 | tok/s 12700
step    190 | loss 2.4591 | lr 3.00e-04 | grad 7.41 | tok/s 16664
step    200 | loss 2.1993 | lr 3.00e-04 | grad 9.56 | tok/s 9420
step    210 | loss 2.1939 | lr 3.00e-04 | grad 6.56 | tok/s 7464
step    220 | loss 2.1779 | lr 3.00e-04 | grad 3.45 | tok/s 7395
step    230 | loss 2.1843 | lr 3.00e-04 | grad 3.25 | tok/s 7320
step    240 | loss 2.3349 | lr 3.00e-04 | grad 4.41 | tok/s 7050
step    250 | loss 2.0679 | lr 3.00e-04 | grad 2.86 | tok/s 7125
step    260 | loss 1.5827 | lr 3.00e-04 | grad 3.41 | tok/s 7423
step    270 | loss 2.0705 | lr 3.00e-04 | grad 2.55 | tok/s 7190
step    280 | loss 2.4610 | lr 3.00e-04 | grad 14.50 | tok/s 7271
step    290 | loss 1.2279 | lr 3.00e-04 | grad 3.05 | tok/s 7404
step    300 | loss 0.7772 | lr 3.00e-04 | grad 4.78 | tok/s 7160
step    310 | loss 2.3523 | lr 3.00e-04 | grad 3.95 | tok/s 7332
step    320 | loss 1.9515 | lr 3.00e-04 | grad 3.88 | tok/s 6939
step    330 | loss 1.9670 | lr 3.00e-04 | grad 3.06 | tok/s 6799
step    340 | loss 2.2972 | lr 3.00e-04 | grad 3.09 | tok/s 6915
step    350 | loss 1.8166 | lr 3.00e-04 | grad 5.66 | tok/s 6755
step    360 | loss 1.2689 | lr 3.00e-04 | grad 4.88 | tok/s 7297
step    370 | loss 1.8071 | lr 3.00e-04 | grad 3.06 | tok/s 6555
step    380 | loss 1.7699 | lr 3.00e-04 | grad 3.08 | tok/s 7173
step    390 | loss 1.5352 | lr 3.00e-04 | grad 2.52 | tok/s 7293
step    400 | loss 1.5163 | lr 3.00e-04 | grad 3.55 | tok/s 7195
step    410 | loss 1.3096 | lr 3.00e-04 | grad 3.33 | tok/s 16005
step    420 | loss 1.9500 | lr 3.00e-04 | grad 10.56 | tok/s 14534
step    430 | loss 2.0186 | lr 3.00e-04 | grad 2.41 | tok/s 15776
step    440 | loss 2.1995 | lr 3.00e-04 | grad 6.47 | tok/s 15626
step    450 | loss 1.9734 | lr 3.00e-04 | grad 2.36 | tok/s 15779
step    460 | loss 1.6788 | lr 3.00e-04 | grad 3.84 | tok/s 13869
step    470 | loss 1.8945 | lr 3.00e-04 | grad 3.28 | tok/s 16040
step    480 | loss 2.3474 | lr 3.00e-04 | grad 5.16 | tok/s 16273
step    490 | loss 1.7511 | lr 3.00e-04 | grad 2.55 | tok/s 15193
step    500 | loss 1.7290 | lr 3.00e-04 | grad 2.91 | tok/s 16203
step    510 | loss 1.6809 | lr 3.00e-04 | grad 2.59 | tok/s 16424
step    520 | loss 1.6649 | lr 3.00e-04 | grad 2.44 | tok/s 16239
step    530 | loss 1.9294 | lr 3.00e-04 | grad 2.30 | tok/s 16037
step    540 | loss 1.7397 | lr 3.00e-04 | grad 2.69 | tok/s 15834
step    550 | loss 1.5935 | lr 3.00e-04 | grad 2.75 | tok/s 15422
step    560 | loss 1.7611 | lr 3.00e-04 | grad 3.33 | tok/s 11302
step    570 | loss 1.6096 | lr 3.00e-04 | grad 2.22 | tok/s 15499
step    580 | loss 1.5854 | lr 3.00e-04 | grad 2.95 | tok/s 15610
step    590 | loss 1.9473 | lr 3.00e-04 | grad 9.69 | tok/s 15580
step    600 | loss 1.7630 | lr 3.00e-04 | grad 2.75 | tok/s 15575
step    610 | loss 1.6046 | lr 3.00e-04 | grad 4.03 | tok/s 15221
step    620 | loss 1.6076 | lr 3.00e-04 | grad 2.80 | tok/s 15575
step    630 | loss 1.5799 | lr 3.00e-04 | grad 2.53 | tok/s 13798
step    640 | loss 1.9897 | lr 3.00e-04 | grad 5.34 | tok/s 10868
step    650 | loss 1.6436 | lr 3.00e-04 | grad 2.73 | tok/s 15710
step    660 | loss 1.6526 | lr 3.00e-04 | grad 2.17 | tok/s 16246
step    670 | loss 1.9905 | lr 3.00e-04 | grad 3.11 | tok/s 13515
step    680 | loss 1.8190 | lr 3.00e-04 | grad 6.28 | tok/s 14075
step    690 | loss 1.6942 | lr 3.00e-04 | grad 3.48 | tok/s 16329
step    700 | loss 1.4756 | lr 3.00e-04 | grad 13.19 | tok/s 16287
step    710 | loss 1.5601 | lr 3.00e-04 | grad 2.77 | tok/s 15397
step    720 | loss 1.5169 | lr 3.00e-04 | grad 2.61 | tok/s 15697
step    730 | loss 1.2997 | lr 3.00e-04 | grad 2.64 | tok/s 16598
step    740 | loss 1.4022 | lr 3.00e-04 | grad 2.33 | tok/s 16096
step    750 | loss 1.2136 | lr 3.00e-04 | grad 2.58 | tok/s 16169
step    760 | loss 1.1029 | lr 3.00e-04 | grad 2.30 | tok/s 16766
step    770 | loss 1.0578 | lr 3.00e-04 | grad 2.06 | tok/s 16788
step    780 | loss 0.9926 | lr 3.00e-04 | grad 2.16 | tok/s 16272
step    790 | loss 1.2534 | lr 3.00e-04 | grad 3.11 | tok/s 14937
step    800 | loss 1.9096 | lr 3.00e-04 | grad 2.73 | tok/s 15735
step    810 | loss 1.6766 | lr 3.00e-04 | grad 3.09 | tok/s 14193
step    820 | loss 1.6179 | lr 3.00e-04 | grad 5.62 | tok/s 15773
step    830 | loss 1.5023 | lr 3.00e-04 | grad 2.62 | tok/s 16307
step    840 | loss 1.4717 | lr 3.00e-04 | grad 2.61 | tok/s 16462
step    850 | loss 1.5597 | lr 3.00e-04 | grad 3.62 | tok/s 15802
step    860 | loss 1.4643 | lr 3.00e-04 | grad 2.91 | tok/s 16326
step    870 | loss 1.5119 | lr 3.00e-04 | grad 3.27 | tok/s 15943
step    880 | loss 1.7147 | lr 3.00e-04 | grad 2.27 | tok/s 15875
step    890 | loss 1.6969 | lr 3.00e-04 | grad 6.75 | tok/s 15765
step    900 | loss 1.5219 | lr 3.00e-04 | grad 2.38 | tok/s 15781
step    910 | loss 1.4342 | lr 3.00e-04 | grad 2.94 | tok/s 15931
step    920 | loss 1.6150 | lr 3.00e-04 | grad 3.22 | tok/s 16429
step    930 | loss 1.5256 | lr 3.00e-04 | grad 3.59 | tok/s 15610
step    940 | loss 1.3444 | lr 3.00e-04 | grad 2.03 | tok/s 16375
step    950 | loss 1.5527 | lr 3.00e-04 | grad 1.98 | tok/s 16337
step    960 | loss 1.4329 | lr 3.00e-04 | grad 3.19 | tok/s 16364
step    970 | loss 1.8356 | lr 3.00e-04 | grad 3.41 | tok/s 15790
step    980 | loss 1.5828 | lr 3.00e-04 | grad 2.88 | tok/s 15719
step    990 | loss 1.5675 | lr 3.00e-04 | grad 4.34 | tok/s 15925
step   1000 | loss 1.7682 | lr 3.00e-04 | grad 2.92 | tok/s 13537
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7682.pt
step   1010 | loss 1.6446 | lr 3.00e-04 | grad 3.20 | tok/s 4728
step   1020 | loss 1.5807 | lr 3.00e-04 | grad 2.61 | tok/s 14874
step   1030 | loss 1.4170 | lr 3.00e-04 | grad 2.73 | tok/s 16343
step   1040 | loss 1.4860 | lr 3.00e-04 | grad 2.58 | tok/s 15485
step   1050 | loss 1.6594 | lr 3.00e-04 | grad 2.39 | tok/s 15965
step   1060 | loss 1.7254 | lr 3.00e-04 | grad 2.89 | tok/s 14857
step   1070 | loss 1.6108 | lr 3.00e-04 | grad 2.67 | tok/s 15692
step   1080 | loss 1.4059 | lr 3.00e-04 | grad 2.20 | tok/s 15268
step   1090 | loss 1.0988 | lr 3.00e-04 | grad 3.72 | tok/s 16436
step   1100 | loss 1.5470 | lr 3.00e-04 | grad 2.06 | tok/s 13557
step   1110 | loss 1.3711 | lr 3.00e-04 | grad 1.70 | tok/s 13108
step   1120 | loss 1.3389 | lr 3.00e-04 | grad 2.36 | tok/s 16099
step   1130 | loss 1.2688 | lr 3.00e-04 | grad 2.19 | tok/s 16590
step   1140 | loss 1.3083 | lr 3.00e-04 | grad 2.16 | tok/s 16682
step   1150 | loss 1.2707 | lr 3.00e-04 | grad 2.17 | tok/s 16695
step   1160 | loss 1.2185 | lr 3.00e-04 | grad 2.09 | tok/s 16475
step   1170 | loss 1.3010 | lr 3.00e-04 | grad 1.80 | tok/s 16548
step   1180 | loss 1.2804 | lr 3.00e-04 | grad 1.85 | tok/s 12575
step   1190 | loss 1.2023 | lr 3.00e-04 | grad 2.42 | tok/s 16582
step   1200 | loss 1.2535 | lr 3.00e-04 | grad 2.05 | tok/s 16550
step   1210 | loss 1.2914 | lr 3.00e-04 | grad 2.11 | tok/s 14236
step   1220 | loss 1.2442 | lr 3.00e-04 | grad 1.63 | tok/s 15699
step   1230 | loss 1.2678 | lr 3.00e-04 | grad 1.98 | tok/s 16790
step   1240 | loss 1.6076 | lr 3.00e-04 | grad 4.22 | tok/s 16023
step   1250 | loss 1.6349 | lr 3.00e-04 | grad 4.53 | tok/s 15557
step   1260 | loss 1.4218 | lr 3.00e-04 | grad 2.36 | tok/s 16066
step   1270 | loss 1.7431 | lr 3.00e-04 | grad 3.67 | tok/s 14966
step   1280 | loss 1.4979 | lr 3.00e-04 | grad 2.47 | tok/s 15872
step   1290 | loss 1.5109 | lr 3.00e-04 | grad 2.47 | tok/s 16316
step   1300 | loss 1.4938 | lr 3.00e-04 | grad 2.59 | tok/s 15688
step   1310 | loss 1.5151 | lr 3.00e-04 | grad 4.16 | tok/s 15915
step   1320 | loss 1.7042 | lr 3.00e-04 | grad 2.17 | tok/s 13100
step   1330 | loss 1.3462 | lr 3.00e-04 | grad 2.86 | tok/s 16049
step   1340 | loss 1.7768 | lr 3.00e-04 | grad 3.69 | tok/s 15248
step   1350 | loss 1.6662 | lr 3.00e-04 | grad 2.73 | tok/s 15354
step   1360 | loss 1.3969 | lr 3.00e-04 | grad 2.16 | tok/s 15597
step   1370 | loss 1.6266 | lr 3.00e-04 | grad 2.64 | tok/s 15787
step   1380 | loss 1.5344 | lr 3.00e-04 | grad 2.58 | tok/s 15239
step   1390 | loss 1.4451 | lr 3.00e-04 | grad 3.73 | tok/s 15283
step   1400 | loss 1.4451 | lr 3.00e-04 | grad 4.53 | tok/s 15928
step   1410 | loss 1.5517 | lr 3.00e-04 | grad 2.22 | tok/s 15354
step   1420 | loss 1.5742 | lr 3.00e-04 | grad 2.09 | tok/s 16398
step   1430 | loss 1.2857 | lr 3.00e-04 | grad 2.34 | tok/s 16023
step   1440 | loss 1.1247 | lr 3.00e-04 | grad 2.22 | tok/s 15536
step   1450 | loss 1.4893 | lr 3.00e-04 | grad 3.08 | tok/s 14682
step   1460 | loss 1.5788 | lr 3.00e-04 | grad 2.27 | tok/s 15611
step   1470 | loss 1.5671 | lr 3.00e-04 | grad 4.50 | tok/s 16576
step   1480 | loss 1.7993 | lr 3.00e-04 | grad 4.88 | tok/s 16350
step   1490 | loss 1.4860 | lr 3.00e-04 | grad 2.28 | tok/s 16386
step   1500 | loss 1.3591 | lr 3.00e-04 | grad 6.34 | tok/s 16263
step   1510 | loss 1.5474 | lr 3.00e-04 | grad 2.16 | tok/s 16573
step   1520 | loss 1.4862 | lr 3.00e-04 | grad 2.31 | tok/s 16263
step   1530 | loss 1.5455 | lr 3.00e-04 | grad 6.31 | tok/s 15516
step   1540 | loss 1.4880 | lr 3.00e-04 | grad 1.91 | tok/s 13206
step   1550 | loss 1.3260 | lr 3.00e-04 | grad 3.53 | tok/s 13382
step   1560 | loss 1.5265 | lr 3.00e-04 | grad 2.61 | tok/s 15429
step   1570 | loss 1.4191 | lr 3.00e-04 | grad 2.39 | tok/s 16384
step   1580 | loss 1.7809 | lr 3.00e-04 | grad 4.22 | tok/s 16671
step   1590 | loss 1.3129 | lr 3.00e-04 | grad 1.80 | tok/s 15558
step   1600 | loss 0.8253 | lr 3.00e-04 | grad 2.16 | tok/s 16451
step   1610 | loss 1.3238 | lr 3.00e-04 | grad 2.25 | tok/s 14713
step   1620 | loss 1.5147 | lr 3.00e-04 | grad 3.22 | tok/s 15945
step   1630 | loss 1.2113 | lr 3.00e-04 | grad 4.00 | tok/s 16635
step   1640 | loss 1.5058 | lr 3.00e-04 | grad 2.12 | tok/s 14265
step   1650 | loss 1.5773 | lr 3.00e-04 | grad 2.17 | tok/s 15187
step   1660 | loss 1.1550 | lr 3.00e-04 | grad 2.30 | tok/s 16214
step   1670 | loss 1.8083 | lr 3.00e-04 | grad 3.06 | tok/s 15213
step   1680 | loss 1.5225 | lr 3.00e-04 | grad 5.69 | tok/s 13645
step   1690 | loss 1.4881 | lr 3.00e-04 | grad 3.69 | tok/s 16209
step   1700 | loss 1.4244 | lr 3.00e-04 | grad 2.11 | tok/s 15341
step   1710 | loss 1.4585 | lr 3.00e-04 | grad 2.53 | tok/s 15295
step   1720 | loss 1.4432 | lr 3.00e-04 | grad 2.50 | tok/s 16558
step   1730 | loss 1.1927 | lr 3.00e-04 | grad 2.61 | tok/s 16661
step   1740 | loss 1.5030 | lr 3.00e-04 | grad 2.73 | tok/s 15889
step   1750 | loss 1.5500 | lr 3.00e-04 | grad 2.78 | tok/s 13687
step   1760 | loss 1.6051 | lr 3.00e-04 | grad 1.92 | tok/s 15803
step   1770 | loss 1.4994 | lr 3.00e-04 | grad 3.91 | tok/s 15735
step   1780 | loss 1.4456 | lr 3.00e-04 | grad 3.36 | tok/s 16076
step   1790 | loss 1.4565 | lr 3.00e-04 | grad 2.17 | tok/s 15797
step   1800 | loss 1.6405 | lr 3.00e-04 | grad 1.98 | tok/s 15434
step   1810 | loss 1.4033 | lr 3.00e-04 | grad 2.31 | tok/s 15613
step   1820 | loss 1.4726 | lr 3.00e-04 | grad 2.17 | tok/s 16397
step   1830 | loss 1.5904 | lr 3.00e-04 | grad 10.50 | tok/s 16057
step   1840 | loss 1.4093 | lr 3.00e-04 | grad 2.14 | tok/s 15708

Training complete! Final step: 1845
