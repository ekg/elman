Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_169/levelE88_100m_20260127_214441
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 480,045,320 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3974 | lr 3.00e-04 | grad 19.50 | tok/s 6218
step     20 | loss 3.3057 | lr 3.00e-04 | grad 12.56 | tok/s 17746
step     30 | loss 2.7178 | lr 3.00e-04 | grad 6.31 | tok/s 17911
step     40 | loss 2.3828 | lr 3.00e-04 | grad 4.31 | tok/s 17156
step     50 | loss 2.9219 | lr 3.00e-04 | grad 13.00 | tok/s 17368
step     60 | loss 2.0539 | lr 3.00e-04 | grad 3.34 | tok/s 17949
step     70 | loss 1.8040 | lr 3.00e-04 | grad 4.97 | tok/s 18119
step     80 | loss 5.5339 | lr 3.00e-04 | grad 39.75 | tok/s 18229
step     90 | loss 4.6742 | lr 3.00e-04 | grad 6.91 | tok/s 18502
step    100 | loss 3.8388 | lr 3.00e-04 | grad 5.94 | tok/s 18477
step    110 | loss 3.2044 | lr 3.00e-04 | grad 11.38 | tok/s 18445
step    120 | loss 3.1040 | lr 3.00e-04 | grad 8.75 | tok/s 18426
step    130 | loss 2.9438 | lr 3.00e-04 | grad 10.12 | tok/s 18408
step    140 | loss 2.6784 | lr 3.00e-04 | grad 7.91 | tok/s 18394
step    150 | loss 2.7988 | lr 3.00e-04 | grad 21.88 | tok/s 18342
step    160 | loss 2.3385 | lr 3.00e-04 | grad 10.06 | tok/s 18332
step    170 | loss 2.4311 | lr 3.00e-04 | grad 11.50 | tok/s 18326
step    180 | loss 2.2083 | lr 3.00e-04 | grad 6.78 | tok/s 18315
step    190 | loss 2.3153 | lr 3.00e-04 | grad 8.50 | tok/s 18244
step    200 | loss 2.0566 | lr 3.00e-04 | grad 5.19 | tok/s 18253
step    210 | loss 2.1242 | lr 3.00e-04 | grad 6.38 | tok/s 18238
step    220 | loss 2.1065 | lr 3.00e-04 | grad 3.84 | tok/s 18004
step    230 | loss 2.0329 | lr 3.00e-04 | grad 3.56 | tok/s 16202
step    240 | loss 2.2651 | lr 3.00e-04 | grad 5.00 | tok/s 16909
step    250 | loss 2.0641 | lr 3.00e-04 | grad 2.70 | tok/s 17348
step    260 | loss 1.4936 | lr 3.00e-04 | grad 3.19 | tok/s 17913
step    270 | loss 2.0362 | lr 3.00e-04 | grad 3.09 | tok/s 17691
step    280 | loss 2.2353 | lr 3.00e-04 | grad 5.38 | tok/s 17372
step    290 | loss 1.3664 | lr 3.00e-04 | grad 2.62 | tok/s 18293
step    300 | loss 0.6049 | lr 3.00e-04 | grad 6.34 | tok/s 18258
step    310 | loss 2.3616 | lr 3.00e-04 | grad 4.06 | tok/s 17934
step    320 | loss 1.8725 | lr 3.00e-04 | grad 5.75 | tok/s 17572
step    330 | loss 1.9196 | lr 3.00e-04 | grad 3.09 | tok/s 16982
step    340 | loss 2.2533 | lr 3.00e-04 | grad 3.03 | tok/s 17238
step    350 | loss 1.8461 | lr 3.00e-04 | grad 3.67 | tok/s 17658
step    360 | loss 1.1856 | lr 3.00e-04 | grad 7.84 | tok/s 18045
step    370 | loss 1.7730 | lr 3.00e-04 | grad 2.66 | tok/s 16394
step    380 | loss 1.7185 | lr 3.00e-04 | grad 2.94 | tok/s 17447
step    390 | loss 1.5070 | lr 3.00e-04 | grad 2.28 | tok/s 18202
step    400 | loss 1.4610 | lr 3.00e-04 | grad 2.75 | tok/s 18076
step    410 | loss 1.2507 | lr 3.00e-04 | grad 2.23 | tok/s 17647
step    420 | loss 1.7908 | lr 3.00e-04 | grad 4.59 | tok/s 16856
step    430 | loss 2.1588 | lr 3.00e-04 | grad 3.25 | tok/s 17938
step    440 | loss 2.1388 | lr 3.00e-04 | grad 4.22 | tok/s 16936
step    450 | loss 1.9834 | lr 3.00e-04 | grad 2.72 | tok/s 17525
step    460 | loss 1.7112 | lr 3.00e-04 | grad 3.14 | tok/s 17160
step    470 | loss 1.8122 | lr 3.00e-04 | grad 2.72 | tok/s 17676
step    480 | loss 2.2163 | lr 3.00e-04 | grad 7.09 | tok/s 17694
step    490 | loss 1.7802 | lr 3.00e-04 | grad 2.66 | tok/s 16710
step    500 | loss 1.6507 | lr 3.00e-04 | grad 3.64 | tok/s 17824
step    510 | loss 1.6849 | lr 3.00e-04 | grad 2.67 | tok/s 18076
step    520 | loss 1.6330 | lr 3.00e-04 | grad 2.19 | tok/s 18038
step    530 | loss 1.9029 | lr 3.00e-04 | grad 2.41 | tok/s 17384
step    540 | loss 1.7152 | lr 3.00e-04 | grad 2.36 | tok/s 17356
step    550 | loss 1.5558 | lr 3.00e-04 | grad 3.02 | tok/s 16993
step    560 | loss 1.7099 | lr 3.00e-04 | grad 2.78 | tok/s 16535
step    570 | loss 1.6538 | lr 3.00e-04 | grad 3.62 | tok/s 17008
step    580 | loss 1.5395 | lr 3.00e-04 | grad 2.31 | tok/s 16940
step    590 | loss 1.8466 | lr 3.00e-04 | grad 3.23 | tok/s 17375
step    600 | loss 1.8205 | lr 3.00e-04 | grad 2.30 | tok/s 16774
step    610 | loss 1.6090 | lr 3.00e-04 | grad 2.42 | tok/s 17641
step    620 | loss 1.5329 | lr 3.00e-04 | grad 2.47 | tok/s 16714
step    630 | loss 1.6421 | lr 3.00e-04 | grad 4.47 | tok/s 16853
step    640 | loss 1.7887 | lr 3.00e-04 | grad 2.53 | tok/s 17269
step    650 | loss 1.6753 | lr 3.00e-04 | grad 2.78 | tok/s 17364
step    660 | loss 1.6838 | lr 3.00e-04 | grad 2.33 | tok/s 17444
step    670 | loss 1.9034 | lr 3.00e-04 | grad 3.42 | tok/s 17544
step    680 | loss 1.7159 | lr 3.00e-04 | grad 2.44 | tok/s 17208
step    690 | loss 1.8271 | lr 3.00e-04 | grad 3.42 | tok/s 17829
step    700 | loss 1.3986 | lr 3.00e-04 | grad 2.97 | tok/s 18148
step    710 | loss 1.5801 | lr 3.00e-04 | grad 2.45 | tok/s 16951
step    720 | loss 1.4581 | lr 3.00e-04 | grad 3.30 | tok/s 16697
step    730 | loss 1.2769 | lr 3.00e-04 | grad 3.12 | tok/s 18076
step    740 | loss 1.4917 | lr 3.00e-04 | grad 2.33 | tok/s 17890
step    750 | loss 1.1959 | lr 3.00e-04 | grad 2.61 | tok/s 18175
step    760 | loss 1.1004 | lr 3.00e-04 | grad 2.14 | tok/s 18176
step    770 | loss 1.0457 | lr 3.00e-04 | grad 2.11 | tok/s 18172
step    780 | loss 0.9893 | lr 3.00e-04 | grad 2.08 | tok/s 18156
step    790 | loss 1.1232 | lr 3.00e-04 | grad 3.36 | tok/s 17602
step    800 | loss 1.8119 | lr 3.00e-04 | grad 5.47 | tok/s 17537
step    810 | loss 1.6988 | lr 3.00e-04 | grad 2.27 | tok/s 17417
step    820 | loss 1.7046 | lr 3.00e-04 | grad 4.06 | tok/s 16794
step    830 | loss 1.4749 | lr 3.00e-04 | grad 2.30 | tok/s 17989
step    840 | loss 1.3418 | lr 3.00e-04 | grad 2.20 | tok/s 18160
step    850 | loss 1.6038 | lr 3.00e-04 | grad 2.20 | tok/s 18065
step    860 | loss 1.4582 | lr 3.00e-04 | grad 3.80 | tok/s 17844
step    870 | loss 1.4870 | lr 3.00e-04 | grad 2.81 | tok/s 17205
step    880 | loss 1.6727 | lr 3.00e-04 | grad 2.48 | tok/s 16171
step    890 | loss 1.6743 | lr 3.00e-04 | grad 3.06 | tok/s 17536
step    900 | loss 1.5530 | lr 3.00e-04 | grad 2.59 | tok/s 17585
step    910 | loss 1.4269 | lr 3.00e-04 | grad 3.91 | tok/s 17193
step    920 | loss 1.5261 | lr 3.00e-04 | grad 3.55 | tok/s 17885
step    930 | loss 1.5936 | lr 3.00e-04 | grad 3.36 | tok/s 17057
step    940 | loss 1.3764 | lr 3.00e-04 | grad 1.95 | tok/s 17958
step    950 | loss 1.4680 | lr 3.00e-04 | grad 2.86 | tok/s 18044
step    960 | loss 1.3390 | lr 3.00e-04 | grad 2.61 | tok/s 18021
step    970 | loss 1.7434 | lr 3.00e-04 | grad 3.50 | tok/s 16962
step    980 | loss 1.6387 | lr 3.00e-04 | grad 2.55 | tok/s 17448
step    990 | loss 1.4419 | lr 3.00e-04 | grad 2.11 | tok/s 17724
step   1000 | loss 1.8450 | lr 3.00e-04 | grad 8.88 | tok/s 16988
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8450.pt
step   1010 | loss 1.7131 | lr 3.00e-04 | grad 3.75 | tok/s 5197
step   1020 | loss 1.6496 | lr 3.00e-04 | grad 2.39 | tok/s 16764
step   1030 | loss 1.3973 | lr 3.00e-04 | grad 2.33 | tok/s 17728
step   1040 | loss 1.5048 | lr 3.00e-04 | grad 2.33 | tok/s 17600
step   1050 | loss 1.6268 | lr 3.00e-04 | grad 2.70 | tok/s 17107
step   1060 | loss 1.6751 | lr 3.00e-04 | grad 2.30 | tok/s 17856
step   1070 | loss 1.6488 | lr 3.00e-04 | grad 2.52 | tok/s 17472
step   1080 | loss 1.3965 | lr 3.00e-04 | grad 2.62 | tok/s 16427
step   1090 | loss 1.0314 | lr 3.00e-04 | grad 5.38 | tok/s 18210
step   1100 | loss 1.5473 | lr 3.00e-04 | grad 2.80 | tok/s 17471
step   1110 | loss 1.3965 | lr 3.00e-04 | grad 2.08 | tok/s 18260
step   1120 | loss 1.3307 | lr 3.00e-04 | grad 2.64 | tok/s 18242
step   1130 | loss 1.2709 | lr 3.00e-04 | grad 2.41 | tok/s 18241
step   1140 | loss 1.2804 | lr 3.00e-04 | grad 2.17 | tok/s 18231
step   1150 | loss 1.2724 | lr 3.00e-04 | grad 2.06 | tok/s 18249
step   1160 | loss 1.2048 | lr 3.00e-04 | grad 2.08 | tok/s 18220
step   1170 | loss 1.2764 | lr 3.00e-04 | grad 2.25 | tok/s 17146
step   1180 | loss 1.2874 | lr 3.00e-04 | grad 2.67 | tok/s 18230
step   1190 | loss 1.2052 | lr 3.00e-04 | grad 2.00 | tok/s 18209
step   1200 | loss 1.2215 | lr 3.00e-04 | grad 1.80 | tok/s 18215
step   1210 | loss 1.2543 | lr 3.00e-04 | grad 2.05 | tok/s 18186
step   1220 | loss 1.2711 | lr 3.00e-04 | grad 2.17 | tok/s 18186
step   1230 | loss 1.2510 | lr 3.00e-04 | grad 1.83 | tok/s 18184
step   1240 | loss 1.3411 | lr 3.00e-04 | grad 5.22 | tok/s 17800
step   1250 | loss 1.7284 | lr 3.00e-04 | grad 2.28 | tok/s 17294
step   1260 | loss 1.3268 | lr 3.00e-04 | grad 2.39 | tok/s 17065
step   1270 | loss 1.7349 | lr 3.00e-04 | grad 2.44 | tok/s 16821
step   1280 | loss 1.5804 | lr 3.00e-04 | grad 2.20 | tok/s 17811
step   1290 | loss 1.5177 | lr 3.00e-04 | grad 2.62 | tok/s 17507
step   1300 | loss 1.5022 | lr 3.00e-04 | grad 3.52 | tok/s 17228
step   1310 | loss 1.4409 | lr 3.00e-04 | grad 3.86 | tok/s 18058
step   1320 | loss 1.6232 | lr 3.00e-04 | grad 3.98 | tok/s 17852
step   1330 | loss 1.4057 | lr 3.00e-04 | grad 2.45 | tok/s 17903
step   1340 | loss 1.6323 | lr 3.00e-04 | grad 2.14 | tok/s 16542
step   1350 | loss 1.7640 | lr 3.00e-04 | grad 3.22 | tok/s 16882
step   1360 | loss 1.4357 | lr 3.00e-04 | grad 2.05 | tok/s 17627
step   1370 | loss 1.5697 | lr 3.00e-04 | grad 4.44 | tok/s 17277
step   1380 | loss 1.5671 | lr 3.00e-04 | grad 2.92 | tok/s 16607
step   1390 | loss 1.4380 | lr 3.00e-04 | grad 2.12 | tok/s 17239
step   1400 | loss 1.3745 | lr 3.00e-04 | grad 2.06 | tok/s 17394
step   1410 | loss 1.5590 | lr 3.00e-04 | grad 4.09 | tok/s 17049
step   1420 | loss 1.6142 | lr 3.00e-04 | grad 2.58 | tok/s 17029
step   1430 | loss 1.3208 | lr 3.00e-04 | grad 2.39 | tok/s 17251
step   1440 | loss 1.1298 | lr 3.00e-04 | grad 2.14 | tok/s 18121
step   1450 | loss 1.2843 | lr 3.00e-04 | grad 6.81 | tok/s 17892
step   1460 | loss 1.6814 | lr 3.00e-04 | grad 5.94 | tok/s 16938
step   1470 | loss 1.4196 | lr 3.00e-04 | grad 1.97 | tok/s 17960
step   1480 | loss 1.8321 | lr 3.00e-04 | grad 3.77 | tok/s 17810
step   1490 | loss 1.5551 | lr 3.00e-04 | grad 5.56 | tok/s 18011
step   1500 | loss 1.2691 | lr 3.00e-04 | grad 2.14 | tok/s 18093
step   1510 | loss 1.5576 | lr 3.00e-04 | grad 2.23 | tok/s 17867
step   1520 | loss 1.4538 | lr 3.00e-04 | grad 2.81 | tok/s 17533
step   1530 | loss 1.4182 | lr 3.00e-04 | grad 2.25 | tok/s 17562
step   1540 | loss 1.6405 | lr 3.00e-04 | grad 2.31 | tok/s 17253
step   1550 | loss 1.2390 | lr 3.00e-04 | grad 2.41 | tok/s 17980
step   1560 | loss 1.5936 | lr 3.00e-04 | grad 2.44 | tok/s 17068
step   1570 | loss 1.3235 | lr 3.00e-04 | grad 3.36 | tok/s 17929
step   1580 | loss 1.6518 | lr 3.00e-04 | grad 3.41 | tok/s 17885
step   1590 | loss 1.5394 | lr 3.00e-04 | grad 1.94 | tok/s 17034
step   1600 | loss 0.8478 | lr 3.00e-04 | grad 1.66 | tok/s 18247
step   1610 | loss 1.1923 | lr 3.00e-04 | grad 2.02 | tok/s 16837
step   1620 | loss 1.3575 | lr 3.00e-04 | grad 3.06 | tok/s 17185
step   1630 | loss 1.3703 | lr 3.00e-04 | grad 2.33 | tok/s 17645
step   1640 | loss 1.4484 | lr 3.00e-04 | grad 4.78 | tok/s 17091
step   1650 | loss 1.5608 | lr 3.00e-04 | grad 3.72 | tok/s 16167
step   1660 | loss 1.2316 | lr 3.00e-04 | grad 1.84 | tok/s 18132
step   1670 | loss 1.6202 | lr 3.00e-04 | grad 7.84 | tok/s 17221
step   1680 | loss 1.5501 | lr 3.00e-04 | grad 2.70 | tok/s 16847
step   1690 | loss 1.4363 | lr 3.00e-04 | grad 4.25 | tok/s 17500
step   1700 | loss 1.5288 | lr 3.00e-04 | grad 2.17 | tok/s 16995
step   1710 | loss 1.4535 | lr 3.00e-04 | grad 2.50 | tok/s 17589
step   1720 | loss 1.5001 | lr 3.00e-04 | grad 3.05 | tok/s 18113
step   1730 | loss 1.1813 | lr 3.00e-04 | grad 3.64 | tok/s 18163
step   1740 | loss 1.4016 | lr 3.00e-04 | grad 2.73 | tok/s 17387
step   1750 | loss 1.5199 | lr 3.00e-04 | grad 2.48 | tok/s 17700
step   1760 | loss 1.5928 | lr 3.00e-04 | grad 2.75 | tok/s 17463
step   1770 | loss 1.4306 | lr 3.00e-04 | grad 2.02 | tok/s 17128
step   1780 | loss 1.4916 | lr 3.00e-04 | grad 2.94 | tok/s 17559
step   1790 | loss 1.4211 | lr 3.00e-04 | grad 2.08 | tok/s 17390
step   1800 | loss 1.5613 | lr 3.00e-04 | grad 2.45 | tok/s 17040
step   1810 | loss 1.4728 | lr 3.00e-04 | grad 3.17 | tok/s 17255
step   1820 | loss 1.4804 | lr 3.00e-04 | grad 5.06 | tok/s 16434
step   1830 | loss 1.4515 | lr 3.00e-04 | grad 2.58 | tok/s 17741
step   1840 | loss 1.4341 | lr 3.00e-04 | grad 1.70 | tok/s 16862
step   1850 | loss 1.2766 | lr 3.00e-04 | grad 1.90 | tok/s 18066
step   1860 | loss 1.3628 | lr 3.00e-04 | grad 2.38 | tok/s 16911
step   1870 | loss 1.3404 | lr 3.00e-04 | grad 1.49 | tok/s 17769
step   1880 | loss 1.3066 | lr 3.00e-04 | grad 2.44 | tok/s 16116
step   1890 | loss 1.5433 | lr 3.00e-04 | grad 2.08 | tok/s 17008
step   1900 | loss 1.3669 | lr 3.00e-04 | grad 1.98 | tok/s 17243
step   1910 | loss 1.4910 | lr 3.00e-04 | grad 1.88 | tok/s 16816
step   1920 | loss 1.3563 | lr 3.00e-04 | grad 1.90 | tok/s 17959
step   1930 | loss 1.4817 | lr 3.00e-04 | grad 2.17 | tok/s 16895
step   1940 | loss 1.4698 | lr 3.00e-04 | grad 3.11 | tok/s 17828
step   1950 | loss 1.8015 | lr 3.00e-04 | grad 3.31 | tok/s 18164
step   1960 | loss 1.4451 | lr 3.00e-04 | grad 3.91 | tok/s 18169
step   1970 | loss 1.5328 | lr 3.00e-04 | grad 5.38 | tok/s 17559
step   1980 | loss 1.5018 | lr 3.00e-04 | grad 1.84 | tok/s 17093
step   1990 | loss 1.6231 | lr 3.00e-04 | grad 2.09 | tok/s 17252
step   2000 | loss 1.5080 | lr 3.00e-04 | grad 2.38 | tok/s 17504
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5080.pt
step   2010 | loss 1.2069 | lr 3.00e-04 | grad 2.62 | tok/s 5399
step   2020 | loss 1.3242 | lr 3.00e-04 | grad 2.69 | tok/s 17933
step   2030 | loss 1.0021 | lr 3.00e-04 | grad 2.75 | tok/s 18492
step   2040 | loss 1.2075 | lr 3.00e-04 | grad 1.88 | tok/s 18368
step   2050 | loss 1.3643 | lr 3.00e-04 | grad 3.17 | tok/s 17615
step   2060 | loss 1.6617 | lr 3.00e-04 | grad 2.47 | tok/s 17353
step   2070 | loss 1.9715 | lr 3.00e-04 | grad 5.88 | tok/s 17403
step   2080 | loss 2.0560 | lr 3.00e-04 | grad 3.73 | tok/s 18232
step   2090 | loss 1.5894 | lr 3.00e-04 | grad 4.34 | tok/s 17833
step   2100 | loss 1.2791 | lr 3.00e-04 | grad 2.31 | tok/s 18108
step   2110 | loss 1.4872 | lr 3.00e-04 | grad 2.00 | tok/s 17089
step   2120 | loss 0.7549 | lr 3.00e-04 | grad 1.35 | tok/s 17600
step   2130 | loss 1.4356 | lr 3.00e-04 | grad 2.36 | tok/s 17296
step   2140 | loss 1.4311 | lr 3.00e-04 | grad 2.34 | tok/s 18057
step   2150 | loss 1.2677 | lr 3.00e-04 | grad 1.91 | tok/s 18259
step   2160 | loss 1.2041 | lr 3.00e-04 | grad 1.94 | tok/s 18280
step   2170 | loss 1.1957 | lr 3.00e-04 | grad 1.94 | tok/s 18268
step   2180 | loss 1.2001 | lr 3.00e-04 | grad 2.00 | tok/s 18247
step   2190 | loss 1.2230 | lr 3.00e-04 | grad 1.80 | tok/s 18255
step   2200 | loss 1.1518 | lr 3.00e-04 | grad 1.84 | tok/s 18261
step   2210 | loss 1.1353 | lr 3.00e-04 | grad 1.74 | tok/s 18261
step   2220 | loss 1.1211 | lr 3.00e-04 | grad 1.67 | tok/s 18274
step   2230 | loss 1.4540 | lr 3.00e-04 | grad 2.16 | tok/s 17892
step   2240 | loss 1.3655 | lr 3.00e-04 | grad 3.12 | tok/s 17601
step   2250 | loss 1.5338 | lr 3.00e-04 | grad 3.02 | tok/s 18231
step   2260 | loss 1.6086 | lr 3.00e-04 | grad 1.87 | tok/s 17624
step   2270 | loss 1.9830 | lr 3.00e-04 | grad 2.34 | tok/s 18074
step   2280 | loss 1.3800 | lr 3.00e-04 | grad 2.42 | tok/s 18246
step   2290 | loss 1.5272 | lr 3.00e-04 | grad 2.30 | tok/s 17415
step   2300 | loss 1.4037 | lr 3.00e-04 | grad 3.67 | tok/s 17738
step   2310 | loss 1.4586 | lr 3.00e-04 | grad 4.84 | tok/s 17312
step   2320 | loss 1.9695 | lr 3.00e-04 | grad 4.53 | tok/s 17247
step   2330 | loss 1.4397 | lr 3.00e-04 | grad 2.52 | tok/s 16838
step   2340 | loss 1.4709 | lr 3.00e-04 | grad 2.73 | tok/s 17321
step   2350 | loss 1.3459 | lr 3.00e-04 | grad 2.52 | tok/s 17856
step   2360 | loss 1.2214 | lr 3.00e-04 | grad 2.31 | tok/s 18078
step   2370 | loss 1.6164 | lr 3.00e-04 | grad 3.20 | tok/s 18013
step   2380 | loss 1.3472 | lr 3.00e-04 | grad 4.59 | tok/s 18249
step   2390 | loss 1.0938 | lr 3.00e-04 | grad 1.63 | tok/s 18174
step   2400 | loss 1.0225 | lr 3.00e-04 | grad 3.58 | tok/s 18220
step   2410 | loss 1.2698 | lr 3.00e-04 | grad 3.11 | tok/s 17378
step   2420 | loss 1.5279 | lr 3.00e-04 | grad 3.11 | tok/s 16528
step   2430 | loss 1.2113 | lr 3.00e-04 | grad 2.22 | tok/s 18130
step   2440 | loss 1.4492 | lr 3.00e-04 | grad 2.20 | tok/s 17531
step   2450 | loss 1.4790 | lr 3.00e-04 | grad 2.69 | tok/s 17472
step   2460 | loss 1.0753 | lr 3.00e-04 | grad 2.20 | tok/s 18248
step   2470 | loss 1.2182 | lr 3.00e-04 | grad 2.36 | tok/s 17965
step   2480 | loss 1.2615 | lr 3.00e-04 | grad 2.48 | tok/s 17919
step   2490 | loss 1.4578 | lr 3.00e-04 | grad 2.14 | tok/s 17361
step   2500 | loss 1.3933 | lr 3.00e-04 | grad 2.52 | tok/s 17968
step   2510 | loss 1.0594 | lr 3.00e-04 | grad 3.36 | tok/s 18196
step   2520 | loss 1.5746 | lr 3.00e-04 | grad 2.92 | tok/s 17903
step   2530 | loss 1.3204 | lr 3.00e-04 | grad 2.55 | tok/s 17392
step   2540 | loss 1.3471 | lr 3.00e-04 | grad 1.95 | tok/s 17658
step   2550 | loss 1.1425 | lr 3.00e-04 | grad 2.19 | tok/s 17993
step   2560 | loss 1.5871 | lr 3.00e-04 | grad 2.36 | tok/s 16648

Training complete! Final step: 2562
