Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_1/levelE88_100m_20260127_180706
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,597,386 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0149 | lr 3.00e-04 | grad 10.62 | tok/s 3089
step     20 | loss 2.8088 | lr 3.00e-04 | grad 6.69 | tok/s 5877
step     30 | loss 2.4384 | lr 3.00e-04 | grad 3.94 | tok/s 5821
step     40 | loss 2.3252 | lr 3.00e-04 | grad 2.86 | tok/s 5579
step     50 | loss 3.0554 | lr 3.00e-04 | grad 4.34 | tok/s 5838
step     60 | loss 1.9611 | lr 3.00e-04 | grad 3.73 | tok/s 5959
step     70 | loss 2.1376 | lr 3.00e-04 | grad 28.62 | tok/s 6031
step     80 | loss 5.6100 | lr 3.00e-04 | grad 8.81 | tok/s 6172
step     90 | loss 4.0782 | lr 3.00e-04 | grad 15.56 | tok/s 6194
step    100 | loss 3.5799 | lr 3.00e-04 | grad 14.19 | tok/s 6256
step    110 | loss 3.0173 | lr 3.00e-04 | grad 12.94 | tok/s 6244
step    120 | loss 2.9125 | lr 3.00e-04 | grad 12.88 | tok/s 6119
step    130 | loss 2.6753 | lr 3.00e-04 | grad 4.25 | tok/s 6027
step    140 | loss 2.5916 | lr 3.00e-04 | grad 4.69 | tok/s 5904
step    150 | loss 2.4467 | lr 3.00e-04 | grad 3.83 | tok/s 6011
step    160 | loss 2.1399 | lr 3.00e-04 | grad 4.22 | tok/s 6031
step    170 | loss 2.3251 | lr 3.00e-04 | grad 8.75 | tok/s 5978
step    180 | loss 2.1080 | lr 3.00e-04 | grad 4.81 | tok/s 6142
step    190 | loss 2.1662 | lr 3.00e-04 | grad 3.22 | tok/s 6151
step    200 | loss 1.9299 | lr 3.00e-04 | grad 3.31 | tok/s 6100
step    210 | loss 1.9758 | lr 3.00e-04 | grad 4.28 | tok/s 6058
step    220 | loss 1.9692 | lr 3.00e-04 | grad 3.28 | tok/s 6003
step    230 | loss 2.2472 | lr 3.00e-04 | grad 7.50 | tok/s 5387
step    240 | loss 2.1425 | lr 3.00e-04 | grad 3.14 | tok/s 5196
step    250 | loss 1.9208 | lr 3.00e-04 | grad 2.53 | tok/s 5236
step    260 | loss 1.5221 | lr 3.00e-04 | grad 2.23 | tok/s 6068
step    270 | loss 2.0252 | lr 3.00e-04 | grad 2.59 | tok/s 5116
step    280 | loss 2.4077 | lr 3.00e-04 | grad 5.44 | tok/s 5557
step    290 | loss 1.1441 | lr 3.00e-04 | grad 3.75 | tok/s 5813
step    300 | loss 0.8814 | lr 3.00e-04 | grad 3.69 | tok/s 5519
step    310 | loss 2.3001 | lr 3.00e-04 | grad 3.64 | tok/s 5637
step    320 | loss 1.9066 | lr 3.00e-04 | grad 3.38 | tok/s 12874
step    330 | loss 1.9298 | lr 3.00e-04 | grad 2.17 | tok/s 14356
step    340 | loss 2.2197 | lr 3.00e-04 | grad 2.14 | tok/s 14301
step    350 | loss 1.6859 | lr 3.00e-04 | grad 3.84 | tok/s 14604
step    360 | loss 1.2869 | lr 3.00e-04 | grad 2.78 | tok/s 14651
step    370 | loss 1.7555 | lr 3.00e-04 | grad 2.12 | tok/s 13414
step    380 | loss 1.7168 | lr 3.00e-04 | grad 2.44 | tok/s 14820
step    390 | loss 1.4824 | lr 3.00e-04 | grad 2.31 | tok/s 15052
step    400 | loss 1.4466 | lr 3.00e-04 | grad 2.03 | tok/s 14973
step    410 | loss 1.3147 | lr 3.00e-04 | grad 2.14 | tok/s 14488
step    420 | loss 1.9743 | lr 3.00e-04 | grad 4.56 | tok/s 14047
step    430 | loss 2.0509 | lr 3.00e-04 | grad 4.81 | tok/s 14619
step    440 | loss 1.9797 | lr 3.00e-04 | grad 3.58 | tok/s 14317
step    450 | loss 1.9058 | lr 3.00e-04 | grad 2.20 | tok/s 14308
step    460 | loss 1.6949 | lr 3.00e-04 | grad 4.91 | tok/s 14241
step    470 | loss 1.8437 | lr 3.00e-04 | grad 3.73 | tok/s 14572
step    480 | loss 2.1794 | lr 3.00e-04 | grad 2.06 | tok/s 14497
step    490 | loss 1.7199 | lr 3.00e-04 | grad 1.91 | tok/s 14140
step    500 | loss 1.6573 | lr 3.00e-04 | grad 1.98 | tok/s 11151
step    510 | loss 1.6800 | lr 3.00e-04 | grad 1.78 | tok/s 14985
step    520 | loss 1.7402 | lr 3.00e-04 | grad 4.03 | tok/s 14613
step    530 | loss 1.8275 | lr 3.00e-04 | grad 2.42 | tok/s 14156
step    540 | loss 1.6147 | lr 3.00e-04 | grad 2.17 | tok/s 14391
step    550 | loss 1.5969 | lr 3.00e-04 | grad 2.92 | tok/s 13522
step    560 | loss 1.6587 | lr 3.00e-04 | grad 2.17 | tok/s 13617
step    570 | loss 1.6174 | lr 3.00e-04 | grad 2.56 | tok/s 14065
step    580 | loss 1.5282 | lr 3.00e-04 | grad 2.59 | tok/s 13836
step    590 | loss 1.9519 | lr 3.00e-04 | grad 4.78 | tok/s 14344
step    600 | loss 1.6885 | lr 3.00e-04 | grad 2.30 | tok/s 13933
step    610 | loss 1.5690 | lr 3.00e-04 | grad 2.47 | tok/s 14164
step    620 | loss 1.5850 | lr 3.00e-04 | grad 2.77 | tok/s 13896
step    630 | loss 1.5831 | lr 3.00e-04 | grad 6.56 | tok/s 14233
step    640 | loss 1.9246 | lr 3.00e-04 | grad 3.02 | tok/s 14159
step    650 | loss 1.6265 | lr 3.00e-04 | grad 1.95 | tok/s 14515
step    660 | loss 1.5847 | lr 3.00e-04 | grad 1.89 | tok/s 14318
step    670 | loss 1.9609 | lr 3.00e-04 | grad 2.75 | tok/s 14650
step    680 | loss 1.8139 | lr 3.00e-04 | grad 4.47 | tok/s 14132
step    690 | loss 1.5941 | lr 3.00e-04 | grad 3.03 | tok/s 14881
step    700 | loss 1.4370 | lr 3.00e-04 | grad 2.59 | tok/s 14615
step    710 | loss 1.4895 | lr 3.00e-04 | grad 1.76 | tok/s 13840
step    720 | loss 1.4830 | lr 3.00e-04 | grad 1.84 | tok/s 14280
step    730 | loss 1.3062 | lr 3.00e-04 | grad 1.98 | tok/s 14926
step    740 | loss 1.3887 | lr 3.00e-04 | grad 2.41 | tok/s 14824
step    750 | loss 1.1300 | lr 3.00e-04 | grad 1.73 | tok/s 15033
step    760 | loss 1.0712 | lr 3.00e-04 | grad 1.96 | tok/s 14966
step    770 | loss 1.0256 | lr 3.00e-04 | grad 1.73 | tok/s 14985
step    780 | loss 0.9746 | lr 3.00e-04 | grad 1.80 | tok/s 14958
step    790 | loss 1.2897 | lr 3.00e-04 | grad 2.09 | tok/s 14192
step    800 | loss 1.8407 | lr 3.00e-04 | grad 2.00 | tok/s 14420
step    810 | loss 1.6182 | lr 3.00e-04 | grad 2.22 | tok/s 14185
step    820 | loss 1.5707 | lr 3.00e-04 | grad 1.84 | tok/s 14344
step    830 | loss 1.4767 | lr 3.00e-04 | grad 1.94 | tok/s 15008
step    840 | loss 1.4794 | lr 3.00e-04 | grad 3.69 | tok/s 14974
step    850 | loss 1.5221 | lr 3.00e-04 | grad 2.44 | tok/s 14865
step    860 | loss 1.4187 | lr 3.00e-04 | grad 2.17 | tok/s 14591
step    870 | loss 1.4668 | lr 3.00e-04 | grad 2.02 | tok/s 14265
step    880 | loss 1.7158 | lr 3.00e-04 | grad 3.42 | tok/s 14338
step    890 | loss 1.6855 | lr 3.00e-04 | grad 3.84 | tok/s 14514
step    900 | loss 1.4152 | lr 3.00e-04 | grad 1.99 | tok/s 14416
step    910 | loss 1.4997 | lr 3.00e-04 | grad 3.66 | tok/s 14448
step    920 | loss 1.4998 | lr 3.00e-04 | grad 2.06 | tok/s 14644
step    930 | loss 1.5021 | lr 3.00e-04 | grad 1.96 | tok/s 13965
step    940 | loss 1.3778 | lr 3.00e-04 | grad 3.25 | tok/s 14884
step    950 | loss 1.3944 | lr 3.00e-04 | grad 2.36 | tok/s 14520
step    960 | loss 1.4420 | lr 3.00e-04 | grad 2.64 | tok/s 14786
step    970 | loss 1.8337 | lr 3.00e-04 | grad 2.47 | tok/s 14127
step    980 | loss 1.4921 | lr 3.00e-04 | grad 2.47 | tok/s 13918
step    990 | loss 1.5636 | lr 3.00e-04 | grad 3.52 | tok/s 14431
step   1000 | loss 1.7051 | lr 3.00e-04 | grad 2.05 | tok/s 14443
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7051.pt
step   1010 | loss 1.6151 | lr 3.00e-04 | grad 1.75 | tok/s 2919
step   1020 | loss 1.4303 | lr 3.00e-04 | grad 1.86 | tok/s 14470
step   1030 | loss 1.4569 | lr 3.00e-04 | grad 1.96 | tok/s 15000
step   1040 | loss 1.5973 | lr 3.00e-04 | grad 2.92 | tok/s 13857
step   1050 | loss 1.6970 | lr 3.00e-04 | grad 2.78 | tok/s 15005
step   1060 | loss 1.6063 | lr 3.00e-04 | grad 2.36 | tok/s 14987
step   1070 | loss 1.3799 | lr 3.00e-04 | grad 1.73 | tok/s 13569
step   1080 | loss 1.0985 | lr 3.00e-04 | grad 1.20 | tok/s 14863
step   1090 | loss 1.4212 | lr 3.00e-04 | grad 3.28 | tok/s 14483
step   1100 | loss 1.4468 | lr 3.00e-04 | grad 1.95 | tok/s 15153
step   1110 | loss 1.3152 | lr 3.00e-04 | grad 1.95 | tok/s 15119
step   1120 | loss 1.2715 | lr 3.00e-04 | grad 1.77 | tok/s 15152
step   1130 | loss 1.2605 | lr 3.00e-04 | grad 1.88 | tok/s 15178
step   1140 | loss 1.2795 | lr 3.00e-04 | grad 1.68 | tok/s 15103
step   1150 | loss 1.1930 | lr 3.00e-04 | grad 1.66 | tok/s 15131
step   1160 | loss 1.2208 | lr 3.00e-04 | grad 1.92 | tok/s 15336
step   1170 | loss 1.3164 | lr 3.00e-04 | grad 1.52 | tok/s 15118
step   1180 | loss 1.1979 | lr 3.00e-04 | grad 1.98 | tok/s 15085
step   1190 | loss 1.1905 | lr 3.00e-04 | grad 1.88 | tok/s 14874
step   1200 | loss 1.2478 | lr 3.00e-04 | grad 1.84 | tok/s 15149
step   1210 | loss 1.2674 | lr 3.00e-04 | grad 1.84 | tok/s 15209
step   1220 | loss 1.2339 | lr 3.00e-04 | grad 1.64 | tok/s 15070
step   1230 | loss 1.2008 | lr 3.00e-04 | grad 1.34 | tok/s 15029
step   1240 | loss 1.7651 | lr 3.00e-04 | grad 3.19 | tok/s 14383
step   1250 | loss 1.3865 | lr 3.00e-04 | grad 2.91 | tok/s 14197
step   1260 | loss 1.6284 | lr 3.00e-04 | grad 4.62 | tok/s 13944
step   1270 | loss 1.5991 | lr 3.00e-04 | grad 1.61 | tok/s 14014
step   1280 | loss 1.4527 | lr 3.00e-04 | grad 1.80 | tok/s 14432
step   1290 | loss 1.4957 | lr 3.00e-04 | grad 2.23 | tok/s 14613
step   1300 | loss 1.4388 | lr 3.00e-04 | grad 2.27 | tok/s 14734
step   1310 | loss 1.5598 | lr 3.00e-04 | grad 2.14 | tok/s 14748
step   1320 | loss 1.5779 | lr 3.00e-04 | grad 2.11 | tok/s 14751
step   1330 | loss 1.4509 | lr 3.00e-04 | grad 8.19 | tok/s 14190
step   1340 | loss 1.6951 | lr 3.00e-04 | grad 2.30 | tok/s 13665
step   1350 | loss 1.4692 | lr 3.00e-04 | grad 2.20 | tok/s 14425
step   1360 | loss 1.3963 | lr 3.00e-04 | grad 1.50 | tok/s 14199
step   1370 | loss 1.6290 | lr 3.00e-04 | grad 2.12 | tok/s 13741
step   1380 | loss 1.5078 | lr 3.00e-04 | grad 1.64 | tok/s 14719
step   1390 | loss 1.3762 | lr 3.00e-04 | grad 1.50 | tok/s 14178
step   1400 | loss 1.4246 | lr 3.00e-04 | grad 2.77 | tok/s 14121
step   1410 | loss 1.6322 | lr 3.00e-04 | grad 4.12 | tok/s 14167
step   1420 | loss 1.3291 | lr 3.00e-04 | grad 1.74 | tok/s 14422
step   1430 | loss 1.1230 | lr 3.00e-04 | grad 1.83 | tok/s 14922
step   1440 | loss 1.1451 | lr 3.00e-04 | grad 4.12 | tok/s 15002
step   1450 | loss 1.6401 | lr 3.00e-04 | grad 1.91 | tok/s 14088
step   1460 | loss 1.4879 | lr 3.00e-04 | grad 1.70 | tok/s 11373
step   1470 | loss 1.8015 | lr 3.00e-04 | grad 3.19 | tok/s 14791
step   1480 | loss 1.5272 | lr 3.00e-04 | grad 2.45 | tok/s 14982
step   1490 | loss 1.2849 | lr 3.00e-04 | grad 1.90 | tok/s 15059
step   1500 | loss 1.5122 | lr 3.00e-04 | grad 2.45 | tok/s 14825
step   1510 | loss 1.4080 | lr 3.00e-04 | grad 2.80 | tok/s 14515
step   1520 | loss 1.4204 | lr 3.00e-04 | grad 2.84 | tok/s 14934
step   1530 | loss 1.5865 | lr 3.00e-04 | grad 2.27 | tok/s 13994
step   1540 | loss 1.2468 | lr 3.00e-04 | grad 2.39 | tok/s 14962
step   1550 | loss 1.5640 | lr 3.00e-04 | grad 1.76 | tok/s 14118
step   1560 | loss 1.2517 | lr 3.00e-04 | grad 1.98 | tok/s 14840
step   1570 | loss 1.6725 | lr 3.00e-04 | grad 3.91 | tok/s 14833
step   1580 | loss 1.5557 | lr 3.00e-04 | grad 1.89 | tok/s 14051
step   1590 | loss 0.9020 | lr 3.00e-04 | grad 1.10 | tok/s 15007
step   1600 | loss 1.0856 | lr 3.00e-04 | grad 1.66 | tok/s 14283
step   1610 | loss 1.3773 | lr 3.00e-04 | grad 3.38 | tok/s 14094
step   1620 | loss 1.3460 | lr 3.00e-04 | grad 1.63 | tok/s 14724
step   1630 | loss 1.3378 | lr 3.00e-04 | grad 1.83 | tok/s 14227

Training complete! Final step: 1637
