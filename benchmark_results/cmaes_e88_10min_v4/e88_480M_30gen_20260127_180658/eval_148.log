Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_148/levelE88_100m_20260127_211344
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 477,622,744 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 5.4477 | lr 3.00e-04 | grad 24.75 | tok/s 9844
step     20 | loss 3.8265 | lr 3.00e-04 | grad 8.19 | tok/s 20488
step     30 | loss 3.3244 | lr 3.00e-04 | grad 7.41 | tok/s 21598
step     40 | loss 4.4683 | lr 3.00e-04 | grad 15.56 | tok/s 21980
step     50 | loss 4.1622 | lr 3.00e-04 | grad 22.88 | tok/s 22210
step     60 | loss 3.4370 | lr 3.00e-04 | grad 10.00 | tok/s 22109
step     70 | loss 3.0102 | lr 3.00e-04 | grad 6.16 | tok/s 21962
step     80 | loss 2.6979 | lr 3.00e-04 | grad 5.81 | tok/s 21911
step     90 | loss 2.5793 | lr 3.00e-04 | grad 4.94 | tok/s 21893
step    100 | loss 2.3160 | lr 3.00e-04 | grad 4.81 | tok/s 21876
step    110 | loss 2.2986 | lr 3.00e-04 | grad 4.38 | tok/s 21741
step    120 | loss 2.7919 | lr 3.00e-04 | grad 3.31 | tok/s 20707
step    130 | loss 2.1707 | lr 3.00e-04 | grad 6.31 | tok/s 21178
step    140 | loss 2.4762 | lr 3.00e-04 | grad 10.38 | tok/s 21236
step    150 | loss 1.5761 | lr 3.00e-04 | grad 7.41 | tok/s 21769
step    160 | loss 2.4798 | lr 3.00e-04 | grad 3.42 | tok/s 21009
step    170 | loss 2.3923 | lr 3.00e-04 | grad 2.73 | tok/s 20703
step    180 | loss 1.9314 | lr 3.00e-04 | grad 4.12 | tok/s 21179
step    190 | loss 1.9987 | lr 3.00e-04 | grad 3.44 | tok/s 20817
step    200 | loss 1.7322 | lr 3.00e-04 | grad 2.89 | tok/s 21768
step    210 | loss 1.9822 | lr 3.00e-04 | grad 7.84 | tok/s 20650
step    220 | loss 2.2918 | lr 3.00e-04 | grad 5.00 | tok/s 20856
step    230 | loss 2.1871 | lr 3.00e-04 | grad 3.42 | tok/s 20838
step    240 | loss 2.3531 | lr 3.00e-04 | grad 7.59 | tok/s 21072
step    250 | loss 1.8319 | lr 3.00e-04 | grad 2.33 | tok/s 20960
step    260 | loss 1.9596 | lr 3.00e-04 | grad 4.47 | tok/s 21521
step    270 | loss 1.8827 | lr 3.00e-04 | grad 3.00 | tok/s 21069
step    280 | loss 1.8329 | lr 3.00e-04 | grad 2.59 | tok/s 19762
step    290 | loss 1.7320 | lr 3.00e-04 | grad 2.95 | tok/s 20448
step    300 | loss 2.0363 | lr 3.00e-04 | grad 3.78 | tok/s 20608
step    310 | loss 1.7173 | lr 3.00e-04 | grad 2.45 | tok/s 20503
step    320 | loss 1.9421 | lr 3.00e-04 | grad 4.72 | tok/s 20767
step    330 | loss 1.7865 | lr 3.00e-04 | grad 2.80 | tok/s 20940
step    340 | loss 2.0895 | lr 3.00e-04 | grad 3.05 | tok/s 20900
step    350 | loss 1.7911 | lr 3.00e-04 | grad 2.58 | tok/s 21433
step    360 | loss 1.6322 | lr 3.00e-04 | grad 2.41 | tok/s 20513
step    370 | loss 1.5230 | lr 3.00e-04 | grad 2.56 | tok/s 21622
step    380 | loss 1.2427 | lr 3.00e-04 | grad 2.31 | tok/s 21846
step    390 | loss 1.1645 | lr 3.00e-04 | grad 2.27 | tok/s 21822
step    400 | loss 1.8054 | lr 3.00e-04 | grad 2.44 | tok/s 20703
step    410 | loss 1.8064 | lr 3.00e-04 | grad 3.20 | tok/s 20927
step    420 | loss 1.6390 | lr 3.00e-04 | grad 6.28 | tok/s 21790
step    430 | loss 1.6507 | lr 3.00e-04 | grad 2.39 | tok/s 21422
step    440 | loss 1.7503 | lr 3.00e-04 | grad 3.61 | tok/s 20780
step    450 | loss 1.6759 | lr 3.00e-04 | grad 2.61 | tok/s 20961
step    460 | loss 1.6354 | lr 3.00e-04 | grad 2.64 | tok/s 21315
step    470 | loss 1.6010 | lr 3.00e-04 | grad 4.72 | tok/s 21096
step    480 | loss 1.6006 | lr 3.00e-04 | grad 3.80 | tok/s 21541
step    490 | loss 1.7386 | lr 3.00e-04 | grad 3.25 | tok/s 20682
step    500 | loss 1.8459 | lr 3.00e-04 | grad 2.33 | tok/s 21024
step    510 | loss 1.7088 | lr 3.00e-04 | grad 2.14 | tok/s 20077
step    520 | loss 1.5665 | lr 3.00e-04 | grad 2.59 | tok/s 21042
step    530 | loss 1.7476 | lr 3.00e-04 | grad 2.58 | tok/s 20720
step    540 | loss 1.6227 | lr 3.00e-04 | grad 2.23 | tok/s 20331
step    550 | loss 1.4043 | lr 3.00e-04 | grad 4.72 | tok/s 21273
step    560 | loss 1.4797 | lr 3.00e-04 | grad 2.73 | tok/s 21837
step    570 | loss 1.3848 | lr 3.00e-04 | grad 2.62 | tok/s 21802
step    580 | loss 1.3321 | lr 3.00e-04 | grad 2.02 | tok/s 21816
step    590 | loss 1.3656 | lr 3.00e-04 | grad 2.16 | tok/s 21812
step    600 | loss 1.3029 | lr 3.00e-04 | grad 2.50 | tok/s 21858
step    610 | loss 1.3326 | lr 3.00e-04 | grad 2.52 | tok/s 21814
step    620 | loss 1.3202 | lr 3.00e-04 | grad 2.20 | tok/s 21774
step    630 | loss 1.7514 | lr 3.00e-04 | grad 7.25 | tok/s 20574
step    640 | loss 1.7813 | lr 3.00e-04 | grad 2.95 | tok/s 20834
step    650 | loss 1.5828 | lr 3.00e-04 | grad 2.44 | tok/s 20815
step    660 | loss 1.6264 | lr 3.00e-04 | grad 2.48 | tok/s 21618
step    670 | loss 1.6682 | lr 3.00e-04 | grad 6.06 | tok/s 20924
step    680 | loss 1.6852 | lr 3.00e-04 | grad 3.19 | tok/s 20539
step    690 | loss 1.6322 | lr 3.00e-04 | grad 2.59 | tok/s 20429
step    700 | loss 1.5102 | lr 3.00e-04 | grad 1.88 | tok/s 20858
step    710 | loss 1.6842 | lr 3.00e-04 | grad 3.58 | tok/s 20566
step    720 | loss 1.3436 | lr 3.00e-04 | grad 2.44 | tok/s 21351
step    730 | loss 1.5183 | lr 3.00e-04 | grad 2.05 | tok/s 20968
step    740 | loss 1.8045 | lr 3.00e-04 | grad 4.81 | tok/s 21542
step    750 | loss 1.5375 | lr 3.00e-04 | grad 2.48 | tok/s 21796
step    760 | loss 1.5750 | lr 3.00e-04 | grad 5.12 | tok/s 21355
step    770 | loss 1.6135 | lr 3.00e-04 | grad 2.81 | tok/s 21009
step    780 | loss 1.5222 | lr 3.00e-04 | grad 2.69 | tok/s 21123
step    790 | loss 1.6504 | lr 3.00e-04 | grad 5.88 | tok/s 21607
step    800 | loss 1.3497 | lr 3.00e-04 | grad 1.73 | tok/s 21247
step    810 | loss 1.3499 | lr 3.00e-04 | grad 3.20 | tok/s 20549
step    820 | loss 1.4635 | lr 3.00e-04 | grad 2.70 | tok/s 20915
step    830 | loss 1.5283 | lr 3.00e-04 | grad 2.16 | tok/s 20640
step    840 | loss 1.6693 | lr 3.00e-04 | grad 2.52 | tok/s 20554
step    850 | loss 1.5820 | lr 3.00e-04 | grad 2.03 | tok/s 20980
step    860 | loss 1.6336 | lr 3.00e-04 | grad 3.84 | tok/s 21298
step    870 | loss 1.4403 | lr 3.00e-04 | grad 2.47 | tok/s 21484
step    880 | loss 1.6289 | lr 3.00e-04 | grad 2.70 | tok/s 21061
step    890 | loss 1.5228 | lr 3.00e-04 | grad 2.17 | tok/s 20979
step    900 | loss 1.5741 | lr 3.00e-04 | grad 1.98 | tok/s 20851
step    910 | loss 1.5740 | lr 3.00e-04 | grad 9.69 | tok/s 20676
step    920 | loss 1.5445 | lr 3.00e-04 | grad 3.14 | tok/s 20307
step    930 | loss 1.4193 | lr 3.00e-04 | grad 3.38 | tok/s 21178
step    940 | loss 1.3921 | lr 3.00e-04 | grad 2.30 | tok/s 20682
step    950 | loss 1.5215 | lr 3.00e-04 | grad 3.31 | tok/s 20320
step    960 | loss 1.4784 | lr 3.00e-04 | grad 2.69 | tok/s 20897
step    970 | loss 1.5061 | lr 3.00e-04 | grad 2.47 | tok/s 20877
step    980 | loss 1.9447 | lr 3.00e-04 | grad 4.44 | tok/s 21759
step    990 | loss 1.6188 | lr 3.00e-04 | grad 2.47 | tok/s 20872
step   1000 | loss 1.6284 | lr 3.00e-04 | grad 3.22 | tok/s 20890
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6284.pt
step   1010 | loss 1.3983 | lr 3.00e-04 | grad 4.41 | tok/s 9123
step   1020 | loss 1.2318 | lr 3.00e-04 | grad 2.55 | tok/s 22127
step   1030 | loss 1.6709 | lr 3.00e-04 | grad 3.06 | tok/s 20766
step   1040 | loss 2.2242 | lr 3.00e-04 | grad 5.06 | tok/s 21711
step   1050 | loss 1.5385 | lr 3.00e-04 | grad 2.88 | tok/s 21138
step   1060 | loss 1.0819 | lr 3.00e-04 | grad 2.34 | tok/s 21762
step   1070 | loss 1.5317 | lr 3.00e-04 | grad 3.17 | tok/s 21384
step   1080 | loss 1.2822 | lr 3.00e-04 | grad 1.92 | tok/s 21964
step   1090 | loss 1.2682 | lr 3.00e-04 | grad 2.62 | tok/s 21947
step   1100 | loss 1.2162 | lr 3.00e-04 | grad 2.06 | tok/s 21928
step   1110 | loss 1.2630 | lr 3.00e-04 | grad 3.25 | tok/s 21822
step   1120 | loss 1.5237 | lr 3.00e-04 | grad 4.06 | tok/s 21428
step   1130 | loss 1.8207 | lr 3.00e-04 | grad 10.69 | tok/s 21538
step   1140 | loss 1.5574 | lr 3.00e-04 | grad 2.27 | tok/s 21797
step   1150 | loss 1.7585 | lr 3.00e-04 | grad 3.56 | tok/s 20621
step   1160 | loss 1.7764 | lr 3.00e-04 | grad 2.66 | tok/s 20744
step   1170 | loss 1.4769 | lr 3.00e-04 | grad 1.80 | tok/s 21021
step   1180 | loss 1.4395 | lr 3.00e-04 | grad 3.94 | tok/s 21454
step   1190 | loss 1.5278 | lr 3.00e-04 | grad 3.83 | tok/s 21890
step   1200 | loss 1.1549 | lr 3.00e-04 | grad 2.84 | tok/s 21807
step   1210 | loss 1.5147 | lr 3.00e-04 | grad 2.19 | tok/s 20550
step   1220 | loss 1.3832 | lr 3.00e-04 | grad 2.98 | tok/s 21146
step   1230 | loss 1.3538 | lr 3.00e-04 | grad 2.38 | tok/s 21666
step   1240 | loss 1.3418 | lr 3.00e-04 | grad 2.50 | tok/s 21195
step   1250 | loss 1.5306 | lr 3.00e-04 | grad 3.81 | tok/s 21625
step   1260 | loss 1.4760 | lr 3.00e-04 | grad 2.92 | tok/s 21623
step   1270 | loss 1.3811 | lr 3.00e-04 | grad 2.06 | tok/s 21202
step   1280 | loss 1.4864 | lr 3.00e-04 | grad 2.09 | tok/s 20841
step   1290 | loss 1.3864 | lr 3.00e-04 | grad 2.72 | tok/s 20744
step   1300 | loss 1.6263 | lr 3.00e-04 | grad 4.50 | tok/s 20689
step   1310 | loss 1.5601 | lr 3.00e-04 | grad 2.64 | tok/s 21305
step   1320 | loss 1.5745 | lr 3.00e-04 | grad 2.67 | tok/s 21453
step   1330 | loss 1.4315 | lr 3.00e-04 | grad 2.89 | tok/s 20874
step   1340 | loss 1.6194 | lr 3.00e-04 | grad 1.97 | tok/s 20990
step   1350 | loss 1.5454 | lr 3.00e-04 | grad 8.31 | tok/s 21007
step   1360 | loss 1.3706 | lr 3.00e-04 | grad 2.27 | tok/s 20517
step   1370 | loss 1.7453 | lr 3.00e-04 | grad 2.95 | tok/s 21361
step   1380 | loss 1.4712 | lr 3.00e-04 | grad 3.97 | tok/s 20410
step   1390 | loss 1.4428 | lr 3.00e-04 | grad 5.91 | tok/s 21281
step   1400 | loss 1.4349 | lr 3.00e-04 | grad 2.72 | tok/s 20862
step   1410 | loss 1.4481 | lr 3.00e-04 | grad 5.75 | tok/s 20586
step   1420 | loss 1.3687 | lr 3.00e-04 | grad 5.81 | tok/s 21577
step   1430 | loss 1.5732 | lr 3.00e-04 | grad 2.27 | tok/s 20812
step   1440 | loss 1.4728 | lr 3.00e-04 | grad 2.56 | tok/s 21430
step   1450 | loss 1.5386 | lr 3.00e-04 | grad 2.72 | tok/s 21215
step   1460 | loss 1.5943 | lr 3.00e-04 | grad 2.58 | tok/s 20628
step   1470 | loss 1.3974 | lr 3.00e-04 | grad 4.03 | tok/s 19552
step   1480 | loss 1.3774 | lr 3.00e-04 | grad 2.22 | tok/s 21389
step   1490 | loss 2.0157 | lr 3.00e-04 | grad 2.34 | tok/s 21081
step   1500 | loss 1.4519 | lr 3.00e-04 | grad 4.09 | tok/s 21155
step   1510 | loss 1.2836 | lr 3.00e-04 | grad 2.53 | tok/s 21029
step   1520 | loss 1.5131 | lr 3.00e-04 | grad 3.03 | tok/s 21040
step   1530 | loss 1.5043 | lr 3.00e-04 | grad 5.31 | tok/s 21303
step   1540 | loss 1.4888 | lr 3.00e-04 | grad 2.12 | tok/s 21396
step   1550 | loss 1.5211 | lr 3.00e-04 | grad 3.67 | tok/s 21067
step   1560 | loss 1.1284 | lr 3.00e-04 | grad 3.39 | tok/s 21822

Training complete! Final step: 1562
