Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_105/levelE88_100m_20260127_202209
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 485,021,018 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.8103 | lr 3.00e-04 | grad 16.38 | tok/s 6051
step     20 | loss 3.5961 | lr 3.00e-04 | grad 9.94 | tok/s 17745
step     30 | loss 2.7652 | lr 3.00e-04 | grad 6.00 | tok/s 17997
step     40 | loss 2.4706 | lr 3.00e-04 | grad 5.06 | tok/s 17179
step     50 | loss 3.1423 | lr 3.00e-04 | grad 13.00 | tok/s 17424
step     60 | loss 2.0964 | lr 3.00e-04 | grad 3.56 | tok/s 17932
step     70 | loss 1.8779 | lr 3.00e-04 | grad 5.31 | tok/s 18231
step     80 | loss 5.5999 | lr 3.00e-04 | grad 47.75 | tok/s 18212
step     90 | loss 4.7676 | lr 3.00e-04 | grad 6.41 | tok/s 18494
step    100 | loss 4.0368 | lr 3.00e-04 | grad 5.38 | tok/s 18465
step    110 | loss 3.3617 | lr 3.00e-04 | grad 21.50 | tok/s 18450
step    120 | loss 3.1189 | lr 3.00e-04 | grad 9.75 | tok/s 18439
step    130 | loss 2.9329 | lr 3.00e-04 | grad 12.44 | tok/s 18382
step    140 | loss 2.7171 | lr 3.00e-04 | grad 10.38 | tok/s 18358
step    150 | loss 2.8405 | lr 3.00e-04 | grad 16.00 | tok/s 18295
step    160 | loss 2.4784 | lr 3.00e-04 | grad 12.31 | tok/s 18289
step    170 | loss 2.4123 | lr 3.00e-04 | grad 11.81 | tok/s 18261
step    180 | loss 2.3269 | lr 3.00e-04 | grad 6.41 | tok/s 18249
step    190 | loss 2.4813 | lr 3.00e-04 | grad 13.94 | tok/s 18247
step    200 | loss 2.1336 | lr 3.00e-04 | grad 5.84 | tok/s 18243
step    210 | loss 2.1361 | lr 3.00e-04 | grad 7.88 | tok/s 18254
step    220 | loss 2.1576 | lr 3.00e-04 | grad 4.06 | tok/s 18034
step    230 | loss 2.1673 | lr 3.00e-04 | grad 3.84 | tok/s 17804
step    240 | loss 2.2729 | lr 3.00e-04 | grad 4.44 | tok/s 16905
step    250 | loss 2.0869 | lr 3.00e-04 | grad 2.94 | tok/s 17391
step    260 | loss 1.5411 | lr 3.00e-04 | grad 3.30 | tok/s 17883
step    270 | loss 2.0859 | lr 3.00e-04 | grad 3.28 | tok/s 17639
step    280 | loss 2.2523 | lr 3.00e-04 | grad 6.19 | tok/s 17350
step    290 | loss 1.4426 | lr 3.00e-04 | grad 11.94 | tok/s 18246
step    300 | loss 0.6066 | lr 3.00e-04 | grad 3.22 | tok/s 18274
step    310 | loss 2.4097 | lr 3.00e-04 | grad 3.89 | tok/s 17936
step    320 | loss 1.9152 | lr 3.00e-04 | grad 5.94 | tok/s 17557
step    330 | loss 1.9432 | lr 3.00e-04 | grad 3.33 | tok/s 16937
step    340 | loss 2.2853 | lr 3.00e-04 | grad 3.30 | tok/s 17218
step    350 | loss 1.8617 | lr 3.00e-04 | grad 3.80 | tok/s 17602
step    360 | loss 1.2255 | lr 3.00e-04 | grad 7.62 | tok/s 18019
step    370 | loss 1.7984 | lr 3.00e-04 | grad 3.00 | tok/s 16367
step    380 | loss 1.7603 | lr 3.00e-04 | grad 3.47 | tok/s 17403
step    390 | loss 1.5302 | lr 3.00e-04 | grad 2.80 | tok/s 18176
step    400 | loss 1.4856 | lr 3.00e-04 | grad 2.81 | tok/s 18000
step    410 | loss 1.2694 | lr 3.00e-04 | grad 2.34 | tok/s 17573
step    420 | loss 1.8070 | lr 3.00e-04 | grad 4.91 | tok/s 16796
step    430 | loss 2.1629 | lr 3.00e-04 | grad 3.58 | tok/s 17896
step    440 | loss 2.1508 | lr 3.00e-04 | grad 4.25 | tok/s 16929
step    450 | loss 2.0245 | lr 3.00e-04 | grad 2.72 | tok/s 17490
step    460 | loss 1.7168 | lr 3.00e-04 | grad 3.41 | tok/s 17115
step    470 | loss 1.8287 | lr 3.00e-04 | grad 3.05 | tok/s 17643
step    480 | loss 2.2481 | lr 3.00e-04 | grad 7.03 | tok/s 17652
step    490 | loss 1.7965 | lr 3.00e-04 | grad 2.77 | tok/s 16681
step    500 | loss 1.6681 | lr 3.00e-04 | grad 3.98 | tok/s 17817
step    510 | loss 1.6891 | lr 3.00e-04 | grad 2.83 | tok/s 18062
step    520 | loss 1.6494 | lr 3.00e-04 | grad 2.31 | tok/s 17992
step    530 | loss 1.9033 | lr 3.00e-04 | grad 2.52 | tok/s 17342
step    540 | loss 1.7310 | lr 3.00e-04 | grad 2.78 | tok/s 17354
step    550 | loss 1.5643 | lr 3.00e-04 | grad 3.30 | tok/s 16974
step    560 | loss 1.7213 | lr 3.00e-04 | grad 2.98 | tok/s 16543
step    570 | loss 1.6678 | lr 3.00e-04 | grad 3.59 | tok/s 16997
step    580 | loss 1.5417 | lr 3.00e-04 | grad 2.72 | tok/s 16904
step    590 | loss 1.8578 | lr 3.00e-04 | grad 3.34 | tok/s 17380
step    600 | loss 1.8207 | lr 3.00e-04 | grad 2.36 | tok/s 16789
step    610 | loss 1.6205 | lr 3.00e-04 | grad 2.59 | tok/s 17611
step    620 | loss 1.5468 | lr 3.00e-04 | grad 2.62 | tok/s 16711
step    630 | loss 1.6481 | lr 3.00e-04 | grad 4.78 | tok/s 16827
step    640 | loss 1.7992 | lr 3.00e-04 | grad 2.69 | tok/s 17275
step    650 | loss 1.6742 | lr 3.00e-04 | grad 3.09 | tok/s 17362
step    660 | loss 1.6889 | lr 3.00e-04 | grad 2.64 | tok/s 17460
step    670 | loss 1.8983 | lr 3.00e-04 | grad 4.69 | tok/s 17579
step    680 | loss 1.7189 | lr 3.00e-04 | grad 2.64 | tok/s 17209
step    690 | loss 1.8354 | lr 3.00e-04 | grad 3.80 | tok/s 17804
step    700 | loss 1.4173 | lr 3.00e-04 | grad 3.05 | tok/s 18154
step    710 | loss 1.5938 | lr 3.00e-04 | grad 2.50 | tok/s 16972
step    720 | loss 1.4680 | lr 3.00e-04 | grad 3.64 | tok/s 16729
step    730 | loss 1.2870 | lr 3.00e-04 | grad 3.14 | tok/s 18097
step    740 | loss 1.5024 | lr 3.00e-04 | grad 2.48 | tok/s 17893
step    750 | loss 1.2110 | lr 3.00e-04 | grad 2.78 | tok/s 18136
step    760 | loss 1.1153 | lr 3.00e-04 | grad 2.45 | tok/s 18138
step    770 | loss 1.0623 | lr 3.00e-04 | grad 2.36 | tok/s 18144
step    780 | loss 1.0069 | lr 3.00e-04 | grad 2.17 | tok/s 18165
step    790 | loss 1.1349 | lr 3.00e-04 | grad 3.66 | tok/s 17617
step    800 | loss 1.8151 | lr 3.00e-04 | grad 5.47 | tok/s 17517
step    810 | loss 1.7094 | lr 3.00e-04 | grad 2.33 | tok/s 17413
step    820 | loss 1.7163 | lr 3.00e-04 | grad 4.31 | tok/s 16698
step    830 | loss 1.4964 | lr 3.00e-04 | grad 2.34 | tok/s 17959
step    840 | loss 1.3507 | lr 3.00e-04 | grad 2.28 | tok/s 18106
step    850 | loss 1.5891 | lr 3.00e-04 | grad 2.42 | tok/s 18043
step    860 | loss 1.4624 | lr 3.00e-04 | grad 4.16 | tok/s 17837
step    870 | loss 1.4959 | lr 3.00e-04 | grad 2.92 | tok/s 17249
step    880 | loss 1.6873 | lr 3.00e-04 | grad 2.69 | tok/s 17301
step    890 | loss 1.6812 | lr 3.00e-04 | grad 3.17 | tok/s 17558
step    900 | loss 1.5651 | lr 3.00e-04 | grad 2.70 | tok/s 16082
step    910 | loss 1.4402 | lr 3.00e-04 | grad 4.03 | tok/s 17222
step    920 | loss 1.5319 | lr 3.00e-04 | grad 3.86 | tok/s 17876
step    930 | loss 1.6057 | lr 3.00e-04 | grad 3.53 | tok/s 17090
step    940 | loss 1.3845 | lr 3.00e-04 | grad 2.19 | tok/s 18058
step    950 | loss 1.4833 | lr 3.00e-04 | grad 3.47 | tok/s 18080
step    960 | loss 1.3407 | lr 3.00e-04 | grad 2.81 | tok/s 18123
step    970 | loss 1.7493 | lr 3.00e-04 | grad 3.62 | tok/s 17054
step    980 | loss 1.6422 | lr 3.00e-04 | grad 2.72 | tok/s 17529
step    990 | loss 1.4454 | lr 3.00e-04 | grad 2.19 | tok/s 17779
step   1000 | loss 1.8322 | lr 3.00e-04 | grad 9.62 | tok/s 17092
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8322.pt
step   1010 | loss 1.7464 | lr 3.00e-04 | grad 2.73 | tok/s 5619
step   1020 | loss 1.6805 | lr 3.00e-04 | grad 3.19 | tok/s 16893
step   1030 | loss 1.4077 | lr 3.00e-04 | grad 1.90 | tok/s 17614
step   1040 | loss 1.5310 | lr 3.00e-04 | grad 4.66 | tok/s 17960
step   1050 | loss 1.6030 | lr 3.00e-04 | grad 2.59 | tok/s 16892
step   1060 | loss 1.7053 | lr 3.00e-04 | grad 2.77 | tok/s 18011
step   1070 | loss 1.6415 | lr 3.00e-04 | grad 3.78 | tok/s 17714
step   1080 | loss 1.4029 | lr 3.00e-04 | grad 2.62 | tok/s 16424
step   1090 | loss 1.0118 | lr 3.00e-04 | grad 5.59 | tok/s 18254
step   1100 | loss 1.5721 | lr 3.00e-04 | grad 3.34 | tok/s 17439
step   1110 | loss 1.4290 | lr 3.00e-04 | grad 2.58 | tok/s 18315
step   1120 | loss 1.3395 | lr 3.00e-04 | grad 2.64 | tok/s 18331
step   1130 | loss 1.2857 | lr 3.00e-04 | grad 2.52 | tok/s 18293
step   1140 | loss 1.2952 | lr 3.00e-04 | grad 2.12 | tok/s 18294
step   1150 | loss 1.2919 | lr 3.00e-04 | grad 2.44 | tok/s 18286
step   1160 | loss 1.2137 | lr 3.00e-04 | grad 2.39 | tok/s 18276
step   1170 | loss 1.2576 | lr 3.00e-04 | grad 2.48 | tok/s 18265
step   1180 | loss 1.3104 | lr 3.00e-04 | grad 2.30 | tok/s 18259
step   1190 | loss 1.2179 | lr 3.00e-04 | grad 2.84 | tok/s 18265
step   1200 | loss 1.2188 | lr 3.00e-04 | grad 2.09 | tok/s 18256
step   1210 | loss 1.2579 | lr 3.00e-04 | grad 1.82 | tok/s 18260
step   1220 | loss 1.2827 | lr 3.00e-04 | grad 2.09 | tok/s 18257
step   1230 | loss 1.2566 | lr 3.00e-04 | grad 1.99 | tok/s 18235
step   1240 | loss 1.2671 | lr 3.00e-04 | grad 3.23 | tok/s 18113
step   1250 | loss 1.8107 | lr 3.00e-04 | grad 2.70 | tok/s 17308
step   1260 | loss 1.3521 | lr 3.00e-04 | grad 3.19 | tok/s 17112
step   1270 | loss 1.7680 | lr 3.00e-04 | grad 3.19 | tok/s 17032
step   1280 | loss 1.5821 | lr 3.00e-04 | grad 2.98 | tok/s 17751
step   1290 | loss 1.4919 | lr 3.00e-04 | grad 2.98 | tok/s 17452
step   1300 | loss 1.5086 | lr 3.00e-04 | grad 2.48 | tok/s 17318
step   1310 | loss 1.4596 | lr 3.00e-04 | grad 2.06 | tok/s 18156
step   1320 | loss 1.5899 | lr 3.00e-04 | grad 2.67 | tok/s 17917
step   1330 | loss 1.5348 | lr 3.00e-04 | grad 2.58 | tok/s 17927
step   1340 | loss 1.5721 | lr 3.00e-04 | grad 3.50 | tok/s 16941
step   1350 | loss 1.7249 | lr 3.00e-04 | grad 2.62 | tok/s 16772
step   1360 | loss 1.4717 | lr 3.00e-04 | grad 1.98 | tok/s 17546
step   1370 | loss 1.5261 | lr 3.00e-04 | grad 8.62 | tok/s 17364
step   1380 | loss 1.6098 | lr 3.00e-04 | grad 3.80 | tok/s 16667
step   1390 | loss 1.4956 | lr 3.00e-04 | grad 5.78 | tok/s 17584
step   1400 | loss 1.3696 | lr 3.00e-04 | grad 1.82 | tok/s 17151
step   1410 | loss 1.5230 | lr 3.00e-04 | grad 8.75 | tok/s 17129
step   1420 | loss 1.6471 | lr 3.00e-04 | grad 2.77 | tok/s 17116
step   1430 | loss 1.3457 | lr 3.00e-04 | grad 2.56 | tok/s 17333
step   1440 | loss 1.1355 | lr 3.00e-04 | grad 2.31 | tok/s 17204
step   1450 | loss 1.1637 | lr 3.00e-04 | grad 2.62 | tok/s 17997
step   1460 | loss 1.7079 | lr 3.00e-04 | grad 2.66 | tok/s 17008
step   1470 | loss 1.5185 | lr 3.00e-04 | grad 2.41 | tok/s 18091
step   1480 | loss 1.8331 | lr 3.00e-04 | grad 4.00 | tok/s 17861
step   1490 | loss 1.5660 | lr 3.00e-04 | grad 3.28 | tok/s 18145
step   1500 | loss 1.3128 | lr 3.00e-04 | grad 2.23 | tok/s 18205
step   1510 | loss 1.5578 | lr 3.00e-04 | grad 3.11 | tok/s 17960
step   1520 | loss 1.4377 | lr 3.00e-04 | grad 4.12 | tok/s 17608
step   1530 | loss 1.4545 | lr 3.00e-04 | grad 4.41 | tok/s 18004
step   1540 | loss 1.6267 | lr 3.00e-04 | grad 3.03 | tok/s 16979
step   1550 | loss 1.2710 | lr 3.00e-04 | grad 3.00 | tok/s 18068
step   1560 | loss 1.5999 | lr 3.00e-04 | grad 2.09 | tok/s 17131
step   1570 | loss 1.2821 | lr 3.00e-04 | grad 2.52 | tok/s 17988
step   1580 | loss 1.6887 | lr 3.00e-04 | grad 4.91 | tok/s 17952
step   1590 | loss 1.5895 | lr 3.00e-04 | grad 2.39 | tok/s 17068
step   1600 | loss 0.9182 | lr 3.00e-04 | grad 1.63 | tok/s 18288
step   1610 | loss 1.1140 | lr 3.00e-04 | grad 2.14 | tok/s 17261
step   1620 | loss 1.4086 | lr 3.00e-04 | grad 3.02 | tok/s 16924
step   1630 | loss 1.3659 | lr 3.00e-04 | grad 2.31 | tok/s 17696
step   1640 | loss 1.3594 | lr 3.00e-04 | grad 2.45 | tok/s 17134
step   1650 | loss 1.5576 | lr 3.00e-04 | grad 2.84 | tok/s 16208
step   1660 | loss 1.3381 | lr 3.00e-04 | grad 2.06 | tok/s 18110
step   1670 | loss 1.4431 | lr 3.00e-04 | grad 4.56 | tok/s 17446
step   1680 | loss 1.6935 | lr 3.00e-04 | grad 2.23 | tok/s 16729
step   1690 | loss 1.4942 | lr 3.00e-04 | grad 4.16 | tok/s 17519
step   1700 | loss 1.5150 | lr 3.00e-04 | grad 2.38 | tok/s 17386
step   1710 | loss 1.4319 | lr 3.00e-04 | grad 2.42 | tok/s 17375
step   1720 | loss 1.5283 | lr 3.00e-04 | grad 2.94 | tok/s 18127
step   1730 | loss 1.1767 | lr 3.00e-04 | grad 2.69 | tok/s 18206
step   1740 | loss 1.3955 | lr 3.00e-04 | grad 2.69 | tok/s 17593
step   1750 | loss 1.5592 | lr 3.00e-04 | grad 3.16 | tok/s 17562
step   1760 | loss 1.5661 | lr 3.00e-04 | grad 2.50 | tok/s 17518
step   1770 | loss 1.4464 | lr 3.00e-04 | grad 2.73 | tok/s 17208
step   1780 | loss 1.4939 | lr 3.00e-04 | grad 2.34 | tok/s 17708
step   1790 | loss 1.4349 | lr 3.00e-04 | grad 3.47 | tok/s 17545
step   1800 | loss 1.5818 | lr 3.00e-04 | grad 2.34 | tok/s 17225
step   1810 | loss 1.4602 | lr 3.00e-04 | grad 3.95 | tok/s 16952
step   1820 | loss 1.4863 | lr 3.00e-04 | grad 5.78 | tok/s 17448
step   1830 | loss 1.4588 | lr 3.00e-04 | grad 4.47 | tok/s 17800
step   1840 | loss 1.4880 | lr 3.00e-04 | grad 2.06 | tok/s 16944
step   1850 | loss 1.2714 | lr 3.00e-04 | grad 2.36 | tok/s 18040
step   1860 | loss 1.3690 | lr 3.00e-04 | grad 2.94 | tok/s 17123
step   1870 | loss 1.3769 | lr 3.00e-04 | grad 2.00 | tok/s 17544
step   1880 | loss 1.2756 | lr 3.00e-04 | grad 2.95 | tok/s 16877
step   1890 | loss 1.5239 | lr 3.00e-04 | grad 2.41 | tok/s 16358
step   1900 | loss 1.3929 | lr 3.00e-04 | grad 2.69 | tok/s 17523
step   1910 | loss 1.4855 | lr 3.00e-04 | grad 2.38 | tok/s 16583
step   1920 | loss 1.3819 | lr 3.00e-04 | grad 2.53 | tok/s 18174
step   1930 | loss 1.4540 | lr 3.00e-04 | grad 3.41 | tok/s 16763
step   1940 | loss 1.4562 | lr 3.00e-04 | grad 2.50 | tok/s 18029
step   1950 | loss 1.8533 | lr 3.00e-04 | grad 3.78 | tok/s 18004
step   1960 | loss 1.4529 | lr 3.00e-04 | grad 4.28 | tok/s 18201
step   1970 | loss 1.4893 | lr 3.00e-04 | grad 2.62 | tok/s 17732
step   1980 | loss 1.5706 | lr 3.00e-04 | grad 2.86 | tok/s 16984
step   1990 | loss 1.6178 | lr 3.00e-04 | grad 3.03 | tok/s 17274
step   2000 | loss 1.5077 | lr 3.00e-04 | grad 2.95 | tok/s 17525
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5077.pt
step   2010 | loss 1.1717 | lr 3.00e-04 | grad 2.42 | tok/s 5776
step   2020 | loss 1.3173 | lr 3.00e-04 | grad 3.31 | tok/s 17967
step   2030 | loss 0.9521 | lr 3.00e-04 | grad 4.81 | tok/s 18517
step   2040 | loss 1.3295 | lr 3.00e-04 | grad 2.69 | tok/s 18406
step   2050 | loss 1.2549 | lr 3.00e-04 | grad 2.50 | tok/s 17733
step   2060 | loss 1.6239 | lr 3.00e-04 | grad 2.38 | tok/s 17256
step   2070 | loss 1.8293 | lr 3.00e-04 | grad 7.84 | tok/s 17403
step   2080 | loss 2.2091 | lr 3.00e-04 | grad 5.81 | tok/s 18332
step   2090 | loss 1.6479 | lr 3.00e-04 | grad 3.42 | tok/s 17959
step   2100 | loss 1.3878 | lr 3.00e-04 | grad 2.73 | tok/s 17988
step   2110 | loss 1.4709 | lr 3.00e-04 | grad 2.22 | tok/s 17068
step   2120 | loss 0.8678 | lr 3.00e-04 | grad 2.50 | tok/s 18458
step   2130 | loss 1.2718 | lr 3.00e-04 | grad 4.44 | tok/s 17635
step   2140 | loss 1.4549 | lr 3.00e-04 | grad 2.25 | tok/s 17768
step   2150 | loss 1.2967 | lr 3.00e-04 | grad 2.75 | tok/s 18281
step   2160 | loss 1.1820 | lr 3.00e-04 | grad 2.81 | tok/s 18254
step   2170 | loss 1.2470 | lr 3.00e-04 | grad 2.17 | tok/s 18257
step   2180 | loss 1.1876 | lr 3.00e-04 | grad 1.97 | tok/s 18228
step   2190 | loss 1.2151 | lr 3.00e-04 | grad 2.42 | tok/s 18261
step   2200 | loss 1.1777 | lr 3.00e-04 | grad 2.09 | tok/s 18237
step   2210 | loss 1.1459 | lr 3.00e-04 | grad 2.48 | tok/s 18233
step   2220 | loss 1.1373 | lr 3.00e-04 | grad 2.33 | tok/s 18242
step   2230 | loss 1.4034 | lr 3.00e-04 | grad 2.86 | tok/s 17914
step   2240 | loss 1.3147 | lr 3.00e-04 | grad 2.23 | tok/s 17593
step   2250 | loss 1.5806 | lr 3.00e-04 | grad 6.81 | tok/s 18266
step   2260 | loss 1.5860 | lr 3.00e-04 | grad 2.59 | tok/s 17651
step   2270 | loss 1.9575 | lr 3.00e-04 | grad 4.38 | tok/s 18074
step   2280 | loss 1.4243 | lr 3.00e-04 | grad 2.89 | tok/s 18219
step   2290 | loss 1.4541 | lr 3.00e-04 | grad 7.41 | tok/s 17600
step   2300 | loss 1.4592 | lr 3.00e-04 | grad 3.52 | tok/s 17872
step   2310 | loss 1.4253 | lr 3.00e-04 | grad 3.16 | tok/s 17183
step   2320 | loss 1.8557 | lr 3.00e-04 | grad 4.25 | tok/s 17142
step   2330 | loss 1.5999 | lr 3.00e-04 | grad 3.58 | tok/s 17246
step   2340 | loss 1.4542 | lr 3.00e-04 | grad 3.31 | tok/s 17021
step   2350 | loss 1.3789 | lr 3.00e-04 | grad 3.17 | tok/s 17814
step   2360 | loss 1.2497 | lr 3.00e-04 | grad 1.90 | tok/s 18254
step   2370 | loss 1.5562 | lr 3.00e-04 | grad 4.16 | tok/s 17857
step   2380 | loss 1.4154 | lr 3.00e-04 | grad 2.47 | tok/s 18260
step   2390 | loss 1.1314 | lr 3.00e-04 | grad 2.36 | tok/s 18233
step   2400 | loss 1.0593 | lr 3.00e-04 | grad 2.27 | tok/s 18234
step   2410 | loss 1.2130 | lr 3.00e-04 | grad 2.08 | tok/s 17506
step   2420 | loss 1.4987 | lr 3.00e-04 | grad 2.70 | tok/s 16851
step   2430 | loss 1.3321 | lr 3.00e-04 | grad 2.09 | tok/s 16932
step   2440 | loss 1.3137 | lr 3.00e-04 | grad 2.41 | tok/s 17680
step   2450 | loss 1.4912 | lr 3.00e-04 | grad 2.27 | tok/s 17585
step   2460 | loss 1.2353 | lr 3.00e-04 | grad 1.99 | tok/s 18145
step   2470 | loss 1.1860 | lr 3.00e-04 | grad 2.34 | tok/s 18007
step   2480 | loss 1.1823 | lr 3.00e-04 | grad 3.58 | tok/s 18117
step   2490 | loss 1.4197 | lr 3.00e-04 | grad 2.95 | tok/s 17264
step   2500 | loss 1.4912 | lr 3.00e-04 | grad 3.81 | tok/s 17995
step   2510 | loss 1.0864 | lr 3.00e-04 | grad 2.70 | tok/s 18234
step   2520 | loss 1.5049 | lr 3.00e-04 | grad 2.38 | tok/s 17976
step   2530 | loss 1.3132 | lr 3.00e-04 | grad 2.78 | tok/s 17612
step   2540 | loss 1.3916 | lr 3.00e-04 | grad 2.95 | tok/s 17529
step   2550 | loss 1.1498 | lr 3.00e-04 | grad 1.80 | tok/s 18215
step   2560 | loss 1.5515 | lr 3.00e-04 | grad 4.78 | tok/s 16961
step   2570 | loss 1.3211 | lr 3.00e-04 | grad 2.69 | tok/s 17481

Training complete! Final step: 2570
