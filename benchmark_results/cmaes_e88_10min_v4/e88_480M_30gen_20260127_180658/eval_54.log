Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_54/levelE88_100m_20260127_190941
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 485,338,138 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0878 | lr 3.00e-04 | grad 18.12 | tok/s 5829
step     20 | loss 2.8843 | lr 3.00e-04 | grad 9.44 | tok/s 16246
step     30 | loss 2.6405 | lr 3.00e-04 | grad 5.94 | tok/s 16426
step     40 | loss 2.4210 | lr 3.00e-04 | grad 4.72 | tok/s 15707
step     50 | loss 2.9835 | lr 3.00e-04 | grad 12.94 | tok/s 15846
step     60 | loss 2.0646 | lr 3.00e-04 | grad 5.00 | tok/s 16492
step     70 | loss 1.8796 | lr 3.00e-04 | grad 5.44 | tok/s 16654
step     80 | loss 6.1574 | lr 3.00e-04 | grad 71.00 | tok/s 16716
step     90 | loss 5.6559 | lr 3.00e-04 | grad 10.56 | tok/s 17042
step    100 | loss 4.3206 | lr 3.00e-04 | grad 8.88 | tok/s 16999
step    110 | loss 3.6262 | lr 3.00e-04 | grad 14.94 | tok/s 16966
step    120 | loss 3.2364 | lr 3.00e-04 | grad 13.19 | tok/s 16975
step    130 | loss 2.9961 | lr 3.00e-04 | grad 15.44 | tok/s 16964
step    140 | loss 2.6325 | lr 3.00e-04 | grad 10.38 | tok/s 16926
step    150 | loss 2.7610 | lr 3.00e-04 | grad 12.81 | tok/s 16936
step    160 | loss 2.3285 | lr 3.00e-04 | grad 8.44 | tok/s 16946
step    170 | loss 2.4182 | lr 3.00e-04 | grad 13.75 | tok/s 16939
step    180 | loss 2.2790 | lr 3.00e-04 | grad 8.56 | tok/s 16935
step    190 | loss 2.4088 | lr 3.00e-04 | grad 6.91 | tok/s 16910
step    200 | loss 2.0863 | lr 3.00e-04 | grad 6.44 | tok/s 16874
step    210 | loss 2.0873 | lr 3.00e-04 | grad 7.00 | tok/s 16904
step    220 | loss 2.1537 | lr 3.00e-04 | grad 3.56 | tok/s 16688
step    230 | loss 2.0508 | lr 3.00e-04 | grad 3.39 | tok/s 15246
step    240 | loss 2.2877 | lr 3.00e-04 | grad 4.91 | tok/s 15662
step    250 | loss 2.0899 | lr 3.00e-04 | grad 2.84 | tok/s 16064
step    260 | loss 1.5293 | lr 3.00e-04 | grad 3.16 | tok/s 16627
step    270 | loss 2.0727 | lr 3.00e-04 | grad 2.98 | tok/s 16376
step    280 | loss 2.2410 | lr 3.00e-04 | grad 5.41 | tok/s 16085
step    290 | loss 1.3711 | lr 3.00e-04 | grad 4.00 | tok/s 16947
step    300 | loss 0.5883 | lr 3.00e-04 | grad 2.81 | tok/s 16896
step    310 | loss 2.3748 | lr 3.00e-04 | grad 3.78 | tok/s 16648
step    320 | loss 1.8981 | lr 3.00e-04 | grad 6.00 | tok/s 16276
step    330 | loss 1.9439 | lr 3.00e-04 | grad 3.05 | tok/s 15724
step    340 | loss 2.2747 | lr 3.00e-04 | grad 2.97 | tok/s 15984
step    350 | loss 1.8622 | lr 3.00e-04 | grad 4.06 | tok/s 16427
step    360 | loss 1.1940 | lr 3.00e-04 | grad 8.12 | tok/s 16757
step    370 | loss 1.8067 | lr 3.00e-04 | grad 2.75 | tok/s 15206
step    380 | loss 1.7507 | lr 3.00e-04 | grad 2.72 | tok/s 16197
step    390 | loss 1.5267 | lr 3.00e-04 | grad 2.22 | tok/s 16911
step    400 | loss 1.4834 | lr 3.00e-04 | grad 2.69 | tok/s 16761
step    410 | loss 1.2665 | lr 3.00e-04 | grad 2.12 | tok/s 16373
step    420 | loss 1.8191 | lr 3.00e-04 | grad 4.59 | tok/s 14802
step    430 | loss 2.1551 | lr 3.00e-04 | grad 3.17 | tok/s 16643
step    440 | loss 2.1536 | lr 3.00e-04 | grad 4.31 | tok/s 15712
step    450 | loss 1.9680 | lr 3.00e-04 | grad 2.83 | tok/s 16262
step    460 | loss 1.7138 | lr 3.00e-04 | grad 2.92 | tok/s 15910
step    470 | loss 1.8359 | lr 3.00e-04 | grad 2.59 | tok/s 16423
step    480 | loss 2.2422 | lr 3.00e-04 | grad 6.97 | tok/s 16412
step    490 | loss 1.7935 | lr 3.00e-04 | grad 2.70 | tok/s 15524
step    500 | loss 1.6724 | lr 3.00e-04 | grad 3.58 | tok/s 16578
step    510 | loss 1.7072 | lr 3.00e-04 | grad 2.42 | tok/s 16807
step    520 | loss 1.6579 | lr 3.00e-04 | grad 2.11 | tok/s 16742
step    530 | loss 1.9215 | lr 3.00e-04 | grad 2.53 | tok/s 16128
step    540 | loss 1.7350 | lr 3.00e-04 | grad 2.42 | tok/s 16135
step    550 | loss 1.5698 | lr 3.00e-04 | grad 3.06 | tok/s 15797
step    560 | loss 1.7264 | lr 3.00e-04 | grad 2.73 | tok/s 15412
step    570 | loss 1.6645 | lr 3.00e-04 | grad 3.80 | tok/s 14760
step    580 | loss 1.5496 | lr 3.00e-04 | grad 2.30 | tok/s 15791
step    590 | loss 1.8540 | lr 3.00e-04 | grad 3.27 | tok/s 16196
step    600 | loss 1.8205 | lr 3.00e-04 | grad 2.30 | tok/s 15627
step    610 | loss 1.6266 | lr 3.00e-04 | grad 2.45 | tok/s 16391
step    620 | loss 1.5471 | lr 3.00e-04 | grad 2.48 | tok/s 15567
step    630 | loss 1.6504 | lr 3.00e-04 | grad 4.41 | tok/s 15688
step    640 | loss 1.8096 | lr 3.00e-04 | grad 2.56 | tok/s 16125
step    650 | loss 1.6663 | lr 3.00e-04 | grad 2.72 | tok/s 16192
step    660 | loss 1.6997 | lr 3.00e-04 | grad 2.31 | tok/s 16254
step    670 | loss 1.9237 | lr 3.00e-04 | grad 3.25 | tok/s 16370
step    680 | loss 1.7350 | lr 3.00e-04 | grad 2.45 | tok/s 16045
step    690 | loss 1.8337 | lr 3.00e-04 | grad 3.44 | tok/s 16604
step    700 | loss 1.4280 | lr 3.00e-04 | grad 3.16 | tok/s 16870
step    710 | loss 1.5920 | lr 3.00e-04 | grad 2.44 | tok/s 15787
step    720 | loss 1.4766 | lr 3.00e-04 | grad 3.31 | tok/s 15532
step    730 | loss 1.2869 | lr 3.00e-04 | grad 2.83 | tok/s 16852
step    740 | loss 1.5050 | lr 3.00e-04 | grad 2.41 | tok/s 16606
step    750 | loss 1.2007 | lr 3.00e-04 | grad 2.55 | tok/s 16889
step    760 | loss 1.1027 | lr 3.00e-04 | grad 2.25 | tok/s 16901
step    770 | loss 1.0539 | lr 3.00e-04 | grad 2.02 | tok/s 16868
step    780 | loss 0.9920 | lr 3.00e-04 | grad 2.16 | tok/s 16895
step    790 | loss 1.1286 | lr 3.00e-04 | grad 3.28 | tok/s 16341
step    800 | loss 1.8234 | lr 3.00e-04 | grad 5.53 | tok/s 16293
step    810 | loss 1.7066 | lr 3.00e-04 | grad 2.16 | tok/s 16222
step    820 | loss 1.7169 | lr 3.00e-04 | grad 3.91 | tok/s 15511
step    830 | loss 1.5004 | lr 3.00e-04 | grad 2.28 | tok/s 16686
step    840 | loss 1.3616 | lr 3.00e-04 | grad 2.31 | tok/s 16891
step    850 | loss 1.6113 | lr 3.00e-04 | grad 2.11 | tok/s 16793
step    860 | loss 1.4822 | lr 3.00e-04 | grad 3.62 | tok/s 16612
step    870 | loss 1.5066 | lr 3.00e-04 | grad 2.58 | tok/s 15967
step    880 | loss 1.6849 | lr 3.00e-04 | grad 2.64 | tok/s 16076
step    890 | loss 1.6902 | lr 3.00e-04 | grad 2.95 | tok/s 16329
step    900 | loss 1.5749 | lr 3.00e-04 | grad 2.61 | tok/s 16262
step    910 | loss 1.4241 | lr 3.00e-04 | grad 4.03 | tok/s 15965
step    920 | loss 1.5249 | lr 3.00e-04 | grad 3.61 | tok/s 16564
step    930 | loss 1.6039 | lr 3.00e-04 | grad 3.52 | tok/s 15817
step    940 | loss 1.3844 | lr 3.00e-04 | grad 1.94 | tok/s 16560
step    950 | loss 1.4896 | lr 3.00e-04 | grad 2.97 | tok/s 16745
step    960 | loss 1.3264 | lr 3.00e-04 | grad 2.64 | tok/s 16795
step    970 | loss 1.7531 | lr 3.00e-04 | grad 3.67 | tok/s 15825
step    980 | loss 1.6450 | lr 3.00e-04 | grad 2.61 | tok/s 16131
step    990 | loss 1.4519 | lr 3.00e-04 | grad 2.11 | tok/s 16450
step   1000 | loss 1.8448 | lr 3.00e-04 | grad 8.44 | tok/s 15867
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8448.pt
step   1010 | loss 1.7101 | lr 3.00e-04 | grad 3.67 | tok/s 5095
step   1020 | loss 1.6649 | lr 3.00e-04 | grad 2.42 | tok/s 12981
step   1030 | loss 1.4067 | lr 3.00e-04 | grad 2.23 | tok/s 16412
step   1040 | loss 1.5177 | lr 3.00e-04 | grad 2.30 | tok/s 16349
step   1050 | loss 1.6350 | lr 3.00e-04 | grad 2.72 | tok/s 15899
step   1060 | loss 1.6906 | lr 3.00e-04 | grad 2.27 | tok/s 16619
step   1070 | loss 1.6713 | lr 3.00e-04 | grad 2.44 | tok/s 16313
step   1080 | loss 1.4066 | lr 3.00e-04 | grad 2.56 | tok/s 15298
step   1090 | loss 1.0285 | lr 3.00e-04 | grad 5.44 | tok/s 16918
step   1100 | loss 1.5593 | lr 3.00e-04 | grad 2.56 | tok/s 16285
step   1110 | loss 1.4025 | lr 3.00e-04 | grad 2.00 | tok/s 16997
step   1120 | loss 1.3340 | lr 3.00e-04 | grad 2.39 | tok/s 16906
step   1130 | loss 1.2757 | lr 3.00e-04 | grad 2.27 | tok/s 16972
step   1140 | loss 1.2885 | lr 3.00e-04 | grad 2.09 | tok/s 16968
step   1150 | loss 1.2797 | lr 3.00e-04 | grad 1.87 | tok/s 16982
step   1160 | loss 1.2084 | lr 3.00e-04 | grad 1.90 | tok/s 16902
step   1170 | loss 1.2862 | lr 3.00e-04 | grad 2.11 | tok/s 16927
step   1180 | loss 1.2981 | lr 3.00e-04 | grad 2.59 | tok/s 16936
step   1190 | loss 1.2133 | lr 3.00e-04 | grad 1.92 | tok/s 16918
step   1200 | loss 1.2308 | lr 3.00e-04 | grad 1.86 | tok/s 16866
step   1210 | loss 1.2598 | lr 3.00e-04 | grad 2.00 | tok/s 16895
step   1220 | loss 1.2780 | lr 3.00e-04 | grad 2.02 | tok/s 16865
step   1230 | loss 1.2557 | lr 3.00e-04 | grad 1.71 | tok/s 16915
step   1240 | loss 1.3677 | lr 3.00e-04 | grad 5.72 | tok/s 16519
step   1250 | loss 1.7305 | lr 3.00e-04 | grad 2.28 | tok/s 15862
step   1260 | loss 1.3209 | lr 3.00e-04 | grad 2.45 | tok/s 15627
step   1270 | loss 1.7429 | lr 3.00e-04 | grad 2.45 | tok/s 15659
step   1280 | loss 1.5831 | lr 3.00e-04 | grad 2.08 | tok/s 13827
step   1290 | loss 1.5328 | lr 3.00e-04 | grad 2.66 | tok/s 16457
step   1300 | loss 1.5102 | lr 3.00e-04 | grad 3.33 | tok/s 16172
step   1310 | loss 1.4516 | lr 3.00e-04 | grad 3.61 | tok/s 16954
step   1320 | loss 1.6364 | lr 3.00e-04 | grad 3.55 | tok/s 16757
step   1330 | loss 1.4144 | lr 3.00e-04 | grad 2.25 | tok/s 16752
step   1340 | loss 1.6378 | lr 3.00e-04 | grad 2.16 | tok/s 15473
step   1350 | loss 1.7737 | lr 3.00e-04 | grad 3.12 | tok/s 15807
step   1360 | loss 1.4528 | lr 3.00e-04 | grad 1.86 | tok/s 16545
step   1370 | loss 1.5690 | lr 3.00e-04 | grad 4.41 | tok/s 16237
step   1380 | loss 1.5780 | lr 3.00e-04 | grad 2.77 | tok/s 15602
step   1390 | loss 1.4436 | lr 3.00e-04 | grad 1.99 | tok/s 16158
step   1400 | loss 1.3952 | lr 3.00e-04 | grad 2.06 | tok/s 16342
step   1410 | loss 1.5811 | lr 3.00e-04 | grad 3.92 | tok/s 16038
step   1420 | loss 1.6205 | lr 3.00e-04 | grad 2.44 | tok/s 16025
step   1430 | loss 1.3227 | lr 3.00e-04 | grad 2.33 | tok/s 16239
step   1440 | loss 1.1381 | lr 3.00e-04 | grad 1.97 | tok/s 17042
step   1450 | loss 1.2978 | lr 3.00e-04 | grad 6.59 | tok/s 16826
step   1460 | loss 1.6925 | lr 3.00e-04 | grad 5.84 | tok/s 15894
step   1470 | loss 1.4294 | lr 3.00e-04 | grad 1.87 | tok/s 15807
step   1480 | loss 1.8563 | lr 3.00e-04 | grad 3.72 | tok/s 16602
step   1490 | loss 1.5627 | lr 3.00e-04 | grad 5.84 | tok/s 16824
step   1500 | loss 1.2778 | lr 3.00e-04 | grad 1.95 | tok/s 16872
step   1510 | loss 1.5604 | lr 3.00e-04 | grad 2.17 | tok/s 16692
step   1520 | loss 1.4641 | lr 3.00e-04 | grad 2.62 | tok/s 16369
step   1530 | loss 1.4193 | lr 3.00e-04 | grad 2.16 | tok/s 16374
step   1540 | loss 1.6586 | lr 3.00e-04 | grad 2.30 | tok/s 16080
step   1550 | loss 1.2500 | lr 3.00e-04 | grad 2.38 | tok/s 16759
step   1560 | loss 1.6054 | lr 3.00e-04 | grad 2.23 | tok/s 15914
step   1570 | loss 1.3329 | lr 3.00e-04 | grad 3.22 | tok/s 16688
step   1580 | loss 1.6776 | lr 3.00e-04 | grad 3.55 | tok/s 16669
step   1590 | loss 1.5509 | lr 3.00e-04 | grad 2.02 | tok/s 15851
step   1600 | loss 0.8522 | lr 3.00e-04 | grad 1.49 | tok/s 16988
step   1610 | loss 1.1955 | lr 3.00e-04 | grad 1.96 | tok/s 14751
step   1620 | loss 1.3605 | lr 3.00e-04 | grad 3.27 | tok/s 16061
step   1630 | loss 1.3640 | lr 3.00e-04 | grad 2.11 | tok/s 16454
step   1640 | loss 1.4610 | lr 3.00e-04 | grad 4.47 | tok/s 15945
step   1650 | loss 1.5891 | lr 3.00e-04 | grad 4.28 | tok/s 15048
step   1660 | loss 1.2329 | lr 3.00e-04 | grad 1.70 | tok/s 16887
step   1670 | loss 1.6220 | lr 3.00e-04 | grad 7.53 | tok/s 16029
step   1680 | loss 1.5616 | lr 3.00e-04 | grad 2.61 | tok/s 15730
step   1690 | loss 1.4560 | lr 3.00e-04 | grad 3.39 | tok/s 16356
step   1700 | loss 1.5340 | lr 3.00e-04 | grad 2.19 | tok/s 15912
step   1710 | loss 1.4561 | lr 3.00e-04 | grad 2.30 | tok/s 16449
step   1720 | loss 1.5115 | lr 3.00e-04 | grad 3.03 | tok/s 16964
step   1730 | loss 1.2098 | lr 3.00e-04 | grad 3.61 | tok/s 16953
step   1740 | loss 1.4123 | lr 3.00e-04 | grad 2.52 | tok/s 16268
step   1750 | loss 1.5232 | lr 3.00e-04 | grad 2.45 | tok/s 16553
step   1760 | loss 1.6020 | lr 3.00e-04 | grad 2.56 | tok/s 16293
step   1770 | loss 1.4376 | lr 3.00e-04 | grad 1.88 | tok/s 16025
step   1780 | loss 1.5047 | lr 3.00e-04 | grad 2.72 | tok/s 16417
step   1790 | loss 1.4290 | lr 3.00e-04 | grad 2.00 | tok/s 16285
step   1800 | loss 1.5721 | lr 3.00e-04 | grad 2.36 | tok/s 15885
step   1810 | loss 1.4846 | lr 3.00e-04 | grad 3.02 | tok/s 16070
step   1820 | loss 1.4851 | lr 3.00e-04 | grad 3.67 | tok/s 16227
step   1830 | loss 1.4549 | lr 3.00e-04 | grad 2.41 | tok/s 16498
step   1840 | loss 1.4682 | lr 3.00e-04 | grad 1.60 | tok/s 15764
step   1850 | loss 1.2912 | lr 3.00e-04 | grad 1.91 | tok/s 16811
step   1860 | loss 1.3715 | lr 3.00e-04 | grad 2.33 | tok/s 15680
step   1870 | loss 1.3461 | lr 3.00e-04 | grad 1.52 | tok/s 16567
step   1880 | loss 1.3185 | lr 3.00e-04 | grad 2.45 | tok/s 15004
step   1890 | loss 1.5528 | lr 3.00e-04 | grad 1.88 | tok/s 15832
step   1900 | loss 1.3749 | lr 3.00e-04 | grad 1.95 | tok/s 16060
step   1910 | loss 1.5026 | lr 3.00e-04 | grad 1.88 | tok/s 15621
step   1920 | loss 1.3656 | lr 3.00e-04 | grad 1.93 | tok/s 16738
step   1930 | loss 1.4878 | lr 3.00e-04 | grad 2.16 | tok/s 15622
step   1940 | loss 1.4794 | lr 3.00e-04 | grad 3.11 | tok/s 16557
step   1950 | loss 1.8400 | lr 3.00e-04 | grad 3.41 | tok/s 16930
step   1960 | loss 1.4617 | lr 3.00e-04 | grad 3.86 | tok/s 16955
step   1970 | loss 1.5432 | lr 3.00e-04 | grad 5.09 | tok/s 16354
step   1980 | loss 1.5050 | lr 3.00e-04 | grad 1.72 | tok/s 15931
step   1990 | loss 1.6323 | lr 3.00e-04 | grad 1.94 | tok/s 16114
step   2000 | loss 1.5146 | lr 3.00e-04 | grad 2.19 | tok/s 16294
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5146.pt
step   2010 | loss 1.1933 | lr 3.00e-04 | grad 2.52 | tok/s 6276
step   2020 | loss 1.3268 | lr 3.00e-04 | grad 2.69 | tok/s 16614
step   2030 | loss 0.9784 | lr 3.00e-04 | grad 4.34 | tok/s 17052
step   2040 | loss 1.2623 | lr 3.00e-04 | grad 1.65 | tok/s 16233
step   2050 | loss 1.3082 | lr 3.00e-04 | grad 2.84 | tok/s 16456
step   2060 | loss 1.6734 | lr 3.00e-04 | grad 2.42 | tok/s 16140
step   2070 | loss 1.9126 | lr 3.00e-04 | grad 7.31 | tok/s 16234
step   2080 | loss 2.0917 | lr 3.00e-04 | grad 3.94 | tok/s 17048
step   2090 | loss 1.5965 | lr 3.00e-04 | grad 2.23 | tok/s 16755
step   2100 | loss 1.3768 | lr 3.00e-04 | grad 3.53 | tok/s 16783
step   2110 | loss 1.4724 | lr 3.00e-04 | grad 2.36 | tok/s 15910
step   2120 | loss 0.8292 | lr 3.00e-04 | grad 1.74 | tok/s 17169
step   2130 | loss 1.3492 | lr 3.00e-04 | grad 2.55 | tok/s 16274
step   2140 | loss 1.4591 | lr 3.00e-04 | grad 1.98 | tok/s 16753
step   2150 | loss 1.2911 | lr 3.00e-04 | grad 2.17 | tok/s 17025
step   2160 | loss 1.1911 | lr 3.00e-04 | grad 1.95 | tok/s 17018
step   2170 | loss 1.2255 | lr 3.00e-04 | grad 1.81 | tok/s 16998
step   2180 | loss 1.1933 | lr 3.00e-04 | grad 1.78 | tok/s 16967
step   2190 | loss 1.2288 | lr 3.00e-04 | grad 1.95 | tok/s 17016
step   2200 | loss 1.1634 | lr 3.00e-04 | grad 1.76 | tok/s 17033
step   2210 | loss 1.1579 | lr 3.00e-04 | grad 1.83 | tok/s 17024
step   2220 | loss 1.1250 | lr 3.00e-04 | grad 1.80 | tok/s 17027
step   2230 | loss 1.4380 | lr 3.00e-04 | grad 2.19 | tok/s 15812
step   2240 | loss 1.3590 | lr 3.00e-04 | grad 4.97 | tok/s 16340
step   2250 | loss 1.5958 | lr 3.00e-04 | grad 4.66 | tok/s 16914
step   2260 | loss 1.5971 | lr 3.00e-04 | grad 2.36 | tok/s 16329
step   2270 | loss 1.9638 | lr 3.00e-04 | grad 3.20 | tok/s 16723
step   2280 | loss 1.3952 | lr 3.00e-04 | grad 2.62 | tok/s 16860
step   2290 | loss 1.5079 | lr 3.00e-04 | grad 2.64 | tok/s 16101
step   2300 | loss 1.4068 | lr 3.00e-04 | grad 2.52 | tok/s 16628
step   2310 | loss 1.4187 | lr 3.00e-04 | grad 1.79 | tok/s 16048
step   2320 | loss 1.9730 | lr 3.00e-04 | grad 2.97 | tok/s 15899
step   2330 | loss 1.4929 | lr 3.00e-04 | grad 2.44 | tok/s 15753
step   2340 | loss 1.4772 | lr 3.00e-04 | grad 2.94 | tok/s 15916
step   2350 | loss 1.3691 | lr 3.00e-04 | grad 2.83 | tok/s 16551
step   2360 | loss 1.2502 | lr 3.00e-04 | grad 3.25 | tok/s 16725
step   2370 | loss 1.6011 | lr 3.00e-04 | grad 3.20 | tok/s 15588
step   2380 | loss 1.4273 | lr 3.00e-04 | grad 3.27 | tok/s 17064

Training complete! Final step: 2384
