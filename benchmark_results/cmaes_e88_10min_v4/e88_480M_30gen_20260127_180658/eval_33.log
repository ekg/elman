Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_33/levelE88_100m_20260127_184855
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 477,156,342 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.5771 | lr 3.00e-04 | grad 20.50 | tok/s 9085
step     20 | loss 3.6394 | lr 3.00e-04 | grad 8.44 | tok/s 18368
step     30 | loss 3.4260 | lr 3.00e-04 | grad 11.19 | tok/s 19334
step     40 | loss 4.6442 | lr 3.00e-04 | grad 26.38 | tok/s 19666
step     50 | loss 4.2672 | lr 3.00e-04 | grad 14.06 | tok/s 19851
step     60 | loss 3.2903 | lr 3.00e-04 | grad 8.19 | tok/s 19752
step     70 | loss 2.8907 | lr 3.00e-04 | grad 5.59 | tok/s 19655
step     80 | loss 2.6621 | lr 3.00e-04 | grad 6.59 | tok/s 19688
step     90 | loss 2.5926 | lr 3.00e-04 | grad 5.44 | tok/s 19638
step    100 | loss 2.2880 | lr 3.00e-04 | grad 4.72 | tok/s 19543
step    110 | loss 2.2669 | lr 3.00e-04 | grad 5.66 | tok/s 19339
step    120 | loss 2.6877 | lr 3.00e-04 | grad 3.70 | tok/s 18411
step    130 | loss 2.0888 | lr 3.00e-04 | grad 7.22 | tok/s 18837
step    140 | loss 2.3883 | lr 3.00e-04 | grad 9.75 | tok/s 18924
step    150 | loss 1.3867 | lr 3.00e-04 | grad 7.97 | tok/s 19400
step    160 | loss 2.3079 | lr 3.00e-04 | grad 3.45 | tok/s 18742
step    170 | loss 2.3040 | lr 3.00e-04 | grad 2.66 | tok/s 18447
step    180 | loss 1.8068 | lr 3.00e-04 | grad 4.41 | tok/s 18891
step    190 | loss 1.8945 | lr 3.00e-04 | grad 3.89 | tok/s 18539
step    200 | loss 1.6121 | lr 3.00e-04 | grad 2.89 | tok/s 19371
step    210 | loss 1.8699 | lr 3.00e-04 | grad 8.50 | tok/s 18397
step    220 | loss 2.1994 | lr 3.00e-04 | grad 5.28 | tok/s 18563
step    230 | loss 2.0387 | lr 3.00e-04 | grad 3.53 | tok/s 18552
step    240 | loss 2.2615 | lr 3.00e-04 | grad 7.66 | tok/s 18808
step    250 | loss 1.7451 | lr 3.00e-04 | grad 2.64 | tok/s 18688
step    260 | loss 1.8797 | lr 3.00e-04 | grad 4.66 | tok/s 19168
step    270 | loss 1.8112 | lr 3.00e-04 | grad 2.94 | tok/s 18789
step    280 | loss 1.7596 | lr 3.00e-04 | grad 2.39 | tok/s 17638
step    290 | loss 1.6597 | lr 3.00e-04 | grad 3.03 | tok/s 18263
step    300 | loss 1.9775 | lr 3.00e-04 | grad 2.94 | tok/s 18418
step    310 | loss 1.6577 | lr 3.00e-04 | grad 2.56 | tok/s 18276
step    320 | loss 1.8831 | lr 3.00e-04 | grad 5.00 | tok/s 18516
step    330 | loss 1.7142 | lr 3.00e-04 | grad 2.78 | tok/s 18740
step    340 | loss 2.0363 | lr 3.00e-04 | grad 2.98 | tok/s 18631
step    350 | loss 1.6994 | lr 3.00e-04 | grad 2.69 | tok/s 19173
step    360 | loss 1.5823 | lr 3.00e-04 | grad 2.39 | tok/s 18344
step    370 | loss 1.4758 | lr 3.00e-04 | grad 2.47 | tok/s 19320
step    380 | loss 1.1988 | lr 3.00e-04 | grad 2.14 | tok/s 19464
step    390 | loss 1.1107 | lr 3.00e-04 | grad 2.08 | tok/s 19512
step    400 | loss 1.7578 | lr 3.00e-04 | grad 2.33 | tok/s 18458
step    410 | loss 1.7806 | lr 3.00e-04 | grad 3.19 | tok/s 18632
step    420 | loss 1.5903 | lr 3.00e-04 | grad 4.56 | tok/s 19428
step    430 | loss 1.6042 | lr 3.00e-04 | grad 2.73 | tok/s 19117
step    440 | loss 1.7112 | lr 3.00e-04 | grad 3.33 | tok/s 18494
step    450 | loss 1.6430 | lr 3.00e-04 | grad 2.25 | tok/s 18725
step    460 | loss 1.5999 | lr 3.00e-04 | grad 2.66 | tok/s 18989
step    470 | loss 1.5683 | lr 3.00e-04 | grad 4.78 | tok/s 18855
step    480 | loss 1.5818 | lr 3.00e-04 | grad 3.86 | tok/s 19248
step    490 | loss 1.7152 | lr 3.00e-04 | grad 3.17 | tok/s 18484
step    500 | loss 1.8145 | lr 3.00e-04 | grad 2.28 | tok/s 18780
step    510 | loss 1.6894 | lr 3.00e-04 | grad 2.47 | tok/s 17940
step    520 | loss 1.5392 | lr 3.00e-04 | grad 2.94 | tok/s 18796
step    530 | loss 1.7214 | lr 3.00e-04 | grad 2.39 | tok/s 18466
step    540 | loss 1.5914 | lr 3.00e-04 | grad 2.34 | tok/s 18110
step    550 | loss 1.3874 | lr 3.00e-04 | grad 4.31 | tok/s 18917
step    560 | loss 1.4542 | lr 3.00e-04 | grad 2.56 | tok/s 19487
step    570 | loss 1.3508 | lr 3.00e-04 | grad 2.50 | tok/s 19510
step    580 | loss 1.3034 | lr 3.00e-04 | grad 1.97 | tok/s 19493
step    590 | loss 1.3391 | lr 3.00e-04 | grad 2.03 | tok/s 19479
step    600 | loss 1.2735 | lr 3.00e-04 | grad 2.33 | tok/s 19453
step    610 | loss 1.3098 | lr 3.00e-04 | grad 2.34 | tok/s 19476
step    620 | loss 1.2992 | lr 3.00e-04 | grad 2.45 | tok/s 19369
step    630 | loss 1.7296 | lr 3.00e-04 | grad 7.72 | tok/s 18339
step    640 | loss 1.7522 | lr 3.00e-04 | grad 2.44 | tok/s 18599
step    650 | loss 1.5656 | lr 3.00e-04 | grad 2.41 | tok/s 18546
step    660 | loss 1.6043 | lr 3.00e-04 | grad 2.44 | tok/s 19271
step    670 | loss 1.6444 | lr 3.00e-04 | grad 6.19 | tok/s 18640
step    680 | loss 1.6634 | lr 3.00e-04 | grad 2.95 | tok/s 18343
step    690 | loss 1.6118 | lr 3.00e-04 | grad 2.50 | tok/s 18207
step    700 | loss 1.4929 | lr 3.00e-04 | grad 1.75 | tok/s 18600
step    710 | loss 1.6592 | lr 3.00e-04 | grad 3.50 | tok/s 18287
step    720 | loss 1.3190 | lr 3.00e-04 | grad 2.42 | tok/s 19030
step    730 | loss 1.5019 | lr 3.00e-04 | grad 1.99 | tok/s 18703
step    740 | loss 1.7935 | lr 3.00e-04 | grad 5.06 | tok/s 19232
step    750 | loss 1.5307 | lr 3.00e-04 | grad 2.23 | tok/s 19463
step    760 | loss 1.5601 | lr 3.00e-04 | grad 5.28 | tok/s 19050
step    770 | loss 1.6110 | lr 3.00e-04 | grad 2.69 | tok/s 18718
step    780 | loss 1.5004 | lr 3.00e-04 | grad 2.53 | tok/s 18858
step    790 | loss 1.6332 | lr 3.00e-04 | grad 5.56 | tok/s 19281
step    800 | loss 1.3404 | lr 3.00e-04 | grad 1.65 | tok/s 18919
step    810 | loss 1.3280 | lr 3.00e-04 | grad 3.28 | tok/s 18300
step    820 | loss 1.4364 | lr 3.00e-04 | grad 2.56 | tok/s 18676
step    830 | loss 1.5097 | lr 3.00e-04 | grad 2.06 | tok/s 18426
step    840 | loss 1.6604 | lr 3.00e-04 | grad 2.52 | tok/s 18346
step    850 | loss 1.5700 | lr 3.00e-04 | grad 1.91 | tok/s 18732
step    860 | loss 1.6181 | lr 3.00e-04 | grad 3.83 | tok/s 18321
step    870 | loss 1.4200 | lr 3.00e-04 | grad 2.34 | tok/s 19177
step    880 | loss 1.6168 | lr 3.00e-04 | grad 2.61 | tok/s 18822
step    890 | loss 1.5112 | lr 3.00e-04 | grad 1.97 | tok/s 18758
step    900 | loss 1.5607 | lr 3.00e-04 | grad 2.05 | tok/s 18685
step    910 | loss 1.5612 | lr 3.00e-04 | grad 8.88 | tok/s 18472
step    920 | loss 1.5142 | lr 3.00e-04 | grad 3.05 | tok/s 18652
step    930 | loss 1.3980 | lr 3.00e-04 | grad 2.61 | tok/s 18914
step    940 | loss 1.3777 | lr 3.00e-04 | grad 2.25 | tok/s 18493
step    950 | loss 1.5156 | lr 3.00e-04 | grad 3.14 | tok/s 18207
step    960 | loss 1.4673 | lr 3.00e-04 | grad 2.36 | tok/s 18684
step    970 | loss 1.4934 | lr 3.00e-04 | grad 2.20 | tok/s 18700
step    980 | loss 1.9206 | lr 3.00e-04 | grad 4.22 | tok/s 19420
step    990 | loss 1.6066 | lr 3.00e-04 | grad 2.39 | tok/s 18673
step   1000 | loss 1.6049 | lr 3.00e-04 | grad 2.77 | tok/s 18708
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6049.pt
step   1010 | loss 1.3821 | lr 3.00e-04 | grad 2.44 | tok/s 10328
step   1020 | loss 1.2021 | lr 3.00e-04 | grad 1.78 | tok/s 19746
step   1030 | loss 1.6236 | lr 3.00e-04 | grad 2.45 | tok/s 18633
step   1040 | loss 2.2182 | lr 3.00e-04 | grad 6.28 | tok/s 19255
step   1050 | loss 1.5039 | lr 3.00e-04 | grad 2.53 | tok/s 19016
step   1060 | loss 1.1435 | lr 3.00e-04 | grad 1.96 | tok/s 19347
step   1070 | loss 1.5070 | lr 3.00e-04 | grad 2.42 | tok/s 18974
step   1080 | loss 1.2815 | lr 3.00e-04 | grad 2.52 | tok/s 19591
step   1090 | loss 1.2530 | lr 3.00e-04 | grad 2.28 | tok/s 19598
step   1100 | loss 1.2071 | lr 3.00e-04 | grad 2.62 | tok/s 19599
step   1110 | loss 1.1992 | lr 3.00e-04 | grad 2.27 | tok/s 19590
step   1120 | loss 1.5164 | lr 3.00e-04 | grad 4.44 | tok/s 19055
step   1130 | loss 1.6723 | lr 3.00e-04 | grad 4.09 | tok/s 19260
step   1140 | loss 1.7203 | lr 3.00e-04 | grad 1.77 | tok/s 19471
step   1150 | loss 1.6861 | lr 3.00e-04 | grad 3.06 | tok/s 18531
step   1160 | loss 1.7970 | lr 3.00e-04 | grad 9.31 | tok/s 18767
step   1170 | loss 1.4792 | lr 3.00e-04 | grad 2.44 | tok/s 18493
step   1180 | loss 1.3730 | lr 3.00e-04 | grad 2.97 | tok/s 19195
step   1190 | loss 1.5706 | lr 3.00e-04 | grad 4.59 | tok/s 19540
step   1200 | loss 1.1459 | lr 3.00e-04 | grad 4.97 | tok/s 19560
step   1210 | loss 1.4919 | lr 3.00e-04 | grad 2.92 | tok/s 18212
step   1220 | loss 1.3858 | lr 3.00e-04 | grad 2.08 | tok/s 18938
step   1230 | loss 1.3464 | lr 3.00e-04 | grad 1.80 | tok/s 19390
step   1240 | loss 1.3279 | lr 3.00e-04 | grad 1.84 | tok/s 19034
step   1250 | loss 1.5320 | lr 3.00e-04 | grad 6.66 | tok/s 19154
step   1260 | loss 1.4262 | lr 3.00e-04 | grad 3.27 | tok/s 19301
step   1270 | loss 1.4042 | lr 3.00e-04 | grad 2.19 | tok/s 18937
step   1280 | loss 1.4620 | lr 3.00e-04 | grad 2.44 | tok/s 18631
step   1290 | loss 1.3454 | lr 3.00e-04 | grad 2.06 | tok/s 18651
step   1300 | loss 1.6700 | lr 3.00e-04 | grad 4.47 | tok/s 18375
step   1310 | loss 1.5185 | lr 3.00e-04 | grad 2.28 | tok/s 19006
step   1320 | loss 1.5466 | lr 3.00e-04 | grad 3.48 | tok/s 19200
step   1330 | loss 1.4196 | lr 3.00e-04 | grad 2.92 | tok/s 18926
step   1340 | loss 1.6391 | lr 3.00e-04 | grad 2.59 | tok/s 18562
step   1350 | loss 1.4979 | lr 3.00e-04 | grad 5.25 | tok/s 18813
step   1360 | loss 1.4177 | lr 3.00e-04 | grad 1.99 | tok/s 18382
step   1370 | loss 1.6852 | lr 3.00e-04 | grad 3.73 | tok/s 19235
step   1380 | loss 1.4411 | lr 3.00e-04 | grad 3.16 | tok/s 18313
step   1390 | loss 1.3597 | lr 3.00e-04 | grad 3.42 | tok/s 19265
step   1400 | loss 1.5156 | lr 3.00e-04 | grad 1.88 | tok/s 18622

Training complete! Final step: 1400
