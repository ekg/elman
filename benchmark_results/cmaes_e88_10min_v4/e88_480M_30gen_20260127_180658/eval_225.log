Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v4/e88_480M_30gen_20260127_180658/eval_225/levelE88_100m_20260127_225700
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,810,842 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3617 | lr 3.00e-04 | grad 15.69 | tok/s 6329
step     20 | loss 3.0675 | lr 3.00e-04 | grad 7.78 | tok/s 16723
step     30 | loss 2.6114 | lr 3.00e-04 | grad 5.69 | tok/s 16897
step     40 | loss 2.3384 | lr 3.00e-04 | grad 4.50 | tok/s 16141
step     50 | loss 2.9611 | lr 3.00e-04 | grad 14.31 | tok/s 16377
step     60 | loss 2.0298 | lr 3.00e-04 | grad 3.70 | tok/s 16858
step     70 | loss 1.8145 | lr 3.00e-04 | grad 4.84 | tok/s 16992
step     80 | loss 5.3734 | lr 3.00e-04 | grad 35.50 | tok/s 17142
step     90 | loss 4.7192 | lr 3.00e-04 | grad 6.69 | tok/s 17360
step    100 | loss 3.8885 | lr 3.00e-04 | grad 5.97 | tok/s 17318
step    110 | loss 3.2915 | lr 3.00e-04 | grad 11.69 | tok/s 17343
step    120 | loss 3.0877 | lr 3.00e-04 | grad 9.31 | tok/s 17318
step    130 | loss 2.7755 | lr 3.00e-04 | grad 10.25 | tok/s 17336
step    140 | loss 2.6523 | lr 3.00e-04 | grad 11.81 | tok/s 17322
step    150 | loss 2.8634 | lr 3.00e-04 | grad 16.12 | tok/s 17324
step    160 | loss 2.4165 | lr 3.00e-04 | grad 9.75 | tok/s 17300
step    170 | loss 2.3910 | lr 3.00e-04 | grad 11.38 | tok/s 17235
step    180 | loss 2.3250 | lr 3.00e-04 | grad 6.53 | tok/s 17253
step    190 | loss 2.3856 | lr 3.00e-04 | grad 5.59 | tok/s 17236
step    200 | loss 2.0459 | lr 3.00e-04 | grad 4.88 | tok/s 17217
step    210 | loss 2.0983 | lr 3.00e-04 | grad 9.62 | tok/s 17214
step    220 | loss 2.0732 | lr 3.00e-04 | grad 3.47 | tok/s 16977
step    230 | loss 2.0159 | lr 3.00e-04 | grad 3.80 | tok/s 16797
step    240 | loss 2.2515 | lr 3.00e-04 | grad 4.88 | tok/s 15928
step    250 | loss 2.0540 | lr 3.00e-04 | grad 2.64 | tok/s 16372
step    260 | loss 1.4937 | lr 3.00e-04 | grad 3.09 | tok/s 16891
step    270 | loss 2.0347 | lr 3.00e-04 | grad 2.94 | tok/s 16665
step    280 | loss 2.2207 | lr 3.00e-04 | grad 5.16 | tok/s 16327
step    290 | loss 1.3504 | lr 3.00e-04 | grad 3.70 | tok/s 17214
step    300 | loss 0.5674 | lr 3.00e-04 | grad 4.56 | tok/s 17173
step    310 | loss 2.3695 | lr 3.00e-04 | grad 3.91 | tok/s 16871
step    320 | loss 1.8719 | lr 3.00e-04 | grad 5.72 | tok/s 16538
step    330 | loss 1.9159 | lr 3.00e-04 | grad 3.02 | tok/s 15965
step    340 | loss 2.2519 | lr 3.00e-04 | grad 2.84 | tok/s 16213
step    350 | loss 1.8292 | lr 3.00e-04 | grad 3.59 | tok/s 16623
step    360 | loss 1.1728 | lr 3.00e-04 | grad 7.12 | tok/s 16967
step    370 | loss 1.7684 | lr 3.00e-04 | grad 2.61 | tok/s 15404
step    380 | loss 1.7223 | lr 3.00e-04 | grad 2.89 | tok/s 16418
step    390 | loss 1.5038 | lr 3.00e-04 | grad 2.25 | tok/s 17145
step    400 | loss 1.4588 | lr 3.00e-04 | grad 2.69 | tok/s 16961
step    410 | loss 1.2474 | lr 3.00e-04 | grad 2.05 | tok/s 16617
step    420 | loss 1.7848 | lr 3.00e-04 | grad 4.44 | tok/s 15836
step    430 | loss 2.1320 | lr 3.00e-04 | grad 2.98 | tok/s 16903
step    440 | loss 2.1284 | lr 3.00e-04 | grad 4.12 | tok/s 15976
step    450 | loss 1.9980 | lr 3.00e-04 | grad 2.69 | tok/s 16509
step    460 | loss 1.6945 | lr 3.00e-04 | grad 2.91 | tok/s 16162
step    470 | loss 1.8207 | lr 3.00e-04 | grad 2.61 | tok/s 16651
step    480 | loss 2.2223 | lr 3.00e-04 | grad 6.19 | tok/s 16641
step    490 | loss 1.7816 | lr 3.00e-04 | grad 2.89 | tok/s 15723
step    500 | loss 1.6480 | lr 3.00e-04 | grad 3.50 | tok/s 16809
step    510 | loss 1.6831 | lr 3.00e-04 | grad 2.48 | tok/s 17001
step    520 | loss 1.6344 | lr 3.00e-04 | grad 2.11 | tok/s 16983
step    530 | loss 1.8976 | lr 3.00e-04 | grad 2.38 | tok/s 16325
step    540 | loss 1.7081 | lr 3.00e-04 | grad 2.30 | tok/s 16343
step    550 | loss 1.5490 | lr 3.00e-04 | grad 2.86 | tok/s 15990
step    560 | loss 1.7146 | lr 3.00e-04 | grad 2.69 | tok/s 15607
step    570 | loss 1.6550 | lr 3.00e-04 | grad 3.59 | tok/s 16023
step    580 | loss 1.5386 | lr 3.00e-04 | grad 2.28 | tok/s 15949
step    590 | loss 1.8459 | lr 3.00e-04 | grad 3.20 | tok/s 16370
step    600 | loss 1.8093 | lr 3.00e-04 | grad 2.20 | tok/s 14913
step    610 | loss 1.6071 | lr 3.00e-04 | grad 2.41 | tok/s 16620
step    620 | loss 1.5317 | lr 3.00e-04 | grad 2.30 | tok/s 15748
step    630 | loss 1.6374 | lr 3.00e-04 | grad 4.31 | tok/s 15894
step    640 | loss 1.7852 | lr 3.00e-04 | grad 2.42 | tok/s 16318
step    650 | loss 1.6681 | lr 3.00e-04 | grad 2.62 | tok/s 16409
step    660 | loss 1.6782 | lr 3.00e-04 | grad 2.22 | tok/s 16461
step    670 | loss 1.8885 | lr 3.00e-04 | grad 3.27 | tok/s 16600
step    680 | loss 1.7158 | lr 3.00e-04 | grad 2.38 | tok/s 16237
step    690 | loss 1.8105 | lr 3.00e-04 | grad 3.12 | tok/s 16791
step    700 | loss 1.4065 | lr 3.00e-04 | grad 2.95 | tok/s 17138
step    710 | loss 1.5724 | lr 3.00e-04 | grad 2.36 | tok/s 15986
step    720 | loss 1.4672 | lr 3.00e-04 | grad 3.27 | tok/s 15783
step    730 | loss 1.2772 | lr 3.00e-04 | grad 2.83 | tok/s 17106
step    740 | loss 1.4884 | lr 3.00e-04 | grad 2.33 | tok/s 16849
step    750 | loss 1.1942 | lr 3.00e-04 | grad 2.53 | tok/s 17166
step    760 | loss 1.0997 | lr 3.00e-04 | grad 2.09 | tok/s 17147
step    770 | loss 1.0491 | lr 3.00e-04 | grad 2.09 | tok/s 17129
step    780 | loss 0.9921 | lr 3.00e-04 | grad 2.05 | tok/s 17161
step    790 | loss 1.1250 | lr 3.00e-04 | grad 3.17 | tok/s 16606
step    800 | loss 1.8057 | lr 3.00e-04 | grad 5.34 | tok/s 16552
step    810 | loss 1.6973 | lr 3.00e-04 | grad 2.20 | tok/s 16458
step    820 | loss 1.6958 | lr 3.00e-04 | grad 4.06 | tok/s 15827
step    830 | loss 1.4698 | lr 3.00e-04 | grad 2.16 | tok/s 16989
step    840 | loss 1.3443 | lr 3.00e-04 | grad 2.12 | tok/s 17141
step    850 | loss 1.5928 | lr 3.00e-04 | grad 2.20 | tok/s 17090
step    860 | loss 1.4562 | lr 3.00e-04 | grad 3.58 | tok/s 16889
step    870 | loss 1.4810 | lr 3.00e-04 | grad 2.55 | tok/s 16323
step    880 | loss 1.6648 | lr 3.00e-04 | grad 2.33 | tok/s 16356
step    890 | loss 1.6780 | lr 3.00e-04 | grad 2.98 | tok/s 16602
step    900 | loss 1.5534 | lr 3.00e-04 | grad 2.47 | tok/s 16588
step    910 | loss 1.4165 | lr 3.00e-04 | grad 3.83 | tok/s 16259
step    920 | loss 1.5132 | lr 3.00e-04 | grad 3.42 | tok/s 16898
step    930 | loss 1.5872 | lr 3.00e-04 | grad 3.36 | tok/s 16128
step    940 | loss 1.3717 | lr 3.00e-04 | grad 1.89 | tok/s 17003
step    950 | loss 1.4698 | lr 3.00e-04 | grad 2.84 | tok/s 17083
step    960 | loss 1.3185 | lr 3.00e-04 | grad 2.58 | tok/s 16163
step    970 | loss 1.7404 | lr 3.00e-04 | grad 3.41 | tok/s 16095
step    980 | loss 1.6314 | lr 3.00e-04 | grad 2.41 | tok/s 16527
step    990 | loss 1.4402 | lr 3.00e-04 | grad 2.08 | tok/s 16822
step   1000 | loss 1.8298 | lr 3.00e-04 | grad 8.56 | tok/s 16134
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8298.pt
step   1010 | loss 1.6952 | lr 3.00e-04 | grad 3.61 | tok/s 5206
step   1020 | loss 1.6488 | lr 3.00e-04 | grad 2.34 | tok/s 15861
step   1030 | loss 1.3870 | lr 3.00e-04 | grad 2.16 | tok/s 16740
step   1040 | loss 1.4969 | lr 3.00e-04 | grad 2.19 | tok/s 16629
step   1050 | loss 1.6243 | lr 3.00e-04 | grad 2.73 | tok/s 16159
step   1060 | loss 1.6753 | lr 3.00e-04 | grad 2.30 | tok/s 16895
step   1070 | loss 1.6557 | lr 3.00e-04 | grad 2.42 | tok/s 16569
step   1080 | loss 1.3916 | lr 3.00e-04 | grad 2.47 | tok/s 15559
step   1090 | loss 1.0184 | lr 3.00e-04 | grad 5.38 | tok/s 17264
step   1100 | loss 1.5450 | lr 3.00e-04 | grad 2.61 | tok/s 16542
step   1110 | loss 1.3945 | lr 3.00e-04 | grad 2.05 | tok/s 17321
step   1120 | loss 1.3280 | lr 3.00e-04 | grad 2.48 | tok/s 17325
step   1130 | loss 1.2686 | lr 3.00e-04 | grad 2.25 | tok/s 17333
step   1140 | loss 1.2757 | lr 3.00e-04 | grad 2.03 | tok/s 17328
step   1150 | loss 1.2680 | lr 3.00e-04 | grad 1.98 | tok/s 17273
step   1160 | loss 1.2001 | lr 3.00e-04 | grad 2.09 | tok/s 17273
step   1170 | loss 1.2704 | lr 3.00e-04 | grad 2.16 | tok/s 17339
step   1180 | loss 1.2829 | lr 3.00e-04 | grad 2.53 | tok/s 17274
step   1190 | loss 1.1984 | lr 3.00e-04 | grad 1.86 | tok/s 17252
step   1200 | loss 1.2198 | lr 3.00e-04 | grad 1.77 | tok/s 17285
step   1210 | loss 1.2483 | lr 3.00e-04 | grad 1.93 | tok/s 17240
step   1220 | loss 1.2650 | lr 3.00e-04 | grad 2.06 | tok/s 17225
step   1230 | loss 1.2431 | lr 3.00e-04 | grad 1.77 | tok/s 17277
step   1240 | loss 1.3409 | lr 3.00e-04 | grad 5.38 | tok/s 16842
step   1250 | loss 1.7167 | lr 3.00e-04 | grad 2.11 | tok/s 16398
step   1260 | loss 1.3460 | lr 3.00e-04 | grad 2.41 | tok/s 16175
step   1270 | loss 1.7277 | lr 3.00e-04 | grad 2.36 | tok/s 16011
step   1280 | loss 1.5783 | lr 3.00e-04 | grad 2.16 | tok/s 16907
step   1290 | loss 1.5141 | lr 3.00e-04 | grad 2.64 | tok/s 16645
step   1300 | loss 1.4928 | lr 3.00e-04 | grad 3.44 | tok/s 16306
step   1310 | loss 1.4435 | lr 3.00e-04 | grad 3.70 | tok/s 17118
step   1320 | loss 1.6152 | lr 3.00e-04 | grad 3.64 | tok/s 16963
step   1330 | loss 1.4021 | lr 3.00e-04 | grad 2.25 | tok/s 16969
step   1340 | loss 1.6315 | lr 3.00e-04 | grad 2.08 | tok/s 15748
step   1350 | loss 1.7560 | lr 3.00e-04 | grad 3.14 | tok/s 15994
step   1360 | loss 1.4319 | lr 3.00e-04 | grad 1.85 | tok/s 16702
step   1370 | loss 1.5559 | lr 3.00e-04 | grad 4.06 | tok/s 16445
step   1380 | loss 1.5652 | lr 3.00e-04 | grad 2.81 | tok/s 15762
step   1390 | loss 1.4336 | lr 3.00e-04 | grad 2.02 | tok/s 16358
step   1400 | loss 1.3704 | lr 3.00e-04 | grad 2.09 | tok/s 16524
step   1410 | loss 1.5489 | lr 3.00e-04 | grad 4.12 | tok/s 16169
step   1420 | loss 1.6117 | lr 3.00e-04 | grad 2.50 | tok/s 16153
step   1430 | loss 1.3197 | lr 3.00e-04 | grad 2.33 | tok/s 16393
step   1440 | loss 1.1268 | lr 3.00e-04 | grad 2.08 | tok/s 17232
step   1450 | loss 1.2768 | lr 3.00e-04 | grad 6.22 | tok/s 16994
step   1460 | loss 1.6746 | lr 3.00e-04 | grad 5.59 | tok/s 16055
step   1470 | loss 1.4181 | lr 3.00e-04 | grad 1.90 | tok/s 17041
step   1480 | loss 1.8362 | lr 3.00e-04 | grad 3.59 | tok/s 16852
step   1490 | loss 1.5561 | lr 3.00e-04 | grad 6.66 | tok/s 17118
step   1500 | loss 1.2666 | lr 3.00e-04 | grad 1.95 | tok/s 17185
step   1510 | loss 1.5553 | lr 3.00e-04 | grad 2.14 | tok/s 16961
step   1520 | loss 1.4479 | lr 3.00e-04 | grad 2.52 | tok/s 16629
step   1530 | loss 1.4106 | lr 3.00e-04 | grad 2.09 | tok/s 15746
step   1540 | loss 1.6331 | lr 3.00e-04 | grad 2.27 | tok/s 16363
step   1550 | loss 1.2402 | lr 3.00e-04 | grad 2.38 | tok/s 17094
step   1560 | loss 1.5924 | lr 3.00e-04 | grad 2.39 | tok/s 16201
step   1570 | loss 1.3257 | lr 3.00e-04 | grad 3.19 | tok/s 17034
step   1580 | loss 1.6621 | lr 3.00e-04 | grad 3.64 | tok/s 16981
step   1590 | loss 1.5427 | lr 3.00e-04 | grad 1.88 | tok/s 16143
step   1600 | loss 0.8463 | lr 3.00e-04 | grad 1.64 | tok/s 17306
step   1610 | loss 1.1863 | lr 3.00e-04 | grad 1.94 | tok/s 15925
step   1620 | loss 1.3466 | lr 3.00e-04 | grad 2.66 | tok/s 16316
step   1630 | loss 1.3668 | lr 3.00e-04 | grad 2.34 | tok/s 16765
step   1640 | loss 1.4438 | lr 3.00e-04 | grad 4.31 | tok/s 16200
step   1650 | loss 1.5543 | lr 3.00e-04 | grad 3.62 | tok/s 15314
step   1660 | loss 1.2218 | lr 3.00e-04 | grad 1.66 | tok/s 17201
step   1670 | loss 1.6085 | lr 3.00e-04 | grad 7.50 | tok/s 16336
step   1680 | loss 1.5422 | lr 3.00e-04 | grad 2.56 | tok/s 16017
step   1690 | loss 1.4408 | lr 3.00e-04 | grad 4.00 | tok/s 16587
step   1700 | loss 1.5245 | lr 3.00e-04 | grad 2.14 | tok/s 16143
step   1710 | loss 1.4393 | lr 3.00e-04 | grad 2.27 | tok/s 16669
step   1720 | loss 1.5014 | lr 3.00e-04 | grad 2.94 | tok/s 17197
step   1730 | loss 1.1888 | lr 3.00e-04 | grad 3.41 | tok/s 17186
step   1740 | loss 1.3946 | lr 3.00e-04 | grad 2.52 | tok/s 16462
step   1750 | loss 1.5148 | lr 3.00e-04 | grad 2.41 | tok/s 16769
step   1760 | loss 1.5862 | lr 3.00e-04 | grad 2.64 | tok/s 16548
step   1770 | loss 1.4244 | lr 3.00e-04 | grad 1.88 | tok/s 16286
step   1780 | loss 1.4893 | lr 3.00e-04 | grad 2.72 | tok/s 16638
step   1790 | loss 1.4162 | lr 3.00e-04 | grad 2.03 | tok/s 16511
step   1800 | loss 1.5550 | lr 3.00e-04 | grad 2.44 | tok/s 16150
step   1810 | loss 1.4571 | lr 3.00e-04 | grad 3.02 | tok/s 16366
step   1820 | loss 1.4816 | lr 3.00e-04 | grad 5.22 | tok/s 16490
step   1830 | loss 1.4417 | lr 3.00e-04 | grad 2.39 | tok/s 16779
step   1840 | loss 1.4260 | lr 3.00e-04 | grad 1.70 | tok/s 16025
step   1850 | loss 1.2723 | lr 3.00e-04 | grad 1.85 | tok/s 17129
step   1860 | loss 1.3571 | lr 3.00e-04 | grad 2.22 | tok/s 16021
step   1870 | loss 1.3309 | lr 3.00e-04 | grad 1.43 | tok/s 16900
step   1880 | loss 1.2969 | lr 3.00e-04 | grad 2.31 | tok/s 15300
step   1890 | loss 1.5383 | lr 3.00e-04 | grad 1.93 | tok/s 15449
step   1900 | loss 1.3592 | lr 3.00e-04 | grad 1.92 | tok/s 16334
step   1910 | loss 1.4833 | lr 3.00e-04 | grad 1.84 | tok/s 15939
step   1920 | loss 1.3544 | lr 3.00e-04 | grad 1.91 | tok/s 17041
step   1930 | loss 1.4717 | lr 3.00e-04 | grad 2.08 | tok/s 16009
step   1940 | loss 1.4651 | lr 3.00e-04 | grad 3.08 | tok/s 16904
step   1950 | loss 1.7857 | lr 3.00e-04 | grad 3.19 | tok/s 17215
step   1960 | loss 1.4373 | lr 3.00e-04 | grad 3.80 | tok/s 17205
step   1970 | loss 1.5298 | lr 3.00e-04 | grad 5.62 | tok/s 16665
step   1980 | loss 1.4862 | lr 3.00e-04 | grad 1.86 | tok/s 16207
step   1990 | loss 1.6272 | lr 3.00e-04 | grad 2.03 | tok/s 16357
step   2000 | loss 1.4985 | lr 3.00e-04 | grad 2.28 | tok/s 16592
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4985.pt
step   2010 | loss 1.1948 | lr 3.00e-04 | grad 2.47 | tok/s 5699
step   2020 | loss 1.3168 | lr 3.00e-04 | grad 2.73 | tok/s 16980
step   2030 | loss 0.9840 | lr 3.00e-04 | grad 4.22 | tok/s 17454
step   2040 | loss 1.2316 | lr 3.00e-04 | grad 1.67 | tok/s 17356
step   2050 | loss 1.2946 | lr 3.00e-04 | grad 2.91 | tok/s 16648
step   2060 | loss 1.6462 | lr 3.00e-04 | grad 2.38 | tok/s 16347
step   2070 | loss 1.8959 | lr 3.00e-04 | grad 7.28 | tok/s 16418
step   2080 | loss 2.1451 | lr 3.00e-04 | grad 3.83 | tok/s 17338
step   2090 | loss 1.5844 | lr 3.00e-04 | grad 2.30 | tok/s 16989
step   2100 | loss 1.3522 | lr 3.00e-04 | grad 3.05 | tok/s 17034
step   2110 | loss 1.4537 | lr 3.00e-04 | grad 2.27 | tok/s 16143
step   2120 | loss 0.8073 | lr 3.00e-04 | grad 1.85 | tok/s 17402
step   2130 | loss 1.3266 | lr 3.00e-04 | grad 2.45 | tok/s 16533
step   2140 | loss 1.4397 | lr 3.00e-04 | grad 1.91 | tok/s 16973
step   2150 | loss 1.2785 | lr 3.00e-04 | grad 2.23 | tok/s 17339
step   2160 | loss 1.1810 | lr 3.00e-04 | grad 1.95 | tok/s 17336
step   2170 | loss 1.2155 | lr 3.00e-04 | grad 1.89 | tok/s 17324
step   2180 | loss 1.1826 | lr 3.00e-04 | grad 1.80 | tok/s 17272
step   2190 | loss 1.2202 | lr 3.00e-04 | grad 2.00 | tok/s 17308
step   2200 | loss 1.1529 | lr 3.00e-04 | grad 1.88 | tok/s 17330
step   2210 | loss 1.1472 | lr 3.00e-04 | grad 1.94 | tok/s 17328
step   2220 | loss 1.1130 | lr 3.00e-04 | grad 1.87 | tok/s 17339
step   2230 | loss 1.4151 | lr 3.00e-04 | grad 2.27 | tok/s 17002
step   2240 | loss 1.3463 | lr 3.00e-04 | grad 4.56 | tok/s 16697
step   2250 | loss 1.5543 | lr 3.00e-04 | grad 5.31 | tok/s 17259
step   2260 | loss 1.5709 | lr 3.00e-04 | grad 2.31 | tok/s 16701
step   2270 | loss 1.9747 | lr 3.00e-04 | grad 3.23 | tok/s 17116
step   2280 | loss 1.3788 | lr 3.00e-04 | grad 2.14 | tok/s 17294
step   2290 | loss 1.4918 | lr 3.00e-04 | grad 2.50 | tok/s 16456
step   2300 | loss 1.4117 | lr 3.00e-04 | grad 2.53 | tok/s 16975
step   2310 | loss 1.4096 | lr 3.00e-04 | grad 1.88 | tok/s 16457
step   2320 | loss 1.9631 | lr 3.00e-04 | grad 3.33 | tok/s 16178
step   2330 | loss 1.4869 | lr 3.00e-04 | grad 2.48 | tok/s 16132
step   2340 | loss 1.4508 | lr 3.00e-04 | grad 2.83 | tok/s 16311
step   2350 | loss 1.3620 | lr 3.00e-04 | grad 2.67 | tok/s 16033
step   2360 | loss 1.2311 | lr 3.00e-04 | grad 3.20 | tok/s 17124
step   2370 | loss 1.5646 | lr 3.00e-04 | grad 3.00 | tok/s 17029
step   2380 | loss 1.3917 | lr 3.00e-04 | grad 3.30 | tok/s 17277
step   2390 | loss 1.1277 | lr 3.00e-04 | grad 4.41 | tok/s 17208
step   2400 | loss 0.9903 | lr 3.00e-04 | grad 1.83 | tok/s 17224
step   2410 | loss 1.2530 | lr 3.00e-04 | grad 2.41 | tok/s 16556
step   2420 | loss 1.4929 | lr 3.00e-04 | grad 2.70 | tok/s 15821

Training complete! Final step: 2429
