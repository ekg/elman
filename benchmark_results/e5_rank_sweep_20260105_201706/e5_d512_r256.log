
Benchmarking E5 backends on byte-level Pile
Config: dim=512, depth=63, rank=256
Training: batch=32, seq=512, steps=1000
