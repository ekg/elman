
Benchmarking E5 backends on byte-level Pile
Config: dim=1024, depth=42, rank=192
Training: batch=32, seq=512, steps=1000
