Using device: cuda
Output directory: benchmark_results/100m_30min/cudagru/levelcudagru_100m_20260114_175410
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level cudagru, 82,735,872 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 30.0 minutes
step     10 | loss 6.4110 | lr 2.70e-06 | grad 73.00 | tok/s 5661
step     20 | loss 4.3150 | lr 5.70e-06 | grad 22.75 | tok/s 5813
step     30 | loss 5.0504 | lr 8.70e-06 | grad 10.88 | tok/s 6163
step     40 | loss 4.4895 | lr 1.17e-05 | grad 5.44 | tok/s 6149
step     50 | loss 4.1308 | lr 1.47e-05 | grad 4.00 | tok/s 6155
step     60 | loss 4.0831 | lr 1.77e-05 | grad 6.41 | tok/s 6013
step     70 | loss 3.8256 | lr 2.07e-05 | grad 4.31 | tok/s 5807
step     80 | loss 4.0612 | lr 2.37e-05 | grad 11.12 | tok/s 6068
step     90 | loss 3.9613 | lr 2.67e-05 | grad 4.56 | tok/s 5835
step    100 | loss 3.8133 | lr 2.97e-05 | grad 3.12 | tok/s 5890
step    110 | loss 3.6805 | lr 3.27e-05 | grad 3.16 | tok/s 5819
step    120 | loss 3.6250 | lr 3.57e-05 | grad 2.73 | tok/s 5767
step    130 | loss 3.6167 | lr 3.87e-05 | grad 3.52 | tok/s 5904
step    140 | loss 3.4217 | lr 4.17e-05 | grad 3.58 | tok/s 7388
step    150 | loss 3.2077 | lr 4.47e-05 | grad 5.28 | tok/s 7738
step    160 | loss 3.1248 | lr 4.77e-05 | grad 5.56 | tok/s 8331
step    170 | loss 3.2665 | lr 5.07e-05 | grad 6.91 | tok/s 8759
step    180 | loss 3.3039 | lr 5.37e-05 | grad 7.34 | tok/s 8773
step    190 | loss 3.1577 | lr 5.67e-05 | grad 9.19 | tok/s 8920
step    200 | loss 3.0965 | lr 5.97e-05 | grad 8.06 | tok/s 9131
step    210 | loss 3.1510 | lr 6.27e-05 | grad 20.50 | tok/s 8708
step    220 | loss 3.2568 | lr 6.57e-05 | grad 4.69 | tok/s 9021
step    230 | loss 3.0501 | lr 6.87e-05 | grad 8.38 | tok/s 8709
step    240 | loss 3.1671 | lr 7.17e-05 | grad 12.94 | tok/s 8884
step    250 | loss 3.0832 | lr 7.47e-05 | grad 10.31 | tok/s 8778
step    260 | loss 3.1372 | lr 7.77e-05 | grad 7.72 | tok/s 8398
step    270 | loss 3.1454 | lr 8.07e-05 | grad 10.19 | tok/s 8718
step    280 | loss 3.2028 | lr 8.37e-05 | grad 13.94 | tok/s 8650
step    290 | loss 3.1782 | lr 8.67e-05 | grad 1.88 | tok/s 9184
step    300 | loss 3.1385 | lr 8.97e-05 | grad 1.59 | tok/s 9200
step    310 | loss 3.1047 | lr 9.27e-05 | grad 3.98 | tok/s 9196
step    320 | loss 3.1647 | lr 9.57e-05 | grad 16.25 | tok/s 8854
step    330 | loss 3.4641 | lr 9.87e-05 | grad 4.81 | tok/s 8655
step    340 | loss 3.3822 | lr 1.02e-04 | grad 2.34 | tok/s 8819
step    350 | loss 3.4557 | lr 1.05e-04 | grad 2.59 | tok/s 8575
step    360 | loss 3.3992 | lr 1.08e-04 | grad 2.75 | tok/s 8678
step    370 | loss 3.3457 | lr 1.11e-04 | grad 2828260565988671488.00 | tok/s 8852
step    380 | loss 3.7169 | lr 1.14e-04 | grad 3.05 | tok/s 9086
step    390 | loss 3.3726 | lr 1.17e-04 | grad 1.88 | tok/s 8342
step    400 | loss 3.4348 | lr 1.20e-04 | grad 2.94 | tok/s 8740
step    410 | loss 3.3478 | lr 1.23e-04 | grad 1.15 | tok/s 8610
step    420 | loss 3.3407 | lr 1.26e-04 | grad 2.80 | tok/s 8487
step    430 | loss 3.4605 | lr 1.29e-04 | grad 0.91 | tok/s 8483
step    440 | loss 3.5948 | lr 1.32e-04 | grad 1.32 | tok/s 8535
step    450 | loss 3.3730 | lr 1.35e-04 | grad 1.34 | tok/s 8281
step    460 | loss 3.3349 | lr 1.38e-04 | grad 0.87 | tok/s 7881
step    470 | loss 3.3755 | lr 1.41e-04 | grad 1.25 | tok/s 8047
step    480 | loss 3.3386 | lr 1.44e-04 | grad 2.72 | tok/s 8029
step    490 | loss 3.2513 | lr 1.47e-04 | grad 0.56 | tok/s 8326
step    500 | loss 3.9494 | lr 1.50e-04 | grad 1.70 | tok/s 7731
step    510 | loss 3.3191 | lr 1.53e-04 | grad 2.22 | tok/s 7456
step    520 | loss 3.3607 | lr 1.56e-04 | grad 1.69 | tok/s 8853
step    530 | loss 3.7721 | lr 1.59e-04 | grad 2.19 | tok/s 8711
step    540 | loss 3.3640 | lr 1.62e-04 | grad 3.05 | tok/s 8695
step    550 | loss 3.1861 | lr 1.65e-04 | grad 1.19 | tok/s 8946
step    560 | loss 3.0755 | lr 1.68e-04 | grad 0.40 | tok/s 9065
step    570 | loss 3.4764 | lr 1.71e-04 | grad 1.72 | tok/s 8783
step    580 | loss 3.7112 | lr 1.74e-04 | grad 2.42 | tok/s 8651
step    590 | loss 3.6816 | lr 1.77e-04 | grad 1.19 | tok/s 8592
step    600 | loss 3.3890 | lr 1.80e-04 | grad 0.95 | tok/s 8645
step    610 | loss 3.5069 | lr 1.83e-04 | grad 3.55 | tok/s 9007
step    620 | loss 3.3927 | lr 1.86e-04 | grad 1.57 | tok/s 8519
step    630 | loss 3.4199 | lr 1.89e-04 | grad 0.86 | tok/s 8874
step    640 | loss 3.7143 | lr 1.92e-04 | grad 1.32 | tok/s 8879
step    650 | loss 3.3492 | lr 1.95e-04 | grad 0.52 | tok/s 8671
step    660 | loss 3.5736 | lr 1.98e-04 | grad 2.27 | tok/s 8446
step    670 | loss 3.4142 | lr 2.01e-04 | grad 1.24 | tok/s 8830
step    680 | loss 3.5054 | lr 2.04e-04 | grad 1.62 | tok/s 8503
step    690 | loss 3.4384 | lr 2.07e-04 | grad 1.62 | tok/s 8625
step    700 | loss 3.5486 | lr 2.10e-04 | grad 1.66 | tok/s 8729
step    710 | loss 3.5485 | lr 2.13e-04 | grad 1.45 | tok/s 8811
step    720 | loss 3.4365 | lr 2.16e-04 | grad 1.05 | tok/s 8691
step    730 | loss 3.4625 | lr 2.19e-04 | grad 0.93 | tok/s 8688
step    740 | loss 3.4718 | lr 2.22e-04 | grad 3.20 | tok/s 8545
step    750 | loss 3.3803 | lr 2.25e-04 | grad 2.03 | tok/s 8536
step    760 | loss 3.5783 | lr 2.28e-04 | grad 1.23 | tok/s 8672
step    770 | loss 3.3174 | lr 2.31e-04 | grad 1.69 | tok/s 8217
step    780 | loss 3.3511 | lr 2.34e-04 | grad 1.63 | tok/s 8336
step    790 | loss 3.4479 | lr 2.37e-04 | grad 1.38 | tok/s 8756
step    800 | loss 3.4314 | lr 2.40e-04 | grad 1.58 | tok/s 8721
step    810 | loss 3.3706 | lr 2.43e-04 | grad 1.76 | tok/s 8490
step    820 | loss 3.6231 | lr 2.46e-04 | grad 1.51 | tok/s 8795
step    830 | loss 3.4479 | lr 2.49e-04 | grad 0.99 | tok/s 8964
step    840 | loss 3.3072 | lr 2.52e-04 | grad 0.52 | tok/s 9039
step    850 | loss 3.5521 | lr 2.55e-04 | grad 1.63 | tok/s 8438
step    860 | loss 3.4877 | lr 2.58e-04 | grad 1.19 | tok/s 7988
step    870 | loss 3.3897 | lr 2.61e-04 | grad 1.29 | tok/s 8404
step    880 | loss 3.4100 | lr 2.64e-04 | grad 1.28 | tok/s 6977
step    890 | loss 3.3044 | lr 2.67e-04 | grad 0.93 | tok/s 8424
step    900 | loss 3.6462 | lr 2.70e-04 | grad 0.91 | tok/s 8281
step    910 | loss 3.4534 | lr 2.73e-04 | grad 1.52 | tok/s 9518
step    920 | loss 3.2025 | lr 2.76e-04 | grad 0.43 | tok/s 8612

Training complete! Final step: 922
