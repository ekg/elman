Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_200M_30gen_20260128_165343/eval_12/levelMoME88_100m_20260128_165904
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 201,251,692 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 5.0 minutes
step     10 | loss 9.4360 | lr 3.00e-04 | grad 9.50 | tok/s 15533
step     20 | loss 6.1366 | lr 3.00e-04 | grad 11.00 | tok/s 32683
step     30 | loss 4.4741 | lr 3.00e-04 | grad 17.75 | tok/s 32917
step     40 | loss 3.6050 | lr 3.00e-04 | grad 4.09 | tok/s 32916
step     50 | loss 3.0012 | lr 3.00e-04 | grad 1.89 | tok/s 32799
step     60 | loss 3.1393 | lr 3.00e-04 | grad 2.16 | tok/s 31724
step     70 | loss 3.1915 | lr 3.00e-04 | grad 6.53 | tok/s 32150
step     80 | loss 2.8794 | lr 3.00e-04 | grad 2.91 | tok/s 31639
step     90 | loss 2.8404 | lr 3.00e-04 | grad 2.70 | tok/s 31295
step    100 | loss 2.3605 | lr 3.00e-04 | grad 2.00 | tok/s 31938
step    110 | loss 2.7471 | lr 3.00e-04 | grad 4.41 | tok/s 31296
step    120 | loss 2.6131 | lr 3.00e-04 | grad 1.34 | tok/s 31397
step    130 | loss 2.4382 | lr 3.00e-04 | grad 2.08 | tok/s 32061
step    140 | loss 2.2001 | lr 3.00e-04 | grad 1.45 | tok/s 30466
step    150 | loss 2.2830 | lr 3.00e-04 | grad 1.70 | tok/s 30832
step    160 | loss 2.2794 | lr 3.00e-04 | grad 1.34 | tok/s 31009
step    170 | loss 2.4639 | lr 3.00e-04 | grad 2.34 | tok/s 31618
step    180 | loss 2.1749 | lr 3.00e-04 | grad 1.55 | tok/s 31368
step    190 | loss 1.9933 | lr 3.00e-04 | grad 2.94 | tok/s 32686
step    200 | loss 2.1711 | lr 3.00e-04 | grad 1.49 | tok/s 31450
step    210 | loss 2.3239 | lr 3.00e-04 | grad 2.27 | tok/s 32327
step    220 | loss 2.1632 | lr 3.00e-04 | grad 1.83 | tok/s 31470
step    230 | loss 2.0934 | lr 3.00e-04 | grad 1.63 | tok/s 31489
step    240 | loss 2.1995 | lr 3.00e-04 | grad 1.90 | tok/s 32063
step    250 | loss 2.1914 | lr 3.00e-04 | grad 1.49 | tok/s 31105
step    260 | loss 2.0113 | lr 3.00e-04 | grad 2.19 | tok/s 30967
step    270 | loss 1.9955 | lr 3.00e-04 | grad 1.91 | tok/s 31182
step    280 | loss 1.9408 | lr 3.00e-04 | grad 1.47 | tok/s 32594
step    290 | loss 1.7886 | lr 3.00e-04 | grad 1.34 | tok/s 32676
step    300 | loss 1.8082 | lr 3.00e-04 | grad 1.70 | tok/s 32682
step    310 | loss 1.8808 | lr 3.00e-04 | grad 1.70 | tok/s 32031
step    320 | loss 2.0326 | lr 3.00e-04 | grad 2.30 | tok/s 31227
step    330 | loss 2.0289 | lr 3.00e-04 | grad 3.19 | tok/s 31913
step    340 | loss 2.0874 | lr 3.00e-04 | grad 3.75 | tok/s 30822
step    350 | loss 1.9908 | lr 3.00e-04 | grad 4.47 | tok/s 30805
step    360 | loss 1.9124 | lr 3.00e-04 | grad 3.70 | tok/s 31792
step    370 | loss 2.3543 | lr 3.00e-04 | grad 2.59 | tok/s 31962
step    380 | loss 1.9264 | lr 3.00e-04 | grad 3.84 | tok/s 32064
step    390 | loss 1.9538 | lr 3.00e-04 | grad 1.96 | tok/s 31803
step    400 | loss 1.9492 | lr 3.00e-04 | grad 1.23 | tok/s 31545
step    410 | loss 1.9767 | lr 3.00e-04 | grad 2.03 | tok/s 30746
step    420 | loss 2.0294 | lr 3.00e-04 | grad 6.25 | tok/s 31483
step    430 | loss 2.1876 | lr 3.00e-04 | grad 2.80 | tok/s 31979
step    440 | loss 1.9304 | lr 3.00e-04 | grad 1.45 | tok/s 31397
step    450 | loss 1.9251 | lr 3.00e-04 | grad 3.00 | tok/s 31185
step    460 | loss 1.9075 | lr 3.00e-04 | grad 1.33 | tok/s 31671
step    470 | loss 1.8366 | lr 3.00e-04 | grad 1.25 | tok/s 30651
step    480 | loss 1.7872 | lr 3.00e-04 | grad 1.37 | tok/s 31095
step    490 | loss 2.5436 | lr 3.00e-04 | grad 1.94 | tok/s 32264
step    500 | loss 1.7926 | lr 3.00e-04 | grad 2.00 | tok/s 31630
step    510 | loss 1.7951 | lr 3.00e-04 | grad 1.51 | tok/s 32213
step    520 | loss 2.3247 | lr 3.00e-04 | grad 2.22 | tok/s 31705
step    530 | loss 1.7548 | lr 3.00e-04 | grad 1.85 | tok/s 31911
step    540 | loss 1.7016 | lr 3.00e-04 | grad 1.33 | tok/s 32379
step    550 | loss 1.5612 | lr 3.00e-04 | grad 1.48 | tok/s 32769
step    560 | loss 1.8367 | lr 3.00e-04 | grad 3.70 | tok/s 32309
step    570 | loss 2.1167 | lr 3.00e-04 | grad 1.56 | tok/s 32131
step    580 | loss 2.3243 | lr 3.00e-04 | grad 1.91 | tok/s 31276

Training complete! Final step: 589
