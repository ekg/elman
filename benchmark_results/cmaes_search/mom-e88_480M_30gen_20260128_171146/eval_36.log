Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_480M_30gen_20260128_171146/eval_36/levelMoME88_100m_20260128_173309
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 514,416,690 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 5.0 minutes
step     10 | loss 7.7412 | lr 3.00e-04 | grad 5.19 | tok/s 4452
step     20 | loss 3.0716 | lr 3.00e-04 | grad 1.42 | tok/s 8121
step     30 | loss 2.7574 | lr 3.00e-04 | grad 0.93 | tok/s 8213
step     40 | loss 2.6994 | lr 3.00e-04 | grad 1.14 | tok/s 7859
step     50 | loss 3.6343 | lr 3.00e-04 | grad 13.69 | tok/s 7974
step     60 | loss 2.4652 | lr 3.00e-04 | grad 6.56 | tok/s 8220
step     70 | loss 2.3345 | lr 3.00e-04 | grad 1.70 | tok/s 8321
step     80 | loss 7.5875 | lr 3.00e-04 | grad 14.62 | tok/s 8366
step     90 | loss 5.9756 | lr 3.00e-04 | grad 1.94 | tok/s 8504
step    100 | loss 4.3495 | lr 3.00e-04 | grad 2.25 | tok/s 8504
step    110 | loss 4.1761 | lr 3.00e-04 | grad 6.38 | tok/s 8508
step    120 | loss 3.9226 | lr 3.00e-04 | grad 6.28 | tok/s 8504
step    130 | loss 3.8123 | lr 3.00e-04 | grad 3.59 | tok/s 8507
step    140 | loss 3.2305 | lr 3.00e-04 | grad 3.56 | tok/s 8484
step    150 | loss 3.6304 | lr 3.00e-04 | grad 4.62 | tok/s 8496
step    160 | loss 2.9995 | lr 3.00e-04 | grad 3.61 | tok/s 8505
step    170 | loss 3.0230 | lr 3.00e-04 | grad 3.38 | tok/s 8470
step    180 | loss 2.8394 | lr 3.00e-04 | grad 2.38 | tok/s 8471
step    190 | loss 2.9420 | lr 3.00e-04 | grad 3.98 | tok/s 8487
step    200 | loss 2.5724 | lr 3.00e-04 | grad 1.88 | tok/s 8504
step    210 | loss 2.5696 | lr 3.00e-04 | grad 2.80 | tok/s 8503
step    220 | loss 2.6141 | lr 3.00e-04 | grad 1.76 | tok/s 8401
step    230 | loss 3.1310 | lr 3.00e-04 | grad 2.03 | tok/s 8299
step    240 | loss 2.5114 | lr 3.00e-04 | grad 2.28 | tok/s 7884
step    250 | loss 2.3644 | lr 3.00e-04 | grad 1.15 | tok/s 8105
step    260 | loss 2.0907 | lr 3.00e-04 | grad 1.17 | tok/s 8356
step    270 | loss 2.3932 | lr 3.00e-04 | grad 1.12 | tok/s 8240
step    280 | loss 2.5911 | lr 3.00e-04 | grad 5.09 | tok/s 8089
step    290 | loss 2.8218 | lr 3.00e-04 | grad 2.25 | tok/s 8516
step    300 | loss 1.9102 | lr 3.00e-04 | grad 2.23 | tok/s 8519
step    310 | loss 2.8331 | lr 3.00e-04 | grad 2.02 | tok/s 8381
step    320 | loss 2.5361 | lr 3.00e-04 | grad 3.11 | tok/s 8206
step    330 | loss 2.2650 | lr 3.00e-04 | grad 1.41 | tok/s 7923
step    340 | loss 2.6020 | lr 3.00e-04 | grad 1.12 | tok/s 8048
step    350 | loss 2.3719 | lr 3.00e-04 | grad 1.82 | tok/s 8243
step    360 | loss 2.6918 | lr 3.00e-04 | grad 3.02 | tok/s 8421
step    370 | loss 2.1751 | lr 3.00e-04 | grad 1.26 | tok/s 7648
step    380 | loss 2.1531 | lr 3.00e-04 | grad 1.18 | tok/s 8147
step    390 | loss 1.9757 | lr 3.00e-04 | grad 0.89 | tok/s 8496
step    400 | loss 1.9441 | lr 3.00e-04 | grad 1.27 | tok/s 8427
step    410 | loss 1.8796 | lr 3.00e-04 | grad 0.87 | tok/s 8245
step    420 | loss 2.1204 | lr 3.00e-04 | grad 2.31 | tok/s 7861
step    430 | loss 2.4842 | lr 3.00e-04 | grad 1.50 | tok/s 8376
step    440 | loss 2.4253 | lr 3.00e-04 | grad 1.78 | tok/s 7919
step    450 | loss 2.4009 | lr 3.00e-04 | grad 1.21 | tok/s 8194
step    460 | loss 2.1381 | lr 3.00e-04 | grad 2.06 | tok/s 8017
step    470 | loss 2.1915 | lr 3.00e-04 | grad 1.34 | tok/s 8269
step    480 | loss 2.7384 | lr 3.00e-04 | grad 3.41 | tok/s 8272
step    490 | loss 2.1516 | lr 3.00e-04 | grad 1.30 | tok/s 7819
step    500 | loss 2.0631 | lr 3.00e-04 | grad 1.48 | tok/s 8349
step    510 | loss 2.0489 | lr 3.00e-04 | grad 1.03 | tok/s 8462
step    520 | loss 2.0544 | lr 3.00e-04 | grad 1.02 | tok/s 8008
step    530 | loss 2.2661 | lr 3.00e-04 | grad 1.30 | tok/s 8123
step    540 | loss 1.9899 | lr 3.00e-04 | grad 1.20 | tok/s 8125
step    550 | loss 1.8267 | lr 3.00e-04 | grad 1.36 | tok/s 7947
step    560 | loss 2.0255 | lr 3.00e-04 | grad 1.16 | tok/s 7743
step    570 | loss 1.9743 | lr 3.00e-04 | grad 1.93 | tok/s 7959
step    580 | loss 1.8466 | lr 3.00e-04 | grad 1.17 | tok/s 7937
step    590 | loss 2.2493 | lr 3.00e-04 | grad 1.65 | tok/s 8126
step    600 | loss 2.0854 | lr 3.00e-04 | grad 1.17 | tok/s 7858
step    610 | loss 1.9199 | lr 3.00e-04 | grad 1.10 | tok/s 8256

Training complete! Final step: 610
