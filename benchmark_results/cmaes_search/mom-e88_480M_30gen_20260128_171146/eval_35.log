Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_480M_30gen_20260128_171146/eval_35/levelMoME88_100m_20260128_173309
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 472,121,076 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 5.0 minutes
step     10 | loss 9.4577 | lr 3.00e-04 | grad 16.88 | tok/s 9126
step     20 | loss 3.2191 | lr 3.00e-04 | grad 2.23 | tok/s 17309
step     30 | loss 3.2708 | lr 3.00e-04 | grad 4.03 | tok/s 18307
step     40 | loss 6.5359 | lr 3.00e-04 | grad 30.62 | tok/s 18616
step     50 | loss 4.7592 | lr 3.00e-04 | grad 13.56 | tok/s 18833
step     60 | loss 3.9490 | lr 3.00e-04 | grad 3.11 | tok/s 18801
step     70 | loss 3.2717 | lr 3.00e-04 | grad 8.19 | tok/s 18773
step     80 | loss 2.9618 | lr 3.00e-04 | grad 9.94 | tok/s 18739
step     90 | loss 2.7014 | lr 3.00e-04 | grad 2.73 | tok/s 18752
step    100 | loss 2.4766 | lr 3.00e-04 | grad 2.12 | tok/s 18691
step    110 | loss 2.4857 | lr 3.00e-04 | grad 1.77 | tok/s 18543
step    120 | loss 3.1844 | lr 3.00e-04 | grad 1.80 | tok/s 17659
step    130 | loss 2.3691 | lr 3.00e-04 | grad 4.66 | tok/s 18059
step    140 | loss 2.6875 | lr 3.00e-04 | grad 5.06 | tok/s 18121
step    150 | loss 2.3835 | lr 3.00e-04 | grad 4.47 | tok/s 18573
step    160 | loss 2.6720 | lr 3.00e-04 | grad 1.88 | tok/s 17909
step    170 | loss 2.4856 | lr 3.00e-04 | grad 1.24 | tok/s 17678
step    180 | loss 2.6351 | lr 3.00e-04 | grad 2.11 | tok/s 18071
step    190 | loss 2.1913 | lr 3.00e-04 | grad 1.91 | tok/s 17751
step    200 | loss 2.0125 | lr 3.00e-04 | grad 1.73 | tok/s 18553
step    210 | loss 2.1741 | lr 3.00e-04 | grad 3.42 | tok/s 17608
step    220 | loss 2.4933 | lr 3.00e-04 | grad 3.62 | tok/s 17801
step    230 | loss 2.2331 | lr 3.00e-04 | grad 2.72 | tok/s 17773
step    240 | loss 2.6078 | lr 3.00e-04 | grad 4.19 | tok/s 18024
step    250 | loss 2.0590 | lr 3.00e-04 | grad 1.38 | tok/s 17869
step    260 | loss 2.1877 | lr 3.00e-04 | grad 2.50 | tok/s 18370
step    270 | loss 2.0836 | lr 3.00e-04 | grad 1.75 | tok/s 17972
step    280 | loss 2.0216 | lr 3.00e-04 | grad 1.33 | tok/s 16896
step    290 | loss 1.9384 | lr 3.00e-04 | grad 3.09 | tok/s 17468
step    300 | loss 2.2286 | lr 3.00e-04 | grad 1.85 | tok/s 17597
step    310 | loss 1.8868 | lr 3.00e-04 | grad 1.33 | tok/s 17523
step    320 | loss 2.1552 | lr 3.00e-04 | grad 3.05 | tok/s 17714
step    330 | loss 1.9470 | lr 3.00e-04 | grad 1.58 | tok/s 17920
step    340 | loss 2.3166 | lr 3.00e-04 | grad 2.66 | tok/s 17846
step    350 | loss 2.2028 | lr 3.00e-04 | grad 1.73 | tok/s 18350
step    360 | loss 1.8359 | lr 3.00e-04 | grad 1.76 | tok/s 17562
step    370 | loss 1.8303 | lr 3.00e-04 | grad 1.59 | tok/s 18491
step    380 | loss 1.6053 | lr 3.00e-04 | grad 1.63 | tok/s 18680
step    390 | loss 1.4975 | lr 3.00e-04 | grad 2.92 | tok/s 18623
step    400 | loss 2.0572 | lr 3.00e-04 | grad 1.75 | tok/s 17663
step    410 | loss 1.9970 | lr 3.00e-04 | grad 1.84 | tok/s 17856
step    420 | loss 2.0152 | lr 3.00e-04 | grad 3.44 | tok/s 18612
step    430 | loss 1.9164 | lr 3.00e-04 | grad 1.40 | tok/s 18290
step    440 | loss 1.9657 | lr 3.00e-04 | grad 1.79 | tok/s 17740
step    450 | loss 1.8542 | lr 3.00e-04 | grad 1.39 | tok/s 17924
step    460 | loss 1.8696 | lr 3.00e-04 | grad 1.76 | tok/s 18201
step    470 | loss 1.8751 | lr 3.00e-04 | grad 2.66 | tok/s 18087
step    480 | loss 1.9053 | lr 3.00e-04 | grad 2.47 | tok/s 18472
step    490 | loss 1.9065 | lr 3.00e-04 | grad 1.95 | tok/s 17738
step    500 | loss 2.0880 | lr 3.00e-04 | grad 1.52 | tok/s 18017
step    510 | loss 1.9193 | lr 3.00e-04 | grad 1.47 | tok/s 17224
step    520 | loss 1.7465 | lr 3.00e-04 | grad 1.64 | tok/s 18015
step    530 | loss 1.9351 | lr 3.00e-04 | grad 1.98 | tok/s 17747
step    540 | loss 1.8611 | lr 3.00e-04 | grad 1.33 | tok/s 17361
step    550 | loss 1.5894 | lr 3.00e-04 | grad 2.38 | tok/s 18152
step    560 | loss 1.6767 | lr 3.00e-04 | grad 1.56 | tok/s 18670
step    570 | loss 1.5641 | lr 3.00e-04 | grad 1.46 | tok/s 18657
step    580 | loss 1.5118 | lr 3.00e-04 | grad 1.45 | tok/s 18682
step    590 | loss 1.5566 | lr 3.00e-04 | grad 1.18 | tok/s 18674
step    600 | loss 1.5026 | lr 3.00e-04 | grad 1.50 | tok/s 18683
step    610 | loss 1.4999 | lr 3.00e-04 | grad 1.13 | tok/s 18666
step    620 | loss 1.4910 | lr 3.00e-04 | grad 1.35 | tok/s 18570
step    630 | loss 1.8929 | lr 3.00e-04 | grad 4.34 | tok/s 17596
step    640 | loss 1.9965 | lr 3.00e-04 | grad 2.55 | tok/s 17809
step    650 | loss 1.7723 | lr 3.00e-04 | grad 1.46 | tok/s 17797
step    660 | loss 1.8148 | lr 3.00e-04 | grad 1.78 | tok/s 18457

Training complete! Final step: 669
