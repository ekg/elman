Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_480M_30gen_20260128_171146/eval_235/levelMoME88_100m_20260128_194547
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 477,842,366 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 5.0 minutes
step     10 | loss 10.6884 | lr 3.00e-04 | grad 8.44 | tok/s 9401
step     20 | loss 3.4054 | lr 3.00e-04 | grad 2.11 | tok/s 18703
step     30 | loss 3.2043 | lr 3.00e-04 | grad 4.09 | tok/s 19777
step     40 | loss 5.7576 | lr 3.00e-04 | grad 24.00 | tok/s 20131
step     50 | loss 4.6744 | lr 3.00e-04 | grad 9.00 | tok/s 20423
step     60 | loss 3.8677 | lr 3.00e-04 | grad 6.31 | tok/s 20279
step     70 | loss 3.3009 | lr 3.00e-04 | grad 9.56 | tok/s 20227
step     80 | loss 2.9983 | lr 3.00e-04 | grad 4.25 | tok/s 20212
step     90 | loss 2.7767 | lr 3.00e-04 | grad 3.98 | tok/s 20173
step    100 | loss 2.5440 | lr 3.00e-04 | grad 4.97 | tok/s 20167
step    110 | loss 2.5403 | lr 3.00e-04 | grad 2.86 | tok/s 20015
step    120 | loss 3.0707 | lr 3.00e-04 | grad 1.80 | tok/s 19054
step    130 | loss 2.3557 | lr 3.00e-04 | grad 4.56 | tok/s 19472
step    140 | loss 2.6482 | lr 3.00e-04 | grad 8.94 | tok/s 19528
step    150 | loss 2.3093 | lr 3.00e-04 | grad 5.97 | tok/s 20012
step    160 | loss 2.6657 | lr 3.00e-04 | grad 2.33 | tok/s 19309
step    170 | loss 2.4987 | lr 3.00e-04 | grad 1.71 | tok/s 19005
step    180 | loss 2.5861 | lr 3.00e-04 | grad 3.11 | tok/s 19461
step    190 | loss 2.1867 | lr 3.00e-04 | grad 2.30 | tok/s 19106
step    200 | loss 2.0138 | lr 3.00e-04 | grad 7.25 | tok/s 19942
step    210 | loss 2.1819 | lr 3.00e-04 | grad 4.81 | tok/s 18948
step    220 | loss 2.5044 | lr 3.00e-04 | grad 8.62 | tok/s 19110
step    230 | loss 2.3063 | lr 3.00e-04 | grad 3.75 | tok/s 19070
step    240 | loss 2.5859 | lr 3.00e-04 | grad 4.78 | tok/s 19330
step    250 | loss 2.0490 | lr 3.00e-04 | grad 1.77 | tok/s 19196
step    260 | loss 2.1815 | lr 3.00e-04 | grad 3.31 | tok/s 19756
step    270 | loss 2.0694 | lr 3.00e-04 | grad 1.88 | tok/s 19298
step    280 | loss 2.0170 | lr 3.00e-04 | grad 1.94 | tok/s 18139
step    290 | loss 1.9436 | lr 3.00e-04 | grad 1.96 | tok/s 18755
step    300 | loss 2.2181 | lr 3.00e-04 | grad 2.28 | tok/s 18881
step    310 | loss 1.8828 | lr 3.00e-04 | grad 1.61 | tok/s 18803
step    320 | loss 2.1418 | lr 3.00e-04 | grad 4.03 | tok/s 19016
step    330 | loss 1.9424 | lr 3.00e-04 | grad 1.80 | tok/s 19242
step    340 | loss 2.3026 | lr 3.00e-04 | grad 2.56 | tok/s 19158
step    350 | loss 2.1790 | lr 3.00e-04 | grad 1.98 | tok/s 19707
step    360 | loss 1.8408 | lr 3.00e-04 | grad 2.06 | tok/s 18867
step    370 | loss 1.8195 | lr 3.00e-04 | grad 2.03 | tok/s 19862
step    380 | loss 1.5784 | lr 3.00e-04 | grad 1.73 | tok/s 20043
step    390 | loss 1.4588 | lr 3.00e-04 | grad 1.73 | tok/s 20045
step    400 | loss 2.0617 | lr 3.00e-04 | grad 2.06 | tok/s 18988
step    410 | loss 2.0106 | lr 3.00e-04 | grad 2.19 | tok/s 19136
step    420 | loss 2.0032 | lr 3.00e-04 | grad 6.53 | tok/s 19966
step    430 | loss 1.9010 | lr 3.00e-04 | grad 1.93 | tok/s 19644
step    440 | loss 1.9743 | lr 3.00e-04 | grad 2.30 | tok/s 19052
step    450 | loss 1.8626 | lr 3.00e-04 | grad 1.61 | tok/s 19242
step    460 | loss 1.8693 | lr 3.00e-04 | grad 2.23 | tok/s 19524
step    470 | loss 1.8504 | lr 3.00e-04 | grad 4.09 | tok/s 19347
step    480 | loss 1.9162 | lr 3.00e-04 | grad 2.61 | tok/s 19803
step    490 | loss 1.9127 | lr 3.00e-04 | grad 2.67 | tok/s 19023
step    500 | loss 2.0841 | lr 3.00e-04 | grad 1.92 | tok/s 19339
step    510 | loss 1.9244 | lr 3.00e-04 | grad 1.68 | tok/s 18450
step    520 | loss 1.7465 | lr 3.00e-04 | grad 2.09 | tok/s 19349
step    530 | loss 1.9318 | lr 3.00e-04 | grad 2.58 | tok/s 19030
step    540 | loss 1.8628 | lr 3.00e-04 | grad 1.67 | tok/s 18630
step    550 | loss 1.5765 | lr 3.00e-04 | grad 3.08 | tok/s 19508
step    560 | loss 1.6696 | lr 3.00e-04 | grad 1.80 | tok/s 19996
step    570 | loss 1.5516 | lr 3.00e-04 | grad 1.77 | tok/s 20012
step    580 | loss 1.5030 | lr 3.00e-04 | grad 1.37 | tok/s 20002
step    590 | loss 1.5371 | lr 3.00e-04 | grad 1.37 | tok/s 20016
step    600 | loss 1.4910 | lr 3.00e-04 | grad 1.70 | tok/s 19999
step    610 | loss 1.4884 | lr 3.00e-04 | grad 1.44 | tok/s 20024
step    620 | loss 1.4828 | lr 3.00e-04 | grad 1.74 | tok/s 19931
step    630 | loss 1.9131 | lr 3.00e-04 | grad 4.97 | tok/s 18855
step    640 | loss 1.9696 | lr 3.00e-04 | grad 2.48 | tok/s 19098
step    650 | loss 1.7763 | lr 3.00e-04 | grad 1.80 | tok/s 19086
step    660 | loss 1.8124 | lr 3.00e-04 | grad 2.12 | tok/s 19797
step    670 | loss 1.8465 | lr 3.00e-04 | grad 5.12 | tok/s 19134
step    680 | loss 1.8710 | lr 3.00e-04 | grad 2.38 | tok/s 18842
step    690 | loss 1.8374 | lr 3.00e-04 | grad 2.06 | tok/s 18670
step    700 | loss 1.6999 | lr 3.00e-04 | grad 1.99 | tok/s 19109
step    710 | loss 1.8887 | lr 3.00e-04 | grad 4.38 | tok/s 18804

Training complete! Final step: 719
