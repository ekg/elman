Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_480M_30gen_20260128_171146/eval_126/levelMoME88_100m_20260128_183131
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 476,804,640 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 5.0 minutes
step     10 | loss 12.7890 | lr 3.00e-04 | grad 10.88 | tok/s 9068
step     20 | loss 3.3760 | lr 3.00e-04 | grad 2.66 | tok/s 18179
step     30 | loss 3.2366 | lr 3.00e-04 | grad 4.78 | tok/s 19181
step     40 | loss 4.8077 | lr 3.00e-04 | grad 19.00 | tok/s 19501
step     50 | loss 4.4650 | lr 3.00e-04 | grad 11.56 | tok/s 19704
step     60 | loss 3.8720 | lr 3.00e-04 | grad 7.56 | tok/s 19671
step     70 | loss 3.2627 | lr 3.00e-04 | grad 8.94 | tok/s 19676
step     80 | loss 3.0886 | lr 3.00e-04 | grad 6.19 | tok/s 19615
step     90 | loss 2.7607 | lr 3.00e-04 | grad 5.00 | tok/s 19629
step    100 | loss 2.5645 | lr 3.00e-04 | grad 4.06 | tok/s 19605
step    110 | loss 2.6336 | lr 3.00e-04 | grad 5.84 | tok/s 19413
step    120 | loss 3.2002 | lr 3.00e-04 | grad 2.22 | tok/s 18481
step    130 | loss 2.4060 | lr 3.00e-04 | grad 7.19 | tok/s 18881
step    140 | loss 2.7083 | lr 3.00e-04 | grad 8.88 | tok/s 18958
step    150 | loss 2.2467 | lr 3.00e-04 | grad 7.94 | tok/s 19402
step    160 | loss 2.6819 | lr 3.00e-04 | grad 2.69 | tok/s 18740
step    170 | loss 2.5460 | lr 3.00e-04 | grad 1.88 | tok/s 18461
step    180 | loss 2.5574 | lr 3.00e-04 | grad 3.16 | tok/s 18919
step    190 | loss 2.2200 | lr 3.00e-04 | grad 2.34 | tok/s 18583
step    200 | loss 2.0459 | lr 3.00e-04 | grad 2.81 | tok/s 19396
step    210 | loss 2.1817 | lr 3.00e-04 | grad 5.75 | tok/s 18434
step    220 | loss 2.5676 | lr 3.00e-04 | grad 22.38 | tok/s 18615
step    230 | loss 2.4116 | lr 3.00e-04 | grad 3.08 | tok/s 18588
step    240 | loss 2.5778 | lr 3.00e-04 | grad 8.81 | tok/s 18828
step    250 | loss 2.0530 | lr 3.00e-04 | grad 1.90 | tok/s 18706
step    260 | loss 2.1893 | lr 3.00e-04 | grad 3.81 | tok/s 19205
step    270 | loss 2.0733 | lr 3.00e-04 | grad 2.48 | tok/s 18796
step    280 | loss 2.0232 | lr 3.00e-04 | grad 2.00 | tok/s 17660
step    290 | loss 1.9319 | lr 3.00e-04 | grad 2.52 | tok/s 18265
step    300 | loss 2.2381 | lr 3.00e-04 | grad 2.62 | tok/s 18390
step    310 | loss 1.8880 | lr 3.00e-04 | grad 2.14 | tok/s 18322
step    320 | loss 2.1669 | lr 3.00e-04 | grad 6.22 | tok/s 18542
step    330 | loss 1.9593 | lr 3.00e-04 | grad 2.22 | tok/s 18745
step    340 | loss 2.3098 | lr 3.00e-04 | grad 3.41 | tok/s 18651
step    350 | loss 2.1263 | lr 3.00e-04 | grad 2.59 | tok/s 19190
step    360 | loss 1.8342 | lr 3.00e-04 | grad 2.34 | tok/s 18395
step    370 | loss 1.8158 | lr 3.00e-04 | grad 2.16 | tok/s 19349
step    380 | loss 1.5635 | lr 3.00e-04 | grad 2.73 | tok/s 19507
step    390 | loss 1.4436 | lr 3.00e-04 | grad 2.36 | tok/s 19505
step    400 | loss 2.0612 | lr 3.00e-04 | grad 2.19 | tok/s 18480
step    410 | loss 2.0194 | lr 3.00e-04 | grad 2.70 | tok/s 18684
step    420 | loss 1.9852 | lr 3.00e-04 | grad 6.94 | tok/s 19477
step    430 | loss 1.9270 | lr 3.00e-04 | grad 2.36 | tok/s 19135
step    440 | loss 1.9828 | lr 3.00e-04 | grad 2.91 | tok/s 18552
step    450 | loss 1.8711 | lr 3.00e-04 | grad 1.94 | tok/s 18791
step    460 | loss 1.8698 | lr 3.00e-04 | grad 2.48 | tok/s 19052
step    470 | loss 1.8485 | lr 3.00e-04 | grad 3.78 | tok/s 18923
step    480 | loss 1.9291 | lr 3.00e-04 | grad 3.36 | tok/s 19313
step    490 | loss 1.9230 | lr 3.00e-04 | grad 2.97 | tok/s 18550
step    500 | loss 2.0835 | lr 3.00e-04 | grad 2.53 | tok/s 18866
step    510 | loss 1.9234 | lr 3.00e-04 | grad 2.11 | tok/s 18023
step    520 | loss 1.7614 | lr 3.00e-04 | grad 2.77 | tok/s 18877
step    530 | loss 1.9420 | lr 3.00e-04 | grad 2.55 | tok/s 18534
step    540 | loss 1.8430 | lr 3.00e-04 | grad 1.81 | tok/s 18161
step    550 | loss 1.5824 | lr 3.00e-04 | grad 3.77 | tok/s 19002
step    560 | loss 1.6676 | lr 3.00e-04 | grad 2.23 | tok/s 19513
step    570 | loss 1.5404 | lr 3.00e-04 | grad 2.17 | tok/s 19489
step    580 | loss 1.4921 | lr 3.00e-04 | grad 1.67 | tok/s 19479
step    590 | loss 1.5368 | lr 3.00e-04 | grad 1.59 | tok/s 19480
step    600 | loss 1.4843 | lr 3.00e-04 | grad 1.98 | tok/s 19490
step    610 | loss 1.4944 | lr 3.00e-04 | grad 1.86 | tok/s 19476
step    620 | loss 1.4848 | lr 3.00e-04 | grad 2.16 | tok/s 19389
step    630 | loss 1.9400 | lr 3.00e-04 | grad 5.94 | tok/s 18392
step    640 | loss 1.9909 | lr 3.00e-04 | grad 3.33 | tok/s 18596
step    650 | loss 1.7807 | lr 3.00e-04 | grad 2.03 | tok/s 18571
step    660 | loss 1.8252 | lr 3.00e-04 | grad 2.56 | tok/s 19285
step    670 | loss 1.8764 | lr 3.00e-04 | grad 6.62 | tok/s 18661
step    680 | loss 1.8677 | lr 3.00e-04 | grad 2.81 | tok/s 18375
step    690 | loss 1.8514 | lr 3.00e-04 | grad 2.30 | tok/s 18224

Training complete! Final step: 699
