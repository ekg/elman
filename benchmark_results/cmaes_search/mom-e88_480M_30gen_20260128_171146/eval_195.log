Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_480M_30gen_20260128_171146/eval_195/levelMoME88_100m_20260128_191914
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 473,568,068 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 5.0 minutes
step     10 | loss 11.8882 | lr 3.00e-04 | grad 9.50 | tok/s 8738
step     20 | loss 3.2530 | lr 3.00e-04 | grad 2.22 | tok/s 16631
step     30 | loss 3.1142 | lr 3.00e-04 | grad 4.72 | tok/s 17624
step     40 | loss 5.1670 | lr 3.00e-04 | grad 54.00 | tok/s 17928
step     50 | loss 4.3765 | lr 3.00e-04 | grad 11.81 | tok/s 18165
step     60 | loss 3.7409 | lr 3.00e-04 | grad 8.06 | tok/s 18129
step     70 | loss 3.1181 | lr 3.00e-04 | grad 10.25 | tok/s 18052
step     80 | loss 2.8678 | lr 3.00e-04 | grad 3.67 | tok/s 17946
step     90 | loss 2.6434 | lr 3.00e-04 | grad 4.88 | tok/s 17983
step    100 | loss 2.4149 | lr 3.00e-04 | grad 9.69 | tok/s 17968
step    110 | loss 2.4657 | lr 3.00e-04 | grad 4.25 | tok/s 17828
step    120 | loss 3.0832 | lr 3.00e-04 | grad 2.23 | tok/s 16969
step    130 | loss 2.3599 | lr 3.00e-04 | grad 5.06 | tok/s 17386
step    140 | loss 2.6349 | lr 3.00e-04 | grad 7.16 | tok/s 17459
step    150 | loss 2.1247 | lr 3.00e-04 | grad 6.69 | tok/s 17952
step    160 | loss 2.5952 | lr 3.00e-04 | grad 2.67 | tok/s 17265
step    170 | loss 2.5031 | lr 3.00e-04 | grad 2.06 | tok/s 17002
step    180 | loss 2.4703 | lr 3.00e-04 | grad 3.02 | tok/s 17416
step    190 | loss 2.1860 | lr 3.00e-04 | grad 2.28 | tok/s 17084
step    200 | loss 1.9907 | lr 3.00e-04 | grad 1.92 | tok/s 17888
step    210 | loss 2.1683 | lr 3.00e-04 | grad 6.31 | tok/s 16964
step    220 | loss 2.5109 | lr 3.00e-04 | grad 11.06 | tok/s 17136
step    230 | loss 2.2990 | lr 3.00e-04 | grad 3.02 | tok/s 17121
step    240 | loss 2.5731 | lr 3.00e-04 | grad 5.47 | tok/s 17344
step    250 | loss 2.0592 | lr 3.00e-04 | grad 3.02 | tok/s 17230
step    260 | loss 2.1777 | lr 3.00e-04 | grad 4.03 | tok/s 17731
step    270 | loss 2.0817 | lr 3.00e-04 | grad 2.16 | tok/s 17305
step    280 | loss 2.0111 | lr 3.00e-04 | grad 2.06 | tok/s 16255
step    290 | loss 1.9372 | lr 3.00e-04 | grad 2.38 | tok/s 16805
step    300 | loss 2.2281 | lr 3.00e-04 | grad 3.62 | tok/s 16950
step    310 | loss 1.8918 | lr 3.00e-04 | grad 1.91 | tok/s 16854
step    320 | loss 2.1340 | lr 3.00e-04 | grad 4.38 | tok/s 17063
step    330 | loss 1.9490 | lr 3.00e-04 | grad 2.14 | tok/s 17245
step    340 | loss 2.2919 | lr 3.00e-04 | grad 2.81 | tok/s 17167
step    350 | loss 2.0955 | lr 3.00e-04 | grad 2.34 | tok/s 17673
step    360 | loss 1.8223 | lr 3.00e-04 | grad 2.38 | tok/s 16891
step    370 | loss 1.8045 | lr 3.00e-04 | grad 2.27 | tok/s 17817
step    380 | loss 1.5408 | lr 3.00e-04 | grad 2.11 | tok/s 17968
step    390 | loss 1.4295 | lr 3.00e-04 | grad 2.31 | tok/s 17973
step    400 | loss 2.0266 | lr 3.00e-04 | grad 2.38 | tok/s 17014
step    410 | loss 2.0114 | lr 3.00e-04 | grad 2.53 | tok/s 17173
step    420 | loss 1.9571 | lr 3.00e-04 | grad 6.94 | tok/s 17908
step    430 | loss 1.9137 | lr 3.00e-04 | grad 2.34 | tok/s 17613
step    440 | loss 1.9667 | lr 3.00e-04 | grad 2.61 | tok/s 17074
step    450 | loss 1.8616 | lr 3.00e-04 | grad 1.66 | tok/s 17257
step    460 | loss 1.8555 | lr 3.00e-04 | grad 2.33 | tok/s 17514
step    470 | loss 1.8446 | lr 3.00e-04 | grad 5.16 | tok/s 17382
step    480 | loss 1.9107 | lr 3.00e-04 | grad 2.92 | tok/s 17770
step    490 | loss 1.9167 | lr 3.00e-04 | grad 3.06 | tok/s 17062
step    500 | loss 2.0762 | lr 3.00e-04 | grad 2.38 | tok/s 17335
step    510 | loss 1.9114 | lr 3.00e-04 | grad 2.02 | tok/s 16553
step    520 | loss 1.7437 | lr 3.00e-04 | grad 2.55 | tok/s 17355
step    530 | loss 1.9390 | lr 3.00e-04 | grad 2.42 | tok/s 17053
step    540 | loss 1.8499 | lr 3.00e-04 | grad 1.96 | tok/s 16696
step    550 | loss 1.5758 | lr 3.00e-04 | grad 3.42 | tok/s 17487
step    560 | loss 1.6556 | lr 3.00e-04 | grad 2.47 | tok/s 17965
step    570 | loss 1.5376 | lr 3.00e-04 | grad 2.20 | tok/s 17974
step    580 | loss 1.4871 | lr 3.00e-04 | grad 1.50 | tok/s 17972
step    590 | loss 1.5271 | lr 3.00e-04 | grad 2.09 | tok/s 17971
step    600 | loss 1.4877 | lr 3.00e-04 | grad 1.93 | tok/s 17962
step    610 | loss 1.4841 | lr 3.00e-04 | grad 1.82 | tok/s 17968
step    620 | loss 1.4814 | lr 3.00e-04 | grad 1.92 | tok/s 17896
step    630 | loss 1.8878 | lr 3.00e-04 | grad 7.78 | tok/s 16932
step    640 | loss 1.9728 | lr 3.00e-04 | grad 2.36 | tok/s 17140

Training complete! Final step: 644
