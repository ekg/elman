Using device: cuda
Output directory: benchmark_results/cmaes_search/mom-e88_480M_30gen_20260128_171146/eval_75/levelMoME88_100m_20260128_175944
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level MoME88, 484,759,596 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 5.0 minutes
step     10 | loss 13.6160 | lr 3.00e-04 | grad 66.50 | tok/s 5371
step     20 | loss 2.9722 | lr 3.00e-04 | grad 3.75 | tok/s 12834
step     30 | loss 2.8846 | lr 3.00e-04 | grad 4.53 | tok/s 13030
step     40 | loss 3.7582 | lr 3.00e-04 | grad 3.91 | tok/s 12451
step     50 | loss 3.2902 | lr 3.00e-04 | grad 46.75 | tok/s 12639
step     60 | loss 2.3187 | lr 3.00e-04 | grad 6.06 | tok/s 13044
step     70 | loss 2.2232 | lr 3.00e-04 | grad 3.61 | tok/s 13205
step     80 | loss 8.1400 | lr 3.00e-04 | grad 51.75 | tok/s 13276
step     90 | loss 5.4634 | lr 3.00e-04 | grad 7.62 | tok/s 13520
step    100 | loss 4.4453 | lr 3.00e-04 | grad 6.12 | tok/s 13498
step    110 | loss 3.9648 | lr 3.00e-04 | grad 30.50 | tok/s 13498
step    120 | loss 3.5240 | lr 3.00e-04 | grad 17.62 | tok/s 13468
step    130 | loss 3.2588 | lr 3.00e-04 | grad 9.00 | tok/s 13465
step    140 | loss 2.8198 | lr 3.00e-04 | grad 5.50 | tok/s 13506
step    150 | loss 3.0585 | lr 3.00e-04 | grad 10.62 | tok/s 13455
step    160 | loss 2.5456 | lr 3.00e-04 | grad 10.19 | tok/s 13450
step    170 | loss 2.5526 | lr 3.00e-04 | grad 16.12 | tok/s 13446
step    180 | loss 2.3422 | lr 3.00e-04 | grad 7.66 | tok/s 13437
step    190 | loss 2.5009 | lr 3.00e-04 | grad 5.75 | tok/s 13466
step    200 | loss 2.2170 | lr 3.00e-04 | grad 5.88 | tok/s 13473
step    210 | loss 2.2532 | lr 3.00e-04 | grad 8.00 | tok/s 13439
step    220 | loss 2.4769 | lr 3.00e-04 | grad 2.75 | tok/s 13286
step    230 | loss 2.9881 | lr 3.00e-04 | grad 5.00 | tok/s 13116
step    240 | loss 2.5403 | lr 3.00e-04 | grad 4.06 | tok/s 12465
step    250 | loss 2.3531 | lr 3.00e-04 | grad 2.34 | tok/s 12821
step    260 | loss 1.9906 | lr 3.00e-04 | grad 2.50 | tok/s 13223
step    270 | loss 2.3878 | lr 3.00e-04 | grad 2.31 | tok/s 13052
step    280 | loss 2.5852 | lr 3.00e-04 | grad 7.16 | tok/s 12810
step    290 | loss 2.5915 | lr 3.00e-04 | grad 6.31 | tok/s 13487
step    300 | loss 1.2551 | lr 3.00e-04 | grad 3.14 | tok/s 13490
step    310 | loss 2.7414 | lr 3.00e-04 | grad 2.98 | tok/s 13241
step    320 | loss 2.3580 | lr 3.00e-04 | grad 4.44 | tok/s 12979
step    330 | loss 2.2311 | lr 3.00e-04 | grad 2.48 | tok/s 12527
step    340 | loss 2.6071 | lr 3.00e-04 | grad 2.17 | tok/s 12723
step    350 | loss 2.2963 | lr 3.00e-04 | grad 3.45 | tok/s 13040
step    360 | loss 2.1814 | lr 3.00e-04 | grad 6.62 | tok/s 13320
step    370 | loss 2.1457 | lr 3.00e-04 | grad 2.56 | tok/s 12088
step    380 | loss 2.0416 | lr 3.00e-04 | grad 2.47 | tok/s 12882
step    390 | loss 1.8088 | lr 3.00e-04 | grad 1.76 | tok/s 13450
step    400 | loss 1.8313 | lr 3.00e-04 | grad 2.38 | tok/s 13315
step    410 | loss 1.7325 | lr 3.00e-04 | grad 2.02 | tok/s 13045
step    420 | loss 2.0999 | lr 3.00e-04 | grad 4.09 | tok/s 12445
step    430 | loss 2.4647 | lr 3.00e-04 | grad 2.80 | tok/s 13248
step    440 | loss 2.4074 | lr 3.00e-04 | grad 3.53 | tok/s 12527
step    450 | loss 2.2580 | lr 3.00e-04 | grad 2.16 | tok/s 12949
step    460 | loss 2.0694 | lr 3.00e-04 | grad 3.67 | tok/s 12674
step    470 | loss 2.1367 | lr 3.00e-04 | grad 2.22 | tok/s 13068
step    480 | loss 2.6562 | lr 3.00e-04 | grad 6.06 | tok/s 13074
step    490 | loss 2.0705 | lr 3.00e-04 | grad 2.27 | tok/s 12360
step    500 | loss 2.0086 | lr 3.00e-04 | grad 2.84 | tok/s 13188
step    510 | loss 1.9933 | lr 3.00e-04 | grad 2.12 | tok/s 13356
step    520 | loss 1.9811 | lr 3.00e-04 | grad 2.20 | tok/s 13342
step    530 | loss 2.1925 | lr 3.00e-04 | grad 2.31 | tok/s 12853
step    540 | loss 1.9630 | lr 3.00e-04 | grad 2.14 | tok/s 12845
step    550 | loss 1.7891 | lr 3.00e-04 | grad 2.59 | tok/s 12565
step    560 | loss 1.9888 | lr 3.00e-04 | grad 2.22 | tok/s 12247
step    570 | loss 1.9504 | lr 3.00e-04 | grad 3.30 | tok/s 12587
step    580 | loss 1.8033 | lr 3.00e-04 | grad 2.30 | tok/s 12529
step    590 | loss 2.1571 | lr 3.00e-04 | grad 2.89 | tok/s 12870
step    600 | loss 2.0528 | lr 3.00e-04 | grad 2.22 | tok/s 12414
step    610 | loss 1.8614 | lr 3.00e-04 | grad 1.98 | tok/s 13054
step    620 | loss 1.7498 | lr 3.00e-04 | grad 2.11 | tok/s 12374
step    630 | loss 1.9107 | lr 3.00e-04 | grad 4.22 | tok/s 12476
step    640 | loss 2.0933 | lr 3.00e-04 | grad 2.30 | tok/s 12811
step    650 | loss 1.8894 | lr 3.00e-04 | grad 2.12 | tok/s 12882
step    660 | loss 1.9321 | lr 3.00e-04 | grad 2.44 | tok/s 12920
step    670 | loss 2.2082 | lr 3.00e-04 | grad 50.00 | tok/s 13011
step    680 | loss 1.9330 | lr 3.00e-04 | grad 2.25 | tok/s 12751
step    690 | loss 2.2042 | lr 3.00e-04 | grad 3.89 | tok/s 13196
step    700 | loss 1.9129 | lr 3.00e-04 | grad 3.22 | tok/s 13438
step    710 | loss 1.8428 | lr 3.00e-04 | grad 2.06 | tok/s 12557
step    720 | loss 1.6793 | lr 3.00e-04 | grad 4.34 | tok/s 12370
step    730 | loss 1.6396 | lr 3.00e-04 | grad 2.89 | tok/s 13416
step    740 | loss 1.7947 | lr 3.00e-04 | grad 2.86 | tok/s 13251
step    750 | loss 1.5344 | lr 3.00e-04 | grad 2.33 | tok/s 13465
step    760 | loss 1.3902 | lr 3.00e-04 | grad 2.23 | tok/s 13442
step    770 | loss 1.3358 | lr 3.00e-04 | grad 1.91 | tok/s 13453
step    780 | loss 1.2830 | lr 3.00e-04 | grad 3.78 | tok/s 13448
step    790 | loss 1.3795 | lr 3.00e-04 | grad 3.25 | tok/s 13023
step    800 | loss 2.1670 | lr 3.00e-04 | grad 4.56 | tok/s 12991
step    810 | loss 1.8943 | lr 3.00e-04 | grad 2.03 | tok/s 12921
step    820 | loss 1.9434 | lr 3.00e-04 | grad 3.75 | tok/s 12411
step    830 | loss 1.8808 | lr 3.00e-04 | grad 2.72 | tok/s 13318
step    840 | loss 1.7419 | lr 3.00e-04 | grad 2.72 | tok/s 13433
step    850 | loss 1.8397 | lr 3.00e-04 | grad 2.50 | tok/s 13382
step    860 | loss 1.7762 | lr 3.00e-04 | grad 3.47 | tok/s 13236
step    870 | loss 1.7302 | lr 3.00e-04 | grad 3.14 | tok/s 12746
step    880 | loss 1.9505 | lr 3.00e-04 | grad 2.84 | tok/s 12816
step    890 | loss 1.8964 | lr 3.00e-04 | grad 2.81 | tok/s 12998
step    900 | loss 1.7684 | lr 3.00e-04 | grad 2.38 | tok/s 12987
step    910 | loss 1.6411 | lr 3.00e-04 | grad 3.23 | tok/s 12735
step    920 | loss 1.7938 | lr 3.00e-04 | grad 3.16 | tok/s 13235
step    930 | loss 1.8028 | lr 3.00e-04 | grad 2.98 | tok/s 12643
step    940 | loss 1.6831 | lr 3.00e-04 | grad 2.12 | tok/s 13328
step    950 | loss 1.8040 | lr 3.00e-04 | grad 2.88 | tok/s 13375
step    960 | loss 1.6559 | lr 3.00e-04 | grad 2.67 | tok/s 13403

Training complete! Final step: 961
