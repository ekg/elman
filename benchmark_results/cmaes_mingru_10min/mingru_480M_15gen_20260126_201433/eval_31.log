Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_31/levelmingru_100m_20260126_204519
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 177,308,160 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.8207 | lr 3.00e-04 | grad 4.31 | tok/s 22755
step     20 | loss 3.1241 | lr 3.00e-04 | grad 2.36 | tok/s 24705
step     30 | loss 3.5529 | lr 3.00e-04 | grad 3.22 | tok/s 24936
step     40 | loss 3.7642 | lr 3.00e-04 | grad 6.56 | tok/s 25761
step     50 | loss 4.9660 | lr 3.00e-04 | grad 3.33 | tok/s 26416
step     60 | loss 4.0161 | lr 3.00e-04 | grad 4.66 | tok/s 26401
step     70 | loss 3.7853 | lr 3.00e-04 | grad 4.66 | tok/s 26378
step     80 | loss 3.6529 | lr 3.00e-04 | grad 4.97 | tok/s 26354
step     90 | loss 3.4016 | lr 3.00e-04 | grad 2.88 | tok/s 26341
step    100 | loss 3.3387 | lr 3.00e-04 | grad 1.83 | tok/s 26318
step    110 | loss 3.1229 | lr 3.00e-04 | grad 4.94 | tok/s 26151
step    120 | loss 3.4242 | lr 3.00e-04 | grad 1.98 | tok/s 25268
step    130 | loss 2.7721 | lr 3.00e-04 | grad 2.33 | tok/s 25373
step    140 | loss 2.7899 | lr 3.00e-04 | grad 3.14 | tok/s 25359
step    150 | loss 2.9872 | lr 3.00e-04 | grad 3.58 | tok/s 25901
step    160 | loss 2.9946 | lr 3.00e-04 | grad 2.36 | tok/s 26013
step    170 | loss 2.8112 | lr 3.00e-04 | grad 2.25 | tok/s 24395
step    180 | loss 2.9652 | lr 3.00e-04 | grad 2.64 | tok/s 25512
step    190 | loss 2.6637 | lr 3.00e-04 | grad 2.22 | tok/s 24292
step    200 | loss 2.4428 | lr 3.00e-04 | grad 1.33 | tok/s 25917
step    210 | loss 2.4261 | lr 3.00e-04 | grad 1.07 | tok/s 24996
step    220 | loss 2.7957 | lr 3.00e-04 | grad 1.61 | tok/s 25183
step    230 | loss 2.8876 | lr 3.00e-04 | grad 3.50 | tok/s 24748
step    240 | loss 2.6077 | lr 3.00e-04 | grad 2.39 | tok/s 25148
step    250 | loss 2.7270 | lr 3.00e-04 | grad 2.03 | tok/s 24897
step    260 | loss 2.5479 | lr 3.00e-04 | grad 2.33 | tok/s 25822
step    270 | loss 2.5555 | lr 3.00e-04 | grad 2.48 | tok/s 25251
step    280 | loss 2.3067 | lr 3.00e-04 | grad 2.31 | tok/s 23827
step    290 | loss 2.3597 | lr 3.00e-04 | grad 1.92 | tok/s 24654
step    300 | loss 2.5165 | lr 3.00e-04 | grad 1.65 | tok/s 24408
step    310 | loss 2.3026 | lr 3.00e-04 | grad 1.27 | tok/s 24635
step    320 | loss 2.4190 | lr 3.00e-04 | grad 2.53 | tok/s 24338
step    330 | loss 2.4236 | lr 3.00e-04 | grad 1.94 | tok/s 25046
step    340 | loss 2.5498 | lr 3.00e-04 | grad 1.44 | tok/s 25133
step    350 | loss 2.6505 | lr 3.00e-04 | grad 1.38 | tok/s 25176
step    360 | loss 2.2942 | lr 3.00e-04 | grad 1.45 | tok/s 24090
step    370 | loss 2.3735 | lr 3.00e-04 | grad 1.83 | tok/s 25785
step    380 | loss 2.2546 | lr 3.00e-04 | grad 2.28 | tok/s 25992
step    390 | loss 2.2090 | lr 3.00e-04 | grad 2.67 | tok/s 25992
step    400 | loss 2.2424 | lr 3.00e-04 | grad 2.97 | tok/s 25127
step    410 | loss 2.4413 | lr 3.00e-04 | grad 2.20 | tok/s 24783
step    420 | loss 2.4591 | lr 3.00e-04 | grad 1.17 | tok/s 25523
step    430 | loss 2.4365 | lr 3.00e-04 | grad 1.65 | tok/s 25781
step    440 | loss 2.3198 | lr 3.00e-04 | grad 1.59 | tok/s 24713
step    450 | loss 2.3444 | lr 3.00e-04 | grad 1.13 | tok/s 25134
step    460 | loss 2.2825 | lr 3.00e-04 | grad 1.62 | tok/s 25057
step    470 | loss 2.3031 | lr 3.00e-04 | grad 1.56 | tok/s 24814
step    480 | loss 2.3920 | lr 3.00e-04 | grad 1.72 | tok/s 25880
step    490 | loss 2.3650 | lr 3.00e-04 | grad 2.22 | tok/s 24873
step    500 | loss 2.2277 | lr 3.00e-04 | grad 1.60 | tok/s 24753
step    510 | loss 2.4885 | lr 3.00e-04 | grad 1.55 | tok/s 24570
step    520 | loss 2.1847 | lr 3.00e-04 | grad 1.73 | tok/s 24395
step    530 | loss 2.2101 | lr 3.00e-04 | grad 1.68 | tok/s 24667
step    540 | loss 2.4680 | lr 3.00e-04 | grad 1.44 | tok/s 24952
step    550 | loss 1.8946 | lr 3.00e-04 | grad 1.61 | tok/s 24483
step    560 | loss 2.2249 | lr 3.00e-04 | grad 1.74 | tok/s 25578
step    570 | loss 2.1619 | lr 3.00e-04 | grad 2.06 | tok/s 25921
step    580 | loss 2.1119 | lr 3.00e-04 | grad 2.61 | tok/s 25930
step    590 | loss 2.0689 | lr 3.00e-04 | grad 1.64 | tok/s 25931
step    600 | loss 2.1452 | lr 3.00e-04 | grad 1.80 | tok/s 25931
step    610 | loss 2.0878 | lr 3.00e-04 | grad 1.86 | tok/s 25925
step    620 | loss 2.0373 | lr 3.00e-04 | grad 1.74 | tok/s 25920
step    630 | loss 2.2765 | lr 3.00e-04 | grad 1.98 | tok/s 24924
step    640 | loss 2.0815 | lr 3.00e-04 | grad 1.54 | tok/s 24184
step    650 | loss 2.2568 | lr 3.00e-04 | grad 1.92 | tok/s 25249
step    660 | loss 2.1383 | lr 3.00e-04 | grad 1.83 | tok/s 25103
step    670 | loss 2.3004 | lr 3.00e-04 | grad 1.57 | tok/s 25433
step    680 | loss 2.2639 | lr 3.00e-04 | grad 2.00 | tok/s 23904
step    690 | loss 2.2451 | lr 3.00e-04 | grad 1.73 | tok/s 24922
step    700 | loss 2.0858 | lr 3.00e-04 | grad 1.77 | tok/s 24049
step    710 | loss 2.2840 | lr 3.00e-04 | grad 1.83 | tok/s 24752
step    720 | loss 2.1729 | lr 3.00e-04 | grad 2.47 | tok/s 24568
step    730 | loss 2.1256 | lr 3.00e-04 | grad 4.16 | tok/s 25739
step    740 | loss 2.1914 | lr 3.00e-04 | grad 1.30 | tok/s 24793
step    750 | loss 2.7268 | lr 3.00e-04 | grad 1.84 | tok/s 25764
step    760 | loss 2.1954 | lr 3.00e-04 | grad 2.47 | tok/s 25748
step    770 | loss 2.0779 | lr 3.00e-04 | grad 1.48 | tok/s 25004
step    780 | loss 2.1587 | lr 3.00e-04 | grad 1.76 | tok/s 25233
step    790 | loss 2.1686 | lr 3.00e-04 | grad 1.61 | tok/s 25076
step    800 | loss 2.5357 | lr 3.00e-04 | grad 1.62 | tok/s 24944
step    810 | loss 1.6545 | lr 3.00e-04 | grad 1.57 | tok/s 24973
step    820 | loss 2.2170 | lr 3.00e-04 | grad 1.19 | tok/s 24941
step    830 | loss 2.1040 | lr 3.00e-04 | grad 1.45 | tok/s 23742
step    840 | loss 2.2755 | lr 3.00e-04 | grad 2.25 | tok/s 25109
step    850 | loss 2.2043 | lr 3.00e-04 | grad 1.97 | tok/s 24725
step    860 | loss 2.2086 | lr 3.00e-04 | grad 1.66 | tok/s 24726
step    870 | loss 2.4710 | lr 3.00e-04 | grad 1.85 | tok/s 25922
step    880 | loss 2.1728 | lr 3.00e-04 | grad 2.11 | tok/s 24974
step    890 | loss 2.0891 | lr 3.00e-04 | grad 1.62 | tok/s 24686
step    900 | loss 2.0766 | lr 3.00e-04 | grad 1.37 | tok/s 24993
step    910 | loss 2.1781 | lr 3.00e-04 | grad 2.09 | tok/s 24445
step    920 | loss 2.1227 | lr 3.00e-04 | grad 1.19 | tok/s 25147
step    930 | loss 2.1674 | lr 3.00e-04 | grad 1.60 | tok/s 24997
step    940 | loss 2.0124 | lr 3.00e-04 | grad 1.10 | tok/s 24826
step    950 | loss 2.0837 | lr 3.00e-04 | grad 1.88 | tok/s 23663
step    960 | loss 2.0114 | lr 3.00e-04 | grad 1.33 | tok/s 24298
step    970 | loss 2.0273 | lr 3.00e-04 | grad 1.88 | tok/s 24886
step    980 | loss 2.5593 | lr 3.00e-04 | grad 1.74 | tok/s 25690
step    990 | loss 2.5259 | lr 3.00e-04 | grad 2.23 | tok/s 25380
step   1000 | loss 2.1884 | lr 3.00e-04 | grad 0.98 | tok/s 24509
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1884.pt
step   1010 | loss 1.7862 | lr 3.00e-04 | grad 1.53 | tok/s 17695
step   1020 | loss 1.8039 | lr 3.00e-04 | grad 1.31 | tok/s 25627
step   1030 | loss 2.2287 | lr 3.00e-04 | grad 1.63 | tok/s 25461
step   1040 | loss 2.2674 | lr 3.00e-04 | grad 4.56 | tok/s 24469
step   1050 | loss 2.4922 | lr 3.00e-04 | grad 1.64 | tok/s 25683
step   1060 | loss 2.2468 | lr 3.00e-04 | grad 1.73 | tok/s 24801
step   1070 | loss 1.6901 | lr 3.00e-04 | grad 1.43 | tok/s 25484
step   1080 | loss 2.0014 | lr 3.00e-04 | grad 1.95 | tok/s 25556
step   1090 | loss 1.9240 | lr 3.00e-04 | grad 1.75 | tok/s 25909
step   1100 | loss 1.9030 | lr 3.00e-04 | grad 1.70 | tok/s 25909
step   1110 | loss 1.8825 | lr 3.00e-04 | grad 2.28 | tok/s 25897
step   1120 | loss 1.9276 | lr 3.00e-04 | grad 2.08 | tok/s 25665
step   1130 | loss 2.3027 | lr 3.00e-04 | grad 4.03 | tok/s 25455
step   1140 | loss 2.4516 | lr 3.00e-04 | grad 1.93 | tok/s 25347
step   1150 | loss 2.1979 | lr 3.00e-04 | grad 4.91 | tok/s 25433
step   1160 | loss 2.4441 | lr 3.00e-04 | grad 2.02 | tok/s 24896
step   1170 | loss 2.2244 | lr 3.00e-04 | grad 1.83 | tok/s 24395
step   1180 | loss 2.0612 | lr 3.00e-04 | grad 1.75 | tok/s 24682
step   1190 | loss 2.1787 | lr 3.00e-04 | grad 1.48 | tok/s 25616
step   1200 | loss 2.1756 | lr 3.00e-04 | grad 2.05 | tok/s 25888
step   1210 | loss 1.8553 | lr 3.00e-04 | grad 1.63 | tok/s 25377
step   1220 | loss 2.0229 | lr 3.00e-04 | grad 1.51 | tok/s 24629
step   1230 | loss 2.0625 | lr 3.00e-04 | grad 1.20 | tok/s 25031
step   1240 | loss 1.9782 | lr 3.00e-04 | grad 1.82 | tok/s 25663
step   1250 | loss 2.0068 | lr 3.00e-04 | grad 1.83 | tok/s 25116
step   1260 | loss 2.3433 | lr 3.00e-04 | grad 2.62 | tok/s 25752
step   1270 | loss 2.1311 | lr 3.00e-04 | grad 1.68 | tok/s 25268
step   1280 | loss 2.0074 | lr 3.00e-04 | grad 2.14 | tok/s 25408
step   1290 | loss 2.0993 | lr 3.00e-04 | grad 1.67 | tok/s 24480
step   1300 | loss 2.0716 | lr 3.00e-04 | grad 2.28 | tok/s 24334
step   1310 | loss 2.4016 | lr 3.00e-04 | grad 1.93 | tok/s 24920
step   1320 | loss 2.0576 | lr 3.00e-04 | grad 2.02 | tok/s 25350
step   1330 | loss 2.2798 | lr 3.00e-04 | grad 1.86 | tok/s 25219
step   1340 | loss 1.9655 | lr 3.00e-04 | grad 1.91 | tok/s 24511
step   1350 | loss 2.1866 | lr 3.00e-04 | grad 1.90 | tok/s 25326
step   1360 | loss 2.2135 | lr 3.00e-04 | grad 1.21 | tok/s 24589
step   1370 | loss 1.9900 | lr 3.00e-04 | grad 1.74 | tok/s 24691
step   1380 | loss 2.3288 | lr 3.00e-04 | grad 1.45 | tok/s 25365
step   1390 | loss 2.0336 | lr 3.00e-04 | grad 1.93 | tok/s 24411
step   1400 | loss 2.2727 | lr 3.00e-04 | grad 1.90 | tok/s 24865
step   1410 | loss 1.9324 | lr 3.00e-04 | grad 1.65 | tok/s 24680
step   1420 | loss 2.0794 | lr 3.00e-04 | grad 2.86 | tok/s 24935
step   1430 | loss 2.2320 | lr 3.00e-04 | grad 1.46 | tok/s 25257
step   1440 | loss 2.1137 | lr 3.00e-04 | grad 1.20 | tok/s 24834
step   1450 | loss 2.1901 | lr 3.00e-04 | grad 1.62 | tok/s 25626
step   1460 | loss 2.0136 | lr 3.00e-04 | grad 1.98 | tok/s 24846
step   1470 | loss 2.0927 | lr 3.00e-04 | grad 1.88 | tok/s 24689
step   1480 | loss 1.9401 | lr 3.00e-04 | grad 1.64 | tok/s 24295
step   1490 | loss 1.9773 | lr 3.00e-04 | grad 1.54 | tok/s 24895
step   1500 | loss 2.4451 | lr 3.00e-04 | grad 1.60 | tok/s 25384
step   1510 | loss 1.9498 | lr 3.00e-04 | grad 2.20 | tok/s 25212
step   1520 | loss 1.9546 | lr 3.00e-04 | grad 1.81 | tok/s 24427
step   1530 | loss 1.9901 | lr 3.00e-04 | grad 1.45 | tok/s 25204
step   1540 | loss 2.0842 | lr 3.00e-04 | grad 1.91 | tok/s 25494
step   1550 | loss 1.9906 | lr 3.00e-04 | grad 1.42 | tok/s 25416
step   1560 | loss 2.0605 | lr 3.00e-04 | grad 1.76 | tok/s 25051
step   1570 | loss 1.9501 | lr 3.00e-04 | grad 2.56 | tok/s 25184
step   1580 | loss 2.0068 | lr 3.00e-04 | grad 2.20 | tok/s 25904
step   1590 | loss 2.0405 | lr 3.00e-04 | grad 1.73 | tok/s 24544
step   1600 | loss 1.8553 | lr 3.00e-04 | grad 1.84 | tok/s 24925
step   1610 | loss 2.0117 | lr 3.00e-04 | grad 1.70 | tok/s 25466
step   1620 | loss 2.6163 | lr 3.00e-04 | grad 1.55 | tok/s 25552
step   1630 | loss 2.3738 | lr 3.00e-04 | grad 1.80 | tok/s 25912
step   1640 | loss 2.2778 | lr 3.00e-04 | grad 1.76 | tok/s 25911
step   1650 | loss 2.2168 | lr 3.00e-04 | grad 2.16 | tok/s 25905
step   1660 | loss 2.1804 | lr 3.00e-04 | grad 1.78 | tok/s 25899
step   1670 | loss 2.1592 | lr 3.00e-04 | grad 1.99 | tok/s 25895
step   1680 | loss 2.1332 | lr 3.00e-04 | grad 1.79 | tok/s 24815
step   1690 | loss 1.9491 | lr 3.00e-04 | grad 2.22 | tok/s 24268
step   1700 | loss 2.0338 | lr 3.00e-04 | grad 1.70 | tok/s 24552
step   1710 | loss 1.8670 | lr 3.00e-04 | grad 1.52 | tok/s 25855
step   1720 | loss 1.9801 | lr 3.00e-04 | grad 1.83 | tok/s 24800
step   1730 | loss 1.9747 | lr 3.00e-04 | grad 2.16 | tok/s 24850
step   1740 | loss 2.1134 | lr 3.00e-04 | grad 1.96 | tok/s 25371
step   1750 | loss 1.9159 | lr 3.00e-04 | grad 1.52 | tok/s 24673
step   1760 | loss 1.9184 | lr 3.00e-04 | grad 2.06 | tok/s 25078
step   1770 | loss 2.2593 | lr 3.00e-04 | grad 2.00 | tok/s 25236
step   1780 | loss 2.2848 | lr 3.00e-04 | grad 5.84 | tok/s 24727
step   1790 | loss 1.9987 | lr 3.00e-04 | grad 2.31 | tok/s 23630
step   1800 | loss 1.8871 | lr 3.00e-04 | grad 1.91 | tok/s 25274
step   1810 | loss 1.9770 | lr 3.00e-04 | grad 2.02 | tok/s 23954
step   1820 | loss 1.9138 | lr 3.00e-04 | grad 1.80 | tok/s 25244
step   1830 | loss 2.0422 | lr 3.00e-04 | grad 1.43 | tok/s 24412
step   1840 | loss 2.0137 | lr 3.00e-04 | grad 2.36 | tok/s 24466
step   1850 | loss 1.9289 | lr 3.00e-04 | grad 1.83 | tok/s 24645
step   1860 | loss 2.0070 | lr 3.00e-04 | grad 1.63 | tok/s 24435
step   1870 | loss 2.0893 | lr 3.00e-04 | grad 2.16 | tok/s 24841
step   1880 | loss 2.0062 | lr 3.00e-04 | grad 2.86 | tok/s 25093

Training complete! Final step: 1888
