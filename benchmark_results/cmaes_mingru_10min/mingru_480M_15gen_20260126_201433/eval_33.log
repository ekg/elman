Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_33/levelmingru_100m_20260126_205532
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 241,096,704 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.3541 | lr 3.00e-04 | grad 4.66 | tok/s 18907
step     20 | loss 3.1764 | lr 3.00e-04 | grad 2.89 | tok/s 23851
step     30 | loss 2.9741 | lr 3.00e-04 | grad 9.81 | tok/s 23986
step     40 | loss 2.9090 | lr 3.00e-04 | grad 2.66 | tok/s 22954
step     50 | loss 2.8529 | lr 3.00e-04 | grad 11.88 | tok/s 22898
step     60 | loss 3.6431 | lr 3.00e-04 | grad 2.39 | tok/s 24426
step     70 | loss 2.6887 | lr 3.00e-04 | grad 3.81 | tok/s 24484
step     80 | loss 4.5174 | lr 3.00e-04 | grad 11.12 | tok/s 24349
step     90 | loss 5.2943 | lr 3.00e-04 | grad 9.31 | tok/s 25104
step    100 | loss 4.0073 | lr 3.00e-04 | grad 4.84 | tok/s 25066
step    110 | loss 3.8233 | lr 3.00e-04 | grad 5.50 | tok/s 25064
step    120 | loss 3.8104 | lr 3.00e-04 | grad 5.62 | tok/s 25020
step    130 | loss 3.9249 | lr 3.00e-04 | grad 4.06 | tok/s 25022
step    140 | loss 3.3956 | lr 3.00e-04 | grad 8.12 | tok/s 25029
step    150 | loss 3.6159 | lr 3.00e-04 | grad 8.12 | tok/s 24965
step    160 | loss 3.4430 | lr 3.00e-04 | grad 4.78 | tok/s 24992
step    170 | loss 3.2578 | lr 3.00e-04 | grad 4.59 | tok/s 24946
step    180 | loss 3.3202 | lr 3.00e-04 | grad 3.27 | tok/s 24961
step    190 | loss 3.2251 | lr 3.00e-04 | grad 4.59 | tok/s 24946
step    200 | loss 3.2344 | lr 3.00e-04 | grad 2.14 | tok/s 24923
step    210 | loss 3.0649 | lr 3.00e-04 | grad 3.48 | tok/s 24932
step    220 | loss 2.9972 | lr 3.00e-04 | grad 5.91 | tok/s 24541
step    230 | loss 3.0712 | lr 3.00e-04 | grad 7.47 | tok/s 24503
step    240 | loss 3.2444 | lr 3.00e-04 | grad 2.73 | tok/s 23157
step    250 | loss 2.7067 | lr 3.00e-04 | grad 2.03 | tok/s 23357
step    260 | loss 2.5179 | lr 3.00e-04 | grad 2.17 | tok/s 24522
step    270 | loss 2.6099 | lr 3.00e-04 | grad 4.28 | tok/s 23611
step    280 | loss 2.5806 | lr 3.00e-04 | grad 4.41 | tok/s 24226
step    290 | loss 2.9855 | lr 3.00e-04 | grad 2.33 | tok/s 24108
step    300 | loss 2.1825 | lr 3.00e-04 | grad 1.27 | tok/s 24788
step    310 | loss 2.6496 | lr 3.00e-04 | grad 2.67 | tok/s 24364
step    320 | loss 2.8386 | lr 3.00e-04 | grad 1.62 | tok/s 24737
step    330 | loss 2.5226 | lr 3.00e-04 | grad 2.39 | tok/s 22342
step    340 | loss 2.7056 | lr 3.00e-04 | grad 1.29 | tok/s 23737
step    350 | loss 2.5336 | lr 3.00e-04 | grad 2.02 | tok/s 23467
step    360 | loss 2.9218 | lr 3.00e-04 | grad 1.41 | tok/s 24714
step    370 | loss 2.5981 | lr 3.00e-04 | grad 2.58 | tok/s 22715
step    380 | loss 2.3854 | lr 3.00e-04 | grad 1.78 | tok/s 23214
step    390 | loss 2.3030 | lr 3.00e-04 | grad 2.47 | tok/s 24469
step    400 | loss 2.2627 | lr 3.00e-04 | grad 1.95 | tok/s 24489
step    410 | loss 2.3562 | lr 3.00e-04 | grad 1.90 | tok/s 24694
step    420 | loss 2.1941 | lr 3.00e-04 | grad 1.77 | tok/s 22579
step    430 | loss 2.5821 | lr 3.00e-04 | grad 2.30 | tok/s 24032
step    440 | loss 2.7324 | lr 3.00e-04 | grad 2.14 | tok/s 23599
step    450 | loss 2.8172 | lr 3.00e-04 | grad 7.50 | tok/s 23667
step    460 | loss 2.4851 | lr 3.00e-04 | grad 1.90 | tok/s 23146
step    470 | loss 2.4723 | lr 3.00e-04 | grad 1.39 | tok/s 23571
step    480 | loss 2.4679 | lr 3.00e-04 | grad 1.77 | tok/s 24011
step    490 | loss 2.8791 | lr 3.00e-04 | grad 2.39 | tok/s 23756
step    500 | loss 2.2299 | lr 3.00e-04 | grad 2.33 | tok/s 23369
step    510 | loss 2.4129 | lr 3.00e-04 | grad 1.80 | tok/s 24340
step    520 | loss 2.4126 | lr 3.00e-04 | grad 1.27 | tok/s 24510
step    530 | loss 2.5195 | lr 3.00e-04 | grad 1.91 | tok/s 24239
step    540 | loss 2.3124 | lr 3.00e-04 | grad 1.25 | tok/s 23594
step    550 | loss 2.1535 | lr 3.00e-04 | grad 1.92 | tok/s 23562
step    560 | loss 2.2280 | lr 3.00e-04 | grad 4.53 | tok/s 21561
step    570 | loss 2.2851 | lr 3.00e-04 | grad 1.66 | tok/s 23591
step    580 | loss 2.1917 | lr 3.00e-04 | grad 1.60 | tok/s 23133
step    590 | loss 2.1415 | lr 3.00e-04 | grad 1.73 | tok/s 22872
step    600 | loss 2.6092 | lr 3.00e-04 | grad 1.86 | tok/s 23408
step    610 | loss 2.2535 | lr 3.00e-04 | grad 2.06 | tok/s 23448
step    620 | loss 2.0988 | lr 3.00e-04 | grad 2.52 | tok/s 23267
step    630 | loss 2.1954 | lr 3.00e-04 | grad 2.94 | tok/s 22823
step    640 | loss 2.4121 | lr 3.00e-04 | grad 3.12 | tok/s 23363
step    650 | loss 2.3215 | lr 3.00e-04 | grad 3.22 | tok/s 23578
step    660 | loss 2.2534 | lr 3.00e-04 | grad 1.86 | tok/s 23930
step    670 | loss 2.1807 | lr 3.00e-04 | grad 1.80 | tok/s 23333
step    680 | loss 2.6312 | lr 3.00e-04 | grad 1.90 | tok/s 24347
step    690 | loss 2.4231 | lr 3.00e-04 | grad 1.92 | tok/s 23111
step    700 | loss 2.5398 | lr 3.00e-04 | grad 2.05 | tok/s 24685
step    710 | loss 2.3614 | lr 3.00e-04 | grad 2.11 | tok/s 23988
step    720 | loss 1.9779 | lr 3.00e-04 | grad 2.39 | tok/s 21780
step    730 | loss 2.3263 | lr 3.00e-04 | grad 2.08 | tok/s 24710
step    740 | loss 2.1332 | lr 3.00e-04 | grad 1.55 | tok/s 24260
step    750 | loss 2.2084 | lr 3.00e-04 | grad 1.64 | tok/s 24700
step    760 | loss 2.0135 | lr 3.00e-04 | grad 1.73 | tok/s 24701
step    770 | loss 2.0715 | lr 3.00e-04 | grad 1.84 | tok/s 24690
step    780 | loss 2.0174 | lr 3.00e-04 | grad 2.53 | tok/s 24676
step    790 | loss 1.9458 | lr 3.00e-04 | grad 1.90 | tok/s 24684
step    800 | loss 2.2200 | lr 3.00e-04 | grad 2.92 | tok/s 23080
step    810 | loss 2.4343 | lr 3.00e-04 | grad 1.98 | tok/s 23679
step    820 | loss 2.1901 | lr 3.00e-04 | grad 2.12 | tok/s 23410
step    830 | loss 2.2417 | lr 3.00e-04 | grad 1.63 | tok/s 23878
step    840 | loss 2.3776 | lr 3.00e-04 | grad 2.45 | tok/s 24733
step    850 | loss 2.3583 | lr 3.00e-04 | grad 6.16 | tok/s 24629
step    860 | loss 2.2532 | lr 3.00e-04 | grad 2.16 | tok/s 24521
step    870 | loss 2.1627 | lr 3.00e-04 | grad 1.40 | tok/s 23635
step    880 | loss 2.2262 | lr 3.00e-04 | grad 2.31 | tok/s 23456
step    890 | loss 2.2698 | lr 3.00e-04 | grad 1.15 | tok/s 23916
step    900 | loss 2.2054 | lr 3.00e-04 | grad 1.95 | tok/s 23980
step    910 | loss 1.9836 | lr 3.00e-04 | grad 1.50 | tok/s 23336
step    920 | loss 2.3093 | lr 3.00e-04 | grad 2.17 | tok/s 24428
step    930 | loss 2.1523 | lr 3.00e-04 | grad 1.84 | tok/s 23497
step    940 | loss 2.2367 | lr 3.00e-04 | grad 1.88 | tok/s 23816
step    950 | loss 2.2990 | lr 3.00e-04 | grad 1.87 | tok/s 24631
step    960 | loss 2.1408 | lr 3.00e-04 | grad 1.34 | tok/s 24747
step    970 | loss 2.1784 | lr 3.00e-04 | grad 1.50 | tok/s 23638
step    980 | loss 2.3029 | lr 3.00e-04 | grad 1.31 | tok/s 23807
step    990 | loss 2.0707 | lr 3.00e-04 | grad 1.79 | tok/s 23793
step   1000 | loss 2.1646 | lr 3.00e-04 | grad 1.99 | tok/s 23459
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1646.pt
step   1010 | loss 2.3913 | lr 3.00e-04 | grad 1.95 | tok/s 10802
step   1020 | loss 2.1765 | lr 3.00e-04 | grad 2.92 | tok/s 22673
step   1030 | loss 2.0286 | lr 3.00e-04 | grad 3.36 | tok/s 22599
step   1040 | loss 2.0273 | lr 3.00e-04 | grad 1.52 | tok/s 24415
step   1050 | loss 2.0100 | lr 3.00e-04 | grad 1.83 | tok/s 22705
step   1060 | loss 2.2171 | lr 3.00e-04 | grad 2.44 | tok/s 24222
step   1070 | loss 2.3833 | lr 3.00e-04 | grad 2.77 | tok/s 24378
step   1080 | loss 2.2386 | lr 3.00e-04 | grad 1.97 | tok/s 23254
step   1090 | loss 1.9968 | lr 3.00e-04 | grad 1.69 | tok/s 22685
step   1100 | loss 1.5878 | lr 3.00e-04 | grad 1.56 | tok/s 24344
step   1110 | loss 2.1153 | lr 3.00e-04 | grad 1.69 | tok/s 24063
step   1120 | loss 2.0505 | lr 3.00e-04 | grad 2.05 | tok/s 24737
step   1130 | loss 2.0327 | lr 3.00e-04 | grad 2.20 | tok/s 24734
step   1140 | loss 1.9660 | lr 3.00e-04 | grad 2.17 | tok/s 24743
step   1150 | loss 1.9617 | lr 3.00e-04 | grad 1.87 | tok/s 24751
step   1160 | loss 1.9194 | lr 3.00e-04 | grad 2.12 | tok/s 24763
step   1170 | loss 1.8632 | lr 3.00e-04 | grad 1.95 | tok/s 24746
step   1180 | loss 1.9887 | lr 3.00e-04 | grad 2.05 | tok/s 24736
step   1190 | loss 1.9889 | lr 3.00e-04 | grad 1.41 | tok/s 24726
step   1200 | loss 1.9080 | lr 3.00e-04 | grad 2.91 | tok/s 24733
step   1210 | loss 1.9420 | lr 3.00e-04 | grad 1.90 | tok/s 24749
step   1220 | loss 1.8912 | lr 3.00e-04 | grad 2.27 | tok/s 24774
step   1230 | loss 1.8468 | lr 3.00e-04 | grad 1.40 | tok/s 24778
step   1240 | loss 1.8939 | lr 3.00e-04 | grad 2.11 | tok/s 24711
step   1250 | loss 2.2688 | lr 3.00e-04 | grad 2.50 | tok/s 23859
step   1260 | loss 2.1234 | lr 3.00e-04 | grad 2.00 | tok/s 23116
step   1270 | loss 1.8713 | lr 3.00e-04 | grad 2.42 | tok/s 23842
step   1280 | loss 2.1715 | lr 3.00e-04 | grad 1.59 | tok/s 22726
step   1290 | loss 2.0591 | lr 3.00e-04 | grad 1.83 | tok/s 24137
step   1300 | loss 2.0962 | lr 3.00e-04 | grad 1.58 | tok/s 24262
step   1310 | loss 1.9733 | lr 3.00e-04 | grad 1.89 | tok/s 23495
step   1320 | loss 2.0508 | lr 3.00e-04 | grad 2.19 | tok/s 24177
step   1330 | loss 2.2534 | lr 3.00e-04 | grad 1.70 | tok/s 24666
step   1340 | loss 1.9926 | lr 3.00e-04 | grad 2.23 | tok/s 23550
step   1350 | loss 2.2507 | lr 3.00e-04 | grad 2.20 | tok/s 22755
step   1360 | loss 2.1844 | lr 3.00e-04 | grad 2.09 | tok/s 23452
step   1370 | loss 1.9669 | lr 3.00e-04 | grad 1.91 | tok/s 23360
step   1380 | loss 2.1917 | lr 3.00e-04 | grad 2.16 | tok/s 23974
step   1390 | loss 2.0563 | lr 3.00e-04 | grad 2.23 | tok/s 22620
step   1400 | loss 1.8755 | lr 3.00e-04 | grad 2.34 | tok/s 23233
step   1410 | loss 2.1517 | lr 3.00e-04 | grad 1.96 | tok/s 23639
step   1420 | loss 2.0841 | lr 3.00e-04 | grad 1.34 | tok/s 23049
step   1430 | loss 2.1723 | lr 3.00e-04 | grad 1.71 | tok/s 24208
step   1440 | loss 1.9129 | lr 3.00e-04 | grad 2.14 | tok/s 23583
step   1450 | loss 1.8751 | lr 3.00e-04 | grad 2.48 | tok/s 24737
step   1460 | loss 2.0675 | lr 3.00e-04 | grad 1.75 | tok/s 24009
step   1470 | loss 2.1045 | lr 3.00e-04 | grad 2.25 | tok/s 23271
step   1480 | loss 2.1538 | lr 3.00e-04 | grad 3.09 | tok/s 24264
step   1490 | loss 2.8705 | lr 3.00e-04 | grad 2.11 | tok/s 24733
step   1500 | loss 2.1574 | lr 3.00e-04 | grad 2.20 | tok/s 24597
step   1510 | loss 1.9967 | lr 3.00e-04 | grad 3.98 | tok/s 24420
step   1520 | loss 2.1230 | lr 3.00e-04 | grad 2.06 | tok/s 24680
step   1530 | loss 1.9721 | lr 3.00e-04 | grad 2.27 | tok/s 23898
step   1540 | loss 2.0377 | lr 3.00e-04 | grad 3.28 | tok/s 23650
step   1550 | loss 2.0454 | lr 3.00e-04 | grad 2.45 | tok/s 23827
step   1560 | loss 1.9078 | lr 3.00e-04 | grad 1.82 | tok/s 24353
step   1570 | loss 2.0330 | lr 3.00e-04 | grad 1.82 | tok/s 23437
step   1580 | loss 2.0532 | lr 3.00e-04 | grad 1.97 | tok/s 24152
step   1590 | loss 2.7446 | lr 3.00e-04 | grad 2.17 | tok/s 24626
step   1600 | loss 1.9470 | lr 3.00e-04 | grad 1.89 | tok/s 23343
step   1610 | loss 1.2746 | lr 3.00e-04 | grad 2.23 | tok/s 24752
step   1620 | loss 1.7888 | lr 3.00e-04 | grad 1.64 | tok/s 22121
step   1630 | loss 2.2550 | lr 3.00e-04 | grad 2.36 | tok/s 23656
step   1640 | loss 1.9247 | lr 3.00e-04 | grad 2.53 | tok/s 24580
step   1650 | loss 1.9460 | lr 3.00e-04 | grad 1.80 | tok/s 22502
step   1660 | loss 2.0679 | lr 3.00e-04 | grad 2.02 | tok/s 22823
step   1670 | loss 1.9433 | lr 3.00e-04 | grad 1.46 | tok/s 24398
step   1680 | loss 2.3806 | lr 3.00e-04 | grad 1.84 | tok/s 22765
step   1690 | loss 1.9731 | lr 3.00e-04 | grad 2.44 | tok/s 23253
step   1700 | loss 2.1699 | lr 3.00e-04 | grad 2.05 | tok/s 24274
step   1710 | loss 1.9656 | lr 3.00e-04 | grad 1.91 | tok/s 23194
step   1720 | loss 2.0776 | lr 3.00e-04 | grad 1.94 | tok/s 24114
step   1730 | loss 2.2751 | lr 3.00e-04 | grad 2.45 | tok/s 24654
step   1740 | loss 2.2816 | lr 3.00e-04 | grad 1.52 | tok/s 24662
step   1750 | loss 2.0310 | lr 3.00e-04 | grad 2.31 | tok/s 23633
step   1760 | loss 2.0081 | lr 3.00e-04 | grad 2.03 | tok/s 23660
step   1770 | loss 2.0361 | lr 3.00e-04 | grad 1.86 | tok/s 23730
step   1780 | loss 1.9691 | lr 3.00e-04 | grad 2.38 | tok/s 23430
step   1790 | loss 1.8992 | lr 3.00e-04 | grad 2.41 | tok/s 23830
step   1800 | loss 1.9596 | lr 3.00e-04 | grad 2.27 | tok/s 23748
step   1810 | loss 2.1030 | lr 3.00e-04 | grad 2.41 | tok/s 23258
step   1820 | loss 1.9809 | lr 3.00e-04 | grad 2.56 | tok/s 23066
step   1830 | loss 2.0262 | lr 3.00e-04 | grad 2.02 | tok/s 24211
step   1840 | loss 2.0223 | lr 3.00e-04 | grad 3.84 | tok/s 23730
step   1850 | loss 1.9384 | lr 3.00e-04 | grad 1.92 | tok/s 23330
step   1860 | loss 1.9692 | lr 3.00e-04 | grad 3.11 | tok/s 24099
step   1870 | loss 1.8893 | lr 3.00e-04 | grad 1.50 | tok/s 23043
step   1880 | loss 1.8502 | lr 3.00e-04 | grad 1.84 | tok/s 23971
step   1890 | loss 2.0197 | lr 3.00e-04 | grad 1.54 | tok/s 21963
step   1900 | loss 1.9104 | lr 3.00e-04 | grad 2.05 | tok/s 23751
step   1910 | loss 1.8425 | lr 3.00e-04 | grad 1.58 | tok/s 22746
step   1920 | loss 1.9304 | lr 3.00e-04 | grad 1.68 | tok/s 23521
step   1930 | loss 1.9003 | lr 3.00e-04 | grad 1.77 | tok/s 24120
step   1940 | loss 1.9111 | lr 3.00e-04 | grad 2.94 | tok/s 23273
step   1950 | loss 2.2693 | lr 3.00e-04 | grad 3.00 | tok/s 24227
step   1960 | loss 2.6873 | lr 3.00e-04 | grad 1.82 | tok/s 24656
step   1970 | loss 2.3402 | lr 3.00e-04 | grad 2.94 | tok/s 24111
step   1980 | loss 2.1961 | lr 3.00e-04 | grad 1.36 | tok/s 23932
step   1990 | loss 1.8872 | lr 3.00e-04 | grad 1.68 | tok/s 23437
step   2000 | loss 2.1813 | lr 3.00e-04 | grad 2.47 | tok/s 23599
  >>> saved checkpoint: checkpoint_step_002000_loss_2.1813.pt
step   2010 | loss 1.7452 | lr 3.00e-04 | grad 2.56 | tok/s 11068
step   2020 | loss 1.5520 | lr 3.00e-04 | grad 2.05 | tok/s 24227
step   2030 | loss 1.8900 | lr 3.00e-04 | grad 1.75 | tok/s 24059
step   2040 | loss 1.4918 | lr 3.00e-04 | grad 1.70 | tok/s 24812
step   2050 | loss 2.1094 | lr 3.00e-04 | grad 1.82 | tok/s 24689
step   2060 | loss 1.9893 | lr 3.00e-04 | grad 2.28 | tok/s 23685
step   2070 | loss 2.1201 | lr 3.00e-04 | grad 1.65 | tok/s 23291
step   2080 | loss 2.2889 | lr 3.00e-04 | grad 5.22 | tok/s 23413
step   2090 | loss 2.4893 | lr 3.00e-04 | grad 2.94 | tok/s 24636
step   2100 | loss 2.0642 | lr 3.00e-04 | grad 2.67 | tok/s 24019
step   2110 | loss 2.1200 | lr 3.00e-04 | grad 1.66 | tok/s 24443
step   2120 | loss 1.9956 | lr 3.00e-04 | grad 2.12 | tok/s 23086
step   2130 | loss 1.1196 | lr 3.00e-04 | grad 0.95 | tok/s 24965
step   2140 | loss 1.9685 | lr 3.00e-04 | grad 2.03 | tok/s 23415
step   2150 | loss 1.9099 | lr 3.00e-04 | grad 2.09 | tok/s 24424
step   2160 | loss 1.7896 | lr 3.00e-04 | grad 2.20 | tok/s 24705
step   2170 | loss 1.7521 | lr 3.00e-04 | grad 2.11 | tok/s 24717
step   2180 | loss 1.7485 | lr 3.00e-04 | grad 2.31 | tok/s 24730
step   2190 | loss 1.7304 | lr 3.00e-04 | grad 1.62 | tok/s 24713
step   2200 | loss 1.7343 | lr 3.00e-04 | grad 1.78 | tok/s 24694
step   2210 | loss 1.7026 | lr 3.00e-04 | grad 1.90 | tok/s 24733
step   2220 | loss 1.6675 | lr 3.00e-04 | grad 1.79 | tok/s 24719
step   2230 | loss 1.6488 | lr 3.00e-04 | grad 2.02 | tok/s 24717
step   2240 | loss 1.9114 | lr 3.00e-04 | grad 2.38 | tok/s 24237
step   2250 | loss 1.9123 | lr 3.00e-04 | grad 2.23 | tok/s 23879
step   2260 | loss 2.3353 | lr 3.00e-04 | grad 2.20 | tok/s 24734
step   2270 | loss 2.1213 | lr 3.00e-04 | grad 1.58 | tok/s 23870
step   2280 | loss 2.4390 | lr 3.00e-04 | grad 1.90 | tok/s 24456
step   2290 | loss 1.9887 | lr 3.00e-04 | grad 2.09 | tok/s 24714
step   2300 | loss 2.0977 | lr 3.00e-04 | grad 1.32 | tok/s 23564
step   2310 | loss 2.4664 | lr 3.00e-04 | grad 2.52 | tok/s 24050
step   2320 | loss 2.0664 | lr 3.00e-04 | grad 3.88 | tok/s 23509
step   2330 | loss 2.2716 | lr 3.00e-04 | grad 2.56 | tok/s 23415
step   2340 | loss 1.8930 | lr 3.00e-04 | grad 1.79 | tok/s 22873
step   2350 | loss 1.9972 | lr 3.00e-04 | grad 2.17 | tok/s 23565
step   2360 | loss 1.9158 | lr 3.00e-04 | grad 1.71 | tok/s 24235
step   2370 | loss 1.8597 | lr 3.00e-04 | grad 1.71 | tok/s 24546
step   2380 | loss 2.2028 | lr 3.00e-04 | grad 2.59 | tok/s 24429
step   2390 | loss 2.2055 | lr 3.00e-04 | grad 2.08 | tok/s 24759
step   2400 | loss 1.7265 | lr 3.00e-04 | grad 1.21 | tok/s 24741
step   2410 | loss 1.6882 | lr 3.00e-04 | grad 2.69 | tok/s 24754
step   2420 | loss 1.6450 | lr 3.00e-04 | grad 2.27 | tok/s 23663
step   2430 | loss 1.9379 | lr 3.00e-04 | grad 2.08 | tok/s 22523
step   2440 | loss 1.8225 | lr 3.00e-04 | grad 1.67 | tok/s 24651
step   2450 | loss 1.9649 | lr 3.00e-04 | grad 1.77 | tok/s 23835
step   2460 | loss 1.9013 | lr 3.00e-04 | grad 2.19 | tok/s 23794
step   2470 | loss 1.7354 | lr 3.00e-04 | grad 2.11 | tok/s 24780
step   2480 | loss 1.7992 | lr 3.00e-04 | grad 2.20 | tok/s 24382
step   2490 | loss 1.8474 | lr 3.00e-04 | grad 1.93 | tok/s 24320
step   2500 | loss 1.8924 | lr 3.00e-04 | grad 1.34 | tok/s 23587
step   2510 | loss 2.1528 | lr 3.00e-04 | grad 2.06 | tok/s 24389
step   2520 | loss 2.0078 | lr 3.00e-04 | grad 2.86 | tok/s 24717
step   2530 | loss 2.1505 | lr 3.00e-04 | grad 1.70 | tok/s 24291
step   2540 | loss 1.7720 | lr 3.00e-04 | grad 1.73 | tok/s 23658
step   2550 | loss 1.9056 | lr 3.00e-04 | grad 2.11 | tok/s 24040
step   2560 | loss 1.7119 | lr 3.00e-04 | grad 1.68 | tok/s 24476
step   2570 | loss 2.0512 | lr 3.00e-04 | grad 1.77 | tok/s 22655
step   2580 | loss 1.8194 | lr 3.00e-04 | grad 1.62 | tok/s 23230
step   2590 | loss 1.8968 | lr 3.00e-04 | grad 1.76 | tok/s 24045
step   2600 | loss 1.9071 | lr 3.00e-04 | grad 1.45 | tok/s 22596
step   2610 | loss 2.3219 | lr 3.00e-04 | grad 3.61 | tok/s 23915
step   2620 | loss 2.0628 | lr 3.00e-04 | grad 2.05 | tok/s 24093
step   2630 | loss 1.9709 | lr 3.00e-04 | grad 2.11 | tok/s 24204
step   2640 | loss 1.9116 | lr 3.00e-04 | grad 2.91 | tok/s 24541
step   2650 | loss 2.0321 | lr 3.00e-04 | grad 1.92 | tok/s 23844
step   2660 | loss 2.1421 | lr 3.00e-04 | grad 2.09 | tok/s 24191
step   2670 | loss 1.7590 | lr 3.00e-04 | grad 1.91 | tok/s 23754
step   2680 | loss 1.9001 | lr 3.00e-04 | grad 1.54 | tok/s 23154
step   2690 | loss 2.1284 | lr 3.00e-04 | grad 1.74 | tok/s 23744
step   2700 | loss 1.8805 | lr 3.00e-04 | grad 1.94 | tok/s 24537
step   2710 | loss 1.9296 | lr 3.00e-04 | grad 2.31 | tok/s 23344
step   2720 | loss 2.1352 | lr 3.00e-04 | grad 2.83 | tok/s 23234
step   2730 | loss 1.8457 | lr 3.00e-04 | grad 2.41 | tok/s 22921
step   2740 | loss 1.7885 | lr 3.00e-04 | grad 2.16 | tok/s 24475
step   2750 | loss 2.2374 | lr 3.00e-04 | grad 1.80 | tok/s 24127
step   2760 | loss 2.0325 | lr 3.00e-04 | grad 2.55 | tok/s 24149
step   2770 | loss 1.7553 | lr 3.00e-04 | grad 1.80 | tok/s 22386
step   2780 | loss 1.9754 | lr 3.00e-04 | grad 1.68 | tok/s 24297
step   2790 | loss 1.8333 | lr 3.00e-04 | grad 2.25 | tok/s 24404
step   2800 | loss 2.2680 | lr 3.00e-04 | grad 1.99 | tok/s 22318
step   2810 | loss 1.6905 | lr 3.00e-04 | grad 2.12 | tok/s 24694
step   2820 | loss 1.8028 | lr 3.00e-04 | grad 2.09 | tok/s 22802
step   2830 | loss 1.8924 | lr 3.00e-04 | grad 2.45 | tok/s 23184
step   2840 | loss 1.8935 | lr 3.00e-04 | grad 2.97 | tok/s 24706
step   2850 | loss 1.8176 | lr 3.00e-04 | grad 3.95 | tok/s 24208
step   2860 | loss 2.2674 | lr 3.00e-04 | grad 3.69 | tok/s 23728
step   2870 | loss 2.0062 | lr 3.00e-04 | grad 1.91 | tok/s 23499
step   2880 | loss 1.8635 | lr 3.00e-04 | grad 2.42 | tok/s 23938
step   2890 | loss 1.9672 | lr 3.00e-04 | grad 2.20 | tok/s 24459
step   2900 | loss 1.9928 | lr 3.00e-04 | grad 1.43 | tok/s 24160
step   2910 | loss 1.9036 | lr 3.00e-04 | grad 3.09 | tok/s 24192
step   2920 | loss 1.8005 | lr 3.00e-04 | grad 1.77 | tok/s 23161
step   2930 | loss 2.0949 | lr 3.00e-04 | grad 2.16 | tok/s 23787
step   2940 | loss 1.8236 | lr 3.00e-04 | grad 1.66 | tok/s 23356
step   2950 | loss 1.7185 | lr 3.00e-04 | grad 1.80 | tok/s 22557
step   2960 | loss 1.8509 | lr 3.00e-04 | grad 1.77 | tok/s 24263
step   2970 | loss 1.7892 | lr 3.00e-04 | grad 2.19 | tok/s 24170
step   2980 | loss 2.0212 | lr 3.00e-04 | grad 3.62 | tok/s 23422
step   2990 | loss 2.4488 | lr 3.00e-04 | grad 6.00 | tok/s 24221
step   3000 | loss 1.9721 | lr 3.00e-04 | grad 1.93 | tok/s 24197
  >>> saved checkpoint: checkpoint_step_003000_loss_1.9721.pt
step   3010 | loss 1.8783 | lr 3.00e-04 | grad 1.79 | tok/s 10886
step   3020 | loss 1.5618 | lr 3.00e-04 | grad 1.63 | tok/s 23962
step   3030 | loss 1.8318 | lr 3.00e-04 | grad 2.23 | tok/s 23672
step   3040 | loss 1.8803 | lr 3.00e-04 | grad 3.00 | tok/s 23741
step   3050 | loss 1.8808 | lr 3.00e-04 | grad 1.74 | tok/s 24063
step   3060 | loss 1.8852 | lr 3.00e-04 | grad 1.95 | tok/s 23828
step   3070 | loss 1.7981 | lr 3.00e-04 | grad 1.65 | tok/s 24377
step   3080 | loss 2.0212 | lr 3.00e-04 | grad 2.27 | tok/s 24636
step   3090 | loss 1.8042 | lr 3.00e-04 | grad 1.82 | tok/s 23997
step   3100 | loss 1.8574 | lr 3.00e-04 | grad 2.48 | tok/s 23949
step   3110 | loss 1.9466 | lr 3.00e-04 | grad 1.68 | tok/s 23711
step   3120 | loss 1.7828 | lr 3.00e-04 | grad 1.76 | tok/s 24748
step   3130 | loss 1.6112 | lr 3.00e-04 | grad 1.88 | tok/s 24736
step   3140 | loss 1.9043 | lr 3.00e-04 | grad 2.27 | tok/s 23380
step   3150 | loss 1.6919 | lr 3.00e-04 | grad 1.80 | tok/s 24727
step   3160 | loss 1.7549 | lr 3.00e-04 | grad 1.88 | tok/s 24504
step   3170 | loss 2.0088 | lr 3.00e-04 | grad 10.94 | tok/s 23367
step   3180 | loss 1.7475 | lr 3.00e-04 | grad 1.65 | tok/s 23485
step   3190 | loss 1.7895 | lr 3.00e-04 | grad 1.80 | tok/s 23596
step   3200 | loss 1.5182 | lr 3.00e-04 | grad 2.23 | tok/s 24373
step   3210 | loss 1.9372 | lr 3.00e-04 | grad 2.64 | tok/s 23874
step   3220 | loss 2.1768 | lr 3.00e-04 | grad 3.06 | tok/s 24330
step   3230 | loss 2.4514 | lr 3.00e-04 | grad 2.08 | tok/s 24456
step   3240 | loss 2.2863 | lr 3.00e-04 | grad 2.08 | tok/s 24745
step   3250 | loss 2.1768 | lr 3.00e-04 | grad 1.38 | tok/s 24725
step   3260 | loss 2.1503 | lr 3.00e-04 | grad 2.09 | tok/s 24747
step   3270 | loss 2.0671 | lr 3.00e-04 | grad 1.99 | tok/s 24733
step   3280 | loss 2.0433 | lr 3.00e-04 | grad 2.75 | tok/s 24702
step   3290 | loss 1.9633 | lr 3.00e-04 | grad 2.44 | tok/s 24713
step   3300 | loss 1.9813 | lr 3.00e-04 | grad 1.99 | tok/s 24699
step   3310 | loss 1.9543 | lr 3.00e-04 | grad 1.73 | tok/s 24716
step   3320 | loss 1.8986 | lr 3.00e-04 | grad 2.28 | tok/s 24708
step   3330 | loss 1.9103 | lr 3.00e-04 | grad 2.88 | tok/s 24725
step   3340 | loss 2.0896 | lr 3.00e-04 | grad 2.47 | tok/s 24338
step   3350 | loss 1.9469 | lr 3.00e-04 | grad 3.05 | tok/s 23560
step   3360 | loss 1.8735 | lr 3.00e-04 | grad 2.25 | tok/s 23868
step   3370 | loss 1.7737 | lr 3.00e-04 | grad 1.52 | tok/s 22697
step   3380 | loss 1.8879 | lr 3.00e-04 | grad 1.94 | tok/s 23091
step   3390 | loss 1.8862 | lr 3.00e-04 | grad 2.05 | tok/s 23825
step   3400 | loss 1.8060 | lr 3.00e-04 | grad 2.19 | tok/s 23948
step   3410 | loss 1.6318 | lr 3.00e-04 | grad 1.94 | tok/s 24751
step   3420 | loss 1.6170 | lr 3.00e-04 | grad 2.44 | tok/s 24726
step   3430 | loss 1.9423 | lr 3.00e-04 | grad 1.84 | tok/s 23044
step   3440 | loss 1.8312 | lr 3.00e-04 | grad 2.17 | tok/s 24077
step   3450 | loss 1.8759 | lr 3.00e-04 | grad 2.12 | tok/s 23422
step   3460 | loss 1.8470 | lr 3.00e-04 | grad 2.45 | tok/s 23951
step   3470 | loss 1.9869 | lr 3.00e-04 | grad 2.66 | tok/s 24111
step   3480 | loss 1.8118 | lr 3.00e-04 | grad 1.84 | tok/s 24274
step   3490 | loss 1.8402 | lr 3.00e-04 | grad 1.84 | tok/s 24735
step   3500 | loss 1.7042 | lr 3.00e-04 | grad 1.95 | tok/s 22884
step   3510 | loss 1.7026 | lr 3.00e-04 | grad 1.49 | tok/s 24128
step   3520 | loss 1.8274 | lr 3.00e-04 | grad 1.62 | tok/s 23755
step   3530 | loss 1.9489 | lr 3.00e-04 | grad 2.14 | tok/s 23482
step   3540 | loss 2.3280 | lr 3.00e-04 | grad 3.42 | tok/s 24665

Training complete! Final step: 3549
