Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_46/levelmingru_100m_20260126_210547
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 191,437,056 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.7120 | lr 3.00e-04 | grad 2.62 | tok/s 16611
step     20 | loss 3.1806 | lr 3.00e-04 | grad 3.28 | tok/s 23934
step     30 | loss 2.9936 | lr 3.00e-04 | grad 3.41 | tok/s 24089
step     40 | loss 2.9284 | lr 3.00e-04 | grad 2.11 | tok/s 23023
step     50 | loss 2.8629 | lr 3.00e-04 | grad 10.38 | tok/s 22987
step     60 | loss 3.6460 | lr 3.00e-04 | grad 1.57 | tok/s 24507
step     70 | loss 2.7044 | lr 3.00e-04 | grad 2.81 | tok/s 24558
step     80 | loss 4.3079 | lr 3.00e-04 | grad 11.62 | tok/s 24474
step     90 | loss 4.9880 | lr 3.00e-04 | grad 7.00 | tok/s 25166
step    100 | loss 3.9634 | lr 3.00e-04 | grad 4.16 | tok/s 25153
step    110 | loss 3.8460 | lr 3.00e-04 | grad 4.69 | tok/s 25185
step    120 | loss 3.8086 | lr 3.00e-04 | grad 4.97 | tok/s 25172
step    130 | loss 3.9708 | lr 3.00e-04 | grad 3.69 | tok/s 25164
step    140 | loss 3.5131 | lr 3.00e-04 | grad 6.03 | tok/s 25168
step    150 | loss 3.7321 | lr 3.00e-04 | grad 6.97 | tok/s 25161
step    160 | loss 3.5959 | lr 3.00e-04 | grad 5.22 | tok/s 25160
step    170 | loss 3.4161 | lr 3.00e-04 | grad 4.50 | tok/s 25148
step    180 | loss 3.5164 | lr 3.00e-04 | grad 3.11 | tok/s 25158
step    190 | loss 3.4174 | lr 3.00e-04 | grad 4.44 | tok/s 25128
step    200 | loss 3.4406 | lr 3.00e-04 | grad 2.25 | tok/s 25117
step    210 | loss 3.2938 | lr 3.00e-04 | grad 3.42 | tok/s 25117
step    220 | loss 3.2003 | lr 3.00e-04 | grad 5.34 | tok/s 24805
step    230 | loss 3.1148 | lr 3.00e-04 | grad 6.91 | tok/s 24792
step    240 | loss 3.3547 | lr 3.00e-04 | grad 2.36 | tok/s 23462
step    250 | loss 2.7293 | lr 3.00e-04 | grad 1.64 | tok/s 23671
step    260 | loss 2.5440 | lr 3.00e-04 | grad 1.71 | tok/s 24825
step    270 | loss 2.6368 | lr 3.00e-04 | grad 4.78 | tok/s 23920
step    280 | loss 2.6086 | lr 3.00e-04 | grad 3.80 | tok/s 24555
step    290 | loss 3.1082 | lr 3.00e-04 | grad 2.77 | tok/s 24416
step    300 | loss 2.3060 | lr 3.00e-04 | grad 2.00 | tok/s 25114
step    310 | loss 2.7135 | lr 3.00e-04 | grad 2.17 | tok/s 24683
step    320 | loss 2.9306 | lr 3.00e-04 | grad 1.25 | tok/s 25050
step    330 | loss 2.5580 | lr 3.00e-04 | grad 1.91 | tok/s 22650
step    340 | loss 2.7375 | lr 3.00e-04 | grad 1.09 | tok/s 24038
step    350 | loss 2.5477 | lr 3.00e-04 | grad 1.60 | tok/s 23741
step    360 | loss 2.9763 | lr 3.00e-04 | grad 1.25 | tok/s 25057
step    370 | loss 2.6347 | lr 3.00e-04 | grad 2.20 | tok/s 22998
step    380 | loss 2.4069 | lr 3.00e-04 | grad 1.57 | tok/s 23528
step    390 | loss 2.3269 | lr 3.00e-04 | grad 1.79 | tok/s 24812
step    400 | loss 2.2816 | lr 3.00e-04 | grad 1.72 | tok/s 24828
step    410 | loss 2.3732 | lr 3.00e-04 | grad 1.50 | tok/s 25059
step    420 | loss 2.2094 | lr 3.00e-04 | grad 1.43 | tok/s 22881
step    430 | loss 2.5997 | lr 3.00e-04 | grad 1.91 | tok/s 24360
step    440 | loss 2.7478 | lr 3.00e-04 | grad 1.52 | tok/s 23931
step    450 | loss 3.1661 | lr 3.00e-04 | grad 6.94 | tok/s 24011
step    460 | loss 2.5146 | lr 3.00e-04 | grad 1.79 | tok/s 23499
step    470 | loss 2.4909 | lr 3.00e-04 | grad 1.26 | tok/s 23907
step    480 | loss 2.4810 | lr 3.00e-04 | grad 1.36 | tok/s 24353
step    490 | loss 2.9156 | lr 3.00e-04 | grad 1.80 | tok/s 24076
step    500 | loss 2.2440 | lr 3.00e-04 | grad 1.63 | tok/s 23708
step    510 | loss 2.4338 | lr 3.00e-04 | grad 1.41 | tok/s 24726
step    520 | loss 2.4319 | lr 3.00e-04 | grad 0.93 | tok/s 24871
step    530 | loss 2.5462 | lr 3.00e-04 | grad 1.56 | tok/s 24580
step    540 | loss 2.3327 | lr 3.00e-04 | grad 1.38 | tok/s 23938
step    550 | loss 2.1721 | lr 3.00e-04 | grad 1.62 | tok/s 23915
step    560 | loss 2.2496 | lr 3.00e-04 | grad 4.31 | tok/s 21862
step    570 | loss 2.3037 | lr 3.00e-04 | grad 1.35 | tok/s 23951
step    580 | loss 2.2078 | lr 3.00e-04 | grad 1.28 | tok/s 23465
step    590 | loss 2.1608 | lr 3.00e-04 | grad 1.38 | tok/s 23186
step    600 | loss 2.6354 | lr 3.00e-04 | grad 1.53 | tok/s 23759
step    610 | loss 2.2793 | lr 3.00e-04 | grad 1.63 | tok/s 23765
step    620 | loss 2.1190 | lr 3.00e-04 | grad 1.91 | tok/s 23623
step    630 | loss 2.2105 | lr 3.00e-04 | grad 2.62 | tok/s 23147
step    640 | loss 2.4285 | lr 3.00e-04 | grad 2.66 | tok/s 23714
step    650 | loss 2.3556 | lr 3.00e-04 | grad 2.34 | tok/s 23929
step    660 | loss 2.2721 | lr 3.00e-04 | grad 1.49 | tok/s 24315
step    670 | loss 2.2027 | lr 3.00e-04 | grad 1.53 | tok/s 23740
step    680 | loss 2.6660 | lr 3.00e-04 | grad 2.09 | tok/s 24745
step    690 | loss 2.4454 | lr 3.00e-04 | grad 1.71 | tok/s 23455
step    700 | loss 2.5703 | lr 3.00e-04 | grad 1.88 | tok/s 25071
step    710 | loss 2.3853 | lr 3.00e-04 | grad 1.86 | tok/s 24376
step    720 | loss 1.9918 | lr 3.00e-04 | grad 1.60 | tok/s 22103
step    730 | loss 2.3599 | lr 3.00e-04 | grad 1.81 | tok/s 25044
step    740 | loss 2.1515 | lr 3.00e-04 | grad 1.33 | tok/s 24620
step    750 | loss 2.2270 | lr 3.00e-04 | grad 1.64 | tok/s 25058
step    760 | loss 2.0391 | lr 3.00e-04 | grad 1.59 | tok/s 25057
step    770 | loss 2.0966 | lr 3.00e-04 | grad 1.86 | tok/s 25057
step    780 | loss 2.0411 | lr 3.00e-04 | grad 1.98 | tok/s 25048
step    790 | loss 1.9833 | lr 3.00e-04 | grad 1.58 | tok/s 25048
step    800 | loss 2.2375 | lr 3.00e-04 | grad 2.47 | tok/s 23401
step    810 | loss 2.4547 | lr 3.00e-04 | grad 1.62 | tok/s 24054
step    820 | loss 2.2085 | lr 3.00e-04 | grad 2.12 | tok/s 23731
step    830 | loss 2.2739 | lr 3.00e-04 | grad 1.48 | tok/s 24174
step    840 | loss 2.4073 | lr 3.00e-04 | grad 1.91 | tok/s 25035
step    850 | loss 2.3852 | lr 3.00e-04 | grad 5.41 | tok/s 24912
step    860 | loss 2.2928 | lr 3.00e-04 | grad 1.98 | tok/s 24803
step    870 | loss 2.1892 | lr 3.00e-04 | grad 1.14 | tok/s 23939
step    880 | loss 2.2534 | lr 3.00e-04 | grad 1.98 | tok/s 23804
step    890 | loss 2.2901 | lr 3.00e-04 | grad 0.98 | tok/s 24242
step    900 | loss 2.2231 | lr 3.00e-04 | grad 1.73 | tok/s 24289
step    910 | loss 2.0073 | lr 3.00e-04 | grad 1.52 | tok/s 23637
step    920 | loss 2.3504 | lr 3.00e-04 | grad 1.66 | tok/s 24746
step    930 | loss 2.1710 | lr 3.00e-04 | grad 1.66 | tok/s 23808
step    940 | loss 2.2630 | lr 3.00e-04 | grad 1.75 | tok/s 24129
step    950 | loss 2.3268 | lr 3.00e-04 | grad 1.74 | tok/s 24929
step    960 | loss 2.1886 | lr 3.00e-04 | grad 1.85 | tok/s 25051
step    970 | loss 2.2068 | lr 3.00e-04 | grad 1.12 | tok/s 23947
step    980 | loss 2.3261 | lr 3.00e-04 | grad 1.18 | tok/s 24103
step    990 | loss 2.0952 | lr 3.00e-04 | grad 1.51 | tok/s 24076
step   1000 | loss 2.1819 | lr 3.00e-04 | grad 1.66 | tok/s 23786
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1819.pt
step   1010 | loss 2.5498 | lr 3.00e-04 | grad 4.00 | tok/s 12681
step   1020 | loss 2.1796 | lr 3.00e-04 | grad 1.19 | tok/s 22956
step   1030 | loss 2.0846 | lr 3.00e-04 | grad 1.37 | tok/s 22665
step   1040 | loss 2.0690 | lr 3.00e-04 | grad 2.27 | tok/s 24642
step   1050 | loss 2.0568 | lr 3.00e-04 | grad 1.34 | tok/s 23458
step   1060 | loss 2.1747 | lr 3.00e-04 | grad 1.48 | tok/s 24001
step   1070 | loss 2.3917 | lr 3.00e-04 | grad 1.64 | tok/s 24628
step   1080 | loss 2.3569 | lr 3.00e-04 | grad 2.23 | tok/s 23762
step   1090 | loss 2.0041 | lr 3.00e-04 | grad 2.06 | tok/s 22764
step   1100 | loss 1.6165 | lr 3.00e-04 | grad 1.59 | tok/s 24571
step   1110 | loss 2.1425 | lr 3.00e-04 | grad 1.38 | tok/s 24381
step   1120 | loss 2.0742 | lr 3.00e-04 | grad 1.26 | tok/s 25076
step   1130 | loss 2.0720 | lr 3.00e-04 | grad 1.73 | tok/s 25037
step   1140 | loss 1.9998 | lr 3.00e-04 | grad 1.36 | tok/s 25058
step   1150 | loss 1.9956 | lr 3.00e-04 | grad 1.62 | tok/s 25057
step   1160 | loss 1.9629 | lr 3.00e-04 | grad 1.57 | tok/s 25036
step   1170 | loss 1.8916 | lr 3.00e-04 | grad 1.95 | tok/s 25063
step   1180 | loss 1.9944 | lr 3.00e-04 | grad 1.84 | tok/s 25051
step   1190 | loss 2.0439 | lr 3.00e-04 | grad 1.67 | tok/s 25047
step   1200 | loss 1.9468 | lr 3.00e-04 | grad 1.45 | tok/s 25053
step   1210 | loss 1.9781 | lr 3.00e-04 | grad 1.95 | tok/s 25058
step   1220 | loss 1.9252 | lr 3.00e-04 | grad 1.48 | tok/s 25037
step   1230 | loss 1.8782 | lr 3.00e-04 | grad 2.59 | tok/s 25048
step   1240 | loss 1.9297 | lr 3.00e-04 | grad 1.80 | tok/s 25049
step   1250 | loss 2.1448 | lr 3.00e-04 | grad 2.98 | tok/s 24168
step   1260 | loss 2.1686 | lr 3.00e-04 | grad 1.39 | tok/s 23407
step   1270 | loss 1.9286 | lr 3.00e-04 | grad 1.78 | tok/s 24126
step   1280 | loss 2.1753 | lr 3.00e-04 | grad 1.76 | tok/s 23246
step   1290 | loss 2.1359 | lr 3.00e-04 | grad 1.70 | tok/s 24439
step   1300 | loss 2.0956 | lr 3.00e-04 | grad 1.78 | tok/s 24405
step   1310 | loss 2.0201 | lr 3.00e-04 | grad 1.80 | tok/s 23771
step   1320 | loss 2.0588 | lr 3.00e-04 | grad 1.77 | tok/s 24745
step   1330 | loss 2.3010 | lr 3.00e-04 | grad 2.06 | tok/s 24727
step   1340 | loss 2.0485 | lr 3.00e-04 | grad 1.55 | tok/s 24193
step   1350 | loss 2.2281 | lr 3.00e-04 | grad 2.34 | tok/s 22761
step   1360 | loss 2.2048 | lr 3.00e-04 | grad 1.55 | tok/s 23724
step   1370 | loss 2.0279 | lr 3.00e-04 | grad 1.98 | tok/s 23689
step   1380 | loss 2.2342 | lr 3.00e-04 | grad 1.56 | tok/s 24508
step   1390 | loss 2.0750 | lr 3.00e-04 | grad 1.39 | tok/s 22681
step   1400 | loss 1.9082 | lr 3.00e-04 | grad 2.11 | tok/s 23758
step   1410 | loss 2.1636 | lr 3.00e-04 | grad 1.64 | tok/s 24125
step   1420 | loss 2.1628 | lr 3.00e-04 | grad 1.72 | tok/s 23342
step   1430 | loss 2.1854 | lr 3.00e-04 | grad 2.02 | tok/s 24102
step   1440 | loss 1.9594 | lr 3.00e-04 | grad 1.76 | tok/s 23843
step   1450 | loss 1.9245 | lr 3.00e-04 | grad 2.23 | tok/s 25066
step   1460 | loss 2.0965 | lr 3.00e-04 | grad 2.23 | tok/s 24469
step   1470 | loss 2.1285 | lr 3.00e-04 | grad 1.45 | tok/s 23432
step   1480 | loss 2.0713 | lr 3.00e-04 | grad 1.12 | tok/s 24600
step   1490 | loss 2.9334 | lr 3.00e-04 | grad 2.95 | tok/s 25090
step   1500 | loss 2.2665 | lr 3.00e-04 | grad 1.73 | tok/s 24936
step   1510 | loss 1.9486 | lr 3.00e-04 | grad 1.81 | tok/s 24759
step   1520 | loss 2.2249 | lr 3.00e-04 | grad 1.84 | tok/s 25009
step   1530 | loss 1.9892 | lr 3.00e-04 | grad 1.69 | tok/s 24230
step   1540 | loss 1.9945 | lr 3.00e-04 | grad 2.59 | tok/s 23964
step   1550 | loss 2.1579 | lr 3.00e-04 | grad 1.26 | tok/s 24163
step   1560 | loss 1.9010 | lr 3.00e-04 | grad 1.86 | tok/s 24774
step   1570 | loss 2.0858 | lr 3.00e-04 | grad 1.98 | tok/s 23691
step   1580 | loss 2.0763 | lr 3.00e-04 | grad 1.80 | tok/s 24816
step   1590 | loss 2.7445 | lr 3.00e-04 | grad 1.58 | tok/s 24640
step   1600 | loss 2.0558 | lr 3.00e-04 | grad 2.06 | tok/s 23599
step   1610 | loss 1.2901 | lr 3.00e-04 | grad 1.22 | tok/s 25163
step   1620 | loss 1.8206 | lr 3.00e-04 | grad 1.34 | tok/s 22709
step   1630 | loss 2.2280 | lr 3.00e-04 | grad 2.39 | tok/s 23799
step   1640 | loss 1.9682 | lr 3.00e-04 | grad 1.92 | tok/s 24757
step   1650 | loss 2.0249 | lr 3.00e-04 | grad 1.19 | tok/s 23321
step   1660 | loss 2.0438 | lr 3.00e-04 | grad 2.34 | tok/s 22663
step   1670 | loss 1.9984 | lr 3.00e-04 | grad 1.94 | tok/s 25050
step   1680 | loss 2.3681 | lr 3.00e-04 | grad 1.59 | tok/s 23191
step   1690 | loss 1.9632 | lr 3.00e-04 | grad 1.76 | tok/s 23255
step   1700 | loss 2.2443 | lr 3.00e-04 | grad 2.20 | tok/s 24613
step   1710 | loss 2.0352 | lr 3.00e-04 | grad 1.88 | tok/s 23559
step   1720 | loss 2.1024 | lr 3.00e-04 | grad 1.62 | tok/s 24399
step   1730 | loss 2.3078 | lr 3.00e-04 | grad 1.15 | tok/s 25067
step   1740 | loss 2.3512 | lr 3.00e-04 | grad 1.88 | tok/s 25078
step   1750 | loss 2.0487 | lr 3.00e-04 | grad 1.77 | tok/s 23994
step   1760 | loss 2.0497 | lr 3.00e-04 | grad 1.50 | tok/s 24052
step   1770 | loss 2.0656 | lr 3.00e-04 | grad 1.76 | tok/s 24117
step   1780 | loss 1.9504 | lr 3.00e-04 | grad 1.77 | tok/s 23806
step   1790 | loss 1.9755 | lr 3.00e-04 | grad 1.89 | tok/s 24347
step   1800 | loss 1.9803 | lr 3.00e-04 | grad 1.56 | tok/s 23992
step   1810 | loss 2.1388 | lr 3.00e-04 | grad 1.62 | tok/s 23632
step   1820 | loss 2.0043 | lr 3.00e-04 | grad 1.52 | tok/s 23615
step   1830 | loss 2.0807 | lr 3.00e-04 | grad 2.09 | tok/s 24383
step   1840 | loss 1.9799 | lr 3.00e-04 | grad 2.22 | tok/s 24086
step   1850 | loss 2.0257 | lr 3.00e-04 | grad 2.31 | tok/s 23698
step   1860 | loss 2.0278 | lr 3.00e-04 | grad 1.50 | tok/s 24507
step   1870 | loss 1.9397 | lr 3.00e-04 | grad 1.48 | tok/s 23560
step   1880 | loss 1.8974 | lr 3.00e-04 | grad 1.59 | tok/s 24672
step   1890 | loss 2.0636 | lr 3.00e-04 | grad 1.53 | tok/s 22135
step   1900 | loss 1.9135 | lr 3.00e-04 | grad 1.82 | tok/s 23700
step   1910 | loss 1.8697 | lr 3.00e-04 | grad 1.45 | tok/s 23548
step   1920 | loss 1.9583 | lr 3.00e-04 | grad 1.81 | tok/s 23427
step   1930 | loss 1.9347 | lr 3.00e-04 | grad 1.61 | tok/s 24693
step   1940 | loss 1.9232 | lr 3.00e-04 | grad 1.34 | tok/s 23416
step   1950 | loss 2.1980 | lr 3.00e-04 | grad 2.61 | tok/s 24625
step   1960 | loss 2.7689 | lr 3.00e-04 | grad 2.69 | tok/s 25105
step   1970 | loss 2.3564 | lr 3.00e-04 | grad 1.91 | tok/s 24503
step   1980 | loss 2.3395 | lr 3.00e-04 | grad 2.25 | tok/s 24638
step   1990 | loss 1.9351 | lr 3.00e-04 | grad 2.45 | tok/s 23790
step   2000 | loss 2.2244 | lr 3.00e-04 | grad 1.56 | tok/s 23646
  >>> saved checkpoint: checkpoint_step_002000_loss_2.2244.pt
step   2010 | loss 1.9304 | lr 3.00e-04 | grad 1.59 | tok/s 12837
step   2020 | loss 1.4254 | lr 3.00e-04 | grad 1.41 | tok/s 24595
step   2030 | loss 1.8781 | lr 3.00e-04 | grad 1.66 | tok/s 24374
step   2040 | loss 1.5293 | lr 3.00e-04 | grad 1.78 | tok/s 25062
step   2050 | loss 2.1853 | lr 3.00e-04 | grad 1.94 | tok/s 25027
step   2060 | loss 1.9956 | lr 3.00e-04 | grad 1.64 | tok/s 24186
step   2070 | loss 2.1457 | lr 3.00e-04 | grad 1.66 | tok/s 23551
step   2080 | loss 2.2037 | lr 3.00e-04 | grad 2.44 | tok/s 23779
step   2090 | loss 2.5357 | lr 3.00e-04 | grad 2.20 | tok/s 25078
step   2100 | loss 2.1894 | lr 3.00e-04 | grad 3.11 | tok/s 24573
step   2110 | loss 2.1369 | lr 3.00e-04 | grad 1.73 | tok/s 24638
step   2120 | loss 2.1184 | lr 3.00e-04 | grad 1.91 | tok/s 23361
step   2130 | loss 1.3284 | lr 3.00e-04 | grad 1.89 | tok/s 25179
step   2140 | loss 1.8410 | lr 3.00e-04 | grad 1.60 | tok/s 24114
step   2150 | loss 1.9523 | lr 3.00e-04 | grad 1.67 | tok/s 24357
step   2160 | loss 1.8350 | lr 3.00e-04 | grad 2.08 | tok/s 25062
step   2170 | loss 1.7788 | lr 3.00e-04 | grad 1.76 | tok/s 25050
step   2180 | loss 1.8123 | lr 3.00e-04 | grad 2.23 | tok/s 25063
step   2190 | loss 1.7626 | lr 3.00e-04 | grad 1.88 | tok/s 25074
step   2200 | loss 1.7619 | lr 3.00e-04 | grad 1.52 | tok/s 25064
step   2210 | loss 1.7471 | lr 3.00e-04 | grad 1.77 | tok/s 25065
step   2220 | loss 1.7152 | lr 3.00e-04 | grad 1.97 | tok/s 25047
step   2230 | loss 1.6924 | lr 3.00e-04 | grad 1.42 | tok/s 25042
step   2240 | loss 1.8901 | lr 3.00e-04 | grad 1.91 | tok/s 24576
step   2250 | loss 1.8843 | lr 3.00e-04 | grad 1.15 | tok/s 24152
step   2260 | loss 2.4182 | lr 3.00e-04 | grad 3.34 | tok/s 25043
step   2270 | loss 2.1967 | lr 3.00e-04 | grad 1.56 | tok/s 24219
step   2280 | loss 2.4623 | lr 3.00e-04 | grad 1.33 | tok/s 24798
step   2290 | loss 2.0210 | lr 3.00e-04 | grad 2.17 | tok/s 25040
step   2300 | loss 2.1444 | lr 3.00e-04 | grad 3.62 | tok/s 24174
step   2310 | loss 2.5542 | lr 3.00e-04 | grad 2.14 | tok/s 24558
step   2320 | loss 2.0448 | lr 3.00e-04 | grad 2.17 | tok/s 23627
step   2330 | loss 2.2582 | lr 3.00e-04 | grad 1.82 | tok/s 23546
step   2340 | loss 2.0345 | lr 3.00e-04 | grad 1.66 | tok/s 23723
step   2350 | loss 2.0193 | lr 3.00e-04 | grad 1.73 | tok/s 23391
step   2360 | loss 1.9378 | lr 3.00e-04 | grad 2.05 | tok/s 24459
step   2370 | loss 1.9696 | lr 3.00e-04 | grad 1.78 | tok/s 25067
step   2380 | loss 2.1374 | lr 3.00e-04 | grad 2.09 | tok/s 24532
step   2390 | loss 2.2657 | lr 3.00e-04 | grad 1.60 | tok/s 25076
step   2400 | loss 1.8281 | lr 3.00e-04 | grad 1.82 | tok/s 25032
step   2410 | loss 1.7502 | lr 3.00e-04 | grad 1.47 | tok/s 25063
step   2420 | loss 1.6746 | lr 3.00e-04 | grad 1.19 | tok/s 24021
step   2430 | loss 1.9500 | lr 3.00e-04 | grad 1.39 | tok/s 23159
step   2440 | loss 1.9041 | lr 3.00e-04 | grad 1.80 | tok/s 24476
step   2450 | loss 1.9261 | lr 3.00e-04 | grad 1.10 | tok/s 24235
step   2460 | loss 1.9598 | lr 3.00e-04 | grad 1.71 | tok/s 24168
step   2470 | loss 1.8813 | lr 3.00e-04 | grad 1.34 | tok/s 24892
step   2480 | loss 1.8009 | lr 3.00e-04 | grad 1.99 | tok/s 24721
step   2490 | loss 1.8791 | lr 3.00e-04 | grad 1.71 | tok/s 24871
step   2500 | loss 1.8657 | lr 3.00e-04 | grad 1.20 | tok/s 23696
step   2510 | loss 2.1834 | lr 3.00e-04 | grad 2.25 | tok/s 24746
step   2520 | loss 2.1582 | lr 3.00e-04 | grad 2.00 | tok/s 25095
step   2530 | loss 2.2065 | lr 3.00e-04 | grad 1.91 | tok/s 24676
step   2540 | loss 1.8083 | lr 3.00e-04 | grad 1.62 | tok/s 24181
step   2550 | loss 1.9488 | lr 3.00e-04 | grad 1.81 | tok/s 24073
step   2560 | loss 1.7709 | lr 3.00e-04 | grad 1.62 | tok/s 25054
step   2570 | loss 2.0655 | lr 3.00e-04 | grad 2.02 | tok/s 23301
step   2580 | loss 1.9038 | lr 3.00e-04 | grad 1.55 | tok/s 24035
step   2590 | loss 1.8839 | lr 3.00e-04 | grad 1.62 | tok/s 23238
step   2600 | loss 2.0052 | lr 3.00e-04 | grad 1.51 | tok/s 23796
step   2610 | loss 2.2054 | lr 3.00e-04 | grad 2.45 | tok/s 23327
step   2620 | loss 2.2492 | lr 3.00e-04 | grad 1.97 | tok/s 24865
step   2630 | loss 2.0008 | lr 3.00e-04 | grad 1.33 | tok/s 24218
step   2640 | loss 1.9138 | lr 3.00e-04 | grad 1.56 | tok/s 24806
step   2650 | loss 2.1113 | lr 3.00e-04 | grad 1.63 | tok/s 24129
step   2660 | loss 2.2143 | lr 3.00e-04 | grad 1.64 | tok/s 24644
step   2670 | loss 1.8141 | lr 3.00e-04 | grad 1.52 | tok/s 24194
step   2680 | loss 1.8983 | lr 3.00e-04 | grad 1.35 | tok/s 23190
step   2690 | loss 2.1904 | lr 3.00e-04 | grad 1.62 | tok/s 24080
step   2700 | loss 1.8890 | lr 3.00e-04 | grad 2.33 | tok/s 24901
step   2710 | loss 2.0126 | lr 3.00e-04 | grad 2.30 | tok/s 24264
step   2720 | loss 2.1427 | lr 3.00e-04 | grad 1.73 | tok/s 23339
step   2730 | loss 1.8629 | lr 3.00e-04 | grad 2.00 | tok/s 22944
step   2740 | loss 1.8754 | lr 3.00e-04 | grad 1.77 | tok/s 24871
step   2750 | loss 2.2268 | lr 3.00e-04 | grad 2.39 | tok/s 24504
step   2760 | loss 2.1495 | lr 3.00e-04 | grad 1.66 | tok/s 24574
step   2770 | loss 1.7819 | lr 3.00e-04 | grad 2.05 | tok/s 23220
step   2780 | loss 2.0305 | lr 3.00e-04 | grad 1.99 | tok/s 23973
step   2790 | loss 1.8926 | lr 3.00e-04 | grad 1.48 | tok/s 24759
step   2800 | loss 2.2608 | lr 3.00e-04 | grad 1.89 | tok/s 23352
step   2810 | loss 1.7741 | lr 3.00e-04 | grad 2.02 | tok/s 24318
step   2820 | loss 1.8439 | lr 3.00e-04 | grad 1.52 | tok/s 23415
step   2830 | loss 1.8427 | lr 3.00e-04 | grad 1.58 | tok/s 23414
step   2840 | loss 1.9962 | lr 3.00e-04 | grad 2.28 | tok/s 24832
step   2850 | loss 1.8411 | lr 3.00e-04 | grad 1.85 | tok/s 24883
step   2860 | loss 2.2388 | lr 3.00e-04 | grad 2.08 | tok/s 23976
step   2870 | loss 2.1593 | lr 3.00e-04 | grad 1.94 | tok/s 24121
step   2880 | loss 1.8456 | lr 3.00e-04 | grad 1.59 | tok/s 23915
step   2890 | loss 2.0422 | lr 3.00e-04 | grad 2.06 | tok/s 24576
step   2900 | loss 2.0506 | lr 3.00e-04 | grad 2.11 | tok/s 25004
step   2910 | loss 1.8317 | lr 3.00e-04 | grad 1.98 | tok/s 24036
step   2920 | loss 1.9776 | lr 3.00e-04 | grad 1.95 | tok/s 24068
step   2930 | loss 2.0225 | lr 3.00e-04 | grad 3.14 | tok/s 23588
step   2940 | loss 1.9587 | lr 3.00e-04 | grad 2.48 | tok/s 24212
step   2950 | loss 1.7421 | lr 3.00e-04 | grad 2.05 | tok/s 22792
step   2960 | loss 1.8883 | lr 3.00e-04 | grad 1.81 | tok/s 24227
step   2970 | loss 1.8557 | lr 3.00e-04 | grad 1.80 | tok/s 24458
step   2980 | loss 1.8482 | lr 3.00e-04 | grad 2.08 | tok/s 23747
step   2990 | loss 2.3312 | lr 3.00e-04 | grad 3.66 | tok/s 24572
step   3000 | loss 2.4223 | lr 3.00e-04 | grad 1.46 | tok/s 24564
  >>> saved checkpoint: checkpoint_step_003000_loss_2.4223.pt
step   3010 | loss 1.8856 | lr 3.00e-04 | grad 1.89 | tok/s 12798
step   3020 | loss 1.7415 | lr 3.00e-04 | grad 5.41 | tok/s 24664
step   3030 | loss 1.8038 | lr 3.00e-04 | grad 1.80 | tok/s 23551
step   3040 | loss 1.9026 | lr 3.00e-04 | grad 1.70 | tok/s 23752
step   3050 | loss 1.9312 | lr 3.00e-04 | grad 1.91 | tok/s 24346
step   3060 | loss 1.8459 | lr 3.00e-04 | grad 1.53 | tok/s 24132
step   3070 | loss 1.8720 | lr 3.00e-04 | grad 1.57 | tok/s 24850
step   3080 | loss 2.0590 | lr 3.00e-04 | grad 1.57 | tok/s 24862
step   3090 | loss 1.8058 | lr 3.00e-04 | grad 1.70 | tok/s 24316
step   3100 | loss 1.9012 | lr 3.00e-04 | grad 1.55 | tok/s 24533
step   3110 | loss 2.0192 | lr 3.00e-04 | grad 1.88 | tok/s 24049
step   3120 | loss 1.8632 | lr 3.00e-04 | grad 1.83 | tok/s 24833
step   3130 | loss 1.6510 | lr 3.00e-04 | grad 1.52 | tok/s 25110
step   3140 | loss 1.9178 | lr 3.00e-04 | grad 2.25 | tok/s 23691
step   3150 | loss 1.8463 | lr 3.00e-04 | grad 2.19 | tok/s 25088
step   3160 | loss 1.7660 | lr 3.00e-04 | grad 1.73 | tok/s 25077
step   3170 | loss 1.8102 | lr 3.00e-04 | grad 2.52 | tok/s 23662
step   3180 | loss 2.0072 | lr 3.00e-04 | grad 1.69 | tok/s 23567
step   3190 | loss 1.8365 | lr 3.00e-04 | grad 1.70 | tok/s 23884
step   3200 | loss 1.6302 | lr 3.00e-04 | grad 6.34 | tok/s 24595
step   3210 | loss 1.8378 | lr 3.00e-04 | grad 2.56 | tok/s 24861
step   3220 | loss 1.9435 | lr 3.00e-04 | grad 1.95 | tok/s 24332
step   3230 | loss 2.5870 | lr 3.00e-04 | grad 1.61 | tok/s 24323
step   3240 | loss 2.3727 | lr 3.00e-04 | grad 1.80 | tok/s 25045
step   3250 | loss 2.2378 | lr 3.00e-04 | grad 1.98 | tok/s 25029
step   3260 | loss 2.1827 | lr 3.00e-04 | grad 1.43 | tok/s 25031
step   3270 | loss 2.1373 | lr 3.00e-04 | grad 2.80 | tok/s 25031
step   3280 | loss 2.0799 | lr 3.00e-04 | grad 2.09 | tok/s 25025
step   3290 | loss 2.0435 | lr 3.00e-04 | grad 2.25 | tok/s 25035
step   3300 | loss 2.0134 | lr 3.00e-04 | grad 2.28 | tok/s 25035
step   3310 | loss 1.9863 | lr 3.00e-04 | grad 2.31 | tok/s 25014
step   3320 | loss 1.9646 | lr 3.00e-04 | grad 2.53 | tok/s 25028
step   3330 | loss 1.9479 | lr 3.00e-04 | grad 2.02 | tok/s 25022
step   3340 | loss 1.9558 | lr 3.00e-04 | grad 2.17 | tok/s 25052
step   3350 | loss 2.1575 | lr 3.00e-04 | grad 1.30 | tok/s 23446
step   3360 | loss 1.9099 | lr 3.00e-04 | grad 1.87 | tok/s 24234
step   3370 | loss 1.8533 | lr 3.00e-04 | grad 1.73 | tok/s 23811
step   3380 | loss 1.8380 | lr 3.00e-04 | grad 1.85 | tok/s 23139
step   3390 | loss 1.9695 | lr 3.00e-04 | grad 1.89 | tok/s 23500
step   3400 | loss 1.8774 | lr 3.00e-04 | grad 2.16 | tok/s 24015
step   3410 | loss 1.6979 | lr 3.00e-04 | grad 1.52 | tok/s 25038
step   3420 | loss 1.6829 | lr 3.00e-04 | grad 2.03 | tok/s 25041
step   3430 | loss 1.9009 | lr 3.00e-04 | grad 1.50 | tok/s 23730
step   3440 | loss 1.8586 | lr 3.00e-04 | grad 1.69 | tok/s 24181
step   3450 | loss 1.9078 | lr 3.00e-04 | grad 1.78 | tok/s 23437
step   3460 | loss 1.8190 | lr 3.00e-04 | grad 2.59 | tok/s 24472
step   3470 | loss 2.1202 | lr 3.00e-04 | grad 1.77 | tok/s 24078
step   3480 | loss 1.8204 | lr 3.00e-04 | grad 1.65 | tok/s 24716
step   3490 | loss 1.8973 | lr 3.00e-04 | grad 1.94 | tok/s 24882
step   3500 | loss 1.7274 | lr 3.00e-04 | grad 1.75 | tok/s 23138
step   3510 | loss 1.7731 | lr 3.00e-04 | grad 1.97 | tok/s 25025
step   3520 | loss 1.8016 | lr 3.00e-04 | grad 2.34 | tok/s 23433
step   3530 | loss 1.8663 | lr 3.00e-04 | grad 1.44 | tok/s 23753
step   3540 | loss 2.3574 | lr 3.00e-04 | grad 1.48 | tok/s 25013
step   3550 | loss 2.0426 | lr 3.00e-04 | grad 1.45 | tok/s 24100
step   3560 | loss 2.3073 | lr 3.00e-04 | grad 2.53 | tok/s 23695
step   3570 | loss 1.9041 | lr 3.00e-04 | grad 1.59 | tok/s 22674
step   3580 | loss 1.8625 | lr 3.00e-04 | grad 1.65 | tok/s 23069
step   3590 | loss 1.6341 | lr 3.00e-04 | grad 1.91 | tok/s 23849
step   3600 | loss 1.8205 | lr 3.00e-04 | grad 1.68 | tok/s 24970

Training complete! Final step: 3609
