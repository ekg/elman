Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_27/levelmingru_100m_20260126_204519
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 241,096,704 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.3541 | lr 3.00e-04 | grad 4.66 | tok/s 19234
step     20 | loss 3.1764 | lr 3.00e-04 | grad 2.89 | tok/s 23950
step     30 | loss 2.9741 | lr 3.00e-04 | grad 9.81 | tok/s 24037
step     40 | loss 2.9090 | lr 3.00e-04 | grad 2.66 | tok/s 22973
step     50 | loss 2.8529 | lr 3.00e-04 | grad 11.88 | tok/s 22940
step     60 | loss 3.6431 | lr 3.00e-04 | grad 2.39 | tok/s 24439
step     70 | loss 2.6887 | lr 3.00e-04 | grad 3.81 | tok/s 24495
step     80 | loss 4.5174 | lr 3.00e-04 | grad 11.12 | tok/s 24429
step     90 | loss 5.2943 | lr 3.00e-04 | grad 9.31 | tok/s 25116
step    100 | loss 4.0073 | lr 3.00e-04 | grad 4.84 | tok/s 25100
step    110 | loss 3.8233 | lr 3.00e-04 | grad 5.50 | tok/s 25100
step    120 | loss 3.8104 | lr 3.00e-04 | grad 5.62 | tok/s 25065
step    130 | loss 3.9249 | lr 3.00e-04 | grad 4.06 | tok/s 25079
step    140 | loss 3.3956 | lr 3.00e-04 | grad 8.12 | tok/s 25052
step    150 | loss 3.6159 | lr 3.00e-04 | grad 8.12 | tok/s 25022
step    160 | loss 3.4430 | lr 3.00e-04 | grad 4.78 | tok/s 25040
step    170 | loss 3.2578 | lr 3.00e-04 | grad 4.59 | tok/s 25020
step    180 | loss 3.3202 | lr 3.00e-04 | grad 3.27 | tok/s 25003
step    190 | loss 3.2251 | lr 3.00e-04 | grad 4.59 | tok/s 24993
step    200 | loss 3.2344 | lr 3.00e-04 | grad 2.14 | tok/s 24984
step    210 | loss 3.0649 | lr 3.00e-04 | grad 3.48 | tok/s 24957
step    220 | loss 2.9972 | lr 3.00e-04 | grad 5.91 | tok/s 24625
step    230 | loss 3.0712 | lr 3.00e-04 | grad 7.47 | tok/s 24595
step    240 | loss 3.2444 | lr 3.00e-04 | grad 2.73 | tok/s 23283
step    250 | loss 2.7067 | lr 3.00e-04 | grad 2.03 | tok/s 23476
step    260 | loss 2.5179 | lr 3.00e-04 | grad 2.17 | tok/s 24627
step    270 | loss 2.6099 | lr 3.00e-04 | grad 4.28 | tok/s 23753
step    280 | loss 2.5806 | lr 3.00e-04 | grad 4.41 | tok/s 24366
step    290 | loss 2.9855 | lr 3.00e-04 | grad 2.33 | tok/s 24222
step    300 | loss 2.1825 | lr 3.00e-04 | grad 1.27 | tok/s 24925
step    310 | loss 2.6496 | lr 3.00e-04 | grad 2.67 | tok/s 24507
step    320 | loss 2.8386 | lr 3.00e-04 | grad 1.62 | tok/s 24849
step    330 | loss 2.5226 | lr 3.00e-04 | grad 2.39 | tok/s 22468
step    340 | loss 2.7056 | lr 3.00e-04 | grad 1.29 | tok/s 23848
step    350 | loss 2.5336 | lr 3.00e-04 | grad 2.02 | tok/s 23568
step    360 | loss 2.9218 | lr 3.00e-04 | grad 1.41 | tok/s 24847
step    370 | loss 2.5981 | lr 3.00e-04 | grad 2.58 | tok/s 22830
step    380 | loss 2.3854 | lr 3.00e-04 | grad 1.78 | tok/s 23326
step    390 | loss 2.3030 | lr 3.00e-04 | grad 2.47 | tok/s 24585
step    400 | loss 2.2627 | lr 3.00e-04 | grad 1.95 | tok/s 24597
step    410 | loss 2.3562 | lr 3.00e-04 | grad 1.90 | tok/s 24818
step    420 | loss 2.1941 | lr 3.00e-04 | grad 1.77 | tok/s 22691
step    430 | loss 2.5821 | lr 3.00e-04 | grad 2.30 | tok/s 24127
step    440 | loss 2.7324 | lr 3.00e-04 | grad 2.14 | tok/s 23701
step    450 | loss 2.8172 | lr 3.00e-04 | grad 7.50 | tok/s 23780
step    460 | loss 2.4851 | lr 3.00e-04 | grad 1.90 | tok/s 23267
step    470 | loss 2.4723 | lr 3.00e-04 | grad 1.39 | tok/s 23660
step    480 | loss 2.4679 | lr 3.00e-04 | grad 1.77 | tok/s 24138
step    490 | loss 2.8791 | lr 3.00e-04 | grad 2.39 | tok/s 23852
step    500 | loss 2.2299 | lr 3.00e-04 | grad 2.33 | tok/s 23474
step    510 | loss 2.4129 | lr 3.00e-04 | grad 1.80 | tok/s 24477
step    520 | loss 2.4126 | lr 3.00e-04 | grad 1.27 | tok/s 24589
step    530 | loss 2.5195 | lr 3.00e-04 | grad 1.91 | tok/s 24332
step    540 | loss 2.3124 | lr 3.00e-04 | grad 1.25 | tok/s 23682
step    550 | loss 2.1535 | lr 3.00e-04 | grad 1.92 | tok/s 23666
step    560 | loss 2.2280 | lr 3.00e-04 | grad 4.53 | tok/s 21668
step    570 | loss 2.2851 | lr 3.00e-04 | grad 1.66 | tok/s 23699
step    580 | loss 2.1917 | lr 3.00e-04 | grad 1.60 | tok/s 23212
step    590 | loss 2.1415 | lr 3.00e-04 | grad 1.73 | tok/s 22947
step    600 | loss 2.6092 | lr 3.00e-04 | grad 1.86 | tok/s 23488
step    610 | loss 2.2535 | lr 3.00e-04 | grad 2.06 | tok/s 23520
step    620 | loss 2.0988 | lr 3.00e-04 | grad 2.52 | tok/s 23352
step    630 | loss 2.1954 | lr 3.00e-04 | grad 2.94 | tok/s 22891
step    640 | loss 2.4121 | lr 3.00e-04 | grad 3.12 | tok/s 23438
step    650 | loss 2.3215 | lr 3.00e-04 | grad 3.22 | tok/s 23651
step    660 | loss 2.2534 | lr 3.00e-04 | grad 1.86 | tok/s 24014
step    670 | loss 2.1807 | lr 3.00e-04 | grad 1.80 | tok/s 23415
step    680 | loss 2.6312 | lr 3.00e-04 | grad 1.90 | tok/s 24426
step    690 | loss 2.4231 | lr 3.00e-04 | grad 1.92 | tok/s 23187
step    700 | loss 2.5398 | lr 3.00e-04 | grad 2.05 | tok/s 24735
step    710 | loss 2.3614 | lr 3.00e-04 | grad 2.11 | tok/s 24060
step    720 | loss 1.9779 | lr 3.00e-04 | grad 2.39 | tok/s 21866
step    730 | loss 2.3263 | lr 3.00e-04 | grad 2.08 | tok/s 24775
step    740 | loss 2.1332 | lr 3.00e-04 | grad 1.55 | tok/s 24327
step    750 | loss 2.2084 | lr 3.00e-04 | grad 1.64 | tok/s 24779
step    760 | loss 2.0135 | lr 3.00e-04 | grad 1.73 | tok/s 24748
step    770 | loss 2.0715 | lr 3.00e-04 | grad 1.84 | tok/s 24733
step    780 | loss 2.0174 | lr 3.00e-04 | grad 2.53 | tok/s 24765
step    790 | loss 1.9458 | lr 3.00e-04 | grad 1.90 | tok/s 24752
step    800 | loss 2.2200 | lr 3.00e-04 | grad 2.92 | tok/s 23137
step    810 | loss 2.4343 | lr 3.00e-04 | grad 1.98 | tok/s 23748
step    820 | loss 2.1901 | lr 3.00e-04 | grad 2.12 | tok/s 23444
step    830 | loss 2.2417 | lr 3.00e-04 | grad 1.63 | tok/s 23858
step    840 | loss 2.3776 | lr 3.00e-04 | grad 2.45 | tok/s 24731
step    850 | loss 2.3583 | lr 3.00e-04 | grad 6.16 | tok/s 24615
step    860 | loss 2.2532 | lr 3.00e-04 | grad 2.16 | tok/s 24501
step    870 | loss 2.1627 | lr 3.00e-04 | grad 1.40 | tok/s 23665
step    880 | loss 2.2262 | lr 3.00e-04 | grad 2.31 | tok/s 23499
step    890 | loss 2.2698 | lr 3.00e-04 | grad 1.15 | tok/s 23921
step    900 | loss 2.2054 | lr 3.00e-04 | grad 1.95 | tok/s 24003
step    910 | loss 1.9836 | lr 3.00e-04 | grad 1.50 | tok/s 23361
step    920 | loss 2.3093 | lr 3.00e-04 | grad 2.17 | tok/s 24447
step    930 | loss 2.1523 | lr 3.00e-04 | grad 1.84 | tok/s 23520
step    940 | loss 2.2367 | lr 3.00e-04 | grad 1.88 | tok/s 23843
step    950 | loss 2.2990 | lr 3.00e-04 | grad 1.87 | tok/s 24638
step    960 | loss 2.1408 | lr 3.00e-04 | grad 1.34 | tok/s 24763
step    970 | loss 2.1784 | lr 3.00e-04 | grad 1.50 | tok/s 23678
step    980 | loss 2.3029 | lr 3.00e-04 | grad 1.31 | tok/s 23842
step    990 | loss 2.0707 | lr 3.00e-04 | grad 1.79 | tok/s 23768
step   1000 | loss 2.1646 | lr 3.00e-04 | grad 1.99 | tok/s 23494
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1646.pt
step   1010 | loss 2.5165 | lr 3.00e-04 | grad 4.31 | tok/s 11767
step   1020 | loss 2.1575 | lr 3.00e-04 | grad 1.35 | tok/s 22750
step   1030 | loss 2.0601 | lr 3.00e-04 | grad 1.45 | tok/s 22450
step   1040 | loss 2.0469 | lr 3.00e-04 | grad 2.62 | tok/s 24376
step   1050 | loss 2.0337 | lr 3.00e-04 | grad 1.61 | tok/s 23197
step   1060 | loss 2.1509 | lr 3.00e-04 | grad 1.79 | tok/s 23740
step   1070 | loss 2.3584 | lr 3.00e-04 | grad 1.82 | tok/s 24374
step   1080 | loss 2.3206 | lr 3.00e-04 | grad 2.55 | tok/s 23484
step   1090 | loss 1.9811 | lr 3.00e-04 | grad 2.56 | tok/s 22532
step   1100 | loss 1.5903 | lr 3.00e-04 | grad 1.84 | tok/s 24363
step   1110 | loss 2.1197 | lr 3.00e-04 | grad 1.41 | tok/s 24101
step   1120 | loss 2.0458 | lr 3.00e-04 | grad 1.37 | tok/s 24785
step   1130 | loss 2.0419 | lr 3.00e-04 | grad 2.11 | tok/s 24759
step   1140 | loss 1.9693 | lr 3.00e-04 | grad 1.79 | tok/s 24796
step   1150 | loss 1.9647 | lr 3.00e-04 | grad 1.80 | tok/s 24768
step   1160 | loss 1.9293 | lr 3.00e-04 | grad 1.69 | tok/s 24775
step   1170 | loss 1.8526 | lr 3.00e-04 | grad 1.85 | tok/s 24794
step   1180 | loss 1.9654 | lr 3.00e-04 | grad 2.11 | tok/s 24782
step   1190 | loss 2.0115 | lr 3.00e-04 | grad 1.89 | tok/s 24770
step   1200 | loss 1.9067 | lr 3.00e-04 | grad 1.68 | tok/s 24790
step   1210 | loss 1.9459 | lr 3.00e-04 | grad 2.31 | tok/s 24760
step   1220 | loss 1.8954 | lr 3.00e-04 | grad 2.09 | tok/s 24779
step   1230 | loss 1.8509 | lr 3.00e-04 | grad 2.80 | tok/s 24797
step   1240 | loss 1.8904 | lr 3.00e-04 | grad 1.86 | tok/s 24758
step   1250 | loss 2.1762 | lr 3.00e-04 | grad 3.36 | tok/s 23918
step   1260 | loss 2.1485 | lr 3.00e-04 | grad 1.58 | tok/s 23170
step   1270 | loss 1.9102 | lr 3.00e-04 | grad 1.82 | tok/s 23902
step   1280 | loss 2.1483 | lr 3.00e-04 | grad 1.98 | tok/s 22971
step   1290 | loss 2.1045 | lr 3.00e-04 | grad 1.80 | tok/s 24140
step   1300 | loss 2.0566 | lr 3.00e-04 | grad 2.44 | tok/s 24116
step   1310 | loss 2.0006 | lr 3.00e-04 | grad 2.34 | tok/s 23501
step   1320 | loss 2.0353 | lr 3.00e-04 | grad 2.19 | tok/s 24460
step   1330 | loss 2.2680 | lr 3.00e-04 | grad 2.09 | tok/s 24435
step   1340 | loss 2.0136 | lr 3.00e-04 | grad 1.80 | tok/s 23909
step   1350 | loss 2.2042 | lr 3.00e-04 | grad 2.48 | tok/s 22527
step   1360 | loss 2.1774 | lr 3.00e-04 | grad 1.71 | tok/s 23430
step   1370 | loss 1.9988 | lr 3.00e-04 | grad 2.38 | tok/s 23415
step   1380 | loss 2.1968 | lr 3.00e-04 | grad 1.75 | tok/s 24229
step   1390 | loss 2.0492 | lr 3.00e-04 | grad 1.67 | tok/s 22434
step   1400 | loss 1.8860 | lr 3.00e-04 | grad 2.34 | tok/s 23492
step   1410 | loss 2.1317 | lr 3.00e-04 | grad 1.55 | tok/s 23827
step   1420 | loss 2.1288 | lr 3.00e-04 | grad 1.98 | tok/s 23079
step   1430 | loss 2.1431 | lr 3.00e-04 | grad 2.27 | tok/s 23818
step   1440 | loss 1.9235 | lr 3.00e-04 | grad 2.06 | tok/s 23590
step   1450 | loss 1.8790 | lr 3.00e-04 | grad 2.39 | tok/s 24743
step   1460 | loss 2.0574 | lr 3.00e-04 | grad 2.53 | tok/s 24187
step   1470 | loss 2.1002 | lr 3.00e-04 | grad 1.73 | tok/s 23159
step   1480 | loss 2.0538 | lr 3.00e-04 | grad 1.46 | tok/s 24262
step   1490 | loss 2.8957 | lr 3.00e-04 | grad 3.73 | tok/s 24773
step   1500 | loss 2.2281 | lr 3.00e-04 | grad 1.87 | tok/s 24640
step   1510 | loss 1.9204 | lr 3.00e-04 | grad 2.19 | tok/s 24460
step   1520 | loss 2.2073 | lr 3.00e-04 | grad 2.58 | tok/s 24740
step   1530 | loss 1.9650 | lr 3.00e-04 | grad 1.80 | tok/s 23932
step   1540 | loss 1.9650 | lr 3.00e-04 | grad 2.86 | tok/s 23677
step   1550 | loss 2.1337 | lr 3.00e-04 | grad 1.63 | tok/s 23883
step   1560 | loss 1.8687 | lr 3.00e-04 | grad 2.03 | tok/s 24464
step   1570 | loss 2.0598 | lr 3.00e-04 | grad 2.50 | tok/s 23420
step   1580 | loss 2.0484 | lr 3.00e-04 | grad 2.33 | tok/s 24526
step   1590 | loss 2.7088 | lr 3.00e-04 | grad 1.75 | tok/s 24353
step   1600 | loss 2.0208 | lr 3.00e-04 | grad 2.22 | tok/s 23336
step   1610 | loss 1.2588 | lr 3.00e-04 | grad 1.57 | tok/s 24960
step   1620 | loss 1.7953 | lr 3.00e-04 | grad 1.62 | tok/s 22457
step   1630 | loss 2.1987 | lr 3.00e-04 | grad 2.48 | tok/s 23502
step   1640 | loss 1.9401 | lr 3.00e-04 | grad 2.25 | tok/s 24498
step   1650 | loss 1.9977 | lr 3.00e-04 | grad 1.35 | tok/s 23067
step   1660 | loss 2.0223 | lr 3.00e-04 | grad 2.45 | tok/s 22422
step   1670 | loss 1.9708 | lr 3.00e-04 | grad 2.25 | tok/s 24767
step   1680 | loss 2.3406 | lr 3.00e-04 | grad 1.84 | tok/s 22934
step   1690 | loss 1.9412 | lr 3.00e-04 | grad 1.88 | tok/s 23018
step   1700 | loss 2.1916 | lr 3.00e-04 | grad 3.19 | tok/s 24366
step   1710 | loss 2.0047 | lr 3.00e-04 | grad 2.03 | tok/s 23292
step   1720 | loss 2.0653 | lr 3.00e-04 | grad 2.06 | tok/s 24117
step   1730 | loss 2.2706 | lr 3.00e-04 | grad 1.29 | tok/s 24761
step   1740 | loss 2.2989 | lr 3.00e-04 | grad 2.02 | tok/s 24754
step   1750 | loss 2.0157 | lr 3.00e-04 | grad 2.06 | tok/s 23723
step   1760 | loss 2.0225 | lr 3.00e-04 | grad 1.61 | tok/s 23778
step   1770 | loss 2.0384 | lr 3.00e-04 | grad 1.86 | tok/s 23833
step   1780 | loss 1.9258 | lr 3.00e-04 | grad 2.08 | tok/s 23539
step   1790 | loss 1.9486 | lr 3.00e-04 | grad 2.08 | tok/s 24081
step   1800 | loss 1.9520 | lr 3.00e-04 | grad 1.88 | tok/s 23730
step   1810 | loss 2.1069 | lr 3.00e-04 | grad 1.80 | tok/s 23355
step   1820 | loss 1.9736 | lr 3.00e-04 | grad 1.70 | tok/s 23373
step   1830 | loss 2.0402 | lr 3.00e-04 | grad 2.78 | tok/s 24120
step   1840 | loss 1.9497 | lr 3.00e-04 | grad 2.59 | tok/s 23839
step   1850 | loss 1.9901 | lr 3.00e-04 | grad 2.36 | tok/s 23461
step   1860 | loss 1.9730 | lr 3.00e-04 | grad 1.84 | tok/s 24252
step   1870 | loss 1.9136 | lr 3.00e-04 | grad 1.90 | tok/s 23307
step   1880 | loss 1.8542 | lr 3.00e-04 | grad 2.27 | tok/s 24409
step   1890 | loss 2.0208 | lr 3.00e-04 | grad 1.59 | tok/s 21925
step   1900 | loss 1.8878 | lr 3.00e-04 | grad 1.88 | tok/s 23514
step   1910 | loss 1.8437 | lr 3.00e-04 | grad 1.77 | tok/s 23289
step   1920 | loss 1.9329 | lr 3.00e-04 | grad 2.33 | tok/s 23162
step   1930 | loss 1.9059 | lr 3.00e-04 | grad 2.00 | tok/s 24427
step   1940 | loss 1.9009 | lr 3.00e-04 | grad 1.59 | tok/s 23175
step   1950 | loss 2.1681 | lr 3.00e-04 | grad 3.25 | tok/s 24335
step   1960 | loss 2.7277 | lr 3.00e-04 | grad 2.84 | tok/s 24777
step   1970 | loss 2.3074 | lr 3.00e-04 | grad 2.09 | tok/s 24231
step   1980 | loss 2.2907 | lr 3.00e-04 | grad 2.45 | tok/s 24319
step   1990 | loss 1.9056 | lr 3.00e-04 | grad 2.34 | tok/s 23495
step   2000 | loss 2.1747 | lr 3.00e-04 | grad 1.88 | tok/s 23349
  >>> saved checkpoint: checkpoint_step_002000_loss_2.1747.pt
step   2010 | loss 1.9029 | lr 3.00e-04 | grad 1.78 | tok/s 12048
step   2020 | loss 1.3953 | lr 3.00e-04 | grad 1.54 | tok/s 24401
step   2030 | loss 1.8520 | lr 3.00e-04 | grad 1.80 | tok/s 24188
step   2040 | loss 1.4903 | lr 3.00e-04 | grad 2.14 | tok/s 24919
step   2050 | loss 2.1462 | lr 3.00e-04 | grad 2.25 | tok/s 24812
step   2060 | loss 1.9548 | lr 3.00e-04 | grad 1.91 | tok/s 23940
step   2070 | loss 2.1106 | lr 3.00e-04 | grad 1.86 | tok/s 23297
step   2080 | loss 2.1815 | lr 3.00e-04 | grad 2.67 | tok/s 23563
step   2090 | loss 2.5408 | lr 3.00e-04 | grad 2.59 | tok/s 24846
step   2100 | loss 2.1307 | lr 3.00e-04 | grad 3.20 | tok/s 24326
step   2110 | loss 2.0824 | lr 3.00e-04 | grad 2.25 | tok/s 24394
step   2120 | loss 2.0719 | lr 3.00e-04 | grad 2.20 | tok/s 23141
step   2130 | loss 1.2949 | lr 3.00e-04 | grad 1.94 | tok/s 24997
step   2140 | loss 1.8033 | lr 3.00e-04 | grad 1.84 | tok/s 23931
step   2150 | loss 1.9163 | lr 3.00e-04 | grad 1.96 | tok/s 24129
step   2160 | loss 1.8035 | lr 3.00e-04 | grad 2.23 | tok/s 24813
step   2170 | loss 1.7366 | lr 3.00e-04 | grad 2.02 | tok/s 24793
step   2180 | loss 1.7782 | lr 3.00e-04 | grad 2.27 | tok/s 24779
step   2190 | loss 1.7241 | lr 3.00e-04 | grad 1.97 | tok/s 24740
step   2200 | loss 1.7250 | lr 3.00e-04 | grad 1.56 | tok/s 24768
step   2210 | loss 1.7123 | lr 3.00e-04 | grad 2.30 | tok/s 24749
step   2220 | loss 1.6749 | lr 3.00e-04 | grad 2.38 | tok/s 24753
step   2230 | loss 1.6517 | lr 3.00e-04 | grad 1.75 | tok/s 24757
step   2240 | loss 1.8579 | lr 3.00e-04 | grad 2.25 | tok/s 24302
step   2250 | loss 1.8484 | lr 3.00e-04 | grad 1.38 | tok/s 23901
step   2260 | loss 2.3627 | lr 3.00e-04 | grad 3.81 | tok/s 24795
step   2270 | loss 2.1495 | lr 3.00e-04 | grad 1.79 | tok/s 23958
step   2280 | loss 2.4222 | lr 3.00e-04 | grad 1.44 | tok/s 24526
step   2290 | loss 1.9888 | lr 3.00e-04 | grad 2.42 | tok/s 24773
step   2300 | loss 2.0981 | lr 3.00e-04 | grad 3.86 | tok/s 23919
step   2310 | loss 2.4999 | lr 3.00e-04 | grad 2.61 | tok/s 24281
step   2320 | loss 1.9986 | lr 3.00e-04 | grad 2.02 | tok/s 23371
step   2330 | loss 2.2328 | lr 3.00e-04 | grad 1.91 | tok/s 23310
step   2340 | loss 2.0087 | lr 3.00e-04 | grad 2.03 | tok/s 23458
step   2350 | loss 1.9665 | lr 3.00e-04 | grad 2.03 | tok/s 23130
step   2360 | loss 1.9056 | lr 3.00e-04 | grad 2.23 | tok/s 24199
step   2370 | loss 1.9180 | lr 3.00e-04 | grad 1.91 | tok/s 24802
step   2380 | loss 2.1034 | lr 3.00e-04 | grad 2.12 | tok/s 24264
step   2390 | loss 2.2207 | lr 3.00e-04 | grad 1.83 | tok/s 24816
step   2400 | loss 1.7856 | lr 3.00e-04 | grad 2.09 | tok/s 24769
step   2410 | loss 1.7054 | lr 3.00e-04 | grad 2.30 | tok/s 24807
step   2420 | loss 1.6303 | lr 3.00e-04 | grad 1.42 | tok/s 23806
step   2430 | loss 1.9247 | lr 3.00e-04 | grad 1.53 | tok/s 22921
step   2440 | loss 1.8637 | lr 3.00e-04 | grad 1.37 | tok/s 24225
step   2450 | loss 1.8789 | lr 3.00e-04 | grad 1.23 | tok/s 23999
step   2460 | loss 1.9319 | lr 3.00e-04 | grad 1.96 | tok/s 23927
step   2470 | loss 1.8309 | lr 3.00e-04 | grad 1.62 | tok/s 24629
step   2480 | loss 1.7598 | lr 3.00e-04 | grad 2.08 | tok/s 24503
step   2490 | loss 1.8247 | lr 3.00e-04 | grad 1.67 | tok/s 24600
step   2500 | loss 1.8370 | lr 3.00e-04 | grad 1.31 | tok/s 23469
step   2510 | loss 2.1384 | lr 3.00e-04 | grad 2.36 | tok/s 24478
step   2520 | loss 2.0650 | lr 3.00e-04 | grad 1.88 | tok/s 24803
step   2530 | loss 2.1511 | lr 3.00e-04 | grad 2.06 | tok/s 24426
step   2540 | loss 1.7723 | lr 3.00e-04 | grad 1.70 | tok/s 23932
step   2550 | loss 1.9136 | lr 3.00e-04 | grad 2.05 | tok/s 23824
step   2560 | loss 1.7267 | lr 3.00e-04 | grad 1.94 | tok/s 24799
step   2570 | loss 2.0251 | lr 3.00e-04 | grad 2.41 | tok/s 23073
step   2580 | loss 1.8643 | lr 3.00e-04 | grad 1.82 | tok/s 23789
step   2590 | loss 1.8405 | lr 3.00e-04 | grad 1.76 | tok/s 23029
step   2600 | loss 1.9602 | lr 3.00e-04 | grad 1.82 | tok/s 23551
step   2610 | loss 2.1537 | lr 3.00e-04 | grad 2.55 | tok/s 23074
step   2620 | loss 2.1559 | lr 3.00e-04 | grad 2.45 | tok/s 24605
step   2630 | loss 1.9757 | lr 3.00e-04 | grad 1.68 | tok/s 23955
step   2640 | loss 1.8797 | lr 3.00e-04 | grad 1.66 | tok/s 24486
step   2650 | loss 2.0721 | lr 3.00e-04 | grad 1.84 | tok/s 23859
step   2660 | loss 2.1649 | lr 3.00e-04 | grad 1.63 | tok/s 24333
step   2670 | loss 1.7699 | lr 3.00e-04 | grad 1.77 | tok/s 23895
step   2680 | loss 1.8646 | lr 3.00e-04 | grad 1.38 | tok/s 22952
step   2690 | loss 2.1464 | lr 3.00e-04 | grad 1.69 | tok/s 23819
step   2700 | loss 1.8541 | lr 3.00e-04 | grad 2.23 | tok/s 24590
step   2710 | loss 1.9771 | lr 3.00e-04 | grad 2.61 | tok/s 23973
step   2720 | loss 2.1123 | lr 3.00e-04 | grad 1.98 | tok/s 23017
step   2730 | loss 1.8388 | lr 3.00e-04 | grad 2.16 | tok/s 22649
step   2740 | loss 1.8126 | lr 3.00e-04 | grad 1.99 | tok/s 24551
step   2750 | loss 2.1671 | lr 3.00e-04 | grad 2.75 | tok/s 24169
step   2760 | loss 2.1105 | lr 3.00e-04 | grad 1.90 | tok/s 24261
step   2770 | loss 1.7528 | lr 3.00e-04 | grad 2.22 | tok/s 22971
step   2780 | loss 1.9797 | lr 3.00e-04 | grad 1.95 | tok/s 23686
step   2790 | loss 1.8200 | lr 3.00e-04 | grad 1.70 | tok/s 24436
step   2800 | loss 2.2435 | lr 3.00e-04 | grad 1.84 | tok/s 23076
step   2810 | loss 1.7281 | lr 3.00e-04 | grad 1.95 | tok/s 24028
step   2820 | loss 1.7964 | lr 3.00e-04 | grad 1.58 | tok/s 23157
step   2830 | loss 1.8118 | lr 3.00e-04 | grad 1.77 | tok/s 23133
step   2840 | loss 1.9521 | lr 3.00e-04 | grad 2.53 | tok/s 24514
step   2850 | loss 1.7671 | lr 3.00e-04 | grad 1.93 | tok/s 24556
step   2860 | loss 2.2140 | lr 3.00e-04 | grad 2.14 | tok/s 23691
step   2870 | loss 2.1273 | lr 3.00e-04 | grad 2.14 | tok/s 23840
step   2880 | loss 1.8151 | lr 3.00e-04 | grad 2.06 | tok/s 23649
step   2890 | loss 2.0012 | lr 3.00e-04 | grad 2.30 | tok/s 24278
step   2900 | loss 1.9936 | lr 3.00e-04 | grad 2.27 | tok/s 24714
step   2910 | loss 1.8056 | lr 3.00e-04 | grad 2.17 | tok/s 23725
step   2920 | loss 1.9264 | lr 3.00e-04 | grad 1.88 | tok/s 23740
step   2930 | loss 1.9918 | lr 3.00e-04 | grad 3.25 | tok/s 23277
step   2940 | loss 1.9226 | lr 3.00e-04 | grad 2.47 | tok/s 23887
step   2950 | loss 1.7101 | lr 3.00e-04 | grad 2.34 | tok/s 22494
step   2960 | loss 1.8358 | lr 3.00e-04 | grad 1.97 | tok/s 23927
step   2970 | loss 1.8101 | lr 3.00e-04 | grad 1.98 | tok/s 24149
step   2980 | loss 1.8156 | lr 3.00e-04 | grad 2.16 | tok/s 23446
step   2990 | loss 2.2787 | lr 3.00e-04 | grad 4.62 | tok/s 24266
step   3000 | loss 2.3492 | lr 3.00e-04 | grad 1.70 | tok/s 24231
  >>> saved checkpoint: checkpoint_step_003000_loss_2.3492.pt
step   3010 | loss 1.8441 | lr 3.00e-04 | grad 1.79 | tok/s 12230
step   3020 | loss 1.6851 | lr 3.00e-04 | grad 3.66 | tok/s 24446
step   3030 | loss 1.7671 | lr 3.00e-04 | grad 2.08 | tok/s 23303
step   3040 | loss 1.8689 | lr 3.00e-04 | grad 1.84 | tok/s 23484
step   3050 | loss 1.9012 | lr 3.00e-04 | grad 2.25 | tok/s 24089
step   3060 | loss 1.8195 | lr 3.00e-04 | grad 1.66 | tok/s 23862
step   3070 | loss 1.8288 | lr 3.00e-04 | grad 1.60 | tok/s 24579
step   3080 | loss 2.0281 | lr 3.00e-04 | grad 1.49 | tok/s 24591
step   3090 | loss 1.7753 | lr 3.00e-04 | grad 1.80 | tok/s 24051
step   3100 | loss 1.8694 | lr 3.00e-04 | grad 1.61 | tok/s 24248
step   3110 | loss 1.9818 | lr 3.00e-04 | grad 2.12 | tok/s 23775
step   3120 | loss 1.8141 | lr 3.00e-04 | grad 1.69 | tok/s 24522
step   3130 | loss 1.5878 | lr 3.00e-04 | grad 1.67 | tok/s 24795
step   3140 | loss 1.8702 | lr 3.00e-04 | grad 2.77 | tok/s 23415
step   3150 | loss 1.7817 | lr 3.00e-04 | grad 2.50 | tok/s 24794
step   3160 | loss 1.7076 | lr 3.00e-04 | grad 1.86 | tok/s 24772
step   3170 | loss 1.7803 | lr 3.00e-04 | grad 2.80 | tok/s 23387
step   3180 | loss 1.9629 | lr 3.00e-04 | grad 1.73 | tok/s 23279
step   3190 | loss 1.8075 | lr 3.00e-04 | grad 2.02 | tok/s 23616
step   3200 | loss 1.5977 | lr 3.00e-04 | grad 6.81 | tok/s 24384
step   3210 | loss 1.8043 | lr 3.00e-04 | grad 3.05 | tok/s 24585
step   3220 | loss 1.8921 | lr 3.00e-04 | grad 1.83 | tok/s 24046
step   3230 | loss 2.5755 | lr 3.00e-04 | grad 1.94 | tok/s 24045
step   3240 | loss 2.3388 | lr 3.00e-04 | grad 1.88 | tok/s 24737
step   3250 | loss 2.2069 | lr 3.00e-04 | grad 1.98 | tok/s 24717
step   3260 | loss 2.1446 | lr 3.00e-04 | grad 1.78 | tok/s 24731
step   3270 | loss 2.1025 | lr 3.00e-04 | grad 3.05 | tok/s 24739
step   3280 | loss 2.0389 | lr 3.00e-04 | grad 2.11 | tok/s 24718
step   3290 | loss 1.9964 | lr 3.00e-04 | grad 1.90 | tok/s 24732
step   3300 | loss 1.9774 | lr 3.00e-04 | grad 3.31 | tok/s 24734
step   3310 | loss 1.9492 | lr 3.00e-04 | grad 2.89 | tok/s 24734
step   3320 | loss 1.9239 | lr 3.00e-04 | grad 2.48 | tok/s 24735
step   3330 | loss 1.9020 | lr 3.00e-04 | grad 1.49 | tok/s 24735
step   3340 | loss 1.9188 | lr 3.00e-04 | grad 2.72 | tok/s 24752
step   3350 | loss 2.1171 | lr 3.00e-04 | grad 1.54 | tok/s 23234
step   3360 | loss 1.8735 | lr 3.00e-04 | grad 1.89 | tok/s 23971
step   3370 | loss 1.8210 | lr 3.00e-04 | grad 1.93 | tok/s 23557
step   3380 | loss 1.8004 | lr 3.00e-04 | grad 2.20 | tok/s 22914
step   3390 | loss 1.9381 | lr 3.00e-04 | grad 2.05 | tok/s 23255
step   3400 | loss 1.8431 | lr 3.00e-04 | grad 2.27 | tok/s 23764
step   3410 | loss 1.6502 | lr 3.00e-04 | grad 1.48 | tok/s 24750
step   3420 | loss 1.6368 | lr 3.00e-04 | grad 2.08 | tok/s 24757
step   3430 | loss 1.8680 | lr 3.00e-04 | grad 1.65 | tok/s 23458
step   3440 | loss 1.8264 | lr 3.00e-04 | grad 1.73 | tok/s 23908
step   3450 | loss 1.8787 | lr 3.00e-04 | grad 2.02 | tok/s 23198
step   3460 | loss 1.7798 | lr 3.00e-04 | grad 2.86 | tok/s 24229
step   3470 | loss 2.0697 | lr 3.00e-04 | grad 1.88 | tok/s 23828
step   3480 | loss 1.7770 | lr 3.00e-04 | grad 1.71 | tok/s 24413
step   3490 | loss 1.8708 | lr 3.00e-04 | grad 2.17 | tok/s 24574
step   3500 | loss 1.6923 | lr 3.00e-04 | grad 2.05 | tok/s 22890
step   3510 | loss 1.7210 | lr 3.00e-04 | grad 2.34 | tok/s 24722
step   3520 | loss 1.7717 | lr 3.00e-04 | grad 2.47 | tok/s 23187
step   3530 | loss 1.8357 | lr 3.00e-04 | grad 1.69 | tok/s 23479
step   3540 | loss 2.2980 | lr 3.00e-04 | grad 1.88 | tok/s 24763
step   3550 | loss 2.0215 | lr 3.00e-04 | grad 1.59 | tok/s 23848
step   3560 | loss 2.2532 | lr 3.00e-04 | grad 2.48 | tok/s 23330

Training complete! Final step: 3562
