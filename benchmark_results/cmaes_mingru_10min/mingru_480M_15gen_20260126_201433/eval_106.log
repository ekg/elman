Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_106/levelmingru_100m_20260126_222745
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 231,716,352 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 5.7813 | lr 3.00e-04 | grad 9.25 | tok/s 19993
step     20 | loss 3.1649 | lr 3.00e-04 | grad 4.38 | tok/s 24146
step     30 | loss 3.4981 | lr 3.00e-04 | grad 2.31 | tok/s 24478
step     40 | loss 4.2448 | lr 3.00e-04 | grad 6.41 | tok/s 25181
step     50 | loss 4.9078 | lr 3.00e-04 | grad 3.41 | tok/s 25822
step     60 | loss 4.1277 | lr 3.00e-04 | grad 4.84 | tok/s 25800
step     70 | loss 3.7008 | lr 3.00e-04 | grad 3.22 | tok/s 25782
step     80 | loss 3.5472 | lr 3.00e-04 | grad 4.50 | tok/s 25773
step     90 | loss 3.2790 | lr 3.00e-04 | grad 4.38 | tok/s 25762
step    100 | loss 3.1106 | lr 3.00e-04 | grad 8.50 | tok/s 25754
step    110 | loss 3.0083 | lr 3.00e-04 | grad 4.31 | tok/s 25581
step    120 | loss 3.4377 | lr 3.00e-04 | grad 2.33 | tok/s 24537
step    130 | loss 2.7237 | lr 3.00e-04 | grad 3.42 | tok/s 25065
step    140 | loss 2.8821 | lr 3.00e-04 | grad 3.80 | tok/s 24863
step    150 | loss 2.9004 | lr 3.00e-04 | grad 3.06 | tok/s 25398
step    160 | loss 3.0698 | lr 3.00e-04 | grad 2.38 | tok/s 25451
step    170 | loss 2.8040 | lr 3.00e-04 | grad 4.06 | tok/s 23897
step    180 | loss 2.9540 | lr 3.00e-04 | grad 3.92 | tok/s 25157
step    190 | loss 2.5914 | lr 3.00e-04 | grad 2.20 | tok/s 23746
step    200 | loss 2.4440 | lr 3.00e-04 | grad 3.48 | tok/s 25586
step    210 | loss 2.4266 | lr 3.00e-04 | grad 3.38 | tok/s 24509
step    220 | loss 2.7872 | lr 3.00e-04 | grad 2.16 | tok/s 24591
step    230 | loss 2.8281 | lr 3.00e-04 | grad 2.11 | tok/s 24357
step    240 | loss 2.7451 | lr 3.00e-04 | grad 4.84 | tok/s 24977
step    250 | loss 2.6157 | lr 3.00e-04 | grad 2.03 | tok/s 24485
step    260 | loss 2.5189 | lr 3.00e-04 | grad 1.77 | tok/s 25481
step    270 | loss 2.5201 | lr 3.00e-04 | grad 1.51 | tok/s 24594
step    280 | loss 2.3156 | lr 3.00e-04 | grad 3.80 | tok/s 23709
step    290 | loss 2.3374 | lr 3.00e-04 | grad 1.94 | tok/s 24153
step    300 | loss 2.5148 | lr 3.00e-04 | grad 2.09 | tok/s 23968
step    310 | loss 2.2752 | lr 3.00e-04 | grad 2.45 | tok/s 24486
step    320 | loss 2.4524 | lr 3.00e-04 | grad 3.14 | tok/s 24190
step    330 | loss 2.3884 | lr 3.00e-04 | grad 2.36 | tok/s 24616
step    340 | loss 2.5272 | lr 3.00e-04 | grad 3.48 | tok/s 24634
step    350 | loss 2.6867 | lr 3.00e-04 | grad 2.11 | tok/s 25297
step    360 | loss 2.2816 | lr 3.00e-04 | grad 2.30 | tok/s 23819
step    370 | loss 2.3598 | lr 3.00e-04 | grad 1.95 | tok/s 25489
step    380 | loss 2.2256 | lr 3.00e-04 | grad 1.90 | tok/s 25707
step    390 | loss 2.1939 | lr 3.00e-04 | grad 1.61 | tok/s 25708
step    400 | loss 2.3078 | lr 3.00e-04 | grad 2.22 | tok/s 24860
step    410 | loss 2.3707 | lr 3.00e-04 | grad 1.93 | tok/s 24316
step    420 | loss 2.4718 | lr 3.00e-04 | grad 1.67 | tok/s 25444
step    430 | loss 2.4196 | lr 3.00e-04 | grad 3.00 | tok/s 25511
step    440 | loss 2.3469 | lr 3.00e-04 | grad 2.22 | tok/s 24462
step    450 | loss 2.2631 | lr 3.00e-04 | grad 2.75 | tok/s 24799
step    460 | loss 2.2989 | lr 3.00e-04 | grad 1.98 | tok/s 24896
step    470 | loss 2.2992 | lr 3.00e-04 | grad 2.34 | tok/s 24562
step    480 | loss 2.4207 | lr 3.00e-04 | grad 2.50 | tok/s 25630
step    490 | loss 2.3339 | lr 3.00e-04 | grad 1.73 | tok/s 24600
step    500 | loss 2.2371 | lr 3.00e-04 | grad 2.06 | tok/s 24438
step    510 | loss 2.4838 | lr 3.00e-04 | grad 2.97 | tok/s 24258
step    520 | loss 2.1376 | lr 3.00e-04 | grad 1.92 | tok/s 24367
step    530 | loss 2.2271 | lr 3.00e-04 | grad 2.72 | tok/s 24337
step    540 | loss 2.4232 | lr 3.00e-04 | grad 1.98 | tok/s 24704
step    550 | loss 1.9021 | lr 3.00e-04 | grad 2.09 | tok/s 24377
step    560 | loss 2.2165 | lr 3.00e-04 | grad 2.30 | tok/s 25345
step    570 | loss 2.1400 | lr 3.00e-04 | grad 2.62 | tok/s 25700
step    580 | loss 2.0899 | lr 3.00e-04 | grad 3.31 | tok/s 25700
step    590 | loss 2.0872 | lr 3.00e-04 | grad 2.53 | tok/s 25689
step    600 | loss 2.1140 | lr 3.00e-04 | grad 2.05 | tok/s 25691
step    610 | loss 2.0783 | lr 3.00e-04 | grad 1.48 | tok/s 25699
step    620 | loss 2.0362 | lr 3.00e-04 | grad 1.73 | tok/s 25694
step    630 | loss 2.2709 | lr 3.00e-04 | grad 1.87 | tok/s 24397
step    640 | loss 2.1310 | lr 3.00e-04 | grad 2.70 | tok/s 24168
step    650 | loss 2.2103 | lr 3.00e-04 | grad 2.08 | tok/s 25125
step    660 | loss 2.1256 | lr 3.00e-04 | grad 1.95 | tok/s 24735
step    670 | loss 2.2684 | lr 3.00e-04 | grad 1.70 | tok/s 25020
step    680 | loss 2.3126 | lr 3.00e-04 | grad 1.83 | tok/s 23974
step    690 | loss 2.2017 | lr 3.00e-04 | grad 2.44 | tok/s 24587
step    700 | loss 2.0598 | lr 3.00e-04 | grad 1.99 | tok/s 23790
step    710 | loss 2.2459 | lr 3.00e-04 | grad 1.45 | tok/s 24231
step    720 | loss 2.1744 | lr 3.00e-04 | grad 2.12 | tok/s 24772
step    730 | loss 2.1232 | lr 3.00e-04 | grad 2.27 | tok/s 25311
step    740 | loss 2.2407 | lr 3.00e-04 | grad 2.38 | tok/s 24674
step    750 | loss 2.6845 | lr 3.00e-04 | grad 1.57 | tok/s 25626
step    760 | loss 2.1777 | lr 3.00e-04 | grad 1.73 | tok/s 25504
step    770 | loss 2.1361 | lr 3.00e-04 | grad 2.64 | tok/s 24689
step    780 | loss 2.1070 | lr 3.00e-04 | grad 2.73 | tok/s 25026
step    790 | loss 2.1536 | lr 3.00e-04 | grad 2.28 | tok/s 24704
step    800 | loss 2.4996 | lr 3.00e-04 | grad 2.02 | tok/s 24892
step    810 | loss 1.6354 | lr 3.00e-04 | grad 1.84 | tok/s 24311
step    820 | loss 2.2409 | lr 3.00e-04 | grad 2.22 | tok/s 25090
step    830 | loss 2.1044 | lr 3.00e-04 | grad 1.88 | tok/s 23558
step    840 | loss 2.2887 | lr 3.00e-04 | grad 2.67 | tok/s 24561
step    850 | loss 2.2083 | lr 3.00e-04 | grad 2.42 | tok/s 24714
step    860 | loss 2.1576 | lr 3.00e-04 | grad 2.22 | tok/s 24583
step    870 | loss 2.4573 | lr 3.00e-04 | grad 1.91 | tok/s 25685
step    880 | loss 2.1391 | lr 3.00e-04 | grad 2.25 | tok/s 24605
step    890 | loss 2.1136 | lr 3.00e-04 | grad 2.19 | tok/s 24545
step    900 | loss 2.0569 | lr 3.00e-04 | grad 2.52 | tok/s 24776
step    910 | loss 2.1608 | lr 3.00e-04 | grad 3.06 | tok/s 24095
step    920 | loss 2.1499 | lr 3.00e-04 | grad 4.00 | tok/s 24964
step    930 | loss 2.0928 | lr 3.00e-04 | grad 2.14 | tok/s 24713
step    940 | loss 2.0016 | lr 3.00e-04 | grad 2.30 | tok/s 24458
step    950 | loss 2.0984 | lr 3.00e-04 | grad 1.96 | tok/s 23805
step    960 | loss 2.0075 | lr 3.00e-04 | grad 3.03 | tok/s 24092
step    970 | loss 2.0284 | lr 3.00e-04 | grad 2.77 | tok/s 24682
step    980 | loss 2.6503 | lr 3.00e-04 | grad 3.83 | tok/s 25485
step    990 | loss 2.4330 | lr 3.00e-04 | grad 1.33 | tok/s 25001
step   1000 | loss 2.1284 | lr 3.00e-04 | grad 1.91 | tok/s 24474
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1284.pt
step   1010 | loss 1.7968 | lr 3.00e-04 | grad 2.25 | tok/s 17185
step   1020 | loss 1.8197 | lr 3.00e-04 | grad 2.75 | tok/s 25426
step   1030 | loss 2.2102 | lr 3.00e-04 | grad 2.28 | tok/s 25183
step   1040 | loss 2.3259 | lr 3.00e-04 | grad 2.72 | tok/s 24340
step   1050 | loss 2.4316 | lr 3.00e-04 | grad 2.42 | tok/s 25361
step   1060 | loss 2.2182 | lr 3.00e-04 | grad 1.84 | tok/s 24720
step   1070 | loss 1.6695 | lr 3.00e-04 | grad 2.17 | tok/s 25076
step   1080 | loss 1.9922 | lr 3.00e-04 | grad 1.84 | tok/s 25554
step   1090 | loss 1.9196 | lr 3.00e-04 | grad 1.61 | tok/s 25711
step   1100 | loss 1.9025 | lr 3.00e-04 | grad 1.33 | tok/s 25714
step   1110 | loss 1.8759 | lr 3.00e-04 | grad 1.52 | tok/s 25712
step   1120 | loss 1.9453 | lr 3.00e-04 | grad 2.27 | tok/s 25457
step   1130 | loss 2.3147 | lr 3.00e-04 | grad 2.02 | tok/s 25250
step   1140 | loss 2.4107 | lr 3.00e-04 | grad 2.58 | tok/s 25128
step   1150 | loss 2.1832 | lr 3.00e-04 | grad 1.34 | tok/s 25108
step   1160 | loss 2.4646 | lr 3.00e-04 | grad 2.08 | tok/s 24729
step   1170 | loss 2.1862 | lr 3.00e-04 | grad 1.53 | tok/s 24054
step   1180 | loss 2.0718 | lr 3.00e-04 | grad 1.88 | tok/s 24836
step   1190 | loss 2.1802 | lr 3.00e-04 | grad 1.94 | tok/s 25447
step   1200 | loss 2.1367 | lr 3.00e-04 | grad 2.34 | tok/s 25693
step   1210 | loss 1.8336 | lr 3.00e-04 | grad 1.73 | tok/s 25136
step   1220 | loss 2.0168 | lr 3.00e-04 | grad 1.70 | tok/s 24484
step   1230 | loss 2.0742 | lr 3.00e-04 | grad 2.91 | tok/s 24717
step   1240 | loss 1.9458 | lr 3.00e-04 | grad 3.05 | tok/s 25549
step   1250 | loss 2.0319 | lr 3.00e-04 | grad 2.02 | tok/s 24919
step   1260 | loss 2.2939 | lr 3.00e-04 | grad 2.05 | tok/s 25553
step   1270 | loss 2.0947 | lr 3.00e-04 | grad 2.11 | tok/s 24940
step   1280 | loss 1.9869 | lr 3.00e-04 | grad 1.72 | tok/s 25197
step   1290 | loss 2.0831 | lr 3.00e-04 | grad 1.76 | tok/s 23851
step   1300 | loss 2.0558 | lr 3.00e-04 | grad 1.34 | tok/s 24240
step   1310 | loss 2.4479 | lr 3.00e-04 | grad 2.22 | tok/s 24946
step   1320 | loss 2.0716 | lr 3.00e-04 | grad 1.84 | tok/s 25364
step   1330 | loss 2.2358 | lr 3.00e-04 | grad 1.74 | tok/s 24935
step   1340 | loss 1.9760 | lr 3.00e-04 | grad 1.90 | tok/s 24370
step   1350 | loss 2.1846 | lr 3.00e-04 | grad 2.53 | tok/s 25114
step   1360 | loss 2.1908 | lr 3.00e-04 | grad 2.56 | tok/s 24192
step   1370 | loss 1.9778 | lr 3.00e-04 | grad 1.76 | tok/s 24656
step   1380 | loss 2.3045 | lr 3.00e-04 | grad 1.92 | tok/s 25107
step   1390 | loss 2.0451 | lr 3.00e-04 | grad 1.76 | tok/s 24263
step   1400 | loss 2.2248 | lr 3.00e-04 | grad 1.70 | tok/s 24283
step   1410 | loss 1.9168 | lr 3.00e-04 | grad 1.98 | tok/s 24694
step   1420 | loss 2.0787 | lr 3.00e-04 | grad 1.73 | tok/s 24897
step   1430 | loss 2.2502 | lr 3.00e-04 | grad 3.03 | tok/s 24910
step   1440 | loss 2.0676 | lr 3.00e-04 | grad 2.06 | tok/s 24644
step   1450 | loss 2.1586 | lr 3.00e-04 | grad 1.62 | tok/s 25285
step   1460 | loss 1.9932 | lr 3.00e-04 | grad 2.19 | tok/s 24616
step   1470 | loss 2.0877 | lr 3.00e-04 | grad 1.78 | tok/s 24513
step   1480 | loss 1.9502 | lr 3.00e-04 | grad 2.08 | tok/s 24315
step   1490 | loss 2.0526 | lr 3.00e-04 | grad 3.03 | tok/s 24735
step   1500 | loss 2.3784 | lr 3.00e-04 | grad 2.42 | tok/s 25171
step   1510 | loss 1.8701 | lr 3.00e-04 | grad 2.41 | tok/s 24897
step   1520 | loss 1.9785 | lr 3.00e-04 | grad 2.70 | tok/s 24349
step   1530 | loss 2.0098 | lr 3.00e-04 | grad 2.02 | tok/s 24827
step   1540 | loss 2.0767 | lr 3.00e-04 | grad 2.48 | tok/s 25468
step   1550 | loss 1.9643 | lr 3.00e-04 | grad 1.92 | tok/s 25028
step   1560 | loss 2.0632 | lr 3.00e-04 | grad 2.20 | tok/s 25037
step   1570 | loss 1.9486 | lr 3.00e-04 | grad 2.14 | tok/s 24988
step   1580 | loss 1.9837 | lr 3.00e-04 | grad 2.19 | tok/s 25707
step   1590 | loss 2.0277 | lr 3.00e-04 | grad 1.52 | tok/s 24197
step   1600 | loss 1.8130 | lr 3.00e-04 | grad 2.05 | tok/s 24892
step   1610 | loss 2.1157 | lr 3.00e-04 | grad 3.45 | tok/s 25244
step   1620 | loss 2.5815 | lr 3.00e-04 | grad 2.73 | tok/s 25353
step   1630 | loss 2.3428 | lr 3.00e-04 | grad 2.20 | tok/s 25696
step   1640 | loss 2.2474 | lr 3.00e-04 | grad 2.48 | tok/s 25700
step   1650 | loss 2.1838 | lr 3.00e-04 | grad 2.52 | tok/s 25693
step   1660 | loss 2.1623 | lr 3.00e-04 | grad 2.61 | tok/s 25700
step   1670 | loss 2.1530 | lr 3.00e-04 | grad 2.77 | tok/s 25592
step   1680 | loss 2.1042 | lr 3.00e-04 | grad 2.83 | tok/s 24610
step   1690 | loss 1.9732 | lr 3.00e-04 | grad 2.22 | tok/s 24118
step   1700 | loss 1.9870 | lr 3.00e-04 | grad 2.81 | tok/s 24394
step   1710 | loss 1.8483 | lr 3.00e-04 | grad 3.00 | tok/s 25701
step   1720 | loss 2.0002 | lr 3.00e-04 | grad 2.16 | tok/s 24603
step   1730 | loss 1.9805 | lr 3.00e-04 | grad 1.48 | tok/s 24534
step   1740 | loss 2.0735 | lr 3.00e-04 | grad 1.52 | tok/s 25044
step   1750 | loss 1.9318 | lr 3.00e-04 | grad 1.91 | tok/s 24728
step   1760 | loss 1.9338 | lr 3.00e-04 | grad 3.44 | tok/s 24874
step   1770 | loss 2.2716 | lr 3.00e-04 | grad 1.91 | tok/s 25001
step   1780 | loss 2.2166 | lr 3.00e-04 | grad 1.53 | tok/s 24260
step   1790 | loss 1.9908 | lr 3.00e-04 | grad 1.95 | tok/s 23732
step   1800 | loss 1.8774 | lr 3.00e-04 | grad 1.80 | tok/s 24971
step   1810 | loss 1.9734 | lr 3.00e-04 | grad 2.30 | tok/s 23862
step   1820 | loss 1.9141 | lr 3.00e-04 | grad 2.14 | tok/s 25025
step   1830 | loss 2.0198 | lr 3.00e-04 | grad 2.25 | tok/s 24091
step   1840 | loss 2.0337 | lr 3.00e-04 | grad 1.57 | tok/s 24421
step   1850 | loss 1.9009 | lr 3.00e-04 | grad 2.23 | tok/s 24367
step   1860 | loss 2.0258 | lr 3.00e-04 | grad 2.23 | tok/s 24324

Training complete! Final step: 1865
