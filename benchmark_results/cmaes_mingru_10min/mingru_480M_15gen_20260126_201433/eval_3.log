Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_3/levelmingru_100m_20260126_201439
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 177,308,160 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.8207 | lr 3.00e-04 | grad 4.31 | tok/s 22082
step     20 | loss 3.1241 | lr 3.00e-04 | grad 2.36 | tok/s 24738
step     30 | loss 3.5529 | lr 3.00e-04 | grad 3.22 | tok/s 24888
step     40 | loss 3.7642 | lr 3.00e-04 | grad 6.56 | tok/s 25778
step     50 | loss 4.9660 | lr 3.00e-04 | grad 3.33 | tok/s 26450
step     60 | loss 4.0161 | lr 3.00e-04 | grad 4.66 | tok/s 26434
step     70 | loss 3.7853 | lr 3.00e-04 | grad 4.66 | tok/s 26419
step     80 | loss 3.6529 | lr 3.00e-04 | grad 4.97 | tok/s 26389
step     90 | loss 3.4016 | lr 3.00e-04 | grad 2.88 | tok/s 26373
step    100 | loss 3.3387 | lr 3.00e-04 | grad 1.83 | tok/s 26344
step    110 | loss 3.1229 | lr 3.00e-04 | grad 4.94 | tok/s 26154
step    120 | loss 3.4242 | lr 3.00e-04 | grad 1.98 | tok/s 25290
step    130 | loss 2.7721 | lr 3.00e-04 | grad 2.33 | tok/s 25389
step    140 | loss 2.7899 | lr 3.00e-04 | grad 3.14 | tok/s 25388
step    150 | loss 2.9872 | lr 3.00e-04 | grad 3.58 | tok/s 25932
step    160 | loss 2.9946 | lr 3.00e-04 | grad 2.36 | tok/s 26047
step    170 | loss 2.8112 | lr 3.00e-04 | grad 2.25 | tok/s 24431
step    180 | loss 2.9652 | lr 3.00e-04 | grad 2.64 | tok/s 25543
step    190 | loss 2.6637 | lr 3.00e-04 | grad 2.22 | tok/s 24332
step    200 | loss 2.4428 | lr 3.00e-04 | grad 1.33 | tok/s 25941
step    210 | loss 2.4261 | lr 3.00e-04 | grad 1.07 | tok/s 25024
step    220 | loss 2.7957 | lr 3.00e-04 | grad 1.61 | tok/s 25205
step    230 | loss 2.8876 | lr 3.00e-04 | grad 3.50 | tok/s 24765
step    240 | loss 2.6077 | lr 3.00e-04 | grad 2.39 | tok/s 25158
step    250 | loss 2.7270 | lr 3.00e-04 | grad 2.03 | tok/s 24906
step    260 | loss 2.5479 | lr 3.00e-04 | grad 2.33 | tok/s 25842
step    270 | loss 2.5555 | lr 3.00e-04 | grad 2.48 | tok/s 25269
step    280 | loss 2.3067 | lr 3.00e-04 | grad 2.31 | tok/s 23846
step    290 | loss 2.3597 | lr 3.00e-04 | grad 1.92 | tok/s 24682
step    300 | loss 2.5165 | lr 3.00e-04 | grad 1.65 | tok/s 24433
step    310 | loss 2.3026 | lr 3.00e-04 | grad 1.27 | tok/s 24668
step    320 | loss 2.4190 | lr 3.00e-04 | grad 2.53 | tok/s 24359
step    330 | loss 2.4236 | lr 3.00e-04 | grad 1.94 | tok/s 25071
step    340 | loss 2.5498 | lr 3.00e-04 | grad 1.44 | tok/s 25152
step    350 | loss 2.6505 | lr 3.00e-04 | grad 1.38 | tok/s 25202
step    360 | loss 2.2942 | lr 3.00e-04 | grad 1.45 | tok/s 24130
step    370 | loss 2.3735 | lr 3.00e-04 | grad 1.83 | tok/s 25828
step    380 | loss 2.2546 | lr 3.00e-04 | grad 2.28 | tok/s 26055
step    390 | loss 2.2090 | lr 3.00e-04 | grad 2.67 | tok/s 26049
step    400 | loss 2.2424 | lr 3.00e-04 | grad 2.97 | tok/s 25190
step    410 | loss 2.4413 | lr 3.00e-04 | grad 2.20 | tok/s 24826
step    420 | loss 2.4591 | lr 3.00e-04 | grad 1.17 | tok/s 25563
step    430 | loss 2.4365 | lr 3.00e-04 | grad 1.65 | tok/s 25839
step    440 | loss 2.3198 | lr 3.00e-04 | grad 1.59 | tok/s 24781
step    450 | loss 2.3444 | lr 3.00e-04 | grad 1.13 | tok/s 25186
step    460 | loss 2.2825 | lr 3.00e-04 | grad 1.62 | tok/s 25107
step    470 | loss 2.3031 | lr 3.00e-04 | grad 1.56 | tok/s 24877
step    480 | loss 2.3920 | lr 3.00e-04 | grad 1.72 | tok/s 25946
step    490 | loss 2.3650 | lr 3.00e-04 | grad 2.22 | tok/s 24940
step    500 | loss 2.2277 | lr 3.00e-04 | grad 1.60 | tok/s 24809
step    510 | loss 2.4885 | lr 3.00e-04 | grad 1.55 | tok/s 24632
step    520 | loss 2.1847 | lr 3.00e-04 | grad 1.73 | tok/s 24440
step    530 | loss 2.2101 | lr 3.00e-04 | grad 1.68 | tok/s 24714
step    540 | loss 2.4680 | lr 3.00e-04 | grad 1.44 | tok/s 24976
step    550 | loss 1.8946 | lr 3.00e-04 | grad 1.61 | tok/s 24504
step    560 | loss 2.2249 | lr 3.00e-04 | grad 1.74 | tok/s 25599
step    570 | loss 2.1619 | lr 3.00e-04 | grad 2.06 | tok/s 25941
step    580 | loss 2.1119 | lr 3.00e-04 | grad 2.61 | tok/s 25941
step    590 | loss 2.0689 | lr 3.00e-04 | grad 1.64 | tok/s 25924
step    600 | loss 2.1452 | lr 3.00e-04 | grad 1.80 | tok/s 25935
step    610 | loss 2.0878 | lr 3.00e-04 | grad 1.86 | tok/s 25918
step    620 | loss 2.0373 | lr 3.00e-04 | grad 1.74 | tok/s 25931
step    630 | loss 2.2765 | lr 3.00e-04 | grad 1.98 | tok/s 24964
step    640 | loss 2.0815 | lr 3.00e-04 | grad 1.54 | tok/s 24214
step    650 | loss 2.2568 | lr 3.00e-04 | grad 1.92 | tok/s 25267
step    660 | loss 2.1383 | lr 3.00e-04 | grad 1.83 | tok/s 25138
step    670 | loss 2.3004 | lr 3.00e-04 | grad 1.57 | tok/s 25467
step    680 | loss 2.2639 | lr 3.00e-04 | grad 2.00 | tok/s 23941
step    690 | loss 2.2451 | lr 3.00e-04 | grad 1.73 | tok/s 24974
step    700 | loss 2.0858 | lr 3.00e-04 | grad 1.77 | tok/s 24107
step    710 | loss 2.2840 | lr 3.00e-04 | grad 1.83 | tok/s 24797
step    720 | loss 2.1729 | lr 3.00e-04 | grad 2.47 | tok/s 24612
step    730 | loss 2.1256 | lr 3.00e-04 | grad 4.16 | tok/s 25789
step    740 | loss 2.1914 | lr 3.00e-04 | grad 1.30 | tok/s 24845
step    750 | loss 2.7268 | lr 3.00e-04 | grad 1.84 | tok/s 25819
step    760 | loss 2.1954 | lr 3.00e-04 | grad 2.47 | tok/s 25795
step    770 | loss 2.0779 | lr 3.00e-04 | grad 1.48 | tok/s 25049
step    780 | loss 2.1587 | lr 3.00e-04 | grad 1.76 | tok/s 25271
step    790 | loss 2.1686 | lr 3.00e-04 | grad 1.61 | tok/s 25133
step    800 | loss 2.5357 | lr 3.00e-04 | grad 1.62 | tok/s 24998
step    810 | loss 1.6545 | lr 3.00e-04 | grad 1.57 | tok/s 25020
step    820 | loss 2.2170 | lr 3.00e-04 | grad 1.19 | tok/s 24987
step    830 | loss 2.1040 | lr 3.00e-04 | grad 1.45 | tok/s 23773
step    840 | loss 2.2755 | lr 3.00e-04 | grad 2.25 | tok/s 25105
step    850 | loss 2.2043 | lr 3.00e-04 | grad 1.97 | tok/s 24741
step    860 | loss 2.2086 | lr 3.00e-04 | grad 1.66 | tok/s 24716
step    870 | loss 2.4710 | lr 3.00e-04 | grad 1.85 | tok/s 25942
step    880 | loss 2.1728 | lr 3.00e-04 | grad 2.11 | tok/s 24996
step    890 | loss 2.0891 | lr 3.00e-04 | grad 1.62 | tok/s 24724
step    900 | loss 2.0766 | lr 3.00e-04 | grad 1.37 | tok/s 25042
step    910 | loss 2.1781 | lr 3.00e-04 | grad 2.09 | tok/s 24509
step    920 | loss 2.1227 | lr 3.00e-04 | grad 1.19 | tok/s 25201
step    930 | loss 2.1674 | lr 3.00e-04 | grad 1.60 | tok/s 25039
step    940 | loss 2.0124 | lr 3.00e-04 | grad 1.10 | tok/s 24860
step    950 | loss 2.0837 | lr 3.00e-04 | grad 1.88 | tok/s 23705
step    960 | loss 2.0114 | lr 3.00e-04 | grad 1.33 | tok/s 24338
step    970 | loss 2.0273 | lr 3.00e-04 | grad 1.88 | tok/s 24926
step    980 | loss 2.5593 | lr 3.00e-04 | grad 1.74 | tok/s 25738
step    990 | loss 2.5259 | lr 3.00e-04 | grad 2.23 | tok/s 25418
step   1000 | loss 2.1884 | lr 3.00e-04 | grad 0.98 | tok/s 24549
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1884.pt
step   1010 | loss 1.7862 | lr 3.00e-04 | grad 1.53 | tok/s 17529
step   1020 | loss 1.8039 | lr 3.00e-04 | grad 1.31 | tok/s 25684
step   1030 | loss 2.2287 | lr 3.00e-04 | grad 1.63 | tok/s 25526
step   1040 | loss 2.2674 | lr 3.00e-04 | grad 4.56 | tok/s 24527
step   1050 | loss 2.4922 | lr 3.00e-04 | grad 1.64 | tok/s 25738
step   1060 | loss 2.2468 | lr 3.00e-04 | grad 1.73 | tok/s 24875
step   1070 | loss 1.6901 | lr 3.00e-04 | grad 1.43 | tok/s 25557
step   1080 | loss 2.0014 | lr 3.00e-04 | grad 1.95 | tok/s 25610
step   1090 | loss 1.9240 | lr 3.00e-04 | grad 1.75 | tok/s 25968
step   1100 | loss 1.9030 | lr 3.00e-04 | grad 1.70 | tok/s 25930
step   1110 | loss 1.8825 | lr 3.00e-04 | grad 2.28 | tok/s 25936
step   1120 | loss 1.9276 | lr 3.00e-04 | grad 2.08 | tok/s 25661
step   1130 | loss 2.3027 | lr 3.00e-04 | grad 4.03 | tok/s 25477
step   1140 | loss 2.4516 | lr 3.00e-04 | grad 1.93 | tok/s 25344
step   1150 | loss 2.1979 | lr 3.00e-04 | grad 4.91 | tok/s 25458
step   1160 | loss 2.4441 | lr 3.00e-04 | grad 2.02 | tok/s 24945
step   1170 | loss 2.2244 | lr 3.00e-04 | grad 1.83 | tok/s 24474
step   1180 | loss 2.0612 | lr 3.00e-04 | grad 1.75 | tok/s 24716
step   1190 | loss 2.1787 | lr 3.00e-04 | grad 1.48 | tok/s 25633
step   1200 | loss 2.1756 | lr 3.00e-04 | grad 2.05 | tok/s 25903
step   1210 | loss 1.8553 | lr 3.00e-04 | grad 1.63 | tok/s 25382
step   1220 | loss 2.0229 | lr 3.00e-04 | grad 1.51 | tok/s 24631
step   1230 | loss 2.0625 | lr 3.00e-04 | grad 1.20 | tok/s 25012
step   1240 | loss 1.9782 | lr 3.00e-04 | grad 1.82 | tok/s 25693
step   1250 | loss 2.0068 | lr 3.00e-04 | grad 1.83 | tok/s 25152
step   1260 | loss 2.3433 | lr 3.00e-04 | grad 2.62 | tok/s 25805
step   1270 | loss 2.1311 | lr 3.00e-04 | grad 1.68 | tok/s 25327
step   1280 | loss 2.0074 | lr 3.00e-04 | grad 2.14 | tok/s 25462
step   1290 | loss 2.0993 | lr 3.00e-04 | grad 1.67 | tok/s 24534
step   1300 | loss 2.0716 | lr 3.00e-04 | grad 2.28 | tok/s 24375
step   1310 | loss 2.4016 | lr 3.00e-04 | grad 1.93 | tok/s 24972
step   1320 | loss 2.0576 | lr 3.00e-04 | grad 2.02 | tok/s 25402
step   1330 | loss 2.2798 | lr 3.00e-04 | grad 1.86 | tok/s 25294
step   1340 | loss 1.9655 | lr 3.00e-04 | grad 1.91 | tok/s 24577
step   1350 | loss 2.1866 | lr 3.00e-04 | grad 1.90 | tok/s 25406
step   1360 | loss 2.2135 | lr 3.00e-04 | grad 1.21 | tok/s 24663
step   1370 | loss 1.9900 | lr 3.00e-04 | grad 1.74 | tok/s 24766
step   1380 | loss 2.3288 | lr 3.00e-04 | grad 1.45 | tok/s 25431
step   1390 | loss 2.0336 | lr 3.00e-04 | grad 1.93 | tok/s 24475
step   1400 | loss 2.2727 | lr 3.00e-04 | grad 1.90 | tok/s 24939
step   1410 | loss 1.9324 | lr 3.00e-04 | grad 1.65 | tok/s 24746
step   1420 | loss 2.0794 | lr 3.00e-04 | grad 2.86 | tok/s 25006
step   1430 | loss 2.2320 | lr 3.00e-04 | grad 1.46 | tok/s 25335
step   1440 | loss 2.1137 | lr 3.00e-04 | grad 1.20 | tok/s 24914
step   1450 | loss 2.1901 | lr 3.00e-04 | grad 1.62 | tok/s 25713
step   1460 | loss 2.0136 | lr 3.00e-04 | grad 1.98 | tok/s 24930
step   1470 | loss 2.0927 | lr 3.00e-04 | grad 1.88 | tok/s 24767
step   1480 | loss 1.9401 | lr 3.00e-04 | grad 1.64 | tok/s 24375
step   1490 | loss 1.9773 | lr 3.00e-04 | grad 1.54 | tok/s 24968
step   1500 | loss 2.4451 | lr 3.00e-04 | grad 1.60 | tok/s 25466
step   1510 | loss 1.9498 | lr 3.00e-04 | grad 2.20 | tok/s 25299
step   1520 | loss 1.9546 | lr 3.00e-04 | grad 1.81 | tok/s 24516
step   1530 | loss 1.9901 | lr 3.00e-04 | grad 1.45 | tok/s 25296
step   1540 | loss 2.0842 | lr 3.00e-04 | grad 1.91 | tok/s 25582
step   1550 | loss 1.9906 | lr 3.00e-04 | grad 1.42 | tok/s 25492
step   1560 | loss 2.0605 | lr 3.00e-04 | grad 1.76 | tok/s 25103
step   1570 | loss 1.9501 | lr 3.00e-04 | grad 2.56 | tok/s 25261
step   1580 | loss 2.0068 | lr 3.00e-04 | grad 2.20 | tok/s 25992
step   1590 | loss 2.0405 | lr 3.00e-04 | grad 1.73 | tok/s 24631
step   1600 | loss 1.8553 | lr 3.00e-04 | grad 1.84 | tok/s 25018
step   1610 | loss 2.0117 | lr 3.00e-04 | grad 1.70 | tok/s 25558
step   1620 | loss 2.6163 | lr 3.00e-04 | grad 1.55 | tok/s 25637
step   1630 | loss 2.3738 | lr 3.00e-04 | grad 1.80 | tok/s 26000
step   1640 | loss 2.2778 | lr 3.00e-04 | grad 1.76 | tok/s 25998
step   1650 | loss 2.2168 | lr 3.00e-04 | grad 2.16 | tok/s 25961
step   1660 | loss 2.1804 | lr 3.00e-04 | grad 1.78 | tok/s 25968
step   1670 | loss 2.1592 | lr 3.00e-04 | grad 1.99 | tok/s 25963
step   1680 | loss 2.1332 | lr 3.00e-04 | grad 1.79 | tok/s 24814
step   1690 | loss 1.9491 | lr 3.00e-04 | grad 2.22 | tok/s 24292
step   1700 | loss 2.0338 | lr 3.00e-04 | grad 1.70 | tok/s 24588
step   1710 | loss 1.8670 | lr 3.00e-04 | grad 1.52 | tok/s 25892
step   1720 | loss 1.9801 | lr 3.00e-04 | grad 1.83 | tok/s 24845
step   1730 | loss 1.9747 | lr 3.00e-04 | grad 2.16 | tok/s 24921
step   1740 | loss 2.1134 | lr 3.00e-04 | grad 1.96 | tok/s 25438
step   1750 | loss 1.9159 | lr 3.00e-04 | grad 1.52 | tok/s 24733
step   1760 | loss 1.9184 | lr 3.00e-04 | grad 2.06 | tok/s 25130
step   1770 | loss 2.2593 | lr 3.00e-04 | grad 2.00 | tok/s 25294
step   1780 | loss 2.2848 | lr 3.00e-04 | grad 5.84 | tok/s 24776
step   1790 | loss 1.9987 | lr 3.00e-04 | grad 2.31 | tok/s 23694
step   1800 | loss 1.8871 | lr 3.00e-04 | grad 1.91 | tok/s 25354
step   1810 | loss 1.9770 | lr 3.00e-04 | grad 2.02 | tok/s 24028
step   1820 | loss 1.9138 | lr 3.00e-04 | grad 1.80 | tok/s 25326
step   1830 | loss 2.0422 | lr 3.00e-04 | grad 1.43 | tok/s 24499
step   1840 | loss 2.0137 | lr 3.00e-04 | grad 2.36 | tok/s 24554
step   1850 | loss 1.9289 | lr 3.00e-04 | grad 1.83 | tok/s 24729
step   1860 | loss 2.0070 | lr 3.00e-04 | grad 1.63 | tok/s 24470
step   1870 | loss 2.0893 | lr 3.00e-04 | grad 2.16 | tok/s 24880
step   1880 | loss 2.0062 | lr 3.00e-04 | grad 2.86 | tok/s 25097
step   1890 | loss 1.8967 | lr 3.00e-04 | grad 1.59 | tok/s 25909

Training complete! Final step: 1891
