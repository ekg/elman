Using device: cuda
Output directory: benchmark_results/cmaes_mingru_10min/mingru_480M_15gen_20260126_201433/eval_50/levelmingru_100m_20260126_211600
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level mingru, 238,706,688 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 6.9722 | lr 3.00e-04 | grad 9.62 | tok/s 20486
step     20 | loss 3.0228 | lr 3.00e-04 | grad 3.17 | tok/s 23456
step     30 | loss 2.9733 | lr 3.00e-04 | grad 4.91 | tok/s 23651
step     40 | loss 3.4532 | lr 3.00e-04 | grad 16.00 | tok/s 24445
step     50 | loss 4.5469 | lr 3.00e-04 | grad 4.16 | tok/s 25060
step     60 | loss 3.4882 | lr 3.00e-04 | grad 4.94 | tok/s 25055
step     70 | loss 3.1814 | lr 3.00e-04 | grad 6.28 | tok/s 25046
step     80 | loss 3.0534 | lr 3.00e-04 | grad 4.03 | tok/s 25025
step     90 | loss 2.8113 | lr 3.00e-04 | grad 2.73 | tok/s 25013
step    100 | loss 2.7348 | lr 3.00e-04 | grad 2.20 | tok/s 24979
step    110 | loss 2.5619 | lr 3.00e-04 | grad 9.12 | tok/s 24828
step    120 | loss 2.9850 | lr 3.00e-04 | grad 2.41 | tok/s 24008
step    130 | loss 2.5966 | lr 3.00e-04 | grad 3.38 | tok/s 24130
step    140 | loss 2.5490 | lr 3.00e-04 | grad 3.09 | tok/s 24137
step    150 | loss 2.3883 | lr 3.00e-04 | grad 11.69 | tok/s 24646
step    160 | loss 2.6952 | lr 3.00e-04 | grad 4.09 | tok/s 24763
step    170 | loss 2.5732 | lr 3.00e-04 | grad 2.83 | tok/s 23247
step    180 | loss 2.6375 | lr 3.00e-04 | grad 3.48 | tok/s 24304
step    190 | loss 2.3526 | lr 3.00e-04 | grad 3.17 | tok/s 23167
step    200 | loss 2.2048 | lr 3.00e-04 | grad 3.56 | tok/s 24710
step    210 | loss 2.1732 | lr 3.00e-04 | grad 2.34 | tok/s 23853
step    220 | loss 2.5463 | lr 3.00e-04 | grad 3.62 | tok/s 24035
step    230 | loss 2.6394 | lr 3.00e-04 | grad 6.25 | tok/s 23629
step    240 | loss 2.3458 | lr 3.00e-04 | grad 2.73 | tok/s 24025
step    250 | loss 2.4556 | lr 3.00e-04 | grad 3.22 | tok/s 23794
step    260 | loss 2.3026 | lr 3.00e-04 | grad 2.94 | tok/s 24666
step    270 | loss 2.3142 | lr 3.00e-04 | grad 3.25 | tok/s 24146
step    280 | loss 2.0645 | lr 3.00e-04 | grad 3.39 | tok/s 22783
step    290 | loss 2.1243 | lr 3.00e-04 | grad 3.47 | tok/s 23588
step    300 | loss 2.2418 | lr 3.00e-04 | grad 3.25 | tok/s 23368
step    310 | loss 2.0739 | lr 3.00e-04 | grad 3.72 | tok/s 23595
step    320 | loss 2.1910 | lr 3.00e-04 | grad 3.61 | tok/s 23320
step    330 | loss 2.1703 | lr 3.00e-04 | grad 2.58 | tok/s 24004
step    340 | loss 2.2590 | lr 3.00e-04 | grad 2.67 | tok/s 24098
step    350 | loss 2.3046 | lr 3.00e-04 | grad 3.17 | tok/s 24146
step    360 | loss 1.9788 | lr 3.00e-04 | grad 2.11 | tok/s 23117
step    370 | loss 2.0470 | lr 3.00e-04 | grad 2.19 | tok/s 24722
step    380 | loss 1.8767 | lr 3.00e-04 | grad 3.05 | tok/s 24926
step    390 | loss 1.7242 | lr 3.00e-04 | grad 3.16 | tok/s 24928
step    400 | loss 1.8250 | lr 3.00e-04 | grad 3.56 | tok/s 24108
step    410 | loss 2.1594 | lr 3.00e-04 | grad 3.34 | tok/s 23784
step    420 | loss 2.1065 | lr 3.00e-04 | grad 2.50 | tok/s 24496
step    430 | loss 2.0912 | lr 3.00e-04 | grad 2.12 | tok/s 24751
step    440 | loss 1.9843 | lr 3.00e-04 | grad 2.23 | tok/s 23759
step    450 | loss 2.0518 | lr 3.00e-04 | grad 2.02 | tok/s 24155
step    460 | loss 1.8917 | lr 3.00e-04 | grad 2.06 | tok/s 24081
step    470 | loss 1.9699 | lr 3.00e-04 | grad 2.34 | tok/s 23841
step    480 | loss 1.9520 | lr 3.00e-04 | grad 3.25 | tok/s 24885
step    490 | loss 2.0311 | lr 3.00e-04 | grad 2.81 | tok/s 23915
step    500 | loss 1.9384 | lr 3.00e-04 | grad 1.77 | tok/s 23805
step    510 | loss 2.1687 | lr 3.00e-04 | grad 1.80 | tok/s 23620
step    520 | loss 1.8627 | lr 3.00e-04 | grad 1.55 | tok/s 23439
step    530 | loss 1.9066 | lr 3.00e-04 | grad 2.39 | tok/s 23707
step    540 | loss 2.1084 | lr 3.00e-04 | grad 2.08 | tok/s 23972
step    550 | loss 1.5558 | lr 3.00e-04 | grad 1.62 | tok/s 23538
step    560 | loss 1.8513 | lr 3.00e-04 | grad 2.28 | tok/s 24601
step    570 | loss 1.7278 | lr 3.00e-04 | grad 2.36 | tok/s 24921
step    580 | loss 1.6740 | lr 3.00e-04 | grad 2.31 | tok/s 24916
step    590 | loss 1.6185 | lr 3.00e-04 | grad 2.00 | tok/s 24916
step    600 | loss 1.6517 | lr 3.00e-04 | grad 1.56 | tok/s 24912
step    610 | loss 1.6293 | lr 3.00e-04 | grad 1.62 | tok/s 24920
step    620 | loss 1.5822 | lr 3.00e-04 | grad 2.22 | tok/s 24912
step    630 | loss 1.8982 | lr 3.00e-04 | grad 1.98 | tok/s 23972
step    640 | loss 1.8262 | lr 3.00e-04 | grad 2.03 | tok/s 23260
step    650 | loss 1.8906 | lr 3.00e-04 | grad 2.12 | tok/s 24285
step    660 | loss 1.8239 | lr 3.00e-04 | grad 2.20 | tok/s 24142
step    670 | loss 1.8932 | lr 3.00e-04 | grad 2.75 | tok/s 24468
step    680 | loss 1.9568 | lr 3.00e-04 | grad 2.30 | tok/s 22980
step    690 | loss 1.8637 | lr 3.00e-04 | grad 1.80 | tok/s 23967
step    700 | loss 1.7648 | lr 3.00e-04 | grad 1.96 | tok/s 23143
step    710 | loss 1.8595 | lr 3.00e-04 | grad 2.19 | tok/s 23803
step    720 | loss 1.7803 | lr 3.00e-04 | grad 2.19 | tok/s 23623
step    730 | loss 1.6137 | lr 3.00e-04 | grad 4.97 | tok/s 24748
step    740 | loss 1.8357 | lr 3.00e-04 | grad 1.87 | tok/s 23845
step    750 | loss 2.2431 | lr 3.00e-04 | grad 2.69 | tok/s 24782
step    760 | loss 1.7540 | lr 3.00e-04 | grad 2.33 | tok/s 24749
step    770 | loss 1.7182 | lr 3.00e-04 | grad 2.27 | tok/s 24053
step    780 | loss 1.7617 | lr 3.00e-04 | grad 2.28 | tok/s 24260
step    790 | loss 1.8253 | lr 3.00e-04 | grad 2.78 | tok/s 24109
step    800 | loss 2.1013 | lr 3.00e-04 | grad 1.97 | tok/s 23980
step    810 | loss 1.2897 | lr 3.00e-04 | grad 1.88 | tok/s 24025
step    820 | loss 1.7923 | lr 3.00e-04 | grad 1.80 | tok/s 23982
step    830 | loss 1.7742 | lr 3.00e-04 | grad 1.78 | tok/s 22832
step    840 | loss 1.8566 | lr 3.00e-04 | grad 3.03 | tok/s 24154
step    850 | loss 1.8039 | lr 3.00e-04 | grad 2.81 | tok/s 23768
step    860 | loss 1.8342 | lr 3.00e-04 | grad 2.12 | tok/s 23765
step    870 | loss 1.9521 | lr 3.00e-04 | grad 2.11 | tok/s 24928
step    880 | loss 1.7727 | lr 3.00e-04 | grad 2.11 | tok/s 24031
step    890 | loss 1.7455 | lr 3.00e-04 | grad 1.65 | tok/s 23746
step    900 | loss 1.7224 | lr 3.00e-04 | grad 1.81 | tok/s 24027
step    910 | loss 1.7933 | lr 3.00e-04 | grad 2.30 | tok/s 23515
step    920 | loss 1.7676 | lr 3.00e-04 | grad 1.51 | tok/s 24166
step    930 | loss 1.7114 | lr 3.00e-04 | grad 1.42 | tok/s 24032
step    940 | loss 1.6071 | lr 3.00e-04 | grad 1.19 | tok/s 23874
step    950 | loss 1.7067 | lr 3.00e-04 | grad 2.14 | tok/s 22758
step    960 | loss 1.6505 | lr 3.00e-04 | grad 1.47 | tok/s 23373
step    970 | loss 1.6552 | lr 3.00e-04 | grad 1.69 | tok/s 23934
step    980 | loss 2.1418 | lr 3.00e-04 | grad 4.09 | tok/s 24721
step    990 | loss 2.0720 | lr 3.00e-04 | grad 2.25 | tok/s 24414
step   1000 | loss 1.7865 | lr 3.00e-04 | grad 1.14 | tok/s 23569
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7865.pt
step   1010 | loss 1.4763 | lr 3.00e-04 | grad 2.14 | tok/s 15352
step   1020 | loss 1.4573 | lr 3.00e-04 | grad 2.80 | tok/s 24660
step   1030 | loss 1.7058 | lr 3.00e-04 | grad 1.82 | tok/s 24435
step   1040 | loss 2.0484 | lr 3.00e-04 | grad 3.44 | tok/s 23616
step   1050 | loss 2.1718 | lr 3.00e-04 | grad 2.53 | tok/s 24585
step   1060 | loss 1.7204 | lr 3.00e-04 | grad 1.27 | tok/s 23982
step   1070 | loss 1.3495 | lr 3.00e-04 | grad 1.52 | tok/s 24338
step   1080 | loss 1.5780 | lr 3.00e-04 | grad 1.77 | tok/s 24783
step   1090 | loss 1.4670 | lr 3.00e-04 | grad 1.92 | tok/s 24931
step   1100 | loss 1.4594 | lr 3.00e-04 | grad 1.67 | tok/s 24933
step   1110 | loss 1.4061 | lr 3.00e-04 | grad 1.75 | tok/s 24914
step   1120 | loss 1.5220 | lr 3.00e-04 | grad 1.76 | tok/s 24674
step   1130 | loss 1.8571 | lr 3.00e-04 | grad 3.58 | tok/s 24486
step   1140 | loss 2.0919 | lr 3.00e-04 | grad 2.59 | tok/s 24365
step   1150 | loss 1.7739 | lr 3.00e-04 | grad 1.40 | tok/s 24332
step   1160 | loss 2.0470 | lr 3.00e-04 | grad 2.31 | tok/s 23971
step   1170 | loss 1.8884 | lr 3.00e-04 | grad 1.70 | tok/s 23319
step   1180 | loss 1.6876 | lr 3.00e-04 | grad 2.27 | tok/s 24093
step   1190 | loss 1.7460 | lr 3.00e-04 | grad 2.69 | tok/s 24663
step   1200 | loss 1.6698 | lr 3.00e-04 | grad 2.39 | tok/s 24905
step   1210 | loss 1.3909 | lr 3.00e-04 | grad 1.62 | tok/s 24360
step   1220 | loss 1.6145 | lr 3.00e-04 | grad 1.57 | tok/s 23723
step   1230 | loss 1.7012 | lr 3.00e-04 | grad 1.93 | tok/s 23961
step   1240 | loss 1.4592 | lr 3.00e-04 | grad 1.63 | tok/s 24763
step   1250 | loss 1.6119 | lr 3.00e-04 | grad 2.00 | tok/s 24149
step   1260 | loss 1.7307 | lr 3.00e-04 | grad 2.73 | tok/s 24758
step   1270 | loss 1.6978 | lr 3.00e-04 | grad 2.12 | tok/s 24169
step   1280 | loss 1.5469 | lr 3.00e-04 | grad 1.77 | tok/s 24434
step   1290 | loss 1.6962 | lr 3.00e-04 | grad 1.67 | tok/s 23127
step   1300 | loss 1.6382 | lr 3.00e-04 | grad 1.20 | tok/s 23499
step   1310 | loss 1.9772 | lr 3.00e-04 | grad 1.96 | tok/s 24195
step   1320 | loss 1.6976 | lr 3.00e-04 | grad 2.16 | tok/s 24574
step   1330 | loss 1.8223 | lr 3.00e-04 | grad 1.74 | tok/s 24217
step   1340 | loss 1.6090 | lr 3.00e-04 | grad 1.95 | tok/s 23621
step   1350 | loss 1.8020 | lr 3.00e-04 | grad 2.28 | tok/s 24351
step   1360 | loss 1.7793 | lr 3.00e-04 | grad 2.73 | tok/s 23477
step   1370 | loss 1.5161 | lr 3.00e-04 | grad 1.84 | tok/s 23915
step   1380 | loss 1.9691 | lr 3.00e-04 | grad 1.80 | tok/s 24344
step   1390 | loss 1.6063 | lr 3.00e-04 | grad 1.79 | tok/s 23538
step   1400 | loss 1.7866 | lr 3.00e-04 | grad 1.51 | tok/s 23542
step   1410 | loss 1.4757 | lr 3.00e-04 | grad 1.73 | tok/s 23946
step   1420 | loss 1.6154 | lr 3.00e-04 | grad 2.14 | tok/s 24137
step   1430 | loss 1.7810 | lr 3.00e-04 | grad 3.38 | tok/s 24158
step   1440 | loss 1.7350 | lr 3.00e-04 | grad 2.05 | tok/s 23911
step   1450 | loss 1.6990 | lr 3.00e-04 | grad 1.63 | tok/s 24515
step   1460 | loss 1.6627 | lr 3.00e-04 | grad 1.94 | tok/s 23869
step   1470 | loss 1.7584 | lr 3.00e-04 | grad 1.47 | tok/s 23772
step   1480 | loss 1.5440 | lr 3.00e-04 | grad 1.52 | tok/s 23576
step   1490 | loss 1.6988 | lr 3.00e-04 | grad 4.00 | tok/s 23994
step   1500 | loss 2.0693 | lr 3.00e-04 | grad 1.59 | tok/s 24423
step   1510 | loss 1.5025 | lr 3.00e-04 | grad 12.81 | tok/s 24140
step   1520 | loss 1.6150 | lr 3.00e-04 | grad 2.66 | tok/s 23618
step   1530 | loss 1.6680 | lr 3.00e-04 | grad 1.59 | tok/s 24066
step   1540 | loss 1.6933 | lr 3.00e-04 | grad 1.79 | tok/s 24690
step   1550 | loss 1.6119 | lr 3.00e-04 | grad 1.46 | tok/s 24268
step   1560 | loss 1.6168 | lr 3.00e-04 | grad 1.62 | tok/s 24278
step   1570 | loss 1.4161 | lr 3.00e-04 | grad 2.08 | tok/s 24234
step   1580 | loss 1.4138 | lr 3.00e-04 | grad 1.35 | tok/s 24918
step   1590 | loss 1.7028 | lr 3.00e-04 | grad 1.97 | tok/s 23472
step   1600 | loss 1.4739 | lr 3.00e-04 | grad 3.52 | tok/s 24161
step   1610 | loss 1.7530 | lr 3.00e-04 | grad 3.22 | tok/s 24481
step   1620 | loss 2.3571 | lr 3.00e-04 | grad 2.80 | tok/s 24588
step   1630 | loss 2.0536 | lr 3.00e-04 | grad 2.17 | tok/s 24918
step   1640 | loss 1.9000 | lr 3.00e-04 | grad 2.55 | tok/s 24907
step   1650 | loss 1.7885 | lr 3.00e-04 | grad 2.45 | tok/s 24907
step   1660 | loss 1.7265 | lr 3.00e-04 | grad 2.48 | tok/s 24914
step   1670 | loss 1.7241 | lr 3.00e-04 | grad 3.00 | tok/s 24815
step   1680 | loss 1.7743 | lr 3.00e-04 | grad 2.38 | tok/s 23873
step   1690 | loss 1.6260 | lr 3.00e-04 | grad 2.84 | tok/s 23389
step   1700 | loss 1.6332 | lr 3.00e-04 | grad 2.05 | tok/s 23662
step   1710 | loss 1.3227 | lr 3.00e-04 | grad 1.42 | tok/s 24933
step   1720 | loss 1.6580 | lr 3.00e-04 | grad 1.80 | tok/s 23855
step   1730 | loss 1.6084 | lr 3.00e-04 | grad 1.71 | tok/s 23779
step   1740 | loss 1.6834 | lr 3.00e-04 | grad 1.39 | tok/s 24290
step   1750 | loss 1.5762 | lr 3.00e-04 | grad 1.88 | tok/s 23971
step   1760 | loss 1.5035 | lr 3.00e-04 | grad 2.73 | tok/s 24122
step   1770 | loss 1.8404 | lr 3.00e-04 | grad 2.64 | tok/s 24244
step   1780 | loss 1.9004 | lr 3.00e-04 | grad 1.61 | tok/s 23544
step   1790 | loss 1.6384 | lr 3.00e-04 | grad 1.85 | tok/s 23034
step   1800 | loss 1.4324 | lr 3.00e-04 | grad 1.66 | tok/s 24189

Training complete! Final step: 1808
