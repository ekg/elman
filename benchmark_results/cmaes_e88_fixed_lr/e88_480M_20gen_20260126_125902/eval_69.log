Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_69/levelE88_100m_20260126_132530
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 476,553,444 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 3.0 minutes
step     10 | loss 3.9841 | lr 3.00e-04 | grad 8.62 | tok/s 7906
step     20 | loss 2.7408 | lr 3.00e-04 | grad 2.94 | tok/s 12611
step     30 | loss 2.9725 | lr 3.00e-04 | grad 6.28 | tok/s 13304
step     40 | loss 4.4061 | lr 3.00e-04 | grad 40.75 | tok/s 13515
step     50 | loss 4.6140 | lr 3.00e-04 | grad 17.50 | tok/s 13676
step     60 | loss 3.6165 | lr 3.00e-04 | grad 13.12 | tok/s 13653
step     70 | loss 2.9002 | lr 3.00e-04 | grad 7.31 | tok/s 13616
step     80 | loss 2.5707 | lr 3.00e-04 | grad 6.50 | tok/s 13627
step     90 | loss 2.3888 | lr 3.00e-04 | grad 4.38 | tok/s 13595
step    100 | loss 2.2068 | lr 3.00e-04 | grad 2.91 | tok/s 13588
step    110 | loss 2.2368 | lr 3.00e-04 | grad 2.89 | tok/s 13465
step    120 | loss 2.7098 | lr 3.00e-04 | grad 1.75 | tok/s 12827
step    130 | loss 2.1249 | lr 3.00e-04 | grad 4.69 | tok/s 13131
step    140 | loss 2.3681 | lr 3.00e-04 | grad 6.53 | tok/s 13160
step    150 | loss 1.4577 | lr 3.00e-04 | grad 4.66 | tok/s 13468
step    160 | loss 2.3322 | lr 3.00e-04 | grad 1.95 | tok/s 13034
step    170 | loss 2.2866 | lr 3.00e-04 | grad 1.54 | tok/s 12851
step    180 | loss 1.8765 | lr 3.00e-04 | grad 2.64 | tok/s 13142
step    190 | loss 1.9320 | lr 3.00e-04 | grad 1.95 | tok/s 12902
step    200 | loss 1.6809 | lr 3.00e-04 | grad 1.58 | tok/s 13488
step    210 | loss 1.9058 | lr 3.00e-04 | grad 3.92 | tok/s 12792
step    220 | loss 2.2131 | lr 3.00e-04 | grad 3.03 | tok/s 12936
step    230 | loss 1.9585 | lr 3.00e-04 | grad 2.41 | tok/s 12917
step    240 | loss 2.2873 | lr 3.00e-04 | grad 4.75 | tok/s 13083
step    250 | loss 1.7849 | lr 3.00e-04 | grad 1.49 | tok/s 12991
step    260 | loss 1.9158 | lr 3.00e-04 | grad 2.83 | tok/s 13354
step    270 | loss 1.8410 | lr 3.00e-04 | grad 1.77 | tok/s 13046
step    280 | loss 1.7908 | lr 3.00e-04 | grad 1.65 | tok/s 12257
step    290 | loss 1.6824 | lr 3.00e-04 | grad 1.96 | tok/s 12683

Training complete! Final step: 291
