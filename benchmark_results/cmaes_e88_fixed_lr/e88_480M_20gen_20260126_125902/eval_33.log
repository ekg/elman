Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_33/levelE88_100m_20260126_131218
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 492,399,872 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 4.2126 | lr 3.00e-04 | grad 27.25 | tok/s 5629
step     20 | loss 2.7639 | lr 3.00e-04 | grad 11.00 | tok/s 13463
step     30 | loss 2.5974 | lr 3.00e-04 | grad 5.72 | tok/s 13626
step     40 | loss 2.4456 | lr 3.00e-04 | grad 4.50 | tok/s 13018
step     50 | loss 3.0767 | lr 3.00e-04 | grad 15.69 | tok/s 13267
step     60 | loss 2.0746 | lr 3.00e-04 | grad 4.62 | tok/s 13651
step     70 | loss 1.9390 | lr 3.00e-04 | grad 6.22 | tok/s 13812
step     80 | loss 6.6182 | lr 3.00e-04 | grad 194.00 | tok/s 13917
step     90 | loss 6.6629 | lr 3.00e-04 | grad 19.75 | tok/s 14159
step    100 | loss 5.3322 | lr 3.00e-04 | grad 23.12 | tok/s 14107
step    110 | loss 4.6629 | lr 3.00e-04 | grad 33.00 | tok/s 14117
step    120 | loss 4.0030 | lr 3.00e-04 | grad 36.00 | tok/s 14125
step    130 | loss 3.6147 | lr 3.00e-04 | grad 41.75 | tok/s 13155
step    140 | loss 2.9811 | lr 3.00e-04 | grad 24.75 | tok/s 14069
step    150 | loss 3.3418 | lr 3.00e-04 | grad 33.00 | tok/s 14063
step    160 | loss 2.5679 | lr 3.00e-04 | grad 26.38 | tok/s 14071
step    170 | loss 2.6869 | lr 3.00e-04 | grad 25.62 | tok/s 14050
step    180 | loss 2.4522 | lr 3.00e-04 | grad 7.78 | tok/s 14010
step    190 | loss 2.7013 | lr 3.00e-04 | grad 9.38 | tok/s 14003
step    200 | loss 2.3154 | lr 3.00e-04 | grad 17.12 | tok/s 14025
step    210 | loss 2.3503 | lr 3.00e-04 | grad 11.25 | tok/s 14050
step    220 | loss 2.3303 | lr 3.00e-04 | grad 3.47 | tok/s 13900
step    230 | loss 2.1081 | lr 3.00e-04 | grad 4.97 | tok/s 13739
step    240 | loss 2.3125 | lr 3.00e-04 | grad 6.06 | tok/s 13007
step    250 | loss 2.1364 | lr 3.00e-04 | grad 2.56 | tok/s 13374
step    260 | loss 1.5784 | lr 3.00e-04 | grad 3.00 | tok/s 13813
step    270 | loss 2.1275 | lr 3.00e-04 | grad 2.69 | tok/s 12866
step    280 | loss 2.2870 | lr 3.00e-04 | grad 4.97 | tok/s 13347
step    290 | loss 1.4794 | lr 3.00e-04 | grad 3.81 | tok/s 14064
step    300 | loss 0.6153 | lr 3.00e-04 | grad 2.98 | tok/s 14047
step    310 | loss 2.4249 | lr 3.00e-04 | grad 3.59 | tok/s 13798
step    320 | loss 1.9665 | lr 3.00e-04 | grad 6.44 | tok/s 13503
step    330 | loss 1.9829 | lr 3.00e-04 | grad 3.00 | tok/s 13042
step    340 | loss 2.3351 | lr 3.00e-04 | grad 2.98 | tok/s 13227
step    350 | loss 1.9400 | lr 3.00e-04 | grad 6.12 | tok/s 13613
step    360 | loss 1.2815 | lr 3.00e-04 | grad 8.62 | tok/s 13900
step    370 | loss 1.8349 | lr 3.00e-04 | grad 2.59 | tok/s 12602
step    380 | loss 1.8099 | lr 3.00e-04 | grad 2.45 | tok/s 13432
step    390 | loss 1.5638 | lr 3.00e-04 | grad 2.08 | tok/s 14009
step    400 | loss 1.5220 | lr 3.00e-04 | grad 2.52 | tok/s 13877
step    410 | loss 1.2983 | lr 3.00e-04 | grad 2.05 | tok/s 12857
step    420 | loss 1.8479 | lr 3.00e-04 | grad 4.47 | tok/s 12919
step    430 | loss 2.1878 | lr 3.00e-04 | grad 2.89 | tok/s 13780
step    440 | loss 2.1841 | lr 3.00e-04 | grad 4.31 | tok/s 13050
step    450 | loss 1.9499 | lr 3.00e-04 | grad 2.73 | tok/s 13513
step    460 | loss 1.7424 | lr 3.00e-04 | grad 2.73 | tok/s 13217
step    470 | loss 1.8645 | lr 3.00e-04 | grad 2.38 | tok/s 13604
step    480 | loss 2.3013 | lr 3.00e-04 | grad 6.88 | tok/s 13623
step    490 | loss 1.8142 | lr 3.00e-04 | grad 2.55 | tok/s 12824
step    500 | loss 1.7068 | lr 3.00e-04 | grad 3.30 | tok/s 13715
step    510 | loss 1.7333 | lr 3.00e-04 | grad 2.30 | tok/s 13858
step    520 | loss 1.6913 | lr 3.00e-04 | grad 2.02 | tok/s 13877
step    530 | loss 1.9383 | lr 3.00e-04 | grad 2.47 | tok/s 13372
step    540 | loss 1.7633 | lr 3.00e-04 | grad 2.19 | tok/s 13358
step    550 | loss 1.5884 | lr 3.00e-04 | grad 2.95 | tok/s 12534
step    560 | loss 1.7388 | lr 3.00e-04 | grad 2.53 | tok/s 12743
step    570 | loss 1.6869 | lr 3.00e-04 | grad 3.72 | tok/s 13132
step    580 | loss 1.5647 | lr 3.00e-04 | grad 2.12 | tok/s 13026
step    590 | loss 1.8944 | lr 3.00e-04 | grad 3.05 | tok/s 13362

Training complete! Final step: 594
