Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_27/levelE88_100m_20260126_130901
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 490,188,768 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 4.0501 | lr 3.00e-04 | grad 12.44 | tok/s 5788
step     20 | loss 2.6009 | lr 3.00e-04 | grad 5.19 | tok/s 13067
step     30 | loss 2.5161 | lr 3.00e-04 | grad 3.22 | tok/s 13183
step     40 | loss 2.3790 | lr 3.00e-04 | grad 2.91 | tok/s 12642
step     50 | loss 2.9219 | lr 3.00e-04 | grad 9.56 | tok/s 12869
step     60 | loss 2.0738 | lr 3.00e-04 | grad 6.94 | tok/s 13243
step     70 | loss 1.9217 | lr 3.00e-04 | grad 4.16 | tok/s 13401
step     80 | loss 5.7662 | lr 3.00e-04 | grad 70.00 | tok/s 13472
step     90 | loss 5.2356 | lr 3.00e-04 | grad 7.94 | tok/s 13663
step    100 | loss 4.0833 | lr 3.00e-04 | grad 8.19 | tok/s 13663
step    110 | loss 3.5357 | lr 3.00e-04 | grad 12.75 | tok/s 13645
step    120 | loss 3.2395 | lr 3.00e-04 | grad 11.62 | tok/s 13602
step    130 | loss 2.9395 | lr 3.00e-04 | grad 14.56 | tok/s 13608
step    140 | loss 2.6424 | lr 3.00e-04 | grad 8.62 | tok/s 13581
step    150 | loss 2.6824 | lr 3.00e-04 | grad 13.38 | tok/s 13579
step    160 | loss 2.2763 | lr 3.00e-04 | grad 7.62 | tok/s 13605
step    170 | loss 2.3682 | lr 3.00e-04 | grad 9.75 | tok/s 13559
step    180 | loss 2.1976 | lr 3.00e-04 | grad 4.88 | tok/s 13547
step    190 | loss 2.3260 | lr 3.00e-04 | grad 8.88 | tok/s 13561
step    200 | loss 2.0412 | lr 3.00e-04 | grad 4.78 | tok/s 13524
step    210 | loss 2.0439 | lr 3.00e-04 | grad 4.53 | tok/s 13538
step    220 | loss 2.1508 | lr 3.00e-04 | grad 2.72 | tok/s 12393
step    230 | loss 2.0551 | lr 3.00e-04 | grad 2.67 | tok/s 13190
step    240 | loss 2.2699 | lr 3.00e-04 | grad 3.67 | tok/s 12562
step    250 | loss 2.0952 | lr 3.00e-04 | grad 2.03 | tok/s 12886
step    260 | loss 1.5695 | lr 3.00e-04 | grad 2.30 | tok/s 13264
step    270 | loss 2.0782 | lr 3.00e-04 | grad 2.17 | tok/s 13109
step    280 | loss 2.2396 | lr 3.00e-04 | grad 4.16 | tok/s 12862
step    290 | loss 1.3860 | lr 3.00e-04 | grad 2.72 | tok/s 13522
step    300 | loss 0.5696 | lr 3.00e-04 | grad 2.53 | tok/s 13524
step    310 | loss 2.4054 | lr 3.00e-04 | grad 3.19 | tok/s 13287
step    320 | loss 1.9523 | lr 3.00e-04 | grad 4.50 | tok/s 13019
step    330 | loss 1.9407 | lr 3.00e-04 | grad 2.27 | tok/s 12551
step    340 | loss 2.2426 | lr 3.00e-04 | grad 2.16 | tok/s 12758
step    350 | loss 1.8769 | lr 3.00e-04 | grad 3.98 | tok/s 13075
step    360 | loss 1.2316 | lr 3.00e-04 | grad 6.81 | tok/s 13382
step    370 | loss 1.8029 | lr 3.00e-04 | grad 2.11 | tok/s 12114
step    380 | loss 1.7656 | lr 3.00e-04 | grad 2.03 | tok/s 12910
step    390 | loss 1.5329 | lr 3.00e-04 | grad 1.62 | tok/s 13467
step    400 | loss 1.4921 | lr 3.00e-04 | grad 2.02 | tok/s 13345
step    410 | loss 1.2805 | lr 3.00e-04 | grad 1.62 | tok/s 13051
step    420 | loss 1.8090 | lr 3.00e-04 | grad 3.48 | tok/s 12452
step    430 | loss 2.1465 | lr 3.00e-04 | grad 2.34 | tok/s 13247
step    440 | loss 2.1346 | lr 3.00e-04 | grad 3.25 | tok/s 12530
step    450 | loss 1.9698 | lr 3.00e-04 | grad 2.23 | tok/s 12964
step    460 | loss 1.7125 | lr 3.00e-04 | grad 2.47 | tok/s 12692
step    470 | loss 1.8149 | lr 3.00e-04 | grad 1.87 | tok/s 13067
step    480 | loss 2.2411 | lr 3.00e-04 | grad 5.59 | tok/s 13075
step    490 | loss 1.7850 | lr 3.00e-04 | grad 2.06 | tok/s 12352
step    500 | loss 1.6777 | lr 3.00e-04 | grad 2.67 | tok/s 13196
step    510 | loss 1.7013 | lr 3.00e-04 | grad 1.87 | tok/s 13393
step    520 | loss 1.6648 | lr 3.00e-04 | grad 1.66 | tok/s 13361
step    530 | loss 1.8989 | lr 3.00e-04 | grad 2.05 | tok/s 12842
step    540 | loss 1.7310 | lr 3.00e-04 | grad 1.80 | tok/s 12851
step    550 | loss 1.5656 | lr 3.00e-04 | grad 2.34 | tok/s 12562
step    560 | loss 1.7117 | lr 3.00e-04 | grad 2.11 | tok/s 12251
step    570 | loss 1.6548 | lr 3.00e-04 | grad 3.11 | tok/s 11954

Training complete! Final step: 575
