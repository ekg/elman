Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_84/levelE88_100m_20260126_133207
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 474,593,486 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 3.0 minutes
step     10 | loss 4.1454 | lr 3.00e-04 | grad 16.75 | tok/s 9275
step     20 | loss 3.2790 | lr 3.00e-04 | grad 7.34 | tok/s 17446
step     30 | loss 3.1763 | lr 3.00e-04 | grad 10.75 | tok/s 18425
step     40 | loss 4.7462 | lr 3.00e-04 | grad 36.25 | tok/s 18764
step     50 | loss 4.6426 | lr 3.00e-04 | grad 22.50 | tok/s 18940
step     60 | loss 3.5109 | lr 3.00e-04 | grad 10.88 | tok/s 18870
step     70 | loss 2.9021 | lr 3.00e-04 | grad 7.00 | tok/s 18871
step     80 | loss 2.6112 | lr 3.00e-04 | grad 6.81 | tok/s 18792
step     90 | loss 2.4158 | lr 3.00e-04 | grad 5.12 | tok/s 18791
step    100 | loss 2.2352 | lr 3.00e-04 | grad 4.91 | tok/s 18791
step    110 | loss 2.2270 | lr 3.00e-04 | grad 4.38 | tok/s 18648
step    120 | loss 2.7357 | lr 3.00e-04 | grad 2.75 | tok/s 17750
step    130 | loss 2.0743 | lr 3.00e-04 | grad 7.19 | tok/s 18179
step    140 | loss 2.3627 | lr 3.00e-04 | grad 9.00 | tok/s 18223
step    150 | loss 1.3832 | lr 3.00e-04 | grad 6.91 | tok/s 18642
step    160 | loss 2.2998 | lr 3.00e-04 | grad 3.05 | tok/s 18052
step    170 | loss 2.2922 | lr 3.00e-04 | grad 2.53 | tok/s 17785
step    180 | loss 1.7883 | lr 3.00e-04 | grad 4.00 | tok/s 18208
step    190 | loss 1.8872 | lr 3.00e-04 | grad 3.33 | tok/s 17874
step    200 | loss 1.6112 | lr 3.00e-04 | grad 2.50 | tok/s 18709
step    210 | loss 1.8730 | lr 3.00e-04 | grad 7.00 | tok/s 17728
step    220 | loss 2.1834 | lr 3.00e-04 | grad 3.94 | tok/s 17923
step    230 | loss 2.0123 | lr 3.00e-04 | grad 3.53 | tok/s 17904
step    240 | loss 2.2485 | lr 3.00e-04 | grad 6.69 | tok/s 18139
step    250 | loss 1.7521 | lr 3.00e-04 | grad 2.16 | tok/s 18021
step    260 | loss 1.8822 | lr 3.00e-04 | grad 4.00 | tok/s 18534
step    270 | loss 1.8171 | lr 3.00e-04 | grad 2.78 | tok/s 18106
step    280 | loss 1.7699 | lr 3.00e-04 | grad 2.31 | tok/s 16997
step    290 | loss 1.6667 | lr 3.00e-04 | grad 2.84 | tok/s 17575
step    300 | loss 1.9671 | lr 3.00e-04 | grad 2.64 | tok/s 17714
step    310 | loss 1.6684 | lr 3.00e-04 | grad 2.25 | tok/s 17638
step    320 | loss 1.8842 | lr 3.00e-04 | grad 4.28 | tok/s 17265
step    330 | loss 1.7212 | lr 3.00e-04 | grad 2.45 | tok/s 18036
step    340 | loss 2.0491 | lr 3.00e-04 | grad 3.02 | tok/s 17952
step    350 | loss 1.7102 | lr 3.00e-04 | grad 2.47 | tok/s 18486
step    360 | loss 1.5832 | lr 3.00e-04 | grad 2.34 | tok/s 17685
step    370 | loss 1.4786 | lr 3.00e-04 | grad 2.28 | tok/s 18628
step    380 | loss 1.2103 | lr 3.00e-04 | grad 2.05 | tok/s 18787
step    390 | loss 1.1258 | lr 3.00e-04 | grad 1.94 | tok/s 18794
step    400 | loss 1.7566 | lr 3.00e-04 | grad 2.23 | tok/s 17792

Training complete! Final step: 400
