Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_36/levelE88_100m_20260126_131218
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 480,923,016 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 4.6589 | lr 3.00e-04 | grad 8.81 | tok/s 4698
step     20 | loss 2.6767 | lr 3.00e-04 | grad 4.19 | tok/s 8601
step     30 | loss 2.5490 | lr 3.00e-04 | grad 1.93 | tok/s 8682
step     40 | loss 2.3357 | lr 3.00e-04 | grad 2.34 | tok/s 8310
step     50 | loss 3.1033 | lr 3.00e-04 | grad 12.94 | tok/s 8405
step     60 | loss 2.1661 | lr 3.00e-04 | grad 3.14 | tok/s 8671
step     70 | loss 2.0201 | lr 3.00e-04 | grad 3.08 | tok/s 8504
step     80 | loss 4.8716 | lr 3.00e-04 | grad 67.00 | tok/s 8821
step     90 | loss 4.9553 | lr 3.00e-04 | grad 8.88 | tok/s 8980
step    100 | loss 4.4760 | lr 3.00e-04 | grad 11.94 | tok/s 8969
step    110 | loss 4.1834 | lr 3.00e-04 | grad 15.94 | tok/s 8957
step    120 | loss 3.7703 | lr 3.00e-04 | grad 16.00 | tok/s 8942
step    130 | loss 3.4826 | lr 3.00e-04 | grad 19.62 | tok/s 8944
step    140 | loss 2.7898 | lr 3.00e-04 | grad 10.62 | tok/s 8604
step    150 | loss 3.0807 | lr 3.00e-04 | grad 11.75 | tok/s 8908
step    160 | loss 2.3952 | lr 3.00e-04 | grad 10.50 | tok/s 8908
step    170 | loss 2.4969 | lr 3.00e-04 | grad 8.69 | tok/s 8895
step    180 | loss 2.2491 | lr 3.00e-04 | grad 2.91 | tok/s 8905
step    190 | loss 2.4256 | lr 3.00e-04 | grad 2.97 | tok/s 8897
step    200 | loss 2.1483 | lr 3.00e-04 | grad 4.28 | tok/s 8902
step    210 | loss 2.0924 | lr 3.00e-04 | grad 4.09 | tok/s 8899
step    220 | loss 2.2241 | lr 3.00e-04 | grad 1.67 | tok/s 8784
step    230 | loss 2.1231 | lr 3.00e-04 | grad 2.36 | tok/s 8686
step    240 | loss 2.2658 | lr 3.00e-04 | grad 2.66 | tok/s 8247
step    250 | loss 2.1118 | lr 3.00e-04 | grad 1.41 | tok/s 8480
step    260 | loss 1.6448 | lr 3.00e-04 | grad 1.74 | tok/s 8750
step    270 | loss 2.1136 | lr 3.00e-04 | grad 1.50 | tok/s 8641
step    280 | loss 2.2823 | lr 3.00e-04 | grad 3.11 | tok/s 8472
step    290 | loss 1.4960 | lr 3.00e-04 | grad 2.20 | tok/s 8905
step    300 | loss 0.6113 | lr 3.00e-04 | grad 1.75 | tok/s 8899
step    310 | loss 2.4427 | lr 3.00e-04 | grad 2.55 | tok/s 8760
step    320 | loss 2.0411 | lr 3.00e-04 | grad 3.52 | tok/s 8576
step    330 | loss 1.9469 | lr 3.00e-04 | grad 1.68 | tok/s 8278
step    340 | loss 2.2449 | lr 3.00e-04 | grad 1.55 | tok/s 8414
step    350 | loss 1.9210 | lr 3.00e-04 | grad 3.17 | tok/s 8631
step    360 | loss 1.3283 | lr 3.00e-04 | grad 4.56 | tok/s 8820
step    370 | loss 1.8390 | lr 3.00e-04 | grad 1.62 | tok/s 8003
step    380 | loss 1.7881 | lr 3.00e-04 | grad 1.53 | tok/s 8548

Training complete! Final step: 381
