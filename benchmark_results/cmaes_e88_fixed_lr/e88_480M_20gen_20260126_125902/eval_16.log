Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_16/levelE88_100m_20260126_130226
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 488,495,888 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 4.5344 | lr 3.00e-04 | grad 10.25 | tok/s 5187
step     20 | loss 2.6900 | lr 3.00e-04 | grad 5.16 | tok/s 10101
step     30 | loss 2.5501 | lr 3.00e-04 | grad 2.41 | tok/s 10201
step     40 | loss 2.3765 | lr 3.00e-04 | grad 2.69 | tok/s 9750
step     50 | loss 3.1148 | lr 3.00e-04 | grad 12.38 | tok/s 9907
step     60 | loss 2.1241 | lr 3.00e-04 | grad 3.34 | tok/s 10202
step     70 | loss 1.9990 | lr 3.00e-04 | grad 3.50 | tok/s 10334
step     80 | loss 5.1587 | lr 3.00e-04 | grad 84.50 | tok/s 10377
step     90 | loss 5.1478 | lr 3.00e-04 | grad 10.12 | tok/s 10498
step    100 | loss 4.5100 | lr 3.00e-04 | grad 11.94 | tok/s 10477
step    110 | loss 4.2412 | lr 3.00e-04 | grad 18.12 | tok/s 10499
step    120 | loss 3.8086 | lr 3.00e-04 | grad 20.00 | tok/s 10421
step    130 | loss 3.5124 | lr 3.00e-04 | grad 25.00 | tok/s 10395
step    140 | loss 2.8548 | lr 3.00e-04 | grad 13.12 | tok/s 9925
step    150 | loss 3.1543 | lr 3.00e-04 | grad 16.75 | tok/s 10351
step    160 | loss 2.4616 | lr 3.00e-04 | grad 13.88 | tok/s 10398
step    170 | loss 2.5177 | lr 3.00e-04 | grad 12.25 | tok/s 10378
step    180 | loss 2.2938 | lr 3.00e-04 | grad 4.41 | tok/s 10333
step    190 | loss 2.5093 | lr 3.00e-04 | grad 7.66 | tok/s 10295
step    200 | loss 2.2179 | lr 3.00e-04 | grad 7.47 | tok/s 10267
step    210 | loss 2.1303 | lr 3.00e-04 | grad 5.72 | tok/s 10250
step    220 | loss 2.2682 | lr 3.00e-04 | grad 2.05 | tok/s 10118
step    230 | loss 2.0776 | lr 3.00e-04 | grad 2.98 | tok/s 9976
step    240 | loss 2.2810 | lr 3.00e-04 | grad 2.92 | tok/s 9472
step    250 | loss 2.1206 | lr 3.00e-04 | grad 1.63 | tok/s 9809
step    260 | loss 1.6285 | lr 3.00e-04 | grad 1.93 | tok/s 10032
step    270 | loss 2.1189 | lr 3.00e-04 | grad 1.72 | tok/s 9911
step    280 | loss 2.2750 | lr 3.00e-04 | grad 3.42 | tok/s 9479
step    290 | loss 1.4364 | lr 3.00e-04 | grad 2.80 | tok/s 10177
step    300 | loss 0.5836 | lr 3.00e-04 | grad 1.84 | tok/s 10152
step    310 | loss 2.4377 | lr 3.00e-04 | grad 2.80 | tok/s 9993
step    320 | loss 2.0163 | lr 3.00e-04 | grad 3.84 | tok/s 9769
step    330 | loss 1.9592 | lr 3.00e-04 | grad 1.95 | tok/s 9428
step    340 | loss 2.2742 | lr 3.00e-04 | grad 1.82 | tok/s 9581
step    350 | loss 1.9312 | lr 3.00e-04 | grad 3.05 | tok/s 9812
step    360 | loss 1.2878 | lr 3.00e-04 | grad 4.22 | tok/s 10031
step    370 | loss 1.8366 | lr 3.00e-04 | grad 1.78 | tok/s 9079
step    380 | loss 1.8021 | lr 3.00e-04 | grad 1.69 | tok/s 9679
step    390 | loss 1.5640 | lr 3.00e-04 | grad 1.33 | tok/s 10094
step    400 | loss 1.5206 | lr 3.00e-04 | grad 1.73 | tok/s 10001
step    410 | loss 1.3254 | lr 3.00e-04 | grad 1.45 | tok/s 9774
step    420 | loss 1.8314 | lr 3.00e-04 | grad 3.06 | tok/s 9036
step    430 | loss 2.1565 | lr 3.00e-04 | grad 2.00 | tok/s 9927

Training complete! Final step: 438
