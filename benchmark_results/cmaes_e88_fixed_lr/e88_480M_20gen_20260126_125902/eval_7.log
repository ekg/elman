Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_7/levelE88_100m_20260126_125908
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 493,689,160 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 4.5521 | lr 3.00e-04 | grad 10.50 | tok/s 4968
step     20 | loss 2.6284 | lr 3.00e-04 | grad 4.72 | tok/s 9649
step     30 | loss 2.5338 | lr 3.00e-04 | grad 2.23 | tok/s 9695
step     40 | loss 2.3476 | lr 3.00e-04 | grad 2.48 | tok/s 9301
step     50 | loss 3.0846 | lr 3.00e-04 | grad 12.38 | tok/s 9399
step     60 | loss 2.1068 | lr 3.00e-04 | grad 2.97 | tok/s 9680
step     70 | loss 1.9804 | lr 3.00e-04 | grad 3.28 | tok/s 9807
step     80 | loss 5.1768 | lr 3.00e-04 | grad 95.50 | tok/s 9823
step     90 | loss 5.3115 | lr 3.00e-04 | grad 9.44 | tok/s 9954
step    100 | loss 4.6756 | lr 3.00e-04 | grad 12.12 | tok/s 9948
step    110 | loss 4.2638 | lr 3.00e-04 | grad 21.88 | tok/s 9884
step    120 | loss 3.7942 | lr 3.00e-04 | grad 19.38 | tok/s 9847
step    130 | loss 3.4898 | lr 3.00e-04 | grad 22.00 | tok/s 9471
step    140 | loss 2.8363 | lr 3.00e-04 | grad 13.00 | tok/s 9790
step    150 | loss 3.1717 | lr 3.00e-04 | grad 16.25 | tok/s 9755
step    160 | loss 2.4308 | lr 3.00e-04 | grad 13.25 | tok/s 9739
step    170 | loss 2.5361 | lr 3.00e-04 | grad 11.75 | tok/s 9706
step    180 | loss 2.2728 | lr 3.00e-04 | grad 3.83 | tok/s 9688
step    190 | loss 2.4744 | lr 3.00e-04 | grad 3.17 | tok/s 9684
step    200 | loss 2.1670 | lr 3.00e-04 | grad 7.12 | tok/s 9665
step    210 | loss 2.1166 | lr 3.00e-04 | grad 5.56 | tok/s 9673
step    220 | loss 2.2460 | lr 3.00e-04 | grad 2.03 | tok/s 9523
step    230 | loss 2.0975 | lr 3.00e-04 | grad 2.36 | tok/s 9392
step    240 | loss 2.2601 | lr 3.00e-04 | grad 3.17 | tok/s 8911
step    250 | loss 2.1058 | lr 3.00e-04 | grad 1.59 | tok/s 9151
step    260 | loss 1.6185 | lr 3.00e-04 | grad 1.87 | tok/s 9439
step    270 | loss 2.1107 | lr 3.00e-04 | grad 1.67 | tok/s 9296
step    280 | loss 2.2804 | lr 3.00e-04 | grad 3.59 | tok/s 8718
step    290 | loss 1.4894 | lr 3.00e-04 | grad 2.67 | tok/s 9588
step    300 | loss 0.6002 | lr 3.00e-04 | grad 1.70 | tok/s 9574
step    310 | loss 2.4384 | lr 3.00e-04 | grad 2.89 | tok/s 9441
step    320 | loss 2.0005 | lr 3.00e-04 | grad 3.70 | tok/s 9207
step    330 | loss 1.9496 | lr 3.00e-04 | grad 1.92 | tok/s 8887
step    340 | loss 2.2616 | lr 3.00e-04 | grad 1.76 | tok/s 9016
step    350 | loss 1.9287 | lr 3.00e-04 | grad 3.17 | tok/s 9251
step    360 | loss 1.2940 | lr 3.00e-04 | grad 4.62 | tok/s 9438
step    370 | loss 1.8200 | lr 3.00e-04 | grad 1.73 | tok/s 8546
step    380 | loss 1.7896 | lr 3.00e-04 | grad 1.63 | tok/s 9104
step    390 | loss 1.5546 | lr 3.00e-04 | grad 1.27 | tok/s 9501
step    400 | loss 1.5160 | lr 3.00e-04 | grad 1.76 | tok/s 9414
step    410 | loss 1.3238 | lr 3.00e-04 | grad 1.43 | tok/s 9188

Training complete! Final step: 414
