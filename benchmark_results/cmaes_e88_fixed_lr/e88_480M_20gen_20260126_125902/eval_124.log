Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_124/levelE88_100m_20260126_134835
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 493,883,008 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 3.9769 | lr 3.00e-04 | grad 12.62 | tok/s 6086
step     20 | loss 2.5715 | lr 3.00e-04 | grad 4.25 | tok/s 14730
step     30 | loss 2.4688 | lr 3.00e-04 | grad 3.69 | tok/s 14929
step     40 | loss 2.3540 | lr 3.00e-04 | grad 3.45 | tok/s 14238
step     50 | loss 2.9467 | lr 3.00e-04 | grad 11.31 | tok/s 14429
step     60 | loss 2.0423 | lr 3.00e-04 | grad 6.34 | tok/s 14862
step     70 | loss 1.9041 | lr 3.00e-04 | grad 4.19 | tok/s 15027
step     80 | loss 5.7847 | lr 3.00e-04 | grad 46.75 | tok/s 15135
step     90 | loss 4.9271 | lr 3.00e-04 | grad 8.44 | tok/s 15361
step    100 | loss 3.8882 | lr 3.00e-04 | grad 7.12 | tok/s 15300
step    110 | loss 3.3252 | lr 3.00e-04 | grad 14.25 | tok/s 15304
step    120 | loss 3.0962 | lr 3.00e-04 | grad 9.50 | tok/s 15276
step    130 | loss 2.8164 | lr 3.00e-04 | grad 10.44 | tok/s 15279
step    140 | loss 2.5492 | lr 3.00e-04 | grad 7.00 | tok/s 15254
step    150 | loss 2.5420 | lr 3.00e-04 | grad 7.91 | tok/s 15252
step    160 | loss 2.1848 | lr 3.00e-04 | grad 5.66 | tok/s 15228
step    170 | loss 2.2768 | lr 3.00e-04 | grad 9.06 | tok/s 15238
step    180 | loss 2.0803 | lr 3.00e-04 | grad 5.41 | tok/s 15224
step    190 | loss 2.2632 | lr 3.00e-04 | grad 4.28 | tok/s 15205
step    200 | loss 1.9685 | lr 3.00e-04 | grad 3.77 | tok/s 15187
step    210 | loss 2.0005 | lr 3.00e-04 | grad 5.06 | tok/s 15202
step    220 | loss 2.0938 | lr 3.00e-04 | grad 2.69 | tok/s 15013
step    230 | loss 1.9887 | lr 3.00e-04 | grad 2.81 | tok/s 14832
step    240 | loss 2.2738 | lr 3.00e-04 | grad 4.03 | tok/s 14090
step    250 | loss 2.0953 | lr 3.00e-04 | grad 2.16 | tok/s 14472
step    260 | loss 1.5558 | lr 3.00e-04 | grad 2.42 | tok/s 14914
step    270 | loss 2.0664 | lr 3.00e-04 | grad 2.38 | tok/s 14728
step    280 | loss 2.2475 | lr 3.00e-04 | grad 5.06 | tok/s 14465
step    290 | loss 1.3705 | lr 3.00e-04 | grad 2.36 | tok/s 15190
step    300 | loss 0.5549 | lr 3.00e-04 | grad 4.50 | tok/s 15198
step    310 | loss 2.3979 | lr 3.00e-04 | grad 3.14 | tok/s 14954
step    320 | loss 1.9296 | lr 3.00e-04 | grad 4.62 | tok/s 13792
step    330 | loss 1.9299 | lr 3.00e-04 | grad 2.45 | tok/s 14127
step    340 | loss 2.2504 | lr 3.00e-04 | grad 2.30 | tok/s 14379
step    350 | loss 1.8699 | lr 3.00e-04 | grad 3.20 | tok/s 14717
step    360 | loss 1.1907 | lr 3.00e-04 | grad 6.03 | tok/s 15036
step    370 | loss 1.7968 | lr 3.00e-04 | grad 2.19 | tok/s 13644
step    380 | loss 1.7549 | lr 3.00e-04 | grad 2.17 | tok/s 14548
step    390 | loss 1.5241 | lr 3.00e-04 | grad 1.73 | tok/s 15176
step    400 | loss 1.4807 | lr 3.00e-04 | grad 2.16 | tok/s 15056
step    410 | loss 1.2693 | lr 3.00e-04 | grad 1.70 | tok/s 14715
step    420 | loss 1.7987 | lr 3.00e-04 | grad 3.64 | tok/s 14067
step    430 | loss 2.1417 | lr 3.00e-04 | grad 2.48 | tok/s 14946
step    440 | loss 2.1391 | lr 3.00e-04 | grad 3.58 | tok/s 14138
step    450 | loss 1.9529 | lr 3.00e-04 | grad 2.25 | tok/s 14631
step    460 | loss 1.6950 | lr 3.00e-04 | grad 2.70 | tok/s 14316
step    470 | loss 1.8174 | lr 3.00e-04 | grad 2.03 | tok/s 14739
step    480 | loss 2.2270 | lr 3.00e-04 | grad 5.38 | tok/s 14771
step    490 | loss 1.7740 | lr 3.00e-04 | grad 2.06 | tok/s 13940
step    500 | loss 1.6713 | lr 3.00e-04 | grad 2.91 | tok/s 14875
step    510 | loss 1.6935 | lr 3.00e-04 | grad 1.95 | tok/s 15083
step    520 | loss 1.6511 | lr 3.00e-04 | grad 1.80 | tok/s 15045
step    530 | loss 1.8898 | lr 3.00e-04 | grad 2.12 | tok/s 14464
step    540 | loss 1.7227 | lr 3.00e-04 | grad 1.88 | tok/s 14462
step    550 | loss 1.5602 | lr 3.00e-04 | grad 2.33 | tok/s 14146
step    560 | loss 1.7057 | lr 3.00e-04 | grad 2.20 | tok/s 13768
step    570 | loss 1.6482 | lr 3.00e-04 | grad 2.95 | tok/s 13585
step    580 | loss 1.5362 | lr 3.00e-04 | grad 1.80 | tok/s 14113
step    590 | loss 1.8416 | lr 3.00e-04 | grad 2.70 | tok/s 14464
step    600 | loss 1.8187 | lr 3.00e-04 | grad 1.95 | tok/s 13988
step    610 | loss 1.6094 | lr 3.00e-04 | grad 2.02 | tok/s 14659
step    620 | loss 1.5349 | lr 3.00e-04 | grad 2.05 | tok/s 13915
step    630 | loss 1.6497 | lr 3.00e-04 | grad 3.72 | tok/s 14017
step    640 | loss 1.7927 | lr 3.00e-04 | grad 2.05 | tok/s 14431

Training complete! Final step: 645
