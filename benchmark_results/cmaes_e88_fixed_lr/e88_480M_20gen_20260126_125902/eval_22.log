Using device: cuda
Output directory: benchmark_results/cmaes_e88_fixed_lr/e88_480M_20gen_20260126_125902/eval_22/levelE88_100m_20260126_130544
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 482,868,008 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 3.0 minutes
step     10 | loss 3.9512 | lr 3.00e-04 | grad 13.81 | tok/s 5945
step     20 | loss 2.7371 | lr 3.00e-04 | grad 5.03 | tok/s 15026
step     30 | loss 2.4723 | lr 3.00e-04 | grad 3.20 | tok/s 15132
step     40 | loss 2.3367 | lr 3.00e-04 | grad 3.30 | tok/s 14473
step     50 | loss 2.8808 | lr 3.00e-04 | grad 10.25 | tok/s 14667
step     60 | loss 1.9933 | lr 3.00e-04 | grad 2.98 | tok/s 15207
step     70 | loss 1.8636 | lr 3.00e-04 | grad 3.98 | tok/s 15301
step     80 | loss 5.4014 | lr 3.00e-04 | grad 37.75 | tok/s 15344
step     90 | loss 4.7447 | lr 3.00e-04 | grad 7.09 | tok/s 15595
step    100 | loss 3.8412 | lr 3.00e-04 | grad 6.41 | tok/s 15542
step    110 | loss 3.2257 | lr 3.00e-04 | grad 9.44 | tok/s 15569
step    120 | loss 2.9431 | lr 3.00e-04 | grad 9.62 | tok/s 15459
step    130 | loss 2.7659 | lr 3.00e-04 | grad 9.62 | tok/s 15426
step    140 | loss 2.6361 | lr 3.00e-04 | grad 7.25 | tok/s 15394
step    150 | loss 2.4870 | lr 3.00e-04 | grad 9.50 | tok/s 15355
step    160 | loss 2.1737 | lr 3.00e-04 | grad 6.19 | tok/s 15346
step    170 | loss 2.2584 | lr 3.00e-04 | grad 8.50 | tok/s 15328
step    180 | loss 2.0716 | lr 3.00e-04 | grad 3.58 | tok/s 15309
step    190 | loss 2.2255 | lr 3.00e-04 | grad 9.38 | tok/s 15302
step    200 | loss 1.9321 | lr 3.00e-04 | grad 3.70 | tok/s 15264
step    210 | loss 1.9593 | lr 3.00e-04 | grad 4.53 | tok/s 15314
step    220 | loss 2.0866 | lr 3.00e-04 | grad 2.83 | tok/s 15039
step    230 | loss 1.9937 | lr 3.00e-04 | grad 3.94 | tok/s 13543
step    240 | loss 2.2659 | lr 3.00e-04 | grad 3.84 | tok/s 14088
step    250 | loss 2.0799 | lr 3.00e-04 | grad 2.16 | tok/s 14445
step    260 | loss 1.5385 | lr 3.00e-04 | grad 2.50 | tok/s 14892
step    270 | loss 2.0466 | lr 3.00e-04 | grad 2.30 | tok/s 14691
step    280 | loss 2.2349 | lr 3.00e-04 | grad 5.38 | tok/s 14415
step    290 | loss 1.4219 | lr 3.00e-04 | grad 3.05 | tok/s 15160
step    300 | loss 0.5463 | lr 3.00e-04 | grad 2.77 | tok/s 15112
step    310 | loss 2.3759 | lr 3.00e-04 | grad 3.34 | tok/s 14865
step    320 | loss 1.9141 | lr 3.00e-04 | grad 4.56 | tok/s 14546
step    330 | loss 1.9271 | lr 3.00e-04 | grad 2.48 | tok/s 14032
step    340 | loss 2.2430 | lr 3.00e-04 | grad 2.30 | tok/s 14245
step    350 | loss 1.8639 | lr 3.00e-04 | grad 3.09 | tok/s 14583
step    360 | loss 1.1857 | lr 3.00e-04 | grad 5.56 | tok/s 14905
step    370 | loss 1.7917 | lr 3.00e-04 | grad 2.17 | tok/s 13514
step    380 | loss 1.7465 | lr 3.00e-04 | grad 2.20 | tok/s 14401
step    390 | loss 1.5169 | lr 3.00e-04 | grad 1.71 | tok/s 15022
step    400 | loss 1.4767 | lr 3.00e-04 | grad 2.16 | tok/s 14888
step    410 | loss 1.2660 | lr 3.00e-04 | grad 1.66 | tok/s 14534
step    420 | loss 1.7895 | lr 3.00e-04 | grad 3.64 | tok/s 13886
step    430 | loss 2.1418 | lr 3.00e-04 | grad 2.47 | tok/s 14780
step    440 | loss 2.1261 | lr 3.00e-04 | grad 3.45 | tok/s 13929
step    450 | loss 1.9240 | lr 3.00e-04 | grad 2.23 | tok/s 14464
step    460 | loss 1.7174 | lr 3.00e-04 | grad 2.58 | tok/s 14128
step    470 | loss 1.8149 | lr 3.00e-04 | grad 1.94 | tok/s 14573
step    480 | loss 2.1969 | lr 3.00e-04 | grad 5.59 | tok/s 14597
step    490 | loss 1.7723 | lr 3.00e-04 | grad 2.05 | tok/s 13754
step    500 | loss 1.6597 | lr 3.00e-04 | grad 2.81 | tok/s 14658
step    510 | loss 1.6954 | lr 3.00e-04 | grad 1.95 | tok/s 14900
step    520 | loss 1.6494 | lr 3.00e-04 | grad 1.80 | tok/s 14875
step    530 | loss 1.8951 | lr 3.00e-04 | grad 2.09 | tok/s 14300
step    540 | loss 1.7170 | lr 3.00e-04 | grad 1.93 | tok/s 14266
step    550 | loss 1.5564 | lr 3.00e-04 | grad 2.38 | tok/s 13988
step    560 | loss 1.7032 | lr 3.00e-04 | grad 2.22 | tok/s 13628
step    570 | loss 1.6427 | lr 3.00e-04 | grad 3.09 | tok/s 13996
step    580 | loss 1.5343 | lr 3.00e-04 | grad 1.84 | tok/s 13940
step    590 | loss 1.8457 | lr 3.00e-04 | grad 2.69 | tok/s 14289
step    600 | loss 1.8019 | lr 3.00e-04 | grad 1.91 | tok/s 13783
step    610 | loss 1.6115 | lr 3.00e-04 | grad 2.00 | tok/s 14491
step    620 | loss 1.5316 | lr 3.00e-04 | grad 2.03 | tok/s 13741
step    630 | loss 1.6542 | lr 3.00e-04 | grad 3.86 | tok/s 13853
step    640 | loss 1.7902 | lr 3.00e-04 | grad 2.03 | tok/s 14242

Training complete! Final step: 644
