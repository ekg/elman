Using device: cuda
Output directory: benchmark_results/e87_highblock_20260119_154311/87b16k8/level87b16k8_100m_20260119_154316
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level 87b16k8, 63,022,976 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.1649 | lr 1.00e-06 | grad 36.00 | tok/s 21026
step     20 | loss 4.2370 | lr 1.00e-06 | grad 18.12 | tok/s 61796
step     30 | loss 5.2669 | lr 1.00e-06 | grad 8.62 | tok/s 64810
step     40 | loss 4.5206 | lr 1.00e-06 | grad 4.31 | tok/s 65063
step     50 | loss 4.1527 | lr 1.00e-06 | grad 5.62 | tok/s 64607
step     60 | loss 4.0426 | lr 1.00e-06 | grad 4.59 | tok/s 63721
step     70 | loss 3.3370 | lr 1.00e-06 | grad 4.34 | tok/s 61421
step     80 | loss 3.7368 | lr 1.00e-06 | grad 5.25 | tok/s 63669
step     90 | loss 3.3503 | lr 1.00e-06 | grad 5.25 | tok/s 61349
step    100 | loss 3.0761 | lr 1.00e-06 | grad 2.45 | tok/s 62101
step    110 | loss 3.0140 | lr 1.00e-06 | grad 2.06 | tok/s 61168
step    120 | loss 3.1484 | lr 1.00e-06 | grad 2.75 | tok/s 60083
step    130 | loss 2.9602 | lr 1.00e-06 | grad 1.55 | tok/s 61404
step    140 | loss 2.7547 | lr 1.00e-06 | grad 3.58 | tok/s 61103
step    150 | loss 2.6820 | lr 1.00e-06 | grad 2.28 | tok/s 58362
step    160 | loss 2.5330 | lr 1.00e-06 | grad 1.64 | tok/s 58587
step    170 | loss 2.7186 | lr 1.00e-06 | grad 4.38 | tok/s 60416
step    180 | loss 2.7851 | lr 1.00e-06 | grad 1.58 | tok/s 60693
step    190 | loss 2.5433 | lr 1.00e-06 | grad 1.36 | tok/s 61532
step    200 | loss 2.4088 | lr 1.00e-06 | grad 1.46 | tok/s 62988
step    210 | loss 2.6219 | lr 1.00e-06 | grad 2.25 | tok/s 60413
step    220 | loss 2.6149 | lr 1.00e-06 | grad 1.47 | tok/s 62134
step    230 | loss 2.4307 | lr 1.00e-06 | grad 1.54 | tok/s 60364
step    240 | loss 2.5105 | lr 1.00e-06 | grad 1.84 | tok/s 61440
step    250 | loss 2.4240 | lr 1.00e-06 | grad 1.41 | tok/s 60724
step    260 | loss 2.4219 | lr 1.00e-06 | grad 0.97 | tok/s 58187
step    270 | loss 2.3317 | lr 1.00e-06 | grad 1.66 | tok/s 60101
step    280 | loss 2.2615 | lr 1.00e-06 | grad 2.05 | tok/s 60220
step    290 | loss 2.1978 | lr 1.00e-06 | grad 1.21 | tok/s 63004
step    300 | loss 2.1213 | lr 1.00e-06 | grad 1.28 | tok/s 63177
step    310 | loss 2.0711 | lr 1.00e-06 | grad 0.96 | tok/s 63165
step    320 | loss 2.2407 | lr 1.00e-06 | grad 6.28 | tok/s 60836
step    330 | loss 2.3253 | lr 1.00e-06 | grad 1.27 | tok/s 59281
step    340 | loss 2.3180 | lr 1.00e-06 | grad 2.33 | tok/s 60553
step    350 | loss 2.3019 | lr 1.00e-06 | grad 1.13 | tok/s 58786
step    360 | loss 2.2784 | lr 1.00e-06 | grad 2.83 | tok/s 59563
step    370 | loss 2.1428 | lr 1.00e-06 | grad 1.84 | tok/s 60689
step    380 | loss 2.6738 | lr 1.00e-06 | grad 1.45 | tok/s 62223
step    390 | loss 2.2159 | lr 1.00e-06 | grad 1.32 | tok/s 59527
step    400 | loss 2.3211 | lr 1.00e-06 | grad 4.16 | tok/s 61498
step    410 | loss 2.0698 | lr 1.00e-06 | grad 1.92 | tok/s 59663
step    420 | loss 2.2022 | lr 1.00e-06 | grad 1.63 | tok/s 59124
step    430 | loss 2.3457 | lr 1.00e-06 | grad 1.55 | tok/s 58913
step    440 | loss 2.5297 | lr 1.00e-06 | grad 1.69 | tok/s 60966
step    450 | loss 2.1340 | lr 1.00e-06 | grad 1.08 | tok/s 59400
step    460 | loss 2.1507 | lr 1.00e-06 | grad 1.03 | tok/s 59661
step    470 | loss 2.1488 | lr 1.00e-06 | grad 1.60 | tok/s 60321
step    480 | loss 2.0627 | lr 1.00e-06 | grad 0.83 | tok/s 58116
step    490 | loss 1.9781 | lr 1.00e-06 | grad 0.86 | tok/s 59486
step    500 | loss 2.9247 | lr 1.00e-06 | grad 1.83 | tok/s 61016
step    510 | loss 2.0900 | lr 1.00e-06 | grad 1.53 | tok/s 59498
step    520 | loss 2.0741 | lr 1.00e-06 | grad 1.27 | tok/s 61422
step    530 | loss 2.5347 | lr 1.00e-06 | grad 1.30 | tok/s 60343
step    540 | loss 2.0276 | lr 1.00e-06 | grad 1.61 | tok/s 60609
step    550 | loss 1.9296 | lr 1.00e-06 | grad 0.80 | tok/s 62368
step    560 | loss 1.7780 | lr 1.00e-06 | grad 0.98 | tok/s 63096
step    570 | loss 2.1332 | lr 1.00e-06 | grad 2.69 | tok/s 61762
step    580 | loss 2.4521 | lr 1.00e-06 | grad 1.71 | tok/s 60693
step    590 | loss 2.6364 | lr 1.00e-06 | grad 1.86 | tok/s 59307
step    600 | loss 2.1563 | lr 1.00e-06 | grad 1.52 | tok/s 59696
step    610 | loss 2.1748 | lr 1.00e-06 | grad 2.75 | tok/s 62227
step    620 | loss 2.0369 | lr 1.00e-06 | grad 1.31 | tok/s 59390
step    630 | loss 1.9971 | lr 1.00e-06 | grad 1.09 | tok/s 60944
step    640 | loss 2.4459 | lr 1.00e-06 | grad 1.11 | tok/s 61019
step    650 | loss 2.0247 | lr 1.00e-06 | grad 1.25 | tok/s 59935
step    660 | loss 2.3298 | lr 1.00e-06 | grad 4.69 | tok/s 59167
step    670 | loss 2.1767 | lr 1.00e-06 | grad 1.97 | tok/s 61140
step    680 | loss 2.1388 | lr 1.00e-06 | grad 1.45 | tok/s 59325
step    690 | loss 2.1487 | lr 1.00e-06 | grad 2.12 | tok/s 59463
step    700 | loss 2.2052 | lr 1.00e-06 | grad 1.28 | tok/s 60049
step    710 | loss 2.1339 | lr 1.00e-06 | grad 1.37 | tok/s 60371
step    720 | loss 2.1536 | lr 1.00e-06 | grad 2.31 | tok/s 59890
step    730 | loss 2.2388 | lr 1.00e-06 | grad 1.58 | tok/s 60722
step    740 | loss 2.1139 | lr 1.00e-06 | grad 2.06 | tok/s 59913
step    750 | loss 1.9388 | lr 1.00e-06 | grad 1.68 | tok/s 59571
step    760 | loss 2.3881 | lr 1.00e-06 | grad 0.91 | tok/s 60323
step    770 | loss 1.9424 | lr 1.00e-06 | grad 1.34 | tok/s 59840
step    780 | loss 1.9990 | lr 1.00e-06 | grad 1.35 | tok/s 60287
step    790 | loss 1.9876 | lr 1.00e-06 | grad 1.09 | tok/s 60661
step    800 | loss 1.9430 | lr 1.00e-06 | grad 1.11 | tok/s 60804
step    810 | loss 2.0173 | lr 1.00e-06 | grad 2.73 | tok/s 60374
step    820 | loss 2.6730 | lr 1.00e-06 | grad 2.19 | tok/s 61741
step    830 | loss 2.3620 | lr 1.00e-06 | grad 1.05 | tok/s 62989
step    840 | loss 2.0205 | lr 1.00e-06 | grad 0.89 | tok/s 62610
step    850 | loss 2.3538 | lr 1.00e-06 | grad 1.67 | tok/s 59734
step    860 | loss 2.0760 | lr 1.00e-06 | grad 1.32 | tok/s 58579
step    870 | loss 1.9983 | lr 1.00e-06 | grad 1.27 | tok/s 60419
step    880 | loss 2.0596 | lr 1.00e-06 | grad 1.34 | tok/s 60228
step    890 | loss 1.9118 | lr 1.00e-06 | grad 0.95 | tok/s 59777
step    900 | loss 2.3895 | lr 1.00e-06 | grad 0.87 | tok/s 58323
step    910 | loss 1.9626 | lr 1.00e-06 | grad 1.14 | tok/s 59694
step    920 | loss 1.9144 | lr 1.00e-06 | grad 0.87 | tok/s 59453
step    930 | loss 2.0127 | lr 1.00e-06 | grad 1.44 | tok/s 59079
step    940 | loss 1.9225 | lr 1.00e-06 | grad 1.73 | tok/s 58621
step    950 | loss 2.0066 | lr 1.00e-06 | grad 1.62 | tok/s 59980
step    960 | loss 1.7790 | lr 1.00e-06 | grad 0.86 | tok/s 62972
step    970 | loss 1.6128 | lr 1.00e-06 | grad 0.65 | tok/s 62810
step    980 | loss 1.7835 | lr 1.00e-06 | grad 2.41 | tok/s 60976
step    990 | loss 2.1455 | lr 1.00e-06 | grad 0.97 | tok/s 59666
step   1000 | loss 1.9704 | lr 1.00e-06 | grad 0.76 | tok/s 57967
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9704.pt
step   1010 | loss 2.2189 | lr 1.00e-06 | grad 1.93 | tok/s 50911
step   1020 | loss 1.8746 | lr 1.00e-06 | grad 0.93 | tok/s 59812
step   1030 | loss 2.2001 | lr 1.00e-06 | grad 0.86 | tok/s 58770
step   1040 | loss 1.8522 | lr 1.00e-06 | grad 1.49 | tok/s 59954
step   1050 | loss 1.8878 | lr 1.00e-06 | grad 0.94 | tok/s 60017
step   1060 | loss 2.1731 | lr 1.00e-06 | grad 1.62 | tok/s 60128
step   1070 | loss 2.2621 | lr 1.00e-06 | grad 1.08 | tok/s 60404
step   1080 | loss 2.5994 | lr 1.00e-06 | grad 1.47 | tok/s 59866
step   1090 | loss 2.2711 | lr 1.00e-06 | grad 1.35 | tok/s 60329
step   1100 | loss 1.9367 | lr 1.00e-06 | grad 1.30 | tok/s 59936
step   1110 | loss 2.0069 | lr 1.00e-06 | grad 0.96 | tok/s 60903
step   1120 | loss 2.1623 | lr 1.00e-06 | grad 1.13 | tok/s 61686
step   1130 | loss 1.9361 | lr 1.00e-06 | grad 0.80 | tok/s 58640
step   1140 | loss 1.7989 | lr 1.00e-06 | grad 0.96 | tok/s 60092
step   1150 | loss 2.1309 | lr 1.00e-06 | grad 1.27 | tok/s 60000
step   1160 | loss 1.7734 | lr 1.00e-06 | grad 0.76 | tok/s 59359
step   1170 | loss 2.0962 | lr 1.00e-06 | grad 0.87 | tok/s 60041
step   1180 | loss 1.7912 | lr 1.00e-06 | grad 0.81 | tok/s 63187
step   1190 | loss 1.6806 | lr 1.00e-06 | grad 0.60 | tok/s 63129
step   1200 | loss 1.5997 | lr 1.00e-06 | grad 0.74 | tok/s 63133
step   1210 | loss 1.5608 | lr 1.00e-06 | grad 0.81 | tok/s 63162
step   1220 | loss 1.6034 | lr 1.00e-06 | grad 0.95 | tok/s 62668
step   1230 | loss 1.7841 | lr 1.00e-06 | grad 1.02 | tok/s 60342
step   1240 | loss 1.8640 | lr 1.00e-06 | grad 0.98 | tok/s 59326
step   1250 | loss 1.9450 | lr 1.00e-06 | grad 3.11 | tok/s 61133
step   1260 | loss 2.0175 | lr 1.00e-06 | grad 2.33 | tok/s 61117
step   1270 | loss 2.0867 | lr 1.00e-06 | grad 1.47 | tok/s 60300
step   1280 | loss 1.9197 | lr 1.00e-06 | grad 1.03 | tok/s 59643
step   1290 | loss 1.8465 | lr 1.00e-06 | grad 0.94 | tok/s 59412
step   1300 | loss 1.9071 | lr 1.00e-06 | grad 1.03 | tok/s 58993
step   1310 | loss 1.9948 | lr 1.00e-06 | grad 0.92 | tok/s 58979
step   1320 | loss 1.9457 | lr 1.00e-06 | grad 1.27 | tok/s 60049
step   1330 | loss 1.8821 | lr 1.00e-06 | grad 0.95 | tok/s 60117
step   1340 | loss 1.8341 | lr 1.00e-06 | grad 1.06 | tok/s 60175
step   1350 | loss 1.8975 | lr 1.00e-06 | grad 1.91 | tok/s 61776
step   1360 | loss 1.8096 | lr 1.00e-06 | grad 0.88 | tok/s 58643
step   1370 | loss 1.8935 | lr 1.00e-06 | grad 0.79 | tok/s 59545
step   1380 | loss 1.9727 | lr 1.00e-06 | grad 1.16 | tok/s 60001
step   1390 | loss 1.8757 | lr 1.00e-06 | grad 1.66 | tok/s 58573
step   1400 | loss 1.8743 | lr 1.00e-06 | grad 4.38 | tok/s 61004
step   1410 | loss 1.9036 | lr 1.00e-06 | grad 1.12 | tok/s 61527
step   1420 | loss 1.9447 | lr 1.00e-06 | grad 1.00 | tok/s 58576
step   1430 | loss 1.7326 | lr 1.00e-06 | grad 0.90 | tok/s 57184
step   1440 | loss 1.6652 | lr 1.00e-06 | grad 0.80 | tok/s 60371
step   1450 | loss 1.7406 | lr 1.00e-06 | grad 2.27 | tok/s 61672
step   1460 | loss 1.7927 | lr 1.00e-06 | grad 0.77 | tok/s 57513
step   1470 | loss 1.9125 | lr 1.00e-06 | grad 2.16 | tok/s 59590
step   1480 | loss 1.8126 | lr 1.00e-06 | grad 2.20 | tok/s 60264
step   1490 | loss 1.9637 | lr 1.00e-06 | grad 2.33 | tok/s 60157
step   1500 | loss 2.0526 | lr 1.00e-06 | grad 2.62 | tok/s 58582
step   1510 | loss 1.9378 | lr 1.00e-06 | grad 1.27 | tok/s 61622
step   1520 | loss 1.9040 | lr 1.00e-06 | grad 1.17 | tok/s 61062
step   1530 | loss 1.8422 | lr 1.00e-06 | grad 0.88 | tok/s 60640
step   1540 | loss 1.8195 | lr 1.00e-06 | grad 0.75 | tok/s 59393
step   1550 | loss 1.8066 | lr 1.00e-06 | grad 2.61 | tok/s 61851
step   1560 | loss 2.3799 | lr 1.00e-06 | grad 1.38 | tok/s 60185
step   1570 | loss 1.8291 | lr 1.00e-06 | grad 1.49 | tok/s 59111
step   1580 | loss 2.0103 | lr 1.00e-06 | grad 1.18 | tok/s 61052
step   1590 | loss 1.7303 | lr 1.00e-06 | grad 0.86 | tok/s 59592
step   1600 | loss 1.8109 | lr 1.00e-06 | grad 1.02 | tok/s 58410
step   1610 | loss 1.6590 | lr 1.00e-06 | grad 0.86 | tok/s 61854
step   1620 | loss 1.8079 | lr 1.00e-06 | grad 0.77 | tok/s 60858
step   1630 | loss 1.8595 | lr 1.00e-06 | grad 1.34 | tok/s 61452
step   1640 | loss 1.7400 | lr 1.00e-06 | grad 0.72 | tok/s 59289
step   1650 | loss 1.7756 | lr 1.00e-06 | grad 1.36 | tok/s 58456
step   1660 | loss 1.7825 | lr 1.00e-06 | grad 0.91 | tok/s 58744
step   1670 | loss 1.8626 | lr 1.00e-06 | grad 2.05 | tok/s 61323
step   1680 | loss 2.2673 | lr 1.00e-06 | grad 0.79 | tok/s 61363
step   1690 | loss 1.7977 | lr 1.00e-06 | grad 1.18 | tok/s 59918
step   1700 | loss 2.1654 | lr 1.00e-06 | grad 1.26 | tok/s 61171
step   1710 | loss 1.8568 | lr 1.00e-06 | grad 1.06 | tok/s 59378
step   1720 | loss 1.8665 | lr 1.00e-06 | grad 2.66 | tok/s 59637
step   1730 | loss 1.9972 | lr 1.00e-06 | grad 1.13 | tok/s 59627
step   1740 | loss 1.8254 | lr 1.00e-06 | grad 0.79 | tok/s 60619
step   1750 | loss 1.7614 | lr 1.00e-06 | grad 0.82 | tok/s 58413
step   1760 | loss 2.0197 | lr 1.00e-06 | grad 0.82 | tok/s 59161
step   1770 | loss 1.9035 | lr 1.00e-06 | grad 0.72 | tok/s 60633
step   1780 | loss 1.7786 | lr 1.00e-06 | grad 1.12 | tok/s 58326
step   1790 | loss 1.9820 | lr 1.00e-06 | grad 0.95 | tok/s 59403
step   1800 | loss 1.6772 | lr 1.00e-06 | grad 0.73 | tok/s 60445
step   1810 | loss 1.7702 | lr 1.00e-06 | grad 0.90 | tok/s 60201
step   1820 | loss 1.7207 | lr 1.00e-06 | grad 0.95 | tok/s 59504
step   1830 | loss 1.7523 | lr 1.00e-06 | grad 0.82 | tok/s 59344
step   1840 | loss 1.7473 | lr 1.00e-06 | grad 1.05 | tok/s 58847
step   1850 | loss 1.9776 | lr 1.00e-06 | grad 1.17 | tok/s 59360
step   1860 | loss 1.7254 | lr 1.00e-06 | grad 0.64 | tok/s 59229
step   1870 | loss 1.7869 | lr 1.00e-06 | grad 1.49 | tok/s 60615
step   1880 | loss 1.7354 | lr 1.00e-06 | grad 0.84 | tok/s 60762
step   1890 | loss 1.8767 | lr 1.00e-06 | grad 0.91 | tok/s 59703
step   1900 | loss 1.8737 | lr 1.00e-06 | grad 1.12 | tok/s 60330
step   1910 | loss 1.8780 | lr 1.00e-06 | grad 1.38 | tok/s 59492
step   1920 | loss 1.7561 | lr 1.00e-06 | grad 0.95 | tok/s 61359
step   1930 | loss 1.7526 | lr 1.00e-06 | grad 1.10 | tok/s 60858
step   1940 | loss 1.6466 | lr 1.00e-06 | grad 0.91 | tok/s 62034
step   1950 | loss 1.7871 | lr 1.00e-06 | grad 0.95 | tok/s 60367
step   1960 | loss 2.2093 | lr 1.00e-06 | grad 4.66 | tok/s 61607
step   1970 | loss 1.8489 | lr 1.00e-06 | grad 1.64 | tok/s 59541
step   1980 | loss 1.8221 | lr 1.00e-06 | grad 2.52 | tok/s 59387
step   1990 | loss 1.9463 | lr 1.00e-06 | grad 1.09 | tok/s 60820
step   2000 | loss 1.8218 | lr 1.00e-06 | grad 1.34 | tok/s 61364
  >>> saved checkpoint: checkpoint_step_002000_loss_1.8218.pt
step   2010 | loss 1.5856 | lr 1.00e-06 | grad 0.79 | tok/s 51708
step   2020 | loss 1.4394 | lr 1.00e-06 | grad 0.75 | tok/s 63168
step   2030 | loss 1.7439 | lr 1.00e-06 | grad 1.09 | tok/s 62473
step   2040 | loss 1.5814 | lr 1.00e-06 | grad 0.68 | tok/s 63109
step   2050 | loss 1.5253 | lr 1.00e-06 | grad 1.05 | tok/s 62293
step   2060 | loss 1.8334 | lr 1.00e-06 | grad 0.88 | tok/s 59419
step   2070 | loss 1.7614 | lr 1.00e-06 | grad 1.55 | tok/s 62421
step   2080 | loss 1.9154 | lr 1.00e-06 | grad 2.89 | tok/s 58998
step   2090 | loss 1.8099 | lr 1.00e-06 | grad 0.97 | tok/s 61163
step   2100 | loss 1.7721 | lr 1.00e-06 | grad 0.92 | tok/s 59345
step   2110 | loss 1.5672 | lr 1.00e-06 | grad 0.71 | tok/s 61380
step   2120 | loss 1.6360 | lr 1.00e-06 | grad 1.22 | tok/s 60777
step   2130 | loss 1.7709 | lr 1.00e-06 | grad 2.48 | tok/s 59055
step   2140 | loss 1.8219 | lr 1.00e-06 | grad 2.83 | tok/s 58993
step   2150 | loss 1.8311 | lr 1.00e-06 | grad 0.79 | tok/s 59867
step   2160 | loss 1.7666 | lr 1.00e-06 | grad 0.77 | tok/s 59189
step   2170 | loss 1.8807 | lr 1.00e-06 | grad 0.84 | tok/s 59906
step   2180 | loss 1.7598 | lr 1.00e-06 | grad 0.87 | tok/s 61133
step   2190 | loss 2.0945 | lr 1.00e-06 | grad 0.83 | tok/s 60977
step   2200 | loss 1.5115 | lr 1.00e-06 | grad 0.68 | tok/s 63132
step   2210 | loss 1.4919 | lr 1.00e-06 | grad 0.57 | tok/s 63172
step   2220 | loss 1.4544 | lr 1.00e-06 | grad 0.67 | tok/s 63162
step   2230 | loss 1.6917 | lr 1.00e-06 | grad 1.00 | tok/s 60914
step   2240 | loss 1.9681 | lr 1.00e-06 | grad 1.71 | tok/s 62382
step   2250 | loss 1.9222 | lr 1.00e-06 | grad 1.12 | tok/s 61778
step   2260 | loss 1.9229 | lr 1.00e-06 | grad 1.09 | tok/s 60967
step   2270 | loss 1.7437 | lr 1.00e-06 | grad 1.27 | tok/s 59575
step   2280 | loss 1.8740 | lr 1.00e-06 | grad 0.82 | tok/s 59602

Training complete! Final step: 2288
