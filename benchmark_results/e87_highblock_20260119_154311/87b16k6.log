Using device: cuda
Output directory: benchmark_results/e87_highblock_20260119_154311/87b16k6/level87b16k6_100m_20260119_154317
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level 87b16k6, 63,022,976 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.1479 | lr 1.00e-06 | grad 16.75 | tok/s 21373
step     20 | loss 4.2078 | lr 1.00e-06 | grad 11.69 | tok/s 60739
step     30 | loss 5.0604 | lr 1.00e-06 | grad 4.06 | tok/s 64482
step     40 | loss 4.3561 | lr 1.00e-06 | grad 4.44 | tok/s 65098
step     50 | loss 3.9663 | lr 1.00e-06 | grad 4.28 | tok/s 64899
step     60 | loss 4.0092 | lr 1.00e-06 | grad 6.16 | tok/s 63181
step     70 | loss 3.2192 | lr 1.00e-06 | grad 1.92 | tok/s 60975
step     80 | loss 3.6613 | lr 1.00e-06 | grad 7.97 | tok/s 62986
step     90 | loss 3.3768 | lr 1.00e-06 | grad 6.78 | tok/s 60605
step    100 | loss 3.1184 | lr 1.00e-06 | grad 2.89 | tok/s 61290
step    110 | loss 3.0523 | lr 1.00e-06 | grad 3.06 | tok/s 60433
step    120 | loss 3.2392 | lr 1.00e-06 | grad 1.62 | tok/s 59193
step    130 | loss 3.0511 | lr 1.00e-06 | grad 1.81 | tok/s 60393
step    140 | loss 2.8638 | lr 1.00e-06 | grad 1.28 | tok/s 60412
step    150 | loss 2.7205 | lr 1.00e-06 | grad 2.70 | tok/s 57781
step    160 | loss 2.6108 | lr 1.00e-06 | grad 1.91 | tok/s 58076
step    170 | loss 2.7833 | lr 1.00e-06 | grad 4.75 | tok/s 60016
step    180 | loss 2.8327 | lr 1.00e-06 | grad 1.40 | tok/s 60305
step    190 | loss 2.5984 | lr 1.00e-06 | grad 3.25 | tok/s 61077
step    200 | loss 2.4774 | lr 1.00e-06 | grad 1.70 | tok/s 62202
step    210 | loss 2.7280 | lr 1.00e-06 | grad 3.78 | tok/s 59544
step    220 | loss 2.7033 | lr 1.00e-06 | grad 1.50 | tok/s 61479
step    230 | loss 2.5029 | lr 1.00e-06 | grad 1.78 | tok/s 59455
step    240 | loss 2.5777 | lr 1.00e-06 | grad 2.53 | tok/s 60605
step    250 | loss 2.5095 | lr 1.00e-06 | grad 1.47 | tok/s 59724
step    260 | loss 2.4421 | lr 1.00e-06 | grad 1.02 | tok/s 57231
step    270 | loss 2.3569 | lr 1.00e-06 | grad 1.60 | tok/s 59206
step    280 | loss 2.2876 | lr 1.00e-06 | grad 2.30 | tok/s 59210
step    290 | loss 2.2495 | lr 1.00e-06 | grad 1.34 | tok/s 62111
step    300 | loss 2.1647 | lr 1.00e-06 | grad 1.34 | tok/s 62256
step    310 | loss 2.1251 | lr 1.00e-06 | grad 1.06 | tok/s 61836
step    320 | loss 2.2881 | lr 1.00e-06 | grad 3.92 | tok/s 59870
step    330 | loss 2.3514 | lr 1.00e-06 | grad 1.87 | tok/s 58496
step    340 | loss 2.3504 | lr 1.00e-06 | grad 2.12 | tok/s 59595
step    350 | loss 2.3472 | lr 1.00e-06 | grad 1.27 | tok/s 57811
step    360 | loss 2.2996 | lr 1.00e-06 | grad 2.48 | tok/s 58596
step    370 | loss 2.1885 | lr 1.00e-06 | grad 1.42 | tok/s 59620
step    380 | loss 2.6990 | lr 1.00e-06 | grad 1.44 | tok/s 61050
step    390 | loss 2.2469 | lr 1.00e-06 | grad 1.23 | tok/s 58707
step    400 | loss 2.3842 | lr 1.00e-06 | grad 3.91 | tok/s 59977
step    410 | loss 2.1198 | lr 1.00e-06 | grad 1.84 | tok/s 58408
step    420 | loss 2.2247 | lr 1.00e-06 | grad 1.47 | tok/s 57977
step    430 | loss 2.3709 | lr 1.00e-06 | grad 1.59 | tok/s 57870
step    440 | loss 2.5516 | lr 1.00e-06 | grad 1.55 | tok/s 60086
step    450 | loss 2.1751 | lr 1.00e-06 | grad 1.43 | tok/s 58453
step    460 | loss 2.1791 | lr 1.00e-06 | grad 0.94 | tok/s 58661
step    470 | loss 2.1729 | lr 1.00e-06 | grad 1.77 | tok/s 59199
step    480 | loss 2.0961 | lr 1.00e-06 | grad 1.02 | tok/s 57141
step    490 | loss 2.0277 | lr 1.00e-06 | grad 0.96 | tok/s 58274
step    500 | loss 2.8993 | lr 1.00e-06 | grad 1.87 | tok/s 60080
step    510 | loss 2.0991 | lr 1.00e-06 | grad 0.99 | tok/s 58748
step    520 | loss 2.0806 | lr 1.00e-06 | grad 1.17 | tok/s 60727
step    530 | loss 2.5380 | lr 1.00e-06 | grad 1.38 | tok/s 59494
step    540 | loss 2.1179 | lr 1.00e-06 | grad 1.60 | tok/s 59230
step    550 | loss 1.9708 | lr 1.00e-06 | grad 1.13 | tok/s 60852
step    560 | loss 1.8282 | lr 1.00e-06 | grad 0.99 | tok/s 61582
step    570 | loss 2.1870 | lr 1.00e-06 | grad 2.62 | tok/s 60079
step    580 | loss 2.4746 | lr 1.00e-06 | grad 1.55 | tok/s 59416
step    590 | loss 2.6317 | lr 1.00e-06 | grad 1.92 | tok/s 58183
step    600 | loss 2.1440 | lr 1.00e-06 | grad 1.55 | tok/s 58400
step    610 | loss 2.2198 | lr 1.00e-06 | grad 1.51 | tok/s 61118
step    620 | loss 2.0655 | lr 1.00e-06 | grad 1.41 | tok/s 57983
step    630 | loss 2.0720 | lr 1.00e-06 | grad 1.30 | tok/s 59827
step    640 | loss 2.4821 | lr 1.00e-06 | grad 1.38 | tok/s 59857
step    650 | loss 2.0841 | lr 1.00e-06 | grad 1.45 | tok/s 58689
step    660 | loss 2.3600 | lr 1.00e-06 | grad 4.44 | tok/s 57950
step    670 | loss 2.2130 | lr 1.00e-06 | grad 2.08 | tok/s 59803
step    680 | loss 2.1669 | lr 1.00e-06 | grad 1.21 | tok/s 57814
step    690 | loss 2.1660 | lr 1.00e-06 | grad 1.48 | tok/s 58297
step    700 | loss 2.2409 | lr 1.00e-06 | grad 1.30 | tok/s 58622
step    710 | loss 2.1792 | lr 1.00e-06 | grad 1.27 | tok/s 58976
step    720 | loss 2.2114 | lr 1.00e-06 | grad 5.09 | tok/s 58759
step    730 | loss 2.2821 | lr 1.00e-06 | grad 1.42 | tok/s 59216
step    740 | loss 2.1414 | lr 1.00e-06 | grad 2.12 | tok/s 58732
step    750 | loss 1.9757 | lr 1.00e-06 | grad 1.51 | tok/s 58124
step    760 | loss 2.3241 | lr 1.00e-06 | grad 0.88 | tok/s 58707
step    770 | loss 1.9733 | lr 1.00e-06 | grad 1.55 | tok/s 58388
step    780 | loss 2.0316 | lr 1.00e-06 | grad 1.52 | tok/s 59197
step    790 | loss 2.0227 | lr 1.00e-06 | grad 1.15 | tok/s 59533
step    800 | loss 2.0081 | lr 1.00e-06 | grad 1.23 | tok/s 59476
step    810 | loss 2.0396 | lr 1.00e-06 | grad 2.39 | tok/s 58955
step    820 | loss 2.6748 | lr 1.00e-06 | grad 1.99 | tok/s 60398
step    830 | loss 2.3679 | lr 1.00e-06 | grad 1.17 | tok/s 61405
step    840 | loss 2.0815 | lr 1.00e-06 | grad 1.11 | tok/s 61438
step    850 | loss 2.3842 | lr 1.00e-06 | grad 1.52 | tok/s 58532
step    860 | loss 2.1238 | lr 1.00e-06 | grad 1.16 | tok/s 57250
step    870 | loss 2.0411 | lr 1.00e-06 | grad 1.20 | tok/s 59112
step    880 | loss 2.1170 | lr 1.00e-06 | grad 1.34 | tok/s 58729
step    890 | loss 1.9687 | lr 1.00e-06 | grad 0.96 | tok/s 58617
step    900 | loss 2.4535 | lr 1.00e-06 | grad 0.92 | tok/s 56920
step    910 | loss 1.9931 | lr 1.00e-06 | grad 1.04 | tok/s 58272
step    920 | loss 1.9555 | lr 1.00e-06 | grad 0.93 | tok/s 57932
step    930 | loss 2.0571 | lr 1.00e-06 | grad 1.52 | tok/s 57734
step    940 | loss 1.9567 | lr 1.00e-06 | grad 1.60 | tok/s 57363
step    950 | loss 2.0608 | lr 1.00e-06 | grad 1.81 | tok/s 58728
step    960 | loss 1.8324 | lr 1.00e-06 | grad 0.83 | tok/s 61341
step    970 | loss 1.6572 | lr 1.00e-06 | grad 0.71 | tok/s 61339
step    980 | loss 1.8406 | lr 1.00e-06 | grad 2.30 | tok/s 59709
step    990 | loss 2.1762 | lr 1.00e-06 | grad 0.95 | tok/s 58169
step   1000 | loss 1.9955 | lr 1.00e-06 | grad 0.76 | tok/s 56787
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9955.pt
step   1010 | loss 2.2846 | lr 1.00e-06 | grad 1.65 | tok/s 50185
step   1020 | loss 1.9153 | lr 1.00e-06 | grad 1.26 | tok/s 58335
step   1030 | loss 2.2301 | lr 1.00e-06 | grad 1.01 | tok/s 57338
step   1040 | loss 1.8929 | lr 1.00e-06 | grad 1.43 | tok/s 58443
step   1050 | loss 1.9187 | lr 1.00e-06 | grad 0.93 | tok/s 58796
step   1060 | loss 2.2194 | lr 1.00e-06 | grad 1.68 | tok/s 58884
step   1070 | loss 2.2831 | lr 1.00e-06 | grad 1.08 | tok/s 59102
step   1080 | loss 2.5158 | lr 1.00e-06 | grad 1.36 | tok/s 58277
step   1090 | loss 2.3068 | lr 1.00e-06 | grad 1.95 | tok/s 58791
step   1100 | loss 1.9862 | lr 1.00e-06 | grad 1.27 | tok/s 58387
step   1110 | loss 2.0557 | lr 1.00e-06 | grad 1.00 | tok/s 59162
step   1120 | loss 2.2185 | lr 1.00e-06 | grad 1.20 | tok/s 60174
step   1130 | loss 1.9884 | lr 1.00e-06 | grad 0.83 | tok/s 57192
step   1140 | loss 1.8429 | lr 1.00e-06 | grad 1.01 | tok/s 58603
step   1150 | loss 2.1513 | lr 1.00e-06 | grad 1.23 | tok/s 58418
step   1160 | loss 1.7984 | lr 1.00e-06 | grad 0.87 | tok/s 57753
step   1170 | loss 2.1449 | lr 1.00e-06 | grad 0.89 | tok/s 58588
step   1180 | loss 1.8293 | lr 1.00e-06 | grad 1.03 | tok/s 61465
step   1190 | loss 1.7220 | lr 1.00e-06 | grad 0.70 | tok/s 61262
step   1200 | loss 1.6411 | lr 1.00e-06 | grad 0.82 | tok/s 61355
step   1210 | loss 1.6042 | lr 1.00e-06 | grad 0.90 | tok/s 61352
step   1220 | loss 1.6470 | lr 1.00e-06 | grad 1.03 | tok/s 60869
step   1230 | loss 1.8061 | lr 1.00e-06 | grad 1.02 | tok/s 58891
step   1240 | loss 1.8987 | lr 1.00e-06 | grad 0.93 | tok/s 57759
step   1250 | loss 1.9883 | lr 1.00e-06 | grad 3.42 | tok/s 59617
step   1260 | loss 2.0528 | lr 1.00e-06 | grad 2.31 | tok/s 59503
step   1270 | loss 2.1107 | lr 1.00e-06 | grad 1.42 | tok/s 58768
step   1280 | loss 1.9447 | lr 1.00e-06 | grad 1.00 | tok/s 58102
step   1290 | loss 1.8711 | lr 1.00e-06 | grad 0.91 | tok/s 57784
step   1300 | loss 1.9322 | lr 1.00e-06 | grad 0.92 | tok/s 57568
step   1310 | loss 1.9937 | lr 1.00e-06 | grad 0.95 | tok/s 57471
step   1320 | loss 1.9640 | lr 1.00e-06 | grad 1.35 | tok/s 58403
step   1330 | loss 1.9116 | lr 1.00e-06 | grad 0.98 | tok/s 58586
step   1340 | loss 1.8993 | lr 1.00e-06 | grad 1.06 | tok/s 58545
step   1350 | loss 1.9384 | lr 1.00e-06 | grad 2.03 | tok/s 60016
step   1360 | loss 1.8377 | lr 1.00e-06 | grad 0.87 | tok/s 57068
step   1370 | loss 1.9198 | lr 1.00e-06 | grad 0.81 | tok/s 58111
step   1380 | loss 1.9985 | lr 1.00e-06 | grad 1.05 | tok/s 58460
step   1390 | loss 1.9064 | lr 1.00e-06 | grad 1.62 | tok/s 56998
step   1400 | loss 1.9277 | lr 1.00e-06 | grad 6.50 | tok/s 59380
step   1410 | loss 1.9471 | lr 1.00e-06 | grad 2.03 | tok/s 59779
step   1420 | loss 1.9868 | lr 1.00e-06 | grad 1.00 | tok/s 57082
step   1430 | loss 1.7540 | lr 1.00e-06 | grad 0.94 | tok/s 55722
step   1440 | loss 1.6965 | lr 1.00e-06 | grad 0.88 | tok/s 58783
step   1450 | loss 1.7792 | lr 1.00e-06 | grad 2.48 | tok/s 59598
step   1460 | loss 1.8190 | lr 1.00e-06 | grad 0.77 | tok/s 55808
step   1470 | loss 1.9306 | lr 1.00e-06 | grad 1.91 | tok/s 57829
step   1480 | loss 1.8410 | lr 1.00e-06 | grad 2.33 | tok/s 58475
step   1490 | loss 1.9891 | lr 1.00e-06 | grad 2.55 | tok/s 58374
step   1500 | loss 2.0851 | lr 1.00e-06 | grad 2.11 | tok/s 56780
step   1510 | loss 1.9714 | lr 1.00e-06 | grad 1.28 | tok/s 59536
step   1520 | loss 1.9401 | lr 1.00e-06 | grad 1.14 | tok/s 59110
step   1530 | loss 1.8775 | lr 1.00e-06 | grad 0.85 | tok/s 58814
step   1540 | loss 1.8447 | lr 1.00e-06 | grad 2.55 | tok/s 57643
step   1550 | loss 1.8398 | lr 1.00e-06 | grad 2.83 | tok/s 59975
step   1560 | loss 2.4653 | lr 1.00e-06 | grad 1.42 | tok/s 58505
step   1570 | loss 1.8609 | lr 1.00e-06 | grad 1.30 | tok/s 57312
step   1580 | loss 2.0555 | lr 1.00e-06 | grad 1.18 | tok/s 59270
step   1590 | loss 1.7703 | lr 1.00e-06 | grad 0.95 | tok/s 57888
step   1600 | loss 1.8437 | lr 1.00e-06 | grad 1.04 | tok/s 56756
step   1610 | loss 1.6821 | lr 1.00e-06 | grad 0.79 | tok/s 59960
step   1620 | loss 1.8409 | lr 1.00e-06 | grad 0.90 | tok/s 59099
step   1630 | loss 1.9064 | lr 1.00e-06 | grad 1.59 | tok/s 59435
step   1640 | loss 1.7773 | lr 1.00e-06 | grad 0.72 | tok/s 57557
step   1650 | loss 1.8122 | lr 1.00e-06 | grad 1.52 | tok/s 56759
step   1660 | loss 1.8093 | lr 1.00e-06 | grad 0.94 | tok/s 57148
step   1670 | loss 1.8916 | lr 1.00e-06 | grad 2.19 | tok/s 59545
step   1680 | loss 2.3176 | lr 1.00e-06 | grad 0.79 | tok/s 59262
step   1690 | loss 1.8193 | lr 1.00e-06 | grad 1.16 | tok/s 58227
step   1700 | loss 2.2177 | lr 1.00e-06 | grad 1.65 | tok/s 59281
step   1710 | loss 1.8910 | lr 1.00e-06 | grad 1.05 | tok/s 57756
step   1720 | loss 1.8927 | lr 1.00e-06 | grad 1.18 | tok/s 57940
step   1730 | loss 2.0194 | lr 1.00e-06 | grad 1.23 | tok/s 57734
step   1740 | loss 1.8574 | lr 1.00e-06 | grad 0.83 | tok/s 58737
step   1750 | loss 1.7849 | lr 1.00e-06 | grad 0.72 | tok/s 56685
step   1760 | loss 2.0622 | lr 1.00e-06 | grad 0.77 | tok/s 57421
step   1770 | loss 1.9250 | lr 1.00e-06 | grad 0.70 | tok/s 58774
step   1780 | loss 1.7946 | lr 1.00e-06 | grad 1.16 | tok/s 56618
step   1790 | loss 2.0132 | lr 1.00e-06 | grad 0.84 | tok/s 57683
step   1800 | loss 1.7109 | lr 1.00e-06 | grad 0.74 | tok/s 58662
step   1810 | loss 1.8046 | lr 1.00e-06 | grad 1.00 | tok/s 58386
step   1820 | loss 1.7908 | lr 1.00e-06 | grad 0.94 | tok/s 57718
step   1830 | loss 1.7855 | lr 1.00e-06 | grad 0.88 | tok/s 57411
step   1840 | loss 1.7839 | lr 1.00e-06 | grad 1.01 | tok/s 56957
step   1850 | loss 1.9911 | lr 1.00e-06 | grad 1.27 | tok/s 57638
step   1860 | loss 1.7572 | lr 1.00e-06 | grad 0.72 | tok/s 57492
step   1870 | loss 1.8147 | lr 1.00e-06 | grad 1.36 | tok/s 58761
step   1880 | loss 1.7643 | lr 1.00e-06 | grad 0.80 | tok/s 58925
step   1890 | loss 1.8978 | lr 1.00e-06 | grad 0.91 | tok/s 57907
step   1900 | loss 1.9418 | lr 1.00e-06 | grad 1.37 | tok/s 58656
step   1910 | loss 1.9022 | lr 1.00e-06 | grad 1.38 | tok/s 57763
step   1920 | loss 1.7855 | lr 1.00e-06 | grad 0.98 | tok/s 59754
step   1930 | loss 1.7760 | lr 1.00e-06 | grad 1.08 | tok/s 59223
step   1940 | loss 1.6734 | lr 1.00e-06 | grad 0.95 | tok/s 60274
step   1950 | loss 1.8017 | lr 1.00e-06 | grad 1.05 | tok/s 58753
step   1960 | loss 2.2208 | lr 1.00e-06 | grad 4.84 | tok/s 60035
step   1970 | loss 1.8787 | lr 1.00e-06 | grad 1.36 | tok/s 57977
step   1980 | loss 1.8586 | lr 1.00e-06 | grad 1.95 | tok/s 57940
step   1990 | loss 1.9646 | lr 1.00e-06 | grad 1.05 | tok/s 59128
step   2000 | loss 1.8683 | lr 1.00e-06 | grad 1.78 | tok/s 59610
  >>> saved checkpoint: checkpoint_step_002000_loss_1.8683.pt
step   2010 | loss 1.6031 | lr 1.00e-06 | grad 0.95 | tok/s 51333
step   2020 | loss 1.4665 | lr 1.00e-06 | grad 0.76 | tok/s 61379
step   2030 | loss 1.7798 | lr 1.00e-06 | grad 1.23 | tok/s 60775
step   2040 | loss 1.6103 | lr 1.00e-06 | grad 0.70 | tok/s 61433
step   2050 | loss 1.5522 | lr 1.00e-06 | grad 1.09 | tok/s 60519
step   2060 | loss 1.8506 | lr 1.00e-06 | grad 0.89 | tok/s 57804
step   2070 | loss 1.7741 | lr 1.00e-06 | grad 1.52 | tok/s 60641
step   2080 | loss 1.9725 | lr 1.00e-06 | grad 3.55 | tok/s 57402
step   2090 | loss 1.8584 | lr 1.00e-06 | grad 1.01 | tok/s 59492
step   2100 | loss 1.7971 | lr 1.00e-06 | grad 0.99 | tok/s 57734
step   2110 | loss 1.6052 | lr 1.00e-06 | grad 0.78 | tok/s 59869
step   2120 | loss 1.6616 | lr 1.00e-06 | grad 1.10 | tok/s 59341
step   2130 | loss 1.7875 | lr 1.00e-06 | grad 2.83 | tok/s 57643
step   2140 | loss 1.8574 | lr 1.00e-06 | grad 2.83 | tok/s 57406
step   2150 | loss 1.8801 | lr 1.00e-06 | grad 0.77 | tok/s 58336
step   2160 | loss 1.8053 | lr 1.00e-06 | grad 0.73 | tok/s 57723
step   2170 | loss 1.9210 | lr 1.00e-06 | grad 0.81 | tok/s 58321
step   2180 | loss 1.7844 | lr 1.00e-06 | grad 0.87 | tok/s 59491
step   2190 | loss 2.1606 | lr 1.00e-06 | grad 0.86 | tok/s 59313
step   2200 | loss 1.5347 | lr 1.00e-06 | grad 0.61 | tok/s 61419
step   2210 | loss 1.5178 | lr 1.00e-06 | grad 0.57 | tok/s 61315
step   2220 | loss 1.4800 | lr 1.00e-06 | grad 0.68 | tok/s 61423
step   2230 | loss 1.7242 | lr 1.00e-06 | grad 1.02 | tok/s 59209

Training complete! Final step: 2236
