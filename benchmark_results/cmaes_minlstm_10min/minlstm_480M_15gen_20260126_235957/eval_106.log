Using device: cuda
Output directory: benchmark_results/cmaes_minlstm_10min/minlstm_480M_15gen_20260126_235957/eval_106/levelminlstm_100m_20260127_021311
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level minlstm, 303,261,696 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 6.0970 | lr 3.00e-04 | grad 8.31 | tok/s 19486
step     20 | loss 2.9617 | lr 3.00e-04 | grad 3.62 | tok/s 23991
step     30 | loss 2.7800 | lr 3.00e-04 | grad 3.33 | tok/s 24154
step     40 | loss 2.7197 | lr 3.00e-04 | grad 3.11 | tok/s 23088
step     50 | loss 2.5169 | lr 3.00e-04 | grad 12.81 | tok/s 23047
step     60 | loss 2.8224 | lr 3.00e-04 | grad 3.66 | tok/s 24563
step     70 | loss 2.3417 | lr 3.00e-04 | grad 3.72 | tok/s 24635
step     80 | loss 4.1021 | lr 3.00e-04 | grad 15.50 | tok/s 24523
step     90 | loss 4.6333 | lr 3.00e-04 | grad 10.19 | tok/s 25195
step    100 | loss 3.6780 | lr 3.00e-04 | grad 11.06 | tok/s 25186
step    110 | loss 3.4372 | lr 3.00e-04 | grad 3.39 | tok/s 25177
step    120 | loss 3.4401 | lr 3.00e-04 | grad 6.06 | tok/s 25179
step    130 | loss 3.3628 | lr 3.00e-04 | grad 4.88 | tok/s 25169
step    140 | loss 2.8487 | lr 3.00e-04 | grad 12.25 | tok/s 25163
step    150 | loss 3.0022 | lr 3.00e-04 | grad 9.19 | tok/s 25138
step    160 | loss 2.8308 | lr 3.00e-04 | grad 10.56 | tok/s 25119
step    170 | loss 2.7620 | lr 3.00e-04 | grad 8.12 | tok/s 25107
step    180 | loss 2.6694 | lr 3.00e-04 | grad 5.34 | tok/s 25093
step    190 | loss 2.7232 | lr 3.00e-04 | grad 6.16 | tok/s 25095
step    200 | loss 2.6339 | lr 3.00e-04 | grad 2.02 | tok/s 25056
step    210 | loss 2.4922 | lr 3.00e-04 | grad 4.41 | tok/s 25060
step    220 | loss 2.4141 | lr 3.00e-04 | grad 4.06 | tok/s 24735
step    230 | loss 2.6905 | lr 3.00e-04 | grad 7.03 | tok/s 24746
step    240 | loss 2.6002 | lr 3.00e-04 | grad 2.42 | tok/s 23417
step    250 | loss 2.4941 | lr 3.00e-04 | grad 2.62 | tok/s 23602
step    260 | loss 2.2184 | lr 3.00e-04 | grad 4.28 | tok/s 24778
step    270 | loss 2.3131 | lr 3.00e-04 | grad 2.17 | tok/s 23871
step    280 | loss 2.3680 | lr 3.00e-04 | grad 7.72 | tok/s 24489
step    290 | loss 2.5961 | lr 3.00e-04 | grad 3.00 | tok/s 24373
step    300 | loss 1.5184 | lr 3.00e-04 | grad 2.09 | tok/s 25074
step    310 | loss 2.2122 | lr 3.00e-04 | grad 3.34 | tok/s 24644
step    320 | loss 2.6037 | lr 3.00e-04 | grad 2.66 | tok/s 24980
step    330 | loss 2.3011 | lr 3.00e-04 | grad 2.44 | tok/s 22596
step    340 | loss 2.4660 | lr 3.00e-04 | grad 1.74 | tok/s 24000
step    350 | loss 2.3180 | lr 3.00e-04 | grad 2.33 | tok/s 23707
step    360 | loss 2.3713 | lr 3.00e-04 | grad 3.53 | tok/s 25002
step    370 | loss 2.1929 | lr 3.00e-04 | grad 2.17 | tok/s 22985
step    380 | loss 2.1435 | lr 3.00e-04 | grad 2.22 | tok/s 23504
step    390 | loss 2.0063 | lr 3.00e-04 | grad 2.31 | tok/s 24755
step    400 | loss 1.9374 | lr 3.00e-04 | grad 3.28 | tok/s 24772
step    410 | loss 1.9593 | lr 3.00e-04 | grad 4.19 | tok/s 25005
step    420 | loss 1.9151 | lr 3.00e-04 | grad 2.22 | tok/s 22845
step    430 | loss 2.3127 | lr 3.00e-04 | grad 3.11 | tok/s 24324
step    440 | loss 2.4963 | lr 3.00e-04 | grad 2.70 | tok/s 23876
step    450 | loss 2.4988 | lr 3.00e-04 | grad 12.06 | tok/s 23961
step    460 | loss 2.2411 | lr 3.00e-04 | grad 1.86 | tok/s 23425
step    470 | loss 2.1431 | lr 3.00e-04 | grad 1.94 | tok/s 23847
step    480 | loss 2.1798 | lr 3.00e-04 | grad 2.50 | tok/s 24312
step    490 | loss 2.5441 | lr 3.00e-04 | grad 2.38 | tok/s 24015
step    500 | loss 1.9423 | lr 3.00e-04 | grad 2.12 | tok/s 23655
step    510 | loss 2.1179 | lr 3.00e-04 | grad 2.30 | tok/s 24662
step    520 | loss 2.0955 | lr 3.00e-04 | grad 1.77 | tok/s 24802
step    530 | loss 2.2238 | lr 3.00e-04 | grad 2.48 | tok/s 24513
step    540 | loss 2.0937 | lr 3.00e-04 | grad 1.55 | tok/s 23904
step    550 | loss 1.8479 | lr 3.00e-04 | grad 2.09 | tok/s 23905
step    560 | loss 1.9753 | lr 3.00e-04 | grad 5.66 | tok/s 21845
step    570 | loss 1.9946 | lr 3.00e-04 | grad 2.36 | tok/s 23900
step    580 | loss 1.9092 | lr 3.00e-04 | grad 2.19 | tok/s 23437
step    590 | loss 1.8433 | lr 3.00e-04 | grad 1.82 | tok/s 23146
step    600 | loss 2.2873 | lr 3.00e-04 | grad 2.17 | tok/s 23714
step    610 | loss 1.9901 | lr 3.00e-04 | grad 2.20 | tok/s 23746
step    620 | loss 1.8269 | lr 3.00e-04 | grad 2.95 | tok/s 23575
step    630 | loss 1.9149 | lr 3.00e-04 | grad 3.42 | tok/s 23111
step    640 | loss 2.0803 | lr 3.00e-04 | grad 3.64 | tok/s 23657
step    650 | loss 2.0193 | lr 3.00e-04 | grad 2.16 | tok/s 23864
step    660 | loss 1.9749 | lr 3.00e-04 | grad 2.34 | tok/s 24247
step    670 | loss 1.8734 | lr 3.00e-04 | grad 1.81 | tok/s 23649
step    680 | loss 2.2853 | lr 3.00e-04 | grad 1.72 | tok/s 24655
step    690 | loss 2.0947 | lr 3.00e-04 | grad 2.67 | tok/s 23397
step    700 | loss 2.0061 | lr 3.00e-04 | grad 2.28 | tok/s 25005
step    710 | loss 1.8911 | lr 3.00e-04 | grad 2.39 | tok/s 24309
step    720 | loss 1.6978 | lr 3.00e-04 | grad 2.02 | tok/s 22067
step    730 | loss 1.8632 | lr 3.00e-04 | grad 2.47 | tok/s 24999
step    740 | loss 1.7387 | lr 3.00e-04 | grad 1.62 | tok/s 24580
step    750 | loss 1.7068 | lr 3.00e-04 | grad 2.11 | tok/s 25007
step    760 | loss 1.5061 | lr 3.00e-04 | grad 2.05 | tok/s 25012
step    770 | loss 1.4869 | lr 3.00e-04 | grad 1.50 | tok/s 24994
step    780 | loss 1.4140 | lr 3.00e-04 | grad 1.98 | tok/s 25007
step    790 | loss 1.3254 | lr 3.00e-04 | grad 1.77 | tok/s 25008
step    800 | loss 1.8749 | lr 3.00e-04 | grad 2.56 | tok/s 23372
step    810 | loss 2.0958 | lr 3.00e-04 | grad 2.50 | tok/s 24002
step    820 | loss 1.9225 | lr 3.00e-04 | grad 3.20 | tok/s 23697
step    830 | loss 1.9335 | lr 3.00e-04 | grad 2.12 | tok/s 24168
step    840 | loss 1.8615 | lr 3.00e-04 | grad 2.47 | tok/s 24971
step    850 | loss 1.9610 | lr 3.00e-04 | grad 8.75 | tok/s 24862
step    860 | loss 1.8148 | lr 3.00e-04 | grad 2.28 | tok/s 24769
step    870 | loss 1.7867 | lr 3.00e-04 | grad 1.49 | tok/s 23895
step    880 | loss 1.8411 | lr 3.00e-04 | grad 2.92 | tok/s 23738
step    890 | loss 1.9465 | lr 3.00e-04 | grad 1.68 | tok/s 24173
step    900 | loss 1.8721 | lr 3.00e-04 | grad 2.03 | tok/s 24247
step    910 | loss 1.6668 | lr 3.00e-04 | grad 1.97 | tok/s 23584
step    920 | loss 1.7623 | lr 3.00e-04 | grad 2.00 | tok/s 24665
step    930 | loss 1.7886 | lr 3.00e-04 | grad 1.93 | tok/s 23757
step    940 | loss 1.8393 | lr 3.00e-04 | grad 1.95 | tok/s 24062
step    950 | loss 1.7658 | lr 3.00e-04 | grad 1.98 | tok/s 24880
step    960 | loss 1.6313 | lr 3.00e-04 | grad 1.77 | tok/s 24995
step    970 | loss 1.8098 | lr 3.00e-04 | grad 1.61 | tok/s 23907
step    980 | loss 1.9507 | lr 3.00e-04 | grad 1.62 | tok/s 24066
step    990 | loss 1.7041 | lr 3.00e-04 | grad 1.82 | tok/s 23998
step   1000 | loss 1.8682 | lr 3.00e-04 | grad 2.02 | tok/s 23708
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8682.pt
step   1010 | loss 2.0382 | lr 3.00e-04 | grad 2.98 | tok/s 11017
step   1020 | loss 1.8886 | lr 3.00e-04 | grad 2.47 | tok/s 22858
step   1030 | loss 1.7353 | lr 3.00e-04 | grad 4.66 | tok/s 22835
step   1040 | loss 1.6320 | lr 3.00e-04 | grad 1.50 | tok/s 24653
step   1050 | loss 1.6746 | lr 3.00e-04 | grad 1.90 | tok/s 22937
step   1060 | loss 1.9061 | lr 3.00e-04 | grad 2.78 | tok/s 24486
step   1070 | loss 1.9874 | lr 3.00e-04 | grad 2.89 | tok/s 24611
step   1080 | loss 1.8279 | lr 3.00e-04 | grad 1.91 | tok/s 23493
step   1090 | loss 1.5943 | lr 3.00e-04 | grad 1.55 | tok/s 22901
step   1100 | loss 1.2802 | lr 3.00e-04 | grad 1.61 | tok/s 24576
step   1110 | loss 1.7389 | lr 3.00e-04 | grad 1.64 | tok/s 24327
step   1120 | loss 1.6003 | lr 3.00e-04 | grad 1.78 | tok/s 25025
step   1130 | loss 1.5945 | lr 3.00e-04 | grad 1.81 | tok/s 25009
step   1140 | loss 1.4974 | lr 3.00e-04 | grad 2.08 | tok/s 25006
step   1150 | loss 1.5373 | lr 3.00e-04 | grad 1.73 | tok/s 25014
step   1160 | loss 1.4847 | lr 3.00e-04 | grad 1.61 | tok/s 25018
step   1170 | loss 1.4370 | lr 3.00e-04 | grad 1.84 | tok/s 25004
step   1180 | loss 1.5362 | lr 3.00e-04 | grad 1.95 | tok/s 25003
step   1190 | loss 1.5027 | lr 3.00e-04 | grad 1.41 | tok/s 24998
step   1200 | loss 1.4218 | lr 3.00e-04 | grad 2.44 | tok/s 25013
step   1210 | loss 1.4771 | lr 3.00e-04 | grad 1.94 | tok/s 24999
step   1220 | loss 1.4906 | lr 3.00e-04 | grad 2.12 | tok/s 25004
step   1230 | loss 1.4290 | lr 3.00e-04 | grad 1.80 | tok/s 24999
step   1240 | loss 1.4682 | lr 3.00e-04 | grad 1.87 | tok/s 25000
step   1250 | loss 1.8174 | lr 3.00e-04 | grad 4.31 | tok/s 24120
step   1260 | loss 1.8073 | lr 3.00e-04 | grad 2.70 | tok/s 23387
step   1270 | loss 1.6018 | lr 3.00e-04 | grad 1.83 | tok/s 24125
step   1280 | loss 1.8799 | lr 3.00e-04 | grad 1.98 | tok/s 23007
step   1290 | loss 1.7185 | lr 3.00e-04 | grad 1.72 | tok/s 24424
step   1300 | loss 1.7032 | lr 3.00e-04 | grad 1.76 | tok/s 24551
step   1310 | loss 1.6785 | lr 3.00e-04 | grad 2.06 | tok/s 23737
step   1320 | loss 1.7104 | lr 3.00e-04 | grad 2.56 | tok/s 24454
step   1330 | loss 1.8661 | lr 3.00e-04 | grad 1.50 | tok/s 24927
step   1340 | loss 1.5368 | lr 3.00e-04 | grad 2.03 | tok/s 23787
step   1350 | loss 1.9401 | lr 3.00e-04 | grad 2.25 | tok/s 22988
step   1360 | loss 1.8581 | lr 3.00e-04 | grad 2.08 | tok/s 23723
step   1370 | loss 1.6036 | lr 3.00e-04 | grad 1.41 | tok/s 23639
step   1380 | loss 1.8529 | lr 3.00e-04 | grad 1.70 | tok/s 24282
step   1390 | loss 1.7029 | lr 3.00e-04 | grad 2.14 | tok/s 22881
step   1400 | loss 1.5832 | lr 3.00e-04 | grad 2.33 | tok/s 23515
step   1410 | loss 1.6250 | lr 3.00e-04 | grad 2.64 | tok/s 23921
step   1420 | loss 1.7464 | lr 3.00e-04 | grad 1.57 | tok/s 23333
step   1430 | loss 1.8026 | lr 3.00e-04 | grad 2.00 | tok/s 24453
step   1440 | loss 1.4971 | lr 3.00e-04 | grad 1.89 | tok/s 23809
step   1450 | loss 1.3146 | lr 3.00e-04 | grad 1.84 | tok/s 25022
step   1460 | loss 1.6577 | lr 3.00e-04 | grad 2.14 | tok/s 24300
step   1470 | loss 1.7613 | lr 3.00e-04 | grad 1.68 | tok/s 23534
step   1480 | loss 1.7682 | lr 3.00e-04 | grad 3.05 | tok/s 24544
step   1490 | loss 2.2797 | lr 3.00e-04 | grad 3.09 | tok/s 25022
step   1500 | loss 1.7256 | lr 3.00e-04 | grad 1.96 | tok/s 24900
step   1510 | loss 1.5305 | lr 3.00e-04 | grad 4.69 | tok/s 24721
step   1520 | loss 1.7496 | lr 3.00e-04 | grad 1.91 | tok/s 24973
step   1530 | loss 1.6334 | lr 3.00e-04 | grad 1.97 | tok/s 24165
step   1540 | loss 1.6881 | lr 3.00e-04 | grad 3.66 | tok/s 23932
step   1550 | loss 1.6873 | lr 3.00e-04 | grad 2.08 | tok/s 24133
step   1560 | loss 1.4953 | lr 3.00e-04 | grad 1.93 | tok/s 24646
step   1570 | loss 1.6963 | lr 3.00e-04 | grad 1.88 | tok/s 23736
step   1580 | loss 1.6264 | lr 3.00e-04 | grad 2.14 | tok/s 24419
step   1590 | loss 2.2678 | lr 3.00e-04 | grad 2.47 | tok/s 24895
step   1600 | loss 1.4961 | lr 3.00e-04 | grad 1.61 | tok/s 23611
step   1610 | loss 0.9766 | lr 3.00e-04 | grad 1.56 | tok/s 25064
step   1620 | loss 1.4565 | lr 3.00e-04 | grad 1.64 | tok/s 22394
step   1630 | loss 1.8311 | lr 3.00e-04 | grad 2.11 | tok/s 23958
step   1640 | loss 1.4554 | lr 3.00e-04 | grad 3.09 | tok/s 24932
step   1650 | loss 1.6398 | lr 3.00e-04 | grad 1.55 | tok/s 22784
step   1660 | loss 1.7389 | lr 3.00e-04 | grad 1.80 | tok/s 23136
step   1670 | loss 1.4365 | lr 3.00e-04 | grad 1.48 | tok/s 24759
step   1680 | loss 2.0231 | lr 3.00e-04 | grad 1.83 | tok/s 23082
step   1690 | loss 1.6728 | lr 3.00e-04 | grad 2.80 | tok/s 23536
step   1700 | loss 1.6969 | lr 3.00e-04 | grad 2.41 | tok/s 24546
step   1710 | loss 1.6106 | lr 3.00e-04 | grad 1.73 | tok/s 23430
step   1720 | loss 1.6957 | lr 3.00e-04 | grad 2.08 | tok/s 24434
step   1730 | loss 1.7997 | lr 3.00e-04 | grad 2.17 | tok/s 24998
step   1740 | loss 1.6362 | lr 3.00e-04 | grad 1.59 | tok/s 25019
step   1750 | loss 1.6697 | lr 3.00e-04 | grad 2.20 | tok/s 23960
step   1760 | loss 1.6919 | lr 3.00e-04 | grad 2.16 | tok/s 24013
step   1770 | loss 1.7383 | lr 3.00e-04 | grad 1.73 | tok/s 24053
step   1780 | loss 1.6361 | lr 3.00e-04 | grad 3.25 | tok/s 23751
step   1790 | loss 1.5885 | lr 3.00e-04 | grad 2.86 | tok/s 24126
step   1800 | loss 1.6036 | lr 3.00e-04 | grad 1.78 | tok/s 24028
step   1810 | loss 1.7508 | lr 3.00e-04 | grad 1.58 | tok/s 23539
step   1820 | loss 1.6144 | lr 3.00e-04 | grad 1.52 | tok/s 23386
step   1830 | loss 1.7172 | lr 3.00e-04 | grad 1.70 | tok/s 24539
step   1840 | loss 1.7236 | lr 3.00e-04 | grad 5.34 | tok/s 24052
step   1850 | loss 1.5688 | lr 3.00e-04 | grad 1.77 | tok/s 23662
step   1860 | loss 1.4829 | lr 3.00e-04 | grad 2.47 | tok/s 24442
step   1870 | loss 1.6000 | lr 3.00e-04 | grad 1.44 | tok/s 23334
step   1880 | loss 1.3655 | lr 3.00e-04 | grad 1.95 | tok/s 24297
step   1890 | loss 1.6673 | lr 3.00e-04 | grad 1.40 | tok/s 22239
step   1900 | loss 1.5951 | lr 3.00e-04 | grad 1.73 | tok/s 24066
step   1910 | loss 1.5345 | lr 3.00e-04 | grad 1.69 | tok/s 23051
step   1920 | loss 1.5949 | lr 3.00e-04 | grad 1.91 | tok/s 23852
step   1930 | loss 1.5550 | lr 3.00e-04 | grad 1.43 | tok/s 24432
step   1940 | loss 1.5942 | lr 3.00e-04 | grad 1.89 | tok/s 23595
step   1950 | loss 1.9462 | lr 3.00e-04 | grad 3.39 | tok/s 24556
step   1960 | loss 2.1279 | lr 3.00e-04 | grad 2.34 | tok/s 25016
step   1970 | loss 1.8679 | lr 3.00e-04 | grad 3.09 | tok/s 24413
step   1980 | loss 1.7598 | lr 3.00e-04 | grad 1.39 | tok/s 24245
step   1990 | loss 1.5281 | lr 3.00e-04 | grad 1.52 | tok/s 23743
step   2000 | loss 1.8261 | lr 3.00e-04 | grad 2.05 | tok/s 23887
  >>> saved checkpoint: checkpoint_step_002000_loss_1.8261.pt
step   2010 | loss 1.4436 | lr 3.00e-04 | grad 3.88 | tok/s 10996
step   2020 | loss 1.2592 | lr 3.00e-04 | grad 1.91 | tok/s 24567
step   2030 | loss 1.4889 | lr 3.00e-04 | grad 1.95 | tok/s 24397
step   2040 | loss 1.1823 | lr 3.00e-04 | grad 1.66 | tok/s 25179
step   2050 | loss 1.5337 | lr 3.00e-04 | grad 1.65 | tok/s 25037
step   2060 | loss 1.5562 | lr 3.00e-04 | grad 2.09 | tok/s 24014
step   2070 | loss 1.8080 | lr 3.00e-04 | grad 1.49 | tok/s 23658
step   2080 | loss 2.0775 | lr 3.00e-04 | grad 8.81 | tok/s 23773
step   2090 | loss 2.3359 | lr 3.00e-04 | grad 3.80 | tok/s 24986
step   2100 | loss 1.7086 | lr 3.00e-04 | grad 2.42 | tok/s 24368
step   2110 | loss 1.5876 | lr 3.00e-04 | grad 1.53 | tok/s 24760
step   2120 | loss 1.6142 | lr 3.00e-04 | grad 1.70 | tok/s 23356
step   2130 | loss 0.8709 | lr 3.00e-04 | grad 1.19 | tok/s 25261
step   2140 | loss 1.5909 | lr 3.00e-04 | grad 1.70 | tok/s 23673
step   2150 | loss 1.5626 | lr 3.00e-04 | grad 1.78 | tok/s 24726
step   2160 | loss 1.4271 | lr 3.00e-04 | grad 1.75 | tok/s 25041
step   2170 | loss 1.3619 | lr 3.00e-04 | grad 1.56 | tok/s 25012
step   2180 | loss 1.3535 | lr 3.00e-04 | grad 1.60 | tok/s 25024
step   2190 | loss 1.3567 | lr 3.00e-04 | grad 1.88 | tok/s 25025
step   2200 | loss 1.3784 | lr 3.00e-04 | grad 1.64 | tok/s 25033
step   2210 | loss 1.3216 | lr 3.00e-04 | grad 1.65 | tok/s 25026
step   2220 | loss 1.2986 | lr 3.00e-04 | grad 1.56 | tok/s 25028
step   2230 | loss 1.2747 | lr 3.00e-04 | grad 1.47 | tok/s 25052
step   2240 | loss 1.5850 | lr 3.00e-04 | grad 1.91 | tok/s 24536
step   2250 | loss 1.5364 | lr 3.00e-04 | grad 2.25 | tok/s 24132
step   2260 | loss 1.8163 | lr 3.00e-04 | grad 3.97 | tok/s 24990
step   2270 | loss 1.7698 | lr 3.00e-04 | grad 1.59 | tok/s 24194
step   2280 | loss 2.1446 | lr 3.00e-04 | grad 1.99 | tok/s 24765
step   2290 | loss 1.5797 | lr 3.00e-04 | grad 1.80 | tok/s 25028
step   2300 | loss 1.7278 | lr 3.00e-04 | grad 1.48 | tok/s 23895
step   2310 | loss 1.9399 | lr 3.00e-04 | grad 2.39 | tok/s 24362
step   2320 | loss 1.6733 | lr 3.00e-04 | grad 2.97 | tok/s 23817
step   2330 | loss 2.0285 | lr 3.00e-04 | grad 3.33 | tok/s 23715
step   2340 | loss 1.5859 | lr 3.00e-04 | grad 1.79 | tok/s 23126
step   2350 | loss 1.6519 | lr 3.00e-04 | grad 2.02 | tok/s 23834
step   2360 | loss 1.5162 | lr 3.00e-04 | grad 1.81 | tok/s 24521
step   2370 | loss 1.4061 | lr 3.00e-04 | grad 1.73 | tok/s 24830
step   2380 | loss 1.8333 | lr 3.00e-04 | grad 2.12 | tok/s 24719
step   2390 | loss 1.7251 | lr 3.00e-04 | grad 2.52 | tok/s 25039
step   2400 | loss 1.2837 | lr 3.00e-04 | grad 1.32 | tok/s 24987
step   2410 | loss 1.1961 | lr 3.00e-04 | grad 2.12 | tok/s 25017
step   2420 | loss 1.3744 | lr 3.00e-04 | grad 2.23 | tok/s 23929
step   2430 | loss 1.6471 | lr 3.00e-04 | grad 1.84 | tok/s 22760
step   2440 | loss 1.4199 | lr 3.00e-04 | grad 1.68 | tok/s 24950
step   2450 | loss 1.6058 | lr 3.00e-04 | grad 1.53 | tok/s 24095
step   2460 | loss 1.6144 | lr 3.00e-04 | grad 2.02 | tok/s 24036
step   2470 | loss 1.2639 | lr 3.00e-04 | grad 1.59 | tok/s 25078
step   2480 | loss 1.3766 | lr 3.00e-04 | grad 1.81 | tok/s 24689
step   2490 | loss 1.4403 | lr 3.00e-04 | grad 1.78 | tok/s 24630
step   2500 | loss 1.5838 | lr 3.00e-04 | grad 1.42 | tok/s 23877
step   2510 | loss 1.6460 | lr 3.00e-04 | grad 1.80 | tok/s 24706
step   2520 | loss 1.3617 | lr 3.00e-04 | grad 2.80 | tok/s 25036
step   2530 | loss 1.7703 | lr 3.00e-04 | grad 2.08 | tok/s 24593
step   2540 | loss 1.4453 | lr 3.00e-04 | grad 1.62 | tok/s 23935
step   2550 | loss 1.5535 | lr 3.00e-04 | grad 1.42 | tok/s 24280
step   2560 | loss 1.3055 | lr 3.00e-04 | grad 1.67 | tok/s 24757
step   2570 | loss 1.7301 | lr 3.00e-04 | grad 1.87 | tok/s 22912
step   2580 | loss 1.4599 | lr 3.00e-04 | grad 1.53 | tok/s 23508
step   2590 | loss 1.4983 | lr 3.00e-04 | grad 1.84 | tok/s 24317
step   2600 | loss 1.6013 | lr 3.00e-04 | grad 1.27 | tok/s 22876
step   2610 | loss 1.8887 | lr 3.00e-04 | grad 2.59 | tok/s 24186
step   2620 | loss 1.5937 | lr 3.00e-04 | grad 2.44 | tok/s 24384
step   2630 | loss 1.6905 | lr 3.00e-04 | grad 2.53 | tok/s 24533
step   2640 | loss 1.5279 | lr 3.00e-04 | grad 3.03 | tok/s 24850
step   2650 | loss 1.6814 | lr 3.00e-04 | grad 1.48 | tok/s 24143
step   2660 | loss 1.6964 | lr 3.00e-04 | grad 1.85 | tok/s 24442
step   2670 | loss 1.4492 | lr 3.00e-04 | grad 1.66 | tok/s 24009
step   2680 | loss 1.6016 | lr 3.00e-04 | grad 1.48 | tok/s 23447
step   2690 | loss 1.8327 | lr 3.00e-04 | grad 1.50 | tok/s 24036
step   2700 | loss 1.4846 | lr 3.00e-04 | grad 2.20 | tok/s 24827
step   2710 | loss 1.5921 | lr 3.00e-04 | grad 1.84 | tok/s 23620
step   2720 | loss 1.6851 | lr 3.00e-04 | grad 2.88 | tok/s 23545
step   2730 | loss 1.4964 | lr 3.00e-04 | grad 1.85 | tok/s 23210
step   2740 | loss 1.2923 | lr 3.00e-04 | grad 2.11 | tok/s 24789
step   2750 | loss 1.9339 | lr 3.00e-04 | grad 2.22 | tok/s 24455
step   2760 | loss 1.6826 | lr 3.00e-04 | grad 2.62 | tok/s 24429
step   2770 | loss 1.4708 | lr 3.00e-04 | grad 1.94 | tok/s 22657
step   2780 | loss 1.5441 | lr 3.00e-04 | grad 3.28 | tok/s 24579
step   2790 | loss 1.3848 | lr 3.00e-04 | grad 1.86 | tok/s 24699
step   2800 | loss 1.9600 | lr 3.00e-04 | grad 1.95 | tok/s 22583
step   2810 | loss 1.2913 | lr 3.00e-04 | grad 1.63 | tok/s 25025
step   2820 | loss 1.4842 | lr 3.00e-04 | grad 1.65 | tok/s 23079
step   2830 | loss 1.5815 | lr 3.00e-04 | grad 3.11 | tok/s 23449
step   2840 | loss 1.2809 | lr 3.00e-04 | grad 3.58 | tok/s 25025
step   2850 | loss 1.3121 | lr 3.00e-04 | grad 4.06 | tok/s 24521
step   2860 | loss 1.9465 | lr 3.00e-04 | grad 4.09 | tok/s 23993
step   2870 | loss 1.7461 | lr 3.00e-04 | grad 2.06 | tok/s 23766
step   2880 | loss 1.5741 | lr 3.00e-04 | grad 2.84 | tok/s 24241
step   2890 | loss 1.5224 | lr 3.00e-04 | grad 1.78 | tok/s 24763
step   2900 | loss 1.5818 | lr 3.00e-04 | grad 1.87 | tok/s 24474
step   2910 | loss 1.6212 | lr 3.00e-04 | grad 3.92 | tok/s 24469
step   2920 | loss 1.5124 | lr 3.00e-04 | grad 1.73 | tok/s 23471
step   2930 | loss 1.8250 | lr 3.00e-04 | grad 2.88 | tok/s 24071
step   2940 | loss 1.5173 | lr 3.00e-04 | grad 1.59 | tok/s 23629
step   2950 | loss 1.4130 | lr 3.00e-04 | grad 1.66 | tok/s 22798
step   2960 | loss 1.4450 | lr 3.00e-04 | grad 1.55 | tok/s 24526
step   2970 | loss 1.4527 | lr 3.00e-04 | grad 1.88 | tok/s 24440
step   2980 | loss 1.7665 | lr 3.00e-04 | grad 4.16 | tok/s 23701
step   2990 | loss 2.1999 | lr 3.00e-04 | grad 8.50 | tok/s 24506
step   3000 | loss 1.6590 | lr 3.00e-04 | grad 1.74 | tok/s 24487
  >>> saved checkpoint: checkpoint_step_003000_loss_1.6590.pt
step   3010 | loss 1.5479 | lr 3.00e-04 | grad 1.62 | tok/s 10946
step   3020 | loss 1.2317 | lr 3.00e-04 | grad 1.73 | tok/s 24249
step   3030 | loss 1.5246 | lr 3.00e-04 | grad 1.74 | tok/s 23956
step   3040 | loss 1.5865 | lr 3.00e-04 | grad 3.20 | tok/s 24037
step   3050 | loss 1.5983 | lr 3.00e-04 | grad 1.52 | tok/s 24334
step   3060 | loss 1.5568 | lr 3.00e-04 | grad 1.62 | tok/s 24088
step   3070 | loss 1.4643 | lr 3.00e-04 | grad 1.58 | tok/s 24698
step   3080 | loss 1.7440 | lr 3.00e-04 | grad 1.88 | tok/s 24913
step   3090 | loss 1.5153 | lr 3.00e-04 | grad 1.59 | tok/s 24283
step   3100 | loss 1.5150 | lr 3.00e-04 | grad 2.27 | tok/s 24245
step   3110 | loss 1.6438 | lr 3.00e-04 | grad 1.70 | tok/s 23990
step   3120 | loss 1.2759 | lr 3.00e-04 | grad 1.38 | tok/s 25035
step   3130 | loss 1.1623 | lr 3.00e-04 | grad 1.36 | tok/s 25012
step   3140 | loss 1.5455 | lr 3.00e-04 | grad 2.02 | tok/s 23655
step   3150 | loss 1.2074 | lr 3.00e-04 | grad 1.73 | tok/s 25022
step   3160 | loss 1.3530 | lr 3.00e-04 | grad 2.11 | tok/s 24811
step   3170 | loss 1.7297 | lr 3.00e-04 | grad 16.50 | tok/s 23630
step   3180 | loss 1.4561 | lr 3.00e-04 | grad 1.45 | tok/s 23753
step   3190 | loss 1.4916 | lr 3.00e-04 | grad 1.38 | tok/s 23877
step   3200 | loss 1.1736 | lr 3.00e-04 | grad 4.47 | tok/s 24664
step   3210 | loss 1.6079 | lr 3.00e-04 | grad 2.55 | tok/s 24162
step   3220 | loss 1.8451 | lr 3.00e-04 | grad 2.84 | tok/s 24649
step   3230 | loss 2.2496 | lr 3.00e-04 | grad 2.66 | tok/s 24715
step   3240 | loss 2.0500 | lr 3.00e-04 | grad 2.98 | tok/s 24995
step   3250 | loss 1.8751 | lr 3.00e-04 | grad 2.23 | tok/s 25027
step   3260 | loss 1.8150 | lr 3.00e-04 | grad 2.22 | tok/s 25010
step   3270 | loss 1.7101 | lr 3.00e-04 | grad 2.95 | tok/s 24998
step   3280 | loss 1.6737 | lr 3.00e-04 | grad 2.94 | tok/s 25039
step   3290 | loss 1.5820 | lr 3.00e-04 | grad 2.42 | tok/s 25031
step   3300 | loss 1.5709 | lr 3.00e-04 | grad 2.34 | tok/s 25022
step   3310 | loss 1.5523 | lr 3.00e-04 | grad 1.95 | tok/s 25022
step   3320 | loss 1.4986 | lr 3.00e-04 | grad 2.08 | tok/s 25027
step   3330 | loss 1.5236 | lr 3.00e-04 | grad 2.50 | tok/s 25030
step   3340 | loss 1.7440 | lr 3.00e-04 | grad 2.62 | tok/s 24638
step   3350 | loss 1.5992 | lr 3.00e-04 | grad 2.36 | tok/s 23812
step   3360 | loss 1.5635 | lr 3.00e-04 | grad 1.86 | tok/s 24149
step   3370 | loss 1.4741 | lr 3.00e-04 | grad 1.29 | tok/s 22974
step   3380 | loss 1.5941 | lr 3.00e-04 | grad 1.56 | tok/s 23363
step   3390 | loss 1.5933 | lr 3.00e-04 | grad 1.71 | tok/s 24087
step   3400 | loss 1.4874 | lr 3.00e-04 | grad 1.84 | tok/s 24241
step   3410 | loss 1.2448 | lr 3.00e-04 | grad 1.41 | tok/s 25026
step   3420 | loss 1.1944 | lr 3.00e-04 | grad 1.67 | tok/s 25007
step   3430 | loss 1.6687 | lr 3.00e-04 | grad 1.64 | tok/s 23308
step   3440 | loss 1.5415 | lr 3.00e-04 | grad 1.84 | tok/s 24347
step   3450 | loss 1.5821 | lr 3.00e-04 | grad 1.68 | tok/s 23682
step   3460 | loss 1.5268 | lr 3.00e-04 | grad 1.84 | tok/s 24189
step   3470 | loss 1.6743 | lr 3.00e-04 | grad 1.81 | tok/s 24341
step   3480 | loss 1.4837 | lr 3.00e-04 | grad 1.66 | tok/s 24527
step   3490 | loss 1.5196 | lr 3.00e-04 | grad 1.75 | tok/s 25007
step   3500 | loss 1.3643 | lr 3.00e-04 | grad 1.86 | tok/s 23125
step   3510 | loss 1.2951 | lr 3.00e-04 | grad 1.67 | tok/s 24403
step   3520 | loss 1.5538 | lr 3.00e-04 | grad 1.66 | tok/s 24022
step   3530 | loss 1.6301 | lr 3.00e-04 | grad 2.44 | tok/s 23751
step   3540 | loss 1.8261 | lr 3.00e-04 | grad 3.70 | tok/s 24935
step   3550 | loss 1.5611 | lr 3.00e-04 | grad 2.91 | tok/s 23906
step   3560 | loss 2.0848 | lr 3.00e-04 | grad 2.31 | tok/s 22924
step   3570 | loss 1.5619 | lr 3.00e-04 | grad 2.39 | tok/s 23029
step   3580 | loss 1.4064 | lr 3.00e-04 | grad 1.52 | tok/s 23666

Training complete! Final step: 3580
