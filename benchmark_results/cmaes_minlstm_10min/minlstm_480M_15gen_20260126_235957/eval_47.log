Using device: cuda
Output directory: benchmark_results/cmaes_minlstm_10min/minlstm_480M_15gen_20260126_235957/eval_47/levelminlstm_100m_20260127_005113
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level minlstm, 255,156,480 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.8515 | lr 3.00e-04 | grad 1.72 | tok/s 17313
step     20 | loss 3.2358 | lr 3.00e-04 | grad 2.67 | tok/s 21443
step     30 | loss 3.0295 | lr 3.00e-04 | grad 7.38 | tok/s 21521
step     40 | loss 2.9469 | lr 3.00e-04 | grad 2.00 | tok/s 20523
step     50 | loss 2.8857 | lr 3.00e-04 | grad 10.06 | tok/s 20468
step     60 | loss 3.7330 | lr 3.00e-04 | grad 1.64 | tok/s 21786
step     70 | loss 2.7016 | lr 3.00e-04 | grad 2.88 | tok/s 21846
step     80 | loss 4.3941 | lr 3.00e-04 | grad 9.56 | tok/s 21773
step     90 | loss 5.1089 | lr 3.00e-04 | grad 7.78 | tok/s 22409
step    100 | loss 3.9757 | lr 3.00e-04 | grad 4.03 | tok/s 22393
step    110 | loss 3.8404 | lr 3.00e-04 | grad 4.62 | tok/s 22385
step    120 | loss 3.8027 | lr 3.00e-04 | grad 4.91 | tok/s 22336
step    130 | loss 3.9767 | lr 3.00e-04 | grad 3.75 | tok/s 22334
step    140 | loss 3.4883 | lr 3.00e-04 | grad 6.12 | tok/s 22308
step    150 | loss 3.6893 | lr 3.00e-04 | grad 7.28 | tok/s 22307
step    160 | loss 3.5724 | lr 3.00e-04 | grad 5.06 | tok/s 22291
step    170 | loss 3.4020 | lr 3.00e-04 | grad 3.77 | tok/s 22243
step    180 | loss 3.5367 | lr 3.00e-04 | grad 3.33 | tok/s 22250
step    190 | loss 3.4264 | lr 3.00e-04 | grad 4.28 | tok/s 22222
step    200 | loss 3.4611 | lr 3.00e-04 | grad 2.27 | tok/s 22203
step    210 | loss 3.3179 | lr 3.00e-04 | grad 3.55 | tok/s 22215
step    220 | loss 3.2591 | lr 3.00e-04 | grad 5.34 | tok/s 21931
step    230 | loss 3.1390 | lr 3.00e-04 | grad 7.00 | tok/s 21836
step    240 | loss 3.4118 | lr 3.00e-04 | grad 2.75 | tok/s 20642
step    250 | loss 2.7265 | lr 3.00e-04 | grad 1.72 | tok/s 20839
step    260 | loss 2.5484 | lr 3.00e-04 | grad 1.48 | tok/s 21832
step    270 | loss 2.6354 | lr 3.00e-04 | grad 3.56 | tok/s 21065
step    280 | loss 2.6041 | lr 3.00e-04 | grad 4.03 | tok/s 21598
step    290 | loss 3.0797 | lr 3.00e-04 | grad 3.27 | tok/s 21476
step    300 | loss 2.2676 | lr 3.00e-04 | grad 1.52 | tok/s 22130
step    310 | loss 2.6989 | lr 3.00e-04 | grad 2.14 | tok/s 21736
step    320 | loss 2.9024 | lr 3.00e-04 | grad 1.33 | tok/s 22043
step    330 | loss 2.5718 | lr 3.00e-04 | grad 2.08 | tok/s 19937
step    340 | loss 2.7545 | lr 3.00e-04 | grad 1.14 | tok/s 21143
step    350 | loss 2.5583 | lr 3.00e-04 | grad 1.45 | tok/s 20915
step    360 | loss 2.9994 | lr 3.00e-04 | grad 1.38 | tok/s 22034
step    370 | loss 2.6551 | lr 3.00e-04 | grad 2.05 | tok/s 20237
step    380 | loss 2.4145 | lr 3.00e-04 | grad 1.44 | tok/s 20694
step    390 | loss 2.3158 | lr 3.00e-04 | grad 1.89 | tok/s 21772
step    400 | loss 2.2755 | lr 3.00e-04 | grad 1.52 | tok/s 21821
step    410 | loss 2.3764 | lr 3.00e-04 | grad 1.46 | tok/s 21998
step    420 | loss 2.2083 | lr 3.00e-04 | grad 1.80 | tok/s 20110
step    430 | loss 2.5980 | lr 3.00e-04 | grad 2.06 | tok/s 21392
step    440 | loss 2.7569 | lr 3.00e-04 | grad 1.65 | tok/s 21017
step    450 | loss 3.1689 | lr 3.00e-04 | grad 18.38 | tok/s 21082
step    460 | loss 2.5322 | lr 3.00e-04 | grad 2.03 | tok/s 20628
step    470 | loss 2.4920 | lr 3.00e-04 | grad 1.30 | tok/s 20989
step    480 | loss 2.4858 | lr 3.00e-04 | grad 1.38 | tok/s 21384
step    490 | loss 2.9085 | lr 3.00e-04 | grad 1.77 | tok/s 21158
step    500 | loss 2.2543 | lr 3.00e-04 | grad 2.39 | tok/s 20826
step    510 | loss 2.4337 | lr 3.00e-04 | grad 1.38 | tok/s 21711
step    520 | loss 2.4249 | lr 3.00e-04 | grad 0.93 | tok/s 21815
step    530 | loss 2.5610 | lr 3.00e-04 | grad 1.77 | tok/s 21580
step    540 | loss 2.3336 | lr 3.00e-04 | grad 1.26 | tok/s 21014
step    550 | loss 2.1722 | lr 3.00e-04 | grad 1.73 | tok/s 20990
step    560 | loss 2.2444 | lr 3.00e-04 | grad 4.19 | tok/s 19224
step    570 | loss 2.3061 | lr 3.00e-04 | grad 1.42 | tok/s 21039
step    580 | loss 2.2035 | lr 3.00e-04 | grad 1.16 | tok/s 20611
step    590 | loss 2.1553 | lr 3.00e-04 | grad 1.41 | tok/s 20377
step    600 | loss 2.6362 | lr 3.00e-04 | grad 1.48 | tok/s 20865
step    610 | loss 2.2768 | lr 3.00e-04 | grad 1.71 | tok/s 20883
step    620 | loss 2.1164 | lr 3.00e-04 | grad 1.93 | tok/s 20763
step    630 | loss 2.2059 | lr 3.00e-04 | grad 2.42 | tok/s 20339
step    640 | loss 2.4249 | lr 3.00e-04 | grad 2.59 | tok/s 20817
step    650 | loss 2.3534 | lr 3.00e-04 | grad 2.39 | tok/s 21015
step    660 | loss 2.2650 | lr 3.00e-04 | grad 1.72 | tok/s 21357
step    670 | loss 2.1953 | lr 3.00e-04 | grad 1.51 | tok/s 20793
step    680 | loss 2.6618 | lr 3.00e-04 | grad 2.16 | tok/s 21711
step    690 | loss 2.4477 | lr 3.00e-04 | grad 1.58 | tok/s 20596
step    700 | loss 2.5556 | lr 3.00e-04 | grad 2.08 | tok/s 21991
step    710 | loss 2.3789 | lr 3.00e-04 | grad 1.75 | tok/s 21391
step    720 | loss 1.9844 | lr 3.00e-04 | grad 1.43 | tok/s 19410
step    730 | loss 2.3455 | lr 3.00e-04 | grad 1.91 | tok/s 21969
step    740 | loss 2.1439 | lr 3.00e-04 | grad 1.36 | tok/s 21582
step    750 | loss 2.2320 | lr 3.00e-04 | grad 1.72 | tok/s 21935
step    760 | loss 2.0358 | lr 3.00e-04 | grad 1.60 | tok/s 21942
step    770 | loss 2.0902 | lr 3.00e-04 | grad 1.42 | tok/s 21991
step    780 | loss 2.0350 | lr 3.00e-04 | grad 1.98 | tok/s 21963
step    790 | loss 1.9707 | lr 3.00e-04 | grad 1.48 | tok/s 21975
step    800 | loss 2.2305 | lr 3.00e-04 | grad 2.52 | tok/s 20550
step    810 | loss 2.4518 | lr 3.00e-04 | grad 1.62 | tok/s 21107
step    820 | loss 2.2036 | lr 3.00e-04 | grad 2.03 | tok/s 20792
step    830 | loss 2.2713 | lr 3.00e-04 | grad 1.59 | tok/s 21224
step    840 | loss 2.3913 | lr 3.00e-04 | grad 1.88 | tok/s 21985
step    850 | loss 2.3730 | lr 3.00e-04 | grad 5.25 | tok/s 21836
step    860 | loss 2.2751 | lr 3.00e-04 | grad 1.93 | tok/s 21755
step    870 | loss 2.1748 | lr 3.00e-04 | grad 1.13 | tok/s 20989
step    880 | loss 2.2432 | lr 3.00e-04 | grad 2.09 | tok/s 20851
step    890 | loss 2.2840 | lr 3.00e-04 | grad 1.00 | tok/s 21245
step    900 | loss 2.2169 | lr 3.00e-04 | grad 1.73 | tok/s 21321
step    910 | loss 1.9951 | lr 3.00e-04 | grad 1.61 | tok/s 20746
step    920 | loss 2.3446 | lr 3.00e-04 | grad 1.55 | tok/s 21722
step    930 | loss 2.1612 | lr 3.00e-04 | grad 1.70 | tok/s 20858
step    940 | loss 2.2518 | lr 3.00e-04 | grad 1.68 | tok/s 21152
step    950 | loss 2.3114 | lr 3.00e-04 | grad 1.69 | tok/s 21849
step    960 | loss 2.1606 | lr 3.00e-04 | grad 1.69 | tok/s 21986
step    970 | loss 2.1918 | lr 3.00e-04 | grad 1.15 | tok/s 20986
step    980 | loss 2.3132 | lr 3.00e-04 | grad 1.27 | tok/s 21130
step    990 | loss 2.0784 | lr 3.00e-04 | grad 1.70 | tok/s 21088
step   1000 | loss 2.1714 | lr 3.00e-04 | grad 1.57 | tok/s 20854
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1714.pt
step   1010 | loss 2.4091 | lr 3.00e-04 | grad 2.11 | tok/s 10581
step   1020 | loss 2.1835 | lr 3.00e-04 | grad 2.11 | tok/s 20131
step   1030 | loss 2.0366 | lr 3.00e-04 | grad 3.11 | tok/s 20091
step   1040 | loss 2.0339 | lr 3.00e-04 | grad 1.30 | tok/s 21712
step   1050 | loss 2.0141 | lr 3.00e-04 | grad 1.58 | tok/s 20173
step   1060 | loss 2.2217 | lr 3.00e-04 | grad 1.92 | tok/s 21517
step   1070 | loss 2.4039 | lr 3.00e-04 | grad 2.28 | tok/s 21643
step   1080 | loss 2.2620 | lr 3.00e-04 | grad 1.73 | tok/s 20671
step   1090 | loss 2.0091 | lr 3.00e-04 | grad 1.46 | tok/s 20139
step   1100 | loss 1.6003 | lr 3.00e-04 | grad 1.43 | tok/s 21616
step   1110 | loss 2.1230 | lr 3.00e-04 | grad 1.27 | tok/s 21381
step   1120 | loss 2.0522 | lr 3.00e-04 | grad 1.70 | tok/s 21967
step   1130 | loss 2.0394 | lr 3.00e-04 | grad 1.82 | tok/s 21990
step   1140 | loss 1.9754 | lr 3.00e-04 | grad 1.60 | tok/s 21974
step   1150 | loss 1.9719 | lr 3.00e-04 | grad 1.70 | tok/s 21978
step   1160 | loss 1.9279 | lr 3.00e-04 | grad 1.92 | tok/s 21970
step   1170 | loss 1.8766 | lr 3.00e-04 | grad 1.89 | tok/s 21963
step   1180 | loss 1.9926 | lr 3.00e-04 | grad 1.84 | tok/s 21982
step   1190 | loss 1.9954 | lr 3.00e-04 | grad 1.29 | tok/s 21985
step   1200 | loss 1.9197 | lr 3.00e-04 | grad 1.88 | tok/s 21932
step   1210 | loss 1.9529 | lr 3.00e-04 | grad 1.41 | tok/s 21960
step   1220 | loss 1.8969 | lr 3.00e-04 | grad 1.75 | tok/s 21975
step   1230 | loss 1.8468 | lr 3.00e-04 | grad 1.94 | tok/s 21961
step   1240 | loss 1.9091 | lr 3.00e-04 | grad 2.05 | tok/s 21975
step   1250 | loss 2.2576 | lr 3.00e-04 | grad 2.58 | tok/s 21198
step   1260 | loss 2.1234 | lr 3.00e-04 | grad 1.96 | tok/s 20529
step   1270 | loss 1.8798 | lr 3.00e-04 | grad 1.84 | tok/s 21176
step   1280 | loss 2.1892 | lr 3.00e-04 | grad 1.58 | tok/s 20198
step   1290 | loss 2.0762 | lr 3.00e-04 | grad 1.62 | tok/s 21432
step   1300 | loss 2.1159 | lr 3.00e-04 | grad 1.50 | tok/s 21572
step   1310 | loss 1.9737 | lr 3.00e-04 | grad 1.65 | tok/s 20862
step   1320 | loss 2.0577 | lr 3.00e-04 | grad 1.96 | tok/s 21487
step   1330 | loss 2.2664 | lr 3.00e-04 | grad 1.19 | tok/s 21941
step   1340 | loss 2.0024 | lr 3.00e-04 | grad 2.05 | tok/s 20926
step   1350 | loss 2.2628 | lr 3.00e-04 | grad 2.06 | tok/s 20216
step   1360 | loss 2.1965 | lr 3.00e-04 | grad 1.73 | tok/s 20869
step   1370 | loss 1.9784 | lr 3.00e-04 | grad 1.80 | tok/s 20803
step   1380 | loss 2.2122 | lr 3.00e-04 | grad 1.74 | tok/s 21355
step   1390 | loss 2.0625 | lr 3.00e-04 | grad 2.03 | tok/s 20123
step   1400 | loss 1.8806 | lr 3.00e-04 | grad 2.09 | tok/s 20674
step   1410 | loss 2.1645 | lr 3.00e-04 | grad 1.93 | tok/s 21048
step   1420 | loss 2.1005 | lr 3.00e-04 | grad 1.10 | tok/s 20500
step   1430 | loss 2.2091 | lr 3.00e-04 | grad 1.50 | tok/s 21523
step   1440 | loss 1.9283 | lr 3.00e-04 | grad 1.59 | tok/s 20940
step   1450 | loss 1.8905 | lr 3.00e-04 | grad 1.98 | tok/s 21977
step   1460 | loss 2.0832 | lr 3.00e-04 | grad 1.73 | tok/s 21375
step   1470 | loss 2.1143 | lr 3.00e-04 | grad 2.09 | tok/s 20705
step   1480 | loss 2.1539 | lr 3.00e-04 | grad 2.86 | tok/s 21576
step   1490 | loss 2.8909 | lr 3.00e-04 | grad 1.86 | tok/s 21999
step   1500 | loss 2.1682 | lr 3.00e-04 | grad 1.82 | tok/s 21903
step   1510 | loss 1.9988 | lr 3.00e-04 | grad 3.56 | tok/s 21741
step   1520 | loss 2.1234 | lr 3.00e-04 | grad 1.43 | tok/s 21942
step   1530 | loss 1.9659 | lr 3.00e-04 | grad 1.58 | tok/s 21252
step   1540 | loss 2.0396 | lr 3.00e-04 | grad 3.53 | tok/s 21047
step   1550 | loss 2.0550 | lr 3.00e-04 | grad 2.38 | tok/s 21232
step   1560 | loss 1.9154 | lr 3.00e-04 | grad 1.59 | tok/s 21691
step   1570 | loss 2.0418 | lr 3.00e-04 | grad 1.73 | tok/s 20858
step   1580 | loss 2.0580 | lr 3.00e-04 | grad 1.83 | tok/s 21474
step   1590 | loss 2.7582 | lr 3.00e-04 | grad 1.84 | tok/s 21863
step   1600 | loss 1.9630 | lr 3.00e-04 | grad 1.98 | tok/s 20770
step   1610 | loss 1.2840 | lr 3.00e-04 | grad 2.00 | tok/s 21993
step   1620 | loss 1.7945 | lr 3.00e-04 | grad 1.41 | tok/s 19710
step   1630 | loss 2.2614 | lr 3.00e-04 | grad 2.16 | tok/s 21074
step   1640 | loss 1.9284 | lr 3.00e-04 | grad 2.09 | tok/s 21910
step   1650 | loss 1.9539 | lr 3.00e-04 | grad 1.46 | tok/s 20037
step   1660 | loss 2.0717 | lr 3.00e-04 | grad 1.80 | tok/s 20343
step   1670 | loss 1.9402 | lr 3.00e-04 | grad 1.38 | tok/s 21790
step   1680 | loss 2.4116 | lr 3.00e-04 | grad 1.56 | tok/s 20323
step   1690 | loss 1.9804 | lr 3.00e-04 | grad 2.39 | tok/s 20738
step   1700 | loss 2.1877 | lr 3.00e-04 | grad 2.22 | tok/s 21621
step   1710 | loss 1.9774 | lr 3.00e-04 | grad 1.57 | tok/s 20643
step   1720 | loss 2.0875 | lr 3.00e-04 | grad 1.71 | tok/s 21501
step   1730 | loss 2.2843 | lr 3.00e-04 | grad 2.08 | tok/s 22003
step   1740 | loss 2.3027 | lr 3.00e-04 | grad 1.62 | tok/s 22001
step   1750 | loss 2.0377 | lr 3.00e-04 | grad 1.96 | tok/s 21091
step   1760 | loss 2.0136 | lr 3.00e-04 | grad 1.95 | tok/s 21149
step   1770 | loss 2.0415 | lr 3.00e-04 | grad 1.40 | tok/s 21182
step   1780 | loss 1.9760 | lr 3.00e-04 | grad 2.66 | tok/s 20915
step   1790 | loss 1.9029 | lr 3.00e-04 | grad 1.87 | tok/s 21267
step   1800 | loss 1.9652 | lr 3.00e-04 | grad 1.69 | tok/s 21168
step   1810 | loss 2.1042 | lr 3.00e-04 | grad 1.99 | tok/s 20716
step   1820 | loss 1.9937 | lr 3.00e-04 | grad 1.70 | tok/s 20571
step   1830 | loss 2.0408 | lr 3.00e-04 | grad 1.84 | tok/s 21582
step   1840 | loss 2.0285 | lr 3.00e-04 | grad 3.69 | tok/s 21175
step   1850 | loss 1.9448 | lr 3.00e-04 | grad 1.80 | tok/s 20790
step   1860 | loss 1.9863 | lr 3.00e-04 | grad 2.58 | tok/s 21486
step   1870 | loss 1.8975 | lr 3.00e-04 | grad 1.27 | tok/s 20510
step   1880 | loss 1.8710 | lr 3.00e-04 | grad 1.87 | tok/s 21364
step   1890 | loss 2.0425 | lr 3.00e-04 | grad 1.44 | tok/s 19569
step   1900 | loss 1.9097 | lr 3.00e-04 | grad 1.81 | tok/s 21173
step   1910 | loss 1.8462 | lr 3.00e-04 | grad 1.59 | tok/s 20273
step   1920 | loss 1.9336 | lr 3.00e-04 | grad 1.67 | tok/s 21000
step   1930 | loss 1.9004 | lr 3.00e-04 | grad 1.51 | tok/s 21518
step   1940 | loss 1.9089 | lr 3.00e-04 | grad 2.44 | tok/s 20758
step   1950 | loss 2.2803 | lr 3.00e-04 | grad 2.67 | tok/s 21601
step   1960 | loss 2.6996 | lr 3.00e-04 | grad 1.84 | tok/s 22023
step   1970 | loss 2.3759 | lr 3.00e-04 | grad 2.70 | tok/s 21470
step   1980 | loss 2.2196 | lr 3.00e-04 | grad 1.34 | tok/s 21332
step   1990 | loss 1.8844 | lr 3.00e-04 | grad 1.42 | tok/s 20907
step   2000 | loss 2.2201 | lr 3.00e-04 | grad 2.02 | tok/s 21050
  >>> saved checkpoint: checkpoint_step_002000_loss_2.2201.pt
step   2010 | loss 1.7572 | lr 3.00e-04 | grad 1.99 | tok/s 10590
step   2020 | loss 1.5645 | lr 3.00e-04 | grad 1.94 | tok/s 21662
step   2030 | loss 1.9018 | lr 3.00e-04 | grad 1.55 | tok/s 21514
step   2040 | loss 1.5100 | lr 3.00e-04 | grad 1.56 | tok/s 22193
step   2050 | loss 2.1230 | lr 3.00e-04 | grad 1.66 | tok/s 22049
step   2060 | loss 1.9940 | lr 3.00e-04 | grad 2.23 | tok/s 21148
step   2070 | loss 2.1178 | lr 3.00e-04 | grad 1.57 | tok/s 20817
step   2080 | loss 2.2853 | lr 3.00e-04 | grad 3.84 | tok/s 20902
step   2090 | loss 2.4906 | lr 3.00e-04 | grad 2.47 | tok/s 22010
step   2100 | loss 2.0971 | lr 3.00e-04 | grad 2.73 | tok/s 21489
step   2110 | loss 2.1500 | lr 3.00e-04 | grad 1.27 | tok/s 21812
step   2120 | loss 2.0048 | lr 3.00e-04 | grad 2.11 | tok/s 20574
step   2130 | loss 1.1291 | lr 3.00e-04 | grad 0.66 | tok/s 22225
step   2140 | loss 1.9888 | lr 3.00e-04 | grad 2.00 | tok/s 20861
step   2150 | loss 1.9144 | lr 3.00e-04 | grad 2.25 | tok/s 21794
step   2160 | loss 1.7900 | lr 3.00e-04 | grad 2.16 | tok/s 22044
step   2170 | loss 1.7533 | lr 3.00e-04 | grad 1.89 | tok/s 22059
step   2180 | loss 1.7456 | lr 3.00e-04 | grad 1.90 | tok/s 21993
step   2190 | loss 1.7311 | lr 3.00e-04 | grad 1.84 | tok/s 22041
step   2200 | loss 1.7282 | lr 3.00e-04 | grad 1.65 | tok/s 22032
step   2210 | loss 1.6978 | lr 3.00e-04 | grad 1.52 | tok/s 22042
step   2220 | loss 1.6629 | lr 3.00e-04 | grad 1.95 | tok/s 22068
step   2230 | loss 1.6445 | lr 3.00e-04 | grad 1.74 | tok/s 22056
step   2240 | loss 1.9130 | lr 3.00e-04 | grad 2.12 | tok/s 21596
step   2250 | loss 1.9130 | lr 3.00e-04 | grad 1.95 | tok/s 21244
step   2260 | loss 2.3452 | lr 3.00e-04 | grad 2.02 | tok/s 22058
step   2270 | loss 2.1282 | lr 3.00e-04 | grad 1.64 | tok/s 21314
step   2280 | loss 2.4448 | lr 3.00e-04 | grad 1.57 | tok/s 21827
step   2290 | loss 1.9966 | lr 3.00e-04 | grad 1.88 | tok/s 22066
step   2300 | loss 2.1130 | lr 3.00e-04 | grad 1.45 | tok/s 21059
step   2310 | loss 2.4881 | lr 3.00e-04 | grad 2.34 | tok/s 21439
step   2320 | loss 2.0988 | lr 3.00e-04 | grad 3.27 | tok/s 20920
step   2330 | loss 2.2892 | lr 3.00e-04 | grad 2.44 | tok/s 20875
step   2340 | loss 1.8920 | lr 3.00e-04 | grad 1.82 | tok/s 20364
step   2350 | loss 2.0349 | lr 3.00e-04 | grad 2.17 | tok/s 21007
step   2360 | loss 1.9132 | lr 3.00e-04 | grad 1.66 | tok/s 21600
step   2370 | loss 1.8653 | lr 3.00e-04 | grad 1.63 | tok/s 21875
step   2380 | loss 2.2091 | lr 3.00e-04 | grad 2.27 | tok/s 21761
step   2390 | loss 2.2213 | lr 3.00e-04 | grad 1.95 | tok/s 22050
step   2400 | loss 1.7255 | lr 3.00e-04 | grad 1.12 | tok/s 22037
step   2410 | loss 1.6860 | lr 3.00e-04 | grad 2.12 | tok/s 22099
step   2420 | loss 1.6598 | lr 3.00e-04 | grad 2.27 | tok/s 21100
step   2430 | loss 1.9370 | lr 3.00e-04 | grad 2.06 | tok/s 20079
step   2440 | loss 1.8360 | lr 3.00e-04 | grad 1.52 | tok/s 21975
step   2450 | loss 1.9699 | lr 3.00e-04 | grad 1.71 | tok/s 21232
step   2460 | loss 1.9027 | lr 3.00e-04 | grad 1.86 | tok/s 21185
step   2470 | loss 1.7532 | lr 3.00e-04 | grad 1.75 | tok/s 22069
step   2480 | loss 1.8005 | lr 3.00e-04 | grad 1.98 | tok/s 21728
step   2490 | loss 1.8562 | lr 3.00e-04 | grad 1.74 | tok/s 21703
step   2500 | loss 1.8926 | lr 3.00e-04 | grad 1.44 | tok/s 21029
step   2510 | loss 2.1685 | lr 3.00e-04 | grad 1.75 | tok/s 21779
step   2520 | loss 2.0141 | lr 3.00e-04 | grad 2.81 | tok/s 22040
step   2530 | loss 2.1481 | lr 3.00e-04 | grad 1.55 | tok/s 21698
step   2540 | loss 1.7688 | lr 3.00e-04 | grad 1.59 | tok/s 21116
step   2550 | loss 1.9077 | lr 3.00e-04 | grad 1.77 | tok/s 21419
step   2560 | loss 1.7196 | lr 3.00e-04 | grad 1.66 | tok/s 21822
step   2570 | loss 2.0537 | lr 3.00e-04 | grad 1.62 | tok/s 20200
step   2580 | loss 1.8212 | lr 3.00e-04 | grad 1.49 | tok/s 20713
step   2590 | loss 1.9208 | lr 3.00e-04 | grad 1.88 | tok/s 21403
step   2600 | loss 1.9092 | lr 3.00e-04 | grad 1.43 | tok/s 20121
step   2610 | loss 2.3818 | lr 3.00e-04 | grad 4.28 | tok/s 21307
step   2620 | loss 2.0805 | lr 3.00e-04 | grad 1.88 | tok/s 21476
step   2630 | loss 1.9685 | lr 3.00e-04 | grad 2.05 | tok/s 21575
step   2640 | loss 1.9116 | lr 3.00e-04 | grad 2.69 | tok/s 21879
step   2650 | loss 2.0401 | lr 3.00e-04 | grad 1.86 | tok/s 21257
step   2660 | loss 2.1476 | lr 3.00e-04 | grad 1.98 | tok/s 21571
step   2670 | loss 1.7651 | lr 3.00e-04 | grad 1.74 | tok/s 21178
step   2680 | loss 1.8992 | lr 3.00e-04 | grad 1.46 | tok/s 20650
step   2690 | loss 2.1461 | lr 3.00e-04 | grad 1.48 | tok/s 21214
step   2700 | loss 1.8763 | lr 3.00e-04 | grad 2.14 | tok/s 21911
step   2710 | loss 1.9288 | lr 3.00e-04 | grad 2.00 | tok/s 20830
step   2720 | loss 2.1298 | lr 3.00e-04 | grad 2.33 | tok/s 20752
step   2730 | loss 1.8480 | lr 3.00e-04 | grad 2.16 | tok/s 20448
step   2740 | loss 1.8100 | lr 3.00e-04 | grad 2.19 | tok/s 21857
step   2750 | loss 2.2542 | lr 3.00e-04 | grad 1.82 | tok/s 21533
step   2760 | loss 2.0414 | lr 3.00e-04 | grad 2.48 | tok/s 21530
step   2770 | loss 1.7557 | lr 3.00e-04 | grad 1.97 | tok/s 19946
step   2780 | loss 1.9983 | lr 3.00e-04 | grad 1.82 | tok/s 21672
step   2790 | loss 1.8399 | lr 3.00e-04 | grad 2.06 | tok/s 21763
step   2800 | loss 2.2719 | lr 3.00e-04 | grad 1.83 | tok/s 19870
step   2810 | loss 1.6946 | lr 3.00e-04 | grad 2.19 | tok/s 22007
step   2820 | loss 1.8101 | lr 3.00e-04 | grad 1.92 | tok/s 20341
step   2830 | loss 1.8928 | lr 3.00e-04 | grad 2.42 | tok/s 20649
step   2840 | loss 1.9049 | lr 3.00e-04 | grad 2.47 | tok/s 22062
step   2850 | loss 1.8391 | lr 3.00e-04 | grad 3.66 | tok/s 21590
step   2860 | loss 2.2698 | lr 3.00e-04 | grad 3.56 | tok/s 21133
step   2870 | loss 2.0066 | lr 3.00e-04 | grad 1.77 | tok/s 20922
step   2880 | loss 1.8625 | lr 3.00e-04 | grad 2.30 | tok/s 21349
step   2890 | loss 1.9690 | lr 3.00e-04 | grad 1.87 | tok/s 21812
step   2900 | loss 2.0065 | lr 3.00e-04 | grad 1.41 | tok/s 21574
step   2910 | loss 1.9183 | lr 3.00e-04 | grad 3.30 | tok/s 21550
step   2920 | loss 1.8016 | lr 3.00e-04 | grad 1.78 | tok/s 20656
step   2930 | loss 2.1037 | lr 3.00e-04 | grad 2.09 | tok/s 21198
step   2940 | loss 1.8223 | lr 3.00e-04 | grad 1.66 | tok/s 20844
step   2950 | loss 1.7152 | lr 3.00e-04 | grad 1.77 | tok/s 20098
step   2960 | loss 1.8750 | lr 3.00e-04 | grad 1.57 | tok/s 21616
step   2970 | loss 1.7991 | lr 3.00e-04 | grad 2.38 | tok/s 21555
step   2980 | loss 2.0158 | lr 3.00e-04 | grad 3.69 | tok/s 20855
step   2990 | loss 2.5494 | lr 3.00e-04 | grad 4.66 | tok/s 21594
step   3000 | loss 1.9866 | lr 3.00e-04 | grad 1.88 | tok/s 21573
  >>> saved checkpoint: checkpoint_step_003000_loss_1.9866.pt
step   3010 | loss 1.8723 | lr 3.00e-04 | grad 1.67 | tok/s 10498
step   3020 | loss 1.5858 | lr 3.00e-04 | grad 1.58 | tok/s 21383
step   3030 | loss 1.8281 | lr 3.00e-04 | grad 2.12 | tok/s 21118
step   3040 | loss 1.8759 | lr 3.00e-04 | grad 3.06 | tok/s 21162
step   3050 | loss 1.8808 | lr 3.00e-04 | grad 1.80 | tok/s 21456
step   3060 | loss 1.8802 | lr 3.00e-04 | grad 1.88 | tok/s 21201
step   3070 | loss 1.7952 | lr 3.00e-04 | grad 1.46 | tok/s 21762
step   3080 | loss 2.0232 | lr 3.00e-04 | grad 2.36 | tok/s 21958
step   3090 | loss 1.8088 | lr 3.00e-04 | grad 1.60 | tok/s 21399
step   3100 | loss 1.8517 | lr 3.00e-04 | grad 2.39 | tok/s 21362
step   3110 | loss 1.9507 | lr 3.00e-04 | grad 1.66 | tok/s 21156
step   3120 | loss 1.7968 | lr 3.00e-04 | grad 1.81 | tok/s 22081
step   3130 | loss 1.6218 | lr 3.00e-04 | grad 1.68 | tok/s 22078
step   3140 | loss 1.9328 | lr 3.00e-04 | grad 2.11 | tok/s 20862
step   3150 | loss 1.7089 | lr 3.00e-04 | grad 1.70 | tok/s 22072
step   3160 | loss 1.7638 | lr 3.00e-04 | grad 1.95 | tok/s 21859

Training complete! Final step: 3165
