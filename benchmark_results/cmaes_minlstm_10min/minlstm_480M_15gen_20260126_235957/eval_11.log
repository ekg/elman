Using device: cuda
Output directory: benchmark_results/cmaes_minlstm_10min/minlstm_480M_15gen_20260126_235957/eval_11/levelminlstm_100m_20260127_001016
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level minlstm, 226,925,568 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 5.3994 | lr 3.00e-04 | grad 3.67 | tok/s 21707
step     20 | loss 3.1384 | lr 3.00e-04 | grad 2.53 | tok/s 24321
step     30 | loss 3.5762 | lr 3.00e-04 | grad 3.80 | tok/s 24510
step     40 | loss 3.8427 | lr 3.00e-04 | grad 7.34 | tok/s 25320
step     50 | loss 5.1402 | lr 3.00e-04 | grad 4.59 | tok/s 25960
step     60 | loss 4.0718 | lr 3.00e-04 | grad 5.25 | tok/s 25951
step     70 | loss 3.7809 | lr 3.00e-04 | grad 4.28 | tok/s 25944
step     80 | loss 3.6268 | lr 3.00e-04 | grad 5.44 | tok/s 25919
step     90 | loss 3.3417 | lr 3.00e-04 | grad 2.72 | tok/s 25906
step    100 | loss 3.2637 | lr 3.00e-04 | grad 1.84 | tok/s 25905
step    110 | loss 3.0115 | lr 3.00e-04 | grad 3.23 | tok/s 25734
step    120 | loss 3.4140 | lr 3.00e-04 | grad 1.88 | tok/s 24893
step    130 | loss 2.7599 | lr 3.00e-04 | grad 2.75 | tok/s 25015
step    140 | loss 2.7713 | lr 3.00e-04 | grad 3.41 | tok/s 25002
step    150 | loss 2.9500 | lr 3.00e-04 | grad 3.53 | tok/s 25549
step    160 | loss 2.9943 | lr 3.00e-04 | grad 2.69 | tok/s 25672
step    170 | loss 2.7740 | lr 3.00e-04 | grad 2.39 | tok/s 24080
step    180 | loss 2.9483 | lr 3.00e-04 | grad 3.33 | tok/s 25198
step    190 | loss 2.6438 | lr 3.00e-04 | grad 2.33 | tok/s 24011
step    200 | loss 2.4229 | lr 3.00e-04 | grad 2.25 | tok/s 25587
step    210 | loss 2.4077 | lr 3.00e-04 | grad 1.68 | tok/s 24708
step    220 | loss 2.7817 | lr 3.00e-04 | grad 2.14 | tok/s 24902
step    230 | loss 2.7965 | lr 3.00e-04 | grad 3.42 | tok/s 24474
step    240 | loss 2.5828 | lr 3.00e-04 | grad 2.75 | tok/s 24876
step    250 | loss 2.7123 | lr 3.00e-04 | grad 2.39 | tok/s 24626
step    260 | loss 2.5226 | lr 3.00e-04 | grad 2.53 | tok/s 25565
step    270 | loss 2.5356 | lr 3.00e-04 | grad 2.83 | tok/s 25005
step    280 | loss 2.2856 | lr 3.00e-04 | grad 2.45 | tok/s 23609
step    290 | loss 2.3374 | lr 3.00e-04 | grad 2.66 | tok/s 24431
step    300 | loss 2.4912 | lr 3.00e-04 | grad 2.00 | tok/s 24180
step    310 | loss 2.2761 | lr 3.00e-04 | grad 2.61 | tok/s 24433
step    320 | loss 2.3981 | lr 3.00e-04 | grad 2.98 | tok/s 24143
step    330 | loss 2.4012 | lr 3.00e-04 | grad 1.86 | tok/s 24864
step    340 | loss 2.5306 | lr 3.00e-04 | grad 1.52 | tok/s 24949
step    350 | loss 2.6300 | lr 3.00e-04 | grad 1.61 | tok/s 24984
step    360 | loss 2.2690 | lr 3.00e-04 | grad 1.56 | tok/s 23945
step    370 | loss 2.3490 | lr 3.00e-04 | grad 1.59 | tok/s 25607
step    380 | loss 2.2254 | lr 3.00e-04 | grad 2.14 | tok/s 25819
step    390 | loss 2.1779 | lr 3.00e-04 | grad 2.58 | tok/s 25824
step    400 | loss 2.2174 | lr 3.00e-04 | grad 3.28 | tok/s 24974
step    410 | loss 2.4169 | lr 3.00e-04 | grad 2.36 | tok/s 24623
step    420 | loss 2.4303 | lr 3.00e-04 | grad 1.36 | tok/s 25376
step    430 | loss 2.4084 | lr 3.00e-04 | grad 1.78 | tok/s 25624
step    440 | loss 2.2933 | lr 3.00e-04 | grad 1.83 | tok/s 24589
step    450 | loss 2.3240 | lr 3.00e-04 | grad 1.26 | tok/s 25007
step    460 | loss 2.2447 | lr 3.00e-04 | grad 1.86 | tok/s 24930
step    470 | loss 2.2799 | lr 3.00e-04 | grad 2.05 | tok/s 24695
step    480 | loss 2.3834 | lr 3.00e-04 | grad 1.98 | tok/s 25762
step    490 | loss 2.3364 | lr 3.00e-04 | grad 2.67 | tok/s 24746
step    500 | loss 2.2033 | lr 3.00e-04 | grad 1.48 | tok/s 24621
step    510 | loss 2.4442 | lr 3.00e-04 | grad 1.59 | tok/s 24448
step    520 | loss 2.1543 | lr 3.00e-04 | grad 1.98 | tok/s 24267
step    530 | loss 2.1856 | lr 3.00e-04 | grad 1.69 | tok/s 24541
step    540 | loss 2.4390 | lr 3.00e-04 | grad 1.78 | tok/s 24798
step    550 | loss 1.8687 | lr 3.00e-04 | grad 1.92 | tok/s 24370
step    560 | loss 2.1953 | lr 3.00e-04 | grad 2.31 | tok/s 25461
step    570 | loss 2.1333 | lr 3.00e-04 | grad 2.23 | tok/s 25823
step    580 | loss 2.0729 | lr 3.00e-04 | grad 2.64 | tok/s 25820
step    590 | loss 2.0303 | lr 3.00e-04 | grad 1.82 | tok/s 25809
step    600 | loss 2.1003 | lr 3.00e-04 | grad 1.70 | tok/s 25807
step    610 | loss 2.0545 | lr 3.00e-04 | grad 2.11 | tok/s 25800
step    620 | loss 2.0032 | lr 3.00e-04 | grad 1.78 | tok/s 25817
step    630 | loss 2.2249 | lr 3.00e-04 | grad 2.30 | tok/s 24824
step    640 | loss 2.0553 | lr 3.00e-04 | grad 1.70 | tok/s 24088
step    650 | loss 2.2241 | lr 3.00e-04 | grad 2.03 | tok/s 25153
step    660 | loss 2.1142 | lr 3.00e-04 | grad 2.31 | tok/s 25001
step    670 | loss 2.2666 | lr 3.00e-04 | grad 1.83 | tok/s 25325
step    680 | loss 2.2394 | lr 3.00e-04 | grad 2.12 | tok/s 23806
step    690 | loss 2.2038 | lr 3.00e-04 | grad 1.69 | tok/s 24825
step    700 | loss 2.0552 | lr 3.00e-04 | grad 1.81 | tok/s 23968
step    710 | loss 2.2480 | lr 3.00e-04 | grad 2.06 | tok/s 24654
step    720 | loss 2.1355 | lr 3.00e-04 | grad 2.72 | tok/s 24470
step    730 | loss 2.0911 | lr 3.00e-04 | grad 4.34 | tok/s 25651
step    740 | loss 2.1624 | lr 3.00e-04 | grad 1.81 | tok/s 24704
step    750 | loss 2.6914 | lr 3.00e-04 | grad 1.98 | tok/s 25660
step    760 | loss 2.1618 | lr 3.00e-04 | grad 2.72 | tok/s 25642
step    770 | loss 2.0468 | lr 3.00e-04 | grad 1.43 | tok/s 24908
step    780 | loss 2.1249 | lr 3.00e-04 | grad 1.72 | tok/s 25137
step    790 | loss 2.1442 | lr 3.00e-04 | grad 2.62 | tok/s 25001
step    800 | loss 2.4927 | lr 3.00e-04 | grad 1.95 | tok/s 24853
step    810 | loss 1.6222 | lr 3.00e-04 | grad 1.80 | tok/s 24899
step    820 | loss 2.1822 | lr 3.00e-04 | grad 1.29 | tok/s 24849
step    830 | loss 2.0780 | lr 3.00e-04 | grad 1.70 | tok/s 23662
step    840 | loss 2.2426 | lr 3.00e-04 | grad 2.39 | tok/s 25024
step    850 | loss 2.1718 | lr 3.00e-04 | grad 2.00 | tok/s 24641
step    860 | loss 2.1756 | lr 3.00e-04 | grad 2.02 | tok/s 24634
step    870 | loss 2.4157 | lr 3.00e-04 | grad 1.90 | tok/s 25846
step    880 | loss 2.1298 | lr 3.00e-04 | grad 2.58 | tok/s 24880
step    890 | loss 2.0581 | lr 3.00e-04 | grad 1.94 | tok/s 24604
step    900 | loss 2.0464 | lr 3.00e-04 | grad 1.68 | tok/s 24910
step    910 | loss 2.1466 | lr 3.00e-04 | grad 2.20 | tok/s 24368
step    920 | loss 2.0867 | lr 3.00e-04 | grad 1.59 | tok/s 25068
step    930 | loss 2.1222 | lr 3.00e-04 | grad 1.86 | tok/s 24902
step    940 | loss 1.9737 | lr 3.00e-04 | grad 1.32 | tok/s 24765
step    950 | loss 2.0497 | lr 3.00e-04 | grad 2.23 | tok/s 23601
step    960 | loss 1.9796 | lr 3.00e-04 | grad 1.34 | tok/s 24229
step    970 | loss 1.9963 | lr 3.00e-04 | grad 1.90 | tok/s 24809
step    980 | loss 2.5138 | lr 3.00e-04 | grad 2.19 | tok/s 25625
step    990 | loss 2.4675 | lr 3.00e-04 | grad 2.42 | tok/s 25305
step   1000 | loss 2.1478 | lr 3.00e-04 | grad 0.93 | tok/s 24447
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1478.pt
step   1010 | loss 1.7498 | lr 3.00e-04 | grad 1.60 | tok/s 16849
step   1020 | loss 1.7657 | lr 3.00e-04 | grad 1.36 | tok/s 25550
step   1030 | loss 2.1836 | lr 3.00e-04 | grad 1.59 | tok/s 25389
step   1040 | loss 2.2382 | lr 3.00e-04 | grad 4.62 | tok/s 24409
step   1050 | loss 2.4757 | lr 3.00e-04 | grad 1.66 | tok/s 25604
step   1060 | loss 2.1983 | lr 3.00e-04 | grad 1.91 | tok/s 24749
step   1070 | loss 1.6515 | lr 3.00e-04 | grad 1.59 | tok/s 25422
step   1080 | loss 1.9679 | lr 3.00e-04 | grad 2.17 | tok/s 25466
step   1090 | loss 1.8858 | lr 3.00e-04 | grad 1.85 | tok/s 25853
step   1100 | loss 1.8587 | lr 3.00e-04 | grad 1.61 | tok/s 25847
step   1110 | loss 1.8352 | lr 3.00e-04 | grad 2.84 | tok/s 25854
step   1120 | loss 1.8880 | lr 3.00e-04 | grad 2.50 | tok/s 25609
step   1130 | loss 2.2615 | lr 3.00e-04 | grad 3.94 | tok/s 25386
step   1140 | loss 2.4144 | lr 3.00e-04 | grad 2.06 | tok/s 25273
step   1150 | loss 2.1548 | lr 3.00e-04 | grad 5.22 | tok/s 25395
step   1160 | loss 2.4185 | lr 3.00e-04 | grad 2.11 | tok/s 24860
step   1170 | loss 2.1931 | lr 3.00e-04 | grad 2.31 | tok/s 24374
step   1180 | loss 2.0124 | lr 3.00e-04 | grad 1.79 | tok/s 24655
step   1190 | loss 2.1322 | lr 3.00e-04 | grad 1.57 | tok/s 25595
step   1200 | loss 2.1237 | lr 3.00e-04 | grad 2.52 | tok/s 25852
step   1210 | loss 1.8018 | lr 3.00e-04 | grad 2.20 | tok/s 25331
step   1220 | loss 1.9830 | lr 3.00e-04 | grad 1.43 | tok/s 24580
step   1230 | loss 2.0178 | lr 3.00e-04 | grad 1.34 | tok/s 24972
step   1240 | loss 1.9328 | lr 3.00e-04 | grad 2.16 | tok/s 25601
step   1250 | loss 1.9607 | lr 3.00e-04 | grad 2.02 | tok/s 25062
step   1260 | loss 2.2629 | lr 3.00e-04 | grad 2.02 | tok/s 25687
step   1270 | loss 2.0738 | lr 3.00e-04 | grad 1.97 | tok/s 25220
step   1280 | loss 1.9612 | lr 3.00e-04 | grad 2.03 | tok/s 25343
step   1290 | loss 2.0622 | lr 3.00e-04 | grad 1.91 | tok/s 24426
step   1300 | loss 2.0211 | lr 3.00e-04 | grad 2.14 | tok/s 24271
step   1310 | loss 2.3569 | lr 3.00e-04 | grad 1.88 | tok/s 24865
step   1320 | loss 2.0224 | lr 3.00e-04 | grad 2.55 | tok/s 25302
step   1330 | loss 2.2294 | lr 3.00e-04 | grad 1.80 | tok/s 25164
step   1340 | loss 1.9274 | lr 3.00e-04 | grad 2.52 | tok/s 24454
step   1350 | loss 2.1469 | lr 3.00e-04 | grad 1.82 | tok/s 25274
step   1360 | loss 2.1661 | lr 3.00e-04 | grad 1.27 | tok/s 24534
step   1370 | loss 1.9432 | lr 3.00e-04 | grad 1.95 | tok/s 24642
step   1380 | loss 2.2842 | lr 3.00e-04 | grad 1.77 | tok/s 25305
step   1390 | loss 1.9862 | lr 3.00e-04 | grad 2.08 | tok/s 24359
step   1400 | loss 2.1743 | lr 3.00e-04 | grad 2.23 | tok/s 24825
step   1410 | loss 1.8839 | lr 3.00e-04 | grad 1.91 | tok/s 24641
step   1420 | loss 2.0105 | lr 3.00e-04 | grad 2.50 | tok/s 24895
step   1430 | loss 2.1581 | lr 3.00e-04 | grad 1.40 | tok/s 25209
step   1440 | loss 2.0748 | lr 3.00e-04 | grad 1.41 | tok/s 24795
step   1450 | loss 2.1287 | lr 3.00e-04 | grad 1.80 | tok/s 25590
step   1460 | loss 1.9711 | lr 3.00e-04 | grad 2.28 | tok/s 24808
step   1470 | loss 2.0574 | lr 3.00e-04 | grad 1.97 | tok/s 24639
step   1480 | loss 1.8850 | lr 3.00e-04 | grad 1.59 | tok/s 24263
step   1490 | loss 1.9298 | lr 3.00e-04 | grad 1.68 | tok/s 24860
step   1500 | loss 2.4033 | lr 3.00e-04 | grad 1.80 | tok/s 25343
step   1510 | loss 1.9022 | lr 3.00e-04 | grad 2.20 | tok/s 25177
step   1520 | loss 1.9042 | lr 3.00e-04 | grad 1.97 | tok/s 24401
step   1530 | loss 1.9508 | lr 3.00e-04 | grad 1.49 | tok/s 25134
step   1540 | loss 2.0373 | lr 3.00e-04 | grad 2.23 | tok/s 25434
step   1550 | loss 1.9458 | lr 3.00e-04 | grad 1.72 | tok/s 25377
step   1560 | loss 2.0130 | lr 3.00e-04 | grad 1.72 | tok/s 25004
step   1570 | loss 1.8781 | lr 3.00e-04 | grad 2.89 | tok/s 25158
step   1580 | loss 1.9375 | lr 3.00e-04 | grad 2.14 | tok/s 25846
step   1590 | loss 1.9900 | lr 3.00e-04 | grad 2.09 | tok/s 24517
step   1600 | loss 1.8103 | lr 3.00e-04 | grad 1.78 | tok/s 24903
step   1610 | loss 1.9485 | lr 3.00e-04 | grad 1.91 | tok/s 25426
step   1620 | loss 2.5932 | lr 3.00e-04 | grad 1.77 | tok/s 25480
step   1630 | loss 2.3368 | lr 3.00e-04 | grad 2.23 | tok/s 25873
step   1640 | loss 2.2374 | lr 3.00e-04 | grad 1.88 | tok/s 25877
step   1650 | loss 2.1683 | lr 3.00e-04 | grad 1.94 | tok/s 25874
step   1660 | loss 2.1330 | lr 3.00e-04 | grad 2.31 | tok/s 25875
step   1670 | loss 2.1122 | lr 3.00e-04 | grad 2.20 | tok/s 25872
step   1680 | loss 2.0919 | lr 3.00e-04 | grad 1.50 | tok/s 24795
step   1690 | loss 1.9003 | lr 3.00e-04 | grad 2.20 | tok/s 24249
step   1700 | loss 1.9905 | lr 3.00e-04 | grad 2.05 | tok/s 24527
step   1710 | loss 1.8058 | lr 3.00e-04 | grad 1.36 | tok/s 25834
step   1720 | loss 1.9400 | lr 3.00e-04 | grad 2.08 | tok/s 24771
step   1730 | loss 1.9241 | lr 3.00e-04 | grad 2.39 | tok/s 24822
step   1740 | loss 2.0517 | lr 3.00e-04 | grad 2.02 | tok/s 25346
step   1750 | loss 1.8773 | lr 3.00e-04 | grad 2.22 | tok/s 24652
step   1760 | loss 1.8661 | lr 3.00e-04 | grad 2.36 | tok/s 25039
step   1770 | loss 2.2092 | lr 3.00e-04 | grad 2.05 | tok/s 25221
step   1780 | loss 2.2375 | lr 3.00e-04 | grad 6.00 | tok/s 24691
step   1790 | loss 1.9504 | lr 3.00e-04 | grad 2.66 | tok/s 23606
step   1800 | loss 1.8194 | lr 3.00e-04 | grad 2.08 | tok/s 25253
step   1810 | loss 1.9290 | lr 3.00e-04 | grad 2.20 | tok/s 23925
step   1820 | loss 1.8652 | lr 3.00e-04 | grad 1.86 | tok/s 25214
step   1830 | loss 1.9905 | lr 3.00e-04 | grad 1.62 | tok/s 24385
step   1840 | loss 1.9646 | lr 3.00e-04 | grad 2.42 | tok/s 24447
step   1850 | loss 1.8718 | lr 3.00e-04 | grad 2.03 | tok/s 24623
step   1860 | loss 1.9570 | lr 3.00e-04 | grad 1.80 | tok/s 24414
step   1870 | loss 2.0380 | lr 3.00e-04 | grad 2.44 | tok/s 24816

Training complete! Final step: 1876
