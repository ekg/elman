Using device: cuda
Output directory: benchmark_results/cmaes_minlstm_10min/minlstm_480M_15gen_20260126_235957/eval_25/levelminlstm_100m_20260127_003045
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level minlstm, 226,925,568 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 5.3994 | lr 3.00e-04 | grad 3.67 | tok/s 22032
step     20 | loss 3.1384 | lr 3.00e-04 | grad 2.53 | tok/s 24271
step     30 | loss 3.5762 | lr 3.00e-04 | grad 3.80 | tok/s 24468
step     40 | loss 3.8427 | lr 3.00e-04 | grad 7.34 | tok/s 25282
step     50 | loss 5.1402 | lr 3.00e-04 | grad 4.59 | tok/s 25922
step     60 | loss 4.0718 | lr 3.00e-04 | grad 5.25 | tok/s 25902
step     70 | loss 3.7809 | lr 3.00e-04 | grad 4.28 | tok/s 25889
step     80 | loss 3.6268 | lr 3.00e-04 | grad 5.44 | tok/s 25876
step     90 | loss 3.3417 | lr 3.00e-04 | grad 2.72 | tok/s 25855
step    100 | loss 3.2637 | lr 3.00e-04 | grad 1.84 | tok/s 25857
step    110 | loss 3.0115 | lr 3.00e-04 | grad 3.23 | tok/s 25673
step    120 | loss 3.4140 | lr 3.00e-04 | grad 1.88 | tok/s 24819
step    130 | loss 2.7599 | lr 3.00e-04 | grad 2.75 | tok/s 24949
step    140 | loss 2.7713 | lr 3.00e-04 | grad 3.41 | tok/s 24950
step    150 | loss 2.9500 | lr 3.00e-04 | grad 3.53 | tok/s 25478
step    160 | loss 2.9943 | lr 3.00e-04 | grad 2.69 | tok/s 25589
step    170 | loss 2.7740 | lr 3.00e-04 | grad 2.39 | tok/s 24018
step    180 | loss 2.9483 | lr 3.00e-04 | grad 3.33 | tok/s 25129
step    190 | loss 2.6438 | lr 3.00e-04 | grad 2.33 | tok/s 23946
step    200 | loss 2.4229 | lr 3.00e-04 | grad 2.25 | tok/s 25540
step    210 | loss 2.4077 | lr 3.00e-04 | grad 1.68 | tok/s 24651
step    220 | loss 2.7817 | lr 3.00e-04 | grad 2.14 | tok/s 24836
step    230 | loss 2.7965 | lr 3.00e-04 | grad 3.42 | tok/s 24404
step    240 | loss 2.5828 | lr 3.00e-04 | grad 2.75 | tok/s 24812
step    250 | loss 2.7123 | lr 3.00e-04 | grad 2.39 | tok/s 24575
step    260 | loss 2.5226 | lr 3.00e-04 | grad 2.53 | tok/s 25492
step    270 | loss 2.5356 | lr 3.00e-04 | grad 2.83 | tok/s 24943
step    280 | loss 2.2856 | lr 3.00e-04 | grad 2.45 | tok/s 23547
step    290 | loss 2.3374 | lr 3.00e-04 | grad 2.66 | tok/s 24367
step    300 | loss 2.4912 | lr 3.00e-04 | grad 2.00 | tok/s 24135
step    310 | loss 2.2761 | lr 3.00e-04 | grad 2.61 | tok/s 24353
step    320 | loss 2.3981 | lr 3.00e-04 | grad 2.98 | tok/s 24083
step    330 | loss 2.4012 | lr 3.00e-04 | grad 1.86 | tok/s 24803
step    340 | loss 2.5306 | lr 3.00e-04 | grad 1.52 | tok/s 24891
step    350 | loss 2.6300 | lr 3.00e-04 | grad 1.61 | tok/s 24927
step    360 | loss 2.2690 | lr 3.00e-04 | grad 1.56 | tok/s 23865
step    370 | loss 2.3490 | lr 3.00e-04 | grad 1.59 | tok/s 25541
step    380 | loss 2.2254 | lr 3.00e-04 | grad 2.14 | tok/s 25766
step    390 | loss 2.1779 | lr 3.00e-04 | grad 2.58 | tok/s 25765
step    400 | loss 2.2174 | lr 3.00e-04 | grad 3.28 | tok/s 24924
step    410 | loss 2.4169 | lr 3.00e-04 | grad 2.36 | tok/s 24566
step    420 | loss 2.4303 | lr 3.00e-04 | grad 1.36 | tok/s 25319
step    430 | loss 2.4084 | lr 3.00e-04 | grad 1.78 | tok/s 25575
step    440 | loss 2.2933 | lr 3.00e-04 | grad 1.83 | tok/s 24536
step    450 | loss 2.3240 | lr 3.00e-04 | grad 1.26 | tok/s 24946
step    460 | loss 2.2447 | lr 3.00e-04 | grad 1.86 | tok/s 24861
step    470 | loss 2.2799 | lr 3.00e-04 | grad 2.05 | tok/s 24643
step    480 | loss 2.3834 | lr 3.00e-04 | grad 1.98 | tok/s 25708
step    490 | loss 2.3364 | lr 3.00e-04 | grad 2.67 | tok/s 24700
step    500 | loss 2.2033 | lr 3.00e-04 | grad 1.48 | tok/s 24580
step    510 | loss 2.4442 | lr 3.00e-04 | grad 1.59 | tok/s 24404
step    520 | loss 2.1543 | lr 3.00e-04 | grad 1.98 | tok/s 24210
step    530 | loss 2.1856 | lr 3.00e-04 | grad 1.69 | tok/s 24497
step    540 | loss 2.4390 | lr 3.00e-04 | grad 1.78 | tok/s 24760
step    550 | loss 1.8687 | lr 3.00e-04 | grad 1.92 | tok/s 24315
step    560 | loss 2.1953 | lr 3.00e-04 | grad 2.31 | tok/s 25408
step    570 | loss 2.1333 | lr 3.00e-04 | grad 2.23 | tok/s 25755
step    580 | loss 2.0729 | lr 3.00e-04 | grad 2.64 | tok/s 25753
step    590 | loss 2.0303 | lr 3.00e-04 | grad 1.82 | tok/s 25740
step    600 | loss 2.1003 | lr 3.00e-04 | grad 1.70 | tok/s 25741
step    610 | loss 2.0545 | lr 3.00e-04 | grad 2.11 | tok/s 25751
step    620 | loss 2.0032 | lr 3.00e-04 | grad 1.78 | tok/s 25750
step    630 | loss 2.2249 | lr 3.00e-04 | grad 2.30 | tok/s 24759
step    640 | loss 2.0553 | lr 3.00e-04 | grad 1.70 | tok/s 24027
step    650 | loss 2.2241 | lr 3.00e-04 | grad 2.03 | tok/s 25094
step    660 | loss 2.1142 | lr 3.00e-04 | grad 2.31 | tok/s 24942
step    670 | loss 2.2666 | lr 3.00e-04 | grad 1.83 | tok/s 25266
step    680 | loss 2.2394 | lr 3.00e-04 | grad 2.12 | tok/s 23740
step    690 | loss 2.2038 | lr 3.00e-04 | grad 1.69 | tok/s 24755
step    700 | loss 2.0552 | lr 3.00e-04 | grad 1.81 | tok/s 23893
step    710 | loss 2.2480 | lr 3.00e-04 | grad 2.06 | tok/s 24578
step    720 | loss 2.1355 | lr 3.00e-04 | grad 2.72 | tok/s 24406
step    730 | loss 2.0911 | lr 3.00e-04 | grad 4.34 | tok/s 25576
step    740 | loss 2.1624 | lr 3.00e-04 | grad 1.81 | tok/s 24627
step    750 | loss 2.6914 | lr 3.00e-04 | grad 1.98 | tok/s 25600
step    760 | loss 2.1618 | lr 3.00e-04 | grad 2.72 | tok/s 25573
step    770 | loss 2.0468 | lr 3.00e-04 | grad 1.43 | tok/s 24816
step    780 | loss 2.1249 | lr 3.00e-04 | grad 1.72 | tok/s 25067
step    790 | loss 2.1442 | lr 3.00e-04 | grad 2.62 | tok/s 24920
step    800 | loss 2.4927 | lr 3.00e-04 | grad 1.95 | tok/s 24771
step    810 | loss 1.6222 | lr 3.00e-04 | grad 1.80 | tok/s 24816
step    820 | loss 2.1822 | lr 3.00e-04 | grad 1.29 | tok/s 24771
step    830 | loss 2.0780 | lr 3.00e-04 | grad 1.70 | tok/s 23578
step    840 | loss 2.2426 | lr 3.00e-04 | grad 2.39 | tok/s 24932
step    850 | loss 2.1718 | lr 3.00e-04 | grad 2.00 | tok/s 24552
step    860 | loss 2.1756 | lr 3.00e-04 | grad 2.02 | tok/s 24561
step    870 | loss 2.4157 | lr 3.00e-04 | grad 1.90 | tok/s 25754
step    880 | loss 2.1298 | lr 3.00e-04 | grad 2.58 | tok/s 24828
step    890 | loss 2.0581 | lr 3.00e-04 | grad 1.94 | tok/s 24524
step    900 | loss 2.0464 | lr 3.00e-04 | grad 1.68 | tok/s 24839
step    910 | loss 2.1466 | lr 3.00e-04 | grad 2.20 | tok/s 24300
step    920 | loss 2.0867 | lr 3.00e-04 | grad 1.59 | tok/s 24990
step    930 | loss 2.1222 | lr 3.00e-04 | grad 1.86 | tok/s 24838
step    940 | loss 1.9737 | lr 3.00e-04 | grad 1.32 | tok/s 24674
step    950 | loss 2.0497 | lr 3.00e-04 | grad 2.23 | tok/s 23522
step    960 | loss 1.9796 | lr 3.00e-04 | grad 1.34 | tok/s 24142
step    970 | loss 1.9963 | lr 3.00e-04 | grad 1.90 | tok/s 24733
step    980 | loss 2.5138 | lr 3.00e-04 | grad 2.19 | tok/s 25516
step    990 | loss 2.4675 | lr 3.00e-04 | grad 2.42 | tok/s 25223
step   1000 | loss 2.1478 | lr 3.00e-04 | grad 0.93 | tok/s 24358
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1478.pt
step   1010 | loss 1.7498 | lr 3.00e-04 | grad 1.60 | tok/s 16726
step   1020 | loss 1.7657 | lr 3.00e-04 | grad 1.36 | tok/s 25493
step   1030 | loss 2.1836 | lr 3.00e-04 | grad 1.59 | tok/s 25319
step   1040 | loss 2.2382 | lr 3.00e-04 | grad 4.62 | tok/s 24322
step   1050 | loss 2.4757 | lr 3.00e-04 | grad 1.66 | tok/s 25525
step   1060 | loss 2.1983 | lr 3.00e-04 | grad 1.91 | tok/s 24662
step   1070 | loss 1.6515 | lr 3.00e-04 | grad 1.59 | tok/s 25330
step   1080 | loss 1.9679 | lr 3.00e-04 | grad 2.17 | tok/s 25388
step   1090 | loss 1.8858 | lr 3.00e-04 | grad 1.85 | tok/s 25761
step   1100 | loss 1.8587 | lr 3.00e-04 | grad 1.61 | tok/s 25750
step   1110 | loss 1.8352 | lr 3.00e-04 | grad 2.84 | tok/s 25767
step   1120 | loss 1.8880 | lr 3.00e-04 | grad 2.50 | tok/s 25512
step   1130 | loss 2.2615 | lr 3.00e-04 | grad 3.94 | tok/s 25293
step   1140 | loss 2.4144 | lr 3.00e-04 | grad 2.06 | tok/s 25171
step   1150 | loss 2.1548 | lr 3.00e-04 | grad 5.22 | tok/s 25284
step   1160 | loss 2.4185 | lr 3.00e-04 | grad 2.11 | tok/s 24759
step   1170 | loss 2.1931 | lr 3.00e-04 | grad 2.31 | tok/s 24270
step   1180 | loss 2.0124 | lr 3.00e-04 | grad 1.79 | tok/s 24558
step   1190 | loss 2.1322 | lr 3.00e-04 | grad 1.57 | tok/s 25479
step   1200 | loss 2.1237 | lr 3.00e-04 | grad 2.52 | tok/s 25729
step   1210 | loss 1.8018 | lr 3.00e-04 | grad 2.20 | tok/s 25216
step   1220 | loss 1.9830 | lr 3.00e-04 | grad 1.43 | tok/s 24476
step   1230 | loss 2.0178 | lr 3.00e-04 | grad 1.34 | tok/s 24859
step   1240 | loss 1.9328 | lr 3.00e-04 | grad 2.16 | tok/s 25498
step   1250 | loss 1.9607 | lr 3.00e-04 | grad 2.02 | tok/s 24973
step   1260 | loss 2.2629 | lr 3.00e-04 | grad 2.02 | tok/s 25606
step   1270 | loss 2.0738 | lr 3.00e-04 | grad 1.97 | tok/s 25120
step   1280 | loss 1.9612 | lr 3.00e-04 | grad 2.03 | tok/s 25249
step   1290 | loss 2.0622 | lr 3.00e-04 | grad 1.91 | tok/s 24335
step   1300 | loss 2.0211 | lr 3.00e-04 | grad 2.14 | tok/s 24194
step   1310 | loss 2.3569 | lr 3.00e-04 | grad 1.88 | tok/s 24769
step   1320 | loss 2.0224 | lr 3.00e-04 | grad 2.55 | tok/s 25201
step   1330 | loss 2.2294 | lr 3.00e-04 | grad 1.80 | tok/s 25073
step   1340 | loss 1.9274 | lr 3.00e-04 | grad 2.52 | tok/s 24363
step   1350 | loss 2.1469 | lr 3.00e-04 | grad 1.82 | tok/s 25176
step   1360 | loss 2.1661 | lr 3.00e-04 | grad 1.27 | tok/s 24433
step   1370 | loss 1.9432 | lr 3.00e-04 | grad 1.95 | tok/s 24515
step   1380 | loss 2.2842 | lr 3.00e-04 | grad 1.77 | tok/s 25191
step   1390 | loss 1.9862 | lr 3.00e-04 | grad 2.08 | tok/s 24254
step   1400 | loss 2.1743 | lr 3.00e-04 | grad 2.23 | tok/s 24706
step   1410 | loss 1.8839 | lr 3.00e-04 | grad 1.91 | tok/s 24521
step   1420 | loss 2.0105 | lr 3.00e-04 | grad 2.50 | tok/s 24771
step   1430 | loss 2.1581 | lr 3.00e-04 | grad 1.40 | tok/s 25082
step   1440 | loss 2.0748 | lr 3.00e-04 | grad 1.41 | tok/s 24665
step   1450 | loss 2.1287 | lr 3.00e-04 | grad 1.80 | tok/s 25466
step   1460 | loss 1.9711 | lr 3.00e-04 | grad 2.28 | tok/s 24695
step   1470 | loss 2.0574 | lr 3.00e-04 | grad 1.97 | tok/s 24523
step   1480 | loss 1.8850 | lr 3.00e-04 | grad 1.59 | tok/s 24149
step   1490 | loss 1.9298 | lr 3.00e-04 | grad 1.68 | tok/s 24737
step   1500 | loss 2.4033 | lr 3.00e-04 | grad 1.80 | tok/s 25221
step   1510 | loss 1.9022 | lr 3.00e-04 | grad 2.20 | tok/s 25053
step   1520 | loss 1.9042 | lr 3.00e-04 | grad 1.97 | tok/s 24294
step   1530 | loss 1.9508 | lr 3.00e-04 | grad 1.49 | tok/s 25060
step   1540 | loss 2.0373 | lr 3.00e-04 | grad 2.23 | tok/s 25336
step   1550 | loss 1.9458 | lr 3.00e-04 | grad 1.72 | tok/s 25251
step   1560 | loss 2.0130 | lr 3.00e-04 | grad 1.72 | tok/s 24891
step   1570 | loss 1.8781 | lr 3.00e-04 | grad 2.89 | tok/s 25030
step   1580 | loss 1.9375 | lr 3.00e-04 | grad 2.14 | tok/s 25751
step   1590 | loss 1.9900 | lr 3.00e-04 | grad 2.09 | tok/s 24408
step   1600 | loss 1.8103 | lr 3.00e-04 | grad 1.78 | tok/s 24769
step   1610 | loss 1.9485 | lr 3.00e-04 | grad 1.91 | tok/s 25315
step   1620 | loss 2.5932 | lr 3.00e-04 | grad 1.77 | tok/s 25386
step   1630 | loss 2.3368 | lr 3.00e-04 | grad 2.23 | tok/s 25748
step   1640 | loss 2.2374 | lr 3.00e-04 | grad 1.88 | tok/s 25753
step   1650 | loss 2.1683 | lr 3.00e-04 | grad 1.94 | tok/s 25737
step   1660 | loss 2.1330 | lr 3.00e-04 | grad 2.31 | tok/s 25736
step   1670 | loss 2.1122 | lr 3.00e-04 | grad 2.20 | tok/s 25750
step   1680 | loss 2.0919 | lr 3.00e-04 | grad 1.50 | tok/s 24679
step   1690 | loss 1.9003 | lr 3.00e-04 | grad 2.20 | tok/s 24130
step   1700 | loss 1.9905 | lr 3.00e-04 | grad 2.05 | tok/s 24408
step   1710 | loss 1.8058 | lr 3.00e-04 | grad 1.36 | tok/s 25700
step   1720 | loss 1.9400 | lr 3.00e-04 | grad 2.08 | tok/s 24656
step   1730 | loss 1.9241 | lr 3.00e-04 | grad 2.39 | tok/s 24692
step   1740 | loss 2.0517 | lr 3.00e-04 | grad 2.02 | tok/s 25221
step   1750 | loss 1.8773 | lr 3.00e-04 | grad 2.22 | tok/s 24529
step   1760 | loss 1.8661 | lr 3.00e-04 | grad 2.36 | tok/s 24925
step   1770 | loss 2.2092 | lr 3.00e-04 | grad 2.05 | tok/s 25089
step   1780 | loss 2.2375 | lr 3.00e-04 | grad 6.00 | tok/s 24568
step   1790 | loss 1.9504 | lr 3.00e-04 | grad 2.66 | tok/s 23487
step   1800 | loss 1.8194 | lr 3.00e-04 | grad 2.08 | tok/s 25133
step   1810 | loss 1.9290 | lr 3.00e-04 | grad 2.20 | tok/s 23810
step   1820 | loss 1.8652 | lr 3.00e-04 | grad 1.86 | tok/s 25088
step   1830 | loss 1.9905 | lr 3.00e-04 | grad 1.62 | tok/s 24272
step   1840 | loss 1.9646 | lr 3.00e-04 | grad 2.42 | tok/s 24336
step   1850 | loss 1.8718 | lr 3.00e-04 | grad 2.03 | tok/s 24513
step   1860 | loss 1.9570 | lr 3.00e-04 | grad 1.80 | tok/s 24292
step   1870 | loss 2.0380 | lr 3.00e-04 | grad 2.44 | tok/s 24696

Training complete! Final step: 1870
