Using device: cuda
Output directory: benchmark_results/cmaes_converge/e88_480M_converge0.01_20260201_190214/eval_12/levelE88_100m_20260201_193238
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 474,135,798 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 4.2328 | lr 3.00e-04 | grad 7.28 | tok/s 7353
step     20 | loss 2.7180 | lr 3.00e-04 | grad 2.28 | tok/s 10755
step     30 | loss 3.0114 | lr 3.00e-04 | grad 4.09 | tok/s 11349
step     40 | loss 4.1086 | lr 3.00e-04 | grad 25.38 | tok/s 11555
step     50 | loss 4.3002 | lr 3.00e-04 | grad 11.56 | tok/s 11686
step     60 | loss 3.4536 | lr 3.00e-04 | grad 8.88 | tok/s 11656
step     70 | loss 2.7575 | lr 3.00e-04 | grad 5.16 | tok/s 11631
step     80 | loss 2.5166 | lr 3.00e-04 | grad 3.98 | tok/s 11630
step     90 | loss 2.3516 | lr 3.00e-04 | grad 3.52 | tok/s 11617
step    100 | loss 2.1581 | lr 3.00e-04 | grad 2.06 | tok/s 11603
step    110 | loss 2.2125 | lr 3.00e-04 | grad 2.23 | tok/s 11508
step    120 | loss 2.6745 | lr 3.00e-04 | grad 1.44 | tok/s 10967
step    130 | loss 2.1205 | lr 3.00e-04 | grad 3.95 | tok/s 10977
step    140 | loss 2.3624 | lr 3.00e-04 | grad 5.56 | tok/s 11265
step    150 | loss 1.3691 | lr 3.00e-04 | grad 4.06 | tok/s 11522
step    160 | loss 2.3379 | lr 3.00e-04 | grad 1.66 | tok/s 11145
step    170 | loss 2.2685 | lr 3.00e-04 | grad 1.23 | tok/s 10974
step    180 | loss 1.8803 | lr 3.00e-04 | grad 2.25 | tok/s 11242
step    190 | loss 1.9190 | lr 3.00e-04 | grad 1.59 | tok/s 11043
step    200 | loss 1.6789 | lr 3.00e-04 | grad 1.34 | tok/s 11562
step    210 | loss 1.8867 | lr 3.00e-04 | grad 3.75 | tok/s 10965
step    220 | loss 2.1988 | lr 3.00e-04 | grad 2.53 | tok/s 11079
step    230 | loss 1.9060 | lr 3.00e-04 | grad 2.06 | tok/s 11079
step    240 | loss 2.2319 | lr 3.00e-04 | grad 3.95 | tok/s 11221
step    250 | loss 1.7712 | lr 3.00e-04 | grad 1.26 | tok/s 11149
step    260 | loss 1.8933 | lr 3.00e-04 | grad 2.39 | tok/s 11470
step    270 | loss 1.8194 | lr 3.00e-04 | grad 1.48 | tok/s 11224
step    280 | loss 1.7695 | lr 3.00e-04 | grad 1.45 | tok/s 10534
step    290 | loss 1.6695 | lr 3.00e-04 | grad 1.72 | tok/s 10900
step    300 | loss 1.9489 | lr 3.00e-04 | grad 1.55 | tok/s 10983
step    310 | loss 1.6636 | lr 3.00e-04 | grad 1.37 | tok/s 10931
step    320 | loss 1.8631 | lr 3.00e-04 | grad 2.25 | tok/s 11059
step    330 | loss 1.7152 | lr 3.00e-04 | grad 1.38 | tok/s 11179
step    340 | loss 2.0070 | lr 3.00e-04 | grad 1.58 | tok/s 11137
step    350 | loss 1.7065 | lr 3.00e-04 | grad 1.57 | tok/s 11474
step    360 | loss 1.5741 | lr 3.00e-04 | grad 1.52 | tok/s 10966
step    370 | loss 1.4864 | lr 3.00e-04 | grad 1.31 | tok/s 11548
step    380 | loss 1.2239 | lr 3.00e-04 | grad 1.42 | tok/s 11651
step    390 | loss 1.1190 | lr 3.00e-04 | grad 1.23 | tok/s 11645
step    400 | loss 1.7315 | lr 3.00e-04 | grad 1.43 | tok/s 11041
step    410 | loss 1.7267 | lr 3.00e-04 | grad 1.84 | tok/s 11140
step    420 | loss 1.6223 | lr 3.00e-04 | grad 3.20 | tok/s 11622
step    430 | loss 1.6140 | lr 3.00e-04 | grad 1.51 | tok/s 11426
step    440 | loss 1.6767 | lr 3.00e-04 | grad 1.76 | tok/s 11073
step    450 | loss 1.6145 | lr 3.00e-04 | grad 1.20 | tok/s 11183
step    460 | loss 1.5857 | lr 3.00e-04 | grad 1.61 | tok/s 11359
step    470 | loss 1.5548 | lr 3.00e-04 | grad 2.53 | tok/s 11275
step    480 | loss 1.5654 | lr 3.00e-04 | grad 2.19 | tok/s 11521
step    490 | loss 1.6802 | lr 3.00e-04 | grad 1.84 | tok/s 11066
step    500 | loss 1.7868 | lr 3.00e-04 | grad 1.38 | tok/s 11235
step    510 | loss 1.6630 | lr 3.00e-04 | grad 1.18 | tok/s 10737
step    520 | loss 1.5218 | lr 3.00e-04 | grad 1.64 | tok/s 11243
step    530 | loss 1.6922 | lr 3.00e-04 | grad 1.62 | tok/s 11054
step    540 | loss 1.5803 | lr 3.00e-04 | grad 1.28 | tok/s 10823
step    550 | loss 1.3441 | lr 3.00e-04 | grad 2.09 | tok/s 11300
step    560 | loss 1.4312 | lr 3.00e-04 | grad 1.40 | tok/s 11652
step    570 | loss 1.3396 | lr 3.00e-04 | grad 1.38 | tok/s 11659
step    580 | loss 1.2971 | lr 3.00e-04 | grad 1.05 | tok/s 11639
step    590 | loss 1.3308 | lr 3.00e-04 | grad 1.06 | tok/s 11501
step    600 | loss 1.2669 | lr 3.00e-04 | grad 1.34 | tok/s 11652
step    610 | loss 1.2986 | lr 3.00e-04 | grad 1.23 | tok/s 11659
step    620 | loss 1.2882 | lr 3.00e-04 | grad 1.37 | tok/s 11593
step    630 | loss 1.6161 | lr 3.00e-04 | grad 3.30 | tok/s 10948
step    640 | loss 1.7108 | lr 3.00e-04 | grad 1.70 | tok/s 11100
step    650 | loss 1.5366 | lr 3.00e-04 | grad 1.40 | tok/s 11083
step    660 | loss 1.5830 | lr 3.00e-04 | grad 1.38 | tok/s 11515
step    670 | loss 1.6008 | lr 3.00e-04 | grad 4.28 | tok/s 11139
step    680 | loss 1.6148 | lr 3.00e-04 | grad 1.55 | tok/s 10953
step    690 | loss 1.5432 | lr 3.00e-04 | grad 1.46 | tok/s 10861
step    700 | loss 1.4643 | lr 3.00e-04 | grad 1.13 | tok/s 11106
step    710 | loss 1.6149 | lr 3.00e-04 | grad 2.59 | tok/s 10943
step    720 | loss 1.2919 | lr 3.00e-04 | grad 1.20 | tok/s 11356
step    730 | loss 1.4451 | lr 3.00e-04 | grad 1.19 | tok/s 11180
step    740 | loss 1.7378 | lr 3.00e-04 | grad 2.61 | tok/s 11489
step    750 | loss 1.5127 | lr 3.00e-04 | grad 1.13 | tok/s 11614
step    760 | loss 1.5092 | lr 3.00e-04 | grad 2.61 | tok/s 11385
step    770 | loss 1.5562 | lr 3.00e-04 | grad 1.50 | tok/s 11192
step    780 | loss 1.4700 | lr 3.00e-04 | grad 1.42 | tok/s 11256
step    790 | loss 1.6026 | lr 3.00e-04 | grad 3.48 | tok/s 11513
step    800 | loss 1.3008 | lr 3.00e-04 | grad 1.00 | tok/s 11279
step    810 | loss 1.2991 | lr 3.00e-04 | grad 2.14 | tok/s 10903
step    820 | loss 1.4040 | lr 3.00e-04 | grad 1.40 | tok/s 11132
step    830 | loss 1.4743 | lr 3.00e-04 | grad 1.11 | tok/s 10993
step    840 | loss 1.5950 | lr 3.00e-04 | grad 1.18 | tok/s 10950
step    850 | loss 1.5257 | lr 3.00e-04 | grad 1.23 | tok/s 11151
step    860 | loss 1.5576 | lr 3.00e-04 | grad 1.82 | tok/s 11372
step    870 | loss 1.3825 | lr 3.00e-04 | grad 1.49 | tok/s 11449
step    880 | loss 1.5709 | lr 3.00e-04 | grad 1.31 | tok/s 11228
step    890 | loss 1.4682 | lr 3.00e-04 | grad 1.06 | tok/s 11183
step    900 | loss 1.5124 | lr 3.00e-04 | grad 1.30 | tok/s 11121
step    910 | loss 1.5030 | lr 3.00e-04 | grad 5.56 | tok/s 11012
step    920 | loss 1.4572 | lr 3.00e-04 | grad 1.30 | tok/s 11132
step    930 | loss 1.3765 | lr 3.00e-04 | grad 1.62 | tok/s 11263
step    940 | loss 1.3364 | lr 3.00e-04 | grad 1.48 | tok/s 11019
step    950 | loss 1.4739 | lr 3.00e-04 | grad 1.76 | tok/s 10832
step    960 | loss 1.4250 | lr 3.00e-04 | grad 1.05 | tok/s 11128
step    970 | loss 1.4608 | lr 3.00e-04 | grad 1.23 | tok/s 11131
step    980 | loss 1.8363 | lr 3.00e-04 | grad 2.56 | tok/s 11583
step    990 | loss 1.5434 | lr 3.00e-04 | grad 1.34 | tok/s 11108
step   1000 | loss 1.5417 | lr 3.00e-04 | grad 1.35 | tok/s 11142
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5417.pt
step   1010 | loss 1.3451 | lr 3.00e-04 | grad 1.46 | tok/s 7756
step   1020 | loss 1.1868 | lr 3.00e-04 | grad 1.11 | tok/s 11704
step   1030 | loss 1.5736 | lr 3.00e-04 | grad 1.34 | tok/s 10934
step   1040 | loss 2.1173 | lr 3.00e-04 | grad 1.91 | tok/s 11442
step   1050 | loss 1.4488 | lr 3.00e-04 | grad 1.48 | tok/s 11298
step   1060 | loss 1.1049 | lr 3.00e-04 | grad 0.95 | tok/s 11467
step   1070 | loss 1.4559 | lr 3.00e-04 | grad 1.27 | tok/s 11261
step   1080 | loss 1.2503 | lr 3.00e-04 | grad 1.26 | tok/s 11642
step   1090 | loss 1.2247 | lr 3.00e-04 | grad 1.08 | tok/s 11641
step   1100 | loss 1.1829 | lr 3.00e-04 | grad 1.07 | tok/s 11652
step   1110 | loss 1.1709 | lr 3.00e-04 | grad 1.23 | tok/s 11650
step   1120 | loss 1.4619 | lr 3.00e-04 | grad 2.52 | tok/s 11316
step   1130 | loss 1.6212 | lr 3.00e-04 | grad 2.03 | tok/s 11443
step   1140 | loss 1.6617 | lr 3.00e-04 | grad 1.19 | tok/s 11581
step   1150 | loss 1.5702 | lr 3.00e-04 | grad 1.49 | tok/s 11014
step   1160 | loss 1.7346 | lr 3.00e-04 | grad 4.81 | tok/s 11177
step   1170 | loss 1.4150 | lr 3.00e-04 | grad 1.34 | tok/s 10987
step   1180 | loss 1.3348 | lr 3.00e-04 | grad 1.62 | tok/s 11402
step   1190 | loss 1.5063 | lr 3.00e-04 | grad 3.59 | tok/s 11614
step   1200 | loss 1.1097 | lr 3.00e-04 | grad 2.02 | tok/s 11622
step   1210 | loss 1.4323 | lr 3.00e-04 | grad 1.88 | tok/s 10813
step   1220 | loss 1.3430 | lr 3.00e-04 | grad 1.26 | tok/s 11245
step   1230 | loss 1.3017 | lr 3.00e-04 | grad 0.97 | tok/s 11535
step   1240 | loss 1.2954 | lr 3.00e-04 | grad 1.15 | tok/s 11359
step   1250 | loss 1.4679 | lr 3.00e-04 | grad 3.67 | tok/s 11385
step   1260 | loss 1.3782 | lr 3.00e-04 | grad 1.51 | tok/s 11477
step   1270 | loss 1.3563 | lr 3.00e-04 | grad 1.09 | tok/s 11269
step   1280 | loss 1.4097 | lr 3.00e-04 | grad 1.43 | tok/s 11090
step   1290 | loss 1.3052 | lr 3.00e-04 | grad 1.32 | tok/s 11119
step   1300 | loss 1.5774 | lr 3.00e-04 | grad 3.14 | tok/s 10932
step   1310 | loss 1.4612 | lr 3.00e-04 | grad 1.34 | tok/s 11328
step   1320 | loss 1.4840 | lr 3.00e-04 | grad 2.27 | tok/s 11414
step   1330 | loss 1.3724 | lr 3.00e-04 | grad 1.24 | tok/s 11254
step   1340 | loss 1.5301 | lr 3.00e-04 | grad 1.48 | tok/s 11038
step   1350 | loss 1.4361 | lr 3.00e-04 | grad 3.28 | tok/s 11203
step   1360 | loss 1.3774 | lr 3.00e-04 | grad 1.35 | tok/s 10909
step   1370 | loss 1.6065 | lr 3.00e-04 | grad 2.23 | tok/s 11430
step   1380 | loss 1.3888 | lr 3.00e-04 | grad 2.09 | tok/s 10885
step   1390 | loss 1.3189 | lr 3.00e-04 | grad 1.53 | tok/s 11460
step   1400 | loss 1.4292 | lr 3.00e-04 | grad 1.09 | tok/s 11097
step   1410 | loss 1.4095 | lr 3.00e-04 | grad 2.78 | tok/s 10823
step   1420 | loss 1.1804 | lr 3.00e-04 | grad 6.25 | tok/s 11519
step   1430 | loss 1.5388 | lr 3.00e-04 | grad 1.29 | tok/s 11075
step   1440 | loss 1.4126 | lr 3.00e-04 | grad 1.57 | tok/s 11425
step   1450 | loss 1.4290 | lr 3.00e-04 | grad 1.52 | tok/s 11347
step   1460 | loss 1.5562 | lr 3.00e-04 | grad 2.91 | tok/s 11065
step   1470 | loss 1.3085 | lr 3.00e-04 | grad 1.20 | tok/s 10699
step   1480 | loss 1.3577 | lr 3.00e-04 | grad 1.89 | tok/s 11464
step   1490 | loss 1.8417 | lr 3.00e-04 | grad 2.70 | tok/s 11076
step   1500 | loss 1.3979 | lr 3.00e-04 | grad 1.47 | tok/s 11286
step   1510 | loss 1.2014 | lr 3.00e-04 | grad 1.06 | tok/s 11179
step   1520 | loss 1.4544 | lr 3.00e-04 | grad 1.23 | tok/s 11225
step   1530 | loss 1.3937 | lr 3.00e-04 | grad 1.79 | tok/s 11325
step   1540 | loss 1.4878 | lr 3.00e-04 | grad 1.34 | tok/s 11428
step   1550 | loss 1.4529 | lr 3.00e-04 | grad 2.33 | tok/s 11207
step   1560 | loss 1.0957 | lr 3.00e-04 | grad 1.14 | tok/s 11633
step   1570 | loss 1.2388 | lr 3.00e-04 | grad 1.06 | tok/s 11301
step   1580 | loss 1.3675 | lr 3.00e-04 | grad 4.75 | tok/s 11249
step   1590 | loss 1.3503 | lr 3.00e-04 | grad 1.38 | tok/s 11069
step   1600 | loss 1.3027 | lr 3.00e-04 | grad 1.72 | tok/s 11325
step   1610 | loss 1.9716 | lr 3.00e-04 | grad 1.95 | tok/s 11474
step   1620 | loss 1.8227 | lr 3.00e-04 | grad 1.73 | tok/s 11639
step   1630 | loss 1.5799 | lr 3.00e-04 | grad 1.54 | tok/s 11642
step   1640 | loss 1.4367 | lr 3.00e-04 | grad 1.65 | tok/s 11650
step   1650 | loss 1.3688 | lr 3.00e-04 | grad 1.63 | tok/s 11656
step   1660 | loss 1.3209 | lr 3.00e-04 | grad 1.46 | tok/s 11648
step   1670 | loss 1.5066 | lr 3.00e-04 | grad 1.88 | tok/s 11262
step   1680 | loss 1.3909 | lr 3.00e-04 | grad 1.14 | tok/s 10940
step   1690 | loss 1.4586 | lr 3.00e-04 | grad 1.17 | tok/s 11030
step   1700 | loss 1.2470 | lr 3.00e-04 | grad 1.06 | tok/s 11457
step   1710 | loss 1.2692 | lr 3.00e-04 | grad 1.34 | tok/s 11224
step   1720 | loss 1.4384 | lr 3.00e-04 | grad 1.52 | tok/s 11156
step   1730 | loss 1.4008 | lr 3.00e-04 | grad 1.45 | tok/s 11268
step   1740 | loss 1.3827 | lr 3.00e-04 | grad 1.02 | tok/s 11517
step   1750 | loss 1.2171 | lr 3.00e-04 | grad 1.42 | tok/s 11029
step   1760 | loss 1.4610 | lr 3.00e-04 | grad 2.12 | tok/s 11107
step   1770 | loss 1.5239 | lr 3.00e-04 | grad 2.11 | tok/s 11362
step   1780 | loss 1.7264 | lr 3.00e-04 | grad 2.14 | tok/s 10680
step   1790 | loss 1.2310 | lr 3.00e-04 | grad 3.02 | tok/s 11038
step   1800 | loss 1.3322 | lr 3.00e-04 | grad 1.62 | tok/s 11030
step   1810 | loss 1.3490 | lr 3.00e-04 | grad 1.62 | tok/s 11284
step   1820 | loss 1.5007 | lr 3.00e-04 | grad 1.49 | tok/s 11010
step   1830 | loss 1.3754 | lr 3.00e-04 | grad 1.27 | tok/s 10868
step   1840 | loss 1.2975 | lr 3.00e-04 | grad 1.17 | tok/s 11264
step   1850 | loss 1.3827 | lr 3.00e-04 | grad 2.67 | tok/s 10883
step   1860 | loss 1.4641 | lr 3.00e-04 | grad 2.34 | tok/s 11238
step   1870 | loss 1.3126 | lr 3.00e-04 | grad 1.09 | tok/s 11262
step   1880 | loss 1.4390 | lr 3.00e-04 | grad 0.96 | tok/s 11393
step   1890 | loss 1.2230 | lr 3.00e-04 | grad 1.16 | tok/s 11632
step   1900 | loss 1.1777 | lr 3.00e-04 | grad 1.03 | tok/s 11648
step   1910 | loss 1.1491 | lr 3.00e-04 | grad 1.08 | tok/s 11650
step   1920 | loss 1.1349 | lr 3.00e-04 | grad 1.12 | tok/s 11657
step   1930 | loss 1.2355 | lr 3.00e-04 | grad 1.51 | tok/s 11457
step   1940 | loss 1.4857 | lr 3.00e-04 | grad 1.42 | tok/s 11020
step   1950 | loss 1.4331 | lr 3.00e-04 | grad 1.90 | tok/s 10983
step   1960 | loss 1.4587 | lr 3.00e-04 | grad 3.31 | tok/s 11080
step   1970 | loss 1.4406 | lr 3.00e-04 | grad 1.33 | tok/s 11273
step   1980 | loss 1.3781 | lr 3.00e-04 | grad 1.67 | tok/s 11142
step   1990 | loss 1.4752 | lr 3.00e-04 | grad 1.79 | tok/s 11251
step   2000 | loss 1.0377 | lr 3.00e-04 | grad 1.36 | tok/s 11668
  >>> saved checkpoint: checkpoint_step_002000_loss_1.0377.pt
step   2010 | loss 1.3227 | lr 3.00e-04 | grad 1.62 | tok/s 7480
step   2020 | loss 1.3604 | lr 3.00e-04 | grad 1.18 | tok/s 11169
step   2030 | loss 1.9123 | lr 3.00e-04 | grad 1.97 | tok/s 10960
step   2040 | loss 1.3659 | lr 3.00e-04 | grad 1.14 | tok/s 11354
step   2050 | loss 1.3594 | lr 3.00e-04 | grad 1.76 | tok/s 11207
step   2060 | loss 1.5968 | lr 3.00e-04 | grad 1.68 | tok/s 11264
step   2070 | loss 1.0972 | lr 3.00e-04 | grad 1.12 | tok/s 11240
step   2080 | loss 1.2022 | lr 3.00e-04 | grad 0.94 | tok/s 11046
step   2090 | loss 1.5042 | lr 3.00e-04 | grad 2.00 | tok/s 11485
step   2100 | loss 1.4490 | lr 3.00e-04 | grad 1.30 | tok/s 11499
step   2110 | loss 1.3518 | lr 3.00e-04 | grad 1.22 | tok/s 11153
step   2120 | loss 2.1216 | lr 3.00e-04 | grad 1.42 | tok/s 11372
step   2130 | loss 1.4349 | lr 3.00e-04 | grad 2.05 | tok/s 10989
step   2140 | loss 1.4139 | lr 3.00e-04 | grad 1.61 | tok/s 11195
step   2150 | loss 1.6591 | lr 3.00e-04 | grad 1.28 | tok/s 11449
step   2160 | loss 1.3738 | lr 3.00e-04 | grad 1.43 | tok/s 11227
step   2170 | loss 1.4504 | lr 3.00e-04 | grad 2.56 | tok/s 11468
step   2180 | loss 1.0942 | lr 3.00e-04 | grad 1.62 | tok/s 11637
step   2190 | loss 1.4581 | lr 3.00e-04 | grad 1.71 | tok/s 11149
step   2200 | loss 1.1303 | lr 3.00e-04 | grad 2.06 | tok/s 11681
step   2210 | loss 1.4139 | lr 3.00e-04 | grad 1.37 | tok/s 11282
step   2220 | loss 1.4284 | lr 3.00e-04 | grad 1.19 | tok/s 10840
step   2230 | loss 1.5612 | lr 3.00e-04 | grad 1.08 | tok/s 11239
step   2240 | loss 1.3355 | lr 3.00e-04 | grad 1.59 | tok/s 11347
step   2250 | loss 1.3286 | lr 3.00e-04 | grad 1.07 | tok/s 11137
step   2260 | loss 1.5577 | lr 3.00e-04 | grad 4.12 | tok/s 11275
step   2270 | loss 1.5596 | lr 3.00e-04 | grad 1.56 | tok/s 10712
step   2280 | loss 1.3770 | lr 3.00e-04 | grad 1.87 | tok/s 11393
step   2290 | loss 1.2386 | lr 3.00e-04 | grad 1.46 | tok/s 10940
step   2300 | loss 1.6646 | lr 3.00e-04 | grad 2.19 | tok/s 11120
step   2310 | loss 1.2941 | lr 3.00e-04 | grad 1.22 | tok/s 11445
step   2320 | loss 1.3278 | lr 3.00e-04 | grad 1.12 | tok/s 11711
step   2330 | loss 1.2606 | lr 3.00e-04 | grad 1.10 | tok/s 11720
step   2340 | loss 1.2301 | lr 3.00e-04 | grad 1.02 | tok/s 11724
step   2350 | loss 1.2133 | lr 3.00e-04 | grad 1.07 | tok/s 11717
step   2360 | loss 1.1493 | lr 3.00e-04 | grad 1.06 | tok/s 11712
step   2370 | loss 1.1603 | lr 3.00e-04 | grad 1.16 | tok/s 11709
step   2380 | loss 1.1426 | lr 3.00e-04 | grad 1.11 | tok/s 11709
step   2390 | loss 1.1609 | lr 3.00e-04 | grad 1.03 | tok/s 11705
step   2400 | loss 1.1094 | lr 3.00e-04 | grad 1.05 | tok/s 11706
step   2410 | loss 1.4490 | lr 3.00e-04 | grad 9.75 | tok/s 11514
step   2420 | loss 1.0764 | lr 3.00e-04 | grad 0.69 | tok/s 11536
step   2430 | loss 1.2708 | lr 3.00e-04 | grad 1.70 | tok/s 10974
step   2440 | loss 1.3439 | lr 3.00e-04 | grad 1.09 | tok/s 11031
step   2450 | loss 1.3281 | lr 3.00e-04 | grad 1.21 | tok/s 11369
step   2460 | loss 1.4790 | lr 3.00e-04 | grad 1.12 | tok/s 11509
step   2470 | loss 1.3176 | lr 3.00e-04 | grad 1.34 | tok/s 11138
step   2480 | loss 1.3881 | lr 3.00e-04 | grad 2.55 | tok/s 11552
step   2490 | loss 1.4530 | lr 3.00e-04 | grad 2.86 | tok/s 11124
step   2500 | loss 1.5068 | lr 3.00e-04 | grad 1.77 | tok/s 11467
step   2510 | loss 1.3980 | lr 3.00e-04 | grad 1.55 | tok/s 11229
step   2520 | loss 1.3341 | lr 3.00e-04 | grad 1.27 | tok/s 11146
step   2530 | loss 1.5095 | lr 3.00e-04 | grad 1.54 | tok/s 11377

Training complete! Final step: 2531
