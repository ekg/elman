Using device: cuda
Output directory: benchmark_results/cmaes_converge/e88_480M_converge0.01_20260201_190214/eval_16/levelE88_100m_20260201_193238
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 475,499,264 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 4.3451 | lr 3.00e-04 | grad 10.94 | tok/s 9026
step     20 | loss 3.0725 | lr 3.00e-04 | grad 3.52 | tok/s 15834
step     30 | loss 2.8671 | lr 3.00e-04 | grad 4.78 | tok/s 16624
step     40 | loss 3.9884 | lr 3.00e-04 | grad 13.44 | tok/s 16915
step     50 | loss 3.7891 | lr 3.00e-04 | grad 15.06 | tok/s 17060
step     60 | loss 3.0355 | lr 3.00e-04 | grad 5.09 | tok/s 17008
step     70 | loss 2.6369 | lr 3.00e-04 | grad 3.55 | tok/s 16952
step     80 | loss 2.4205 | lr 3.00e-04 | grad 3.45 | tok/s 16977
step     90 | loss 2.2895 | lr 3.00e-04 | grad 3.72 | tok/s 16913
step    100 | loss 2.0594 | lr 3.00e-04 | grad 2.89 | tok/s 16845
step    110 | loss 2.1560 | lr 3.00e-04 | grad 3.45 | tok/s 16744
step    120 | loss 2.6637 | lr 3.00e-04 | grad 2.48 | tok/s 15948
step    130 | loss 2.1093 | lr 3.00e-04 | grad 4.59 | tok/s 16312
step    140 | loss 2.3624 | lr 3.00e-04 | grad 6.44 | tok/s 16350
step    150 | loss 1.3841 | lr 3.00e-04 | grad 5.75 | tok/s 16726
step    160 | loss 2.3374 | lr 3.00e-04 | grad 2.30 | tok/s 16170
step    170 | loss 2.2943 | lr 3.00e-04 | grad 1.85 | tok/s 15931
step    180 | loss 1.8206 | lr 3.00e-04 | grad 2.89 | tok/s 16309
step    190 | loss 1.9052 | lr 3.00e-04 | grad 2.39 | tok/s 16012
step    200 | loss 1.6411 | lr 3.00e-04 | grad 1.90 | tok/s 16747
step    210 | loss 1.8798 | lr 3.00e-04 | grad 4.59 | tok/s 15867
step    220 | loss 2.1805 | lr 3.00e-04 | grad 3.77 | tok/s 16036
step    230 | loss 1.9494 | lr 3.00e-04 | grad 2.48 | tok/s 16021
step    240 | loss 2.2180 | lr 3.00e-04 | grad 5.34 | tok/s 16203
step    250 | loss 1.7524 | lr 3.00e-04 | grad 1.73 | tok/s 16098
step    260 | loss 1.8705 | lr 3.00e-04 | grad 2.88 | tok/s 16597
step    270 | loss 1.7999 | lr 3.00e-04 | grad 2.20 | tok/s 16190
step    280 | loss 1.7594 | lr 3.00e-04 | grad 1.73 | tok/s 15222
step    290 | loss 1.6498 | lr 3.00e-04 | grad 2.08 | tok/s 15774
step    300 | loss 1.9449 | lr 3.00e-04 | grad 2.03 | tok/s 15894
step    310 | loss 1.6478 | lr 3.00e-04 | grad 1.66 | tok/s 15799
step    320 | loss 1.8598 | lr 3.00e-04 | grad 3.22 | tok/s 16002
step    330 | loss 1.7027 | lr 3.00e-04 | grad 1.78 | tok/s 16170
step    340 | loss 2.0046 | lr 3.00e-04 | grad 1.94 | tok/s 16104
step    350 | loss 1.6981 | lr 3.00e-04 | grad 1.89 | tok/s 16593
step    360 | loss 1.5636 | lr 3.00e-04 | grad 1.75 | tok/s 15852
step    370 | loss 1.4667 | lr 3.00e-04 | grad 1.69 | tok/s 16733
step    380 | loss 1.2010 | lr 3.00e-04 | grad 1.65 | tok/s 16858
step    390 | loss 1.1078 | lr 3.00e-04 | grad 1.46 | tok/s 16848
step    400 | loss 1.7309 | lr 3.00e-04 | grad 1.66 | tok/s 16009
step    410 | loss 1.7256 | lr 3.00e-04 | grad 2.25 | tok/s 16114
step    420 | loss 1.6017 | lr 3.00e-04 | grad 3.48 | tok/s 16814
step    430 | loss 1.5907 | lr 3.00e-04 | grad 1.84 | tok/s 16533
step    440 | loss 1.6786 | lr 3.00e-04 | grad 2.23 | tok/s 16021
step    450 | loss 1.6148 | lr 3.00e-04 | grad 1.41 | tok/s 16199
step    460 | loss 1.5837 | lr 3.00e-04 | grad 1.94 | tok/s 16440
step    470 | loss 1.5496 | lr 3.00e-04 | grad 3.12 | tok/s 16314
step    480 | loss 1.5597 | lr 3.00e-04 | grad 2.66 | tok/s 16674
step    490 | loss 1.6813 | lr 3.00e-04 | grad 2.30 | tok/s 16007
step    500 | loss 1.7837 | lr 3.00e-04 | grad 1.61 | tok/s 15862
step    510 | loss 1.6555 | lr 3.00e-04 | grad 1.44 | tok/s 15551
step    520 | loss 1.5213 | lr 3.00e-04 | grad 1.92 | tok/s 16289
step    530 | loss 1.6919 | lr 3.00e-04 | grad 1.82 | tok/s 16007
step    540 | loss 1.5720 | lr 3.00e-04 | grad 1.50 | tok/s 15671
step    550 | loss 1.3571 | lr 3.00e-04 | grad 2.69 | tok/s 16378
step    560 | loss 1.4261 | lr 3.00e-04 | grad 1.72 | tok/s 16858
step    570 | loss 1.3343 | lr 3.00e-04 | grad 1.73 | tok/s 16865
step    580 | loss 1.2949 | lr 3.00e-04 | grad 1.30 | tok/s 16865
step    590 | loss 1.3241 | lr 3.00e-04 | grad 1.31 | tok/s 16867
step    600 | loss 1.2609 | lr 3.00e-04 | grad 1.59 | tok/s 16860
step    610 | loss 1.2972 | lr 3.00e-04 | grad 1.55 | tok/s 16865
step    620 | loss 1.2840 | lr 3.00e-04 | grad 1.77 | tok/s 16793
step    630 | loss 1.6414 | lr 3.00e-04 | grad 4.75 | tok/s 15848
step    640 | loss 1.7168 | lr 3.00e-04 | grad 1.72 | tok/s 16052
step    650 | loss 1.5344 | lr 3.00e-04 | grad 1.66 | tok/s 16060
step    660 | loss 1.5816 | lr 3.00e-04 | grad 1.72 | tok/s 16677
step    670 | loss 1.6076 | lr 3.00e-04 | grad 4.22 | tok/s 16121
step    680 | loss 1.6236 | lr 3.00e-04 | grad 2.03 | tok/s 15849
step    690 | loss 1.5653 | lr 3.00e-04 | grad 1.75 | tok/s 15732
step    700 | loss 1.4663 | lr 3.00e-04 | grad 1.33 | tok/s 16090
step    710 | loss 1.6166 | lr 3.00e-04 | grad 2.94 | tok/s 15825
step    720 | loss 1.2950 | lr 3.00e-04 | grad 1.66 | tok/s 16418
step    730 | loss 1.4570 | lr 3.00e-04 | grad 1.38 | tok/s 16153
step    740 | loss 1.7498 | lr 3.00e-04 | grad 3.70 | tok/s 16629
step    750 | loss 1.5126 | lr 3.00e-04 | grad 1.56 | tok/s 16797
step    760 | loss 1.5222 | lr 3.00e-04 | grad 3.39 | tok/s 16414
step    770 | loss 1.5588 | lr 3.00e-04 | grad 1.86 | tok/s 16161
step    780 | loss 1.4732 | lr 3.00e-04 | grad 1.77 | tok/s 16263
step    790 | loss 1.6018 | lr 3.00e-04 | grad 4.16 | tok/s 16646
step    800 | loss 1.3075 | lr 3.00e-04 | grad 1.23 | tok/s 16333
step    810 | loss 1.3041 | lr 3.00e-04 | grad 2.52 | tok/s 15817
step    820 | loss 1.4065 | lr 3.00e-04 | grad 1.79 | tok/s 16129
step    830 | loss 1.4771 | lr 3.00e-04 | grad 1.38 | tok/s 15903
step    840 | loss 1.6035 | lr 3.00e-04 | grad 1.70 | tok/s 15823
step    850 | loss 1.5255 | lr 3.00e-04 | grad 1.41 | tok/s 16174
step    860 | loss 1.5692 | lr 3.00e-04 | grad 2.36 | tok/s 16453
step    870 | loss 1.3868 | lr 3.00e-04 | grad 1.64 | tok/s 16585
step    880 | loss 1.5777 | lr 3.00e-04 | grad 1.63 | tok/s 16237
step    890 | loss 1.4744 | lr 3.00e-04 | grad 1.36 | tok/s 16157
step    900 | loss 1.5188 | lr 3.00e-04 | grad 1.48 | tok/s 16108
step    910 | loss 1.5075 | lr 3.00e-04 | grad 6.31 | tok/s 15928
step    920 | loss 1.4707 | lr 3.00e-04 | grad 1.66 | tok/s 16125
step    930 | loss 1.3751 | lr 3.00e-04 | grad 1.80 | tok/s 16326
step    940 | loss 1.3457 | lr 3.00e-04 | grad 1.67 | tok/s 15948
step    950 | loss 1.4796 | lr 3.00e-04 | grad 2.20 | tok/s 15681
step    960 | loss 1.4287 | lr 3.00e-04 | grad 1.37 | tok/s 16120
step    970 | loss 1.4657 | lr 3.00e-04 | grad 1.58 | tok/s 16125
step    980 | loss 1.8300 | lr 3.00e-04 | grad 3.03 | tok/s 16769
step    990 | loss 1.5520 | lr 3.00e-04 | grad 1.61 | tok/s 16076
step   1000 | loss 1.5559 | lr 3.00e-04 | grad 1.84 | tok/s 16098
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5559.pt
step   1010 | loss 1.3512 | lr 3.00e-04 | grad 1.79 | tok/s 9068
step   1020 | loss 1.1872 | lr 3.00e-04 | grad 1.39 | tok/s 17051
step   1030 | loss 1.5815 | lr 3.00e-04 | grad 1.77 | tok/s 16097
step   1040 | loss 2.1399 | lr 3.00e-04 | grad 2.55 | tok/s 16649
step   1050 | loss 1.4572 | lr 3.00e-04 | grad 1.70 | tok/s 16407
step   1060 | loss 1.1013 | lr 3.00e-04 | grad 1.20 | tok/s 16710
step   1070 | loss 1.4633 | lr 3.00e-04 | grad 1.51 | tok/s 16338
step   1080 | loss 1.2543 | lr 3.00e-04 | grad 1.69 | tok/s 16888
step   1090 | loss 1.2302 | lr 3.00e-04 | grad 1.46 | tok/s 16897
step   1100 | loss 1.1854 | lr 3.00e-04 | grad 1.45 | tok/s 16892
step   1110 | loss 1.1728 | lr 3.00e-04 | grad 1.48 | tok/s 16864
step   1120 | loss 1.4711 | lr 3.00e-04 | grad 3.09 | tok/s 16397
step   1130 | loss 1.6275 | lr 3.00e-04 | grad 2.67 | tok/s 16569
step   1140 | loss 1.6750 | lr 3.00e-04 | grad 1.37 | tok/s 16761
step   1150 | loss 1.5867 | lr 3.00e-04 | grad 1.92 | tok/s 15943
step   1160 | loss 1.7547 | lr 3.00e-04 | grad 6.53 | tok/s 16164
step   1170 | loss 1.4281 | lr 3.00e-04 | grad 1.67 | tok/s 15943
step   1180 | loss 1.3333 | lr 3.00e-04 | grad 1.94 | tok/s 16524
step   1190 | loss 1.5130 | lr 3.00e-04 | grad 4.03 | tok/s 16839
step   1200 | loss 1.1138 | lr 3.00e-04 | grad 2.59 | tok/s 16910
step   1210 | loss 1.4453 | lr 3.00e-04 | grad 2.17 | tok/s 15716
step   1220 | loss 1.3465 | lr 3.00e-04 | grad 1.45 | tok/s 16328
step   1230 | loss 1.3085 | lr 3.00e-04 | grad 1.19 | tok/s 16717
step   1240 | loss 1.3000 | lr 3.00e-04 | grad 1.38 | tok/s 16471
step   1250 | loss 1.4781 | lr 3.00e-04 | grad 4.78 | tok/s 16518
step   1260 | loss 1.3966 | lr 3.00e-04 | grad 1.84 | tok/s 16637
step   1270 | loss 1.3686 | lr 3.00e-04 | grad 1.42 | tok/s 16346
step   1280 | loss 1.4158 | lr 3.00e-04 | grad 1.68 | tok/s 16059
step   1290 | loss 1.3131 | lr 3.00e-04 | grad 1.61 | tok/s 16105
step   1300 | loss 1.5893 | lr 3.00e-04 | grad 3.88 | tok/s 15846
step   1310 | loss 1.4725 | lr 3.00e-04 | grad 1.58 | tok/s 16424
step   1320 | loss 1.4955 | lr 3.00e-04 | grad 2.88 | tok/s 16548
step   1330 | loss 1.3797 | lr 3.00e-04 | grad 1.72 | tok/s 16316
step   1340 | loss 1.5567 | lr 3.00e-04 | grad 1.70 | tok/s 16006
step   1350 | loss 1.4410 | lr 3.00e-04 | grad 3.73 | tok/s 16257
step   1360 | loss 1.3809 | lr 3.00e-04 | grad 1.56 | tok/s 15833
step   1370 | loss 1.6306 | lr 3.00e-04 | grad 2.62 | tok/s 16578
step   1380 | loss 1.3922 | lr 3.00e-04 | grad 2.27 | tok/s 15780
step   1390 | loss 1.3268 | lr 3.00e-04 | grad 2.09 | tok/s 16622
step   1400 | loss 1.4464 | lr 3.00e-04 | grad 1.36 | tok/s 16074
step   1410 | loss 1.4145 | lr 3.00e-04 | grad 4.66 | tok/s 15677
step   1420 | loss 1.1766 | lr 3.00e-04 | grad 7.28 | tok/s 16686
step   1430 | loss 1.5445 | lr 3.00e-04 | grad 1.82 | tok/s 16043
step   1440 | loss 1.4108 | lr 3.00e-04 | grad 1.88 | tok/s 16546
step   1450 | loss 1.4453 | lr 3.00e-04 | grad 1.87 | tok/s 16441
step   1460 | loss 1.5587 | lr 3.00e-04 | grad 3.34 | tok/s 16035
step   1470 | loss 1.3180 | lr 3.00e-04 | grad 1.54 | tok/s 15512
step   1480 | loss 1.3524 | lr 3.00e-04 | grad 2.23 | tok/s 16618
step   1490 | loss 1.8377 | lr 3.00e-04 | grad 3.89 | tok/s 16211
step   1500 | loss 1.4033 | lr 3.00e-04 | grad 1.64 | tok/s 16055
step   1510 | loss 1.2012 | lr 3.00e-04 | grad 1.27 | tok/s 16212
step   1520 | loss 1.4658 | lr 3.00e-04 | grad 1.70 | tok/s 16271
step   1530 | loss 1.3918 | lr 3.00e-04 | grad 2.42 | tok/s 16416
step   1540 | loss 1.5016 | lr 3.00e-04 | grad 1.55 | tok/s 16565
step   1550 | loss 1.4561 | lr 3.00e-04 | grad 2.80 | tok/s 16237
step   1560 | loss 1.1115 | lr 3.00e-04 | grad 1.41 | tok/s 16858
step   1570 | loss 1.2639 | lr 3.00e-04 | grad 1.28 | tok/s 16367
step   1580 | loss 1.3790 | lr 3.00e-04 | grad 5.91 | tok/s 16292
step   1590 | loss 1.3585 | lr 3.00e-04 | grad 1.54 | tok/s 16028
step   1600 | loss 1.2969 | lr 3.00e-04 | grad 2.06 | tok/s 16398
step   1610 | loss 1.9893 | lr 3.00e-04 | grad 2.64 | tok/s 16623
step   1620 | loss 1.8364 | lr 3.00e-04 | grad 1.88 | tok/s 16843
step   1630 | loss 1.5738 | lr 3.00e-04 | grad 2.16 | tok/s 16850
step   1640 | loss 1.4311 | lr 3.00e-04 | grad 2.33 | tok/s 16866
step   1650 | loss 1.3599 | lr 3.00e-04 | grad 2.23 | tok/s 16858
step   1660 | loss 1.3077 | lr 3.00e-04 | grad 1.91 | tok/s 16851
step   1670 | loss 1.4953 | lr 3.00e-04 | grad 1.91 | tok/s 16298
step   1680 | loss 1.3965 | lr 3.00e-04 | grad 1.39 | tok/s 15829
step   1690 | loss 1.4691 | lr 3.00e-04 | grad 1.30 | tok/s 15982
step   1700 | loss 1.2653 | lr 3.00e-04 | grad 1.27 | tok/s 16585
step   1710 | loss 1.2789 | lr 3.00e-04 | grad 1.61 | tok/s 16295
step   1720 | loss 1.4421 | lr 3.00e-04 | grad 1.77 | tok/s 16176
step   1730 | loss 1.4139 | lr 3.00e-04 | grad 1.65 | tok/s 16354
step   1740 | loss 1.3871 | lr 3.00e-04 | grad 1.30 | tok/s 16703
step   1750 | loss 1.2206 | lr 3.00e-04 | grad 1.64 | tok/s 16006
step   1760 | loss 1.4669 | lr 3.00e-04 | grad 2.45 | tok/s 16092
step   1770 | loss 1.5353 | lr 3.00e-04 | grad 2.31 | tok/s 16451
step   1780 | loss 1.7511 | lr 3.00e-04 | grad 2.53 | tok/s 15461
step   1790 | loss 1.2349 | lr 3.00e-04 | grad 3.00 | tok/s 15969
step   1800 | loss 1.3305 | lr 3.00e-04 | grad 1.86 | tok/s 15963
step   1810 | loss 1.3558 | lr 3.00e-04 | grad 1.84 | tok/s 16307
step   1820 | loss 1.5090 | lr 3.00e-04 | grad 1.70 | tok/s 15922
step   1830 | loss 1.3805 | lr 3.00e-04 | grad 1.49 | tok/s 15735
step   1840 | loss 1.2949 | lr 3.00e-04 | grad 1.38 | tok/s 16321
step   1850 | loss 1.4006 | lr 3.00e-04 | grad 3.03 | tok/s 15768
step   1860 | loss 1.4717 | lr 3.00e-04 | grad 2.86 | tok/s 16268
step   1870 | loss 1.3433 | lr 3.00e-04 | grad 1.31 | tok/s 16312
step   1880 | loss 1.4650 | lr 3.00e-04 | grad 1.39 | tok/s 16472
step   1890 | loss 1.2354 | lr 3.00e-04 | grad 1.51 | tok/s 16866
step   1900 | loss 1.1842 | lr 3.00e-04 | grad 1.38 | tok/s 16864
step   1910 | loss 1.1525 | lr 3.00e-04 | grad 1.41 | tok/s 16867
step   1920 | loss 1.1366 | lr 3.00e-04 | grad 1.52 | tok/s 16866
step   1930 | loss 1.2365 | lr 3.00e-04 | grad 1.82 | tok/s 16590
step   1940 | loss 1.5056 | lr 3.00e-04 | grad 1.66 | tok/s 15950
step   1950 | loss 1.4416 | lr 3.00e-04 | grad 2.27 | tok/s 15915
step   1960 | loss 1.4610 | lr 3.00e-04 | grad 3.97 | tok/s 16042
step   1970 | loss 1.4508 | lr 3.00e-04 | grad 1.53 | tok/s 16363
step   1980 | loss 1.3819 | lr 3.00e-04 | grad 1.97 | tok/s 16134
step   1990 | loss 1.4848 | lr 3.00e-04 | grad 1.97 | tok/s 16274
step   2000 | loss 1.0654 | lr 3.00e-04 | grad 1.70 | tok/s 16894
  >>> saved checkpoint: checkpoint_step_002000_loss_1.0654.pt
step   2010 | loss 1.3326 | lr 3.00e-04 | grad 1.95 | tok/s 8509
step   2020 | loss 1.3713 | lr 3.00e-04 | grad 1.95 | tok/s 16241
step   2030 | loss 1.9631 | lr 3.00e-04 | grad 1.68 | tok/s 15983
step   2040 | loss 1.3602 | lr 3.00e-04 | grad 1.19 | tok/s 16605
step   2050 | loss 1.3746 | lr 3.00e-04 | grad 1.89 | tok/s 16300
step   2060 | loss 1.6002 | lr 3.00e-04 | grad 1.64 | tok/s 16379
step   2070 | loss 1.0793 | lr 3.00e-04 | grad 1.63 | tok/s 15811
step   2080 | loss 1.1880 | lr 3.00e-04 | grad 1.16 | tok/s 16230
step   2090 | loss 1.6039 | lr 3.00e-04 | grad 3.47 | tok/s 16631
step   2100 | loss 1.4005 | lr 3.00e-04 | grad 2.03 | tok/s 16550
step   2110 | loss 1.5686 | lr 3.00e-04 | grad 6.59 | tok/s 16154
step   2120 | loss 1.9579 | lr 3.00e-04 | grad 1.91 | tok/s 16347
step   2130 | loss 1.4471 | lr 3.00e-04 | grad 2.09 | tok/s 16040
step   2140 | loss 1.4167 | lr 3.00e-04 | grad 2.70 | tok/s 15996
step   2150 | loss 1.6659 | lr 3.00e-04 | grad 1.94 | tok/s 16527
step   2160 | loss 1.4051 | lr 3.00e-04 | grad 1.65 | tok/s 16317
step   2170 | loss 1.4466 | lr 3.00e-04 | grad 1.84 | tok/s 16575
step   2180 | loss 1.1777 | lr 3.00e-04 | grad 3.95 | tok/s 16815
step   2190 | loss 1.3818 | lr 3.00e-04 | grad 2.06 | tok/s 16082
step   2200 | loss 1.1426 | lr 3.00e-04 | grad 2.00 | tok/s 16862
step   2210 | loss 1.4291 | lr 3.00e-04 | grad 1.70 | tok/s 16282
step   2220 | loss 1.4620 | lr 3.00e-04 | grad 1.38 | tok/s 15546
step   2230 | loss 1.5511 | lr 3.00e-04 | grad 1.15 | tok/s 16297
step   2240 | loss 1.3708 | lr 3.00e-04 | grad 1.50 | tok/s 16220
step   2250 | loss 1.3567 | lr 3.00e-04 | grad 1.68 | tok/s 16156
step   2260 | loss 1.5905 | lr 3.00e-04 | grad 1.88 | tok/s 16242
step   2270 | loss 1.5720 | lr 3.00e-04 | grad 1.73 | tok/s 15537
step   2280 | loss 1.3247 | lr 3.00e-04 | grad 2.06 | tok/s 16488
step   2290 | loss 1.3799 | lr 3.00e-04 | grad 4.44 | tok/s 15750
step   2300 | loss 1.5734 | lr 3.00e-04 | grad 1.48 | tok/s 15924
step   2310 | loss 1.3168 | lr 3.00e-04 | grad 1.58 | tok/s 16557
step   2320 | loss 1.3257 | lr 3.00e-04 | grad 1.38 | tok/s 16859
step   2330 | loss 1.2590 | lr 3.00e-04 | grad 1.51 | tok/s 16878
step   2340 | loss 1.2230 | lr 3.00e-04 | grad 1.34 | tok/s 16855
step   2350 | loss 1.2183 | lr 3.00e-04 | grad 1.46 | tok/s 16876
step   2360 | loss 1.1402 | lr 3.00e-04 | grad 1.31 | tok/s 16895
step   2370 | loss 1.1704 | lr 3.00e-04 | grad 1.21 | tok/s 16861
step   2380 | loss 1.1463 | lr 3.00e-04 | grad 1.27 | tok/s 16866
step   2390 | loss 1.1528 | lr 3.00e-04 | grad 1.30 | tok/s 16860
step   2400 | loss 1.1031 | lr 3.00e-04 | grad 1.16 | tok/s 16863
step   2410 | loss 1.4970 | lr 3.00e-04 | grad 2.16 | tok/s 16568
step   2420 | loss 0.9965 | lr 3.00e-04 | grad 1.11 | tok/s 16598
step   2430 | loss 1.3408 | lr 3.00e-04 | grad 1.46 | tok/s 15709
step   2440 | loss 1.3411 | lr 3.00e-04 | grad 1.20 | tok/s 15950
step   2450 | loss 1.3788 | lr 3.00e-04 | grad 1.80 | tok/s 16244
step   2460 | loss 1.4295 | lr 3.00e-04 | grad 1.15 | tok/s 16630
step   2470 | loss 1.3606 | lr 3.00e-04 | grad 1.60 | tok/s 15917
step   2480 | loss 1.3684 | lr 3.00e-04 | grad 1.58 | tok/s 16644
step   2490 | loss 1.5218 | lr 3.00e-04 | grad 2.27 | tok/s 16003
step   2500 | loss 1.4962 | lr 3.00e-04 | grad 1.42 | tok/s 16404
step   2510 | loss 1.3924 | lr 3.00e-04 | grad 1.77 | tok/s 16154
step   2520 | loss 1.3884 | lr 3.00e-04 | grad 2.70 | tok/s 16217
step   2530 | loss 1.4928 | lr 3.00e-04 | grad 2.25 | tok/s 16274
step   2540 | loss 1.4183 | lr 3.00e-04 | grad 1.95 | tok/s 15664
step   2550 | loss 1.3844 | lr 3.00e-04 | grad 1.81 | tok/s 16171
step   2560 | loss 1.4009 | lr 3.00e-04 | grad 2.22 | tok/s 15938
step   2570 | loss 1.4396 | lr 3.00e-04 | grad 4.31 | tok/s 16289
step   2580 | loss 1.4503 | lr 3.00e-04 | grad 1.64 | tok/s 15652
step   2590 | loss 1.3192 | lr 3.00e-04 | grad 2.03 | tok/s 15821
step   2600 | loss 1.4209 | lr 3.00e-04 | grad 1.95 | tok/s 16423
step   2610 | loss 1.2776 | lr 3.00e-04 | grad 1.68 | tok/s 16405
step   2620 | loss 1.4733 | lr 3.00e-04 | grad 1.60 | tok/s 15875
step   2630 | loss 1.0941 | lr 3.00e-04 | grad 1.26 | tok/s 16580
step   2640 | loss 1.3822 | lr 3.00e-04 | grad 1.26 | tok/s 15657
step   2650 | loss 1.1841 | lr 3.00e-04 | grad 1.49 | tok/s 16257
step   2660 | loss 1.3133 | lr 3.00e-04 | grad 1.48 | tok/s 16737
step   2670 | loss 1.0566 | lr 3.00e-04 | grad 1.68 | tok/s 16297
step   2680 | loss 1.3453 | lr 3.00e-04 | grad 1.60 | tok/s 15995
step   2690 | loss 1.3697 | lr 3.00e-04 | grad 2.33 | tok/s 15661
step   2700 | loss 1.3052 | lr 3.00e-04 | grad 1.40 | tok/s 16464
step   2710 | loss 1.6571 | lr 3.00e-04 | grad 1.38 | tok/s 15954
step   2720 | loss 1.2569 | lr 3.00e-04 | grad 1.28 | tok/s 16175
step   2730 | loss 1.3506 | lr 3.00e-04 | grad 2.66 | tok/s 16319
step   2740 | loss 1.3489 | lr 3.00e-04 | grad 2.31 | tok/s 15830
step   2750 | loss 1.3039 | lr 3.00e-04 | grad 1.56 | tok/s 16805
step   2760 | loss 1.2552 | lr 3.00e-04 | grad 1.58 | tok/s 16209
step   2770 | loss 1.2906 | lr 3.00e-04 | grad 2.06 | tok/s 16513
step   2780 | loss 1.2918 | lr 3.00e-04 | grad 1.80 | tok/s 16521
step   2790 | loss 1.5476 | lr 3.00e-04 | grad 9.50 | tok/s 15850
step   2800 | loss 1.2895 | lr 3.00e-04 | grad 2.30 | tok/s 15869
step   2810 | loss 1.3511 | lr 3.00e-04 | grad 1.45 | tok/s 15853
step   2820 | loss 1.3268 | lr 3.00e-04 | grad 1.26 | tok/s 15327
step   2830 | loss 1.2633 | lr 3.00e-04 | grad 1.53 | tok/s 16070
step   2840 | loss 1.1690 | lr 3.00e-04 | grad 1.43 | tok/s 16291
step   2850 | loss 1.1007 | lr 3.00e-04 | grad 1.20 | tok/s 16860
step   2860 | loss 1.2345 | lr 3.00e-04 | grad 1.37 | tok/s 16337
step   2870 | loss 1.3385 | lr 3.00e-04 | grad 2.06 | tok/s 15766
step   2880 | loss 1.4691 | lr 3.00e-04 | grad 3.77 | tok/s 15896
step   2890 | loss 1.5038 | lr 3.00e-04 | grad 1.45 | tok/s 16504
step   2900 | loss 1.3341 | lr 3.00e-04 | grad 1.88 | tok/s 15810
step   2910 | loss 1.2728 | lr 3.00e-04 | grad 1.38 | tok/s 16312
step   2920 | loss 1.2113 | lr 3.00e-04 | grad 6.22 | tok/s 16289
step   2930 | loss 1.3480 | lr 3.00e-04 | grad 1.33 | tok/s 16489
step   2940 | loss 1.3261 | lr 3.00e-04 | grad 2.69 | tok/s 15923
step   2950 | loss 1.5251 | lr 3.00e-04 | grad 1.53 | tok/s 16129
step   2960 | loss 1.6438 | lr 3.00e-04 | grad 6.44 | tok/s 15859
step   2970 | loss 1.3183 | lr 3.00e-04 | grad 1.50 | tok/s 16478
step   2980 | loss 1.2875 | lr 3.00e-04 | grad 1.93 | tok/s 16600
step   2990 | loss 1.4481 | lr 3.00e-04 | grad 1.59 | tok/s 16352
step   3000 | loss 1.3089 | lr 3.00e-04 | grad 1.58 | tok/s 16448
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3089.pt
step   3010 | loss 1.3350 | lr 3.00e-04 | grad 1.78 | tok/s 9368
step   3020 | loss 1.2890 | lr 3.00e-04 | grad 1.77 | tok/s 16191
step   3030 | loss 1.2026 | lr 3.00e-04 | grad 1.55 | tok/s 16300
step   3040 | loss 1.2967 | lr 3.00e-04 | grad 1.67 | tok/s 16447
step   3050 | loss 1.1172 | lr 3.00e-04 | grad 2.91 | tok/s 16976
step   3060 | loss 1.5337 | lr 3.00e-04 | grad 1.74 | tok/s 16020
step   3070 | loss 1.9867 | lr 3.00e-04 | grad 2.03 | tok/s 16740
step   3080 | loss 1.4019 | lr 3.00e-04 | grad 1.61 | tok/s 16309
step   3090 | loss 1.3193 | lr 3.00e-04 | grad 1.52 | tok/s 15683
step   3100 | loss 1.2257 | lr 3.00e-04 | grad 1.76 | tok/s 16795
step   3110 | loss 1.3337 | lr 3.00e-04 | grad 2.11 | tok/s 16409
step   3120 | loss 1.2979 | lr 3.00e-04 | grad 1.61 | tok/s 16318
step   3130 | loss 1.3355 | lr 3.00e-04 | grad 1.81 | tok/s 15633
step   3140 | loss 1.2671 | lr 3.00e-04 | grad 2.19 | tok/s 16193
step   3150 | loss 1.4357 | lr 3.00e-04 | grad 2.86 | tok/s 15804
step   3160 | loss 1.3068 | lr 3.00e-04 | grad 1.22 | tok/s 16733
step   3170 | loss 1.1139 | lr 3.00e-04 | grad 3.25 | tok/s 16734
step   3180 | loss 1.4607 | lr 3.00e-04 | grad 1.88 | tok/s 16536
step   3190 | loss 1.3444 | lr 3.00e-04 | grad 1.19 | tok/s 16336
step   3200 | loss 1.3290 | lr 3.00e-04 | grad 1.46 | tok/s 16130
step   3210 | loss 1.3293 | lr 3.00e-04 | grad 1.20 | tok/s 16588
step   3220 | loss 1.2794 | lr 3.00e-04 | grad 1.38 | tok/s 16352
step   3230 | loss 1.3025 | lr 3.00e-04 | grad 1.66 | tok/s 15836
step   3240 | loss 1.3189 | lr 3.00e-04 | grad 1.50 | tok/s 15733
step   3250 | loss 1.3169 | lr 3.00e-04 | grad 1.52 | tok/s 16077
step   3260 | loss 1.2882 | lr 3.00e-04 | grad 1.55 | tok/s 16096
step   3270 | loss 1.3628 | lr 3.00e-04 | grad 1.73 | tok/s 16112
step   3280 | loss 1.2923 | lr 3.00e-04 | grad 1.18 | tok/s 16401
step   3290 | loss 1.3061 | lr 3.00e-04 | grad 2.83 | tok/s 16236
step   3300 | loss 1.3787 | lr 3.00e-04 | grad 1.66 | tok/s 16778
step   3310 | loss 1.8116 | lr 3.00e-04 | grad 1.89 | tok/s 16478
step   3320 | loss 1.3122 | lr 3.00e-04 | grad 2.02 | tok/s 15700
step   3330 | loss 1.2607 | lr 3.00e-04 | grad 1.26 | tok/s 16386
step   3340 | loss 1.1616 | lr 3.00e-04 | grad 1.74 | tok/s 16152
step   3350 | loss 1.2976 | lr 3.00e-04 | grad 2.33 | tok/s 16944
step   3360 | loss 1.3449 | lr 3.00e-04 | grad 1.45 | tok/s 15855
step   3370 | loss 1.4495 | lr 3.00e-04 | grad 1.41 | tok/s 16122
step   3380 | loss 1.3148 | lr 3.00e-04 | grad 2.66 | tok/s 16035
step   3390 | loss 1.2608 | lr 3.00e-04 | grad 2.58 | tok/s 16260
step   3400 | loss 1.3609 | lr 3.00e-04 | grad 3.59 | tok/s 16131
step   3410 | loss 1.4431 | lr 3.00e-04 | grad 2.05 | tok/s 16177
step   3420 | loss 1.3114 | lr 3.00e-04 | grad 1.41 | tok/s 16494
step   3430 | loss 1.4037 | lr 3.00e-04 | grad 4.88 | tok/s 16458
step   3440 | loss 1.2801 | lr 3.00e-04 | grad 1.53 | tok/s 15846
step   3450 | loss 1.3522 | lr 3.00e-04 | grad 1.55 | tok/s 16237
step   3460 | loss 1.4227 | lr 3.00e-04 | grad 4.66 | tok/s 16149
step   3470 | loss 1.4183 | lr 3.00e-04 | grad 1.31 | tok/s 15842
step   3480 | loss 1.3071 | lr 3.00e-04 | grad 1.65 | tok/s 16559
step   3490 | loss 1.4876 | lr 3.00e-04 | grad 1.44 | tok/s 15974
step   3500 | loss 1.3645 | lr 3.00e-04 | grad 1.47 | tok/s 15633
step   3510 | loss 1.3309 | lr 3.00e-04 | grad 1.94 | tok/s 16164
step   3520 | loss 1.3705 | lr 3.00e-04 | grad 2.55 | tok/s 16639
step   3530 | loss 1.4068 | lr 3.00e-04 | grad 1.55 | tok/s 15788
step   3540 | loss 1.2885 | lr 3.00e-04 | grad 1.49 | tok/s 16153
step   3550 | loss 1.2821 | lr 3.00e-04 | grad 1.24 | tok/s 16595
step   3560 | loss 1.4514 | lr 3.00e-04 | grad 2.27 | tok/s 16348
step   3570 | loss 1.1709 | lr 3.00e-04 | grad 1.54 | tok/s 16494
step   3580 | loss 1.2346 | lr 3.00e-04 | grad 1.44 | tok/s 16217
step   3590 | loss 1.2820 | lr 3.00e-04 | grad 1.29 | tok/s 15977
step   3600 | loss 1.2887 | lr 3.00e-04 | grad 2.08 | tok/s 16108
step   3610 | loss 1.3896 | lr 3.00e-04 | grad 1.18 | tok/s 16111
step   3620 | loss 1.2780 | lr 3.00e-04 | grad 1.35 | tok/s 16087
step   3630 | loss 1.3128 | lr 3.00e-04 | grad 1.35 | tok/s 16219
step   3640 | loss 1.5659 | lr 3.00e-04 | grad 1.82 | tok/s 15868

Training complete! Final step: 3648
