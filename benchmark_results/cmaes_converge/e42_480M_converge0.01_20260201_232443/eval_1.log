Using device: cuda
Output directory: benchmark_results/cmaes_converge/e42_480M_converge0.01_20260201_232443/eval_1/level42_100m_20260201_232449
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 468,887,936 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 7.5894 | lr 3.00e-04 | grad 49.75 | tok/s 8060
step     20 | loss 2.9638 | lr 3.00e-04 | grad 7.41 | tok/s 13325
step     30 | loss 3.6710 | lr 3.00e-04 | grad 6.56 | tok/s 14091
step     40 | loss 4.6920 | lr 3.00e-04 | grad 14.69 | tok/s 14352
step     50 | loss 4.1172 | lr 3.00e-04 | grad 11.06 | tok/s 14506
step     60 | loss 3.7138 | lr 3.00e-04 | grad 8.31 | tok/s 14458
step     70 | loss 3.3537 | lr 3.00e-04 | grad 7.81 | tok/s 14413
step     80 | loss 3.0109 | lr 3.00e-04 | grad 7.03 | tok/s 14374
step     90 | loss 2.7964 | lr 3.00e-04 | grad 3.64 | tok/s 14326
step    100 | loss 2.6301 | lr 3.00e-04 | grad 4.84 | tok/s 14308
step    110 | loss 2.6988 | lr 3.00e-04 | grad 8.38 | tok/s 14176
step    120 | loss 3.3285 | lr 3.00e-04 | grad 3.27 | tok/s 13456
step    130 | loss 2.6010 | lr 3.00e-04 | grad 7.47 | tok/s 13770
step    140 | loss 2.7896 | lr 3.00e-04 | grad 7.09 | tok/s 13771
step    150 | loss 2.4547 | lr 3.00e-04 | grad 7.62 | tok/s 14111
step    160 | loss 2.7575 | lr 3.00e-04 | grad 2.81 | tok/s 13613
step    170 | loss 2.6376 | lr 3.00e-04 | grad 3.00 | tok/s 13378
step    180 | loss 2.7468 | lr 3.00e-04 | grad 5.00 | tok/s 13692
step    190 | loss 2.3485 | lr 3.00e-04 | grad 2.81 | tok/s 13431
step    200 | loss 2.2429 | lr 3.00e-04 | grad 2.72 | tok/s 14016
step    210 | loss 2.3018 | lr 3.00e-04 | grad 4.03 | tok/s 13282
step    220 | loss 2.5867 | lr 3.00e-04 | grad 3.48 | tok/s 13406
step    230 | loss 2.4063 | lr 3.00e-04 | grad 2.73 | tok/s 13385
step    240 | loss 2.6895 | lr 3.00e-04 | grad 4.16 | tok/s 13555
step    250 | loss 2.2163 | lr 3.00e-04 | grad 2.36 | tok/s 13456
step    260 | loss 2.3449 | lr 3.00e-04 | grad 2.91 | tok/s 13824
step    270 | loss 2.2228 | lr 3.00e-04 | grad 3.44 | tok/s 13502
step    280 | loss 2.1646 | lr 3.00e-04 | grad 1.79 | tok/s 12693
step    290 | loss 2.0973 | lr 3.00e-04 | grad 2.23 | tok/s 13086
step    300 | loss 2.3634 | lr 3.00e-04 | grad 3.00 | tok/s 13190
step    310 | loss 2.0474 | lr 3.00e-04 | grad 1.96 | tok/s 13118
step    320 | loss 2.3119 | lr 3.00e-04 | grad 4.34 | tok/s 13270
step    330 | loss 2.1069 | lr 3.00e-04 | grad 2.23 | tok/s 13402
step    340 | loss 2.4541 | lr 3.00e-04 | grad 2.88 | tok/s 13359
step    350 | loss 2.3319 | lr 3.00e-04 | grad 2.70 | tok/s 13741
step    360 | loss 2.0107 | lr 3.00e-04 | grad 2.11 | tok/s 13147
step    370 | loss 2.0314 | lr 3.00e-04 | grad 1.85 | tok/s 13851
step    380 | loss 1.8209 | lr 3.00e-04 | grad 2.50 | tok/s 13962
step    390 | loss 1.7390 | lr 3.00e-04 | grad 2.48 | tok/s 13953
step    400 | loss 2.2262 | lr 3.00e-04 | grad 1.65 | tok/s 13228
step    410 | loss 2.1294 | lr 3.00e-04 | grad 1.97 | tok/s 13347
step    420 | loss 2.1986 | lr 3.00e-04 | grad 2.52 | tok/s 13923
step    430 | loss 2.0468 | lr 3.00e-04 | grad 2.78 | tok/s 13680
step    440 | loss 2.1253 | lr 3.00e-04 | grad 2.78 | tok/s 13256
step    450 | loss 1.9978 | lr 3.00e-04 | grad 1.61 | tok/s 13412
step    460 | loss 2.0422 | lr 3.00e-04 | grad 1.88 | tok/s 13604
step    470 | loss 2.0485 | lr 3.00e-04 | grad 3.27 | tok/s 13515
step    480 | loss 2.1128 | lr 3.00e-04 | grad 3.41 | tok/s 13810
step    490 | loss 2.0664 | lr 3.00e-04 | grad 2.56 | tok/s 13242
step    500 | loss 2.2356 | lr 3.00e-04 | grad 2.45 | tok/s 13467
step    510 | loss 2.0574 | lr 3.00e-04 | grad 2.86 | tok/s 12868
step    520 | loss 1.9225 | lr 3.00e-04 | grad 1.99 | tok/s 13478
step    530 | loss 2.0821 | lr 3.00e-04 | grad 1.94 | tok/s 13244
step    540 | loss 2.0136 | lr 3.00e-04 | grad 1.50 | tok/s 12974
step    550 | loss 1.7060 | lr 3.00e-04 | grad 3.45 | tok/s 13564
step    560 | loss 1.8641 | lr 3.00e-04 | grad 1.80 | tok/s 13957
step    570 | loss 1.7555 | lr 3.00e-04 | grad 2.31 | tok/s 13957
step    580 | loss 1.6842 | lr 3.00e-04 | grad 1.45 | tok/s 13955
step    590 | loss 1.7403 | lr 3.00e-04 | grad 2.42 | tok/s 13958
step    600 | loss 1.6837 | lr 3.00e-04 | grad 2.33 | tok/s 13951
step    610 | loss 1.6702 | lr 3.00e-04 | grad 1.96 | tok/s 13943
step    620 | loss 1.6541 | lr 3.00e-04 | grad 2.48 | tok/s 13889
step    630 | loss 2.0809 | lr 3.00e-04 | grad 6.00 | tok/s 13133
step    640 | loss 2.0646 | lr 3.00e-04 | grad 2.14 | tok/s 13304
step    650 | loss 1.8975 | lr 3.00e-04 | grad 1.88 | tok/s 13309
step    660 | loss 1.9606 | lr 3.00e-04 | grad 2.20 | tok/s 13808
step    670 | loss 2.0104 | lr 3.00e-04 | grad 4.41 | tok/s 13337
step    680 | loss 1.9962 | lr 3.00e-04 | grad 2.14 | tok/s 13131
step    690 | loss 1.9490 | lr 3.00e-04 | grad 2.12 | tok/s 13025
step    700 | loss 1.8450 | lr 3.00e-04 | grad 1.49 | tok/s 13313
step    710 | loss 2.0237 | lr 3.00e-04 | grad 3.52 | tok/s 13099
step    720 | loss 1.7209 | lr 3.00e-04 | grad 2.14 | tok/s 13614
step    730 | loss 1.8267 | lr 3.00e-04 | grad 1.31 | tok/s 13395
step    740 | loss 2.2848 | lr 3.00e-04 | grad 3.69 | tok/s 13758
step    750 | loss 2.0297 | lr 3.00e-04 | grad 2.66 | tok/s 13918
step    760 | loss 1.8843 | lr 3.00e-04 | grad 3.09 | tok/s 13635
step    770 | loss 1.8891 | lr 3.00e-04 | grad 2.47 | tok/s 13400
step    780 | loss 1.8202 | lr 3.00e-04 | grad 2.53 | tok/s 13487
step    790 | loss 2.1407 | lr 3.00e-04 | grad 3.27 | tok/s 13783
step    800 | loss 1.6955 | lr 3.00e-04 | grad 1.26 | tok/s 13560
step    810 | loss 1.6491 | lr 3.00e-04 | grad 2.83 | tok/s 13090
step    820 | loss 1.7937 | lr 3.00e-04 | grad 2.42 | tok/s 13350
step    830 | loss 1.8490 | lr 3.00e-04 | grad 2.14 | tok/s 13172
step    840 | loss 2.0021 | lr 3.00e-04 | grad 1.96 | tok/s 13106
step    850 | loss 1.9175 | lr 3.00e-04 | grad 2.58 | tok/s 13393
step    860 | loss 1.9924 | lr 3.00e-04 | grad 2.11 | tok/s 13611
step    870 | loss 1.9160 | lr 3.00e-04 | grad 2.25 | tok/s 13716
step    880 | loss 1.8856 | lr 3.00e-04 | grad 1.96 | tok/s 13454
step    890 | loss 1.7696 | lr 3.00e-04 | grad 1.69 | tok/s 13394
step    900 | loss 1.8285 | lr 3.00e-04 | grad 1.62 | tok/s 13323
step    910 | loss 1.8714 | lr 3.00e-04 | grad 5.09 | tok/s 13192
step    920 | loss 1.7868 | lr 3.00e-04 | grad 2.36 | tok/s 13338
step    930 | loss 1.7195 | lr 3.00e-04 | grad 2.28 | tok/s 13525
step    940 | loss 1.6953 | lr 3.00e-04 | grad 2.16 | tok/s 13213
step    950 | loss 1.8027 | lr 3.00e-04 | grad 2.95 | tok/s 12989
step    960 | loss 1.7387 | lr 3.00e-04 | grad 2.05 | tok/s 13353
step    970 | loss 1.7213 | lr 3.00e-04 | grad 1.84 | tok/s 13339
step    980 | loss 2.3470 | lr 3.00e-04 | grad 3.52 | tok/s 13874
step    990 | loss 1.9414 | lr 3.00e-04 | grad 2.62 | tok/s 13312
step   1000 | loss 1.8675 | lr 3.00e-04 | grad 2.80 | tok/s 13359
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8675.pt
step   1010 | loss 1.6725 | lr 3.00e-04 | grad 1.53 | tok/s 8440
step   1020 | loss 1.5833 | lr 3.00e-04 | grad 3.00 | tok/s 14055
step   1030 | loss 1.9065 | lr 3.00e-04 | grad 2.06 | tok/s 13254
step   1040 | loss 2.3606 | lr 3.00e-04 | grad 6.69 | tok/s 13697
step   1050 | loss 1.8587 | lr 3.00e-04 | grad 1.83 | tok/s 13518
step   1060 | loss 1.3713 | lr 3.00e-04 | grad 1.50 | tok/s 13771
step   1070 | loss 1.7633 | lr 3.00e-04 | grad 2.89 | tok/s 13512
step   1080 | loss 1.5254 | lr 3.00e-04 | grad 2.31 | tok/s 13959
step   1090 | loss 1.4971 | lr 3.00e-04 | grad 2.12 | tok/s 13989
step   1100 | loss 1.4532 | lr 3.00e-04 | grad 2.20 | tok/s 13980
step   1110 | loss 1.4349 | lr 3.00e-04 | grad 2.55 | tok/s 13978
step   1120 | loss 1.8177 | lr 3.00e-04 | grad 4.19 | tok/s 13598
step   1130 | loss 1.9922 | lr 3.00e-04 | grad 3.12 | tok/s 13743
step   1140 | loss 2.0473 | lr 3.00e-04 | grad 2.27 | tok/s 13901
step   1150 | loss 2.2056 | lr 3.00e-04 | grad 2.30 | tok/s 13192
step   1160 | loss 2.0765 | lr 3.00e-04 | grad 6.09 | tok/s 13394
step   1170 | loss 1.7226 | lr 3.00e-04 | grad 2.34 | tok/s 13185
step   1180 | loss 1.6799 | lr 3.00e-04 | grad 2.91 | tok/s 13679
step   1190 | loss 1.9487 | lr 3.00e-04 | grad 2.83 | tok/s 13958
step   1200 | loss 1.4483 | lr 3.00e-04 | grad 2.95 | tok/s 13983
step   1210 | loss 1.7021 | lr 3.00e-04 | grad 2.17 | tok/s 13017
step   1220 | loss 1.6495 | lr 3.00e-04 | grad 2.50 | tok/s 13520
step   1230 | loss 1.6141 | lr 3.00e-04 | grad 1.88 | tok/s 13871
step   1240 | loss 1.5758 | lr 3.00e-04 | grad 1.86 | tok/s 13645
step   1250 | loss 1.8242 | lr 3.00e-04 | grad 2.12 | tok/s 13667
step   1260 | loss 1.7180 | lr 3.00e-04 | grad 1.62 | tok/s 13781
step   1270 | loss 1.6604 | lr 3.00e-04 | grad 2.19 | tok/s 13527
step   1280 | loss 1.7317 | lr 3.00e-04 | grad 2.80 | tok/s 13299
step   1290 | loss 1.6476 | lr 3.00e-04 | grad 1.98 | tok/s 13360
step   1300 | loss 1.9905 | lr 3.00e-04 | grad 3.11 | tok/s 13102
step   1310 | loss 1.7778 | lr 3.00e-04 | grad 1.74 | tok/s 13601
step   1320 | loss 1.8214 | lr 3.00e-04 | grad 3.48 | tok/s 13708
step   1330 | loss 1.6873 | lr 3.00e-04 | grad 2.36 | tok/s 13509
step   1340 | loss 1.9228 | lr 3.00e-04 | grad 2.91 | tok/s 13260
step   1350 | loss 1.7532 | lr 3.00e-04 | grad 3.42 | tok/s 13458
step   1360 | loss 1.7382 | lr 3.00e-04 | grad 2.20 | tok/s 13126
step   1370 | loss 1.9278 | lr 3.00e-04 | grad 2.94 | tok/s 13731
step   1380 | loss 1.6799 | lr 3.00e-04 | grad 2.73 | tok/s 13066
step   1390 | loss 1.6486 | lr 3.00e-04 | grad 2.52 | tok/s 13770
step   1400 | loss 1.8449 | lr 3.00e-04 | grad 1.76 | tok/s 13335
step   1410 | loss 1.7175 | lr 3.00e-04 | grad 2.89 | tok/s 12998
step   1420 | loss 1.6723 | lr 3.00e-04 | grad 5.97 | tok/s 13818
step   1430 | loss 1.8917 | lr 3.00e-04 | grad 2.30 | tok/s 13285
step   1440 | loss 1.7532 | lr 3.00e-04 | grad 2.03 | tok/s 13707
step   1450 | loss 1.7960 | lr 3.00e-04 | grad 2.31 | tok/s 13623
step   1460 | loss 1.8408 | lr 3.00e-04 | grad 3.58 | tok/s 13284
step   1470 | loss 1.5537 | lr 3.00e-04 | grad 2.59 | tok/s 12851
step   1480 | loss 1.6495 | lr 3.00e-04 | grad 2.72 | tok/s 13747
step   1490 | loss 2.1561 | lr 3.00e-04 | grad 4.59 | tok/s 13406
step   1500 | loss 1.6738 | lr 3.00e-04 | grad 2.11 | tok/s 13451
step   1510 | loss 1.5466 | lr 3.00e-04 | grad 1.77 | tok/s 13425
step   1520 | loss 1.7241 | lr 3.00e-04 | grad 2.39 | tok/s 13472
step   1530 | loss 1.6571 | lr 3.00e-04 | grad 3.17 | tok/s 13598
step   1540 | loss 1.7566 | lr 3.00e-04 | grad 2.02 | tok/s 13716
step   1550 | loss 1.7267 | lr 3.00e-04 | grad 2.48 | tok/s 13445
step   1560 | loss 1.3876 | lr 3.00e-04 | grad 1.88 | tok/s 13956
step   1570 | loss 1.5508 | lr 3.00e-04 | grad 2.12 | tok/s 13578
step   1580 | loss 1.6986 | lr 3.00e-04 | grad 8.12 | tok/s 13514
step   1590 | loss 1.5877 | lr 3.00e-04 | grad 2.08 | tok/s 13285
step   1600 | loss 1.5675 | lr 3.00e-04 | grad 2.22 | tok/s 13594
step   1610 | loss 2.3028 | lr 3.00e-04 | grad 4.69 | tok/s 13746
step   1620 | loss 2.1839 | lr 3.00e-04 | grad 3.03 | tok/s 13928
step   1630 | loss 1.9599 | lr 3.00e-04 | grad 2.72 | tok/s 13963
step   1640 | loss 1.8103 | lr 3.00e-04 | grad 3.08 | tok/s 13969
step   1650 | loss 1.7399 | lr 3.00e-04 | grad 3.55 | tok/s 13975
step   1660 | loss 1.6857 | lr 3.00e-04 | grad 3.20 | tok/s 13963
step   1670 | loss 1.8287 | lr 3.00e-04 | grad 3.36 | tok/s 13520
step   1680 | loss 1.6340 | lr 3.00e-04 | grad 1.77 | tok/s 13144
step   1690 | loss 1.7082 | lr 3.00e-04 | grad 1.77 | tok/s 13248
step   1700 | loss 1.5018 | lr 3.00e-04 | grad 2.59 | tok/s 13739
step   1710 | loss 1.5658 | lr 3.00e-04 | grad 2.08 | tok/s 13492
step   1720 | loss 1.6776 | lr 3.00e-04 | grad 2.30 | tok/s 13415
step   1730 | loss 1.7203 | lr 3.00e-04 | grad 2.03 | tok/s 13552
step   1740 | loss 1.6377 | lr 3.00e-04 | grad 2.36 | tok/s 13840
step   1750 | loss 1.4788 | lr 3.00e-04 | grad 2.22 | tok/s 13267
step   1760 | loss 1.7184 | lr 3.00e-04 | grad 3.27 | tok/s 13320
step   1770 | loss 1.8750 | lr 3.00e-04 | grad 2.66 | tok/s 13628
step   1780 | loss 1.9970 | lr 3.00e-04 | grad 2.64 | tok/s 12814
step   1790 | loss 1.5342 | lr 3.00e-04 | grad 4.25 | tok/s 13239
step   1800 | loss 1.6152 | lr 3.00e-04 | grad 1.77 | tok/s 13235
step   1810 | loss 1.5873 | lr 3.00e-04 | grad 2.00 | tok/s 13514
step   1820 | loss 1.7643 | lr 3.00e-04 | grad 2.34 | tok/s 13196
step   1830 | loss 1.6031 | lr 3.00e-04 | grad 2.30 | tok/s 13051
step   1840 | loss 1.6341 | lr 3.00e-04 | grad 2.00 | tok/s 13533
step   1850 | loss 1.6605 | lr 3.00e-04 | grad 3.31 | tok/s 13070
step   1860 | loss 1.7103 | lr 3.00e-04 | grad 2.94 | tok/s 13483
step   1870 | loss 1.5921 | lr 3.00e-04 | grad 1.39 | tok/s 13532
step   1880 | loss 1.7498 | lr 3.00e-04 | grad 2.58 | tok/s 13665
step   1890 | loss 1.4578 | lr 3.00e-04 | grad 2.08 | tok/s 13967
step   1900 | loss 1.4007 | lr 3.00e-04 | grad 2.69 | tok/s 13963
step   1910 | loss 1.3758 | lr 3.00e-04 | grad 2.08 | tok/s 13958
step   1920 | loss 1.3555 | lr 3.00e-04 | grad 2.05 | tok/s 13821
step   1930 | loss 1.4693 | lr 3.00e-04 | grad 2.72 | tok/s 13746
step   1940 | loss 1.7638 | lr 3.00e-04 | grad 2.22 | tok/s 13229
step   1950 | loss 1.7426 | lr 3.00e-04 | grad 2.14 | tok/s 13185
step   1960 | loss 1.7642 | lr 3.00e-04 | grad 3.62 | tok/s 13292
step   1970 | loss 1.7206 | lr 3.00e-04 | grad 1.84 | tok/s 13528
step   1980 | loss 1.6971 | lr 3.00e-04 | grad 2.14 | tok/s 13349
step   1990 | loss 1.8253 | lr 3.00e-04 | grad 2.75 | tok/s 13496
step   2000 | loss 1.3629 | lr 3.00e-04 | grad 2.27 | tok/s 14011
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3629.pt
step   2010 | loss 1.6039 | lr 3.00e-04 | grad 1.97 | tok/s 8134
step   2020 | loss 1.6070 | lr 3.00e-04 | grad 2.17 | tok/s 13336
step   2030 | loss 2.0040 | lr 3.00e-04 | grad 1.95 | tok/s 13137
step   2040 | loss 1.5778 | lr 3.00e-04 | grad 1.68 | tok/s 13657
step   2050 | loss 1.6193 | lr 3.00e-04 | grad 1.91 | tok/s 13409
step   2060 | loss 1.8568 | lr 3.00e-04 | grad 2.14 | tok/s 13449
step   2070 | loss 1.3148 | lr 3.00e-04 | grad 2.84 | tok/s 13290
step   2080 | loss 1.4254 | lr 3.00e-04 | grad 2.09 | tok/s 13375
step   2090 | loss 1.9494 | lr 3.00e-04 | grad 3.25 | tok/s 13697
step   2100 | loss 1.7829 | lr 3.00e-04 | grad 3.66 | tok/s 12629
step   2110 | loss 1.8344 | lr 3.00e-04 | grad 6.81 | tok/s 13333
step   2120 | loss 2.3041 | lr 3.00e-04 | grad 2.67 | tok/s 13518
step   2130 | loss 1.6816 | lr 3.00e-04 | grad 1.87 | tok/s 13252
step   2140 | loss 1.7417 | lr 3.00e-04 | grad 2.66 | tok/s 13247
step   2150 | loss 1.9586 | lr 3.00e-04 | grad 2.89 | tok/s 13678
step   2160 | loss 1.6700 | lr 3.00e-04 | grad 2.25 | tok/s 13501
step   2170 | loss 1.7091 | lr 3.00e-04 | grad 1.68 | tok/s 13699
step   2180 | loss 1.5024 | lr 3.00e-04 | grad 4.69 | tok/s 13922
step   2190 | loss 1.6459 | lr 3.00e-04 | grad 1.85 | tok/s 13334
step   2200 | loss 1.4376 | lr 3.00e-04 | grad 1.99 | tok/s 13976
step   2210 | loss 1.6960 | lr 3.00e-04 | grad 2.39 | tok/s 13501
step   2220 | loss 1.6862 | lr 3.00e-04 | grad 2.08 | tok/s 12891
step   2230 | loss 1.7867 | lr 3.00e-04 | grad 2.33 | tok/s 13506
step   2240 | loss 1.5685 | lr 3.00e-04 | grad 1.92 | tok/s 13434
step   2250 | loss 1.5716 | lr 3.00e-04 | grad 2.14 | tok/s 13396
step   2260 | loss 1.8861 | lr 3.00e-04 | grad 1.95 | tok/s 13456
step   2270 | loss 1.8228 | lr 3.00e-04 | grad 1.84 | tok/s 12865
step   2280 | loss 1.5391 | lr 3.00e-04 | grad 2.19 | tok/s 13666
step   2290 | loss 1.7523 | lr 3.00e-04 | grad 12.62 | tok/s 13067
step   2300 | loss 1.8268 | lr 3.00e-04 | grad 2.86 | tok/s 13208
step   2310 | loss 1.5111 | lr 3.00e-04 | grad 2.22 | tok/s 13743
step   2320 | loss 1.5439 | lr 3.00e-04 | grad 2.50 | tok/s 13980
step   2330 | loss 1.4994 | lr 3.00e-04 | grad 2.55 | tok/s 13972
step   2340 | loss 1.4523 | lr 3.00e-04 | grad 2.41 | tok/s 13968
step   2350 | loss 1.4431 | lr 3.00e-04 | grad 2.19 | tok/s 13990
step   2360 | loss 1.3854 | lr 3.00e-04 | grad 2.80 | tok/s 13985
step   2370 | loss 1.3792 | lr 3.00e-04 | grad 2.62 | tok/s 13971
step   2380 | loss 1.3594 | lr 3.00e-04 | grad 1.92 | tok/s 13990
step   2390 | loss 1.3803 | lr 3.00e-04 | grad 2.45 | tok/s 13982
step   2400 | loss 1.3302 | lr 3.00e-04 | grad 2.05 | tok/s 13985
step   2410 | loss 1.7486 | lr 3.00e-04 | grad 3.64 | tok/s 13747
step   2420 | loss 1.1684 | lr 3.00e-04 | grad 1.12 | tok/s 13773
step   2430 | loss 1.5580 | lr 3.00e-04 | grad 1.69 | tok/s 13032
step   2440 | loss 1.5535 | lr 3.00e-04 | grad 1.48 | tok/s 13229
step   2450 | loss 1.5742 | lr 3.00e-04 | grad 2.42 | tok/s 13471
step   2460 | loss 1.6727 | lr 3.00e-04 | grad 2.09 | tok/s 13781
step   2470 | loss 1.5482 | lr 3.00e-04 | grad 1.88 | tok/s 13198
step   2480 | loss 1.6845 | lr 3.00e-04 | grad 2.48 | tok/s 13808
step   2490 | loss 1.8139 | lr 3.00e-04 | grad 2.39 | tok/s 13269
step   2500 | loss 1.7771 | lr 3.00e-04 | grad 1.95 | tok/s 13605
step   2510 | loss 1.6629 | lr 3.00e-04 | grad 2.28 | tok/s 13392
step   2520 | loss 1.6449 | lr 3.00e-04 | grad 2.95 | tok/s 13436
step   2530 | loss 1.7441 | lr 3.00e-04 | grad 2.66 | tok/s 13496
step   2540 | loss 1.6368 | lr 3.00e-04 | grad 1.91 | tok/s 13003
step   2550 | loss 1.6314 | lr 3.00e-04 | grad 3.80 | tok/s 13420
step   2560 | loss 1.6487 | lr 3.00e-04 | grad 2.83 | tok/s 13219
step   2570 | loss 1.6800 | lr 3.00e-04 | grad 5.06 | tok/s 13511
step   2580 | loss 1.7505 | lr 3.00e-04 | grad 2.03 | tok/s 12982
step   2590 | loss 1.5523 | lr 3.00e-04 | grad 2.45 | tok/s 13127
step   2600 | loss 1.6880 | lr 3.00e-04 | grad 2.05 | tok/s 13587
step   2610 | loss 1.5884 | lr 3.00e-04 | grad 2.03 | tok/s 13607
step   2620 | loss 1.7425 | lr 3.00e-04 | grad 1.34 | tok/s 13522
step   2630 | loss 1.3136 | lr 3.00e-04 | grad 1.59 | tok/s 13717
step   2640 | loss 1.6544 | lr 3.00e-04 | grad 2.02 | tok/s 12978
step   2650 | loss 1.4154 | lr 3.00e-04 | grad 2.34 | tok/s 13482
step   2660 | loss 1.5338 | lr 3.00e-04 | grad 1.88 | tok/s 13874
step   2670 | loss 1.5065 | lr 3.00e-04 | grad 2.25 | tok/s 13509
step   2680 | loss 1.5818 | lr 3.00e-04 | grad 2.34 | tok/s 13243
step   2690 | loss 1.5474 | lr 3.00e-04 | grad 2.27 | tok/s 12984
step   2700 | loss 1.5272 | lr 3.00e-04 | grad 1.14 | tok/s 13666
step   2710 | loss 1.9541 | lr 3.00e-04 | grad 1.99 | tok/s 13227
step   2720 | loss 1.5648 | lr 3.00e-04 | grad 2.08 | tok/s 13428
step   2730 | loss 1.5953 | lr 3.00e-04 | grad 2.39 | tok/s 13527
step   2740 | loss 1.5770 | lr 3.00e-04 | grad 2.58 | tok/s 13137
step   2750 | loss 1.5978 | lr 3.00e-04 | grad 1.95 | tok/s 13935
step   2760 | loss 1.4700 | lr 3.00e-04 | grad 1.80 | tok/s 13447
step   2770 | loss 1.6195 | lr 3.00e-04 | grad 3.23 | tok/s 13697
step   2780 | loss 1.5080 | lr 3.00e-04 | grad 2.22 | tok/s 13708
step   2790 | loss 1.7541 | lr 3.00e-04 | grad 7.00 | tok/s 13153
step   2800 | loss 1.5383 | lr 3.00e-04 | grad 3.09 | tok/s 13168
step   2810 | loss 1.6167 | lr 3.00e-04 | grad 1.85 | tok/s 13166
step   2820 | loss 1.5214 | lr 3.00e-04 | grad 1.63 | tok/s 12714
step   2830 | loss 1.4538 | lr 3.00e-04 | grad 1.57 | tok/s 13318
step   2840 | loss 1.3658 | lr 3.00e-04 | grad 2.22 | tok/s 13529
step   2850 | loss 1.3420 | lr 3.00e-04 | grad 1.89 | tok/s 13977
step   2860 | loss 1.4558 | lr 3.00e-04 | grad 2.11 | tok/s 13559
step   2870 | loss 1.5903 | lr 3.00e-04 | grad 2.06 | tok/s 13076
step   2880 | loss 1.6629 | lr 3.00e-04 | grad 3.73 | tok/s 13192
step   2890 | loss 1.7302 | lr 3.00e-04 | grad 1.44 | tok/s 13693
step   2900 | loss 1.5742 | lr 3.00e-04 | grad 1.98 | tok/s 13116
step   2910 | loss 1.5741 | lr 3.00e-04 | grad 1.87 | tok/s 13518
step   2920 | loss 1.4427 | lr 3.00e-04 | grad 5.16 | tok/s 13504
step   2930 | loss 1.5946 | lr 3.00e-04 | grad 2.39 | tok/s 13666
step   2940 | loss 1.5913 | lr 3.00e-04 | grad 3.55 | tok/s 13194
step   2950 | loss 1.8095 | lr 3.00e-04 | grad 2.39 | tok/s 13355
step   2960 | loss 1.8662 | lr 3.00e-04 | grad 4.78 | tok/s 13117
step   2970 | loss 1.5524 | lr 3.00e-04 | grad 1.96 | tok/s 13633
step   2980 | loss 1.5695 | lr 3.00e-04 | grad 2.55 | tok/s 13720
step   2990 | loss 1.7229 | lr 3.00e-04 | grad 2.16 | tok/s 13555
step   3000 | loss 1.5153 | lr 3.00e-04 | grad 1.96 | tok/s 13612
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5153.pt
step   3010 | loss 1.5695 | lr 3.00e-04 | grad 1.47 | tok/s 9049
step   3020 | loss 1.5154 | lr 3.00e-04 | grad 1.77 | tok/s 13266
step   3030 | loss 1.4675 | lr 3.00e-04 | grad 1.66 | tok/s 13386

Training complete! Final step: 3030
