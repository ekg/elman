Using device: cuda
Output directory: benchmark_results/cmaes_converge/e42_480M_converge0.01_20260201_232443/eval_3/level42_100m_20260201_232449
Auto r_h_mode: spectral_norm (level 42 has full W_h)
Model: Level 42, 483,674,752 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 30.0 minutes
step     10 | loss 4.8346 | lr 3.00e-04 | grad 8.81 | tok/s 3878
step     20 | loss 3.1098 | lr 3.00e-04 | grad 4.62 | tok/s 6126
step     30 | loss 2.8602 | lr 3.00e-04 | grad 4.12 | tok/s 6195
step     40 | loss 2.6279 | lr 3.00e-04 | grad 4.22 | tok/s 5929
step     50 | loss 3.4041 | lr 3.00e-04 | grad 7.91 | tok/s 6055
step     60 | loss 2.3063 | lr 3.00e-04 | grad 2.59 | tok/s 6252
step     70 | loss 2.2958 | lr 3.00e-04 | grad 4.41 | tok/s 6320
step     80 | loss 5.1126 | lr 3.00e-04 | grad 15.81 | tok/s 6354
step     90 | loss 4.3620 | lr 3.00e-04 | grad 3.94 | tok/s 6424
step    100 | loss 3.7178 | lr 3.00e-04 | grad 4.84 | tok/s 6440
step    110 | loss 3.6302 | lr 3.00e-04 | grad 13.44 | tok/s 6453
step    120 | loss 3.3619 | lr 3.00e-04 | grad 15.12 | tok/s 6423
step    130 | loss 3.2290 | lr 3.00e-04 | grad 6.94 | tok/s 6439
step    140 | loss 2.7752 | lr 3.00e-04 | grad 5.47 | tok/s 6416
step    150 | loss 3.0526 | lr 3.00e-04 | grad 12.62 | tok/s 6420
step    160 | loss 2.5990 | lr 3.00e-04 | grad 11.88 | tok/s 6417
step    170 | loss 2.6783 | lr 3.00e-04 | grad 7.25 | tok/s 6432
step    180 | loss 2.4922 | lr 3.00e-04 | grad 7.19 | tok/s 6424
step    190 | loss 2.7091 | lr 3.00e-04 | grad 10.00 | tok/s 6418
step    200 | loss 2.3995 | lr 3.00e-04 | grad 4.28 | tok/s 6420
step    210 | loss 2.3789 | lr 3.00e-04 | grad 4.31 | tok/s 6430
step    220 | loss 2.6011 | lr 3.00e-04 | grad 3.48 | tok/s 6368
step    230 | loss 3.0360 | lr 3.00e-04 | grad 3.59 | tok/s 6279
step    240 | loss 2.5284 | lr 3.00e-04 | grad 3.09 | tok/s 5958
step    250 | loss 2.3481 | lr 3.00e-04 | grad 2.30 | tok/s 6138
step    260 | loss 2.0476 | lr 3.00e-04 | grad 2.48 | tok/s 6329
step    270 | loss 2.3662 | lr 3.00e-04 | grad 2.55 | tok/s 6242
step    280 | loss 2.5344 | lr 3.00e-04 | grad 2.84 | tok/s 6121
step    290 | loss 2.3457 | lr 3.00e-04 | grad 1.95 | tok/s 6434
step    300 | loss 1.2338 | lr 3.00e-04 | grad 3.36 | tok/s 6433
step    310 | loss 2.9704 | lr 3.00e-04 | grad 3.66 | tok/s 6335
step    320 | loss 2.5735 | lr 3.00e-04 | grad 4.78 | tok/s 6203
step    330 | loss 2.2418 | lr 3.00e-04 | grad 1.93 | tok/s 5989
step    340 | loss 2.5217 | lr 3.00e-04 | grad 1.95 | tok/s 6083
step    350 | loss 2.3089 | lr 3.00e-04 | grad 2.39 | tok/s 6240
step    360 | loss 2.3463 | lr 3.00e-04 | grad 4.25 | tok/s 6373
step    370 | loss 2.1584 | lr 3.00e-04 | grad 2.20 | tok/s 5777
step    380 | loss 2.0901 | lr 3.00e-04 | grad 1.91 | tok/s 6158
step    390 | loss 1.8935 | lr 3.00e-04 | grad 1.91 | tok/s 6431
step    400 | loss 1.8926 | lr 3.00e-04 | grad 2.20 | tok/s 6372
step    410 | loss 1.8196 | lr 3.00e-04 | grad 1.54 | tok/s 6234
step    420 | loss 2.0981 | lr 3.00e-04 | grad 3.25 | tok/s 5949
step    430 | loss 2.4220 | lr 3.00e-04 | grad 2.25 | tok/s 6332
step    440 | loss 2.4422 | lr 3.00e-04 | grad 2.47 | tok/s 5984
step    450 | loss 2.5409 | lr 3.00e-04 | grad 1.61 | tok/s 6192
step    460 | loss 2.1288 | lr 3.00e-04 | grad 2.88 | tok/s 6065
step    470 | loss 2.1850 | lr 3.00e-04 | grad 2.02 | tok/s 6251
step    480 | loss 2.6314 | lr 3.00e-04 | grad 4.25 | tok/s 6250
step    490 | loss 2.0856 | lr 3.00e-04 | grad 2.11 | tok/s 5909
step    500 | loss 2.0475 | lr 3.00e-04 | grad 2.92 | tok/s 6313
step    510 | loss 2.0382 | lr 3.00e-04 | grad 1.80 | tok/s 6400
step    520 | loss 2.0306 | lr 3.00e-04 | grad 1.65 | tok/s 6387
step    530 | loss 2.2460 | lr 3.00e-04 | grad 1.56 | tok/s 6138
step    540 | loss 1.9934 | lr 3.00e-04 | grad 2.06 | tok/s 6143
step    550 | loss 1.8350 | lr 3.00e-04 | grad 2.30 | tok/s 6013
step    560 | loss 2.0217 | lr 3.00e-04 | grad 1.96 | tok/s 5855
step    570 | loss 1.9683 | lr 3.00e-04 | grad 2.55 | tok/s 6014
step    580 | loss 1.8478 | lr 3.00e-04 | grad 2.06 | tok/s 5980
step    590 | loss 2.2092 | lr 3.00e-04 | grad 2.06 | tok/s 6148
step    600 | loss 2.0679 | lr 3.00e-04 | grad 1.66 | tok/s 5931
step    610 | loss 1.9190 | lr 3.00e-04 | grad 1.43 | tok/s 6237
step    620 | loss 1.7941 | lr 3.00e-04 | grad 1.79 | tok/s 5916
step    630 | loss 1.9545 | lr 3.00e-04 | grad 2.73 | tok/s 5963
step    640 | loss 2.1301 | lr 3.00e-04 | grad 2.00 | tok/s 6122
step    650 | loss 1.9378 | lr 3.00e-04 | grad 2.22 | tok/s 6147
step    660 | loss 1.9898 | lr 3.00e-04 | grad 1.30 | tok/s 6180
step    670 | loss 2.2440 | lr 3.00e-04 | grad 6.69 | tok/s 6218
step    680 | loss 1.9667 | lr 3.00e-04 | grad 1.82 | tok/s 6095
step    690 | loss 2.2398 | lr 3.00e-04 | grad 2.20 | tok/s 6312
step    700 | loss 1.9545 | lr 3.00e-04 | grad 2.16 | tok/s 6428
step    710 | loss 1.8727 | lr 3.00e-04 | grad 1.77 | tok/s 6007
step    720 | loss 1.7158 | lr 3.00e-04 | grad 1.99 | tok/s 5913
step    730 | loss 1.7343 | lr 3.00e-04 | grad 2.25 | tok/s 6412
step    740 | loss 1.8583 | lr 3.00e-04 | grad 1.91 | tok/s 6324
step    750 | loss 1.6088 | lr 3.00e-04 | grad 1.83 | tok/s 6427
step    760 | loss 1.4787 | lr 3.00e-04 | grad 1.66 | tok/s 6434
step    770 | loss 1.4339 | lr 3.00e-04 | grad 1.55 | tok/s 6423
step    780 | loss 1.3780 | lr 3.00e-04 | grad 1.73 | tok/s 6426
step    790 | loss 1.4619 | lr 3.00e-04 | grad 2.31 | tok/s 6221
step    800 | loss 2.2246 | lr 3.00e-04 | grad 3.55 | tok/s 6201
step    810 | loss 1.9328 | lr 3.00e-04 | grad 1.86 | tok/s 6176
step    820 | loss 1.9509 | lr 3.00e-04 | grad 2.83 | tok/s 5926
step    830 | loss 1.9826 | lr 3.00e-04 | grad 1.76 | tok/s 6356
step    840 | loss 1.8315 | lr 3.00e-04 | grad 1.98 | tok/s 6432
step    850 | loss 1.8474 | lr 3.00e-04 | grad 2.06 | tok/s 6399
step    860 | loss 1.8568 | lr 3.00e-04 | grad 3.09 | tok/s 6332
step    870 | loss 1.7863 | lr 3.00e-04 | grad 1.96 | tok/s 6093
step    880 | loss 1.9756 | lr 3.00e-04 | grad 1.94 | tok/s 6125
step    890 | loss 1.9247 | lr 3.00e-04 | grad 2.22 | tok/s 6205
step    900 | loss 1.8125 | lr 3.00e-04 | grad 1.69 | tok/s 6208
step    910 | loss 1.6523 | lr 3.00e-04 | grad 2.38 | tok/s 6080
step    920 | loss 1.8345 | lr 3.00e-04 | grad 2.69 | tok/s 6320
step    930 | loss 1.8423 | lr 3.00e-04 | grad 2.69 | tok/s 6021
step    940 | loss 1.7362 | lr 3.00e-04 | grad 1.60 | tok/s 6356
step    950 | loss 1.8550 | lr 3.00e-04 | grad 2.12 | tok/s 3111
step    960 | loss 1.9770 | lr 3.00e-04 | grad 2.45 | tok/s 2869
step    970 | loss 1.8450 | lr 3.00e-04 | grad 1.50 | tok/s 2839
step    980 | loss 2.1505 | lr 3.00e-04 | grad 2.44 | tok/s 2839
step    990 | loss 1.7932 | lr 3.00e-04 | grad 1.93 | tok/s 2830
step   1000 | loss 1.8846 | lr 3.00e-04 | grad 1.71 | tok/s 2853
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8846.pt
step   1010 | loss 1.9121 | lr 3.00e-04 | grad 1.95 | tok/s 2319
step   1020 | loss 1.4904 | lr 3.00e-04 | grad 1.40 | tok/s 2780
step   1030 | loss 1.7471 | lr 3.00e-04 | grad 1.67 | tok/s 2947
step   1040 | loss 1.5917 | lr 3.00e-04 | grad 2.00 | tok/s 2996
step   1050 | loss 1.5462 | lr 3.00e-04 | grad 1.77 | tok/s 2998
step   1060 | loss 1.5415 | lr 3.00e-04 | grad 1.87 | tok/s 2996
step   1070 | loss 1.5159 | lr 3.00e-04 | grad 1.95 | tok/s 2986
step   1080 | loss 1.5597 | lr 3.00e-04 | grad 1.83 | tok/s 2998
step   1090 | loss 1.5303 | lr 3.00e-04 | grad 1.62 | tok/s 2995
step   1100 | loss 2.0723 | lr 3.00e-04 | grad 2.53 | tok/s 2789
step   1110 | loss 1.8218 | lr 3.00e-04 | grad 3.59 | tok/s 2871
step   1120 | loss 1.7525 | lr 3.00e-04 | grad 2.55 | tok/s 2905
step   1130 | loss 1.7440 | lr 3.00e-04 | grad 2.78 | tok/s 2910
step   1140 | loss 1.7091 | lr 3.00e-04 | grad 2.66 | tok/s 2895
step   1150 | loss 2.0427 | lr 3.00e-04 | grad 2.03 | tok/s 2782
step   1160 | loss 1.8432 | lr 3.00e-04 | grad 1.67 | tok/s 2867
step   1170 | loss 1.7862 | lr 3.00e-04 | grad 4.00 | tok/s 2750
step   1180 | loss 1.7768 | lr 3.00e-04 | grad 1.68 | tok/s 2894
step   1190 | loss 1.7563 | lr 3.00e-04 | grad 2.05 | tok/s 2915
step   1200 | loss 1.6475 | lr 3.00e-04 | grad 2.30 | tok/s 2945
step   1210 | loss 2.0355 | lr 3.00e-04 | grad 5.38 | tok/s 2943
step   1220 | loss 2.2599 | lr 3.00e-04 | grad 1.66 | tok/s 2983
step   1230 | loss 1.7365 | lr 3.00e-04 | grad 2.34 | tok/s 2940
step   1240 | loss 1.7646 | lr 3.00e-04 | grad 1.88 | tok/s 2807
step   1250 | loss 1.6734 | lr 3.00e-04 | grad 1.38 | tok/s 2888
step   1260 | loss 1.8762 | lr 3.00e-04 | grad 5.00 | tok/s 2962
step   1270 | loss 1.9875 | lr 3.00e-04 | grad 1.71 | tok/s 2910
step   1280 | loss 1.3646 | lr 3.00e-04 | grad 1.80 | tok/s 2833
step   1290 | loss 1.7651 | lr 3.00e-04 | grad 2.23 | tok/s 2936
step   1300 | loss 1.8167 | lr 3.00e-04 | grad 1.98 | tok/s 2748
step   1310 | loss 1.9861 | lr 3.00e-04 | grad 5.19 | tok/s 4016
step   1320 | loss 1.8302 | lr 3.00e-04 | grad 4.62 | tok/s 2756
step   1330 | loss 1.8313 | lr 3.00e-04 | grad 1.88 | tok/s 2907
step   1340 | loss 1.9645 | lr 3.00e-04 | grad 2.55 | tok/s 3002
step   1350 | loss 1.8149 | lr 3.00e-04 | grad 2.09 | tok/s 2923
step   1360 | loss 1.7190 | lr 3.00e-04 | grad 1.70 | tok/s 2800
step   1370 | loss 1.7143 | lr 3.00e-04 | grad 2.59 | tok/s 2888
step   1380 | loss 1.8410 | lr 3.00e-04 | grad 2.88 | tok/s 2817
step   1390 | loss 1.7595 | lr 3.00e-04 | grad 2.84 | tok/s 2889
step   1400 | loss 1.7062 | lr 3.00e-04 | grad 1.29 | tok/s 2894
step   1410 | loss 1.6539 | lr 3.00e-04 | grad 2.00 | tok/s 2839
step   1420 | loss 1.7060 | lr 3.00e-04 | grad 1.55 | tok/s 2732
step   1430 | loss 1.6329 | lr 3.00e-04 | grad 1.71 | tok/s 2816
step   1440 | loss 1.6356 | lr 3.00e-04 | grad 1.95 | tok/s 2847
step   1450 | loss 2.2225 | lr 3.00e-04 | grad 3.92 | tok/s 2988
step   1460 | loss 2.0084 | lr 3.00e-04 | grad 2.58 | tok/s 2959
step   1470 | loss 1.7459 | lr 3.00e-04 | grad 2.28 | tok/s 2860
step   1480 | loss 1.5077 | lr 3.00e-04 | grad 1.87 | tok/s 2929
step   1490 | loss 1.4804 | lr 3.00e-04 | grad 1.79 | tok/s 2905
step   1500 | loss 1.5826 | lr 3.00e-04 | grad 2.30 | tok/s 2991
step   1510 | loss 1.6519 | lr 3.00e-04 | grad 1.88 | tok/s 2737
step   1520 | loss 2.3120 | lr 3.00e-04 | grad 2.31 | tok/s 2966
step   1530 | loss 1.7994 | lr 3.00e-04 | grad 2.03 | tok/s 2855
step   1540 | loss 1.3350 | lr 3.00e-04 | grad 1.74 | tok/s 2965
step   1550 | loss 1.6464 | lr 3.00e-04 | grad 1.95 | tok/s 2952
step   1560 | loss 1.4439 | lr 3.00e-04 | grad 1.45 | tok/s 3003
step   1570 | loss 1.4269 | lr 3.00e-04 | grad 1.67 | tok/s 3001
step   1580 | loss 1.3938 | lr 3.00e-04 | grad 1.51 | tok/s 2992
step   1590 | loss 1.4622 | lr 3.00e-04 | grad 2.22 | tok/s 2980
step   1600 | loss 1.7978 | lr 3.00e-04 | grad 3.39 | tok/s 2906
step   1610 | loss 2.1236 | lr 3.00e-04 | grad 6.66 | tok/s 2964
step   1620 | loss 1.7440 | lr 3.00e-04 | grad 1.42 | tok/s 2959
step   1630 | loss 2.3737 | lr 3.00e-04 | grad 3.34 | tok/s 2860
step   1640 | loss 2.0601 | lr 3.00e-04 | grad 2.50 | tok/s 2800
step   1650 | loss 1.6606 | lr 3.00e-04 | grad 1.36 | tok/s 2883
step   1660 | loss 1.7298 | lr 3.00e-04 | grad 3.62 | tok/s 2962
step   1670 | loss 1.8889 | lr 3.00e-04 | grad 2.33 | tok/s 2996
step   1680 | loss 1.3237 | lr 3.00e-04 | grad 2.11 | tok/s 3967
step   1690 | loss 1.5126 | lr 3.00e-04 | grad 2.14 | tok/s 2855
step   1700 | loss 1.6393 | lr 3.00e-04 | grad 2.23 | tok/s 2930
step   1710 | loss 1.5552 | lr 3.00e-04 | grad 1.23 | tok/s 2916
step   1720 | loss 1.5181 | lr 3.00e-04 | grad 2.17 | tok/s 2942
step   1730 | loss 1.7868 | lr 3.00e-04 | grad 5.34 | tok/s 2874
step   1740 | loss 1.6980 | lr 3.00e-04 | grad 2.14 | tok/s 2983
step   1750 | loss 1.6037 | lr 3.00e-04 | grad 2.14 | tok/s 2910
step   1760 | loss 1.5981 | lr 3.00e-04 | grad 2.47 | tok/s 2831
step   1770 | loss 1.6088 | lr 3.00e-04 | grad 2.31 | tok/s 2854
step   1780 | loss 2.0591 | lr 3.00e-04 | grad 4.38 | tok/s 2838
step   1790 | loss 1.7601 | lr 3.00e-04 | grad 2.00 | tok/s 2913
step   1800 | loss 1.6542 | lr 3.00e-04 | grad 1.67 | tok/s 2892
step   1810 | loss 1.7660 | lr 3.00e-04 | grad 2.47 | tok/s 2947

Training complete! Final step: 1810
