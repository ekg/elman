Using device: cuda
Output directory: benchmark_results/cmaes_converge/e1_480M_converge0.01_20260201_200250/eval_15/level1_100m_20260201_203312
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 446,285,952 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 3.9038 | lr 3.00e-04 | grad 6.00 | tok/s 8189
step     20 | loss 2.4659 | lr 3.00e-04 | grad 1.35 | tok/s 12940
step     30 | loss 2.7818 | lr 3.00e-04 | grad 2.00 | tok/s 13722
step     40 | loss 3.8247 | lr 3.00e-04 | grad 11.69 | tok/s 13989
step     50 | loss 3.6428 | lr 3.00e-04 | grad 4.47 | tok/s 14162
step     60 | loss 2.7942 | lr 3.00e-04 | grad 2.56 | tok/s 14147
step     70 | loss 2.4657 | lr 3.00e-04 | grad 3.44 | tok/s 14134
step     80 | loss 2.2260 | lr 3.00e-04 | grad 2.19 | tok/s 14116
step     90 | loss 2.1892 | lr 3.00e-04 | grad 1.77 | tok/s 14105
step    100 | loss 2.0164 | lr 3.00e-04 | grad 1.67 | tok/s 14103
step    110 | loss 2.1255 | lr 3.00e-04 | grad 2.38 | tok/s 13998
step    120 | loss 2.5668 | lr 3.00e-04 | grad 1.12 | tok/s 13321
step    130 | loss 2.0127 | lr 3.00e-04 | grad 3.23 | tok/s 13646
step    140 | loss 2.3465 | lr 3.00e-04 | grad 4.22 | tok/s 13668
step    150 | loss 1.5079 | lr 3.00e-04 | grad 4.09 | tok/s 13993
step    160 | loss 2.2366 | lr 3.00e-04 | grad 1.44 | tok/s 13549
step    170 | loss 2.1665 | lr 3.00e-04 | grad 1.00 | tok/s 13348
step    180 | loss 1.8612 | lr 3.00e-04 | grad 1.71 | tok/s 13668
step    190 | loss 1.8357 | lr 3.00e-04 | grad 1.32 | tok/s 13413
step    200 | loss 1.5697 | lr 3.00e-04 | grad 1.04 | tok/s 14042
step    210 | loss 1.7947 | lr 3.00e-04 | grad 2.38 | tok/s 13313
step    220 | loss 2.1185 | lr 3.00e-04 | grad 1.51 | tok/s 13447
step    230 | loss 1.8840 | lr 3.00e-04 | grad 1.62 | tok/s 13443
step    240 | loss 2.1558 | lr 3.00e-04 | grad 2.98 | tok/s 13616
step    250 | loss 1.7052 | lr 3.00e-04 | grad 1.03 | tok/s 13523
step    260 | loss 1.8277 | lr 3.00e-04 | grad 1.92 | tok/s 13917
step    270 | loss 1.7660 | lr 3.00e-04 | grad 1.25 | tok/s 13589
step    280 | loss 1.7267 | lr 3.00e-04 | grad 1.20 | tok/s 12765
step    290 | loss 1.6214 | lr 3.00e-04 | grad 1.45 | tok/s 13199
step    300 | loss 1.9104 | lr 3.00e-04 | grad 1.41 | tok/s 13300
step    310 | loss 1.6255 | lr 3.00e-04 | grad 1.12 | tok/s 13240
step    320 | loss 1.8351 | lr 3.00e-04 | grad 1.99 | tok/s 13381
step    330 | loss 1.6722 | lr 3.00e-04 | grad 1.12 | tok/s 13536
step    340 | loss 1.9621 | lr 3.00e-04 | grad 1.42 | tok/s 13474
step    350 | loss 1.6983 | lr 3.00e-04 | grad 1.33 | tok/s 13874
step    360 | loss 1.5469 | lr 3.00e-04 | grad 1.12 | tok/s 13257
step    370 | loss 1.4889 | lr 3.00e-04 | grad 1.11 | tok/s 13983
step    380 | loss 1.2326 | lr 3.00e-04 | grad 1.06 | tok/s 14110
step    390 | loss 1.1348 | lr 3.00e-04 | grad 0.84 | tok/s 14111
step    400 | loss 1.7291 | lr 3.00e-04 | grad 1.20 | tok/s 13357
step    410 | loss 1.7366 | lr 3.00e-04 | grad 1.58 | tok/s 13489
step    420 | loss 1.6307 | lr 3.00e-04 | grad 1.71 | tok/s 14065
step    430 | loss 1.5550 | lr 3.00e-04 | grad 1.23 | tok/s 13834
step    440 | loss 1.6780 | lr 3.00e-04 | grad 1.51 | tok/s 13404
step    450 | loss 1.5933 | lr 3.00e-04 | grad 0.97 | tok/s 13552
step    460 | loss 1.5837 | lr 3.00e-04 | grad 1.35 | tok/s 13749
step    470 | loss 1.5598 | lr 3.00e-04 | grad 2.12 | tok/s 13648
step    480 | loss 1.5604 | lr 3.00e-04 | grad 1.85 | tok/s 13959
step    490 | loss 1.6647 | lr 3.00e-04 | grad 1.70 | tok/s 13391
step    500 | loss 1.8068 | lr 3.00e-04 | grad 1.16 | tok/s 13624
step    510 | loss 1.6774 | lr 3.00e-04 | grad 0.97 | tok/s 13005
step    520 | loss 1.5264 | lr 3.00e-04 | grad 1.42 | tok/s 13628
step    530 | loss 1.6898 | lr 3.00e-04 | grad 1.36 | tok/s 13397
step    540 | loss 1.5726 | lr 3.00e-04 | grad 1.08 | tok/s 13117
step    550 | loss 1.3303 | lr 3.00e-04 | grad 1.88 | tok/s 13697
step    560 | loss 1.4192 | lr 3.00e-04 | grad 1.23 | tok/s 14108
step    570 | loss 1.3254 | lr 3.00e-04 | grad 1.17 | tok/s 14114
step    580 | loss 1.2848 | lr 3.00e-04 | grad 0.89 | tok/s 14117
step    590 | loss 1.3214 | lr 3.00e-04 | grad 0.91 | tok/s 14107
step    600 | loss 1.2597 | lr 3.00e-04 | grad 1.02 | tok/s 14120
step    610 | loss 1.2913 | lr 3.00e-04 | grad 0.98 | tok/s 14120
step    620 | loss 1.2815 | lr 3.00e-04 | grad 0.99 | tok/s 14064
step    630 | loss 1.6801 | lr 3.00e-04 | grad 2.84 | tok/s 13270
step    640 | loss 1.7011 | lr 3.00e-04 | grad 1.13 | tok/s 13457
step    650 | loss 1.5341 | lr 3.00e-04 | grad 1.16 | tok/s 13440
step    660 | loss 1.5783 | lr 3.00e-04 | grad 1.26 | tok/s 13951
step    670 | loss 1.6069 | lr 3.00e-04 | grad 3.50 | tok/s 13493
step    680 | loss 1.6111 | lr 3.00e-04 | grad 1.53 | tok/s 13271
step    690 | loss 1.5771 | lr 3.00e-04 | grad 1.20 | tok/s 13170
step    700 | loss 1.4625 | lr 3.00e-04 | grad 0.96 | tok/s 13462
step    710 | loss 1.6225 | lr 3.00e-04 | grad 2.12 | tok/s 13237
step    720 | loss 1.3017 | lr 3.00e-04 | grad 1.02 | tok/s 13773
step    730 | loss 1.4572 | lr 3.00e-04 | grad 0.97 | tok/s 13538
step    740 | loss 1.7476 | lr 3.00e-04 | grad 2.59 | tok/s 13919
step    750 | loss 1.5366 | lr 3.00e-04 | grad 1.07 | tok/s 14068
step    760 | loss 1.5083 | lr 3.00e-04 | grad 2.19 | tok/s 13787
step    770 | loss 1.5462 | lr 3.00e-04 | grad 1.24 | tok/s 13552
step    780 | loss 1.4839 | lr 3.00e-04 | grad 1.24 | tok/s 13640
step    790 | loss 1.6121 | lr 3.00e-04 | grad 3.03 | tok/s 13936
step    800 | loss 1.3242 | lr 3.00e-04 | grad 0.95 | tok/s 13687
step    810 | loss 1.3181 | lr 3.00e-04 | grad 1.97 | tok/s 13231
step    820 | loss 1.4350 | lr 3.00e-04 | grad 1.35 | tok/s 13508
step    830 | loss 1.4973 | lr 3.00e-04 | grad 0.86 | tok/s 13310
step    840 | loss 1.6201 | lr 3.00e-04 | grad 1.01 | tok/s 13267
step    850 | loss 1.5276 | lr 3.00e-04 | grad 1.02 | tok/s 13549
step    860 | loss 1.5754 | lr 3.00e-04 | grad 1.58 | tok/s 13774
step    870 | loss 1.3964 | lr 3.00e-04 | grad 1.22 | tok/s 13858
step    880 | loss 1.5740 | lr 3.00e-04 | grad 1.12 | tok/s 13598
step    890 | loss 1.4711 | lr 3.00e-04 | grad 0.85 | tok/s 13531
step    900 | loss 1.5136 | lr 3.00e-04 | grad 1.06 | tok/s 13474
step    910 | loss 1.4908 | lr 3.00e-04 | grad 3.75 | tok/s 13331
step    920 | loss 1.4699 | lr 3.00e-04 | grad 1.05 | tok/s 13491
step    930 | loss 1.3799 | lr 3.00e-04 | grad 1.22 | tok/s 13671
step    940 | loss 1.3609 | lr 3.00e-04 | grad 1.38 | tok/s 13345
step    950 | loss 1.4621 | lr 3.00e-04 | grad 1.70 | tok/s 13127
step    960 | loss 1.4240 | lr 3.00e-04 | grad 0.87 | tok/s 13490
step    970 | loss 1.4485 | lr 3.00e-04 | grad 1.10 | tok/s 13496
step    980 | loss 1.8391 | lr 3.00e-04 | grad 2.44 | tok/s 14029
step    990 | loss 1.5569 | lr 3.00e-04 | grad 1.18 | tok/s 13448
step   1000 | loss 1.5334 | lr 3.00e-04 | grad 1.22 | tok/s 13490
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5334.pt
step   1010 | loss 1.3487 | lr 3.00e-04 | grad 1.65 | tok/s 8877
step   1020 | loss 1.2301 | lr 3.00e-04 | grad 0.92 | tok/s 14161
step   1030 | loss 1.5263 | lr 3.00e-04 | grad 1.36 | tok/s 13444
step   1040 | loss 2.1028 | lr 3.00e-04 | grad 2.25 | tok/s 13760
step   1050 | loss 1.4944 | lr 3.00e-04 | grad 1.85 | tok/s 13854
step   1060 | loss 1.1383 | lr 3.00e-04 | grad 2.00 | tok/s 13684
step   1070 | loss 1.4352 | lr 3.00e-04 | grad 1.23 | tok/s 13627
step   1080 | loss 1.2560 | lr 3.00e-04 | grad 1.10 | tok/s 14104
step   1090 | loss 1.2140 | lr 3.00e-04 | grad 0.74 | tok/s 14104
step   1100 | loss 1.2028 | lr 3.00e-04 | grad 0.87 | tok/s 14103
step   1110 | loss 1.1479 | lr 3.00e-04 | grad 0.82 | tok/s 14103
step   1120 | loss 1.4360 | lr 3.00e-04 | grad 2.84 | tok/s 13715
step   1130 | loss 1.6209 | lr 3.00e-04 | grad 1.09 | tok/s 13862
step   1140 | loss 1.7657 | lr 3.00e-04 | grad 1.45 | tok/s 14016
step   1150 | loss 1.6566 | lr 3.00e-04 | grad 1.61 | tok/s 13570
step   1160 | loss 1.7214 | lr 3.00e-04 | grad 1.58 | tok/s 13371
step   1170 | loss 1.4818 | lr 3.00e-04 | grad 1.28 | tok/s 13218
step   1180 | loss 1.3387 | lr 3.00e-04 | grad 1.93 | tok/s 13899
step   1190 | loss 1.5813 | lr 3.00e-04 | grad 1.66 | tok/s 14015
step   1200 | loss 1.1413 | lr 3.00e-04 | grad 1.22 | tok/s 14074
step   1210 | loss 1.3835 | lr 3.00e-04 | grad 1.34 | tok/s 13124
step   1220 | loss 1.3886 | lr 3.00e-04 | grad 1.42 | tok/s 13790
step   1230 | loss 1.3224 | lr 3.00e-04 | grad 0.89 | tok/s 13820
step   1240 | loss 1.2977 | lr 3.00e-04 | grad 1.09 | tok/s 13875
step   1250 | loss 1.4703 | lr 3.00e-04 | grad 1.56 | tok/s 13668
step   1260 | loss 1.3872 | lr 3.00e-04 | grad 1.35 | tok/s 13964
step   1270 | loss 1.3713 | lr 3.00e-04 | grad 1.22 | tok/s 13564
step   1280 | loss 1.3740 | lr 3.00e-04 | grad 1.26 | tok/s 13407
step   1290 | loss 1.3485 | lr 3.00e-04 | grad 1.54 | tok/s 13458
step   1300 | loss 1.6445 | lr 3.00e-04 | grad 4.78 | tok/s 13231
step   1310 | loss 1.5032 | lr 3.00e-04 | grad 1.23 | tok/s 13765
step   1320 | loss 1.4773 | lr 3.00e-04 | grad 1.26 | tok/s 13777
step   1330 | loss 1.4055 | lr 3.00e-04 | grad 1.12 | tok/s 13638
step   1340 | loss 1.5872 | lr 3.00e-04 | grad 1.55 | tok/s 13354
step   1350 | loss 1.4052 | lr 3.00e-04 | grad 1.02 | tok/s 13636
step   1360 | loss 1.4457 | lr 3.00e-04 | grad 1.25 | tok/s 13145
step   1370 | loss 1.5685 | lr 3.00e-04 | grad 1.60 | tok/s 13855
step   1380 | loss 1.4392 | lr 3.00e-04 | grad 1.28 | tok/s 13246
step   1390 | loss 1.3609 | lr 3.00e-04 | grad 1.77 | tok/s 13872
step   1400 | loss 1.5055 | lr 3.00e-04 | grad 1.23 | tok/s 13380
step   1410 | loss 1.4140 | lr 3.00e-04 | grad 2.05 | tok/s 13086
step   1420 | loss 1.1242 | lr 3.00e-04 | grad 6.47 | tok/s 13936
step   1430 | loss 1.6944 | lr 3.00e-04 | grad 1.34 | tok/s 13433
step   1440 | loss 1.4336 | lr 3.00e-04 | grad 1.36 | tok/s 13786
step   1450 | loss 1.4790 | lr 3.00e-04 | grad 6.19 | tok/s 13772
step   1460 | loss 1.5584 | lr 3.00e-04 | grad 2.80 | tok/s 13366
step   1470 | loss 1.3420 | lr 3.00e-04 | grad 1.12 | tok/s 13061
step   1480 | loss 1.3763 | lr 3.00e-04 | grad 1.03 | tok/s 13790
step   1490 | loss 1.7871 | lr 3.00e-04 | grad 3.50 | tok/s 13573
step   1500 | loss 1.4391 | lr 3.00e-04 | grad 1.35 | tok/s 13606
step   1510 | loss 1.2538 | lr 3.00e-04 | grad 1.20 | tok/s 13604
step   1520 | loss 1.4672 | lr 3.00e-04 | grad 1.05 | tok/s 13498
step   1530 | loss 1.3880 | lr 3.00e-04 | grad 1.12 | tok/s 13720
step   1540 | loss 1.4947 | lr 3.00e-04 | grad 1.12 | tok/s 13851
step   1550 | loss 1.4892 | lr 3.00e-04 | grad 1.49 | tok/s 13573
step   1560 | loss 1.1546 | lr 3.00e-04 | grad 1.23 | tok/s 14108
step   1570 | loss 1.3165 | lr 3.00e-04 | grad 0.96 | tok/s 13702
step   1580 | loss 1.2798 | lr 3.00e-04 | grad 2.02 | tok/s 13662
step   1590 | loss 1.4511 | lr 3.00e-04 | grad 1.38 | tok/s 13370
step   1600 | loss 1.2697 | lr 3.00e-04 | grad 1.94 | tok/s 13872
step   1610 | loss 1.9261 | lr 3.00e-04 | grad 1.98 | tok/s 13748
step   1620 | loss 1.8088 | lr 3.00e-04 | grad 2.17 | tok/s 14104
step   1630 | loss 1.5263 | lr 3.00e-04 | grad 1.68 | tok/s 14100
step   1640 | loss 1.3894 | lr 3.00e-04 | grad 1.55 | tok/s 14090
step   1650 | loss 1.3195 | lr 3.00e-04 | grad 1.51 | tok/s 14091
step   1660 | loss 1.2835 | lr 3.00e-04 | grad 1.35 | tok/s 14100
step   1670 | loss 1.4904 | lr 3.00e-04 | grad 1.19 | tok/s 13673
step   1680 | loss 1.3996 | lr 3.00e-04 | grad 1.33 | tok/s 13532
step   1690 | loss 1.4596 | lr 3.00e-04 | grad 1.46 | tok/s 13136
step   1700 | loss 1.3024 | lr 3.00e-04 | grad 0.91 | tok/s 13832
step   1710 | loss 1.2802 | lr 3.00e-04 | grad 1.38 | tok/s 13670
step   1720 | loss 1.4525 | lr 3.00e-04 | grad 1.18 | tok/s 13488
step   1730 | loss 1.4325 | lr 3.00e-04 | grad 1.76 | tok/s 13676
step   1740 | loss 1.3831 | lr 3.00e-04 | grad 1.11 | tok/s 13969
step   1750 | loss 1.2154 | lr 3.00e-04 | grad 0.88 | tok/s 13518
step   1760 | loss 1.4444 | lr 3.00e-04 | grad 1.32 | tok/s 13327
step   1770 | loss 1.5938 | lr 3.00e-04 | grad 1.28 | tok/s 13835
step   1780 | loss 1.7291 | lr 3.00e-04 | grad 0.99 | tok/s 12863
step   1790 | loss 1.3265 | lr 3.00e-04 | grad 1.37 | tok/s 13365
step   1800 | loss 1.2755 | lr 3.00e-04 | grad 1.12 | tok/s 13479
step   1810 | loss 1.3895 | lr 3.00e-04 | grad 0.93 | tok/s 13565
step   1820 | loss 1.5380 | lr 3.00e-04 | grad 1.20 | tok/s 13496
step   1830 | loss 1.3742 | lr 3.00e-04 | grad 1.00 | tok/s 13026
step   1840 | loss 1.3377 | lr 3.00e-04 | grad 1.26 | tok/s 13593
step   1850 | loss 1.4078 | lr 3.00e-04 | grad 1.03 | tok/s 13294
step   1860 | loss 1.4468 | lr 3.00e-04 | grad 1.05 | tok/s 13526
step   1870 | loss 1.3950 | lr 3.00e-04 | grad 1.16 | tok/s 13712
step   1880 | loss 1.4798 | lr 3.00e-04 | grad 1.52 | tok/s 13726
step   1890 | loss 1.2286 | lr 3.00e-04 | grad 0.94 | tok/s 14108
step   1900 | loss 1.1729 | lr 3.00e-04 | grad 0.86 | tok/s 14101
step   1910 | loss 1.1553 | lr 3.00e-04 | grad 1.07 | tok/s 14105
step   1920 | loss 1.1445 | lr 3.00e-04 | grad 0.90 | tok/s 14100
step   1930 | loss 1.2167 | lr 3.00e-04 | grad 1.30 | tok/s 13906
step   1940 | loss 1.5176 | lr 3.00e-04 | grad 1.57 | tok/s 13499
step   1950 | loss 1.4288 | lr 3.00e-04 | grad 2.16 | tok/s 13173
step   1960 | loss 1.4524 | lr 3.00e-04 | grad 1.80 | tok/s 13353
step   1970 | loss 1.5112 | lr 3.00e-04 | grad 1.02 | tok/s 13728
step   1980 | loss 1.4272 | lr 3.00e-04 | grad 1.96 | tok/s 13404
step   1990 | loss 1.4963 | lr 3.00e-04 | grad 1.68 | tok/s 13648
step   2000 | loss 1.1294 | lr 3.00e-04 | grad 1.23 | tok/s 14089
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1294.pt
step   2010 | loss 1.3418 | lr 3.00e-04 | grad 1.01 | tok/s 8569
step   2020 | loss 1.3827 | lr 3.00e-04 | grad 1.16 | tok/s 13422
step   2030 | loss 1.7321 | lr 3.00e-04 | grad 1.49 | tok/s 13300
step   2040 | loss 1.4237 | lr 3.00e-04 | grad 1.09 | tok/s 13581
step   2050 | loss 1.3448 | lr 3.00e-04 | grad 1.52 | tok/s 13527
step   2060 | loss 1.6375 | lr 3.00e-04 | grad 3.72 | tok/s 13644
step   2070 | loss 1.1504 | lr 3.00e-04 | grad 1.34 | tok/s 13673
step   2080 | loss 1.2640 | lr 3.00e-04 | grad 0.85 | tok/s 13142
step   2090 | loss 1.4464 | lr 3.00e-04 | grad 2.31 | tok/s 13909
step   2100 | loss 1.5246 | lr 3.00e-04 | grad 1.44 | tok/s 14009
step   2110 | loss 1.3866 | lr 3.00e-04 | grad 1.95 | tok/s 13317
step   2120 | loss 2.1356 | lr 3.00e-04 | grad 1.80 | tok/s 13589
step   2130 | loss 1.4324 | lr 3.00e-04 | grad 2.06 | tok/s 13273
step   2140 | loss 1.5031 | lr 3.00e-04 | grad 1.20 | tok/s 13722
step   2150 | loss 1.6916 | lr 3.00e-04 | grad 1.39 | tok/s 13648
step   2160 | loss 1.4238 | lr 3.00e-04 | grad 0.93 | tok/s 13595
step   2170 | loss 1.4667 | lr 3.00e-04 | grad 0.99 | tok/s 13646
step   2180 | loss 1.1830 | lr 3.00e-04 | grad 1.55 | tok/s 14032
step   2190 | loss 1.4818 | lr 3.00e-04 | grad 2.22 | tok/s 13441
step   2200 | loss 1.1813 | lr 3.00e-04 | grad 0.93 | tok/s 14092
step   2210 | loss 1.4508 | lr 3.00e-04 | grad 1.10 | tok/s 13610
step   2220 | loss 1.4374 | lr 3.00e-04 | grad 1.26 | tok/s 13174
step   2230 | loss 1.5993 | lr 3.00e-04 | grad 0.92 | tok/s 13439
step   2240 | loss 1.3262 | lr 3.00e-04 | grad 1.90 | tok/s 13661
step   2250 | loss 1.3544 | lr 3.00e-04 | grad 0.95 | tok/s 13416
step   2260 | loss 1.5133 | lr 3.00e-04 | grad 1.20 | tok/s 13665
step   2270 | loss 1.6904 | lr 3.00e-04 | grad 1.20 | tok/s 13120
step   2280 | loss 1.3913 | lr 3.00e-04 | grad 1.01 | tok/s 13506
step   2290 | loss 1.2452 | lr 3.00e-04 | grad 1.12 | tok/s 13264
step   2300 | loss 1.6644 | lr 3.00e-04 | grad 2.03 | tok/s 13366
step   2310 | loss 1.3764 | lr 3.00e-04 | grad 1.32 | tok/s 13710
step   2320 | loss 1.3428 | lr 3.00e-04 | grad 1.33 | tok/s 14095
step   2330 | loss 1.2610 | lr 3.00e-04 | grad 1.10 | tok/s 14101
step   2340 | loss 1.2345 | lr 3.00e-04 | grad 1.05 | tok/s 14107
step   2350 | loss 1.2165 | lr 3.00e-04 | grad 1.09 | tok/s 14102
step   2360 | loss 1.1566 | lr 3.00e-04 | grad 1.02 | tok/s 14093
step   2370 | loss 1.1639 | lr 3.00e-04 | grad 1.07 | tok/s 14104
step   2380 | loss 1.1518 | lr 3.00e-04 | grad 0.99 | tok/s 14093
step   2390 | loss 1.1621 | lr 3.00e-04 | grad 0.93 | tok/s 14104
step   2400 | loss 1.1191 | lr 3.00e-04 | grad 0.98 | tok/s 14095
step   2410 | loss 1.3462 | lr 3.00e-04 | grad 6.66 | tok/s 13906
step   2420 | loss 1.2731 | lr 3.00e-04 | grad 1.01 | tok/s 13827
step   2430 | loss 1.1916 | lr 3.00e-04 | grad 1.52 | tok/s 13291
step   2440 | loss 1.4006 | lr 3.00e-04 | grad 1.26 | tok/s 13163
step   2450 | loss 1.3363 | lr 3.00e-04 | grad 1.00 | tok/s 13666
step   2460 | loss 1.5318 | lr 3.00e-04 | grad 1.05 | tok/s 13835
step   2470 | loss 1.3216 | lr 3.00e-04 | grad 1.13 | tok/s 13458
step   2480 | loss 1.4716 | lr 3.00e-04 | grad 1.86 | tok/s 13804
step   2490 | loss 1.5183 | lr 3.00e-04 | grad 1.45 | tok/s 13421
step   2500 | loss 1.5607 | lr 3.00e-04 | grad 1.30 | tok/s 13759
step   2510 | loss 1.4350 | lr 3.00e-04 | grad 1.10 | tok/s 13618
step   2520 | loss 1.3828 | lr 3.00e-04 | grad 1.41 | tok/s 13409
step   2530 | loss 1.5233 | lr 3.00e-04 | grad 1.88 | tok/s 13718
step   2540 | loss 1.4286 | lr 3.00e-04 | grad 2.88 | tok/s 13088
step   2550 | loss 1.3116 | lr 3.00e-04 | grad 1.50 | tok/s 13552
step   2560 | loss 1.5601 | lr 3.00e-04 | grad 1.27 | tok/s 13321
step   2570 | loss 1.3563 | lr 3.00e-04 | grad 1.11 | tok/s 13493
step   2580 | loss 1.5643 | lr 3.00e-04 | grad 1.20 | tok/s 13427
step   2590 | loss 1.3178 | lr 3.00e-04 | grad 1.22 | tok/s 13152
step   2600 | loss 1.4496 | lr 3.00e-04 | grad 1.01 | tok/s 13520
step   2610 | loss 1.3273 | lr 3.00e-04 | grad 1.13 | tok/s 13844
step   2620 | loss 1.5563 | lr 3.00e-04 | grad 1.30 | tok/s 13383
step   2630 | loss 1.1667 | lr 3.00e-04 | grad 1.51 | tok/s 13862
step   2640 | loss 1.3132 | lr 3.00e-04 | grad 1.02 | tok/s 13361
step   2650 | loss 1.2495 | lr 3.00e-04 | grad 1.36 | tok/s 13637
step   2660 | loss 1.3275 | lr 3.00e-04 | grad 0.88 | tok/s 13726
step   2670 | loss 1.1377 | lr 3.00e-04 | grad 1.13 | tok/s 13644
step   2680 | loss 1.3849 | lr 3.00e-04 | grad 1.28 | tok/s 13390
step   2690 | loss 1.3211 | lr 3.00e-04 | grad 1.27 | tok/s 13157
step   2700 | loss 1.3966 | lr 3.00e-04 | grad 1.11 | tok/s 13594
step   2710 | loss 1.6656 | lr 3.00e-04 | grad 1.54 | tok/s 13487
step   2720 | loss 1.3403 | lr 3.00e-04 | grad 1.25 | tok/s 13700
step   2730 | loss 1.3103 | lr 3.00e-04 | grad 2.44 | tok/s 13494
step   2740 | loss 1.4248 | lr 3.00e-04 | grad 1.92 | tok/s 13456
step   2750 | loss 1.3787 | lr 3.00e-04 | grad 1.36 | tok/s 13678
step   2760 | loss 1.2181 | lr 3.00e-04 | grad 0.99 | tok/s 13790
step   2770 | loss 1.3446 | lr 3.00e-04 | grad 1.25 | tok/s 13581
step   2780 | loss 1.3058 | lr 3.00e-04 | grad 2.22 | tok/s 13813
step   2790 | loss 1.4356 | lr 3.00e-04 | grad 2.20 | tok/s 13447
step   2800 | loss 1.4561 | lr 3.00e-04 | grad 2.47 | tok/s 13067
step   2810 | loss 1.3833 | lr 3.00e-04 | grad 1.41 | tok/s 13591
step   2820 | loss 1.3505 | lr 3.00e-04 | grad 2.03 | tok/s 12727
step   2830 | loss 1.2686 | lr 3.00e-04 | grad 0.96 | tok/s 13507
step   2840 | loss 1.1927 | lr 3.00e-04 | grad 1.27 | tok/s 13326
step   2850 | loss 1.1685 | lr 3.00e-04 | grad 0.85 | tok/s 14096
step   2860 | loss 1.1907 | lr 3.00e-04 | grad 1.73 | tok/s 13712
step   2870 | loss 1.3502 | lr 3.00e-04 | grad 1.16 | tok/s 13362
step   2880 | loss 1.4016 | lr 3.00e-04 | grad 1.19 | tok/s 13224
step   2890 | loss 1.5610 | lr 3.00e-04 | grad 3.75 | tok/s 13645
step   2900 | loss 1.4159 | lr 3.00e-04 | grad 1.55 | tok/s 13203
step   2910 | loss 1.3362 | lr 3.00e-04 | grad 1.36 | tok/s 13873
step   2920 | loss 1.2511 | lr 3.00e-04 | grad 1.88 | tok/s 13359
step   2930 | loss 1.3937 | lr 3.00e-04 | grad 1.47 | tok/s 13785
step   2940 | loss 1.2458 | lr 3.00e-04 | grad 0.99 | tok/s 13495
step   2950 | loss 1.6584 | lr 3.00e-04 | grad 0.99 | tok/s 13606
step   2960 | loss 1.5371 | lr 3.00e-04 | grad 1.27 | tok/s 13110
step   2970 | loss 1.4358 | lr 3.00e-04 | grad 1.13 | tok/s 13588
step   2980 | loss 1.3319 | lr 3.00e-04 | grad 1.07 | tok/s 13757
step   2990 | loss 1.4640 | lr 3.00e-04 | grad 1.51 | tok/s 13650
step   3000 | loss 1.3382 | lr 3.00e-04 | grad 1.80 | tok/s 13728
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3382.pt
step   3010 | loss 1.4597 | lr 3.00e-04 | grad 2.38 | tok/s 8796
step   3020 | loss 1.3253 | lr 3.00e-04 | grad 1.43 | tok/s 13471
step   3030 | loss 1.2713 | lr 3.00e-04 | grad 1.28 | tok/s 13215
step   3040 | loss 1.2994 | lr 3.00e-04 | grad 1.20 | tok/s 13659
step   3050 | loss 1.2003 | lr 3.00e-04 | grad 0.93 | tok/s 14060

Training complete! Final step: 3056
