Using device: cuda
Output directory: benchmark_results/cmaes_converge/e1_480M_converge0.01_20260201_200250/eval_6/level1_100m_20260201_200257
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 473,872,768 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 30.0 minutes
step     10 | loss 6.0219 | lr 3.00e-04 | grad 7.69 | tok/s 8980
step     20 | loss 3.0822 | lr 3.00e-04 | grad 4.69 | tok/s 15926
step     30 | loss 3.1333 | lr 3.00e-04 | grad 4.12 | tok/s 16844
step     40 | loss 4.3722 | lr 3.00e-04 | grad 11.00 | tok/s 17210
step     50 | loss 4.6357 | lr 3.00e-04 | grad 9.94 | tok/s 17407
step     60 | loss 3.2518 | lr 3.00e-04 | grad 3.98 | tok/s 17415
step     70 | loss 2.8113 | lr 3.00e-04 | grad 5.25 | tok/s 17389
step     80 | loss 2.5581 | lr 3.00e-04 | grad 4.09 | tok/s 17381
step     90 | loss 2.4993 | lr 3.00e-04 | grad 3.17 | tok/s 17385
step    100 | loss 2.3068 | lr 3.00e-04 | grad 2.44 | tok/s 17401
step    110 | loss 2.4783 | lr 3.00e-04 | grad 4.31 | tok/s 17251
step    120 | loss 3.0689 | lr 3.00e-04 | grad 3.39 | tok/s 16418
step    130 | loss 2.3915 | lr 3.00e-04 | grad 5.09 | tok/s 16799
step    140 | loss 2.6235 | lr 3.00e-04 | grad 8.94 | tok/s 16858
step    150 | loss 2.0461 | lr 3.00e-04 | grad 5.53 | tok/s 17258
step    160 | loss 2.5755 | lr 3.00e-04 | grad 2.06 | tok/s 16696
step    170 | loss 2.4563 | lr 3.00e-04 | grad 3.73 | tok/s 16453
step    180 | loss 2.3127 | lr 3.00e-04 | grad 2.59 | tok/s 16830
step    190 | loss 2.1571 | lr 3.00e-04 | grad 3.30 | tok/s 16525
step    200 | loss 1.9951 | lr 3.00e-04 | grad 2.50 | tok/s 17296
step    210 | loss 2.1149 | lr 3.00e-04 | grad 4.47 | tok/s 16394
step    220 | loss 2.3960 | lr 3.00e-04 | grad 3.45 | tok/s 16573
step    230 | loss 2.2894 | lr 3.00e-04 | grad 2.30 | tok/s 16556
step    240 | loss 2.4688 | lr 3.00e-04 | grad 3.98 | tok/s 16765
step    250 | loss 2.0167 | lr 3.00e-04 | grad 2.27 | tok/s 16664
step    260 | loss 2.1066 | lr 3.00e-04 | grad 2.75 | tok/s 17128
step    270 | loss 2.0234 | lr 3.00e-04 | grad 2.66 | tok/s 16741
step    280 | loss 1.9751 | lr 3.00e-04 | grad 1.72 | tok/s 15711
step    290 | loss 1.9009 | lr 3.00e-04 | grad 2.23 | tok/s 16270
step    300 | loss 2.1412 | lr 3.00e-04 | grad 2.84 | tok/s 16385
step    310 | loss 1.8451 | lr 3.00e-04 | grad 1.65 | tok/s 16293
step    320 | loss 2.0698 | lr 3.00e-04 | grad 2.30 | tok/s 16485
step    330 | loss 1.8917 | lr 3.00e-04 | grad 2.03 | tok/s 16665
step    340 | loss 2.1706 | lr 3.00e-04 | grad 1.75 | tok/s 16611
step    350 | loss 1.9328 | lr 3.00e-04 | grad 1.79 | tok/s 17073
step    360 | loss 1.7387 | lr 3.00e-04 | grad 1.75 | tok/s 16331
step    370 | loss 1.6836 | lr 3.00e-04 | grad 1.82 | tok/s 17215
step    380 | loss 1.4109 | lr 3.00e-04 | grad 1.80 | tok/s 17362
step    390 | loss 1.3206 | lr 3.00e-04 | grad 2.11 | tok/s 17365
step    400 | loss 1.9067 | lr 3.00e-04 | grad 1.48 | tok/s 16463
step    410 | loss 1.8896 | lr 3.00e-04 | grad 1.84 | tok/s 16625
step    420 | loss 1.7687 | lr 3.00e-04 | grad 1.87 | tok/s 17322
step    430 | loss 1.7033 | lr 3.00e-04 | grad 2.28 | tok/s 17021
step    440 | loss 1.8325 | lr 3.00e-04 | grad 2.17 | tok/s 16509
step    450 | loss 1.7376 | lr 3.00e-04 | grad 1.51 | tok/s 16701
step    460 | loss 1.7129 | lr 3.00e-04 | grad 1.58 | tok/s 16951
step    470 | loss 1.7072 | lr 3.00e-04 | grad 2.88 | tok/s 16792
step    480 | loss 1.6769 | lr 3.00e-04 | grad 2.42 | tok/s 17172
step    490 | loss 1.7901 | lr 3.00e-04 | grad 1.91 | tok/s 16501
step    500 | loss 1.9453 | lr 3.00e-04 | grad 1.59 | tok/s 16761
step    510 | loss 1.7992 | lr 3.00e-04 | grad 1.66 | tok/s 16024
step    520 | loss 1.6425 | lr 3.00e-04 | grad 1.66 | tok/s 16768
step    530 | loss 1.8092 | lr 3.00e-04 | grad 1.47 | tok/s 16501
step    540 | loss 1.6863 | lr 3.00e-04 | grad 1.16 | tok/s 16159
step    550 | loss 1.4460 | lr 3.00e-04 | grad 2.94 | tok/s 16883
step    560 | loss 1.5236 | lr 3.00e-04 | grad 1.79 | tok/s 17373
step    570 | loss 1.4273 | lr 3.00e-04 | grad 1.88 | tok/s 17359
step    580 | loss 1.3820 | lr 3.00e-04 | grad 1.23 | tok/s 17360
step    590 | loss 1.4182 | lr 3.00e-04 | grad 1.62 | tok/s 17378
step    600 | loss 1.3621 | lr 3.00e-04 | grad 1.52 | tok/s 17349
step    610 | loss 1.3920 | lr 3.00e-04 | grad 1.63 | tok/s 17359
step    620 | loss 1.3866 | lr 3.00e-04 | grad 1.79 | tok/s 17279
step    630 | loss 1.8105 | lr 3.00e-04 | grad 5.19 | tok/s 16359
step    640 | loss 1.7993 | lr 3.00e-04 | grad 1.74 | tok/s 16571
step    650 | loss 1.6306 | lr 3.00e-04 | grad 1.54 | tok/s 16545
step    660 | loss 1.6709 | lr 3.00e-04 | grad 1.53 | tok/s 17194
step    670 | loss 1.7207 | lr 3.00e-04 | grad 4.25 | tok/s 16616
step    680 | loss 1.7293 | lr 3.00e-04 | grad 2.02 | tok/s 16340
step    690 | loss 1.6844 | lr 3.00e-04 | grad 1.52 | tok/s 16218
step    700 | loss 1.5531 | lr 3.00e-04 | grad 1.18 | tok/s 16573
step    710 | loss 1.7435 | lr 3.00e-04 | grad 2.64 | tok/s 16319
step    720 | loss 1.3982 | lr 3.00e-04 | grad 1.66 | tok/s 16965
step    730 | loss 1.5562 | lr 3.00e-04 | grad 1.33 | tok/s 16689
step    740 | loss 1.8591 | lr 3.00e-04 | grad 3.64 | tok/s 17135
step    750 | loss 1.6207 | lr 3.00e-04 | grad 1.61 | tok/s 17343
step    760 | loss 1.6010 | lr 3.00e-04 | grad 2.81 | tok/s 16960
step    770 | loss 1.6278 | lr 3.00e-04 | grad 1.72 | tok/s 16668
step    780 | loss 1.5699 | lr 3.00e-04 | grad 1.73 | tok/s 16801
step    790 | loss 1.7274 | lr 3.00e-04 | grad 4.00 | tok/s 17180
step    800 | loss 1.4081 | lr 3.00e-04 | grad 0.96 | tok/s 16879
step    810 | loss 1.4014 | lr 3.00e-04 | grad 2.19 | tok/s 16311
step    820 | loss 1.5282 | lr 3.00e-04 | grad 1.86 | tok/s 16638
step    830 | loss 1.5690 | lr 3.00e-04 | grad 1.20 | tok/s 16416
step    840 | loss 1.7271 | lr 3.00e-04 | grad 1.69 | tok/s 16330
step    850 | loss 1.6150 | lr 3.00e-04 | grad 1.28 | tok/s 16685
step    860 | loss 1.6901 | lr 3.00e-04 | grad 2.12 | tok/s 16964
step    870 | loss 1.5138 | lr 3.00e-04 | grad 1.52 | tok/s 17088
step    880 | loss 1.6502 | lr 3.00e-04 | grad 1.65 | tok/s 16750
step    890 | loss 1.5436 | lr 3.00e-04 | grad 1.20 | tok/s 16668
step    900 | loss 1.5978 | lr 3.00e-04 | grad 1.26 | tok/s 16610
step    910 | loss 1.5970 | lr 3.00e-04 | grad 4.12 | tok/s 16418
step    920 | loss 1.5599 | lr 3.00e-04 | grad 1.58 | tok/s 16601
step    930 | loss 1.4567 | lr 3.00e-04 | grad 1.61 | tok/s 16824
step    940 | loss 1.4433 | lr 3.00e-04 | grad 1.59 | tok/s 16435
step    950 | loss 1.5441 | lr 3.00e-04 | grad 2.11 | tok/s 16182
step    960 | loss 1.4999 | lr 3.00e-04 | grad 1.45 | tok/s 16620
step    970 | loss 1.5216 | lr 3.00e-04 | grad 1.45 | tok/s 16623
step    980 | loss 1.9556 | lr 3.00e-04 | grad 3.02 | tok/s 17290
step    990 | loss 1.6526 | lr 3.00e-04 | grad 1.46 | tok/s 16563
step   1000 | loss 1.6372 | lr 3.00e-04 | grad 1.91 | tok/s 16633
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6372.pt
step   1010 | loss 1.4293 | lr 3.00e-04 | grad 1.51 | tok/s 9642
step   1020 | loss 1.2786 | lr 3.00e-04 | grad 1.36 | tok/s 17440
step   1030 | loss 1.6620 | lr 3.00e-04 | grad 1.61 | tok/s 16480
step   1040 | loss 2.1670 | lr 3.00e-04 | grad 4.41 | tok/s 17020
step   1050 | loss 1.5670 | lr 3.00e-04 | grad 1.59 | tok/s 16816
step   1060 | loss 1.1633 | lr 3.00e-04 | grad 1.67 | tok/s 17110
step   1070 | loss 1.5521 | lr 3.00e-04 | grad 1.62 | tok/s 16801
step   1080 | loss 1.3213 | lr 3.00e-04 | grad 1.70 | tok/s 17385
step   1090 | loss 1.2948 | lr 3.00e-04 | grad 1.72 | tok/s 17387
step   1100 | loss 1.2519 | lr 3.00e-04 | grad 1.73 | tok/s 17328
step   1110 | loss 1.2477 | lr 3.00e-04 | grad 1.51 | tok/s 17372
step   1120 | loss 1.5599 | lr 3.00e-04 | grad 3.17 | tok/s 16879
step   1130 | loss 1.7204 | lr 3.00e-04 | grad 2.11 | tok/s 17062
step   1140 | loss 1.7857 | lr 3.00e-04 | grad 1.36 | tok/s 17274
step   1150 | loss 1.7992 | lr 3.00e-04 | grad 1.93 | tok/s 16400
step   1160 | loss 1.8569 | lr 3.00e-04 | grad 6.69 | tok/s 16634
step   1170 | loss 1.5071 | lr 3.00e-04 | grad 1.41 | tok/s 16405
step   1180 | loss 1.4214 | lr 3.00e-04 | grad 2.36 | tok/s 17000
step   1190 | loss 1.6132 | lr 3.00e-04 | grad 2.94 | tok/s 17340
step   1200 | loss 1.2148 | lr 3.00e-04 | grad 2.61 | tok/s 17350
step   1210 | loss 1.5107 | lr 3.00e-04 | grad 1.88 | tok/s 16150
step   1220 | loss 1.4336 | lr 3.00e-04 | grad 1.38 | tok/s 16810
step   1230 | loss 1.3829 | lr 3.00e-04 | grad 1.08 | tok/s 17199
step   1240 | loss 1.3682 | lr 3.00e-04 | grad 1.21 | tok/s 16957
step   1250 | loss 1.5542 | lr 3.00e-04 | grad 2.41 | tok/s 16985
step   1260 | loss 1.4757 | lr 3.00e-04 | grad 1.84 | tok/s 17119
step   1270 | loss 1.4406 | lr 3.00e-04 | grad 1.36 | tok/s 16795
step   1280 | loss 1.4851 | lr 3.00e-04 | grad 1.60 | tok/s 16533
step   1290 | loss 1.3941 | lr 3.00e-04 | grad 1.34 | tok/s 16594
step   1300 | loss 1.7294 | lr 3.00e-04 | grad 3.34 | tok/s 16307
step   1310 | loss 1.5530 | lr 3.00e-04 | grad 1.42 | tok/s 16910
step   1320 | loss 1.5907 | lr 3.00e-04 | grad 2.45 | tok/s 17025
step   1330 | loss 1.4392 | lr 3.00e-04 | grad 1.64 | tok/s 16806
step   1340 | loss 1.6950 | lr 3.00e-04 | grad 1.63 | tok/s 16488
step   1350 | loss 1.5226 | lr 3.00e-04 | grad 3.30 | tok/s 16715
step   1360 | loss 1.4626 | lr 3.00e-04 | grad 1.37 | tok/s 16285
step   1370 | loss 1.7515 | lr 3.00e-04 | grad 2.72 | tok/s 17065
step   1380 | loss 1.4734 | lr 3.00e-04 | grad 2.17 | tok/s 16254
step   1390 | loss 1.4128 | lr 3.00e-04 | grad 1.93 | tok/s 17108
step   1400 | loss 1.6172 | lr 3.00e-04 | grad 1.23 | tok/s 16532
step   1410 | loss 1.5036 | lr 3.00e-04 | grad 2.19 | tok/s 16158
step   1420 | loss 1.3515 | lr 3.00e-04 | grad 6.22 | tok/s 17183
step   1430 | loss 1.6585 | lr 3.00e-04 | grad 2.42 | tok/s 16515
step   1440 | loss 1.5059 | lr 3.00e-04 | grad 1.65 | tok/s 17027
step   1450 | loss 1.5733 | lr 3.00e-04 | grad 1.87 | tok/s 16904
step   1460 | loss 1.6600 | lr 3.00e-04 | grad 3.45 | tok/s 16531
step   1470 | loss 1.3796 | lr 3.00e-04 | grad 1.70 | tok/s 15986
step   1480 | loss 1.4556 | lr 3.00e-04 | grad 2.31 | tok/s 17094
step   1490 | loss 1.9739 | lr 3.00e-04 | grad 2.80 | tok/s 16656
step   1500 | loss 1.4827 | lr 3.00e-04 | grad 1.60 | tok/s 16809
step   1510 | loss 1.3092 | lr 3.00e-04 | grad 1.20 | tok/s 16666
step   1520 | loss 1.5368 | lr 3.00e-04 | grad 1.79 | tok/s 16727
step   1530 | loss 1.4643 | lr 3.00e-04 | grad 2.16 | tok/s 16878
step   1540 | loss 1.5645 | lr 3.00e-04 | grad 1.42 | tok/s 17042
step   1550 | loss 1.5364 | lr 3.00e-04 | grad 2.22 | tok/s 16727
step   1560 | loss 1.1888 | lr 3.00e-04 | grad 1.26 | tok/s 17341
step   1570 | loss 1.3600 | lr 3.00e-04 | grad 1.12 | tok/s 16877
step   1580 | loss 1.4791 | lr 3.00e-04 | grad 6.50 | tok/s 16785
step   1590 | loss 1.4189 | lr 3.00e-04 | grad 1.45 | tok/s 16504
step   1600 | loss 1.3532 | lr 3.00e-04 | grad 1.93 | tok/s 16907
step   1610 | loss 2.0466 | lr 3.00e-04 | grad 2.02 | tok/s 17111
step   1620 | loss 1.7742 | lr 3.00e-04 | grad 2.23 | tok/s 17356
step   1630 | loss 1.5545 | lr 3.00e-04 | grad 2.09 | tok/s 17349
step   1640 | loss 1.4332 | lr 3.00e-04 | grad 1.99 | tok/s 17342
step   1650 | loss 1.3770 | lr 3.00e-04 | grad 1.91 | tok/s 17330
step   1660 | loss 1.3302 | lr 3.00e-04 | grad 1.89 | tok/s 17355
step   1670 | loss 1.5747 | lr 3.00e-04 | grad 2.20 | tok/s 16784
step   1680 | loss 1.4533 | lr 3.00e-04 | grad 1.36 | tok/s 16332
step   1690 | loss 1.5256 | lr 3.00e-04 | grad 1.12 | tok/s 16441
step   1700 | loss 1.3369 | lr 3.00e-04 | grad 1.27 | tok/s 17067
step   1710 | loss 1.3798 | lr 3.00e-04 | grad 1.48 | tok/s 16756
step   1720 | loss 1.4992 | lr 3.00e-04 | grad 1.52 | tok/s 16656
step   1730 | loss 1.4974 | lr 3.00e-04 | grad 1.30 | tok/s 16821
step   1740 | loss 1.4400 | lr 3.00e-04 | grad 1.30 | tok/s 17170
step   1750 | loss 1.2910 | lr 3.00e-04 | grad 1.70 | tok/s 16469
step   1760 | loss 1.5347 | lr 3.00e-04 | grad 2.83 | tok/s 16566
step   1770 | loss 1.6475 | lr 3.00e-04 | grad 1.84 | tok/s 16919
step   1780 | loss 1.8011 | lr 3.00e-04 | grad 2.36 | tok/s 15932
step   1790 | loss 1.3369 | lr 3.00e-04 | grad 3.92 | tok/s 16466
step   1800 | loss 1.4171 | lr 3.00e-04 | grad 1.70 | tok/s 16416
step   1810 | loss 1.4242 | lr 3.00e-04 | grad 1.71 | tok/s 16805
step   1820 | loss 1.5792 | lr 3.00e-04 | grad 1.52 | tok/s 16372
step   1830 | loss 1.4380 | lr 3.00e-04 | grad 1.43 | tok/s 16184
step   1840 | loss 1.4026 | lr 3.00e-04 | grad 1.33 | tok/s 16803
step   1850 | loss 1.4534 | lr 3.00e-04 | grad 2.62 | tok/s 16250
step   1860 | loss 1.5352 | lr 3.00e-04 | grad 2.69 | tok/s 16756
step   1870 | loss 1.4366 | lr 3.00e-04 | grad 1.21 | tok/s 16814
step   1880 | loss 1.5606 | lr 3.00e-04 | grad 1.49 | tok/s 16958
step   1890 | loss 1.2879 | lr 3.00e-04 | grad 1.34 | tok/s 17337
step   1900 | loss 1.2422 | lr 3.00e-04 | grad 1.35 | tok/s 17346
step   1910 | loss 1.2169 | lr 3.00e-04 | grad 1.25 | tok/s 17365
step   1920 | loss 1.2090 | lr 3.00e-04 | grad 1.26 | tok/s 17351
step   1930 | loss 1.3045 | lr 3.00e-04 | grad 1.57 | tok/s 17062
step   1940 | loss 1.5785 | lr 3.00e-04 | grad 1.45 | tok/s 16428
step   1950 | loss 1.5291 | lr 3.00e-04 | grad 2.02 | tok/s 16365
step   1960 | loss 1.5474 | lr 3.00e-04 | grad 3.59 | tok/s 16507
step   1970 | loss 1.5330 | lr 3.00e-04 | grad 1.40 | tok/s 16784
step   1980 | loss 1.4723 | lr 3.00e-04 | grad 1.59 | tok/s 16576
step   1990 | loss 1.5883 | lr 3.00e-04 | grad 1.91 | tok/s 16748
step   2000 | loss 1.1400 | lr 3.00e-04 | grad 1.44 | tok/s 17400
  >>> saved checkpoint: checkpoint_step_002000_loss_1.1400.pt
step   2010 | loss 1.4188 | lr 3.00e-04 | grad 1.84 | tok/s 9324
step   2020 | loss 1.4365 | lr 3.00e-04 | grad 1.36 | tok/s 16556
step   2030 | loss 1.8858 | lr 3.00e-04 | grad 1.92 | tok/s 16268
step   2040 | loss 1.4407 | lr 3.00e-04 | grad 1.34 | tok/s 16887
step   2050 | loss 1.4284 | lr 3.00e-04 | grad 2.39 | tok/s 16655
step   2060 | loss 1.6733 | lr 3.00e-04 | grad 2.17 | tok/s 16724
step   2070 | loss 1.1719 | lr 3.00e-04 | grad 1.10 | tok/s 16727
step   2080 | loss 1.2986 | lr 3.00e-04 | grad 0.91 | tok/s 16411
step   2090 | loss 1.5856 | lr 3.00e-04 | grad 2.31 | tok/s 17064
step   2100 | loss 1.5782 | lr 3.00e-04 | grad 1.30 | tok/s 17045
step   2110 | loss 1.4406 | lr 3.00e-04 | grad 1.33 | tok/s 16569
step   2120 | loss 2.2027 | lr 3.00e-04 | grad 1.85 | tok/s 16885
step   2130 | loss 1.5183 | lr 3.00e-04 | grad 2.16 | tok/s 16319
step   2140 | loss 1.5294 | lr 3.00e-04 | grad 1.87 | tok/s 16620
step   2150 | loss 1.7268 | lr 3.00e-04 | grad 1.77 | tok/s 16988
step   2160 | loss 1.4980 | lr 3.00e-04 | grad 1.61 | tok/s 16670
step   2170 | loss 1.5558 | lr 3.00e-04 | grad 3.09 | tok/s 17014
step   2180 | loss 1.2259 | lr 3.00e-04 | grad 1.59 | tok/s 17300
step   2190 | loss 1.5747 | lr 3.00e-04 | grad 2.00 | tok/s 16583
step   2200 | loss 1.2191 | lr 3.00e-04 | grad 2.53 | tok/s 17328
step   2210 | loss 1.5182 | lr 3.00e-04 | grad 1.60 | tok/s 16758
step   2220 | loss 1.5131 | lr 3.00e-04 | grad 1.39 | tok/s 16132
step   2230 | loss 1.6444 | lr 3.00e-04 | grad 1.20 | tok/s 16703
step   2240 | loss 1.4127 | lr 3.00e-04 | grad 2.14 | tok/s 16849
step   2250 | loss 1.3980 | lr 3.00e-04 | grad 1.39 | tok/s 16533
step   2260 | loss 1.6912 | lr 3.00e-04 | grad 4.84 | tok/s 16830
step   2270 | loss 1.6395 | lr 3.00e-04 | grad 1.46 | tok/s 15893
step   2280 | loss 1.4547 | lr 3.00e-04 | grad 2.72 | tok/s 16905
step   2290 | loss 1.3287 | lr 3.00e-04 | grad 1.68 | tok/s 16240
step   2300 | loss 1.8058 | lr 3.00e-04 | grad 2.19 | tok/s 16479
step   2310 | loss 1.3681 | lr 3.00e-04 | grad 1.38 | tok/s 16960
step   2320 | loss 1.3801 | lr 3.00e-04 | grad 1.38 | tok/s 17347
step   2330 | loss 1.3055 | lr 3.00e-04 | grad 1.62 | tok/s 17355
step   2340 | loss 1.2785 | lr 3.00e-04 | grad 1.46 | tok/s 17368
step   2350 | loss 1.2633 | lr 3.00e-04 | grad 1.38 | tok/s 17340
step   2360 | loss 1.1964 | lr 3.00e-04 | grad 1.43 | tok/s 17359
step   2370 | loss 1.2148 | lr 3.00e-04 | grad 1.51 | tok/s 17343
step   2380 | loss 1.1991 | lr 3.00e-04 | grad 1.52 | tok/s 17350
step   2390 | loss 1.2101 | lr 3.00e-04 | grad 1.23 | tok/s 17365
step   2400 | loss 1.1627 | lr 3.00e-04 | grad 1.27 | tok/s 17362
step   2410 | loss 1.4912 | lr 3.00e-04 | grad 8.44 | tok/s 17056
step   2420 | loss 1.1309 | lr 3.00e-04 | grad 0.60 | tok/s 17126
step   2430 | loss 1.3433 | lr 3.00e-04 | grad 1.70 | tok/s 16268
step   2440 | loss 1.4160 | lr 3.00e-04 | grad 1.07 | tok/s 16329
step   2450 | loss 1.3934 | lr 3.00e-04 | grad 1.60 | tok/s 16784
step   2460 | loss 1.5670 | lr 3.00e-04 | grad 1.16 | tok/s 17009
step   2470 | loss 1.3907 | lr 3.00e-04 | grad 1.50 | tok/s 16472
step   2480 | loss 1.5186 | lr 3.00e-04 | grad 2.06 | tok/s 17098
step   2490 | loss 1.5848 | lr 3.00e-04 | grad 3.72 | tok/s 16442
step   2500 | loss 1.6479 | lr 3.00e-04 | grad 1.97 | tok/s 16970
step   2510 | loss 1.4748 | lr 3.00e-04 | grad 1.47 | tok/s 16604
step   2520 | loss 1.4299 | lr 3.00e-04 | grad 1.67 | tok/s 16672
step   2530 | loss 1.6067 | lr 3.00e-04 | grad 1.79 | tok/s 16837
step   2540 | loss 1.4986 | lr 3.00e-04 | grad 2.61 | tok/s 16148
step   2550 | loss 1.4644 | lr 3.00e-04 | grad 4.69 | tok/s 16646
step   2560 | loss 1.5210 | lr 3.00e-04 | grad 1.26 | tok/s 16417
step   2570 | loss 1.4186 | lr 3.00e-04 | grad 1.26 | tok/s 16710
step   2580 | loss 1.5985 | lr 3.00e-04 | grad 1.38 | tok/s 16363
step   2590 | loss 1.3768 | lr 3.00e-04 | grad 1.19 | tok/s 16096
step   2600 | loss 1.5156 | lr 3.00e-04 | grad 1.28 | tok/s 16832
step   2610 | loss 1.3828 | lr 3.00e-04 | grad 1.48 | tok/s 16992
step   2620 | loss 1.5944 | lr 3.00e-04 | grad 1.29 | tok/s 16574
step   2630 | loss 1.1857 | lr 3.00e-04 | grad 1.67 | tok/s 17059
step   2640 | loss 1.4250 | lr 3.00e-04 | grad 1.65 | tok/s 16278
step   2650 | loss 1.2550 | lr 3.00e-04 | grad 1.36 | tok/s 16740
step   2660 | loss 1.4027 | lr 3.00e-04 | grad 0.96 | tok/s 17103
step   2670 | loss 1.2442 | lr 3.00e-04 | grad 1.59 | tok/s 16695
step   2680 | loss 1.4228 | lr 3.00e-04 | grad 1.20 | tok/s 16443
step   2690 | loss 1.3721 | lr 3.00e-04 | grad 1.41 | tok/s 16194
step   2700 | loss 1.4612 | lr 3.00e-04 | grad 2.33 | tok/s 16886
step   2710 | loss 1.7329 | lr 3.00e-04 | grad 2.45 | tok/s 16442
step   2720 | loss 1.3740 | lr 3.00e-04 | grad 1.59 | tok/s 16804
step   2730 | loss 1.3860 | lr 3.00e-04 | grad 2.34 | tok/s 16848
step   2740 | loss 1.4345 | lr 3.00e-04 | grad 1.06 | tok/s 16249
step   2750 | loss 1.4409 | lr 3.00e-04 | grad 3.45 | tok/s 17145
step   2760 | loss 1.2964 | lr 3.00e-04 | grad 1.62 | tok/s 16729
step   2770 | loss 1.3938 | lr 3.00e-04 | grad 1.71 | tok/s 16963
step   2780 | loss 1.3536 | lr 3.00e-04 | grad 1.83 | tok/s 17009
step   2790 | loss 1.5225 | lr 3.00e-04 | grad 1.38 | tok/s 16472
step   2800 | loss 1.5137 | lr 3.00e-04 | grad 4.88 | tok/s 16169
step   2810 | loss 1.4377 | lr 3.00e-04 | grad 1.59 | tok/s 16465
step   2820 | loss 1.3941 | lr 3.00e-04 | grad 1.25 | tok/s 15895
step   2830 | loss 1.3222 | lr 3.00e-04 | grad 1.71 | tok/s 16495
step   2840 | loss 1.2221 | lr 3.00e-04 | grad 1.31 | tok/s 16570
step   2850 | loss 1.2051 | lr 3.00e-04 | grad 1.32 | tok/s 17321
step   2860 | loss 1.2667 | lr 3.00e-04 | grad 1.10 | tok/s 16869
step   2870 | loss 1.4215 | lr 3.00e-04 | grad 1.54 | tok/s 16285
step   2880 | loss 1.4369 | lr 3.00e-04 | grad 1.51 | tok/s 16275
step   2890 | loss 1.6587 | lr 3.00e-04 | grad 1.75 | tok/s 16938
step   2900 | loss 1.4338 | lr 3.00e-04 | grad 1.54 | tok/s 16248
step   2910 | loss 1.3745 | lr 3.00e-04 | grad 1.35 | tok/s 16869
step   2920 | loss 1.2293 | lr 3.00e-04 | grad 1.80 | tok/s 16646
step   2930 | loss 1.5150 | lr 3.00e-04 | grad 1.18 | tok/s 16946
step   2940 | loss 1.3336 | lr 3.00e-04 | grad 1.60 | tok/s 16556
step   2950 | loss 1.7048 | lr 3.00e-04 | grad 1.44 | tok/s 16486
step   2960 | loss 1.6232 | lr 3.00e-04 | grad 1.54 | tok/s 16274
step   2970 | loss 1.4898 | lr 3.00e-04 | grad 1.08 | tok/s 16868
step   2980 | loss 1.3857 | lr 3.00e-04 | grad 1.34 | tok/s 16929
step   2990 | loss 1.5332 | lr 3.00e-04 | grad 1.48 | tok/s 16808
step   3000 | loss 1.3953 | lr 3.00e-04 | grad 1.64 | tok/s 16893
  >>> saved checkpoint: checkpoint_step_003000_loss_1.3953.pt
step   3010 | loss 1.4899 | lr 3.00e-04 | grad 1.21 | tok/s 10121
step   3020 | loss 1.3697 | lr 3.00e-04 | grad 1.44 | tok/s 16479
step   3030 | loss 1.3208 | lr 3.00e-04 | grad 1.39 | tok/s 16423
step   3040 | loss 1.3444 | lr 3.00e-04 | grad 1.62 | tok/s 16796
step   3050 | loss 1.2127 | lr 3.00e-04 | grad 1.05 | tok/s 17273
step   3060 | loss 1.6524 | lr 3.00e-04 | grad 1.96 | tok/s 16861
step   3070 | loss 2.0223 | lr 3.00e-04 | grad 3.81 | tok/s 16759
step   3080 | loss 1.4535 | lr 3.00e-04 | grad 1.70 | tok/s 16633
step   3090 | loss 1.4138 | lr 3.00e-04 | grad 1.09 | tok/s 16046
step   3100 | loss 1.3034 | lr 3.00e-04 | grad 1.44 | tok/s 17067
step   3110 | loss 1.4308 | lr 3.00e-04 | grad 1.42 | tok/s 17083
step   3120 | loss 1.4275 | lr 3.00e-04 | grad 1.54 | tok/s 16545
step   3130 | loss 1.3575 | lr 3.00e-04 | grad 1.19 | tok/s 16360
step   3140 | loss 1.3299 | lr 3.00e-04 | grad 1.55 | tok/s 16434
step   3150 | loss 1.4743 | lr 3.00e-04 | grad 5.00 | tok/s 15956
step   3160 | loss 1.4355 | lr 3.00e-04 | grad 1.91 | tok/s 17169
step   3170 | loss 1.2062 | lr 3.00e-04 | grad 1.02 | tok/s 17183
step   3180 | loss 1.3906 | lr 3.00e-04 | grad 3.16 | tok/s 16967
step   3190 | loss 1.5205 | lr 3.00e-04 | grad 1.50 | tok/s 16771
step   3200 | loss 1.3416 | lr 3.00e-04 | grad 1.88 | tok/s 16771
step   3210 | loss 1.4606 | lr 3.00e-04 | grad 2.02 | tok/s 16872
step   3220 | loss 1.3149 | lr 3.00e-04 | grad 1.42 | tok/s 17269
step   3230 | loss 1.3703 | lr 3.00e-04 | grad 1.41 | tok/s 15908
step   3240 | loss 1.3879 | lr 3.00e-04 | grad 2.39 | tok/s 16385
step   3250 | loss 1.3985 | lr 3.00e-04 | grad 2.58 | tok/s 16394
step   3260 | loss 1.3625 | lr 3.00e-04 | grad 1.03 | tok/s 16524
step   3270 | loss 1.4347 | lr 3.00e-04 | grad 3.66 | tok/s 16403
step   3280 | loss 1.4431 | lr 3.00e-04 | grad 1.48 | tok/s 16685
step   3290 | loss 1.2881 | lr 3.00e-04 | grad 1.35 | tok/s 16722
step   3300 | loss 1.4748 | lr 3.00e-04 | grad 2.05 | tok/s 17258
step   3310 | loss 1.9438 | lr 3.00e-04 | grad 2.55 | tok/s 16767
step   3320 | loss 1.4329 | lr 3.00e-04 | grad 1.21 | tok/s 16589
step   3330 | loss 1.3116 | lr 3.00e-04 | grad 1.16 | tok/s 16257
step   3340 | loss 1.1838 | lr 3.00e-04 | grad 2.17 | tok/s 17170
step   3350 | loss 1.4243 | lr 3.00e-04 | grad 2.03 | tok/s 17184
step   3360 | loss 1.4192 | lr 3.00e-04 | grad 1.23 | tok/s 16290
step   3370 | loss 1.5664 | lr 3.00e-04 | grad 1.16 | tok/s 16546
step   3380 | loss 1.4153 | lr 3.00e-04 | grad 1.59 | tok/s 16520
step   3390 | loss 1.3552 | lr 3.00e-04 | grad 2.73 | tok/s 16717
step   3400 | loss 1.3781 | lr 3.00e-04 | grad 1.44 | tok/s 16600
step   3410 | loss 1.5069 | lr 3.00e-04 | grad 1.68 | tok/s 16446
step   3420 | loss 1.5063 | lr 3.00e-04 | grad 1.32 | tok/s 16735
step   3430 | loss 1.4742 | lr 3.00e-04 | grad 3.30 | tok/s 16728
step   3440 | loss 1.3129 | lr 3.00e-04 | grad 1.67 | tok/s 16203
step   3450 | loss 1.4640 | lr 3.00e-04 | grad 2.30 | tok/s 16671
step   3460 | loss 1.4314 | lr 3.00e-04 | grad 2.41 | tok/s 16393
step   3470 | loss 1.5889 | lr 3.00e-04 | grad 1.17 | tok/s 16633
step   3480 | loss 1.3418 | lr 3.00e-04 | grad 2.08 | tok/s 16493
step   3490 | loss 1.6141 | lr 3.00e-04 | grad 4.03 | tok/s 16691
step   3500 | loss 1.4682 | lr 3.00e-04 | grad 1.40 | tok/s 16160
step   3510 | loss 1.3537 | lr 3.00e-04 | grad 1.23 | tok/s 16033
step   3520 | loss 1.4252 | lr 3.00e-04 | grad 1.98 | tok/s 17035
step   3530 | loss 1.5661 | lr 3.00e-04 | grad 2.22 | tok/s 16437
step   3540 | loss 1.4144 | lr 3.00e-04 | grad 1.69 | tok/s 16222
step   3550 | loss 1.3409 | lr 3.00e-04 | grad 1.41 | tok/s 16976
step   3560 | loss 1.4863 | lr 3.00e-04 | grad 1.77 | tok/s 16749
step   3570 | loss 1.2603 | lr 3.00e-04 | grad 1.45 | tok/s 17330
step   3580 | loss 1.2918 | lr 3.00e-04 | grad 1.48 | tok/s 16409
step   3590 | loss 1.3971 | lr 3.00e-04 | grad 1.56 | tok/s 16111
step   3600 | loss 1.2687 | lr 3.00e-04 | grad 1.17 | tok/s 16700
step   3610 | loss 1.5158 | lr 3.00e-04 | grad 1.43 | tok/s 16778
step   3620 | loss 1.3637 | lr 3.00e-04 | grad 1.16 | tok/s 15990
step   3630 | loss 1.3871 | lr 3.00e-04 | grad 1.76 | tok/s 16917
step   3640 | loss 1.6172 | lr 3.00e-04 | grad 1.19 | tok/s 16146
step   3650 | loss 1.5360 | lr 3.00e-04 | grad 1.54 | tok/s 16565
step   3660 | loss 1.4427 | lr 3.00e-04 | grad 1.34 | tok/s 16195
step   3670 | loss 1.3230 | lr 3.00e-04 | grad 1.43 | tok/s 16828
step   3680 | loss 1.3282 | lr 3.00e-04 | grad 1.36 | tok/s 16277
step   3690 | loss 1.3499 | lr 3.00e-04 | grad 1.09 | tok/s 17123
step   3700 | loss 1.2754 | lr 3.00e-04 | grad 1.08 | tok/s 16909
step   3710 | loss 1.3717 | lr 3.00e-04 | grad 1.27 | tok/s 16888
step   3720 | loss 1.4148 | lr 3.00e-04 | grad 1.14 | tok/s 16941
step   3730 | loss 1.5160 | lr 3.00e-04 | grad 2.12 | tok/s 16531
step   3740 | loss 1.4823 | lr 3.00e-04 | grad 1.83 | tok/s 16585
step   3750 | loss 1.3196 | lr 3.00e-04 | grad 1.64 | tok/s 16963

Training complete! Final step: 3754
