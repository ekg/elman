Using device: cuda
Output directory: benchmark_results/e88_scaling/dim1536/levelE88_dim1536_100m_20260122_222613
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88_dim1536, 476,023,552 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 4.0541 | lr 3.00e-04 | grad 15.25 | tok/s 7970
step     20 | loss 3.5160 | lr 3.00e-04 | grad 34.75 | tok/s 10128
step     30 | loss 4.5679 | lr 3.00e-04 | grad 15.38 | tok/s 10562
step     40 | loss 3.4727 | lr 3.00e-04 | grad 9.38 | tok/s 10360
step     50 | loss 2.8328 | lr 3.00e-04 | grad 4.62 | tok/s 10183
step     60 | loss 3.1627 | lr 3.00e-04 | grad 4.28 | tok/s 9857
step     70 | loss 2.6821 | lr 3.00e-04 | grad 2.86 | tok/s 9422
step     80 | loss 2.5304 | lr 3.00e-04 | grad 4.19 | tok/s 9757
step     90 | loss 2.6690 | lr 3.00e-04 | grad 11.06 | tok/s 9392
step    100 | loss 2.3616 | lr 3.00e-04 | grad 3.31 | tok/s 9453
step    110 | loss 2.3365 | lr 3.00e-04 | grad 2.44 | tok/s 9311
step    120 | loss 2.3611 | lr 3.00e-04 | grad 2.69 | tok/s 9149
step    130 | loss 2.3571 | lr 3.00e-04 | grad 2.12 | tok/s 9358
step    140 | loss 2.1511 | lr 3.00e-04 | grad 1.89 | tok/s 9380
step    150 | loss 2.0399 | lr 3.00e-04 | grad 2.27 | tok/s 8939
step    160 | loss 1.9818 | lr 3.00e-04 | grad 1.79 | tok/s 9014
step    170 | loss 2.1569 | lr 3.00e-04 | grad 14.06 | tok/s 9321
step    180 | loss 2.0915 | lr 3.00e-04 | grad 1.22 | tok/s 9353
step    190 | loss 1.8374 | lr 3.00e-04 | grad 1.95 | tok/s 9510
step    200 | loss 1.5022 | lr 3.00e-04 | grad 1.52 | tok/s 9721
step    210 | loss 2.0103 | lr 3.00e-04 | grad 1.87 | tok/s 9327
step    220 | loss 1.8978 | lr 3.00e-04 | grad 1.95 | tok/s 9632
step    230 | loss 1.8499 | lr 3.00e-04 | grad 2.64 | tok/s 9309
step    240 | loss 1.8169 | lr 3.00e-04 | grad 2.06 | tok/s 9487
step    250 | loss 1.7891 | lr 3.00e-04 | grad 1.67 | tok/s 9353
step    260 | loss 1.8697 | lr 3.00e-04 | grad 1.35 | tok/s 8985
step    270 | loss 1.7839 | lr 3.00e-04 | grad 1.28 | tok/s 9315
step    280 | loss 1.6642 | lr 3.00e-04 | grad 2.09 | tok/s 9295
step    290 | loss 1.5726 | lr 3.00e-04 | grad 1.43 | tok/s 9805
step    300 | loss 1.4958 | lr 3.00e-04 | grad 1.41 | tok/s 9807
step    310 | loss 1.4472 | lr 3.00e-04 | grad 1.36 | tok/s 9813
step    320 | loss 1.6238 | lr 3.00e-04 | grad 2.20 | tok/s 9425
step    330 | loss 1.7433 | lr 3.00e-04 | grad 1.27 | tok/s 9195
step    340 | loss 1.7402 | lr 3.00e-04 | grad 2.94 | tok/s 9408
step    350 | loss 1.7463 | lr 3.00e-04 | grad 1.30 | tok/s 9126
step    360 | loss 1.7014 | lr 3.00e-04 | grad 3.36 | tok/s 9252

Training complete! Final step: 360
