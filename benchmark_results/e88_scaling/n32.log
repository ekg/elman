Using device: cuda
Output directory: benchmark_results/e88_scaling/n32/levelE88_n32_100m_20260122_223747
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88_n32, 541,662,208 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 4.5477 | lr 3.00e-04 | grad 15.12 | tok/s 8129
step     20 | loss 3.6147 | lr 3.00e-04 | grad 26.62 | tok/s 10238
step     30 | loss 4.4292 | lr 3.00e-04 | grad 10.38 | tok/s 10601
step     40 | loss 3.2245 | lr 3.00e-04 | grad 8.31 | tok/s 10460
step     50 | loss 2.6738 | lr 3.00e-04 | grad 5.22 | tok/s 10340
step     60 | loss 2.9655 | lr 3.00e-04 | grad 4.84 | tok/s 10081
step     70 | loss 2.6703 | lr 3.00e-04 | grad 3.06 | tok/s 9713
step     80 | loss 2.4704 | lr 3.00e-04 | grad 4.12 | tok/s 10068
step     90 | loss 2.5710 | lr 3.00e-04 | grad 10.31 | tok/s 9683
step    100 | loss 2.2295 | lr 3.00e-04 | grad 3.81 | tok/s 9775
step    110 | loss 2.2441 | lr 3.00e-04 | grad 2.73 | tok/s 9625
step    120 | loss 2.3233 | lr 3.00e-04 | grad 2.62 | tok/s 9504
step    130 | loss 2.2767 | lr 3.00e-04 | grad 2.31 | tok/s 9733
step    140 | loss 2.0880 | lr 3.00e-04 | grad 2.11 | tok/s 9750
step    150 | loss 1.9637 | lr 3.00e-04 | grad 2.81 | tok/s 9308
step    160 | loss 1.9150 | lr 3.00e-04 | grad 1.90 | tok/s 9378
step    170 | loss 2.0708 | lr 3.00e-04 | grad 10.81 | tok/s 9716
step    180 | loss 1.9808 | lr 3.00e-04 | grad 1.33 | tok/s 9738
step    190 | loss 1.7310 | lr 3.00e-04 | grad 1.94 | tok/s 9895
step    200 | loss 1.3734 | lr 3.00e-04 | grad 1.84 | tok/s 10128
step    210 | loss 1.9404 | lr 3.00e-04 | grad 2.03 | tok/s 9693
step    220 | loss 1.7873 | lr 3.00e-04 | grad 1.90 | tok/s 10031
step    230 | loss 1.7850 | lr 3.00e-04 | grad 3.05 | tok/s 9690
step    240 | loss 1.7419 | lr 3.00e-04 | grad 2.16 | tok/s 9862
step    250 | loss 1.7172 | lr 3.00e-04 | grad 1.84 | tok/s 9748
step    260 | loss 1.8248 | lr 3.00e-04 | grad 1.56 | tok/s 9356
step    270 | loss 1.7282 | lr 3.00e-04 | grad 1.41 | tok/s 9719
step    280 | loss 1.6066 | lr 3.00e-04 | grad 2.22 | tok/s 9696
step    290 | loss 1.5101 | lr 3.00e-04 | grad 1.52 | tok/s 10207
step    300 | loss 1.4419 | lr 3.00e-04 | grad 1.71 | tok/s 10222
step    310 | loss 1.3955 | lr 3.00e-04 | grad 1.43 | tok/s 10230
step    320 | loss 1.5738 | lr 3.00e-04 | grad 2.95 | tok/s 9824
step    330 | loss 1.7015 | lr 3.00e-04 | grad 1.35 | tok/s 9586
step    340 | loss 1.7024 | lr 3.00e-04 | grad 3.22 | tok/s 9807
step    350 | loss 1.7066 | lr 3.00e-04 | grad 1.45 | tok/s 9521
step    360 | loss 1.6556 | lr 3.00e-04 | grad 3.42 | tok/s 9627
step    370 | loss 1.4719 | lr 3.00e-04 | grad 1.29 | tok/s 9817

Training complete! Final step: 373
