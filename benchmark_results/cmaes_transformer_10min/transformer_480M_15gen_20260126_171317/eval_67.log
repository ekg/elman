Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_67/levelllama_100m_20260126_183528
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 225,768,448 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 5.2381 | lr 3.00e-04 | grad 2.12 | tok/s 12374
step     20 | loss 2.9050 | lr 3.00e-04 | grad 0.86 | tok/s 33604
step     30 | loss 3.3586 | lr 3.00e-04 | grad 1.38 | tok/s 35580
step     40 | loss 5.5064 | lr 3.00e-04 | grad 6.47 | tok/s 36277
step     50 | loss 4.7776 | lr 3.00e-04 | grad 3.59 | tok/s 36760
step     60 | loss 3.8759 | lr 3.00e-04 | grad 2.81 | tok/s 36754
step     70 | loss 3.3551 | lr 3.00e-04 | grad 2.73 | tok/s 36670
step     80 | loss 3.1375 | lr 3.00e-04 | grad 1.31 | tok/s 36613
step     90 | loss 2.8190 | lr 3.00e-04 | grad 1.33 | tok/s 36544
step    100 | loss 2.6077 | lr 3.00e-04 | grad 1.71 | tok/s 36474
step    110 | loss 2.6494 | lr 3.00e-04 | grad 1.39 | tok/s 36150
step    120 | loss 3.4530 | lr 3.00e-04 | grad 0.72 | tok/s 34384
step    130 | loss 2.6164 | lr 3.00e-04 | grad 2.06 | tok/s 35165
step    140 | loss 2.9375 | lr 3.00e-04 | grad 5.06 | tok/s 35226
step    150 | loss 2.8729 | lr 3.00e-04 | grad 4.78 | tok/s 36027
step    160 | loss 2.9501 | lr 3.00e-04 | grad 1.49 | tok/s 34800
step    170 | loss 2.7108 | lr 3.00e-04 | grad 0.70 | tok/s 34220
step    180 | loss 2.9209 | lr 3.00e-04 | grad 1.33 | tok/s 34978
step    190 | loss 2.4543 | lr 3.00e-04 | grad 2.09 | tok/s 34275
step    200 | loss 2.4014 | lr 3.00e-04 | grad 0.84 | tok/s 35756
step    210 | loss 2.4171 | lr 3.00e-04 | grad 2.33 | tok/s 33883
step    220 | loss 2.6604 | lr 3.00e-04 | grad 3.08 | tok/s 34205
step    230 | loss 2.4363 | lr 3.00e-04 | grad 1.50 | tok/s 34107
step    240 | loss 2.7693 | lr 3.00e-04 | grad 1.80 | tok/s 34528
step    250 | loss 2.3183 | lr 3.00e-04 | grad 0.98 | tok/s 34280
step    260 | loss 2.4503 | lr 3.00e-04 | grad 1.75 | tok/s 35187
step    270 | loss 2.3145 | lr 3.00e-04 | grad 1.80 | tok/s 34321
step    280 | loss 2.2463 | lr 3.00e-04 | grad 0.72 | tok/s 32204
step    290 | loss 2.1778 | lr 3.00e-04 | grad 1.13 | tok/s 33258
step    300 | loss 2.4437 | lr 3.00e-04 | grad 1.05 | tok/s 33496
step    310 | loss 2.1289 | lr 3.00e-04 | grad 0.73 | tok/s 33314
step    320 | loss 2.3994 | lr 3.00e-04 | grad 2.59 | tok/s 33677
step    330 | loss 2.1947 | lr 3.00e-04 | grad 0.89 | tok/s 33985
step    340 | loss 2.4950 | lr 3.00e-04 | grad 1.48 | tok/s 33820
step    350 | loss 2.5090 | lr 3.00e-04 | grad 1.16 | tok/s 34756
step    360 | loss 2.1088 | lr 3.00e-04 | grad 0.98 | tok/s 33239
step    370 | loss 2.1721 | lr 3.00e-04 | grad 0.83 | tok/s 34968
step    380 | loss 1.9957 | lr 3.00e-04 | grad 1.53 | tok/s 35239
step    390 | loss 1.9435 | lr 3.00e-04 | grad 1.29 | tok/s 35186
step    400 | loss 2.2749 | lr 3.00e-04 | grad 0.86 | tok/s 33319
step    410 | loss 2.1642 | lr 3.00e-04 | grad 1.05 | tok/s 33569
step    420 | loss 2.3528 | lr 3.00e-04 | grad 1.28 | tok/s 34997
step    430 | loss 2.1836 | lr 3.00e-04 | grad 1.20 | tok/s 34420
step    440 | loss 2.1739 | lr 3.00e-04 | grad 1.22 | tok/s 33360
step    450 | loss 2.0710 | lr 3.00e-04 | grad 0.76 | tok/s 33689
step    460 | loss 2.1669 | lr 3.00e-04 | grad 0.84 | tok/s 34180
step    470 | loss 2.1503 | lr 3.00e-04 | grad 1.80 | tok/s 33894
step    480 | loss 2.1850 | lr 3.00e-04 | grad 1.27 | tok/s 34612
step    490 | loss 2.1082 | lr 3.00e-04 | grad 1.34 | tok/s 33219
step    500 | loss 2.2468 | lr 3.00e-04 | grad 0.89 | tok/s 33746
step    510 | loss 2.1090 | lr 3.00e-04 | grad 0.84 | tok/s 32229
step    520 | loss 1.9783 | lr 3.00e-04 | grad 1.03 | tok/s 33771
step    530 | loss 2.1284 | lr 3.00e-04 | grad 1.08 | tok/s 33192
step    540 | loss 2.0949 | lr 3.00e-04 | grad 0.71 | tok/s 32442
step    550 | loss 1.7772 | lr 3.00e-04 | grad 1.63 | tok/s 33906
step    560 | loss 1.9814 | lr 3.00e-04 | grad 1.29 | tok/s 34894
step    570 | loss 1.8652 | lr 3.00e-04 | grad 1.21 | tok/s 34880
step    580 | loss 1.7987 | lr 3.00e-04 | grad 1.15 | tok/s 34879
step    590 | loss 1.8498 | lr 3.00e-04 | grad 1.03 | tok/s 34838
step    600 | loss 1.8075 | lr 3.00e-04 | grad 0.92 | tok/s 34797
step    610 | loss 1.7687 | lr 3.00e-04 | grad 1.05 | tok/s 34666
step    620 | loss 1.7571 | lr 3.00e-04 | grad 0.91 | tok/s 34538
step    630 | loss 1.9535 | lr 3.00e-04 | grad 2.17 | tok/s 32642
step    640 | loss 2.1348 | lr 3.00e-04 | grad 1.70 | tok/s 33029
step    650 | loss 1.9394 | lr 3.00e-04 | grad 0.94 | tok/s 33049
step    660 | loss 2.0066 | lr 3.00e-04 | grad 1.08 | tok/s 34268
step    670 | loss 2.0445 | lr 3.00e-04 | grad 2.34 | tok/s 33125
step    680 | loss 2.0263 | lr 3.00e-04 | grad 1.18 | tok/s 32601
step    690 | loss 1.9934 | lr 3.00e-04 | grad 1.02 | tok/s 32355
step    700 | loss 1.9045 | lr 3.00e-04 | grad 1.02 | tok/s 33048
step    710 | loss 2.0426 | lr 3.00e-04 | grad 2.20 | tok/s 32527
step    720 | loss 1.8084 | lr 3.00e-04 | grad 1.07 | tok/s 33784
step    730 | loss 1.8882 | lr 3.00e-04 | grad 0.84 | tok/s 33182
step    740 | loss 2.3357 | lr 3.00e-04 | grad 1.95 | tok/s 34073
step    750 | loss 2.1382 | lr 3.00e-04 | grad 1.17 | tok/s 34474
step    760 | loss 1.9230 | lr 3.00e-04 | grad 2.03 | tok/s 33783
step    770 | loss 1.9294 | lr 3.00e-04 | grad 1.03 | tok/s 33215
step    780 | loss 1.8744 | lr 3.00e-04 | grad 1.30 | tok/s 33419
step    790 | loss 2.2031 | lr 3.00e-04 | grad 1.98 | tok/s 34176
step    800 | loss 1.7657 | lr 3.00e-04 | grad 1.27 | tok/s 33585
step    810 | loss 1.6954 | lr 3.00e-04 | grad 1.74 | tok/s 32452
step    820 | loss 1.8509 | lr 3.00e-04 | grad 1.11 | tok/s 33050
step    830 | loss 1.8892 | lr 3.00e-04 | grad 0.94 | tok/s 32635
step    840 | loss 2.0063 | lr 3.00e-04 | grad 0.98 | tok/s 32477
step    850 | loss 1.9924 | lr 3.00e-04 | grad 1.05 | tok/s 33128
step    860 | loss 2.0318 | lr 3.00e-04 | grad 1.32 | tok/s 33630
step    870 | loss 2.0854 | lr 3.00e-04 | grad 1.15 | tok/s 33929
step    880 | loss 1.9157 | lr 3.00e-04 | grad 0.90 | tok/s 33276
step    890 | loss 1.8098 | lr 3.00e-04 | grad 1.09 | tok/s 33117
step    900 | loss 1.8642 | lr 3.00e-04 | grad 0.89 | tok/s 32935
step    910 | loss 1.9299 | lr 3.00e-04 | grad 3.44 | tok/s 32583
step    920 | loss 1.8263 | lr 3.00e-04 | grad 1.11 | tok/s 32893
step    930 | loss 1.7889 | lr 3.00e-04 | grad 1.01 | tok/s 33318
step    940 | loss 1.7603 | lr 3.00e-04 | grad 1.03 | tok/s 32588
step    950 | loss 1.8328 | lr 3.00e-04 | grad 1.34 | tok/s 32095
step    960 | loss 1.7763 | lr 3.00e-04 | grad 1.11 | tok/s 32980
step    970 | loss 1.7681 | lr 3.00e-04 | grad 1.15 | tok/s 32970
step    980 | loss 2.5493 | lr 3.00e-04 | grad 1.80 | tok/s 34340
step    990 | loss 1.9796 | lr 3.00e-04 | grad 1.19 | tok/s 32901
step   1000 | loss 1.8872 | lr 3.00e-04 | grad 1.34 | tok/s 33023
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8872.pt
step   1010 | loss 1.6316 | lr 3.00e-04 | grad 1.31 | tok/s 18576
step   1020 | loss 1.7271 | lr 3.00e-04 | grad 1.16 | tok/s 34730
step   1030 | loss 1.8843 | lr 3.00e-04 | grad 1.29 | tok/s 32993
step   1040 | loss 2.3597 | lr 3.00e-04 | grad 1.91 | tok/s 33767
step   1050 | loss 1.9769 | lr 3.00e-04 | grad 1.04 | tok/s 34006
step   1060 | loss 1.6060 | lr 3.00e-04 | grad 0.88 | tok/s 33564
step   1070 | loss 1.7146 | lr 3.00e-04 | grad 1.45 | tok/s 33476
step   1080 | loss 1.6136 | lr 3.00e-04 | grad 0.99 | tok/s 34615
step   1090 | loss 1.5902 | lr 3.00e-04 | grad 1.22 | tok/s 34536
step   1100 | loss 1.5569 | lr 3.00e-04 | grad 1.09 | tok/s 34568
step   1110 | loss 1.5030 | lr 3.00e-04 | grad 1.17 | tok/s 34571
step   1120 | loss 1.7190 | lr 3.00e-04 | grad 1.05 | tok/s 33569
step   1130 | loss 2.1666 | lr 3.00e-04 | grad 1.09 | tok/s 33983
step   1140 | loss 2.1051 | lr 3.00e-04 | grad 1.22 | tok/s 34389
step   1150 | loss 2.2979 | lr 3.00e-04 | grad 1.90 | tok/s 33602
step   1160 | loss 1.9804 | lr 3.00e-04 | grad 2.98 | tok/s 32548
step   1170 | loss 1.8334 | lr 3.00e-04 | grad 1.30 | tok/s 32443
step   1180 | loss 1.7529 | lr 3.00e-04 | grad 1.19 | tok/s 34139
step   1190 | loss 2.0780 | lr 3.00e-04 | grad 1.34 | tok/s 34221
step   1200 | loss 1.6012 | lr 3.00e-04 | grad 1.28 | tok/s 34508
step   1210 | loss 1.6433 | lr 3.00e-04 | grad 1.12 | tok/s 32518
step   1220 | loss 1.7273 | lr 3.00e-04 | grad 1.30 | tok/s 33580
step   1230 | loss 1.7623 | lr 3.00e-04 | grad 1.02 | tok/s 33820
step   1240 | loss 1.6671 | lr 3.00e-04 | grad 1.80 | tok/s 34143
step   1250 | loss 1.8721 | lr 3.00e-04 | grad 1.39 | tok/s 33348
step   1260 | loss 1.9772 | lr 3.00e-04 | grad 1.16 | tok/s 34302
step   1270 | loss 1.7083 | lr 3.00e-04 | grad 1.64 | tok/s 33212
step   1280 | loss 1.7181 | lr 3.00e-04 | grad 1.36 | tok/s 33347
step   1290 | loss 1.7191 | lr 3.00e-04 | grad 1.33 | tok/s 32529
step   1300 | loss 1.9563 | lr 3.00e-04 | grad 3.19 | tok/s 32416
step   1310 | loss 1.9832 | lr 3.00e-04 | grad 1.05 | tok/s 33807
step   1320 | loss 1.8111 | lr 3.00e-04 | grad 2.17 | tok/s 33683
step   1330 | loss 1.8566 | lr 3.00e-04 | grad 1.39 | tok/s 33638
step   1340 | loss 1.9115 | lr 3.00e-04 | grad 1.12 | tok/s 32587
step   1350 | loss 1.7900 | lr 3.00e-04 | grad 1.12 | tok/s 33862
step   1360 | loss 1.8381 | lr 3.00e-04 | grad 1.23 | tok/s 31829
step   1370 | loss 1.9676 | lr 3.00e-04 | grad 2.34 | tok/s 33989
step   1380 | loss 1.8033 | lr 3.00e-04 | grad 1.35 | tok/s 32926
step   1390 | loss 1.8156 | lr 3.00e-04 | grad 1.38 | tok/s 33579
step   1400 | loss 1.8259 | lr 3.00e-04 | grad 1.18 | tok/s 32816
step   1410 | loss 1.6659 | lr 3.00e-04 | grad 1.38 | tok/s 32231
step   1420 | loss 1.7162 | lr 3.00e-04 | grad 1.34 | tok/s 34256
step   1430 | loss 2.0672 | lr 3.00e-04 | grad 1.07 | tok/s 33113
step   1440 | loss 1.7799 | lr 3.00e-04 | grad 1.53 | tok/s 33398
step   1450 | loss 1.7872 | lr 3.00e-04 | grad 1.05 | tok/s 33754
step   1460 | loss 1.8516 | lr 3.00e-04 | grad 1.45 | tok/s 32761
step   1470 | loss 1.6918 | lr 3.00e-04 | grad 1.50 | tok/s 32373
step   1480 | loss 1.7229 | lr 3.00e-04 | grad 1.87 | tok/s 33545
step   1490 | loss 1.9108 | lr 3.00e-04 | grad 1.89 | tok/s 33302
step   1500 | loss 1.9348 | lr 3.00e-04 | grad 1.31 | tok/s 33735
step   1510 | loss 1.6151 | lr 3.00e-04 | grad 1.09 | tok/s 33084
step   1520 | loss 1.7516 | lr 3.00e-04 | grad 1.43 | tok/s 32946
step   1530 | loss 1.7004 | lr 3.00e-04 | grad 1.40 | tok/s 33790
step   1540 | loss 1.7939 | lr 3.00e-04 | grad 1.03 | tok/s 33829
step   1550 | loss 1.7721 | lr 3.00e-04 | grad 2.28 | tok/s 33249
step   1560 | loss 1.6029 | lr 3.00e-04 | grad 1.25 | tok/s 34269
step   1570 | loss 1.6864 | lr 3.00e-04 | grad 1.06 | tok/s 33546
step   1580 | loss 1.5883 | lr 3.00e-04 | grad 1.39 | tok/s 33747
step   1590 | loss 1.7479 | lr 3.00e-04 | grad 1.85 | tok/s 32462
step   1600 | loss 1.5495 | lr 3.00e-04 | grad 3.69 | tok/s 34302
step   1610 | loss 2.1842 | lr 3.00e-04 | grad 2.67 | tok/s 33435
step   1620 | loss 2.3514 | lr 3.00e-04 | grad 1.84 | tok/s 34528
step   1630 | loss 2.1092 | lr 3.00e-04 | grad 1.34 | tok/s 34541
step   1640 | loss 1.9542 | lr 3.00e-04 | grad 1.50 | tok/s 34419
step   1650 | loss 1.8823 | lr 3.00e-04 | grad 1.43 | tok/s 34481
step   1660 | loss 1.8332 | lr 3.00e-04 | grad 1.18 | tok/s 34402
step   1670 | loss 1.9284 | lr 3.00e-04 | grad 1.77 | tok/s 33466
step   1680 | loss 1.7179 | lr 3.00e-04 | grad 1.24 | tok/s 33064
step   1690 | loss 1.7325 | lr 3.00e-04 | grad 1.52 | tok/s 32362
step   1700 | loss 1.6105 | lr 3.00e-04 | grad 1.23 | tok/s 33601
step   1710 | loss 1.5894 | lr 3.00e-04 | grad 1.57 | tok/s 33761
step   1720 | loss 1.7074 | lr 3.00e-04 | grad 1.10 | tok/s 32727
step   1730 | loss 1.7816 | lr 3.00e-04 | grad 2.33 | tok/s 33757
step   1740 | loss 1.7003 | lr 3.00e-04 | grad 1.29 | tok/s 33941
step   1750 | loss 1.6015 | lr 3.00e-04 | grad 1.20 | tok/s 33191
step   1760 | loss 1.6707 | lr 3.00e-04 | grad 1.25 | tok/s 32856
step   1770 | loss 1.9965 | lr 3.00e-04 | grad 1.43 | tok/s 33624
step   1780 | loss 1.9729 | lr 3.00e-04 | grad 1.27 | tok/s 31762
step   1790 | loss 1.5770 | lr 3.00e-04 | grad 1.13 | tok/s 32300
step   1800 | loss 1.6521 | lr 3.00e-04 | grad 1.16 | tok/s 33010
step   1810 | loss 1.6824 | lr 3.00e-04 | grad 1.49 | tok/s 33350
step   1820 | loss 1.7870 | lr 3.00e-04 | grad 1.77 | tok/s 32839
step   1830 | loss 1.6299 | lr 3.00e-04 | grad 1.06 | tok/s 31900
step   1840 | loss 1.7194 | lr 3.00e-04 | grad 1.10 | tok/s 33057
step   1850 | loss 1.7343 | lr 3.00e-04 | grad 1.45 | tok/s 32886
step   1860 | loss 1.6811 | lr 3.00e-04 | grad 1.45 | tok/s 32817
step   1870 | loss 1.6805 | lr 3.00e-04 | grad 1.65 | tok/s 33343
step   1880 | loss 1.7456 | lr 3.00e-04 | grad 1.25 | tok/s 33514
step   1890 | loss 1.5556 | lr 3.00e-04 | grad 1.13 | tok/s 34458
step   1900 | loss 1.4888 | lr 3.00e-04 | grad 1.09 | tok/s 34501
step   1910 | loss 1.4571 | lr 3.00e-04 | grad 1.04 | tok/s 34440
step   1920 | loss 1.4422 | lr 3.00e-04 | grad 1.04 | tok/s 34474
step   1930 | loss 1.4722 | lr 3.00e-04 | grad 2.00 | tok/s 34375
step   1940 | loss 1.8037 | lr 3.00e-04 | grad 1.57 | tok/s 32690
step   1950 | loss 1.6907 | lr 3.00e-04 | grad 0.96 | tok/s 32466
step   1960 | loss 1.7958 | lr 3.00e-04 | grad 1.71 | tok/s 32858
step   1970 | loss 1.8289 | lr 3.00e-04 | grad 1.45 | tok/s 33557
step   1980 | loss 1.7201 | lr 3.00e-04 | grad 1.46 | tok/s 32504
step   1990 | loss 1.9406 | lr 3.00e-04 | grad 1.96 | tok/s 33370
step   2000 | loss 1.4532 | lr 3.00e-04 | grad 1.20 | tok/s 34551
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4532.pt
step   2010 | loss 1.6285 | lr 3.00e-04 | grad 1.16 | tok/s 19454
step   2020 | loss 1.6740 | lr 3.00e-04 | grad 1.17 | tok/s 32477
step   2030 | loss 1.8861 | lr 3.00e-04 | grad 6.97 | tok/s 32575
step   2040 | loss 1.8167 | lr 3.00e-04 | grad 1.23 | tok/s 33207
step   2050 | loss 1.6067 | lr 3.00e-04 | grad 1.66 | tok/s 33493
step   2060 | loss 1.7918 | lr 3.00e-04 | grad 1.14 | tok/s 33329
step   2070 | loss 1.6069 | lr 3.00e-04 | grad 1.06 | tok/s 33638
step   2080 | loss 1.5610 | lr 3.00e-04 | grad 1.62 | tok/s 32009
step   2090 | loss 1.6040 | lr 3.00e-04 | grad 1.45 | tok/s 34204
step   2100 | loss 2.2379 | lr 3.00e-04 | grad 1.97 | tok/s 34523
step   2110 | loss 1.7655 | lr 3.00e-04 | grad 1.66 | tok/s 33356
step   2120 | loss 2.4398 | lr 3.00e-04 | grad 2.06 | tok/s 33589
step   2130 | loss 1.7826 | lr 3.00e-04 | grad 1.48 | tok/s 32344
step   2140 | loss 1.8759 | lr 3.00e-04 | grad 2.56 | tok/s 33841
step   2150 | loss 1.9532 | lr 3.00e-04 | grad 1.45 | tok/s 33035
step   2160 | loss 1.7828 | lr 3.00e-04 | grad 1.51 | tok/s 33387
step   2170 | loss 1.6255 | lr 3.00e-04 | grad 2.47 | tok/s 33788
step   2180 | loss 1.4222 | lr 3.00e-04 | grad 1.05 | tok/s 34323
step   2190 | loss 1.8438 | lr 3.00e-04 | grad 1.24 | tok/s 33176
step   2200 | loss 1.6591 | lr 3.00e-04 | grad 1.32 | tok/s 34229
step   2210 | loss 1.8115 | lr 3.00e-04 | grad 1.15 | tok/s 33945
step   2220 | loss 1.6424 | lr 3.00e-04 | grad 1.09 | tok/s 32646
step   2230 | loss 1.7943 | lr 3.00e-04 | grad 3.23 | tok/s 32383
step   2240 | loss 1.5810 | lr 3.00e-04 | grad 1.27 | tok/s 33395
step   2250 | loss 1.6476 | lr 3.00e-04 | grad 1.14 | tok/s 32824
step   2260 | loss 1.7240 | lr 3.00e-04 | grad 1.19 | tok/s 34046
step   2270 | loss 1.8672 | lr 3.00e-04 | grad 1.61 | tok/s 31900
step   2280 | loss 1.7159 | lr 3.00e-04 | grad 1.21 | tok/s 33034
step   2290 | loss 1.5052 | lr 3.00e-04 | grad 1.42 | tok/s 32876
step   2300 | loss 1.7828 | lr 3.00e-04 | grad 1.09 | tok/s 32652
step   2310 | loss 1.6033 | lr 3.00e-04 | grad 0.88 | tok/s 32912
step   2320 | loss 1.6714 | lr 3.00e-04 | grad 1.29 | tok/s 34287
step   2330 | loss 1.6072 | lr 3.00e-04 | grad 1.29 | tok/s 34470
step   2340 | loss 1.5815 | lr 3.00e-04 | grad 1.20 | tok/s 34513
step   2350 | loss 1.5184 | lr 3.00e-04 | grad 1.19 | tok/s 34470
step   2360 | loss 1.5197 | lr 3.00e-04 | grad 1.39 | tok/s 34444
step   2370 | loss 1.4615 | lr 3.00e-04 | grad 1.15 | tok/s 34509
step   2380 | loss 1.4412 | lr 3.00e-04 | grad 1.22 | tok/s 34378
step   2390 | loss 1.4563 | lr 3.00e-04 | grad 1.23 | tok/s 34414
step   2400 | loss 1.4562 | lr 3.00e-04 | grad 1.23 | tok/s 34439
step   2410 | loss 1.4724 | lr 3.00e-04 | grad 1.23 | tok/s 34433
step   2420 | loss 1.8192 | lr 3.00e-04 | grad 1.47 | tok/s 33392
step   2430 | loss 1.2254 | lr 3.00e-04 | grad 1.34 | tok/s 33659
step   2440 | loss 1.6472 | lr 3.00e-04 | grad 1.26 | tok/s 31774
step   2450 | loss 1.5746 | lr 3.00e-04 | grad 1.20 | tok/s 32920
step   2460 | loss 1.7441 | lr 3.00e-04 | grad 1.52 | tok/s 33938
step   2470 | loss 1.5416 | lr 3.00e-04 | grad 1.30 | tok/s 33654
step   2480 | loss 1.7014 | lr 3.00e-04 | grad 1.42 | tok/s 33160
step   2490 | loss 1.7032 | lr 3.00e-04 | grad 3.27 | tok/s 33952

Training complete! Final step: 2499
