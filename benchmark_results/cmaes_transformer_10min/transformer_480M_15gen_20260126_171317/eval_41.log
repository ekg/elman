Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_41/levelllama_100m_20260126_180441
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 238,308,224 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 6.2149 | lr 3.00e-04 | grad 4.06 | tok/s 13203
step     20 | loss 2.9158 | lr 3.00e-04 | grad 1.77 | tok/s 40308
step     30 | loss 3.2857 | lr 3.00e-04 | grad 1.98 | tok/s 42587
step     40 | loss 5.7281 | lr 3.00e-04 | grad 7.34 | tok/s 43405
step     50 | loss 4.6725 | lr 3.00e-04 | grad 4.47 | tok/s 43958
step     60 | loss 3.7645 | lr 3.00e-04 | grad 3.52 | tok/s 43888
step     70 | loss 3.2732 | lr 3.00e-04 | grad 3.91 | tok/s 43767
step     80 | loss 3.0071 | lr 3.00e-04 | grad 2.36 | tok/s 43660
step     90 | loss 2.7235 | lr 3.00e-04 | grad 1.82 | tok/s 43527
step    100 | loss 2.5288 | lr 3.00e-04 | grad 2.80 | tok/s 43473
step    110 | loss 2.6221 | lr 3.00e-04 | grad 2.30 | tok/s 43065
step    120 | loss 3.3981 | lr 3.00e-04 | grad 1.49 | tok/s 40967
step    130 | loss 2.6277 | lr 3.00e-04 | grad 2.53 | tok/s 41844
step    140 | loss 2.9074 | lr 3.00e-04 | grad 5.72 | tok/s 41946
step    150 | loss 2.6996 | lr 3.00e-04 | grad 4.97 | tok/s 42944
step    160 | loss 2.8176 | lr 3.00e-04 | grad 1.67 | tok/s 41339
step    170 | loss 2.7166 | lr 3.00e-04 | grad 1.57 | tok/s 40640
step    180 | loss 2.8702 | lr 3.00e-04 | grad 1.67 | tok/s 41520
step    190 | loss 2.4448 | lr 3.00e-04 | grad 1.73 | tok/s 40700
step    200 | loss 2.3771 | lr 3.00e-04 | grad 1.38 | tok/s 42421
step    210 | loss 2.3874 | lr 3.00e-04 | grad 2.64 | tok/s 40169
step    220 | loss 2.6585 | lr 3.00e-04 | grad 4.06 | tok/s 40463
step    230 | loss 2.4146 | lr 3.00e-04 | grad 2.03 | tok/s 40347
step    240 | loss 2.7521 | lr 3.00e-04 | grad 2.31 | tok/s 40725
step    250 | loss 2.2986 | lr 3.00e-04 | grad 1.63 | tok/s 40378
step    260 | loss 2.4311 | lr 3.00e-04 | grad 1.94 | tok/s 41366
step    270 | loss 2.2918 | lr 3.00e-04 | grad 1.80 | tok/s 40362
step    280 | loss 2.2243 | lr 3.00e-04 | grad 0.88 | tok/s 37877
step    290 | loss 2.1601 | lr 3.00e-04 | grad 1.89 | tok/s 39025
step    300 | loss 2.4291 | lr 3.00e-04 | grad 1.60 | tok/s 39194
step    310 | loss 2.1128 | lr 3.00e-04 | grad 1.20 | tok/s 38969
step    320 | loss 2.3712 | lr 3.00e-04 | grad 2.97 | tok/s 39265
step    330 | loss 2.1686 | lr 3.00e-04 | grad 1.45 | tok/s 39647
step    340 | loss 2.4712 | lr 3.00e-04 | grad 1.65 | tok/s 39473
step    350 | loss 2.4199 | lr 3.00e-04 | grad 1.37 | tok/s 40492
step    360 | loss 2.0659 | lr 3.00e-04 | grad 1.29 | tok/s 38614
step    370 | loss 2.1285 | lr 3.00e-04 | grad 1.19 | tok/s 40720
step    380 | loss 1.9335 | lr 3.00e-04 | grad 1.60 | tok/s 40973
step    390 | loss 1.8577 | lr 3.00e-04 | grad 1.69 | tok/s 40912
step    400 | loss 2.2391 | lr 3.00e-04 | grad 1.09 | tok/s 38741
step    410 | loss 2.1441 | lr 3.00e-04 | grad 1.26 | tok/s 39015
step    420 | loss 2.2776 | lr 3.00e-04 | grad 2.03 | tok/s 40618
step    430 | loss 2.1132 | lr 3.00e-04 | grad 1.74 | tok/s 39940
step    440 | loss 2.1367 | lr 3.00e-04 | grad 1.44 | tok/s 38637
step    450 | loss 2.0271 | lr 3.00e-04 | grad 1.11 | tok/s 38993
step    460 | loss 2.1010 | lr 3.00e-04 | grad 1.16 | tok/s 39534
step    470 | loss 2.0832 | lr 3.00e-04 | grad 1.99 | tok/s 39197
step    480 | loss 2.1155 | lr 3.00e-04 | grad 1.95 | tok/s 40013
step    490 | loss 2.0694 | lr 3.00e-04 | grad 1.71 | tok/s 38436
step    500 | loss 2.2137 | lr 3.00e-04 | grad 1.33 | tok/s 38952
step    510 | loss 2.0633 | lr 3.00e-04 | grad 0.91 | tok/s 37216
step    520 | loss 1.9232 | lr 3.00e-04 | grad 1.19 | tok/s 38991
step    530 | loss 2.0813 | lr 3.00e-04 | grad 1.16 | tok/s 38271
step    540 | loss 2.0316 | lr 3.00e-04 | grad 0.93 | tok/s 37442
step    550 | loss 1.7206 | lr 3.00e-04 | grad 2.11 | tok/s 39248
step    560 | loss 1.8973 | lr 3.00e-04 | grad 1.28 | tok/s 40251
step    570 | loss 1.7862 | lr 3.00e-04 | grad 1.54 | tok/s 40247
step    580 | loss 1.7139 | lr 3.00e-04 | grad 1.01 | tok/s 40230
step    590 | loss 1.7656 | lr 3.00e-04 | grad 1.37 | tok/s 40174
step    600 | loss 1.7086 | lr 3.00e-04 | grad 1.44 | tok/s 40167
step    610 | loss 1.6903 | lr 3.00e-04 | grad 1.14 | tok/s 40192
step    620 | loss 1.6693 | lr 3.00e-04 | grad 1.30 | tok/s 39973
step    630 | loss 1.9402 | lr 3.00e-04 | grad 3.56 | tok/s 37825
step    640 | loss 2.0699 | lr 3.00e-04 | grad 1.45 | tok/s 38276
step    650 | loss 1.8768 | lr 3.00e-04 | grad 1.09 | tok/s 38253
step    660 | loss 1.9440 | lr 3.00e-04 | grad 1.37 | tok/s 39707
step    670 | loss 1.9691 | lr 3.00e-04 | grad 2.67 | tok/s 38376
step    680 | loss 1.9715 | lr 3.00e-04 | grad 1.45 | tok/s 37730
step    690 | loss 1.9208 | lr 3.00e-04 | grad 1.19 | tok/s 37475
step    700 | loss 1.8341 | lr 3.00e-04 | grad 1.16 | tok/s 38244
step    710 | loss 1.9815 | lr 3.00e-04 | grad 2.56 | tok/s 37672
step    720 | loss 1.7182 | lr 3.00e-04 | grad 1.61 | tok/s 39117
step    730 | loss 1.8145 | lr 3.00e-04 | grad 0.96 | tok/s 38446
step    740 | loss 2.2353 | lr 3.00e-04 | grad 2.27 | tok/s 39520
step    750 | loss 2.0232 | lr 3.00e-04 | grad 1.59 | tok/s 39999
step    760 | loss 1.8605 | lr 3.00e-04 | grad 2.22 | tok/s 39144
step    770 | loss 1.8634 | lr 3.00e-04 | grad 1.25 | tok/s 38477
step    780 | loss 1.8099 | lr 3.00e-04 | grad 1.38 | tok/s 38724
step    790 | loss 2.1136 | lr 3.00e-04 | grad 2.53 | tok/s 39594
step    800 | loss 1.6847 | lr 3.00e-04 | grad 1.06 | tok/s 38957
step    810 | loss 1.6346 | lr 3.00e-04 | grad 1.98 | tok/s 37608
step    820 | loss 1.7793 | lr 3.00e-04 | grad 1.28 | tok/s 38343
step    830 | loss 1.8219 | lr 3.00e-04 | grad 1.23 | tok/s 37847
step    840 | loss 1.9516 | lr 3.00e-04 | grad 1.27 | tok/s 37642
step    850 | loss 1.9000 | lr 3.00e-04 | grad 1.15 | tok/s 38414
step    860 | loss 1.9556 | lr 3.00e-04 | grad 1.41 | tok/s 39081
step    870 | loss 1.9596 | lr 3.00e-04 | grad 1.23 | tok/s 39349
step    880 | loss 1.8558 | lr 3.00e-04 | grad 1.05 | tok/s 38617
step    890 | loss 1.7466 | lr 3.00e-04 | grad 1.14 | tok/s 38404
step    900 | loss 1.8056 | lr 3.00e-04 | grad 1.01 | tok/s 38255
step    910 | loss 1.8619 | lr 3.00e-04 | grad 4.22 | tok/s 37863
step    920 | loss 1.7559 | lr 3.00e-04 | grad 1.20 | tok/s 38308
step    930 | loss 1.7120 | lr 3.00e-04 | grad 1.21 | tok/s 38741
step    940 | loss 1.6745 | lr 3.00e-04 | grad 1.12 | tok/s 37915
step    950 | loss 1.7661 | lr 3.00e-04 | grad 1.58 | tok/s 37251
step    960 | loss 1.7113 | lr 3.00e-04 | grad 1.14 | tok/s 38262
step    970 | loss 1.7092 | lr 3.00e-04 | grad 1.16 | tok/s 38265
step    980 | loss 2.4121 | lr 3.00e-04 | grad 2.16 | tok/s 39805
step    990 | loss 1.9044 | lr 3.00e-04 | grad 1.48 | tok/s 38201
step   1000 | loss 1.8181 | lr 3.00e-04 | grad 1.30 | tok/s 38286
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8181.pt
step   1010 | loss 1.5052 | lr 3.00e-04 | grad 1.35 | tok/s 21753
step   1020 | loss 1.6173 | lr 3.00e-04 | grad 1.26 | tok/s 40242
step   1030 | loss 1.8017 | lr 3.00e-04 | grad 1.52 | tok/s 38179
step   1040 | loss 2.2416 | lr 3.00e-04 | grad 1.99 | tok/s 39136
step   1050 | loss 1.9410 | lr 3.00e-04 | grad 1.06 | tok/s 39408
step   1060 | loss 1.6126 | lr 3.00e-04 | grad 4.94 | tok/s 38923
step   1070 | loss 1.5922 | lr 3.00e-04 | grad 1.25 | tok/s 38921
step   1080 | loss 1.5330 | lr 3.00e-04 | grad 1.31 | tok/s 40117
step   1090 | loss 1.5087 | lr 3.00e-04 | grad 1.15 | tok/s 40168
step   1100 | loss 1.4869 | lr 3.00e-04 | grad 1.43 | tok/s 40086
step   1110 | loss 1.4195 | lr 3.00e-04 | grad 1.23 | tok/s 40086
step   1120 | loss 1.6309 | lr 3.00e-04 | grad 1.12 | tok/s 39697
step   1130 | loss 2.0437 | lr 3.00e-04 | grad 1.30 | tok/s 38870
step   1140 | loss 2.0454 | lr 3.00e-04 | grad 1.45 | tok/s 39689
step   1150 | loss 2.1316 | lr 3.00e-04 | grad 3.30 | tok/s 39111
step   1160 | loss 1.8721 | lr 3.00e-04 | grad 1.91 | tok/s 37583
step   1170 | loss 1.8661 | lr 3.00e-04 | grad 2.80 | tok/s 37803
step   1180 | loss 1.6786 | lr 3.00e-04 | grad 1.09 | tok/s 39375
step   1190 | loss 1.9188 | lr 3.00e-04 | grad 1.59 | tok/s 39653
step   1200 | loss 1.5890 | lr 3.00e-04 | grad 1.33 | tok/s 40073
step   1210 | loss 1.5364 | lr 3.00e-04 | grad 1.66 | tok/s 38149
step   1220 | loss 1.6427 | lr 3.00e-04 | grad 1.73 | tok/s 38680
step   1230 | loss 1.7077 | lr 3.00e-04 | grad 1.26 | tok/s 38955
step   1240 | loss 1.5569 | lr 3.00e-04 | grad 1.08 | tok/s 39775
step   1250 | loss 1.7492 | lr 3.00e-04 | grad 1.91 | tok/s 38564
step   1260 | loss 1.8546 | lr 3.00e-04 | grad 2.02 | tok/s 40019
step   1270 | loss 1.6380 | lr 3.00e-04 | grad 2.28 | tok/s 38450
step   1280 | loss 1.6194 | lr 3.00e-04 | grad 3.52 | tok/s 38607
step   1290 | loss 1.6784 | lr 3.00e-04 | grad 1.34 | tok/s 37692
step   1300 | loss 1.7827 | lr 3.00e-04 | grad 3.11 | tok/s 37713
step   1310 | loss 1.9668 | lr 3.00e-04 | grad 1.42 | tok/s 39085
step   1320 | loss 1.6990 | lr 3.00e-04 | grad 1.11 | tok/s 39033
step   1330 | loss 1.8268 | lr 3.00e-04 | grad 0.95 | tok/s 39326
step   1340 | loss 1.8229 | lr 3.00e-04 | grad 4.59 | tok/s 37557
step   1350 | loss 1.7079 | lr 3.00e-04 | grad 1.74 | tok/s 39170
step   1360 | loss 1.7847 | lr 3.00e-04 | grad 1.39 | tok/s 37255
step   1370 | loss 1.7904 | lr 3.00e-04 | grad 3.06 | tok/s 39017
step   1380 | loss 1.8135 | lr 3.00e-04 | grad 1.46 | tok/s 38306
step   1390 | loss 1.6913 | lr 3.00e-04 | grad 1.09 | tok/s 39033
step   1400 | loss 1.7745 | lr 3.00e-04 | grad 1.27 | tok/s 37817
step   1410 | loss 1.5698 | lr 3.00e-04 | grad 1.62 | tok/s 37519
step   1420 | loss 1.5821 | lr 3.00e-04 | grad 1.50 | tok/s 39657
step   1430 | loss 2.0411 | lr 3.00e-04 | grad 1.52 | tok/s 38637
step   1440 | loss 1.6848 | lr 3.00e-04 | grad 2.05 | tok/s 38327
step   1450 | loss 1.7139 | lr 3.00e-04 | grad 1.16 | tok/s 39215
step   1460 | loss 1.7313 | lr 3.00e-04 | grad 1.36 | tok/s 37910
step   1470 | loss 1.6882 | lr 3.00e-04 | grad 1.41 | tok/s 37513
step   1480 | loss 1.6279 | lr 3.00e-04 | grad 1.70 | tok/s 38824
step   1490 | loss 1.7652 | lr 3.00e-04 | grad 1.31 | tok/s 38651
step   1500 | loss 1.9646 | lr 3.00e-04 | grad 2.22 | tok/s 39091
step   1510 | loss 1.5184 | lr 3.00e-04 | grad 1.52 | tok/s 38582
step   1520 | loss 1.6740 | lr 3.00e-04 | grad 1.11 | tok/s 38080
step   1530 | loss 1.6414 | lr 3.00e-04 | grad 1.77 | tok/s 39240
step   1540 | loss 1.7250 | lr 3.00e-04 | grad 1.41 | tok/s 39610
step   1550 | loss 1.6255 | lr 3.00e-04 | grad 1.77 | tok/s 38157
step   1560 | loss 1.5718 | lr 3.00e-04 | grad 1.09 | tok/s 39827
step   1570 | loss 1.5482 | lr 3.00e-04 | grad 1.39 | tok/s 38920
step   1580 | loss 1.4984 | lr 3.00e-04 | grad 1.77 | tok/s 39378
step   1590 | loss 1.6682 | lr 3.00e-04 | grad 1.45 | tok/s 37521
step   1600 | loss 1.3689 | lr 3.00e-04 | grad 2.34 | tok/s 39598
step   1610 | loss 2.1190 | lr 3.00e-04 | grad 2.50 | tok/s 38724
step   1620 | loss 2.3666 | lr 3.00e-04 | grad 1.44 | tok/s 39992
step   1630 | loss 2.0669 | lr 3.00e-04 | grad 1.72 | tok/s 40005
step   1640 | loss 1.9113 | lr 3.00e-04 | grad 1.42 | tok/s 39992
step   1650 | loss 1.8206 | lr 3.00e-04 | grad 1.49 | tok/s 39979
step   1660 | loss 1.7585 | lr 3.00e-04 | grad 1.40 | tok/s 40030
step   1670 | loss 1.8405 | lr 3.00e-04 | grad 2.16 | tok/s 38787
step   1680 | loss 1.6511 | lr 3.00e-04 | grad 1.34 | tok/s 38611
step   1690 | loss 1.6612 | lr 3.00e-04 | grad 1.27 | tok/s 37663
step   1700 | loss 1.5828 | lr 3.00e-04 | grad 1.41 | tok/s 38647
step   1710 | loss 1.4399 | lr 3.00e-04 | grad 1.59 | tok/s 39586
step   1720 | loss 1.6829 | lr 3.00e-04 | grad 1.20 | tok/s 37788
step   1730 | loss 1.6471 | lr 3.00e-04 | grad 1.49 | tok/s 38983
step   1740 | loss 1.6710 | lr 3.00e-04 | grad 1.15 | tok/s 39095
step   1750 | loss 1.5367 | lr 3.00e-04 | grad 1.33 | tok/s 38513
step   1760 | loss 1.5742 | lr 3.00e-04 | grad 1.16 | tok/s 38222
step   1770 | loss 1.9312 | lr 3.00e-04 | grad 2.14 | tok/s 39169
step   1780 | loss 1.9412 | lr 3.00e-04 | grad 1.99 | tok/s 36700
step   1790 | loss 1.5177 | lr 3.00e-04 | grad 0.96 | tok/s 37866
step   1800 | loss 1.5600 | lr 3.00e-04 | grad 1.17 | tok/s 38318
step   1810 | loss 1.6204 | lr 3.00e-04 | grad 1.61 | tok/s 38201
step   1820 | loss 1.6787 | lr 3.00e-04 | grad 1.42 | tok/s 38634
step   1830 | loss 1.6024 | lr 3.00e-04 | grad 1.29 | tok/s 37055
step   1840 | loss 1.6435 | lr 3.00e-04 | grad 0.99 | tok/s 38531
step   1850 | loss 1.6253 | lr 3.00e-04 | grad 1.77 | tok/s 37949
step   1860 | loss 1.6490 | lr 3.00e-04 | grad 1.23 | tok/s 37965
step   1870 | loss 1.6415 | lr 3.00e-04 | grad 3.52 | tok/s 38453
step   1880 | loss 1.6759 | lr 3.00e-04 | grad 1.67 | tok/s 38923
step   1890 | loss 1.4774 | lr 3.00e-04 | grad 1.20 | tok/s 39988
step   1900 | loss 1.4279 | lr 3.00e-04 | grad 1.30 | tok/s 40026
step   1910 | loss 1.3919 | lr 3.00e-04 | grad 0.91 | tok/s 39974
step   1920 | loss 1.3667 | lr 3.00e-04 | grad 1.09 | tok/s 40011
step   1930 | loss 1.3534 | lr 3.00e-04 | grad 1.56 | tok/s 39973
step   1940 | loss 1.7777 | lr 3.00e-04 | grad 2.09 | tok/s 37970
step   1950 | loss 1.6362 | lr 3.00e-04 | grad 1.49 | tok/s 37959
step   1960 | loss 1.6759 | lr 3.00e-04 | grad 1.32 | tok/s 38086
step   1970 | loss 1.7936 | lr 3.00e-04 | grad 1.84 | tok/s 38556
step   1980 | loss 1.6162 | lr 3.00e-04 | grad 1.44 | tok/s 37706
step   1990 | loss 1.8795 | lr 3.00e-04 | grad 1.52 | tok/s 38985
step   2000 | loss 1.4112 | lr 3.00e-04 | grad 1.42 | tok/s 39909
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4112.pt
step   2010 | loss 1.5072 | lr 3.00e-04 | grad 1.55 | tok/s 21745
step   2020 | loss 1.5604 | lr 3.00e-04 | grad 1.27 | tok/s 36880
step   2030 | loss 1.6938 | lr 3.00e-04 | grad 5.22 | tok/s 37709
step   2040 | loss 1.9398 | lr 3.00e-04 | grad 1.13 | tok/s 38669
step   2050 | loss 1.5473 | lr 3.00e-04 | grad 1.12 | tok/s 38990
step   2060 | loss 1.7079 | lr 3.00e-04 | grad 1.32 | tok/s 38783
step   2070 | loss 1.5895 | lr 3.00e-04 | grad 0.80 | tok/s 38697
step   2080 | loss 1.4817 | lr 3.00e-04 | grad 1.12 | tok/s 37487
step   2090 | loss 1.4093 | lr 3.00e-04 | grad 1.42 | tok/s 39350
step   2100 | loss 2.0952 | lr 3.00e-04 | grad 1.91 | tok/s 40010
step   2110 | loss 1.6745 | lr 3.00e-04 | grad 1.84 | tok/s 38720
step   2120 | loss 2.2177 | lr 3.00e-04 | grad 2.72 | tok/s 38849
step   2130 | loss 1.7925 | lr 3.00e-04 | grad 1.49 | tok/s 37870
step   2140 | loss 1.7101 | lr 3.00e-04 | grad 2.94 | tok/s 38807
step   2150 | loss 1.8830 | lr 3.00e-04 | grad 1.52 | tok/s 38308
step   2160 | loss 1.7401 | lr 3.00e-04 | grad 3.14 | tok/s 38785
step   2170 | loss 1.6116 | lr 3.00e-04 | grad 2.62 | tok/s 39114
step   2180 | loss 1.3743 | lr 3.00e-04 | grad 0.91 | tok/s 39851
step   2190 | loss 1.7480 | lr 3.00e-04 | grad 1.56 | tok/s 38467
step   2200 | loss 1.5322 | lr 3.00e-04 | grad 1.38 | tok/s 39668
step   2210 | loss 1.6766 | lr 3.00e-04 | grad 1.21 | tok/s 39387
step   2220 | loss 1.5771 | lr 3.00e-04 | grad 1.23 | tok/s 38452
step   2230 | loss 1.6042 | lr 3.00e-04 | grad 2.08 | tok/s 37174
step   2240 | loss 1.6771 | lr 3.00e-04 | grad 1.66 | tok/s 39095
step   2250 | loss 1.5862 | lr 3.00e-04 | grad 1.20 | tok/s 37847
step   2260 | loss 1.6386 | lr 3.00e-04 | grad 1.18 | tok/s 39322
step   2270 | loss 1.7764 | lr 3.00e-04 | grad 1.72 | tok/s 37371
step   2280 | loss 1.7078 | lr 3.00e-04 | grad 1.11 | tok/s 37991
step   2290 | loss 1.4650 | lr 3.00e-04 | grad 1.30 | tok/s 38777
step   2300 | loss 1.6974 | lr 3.00e-04 | grad 1.30 | tok/s 37459
step   2310 | loss 1.5776 | lr 3.00e-04 | grad 1.61 | tok/s 38430
step   2320 | loss 1.5891 | lr 3.00e-04 | grad 1.15 | tok/s 39827
step   2330 | loss 1.5427 | lr 3.00e-04 | grad 1.27 | tok/s 40116
step   2340 | loss 1.5041 | lr 3.00e-04 | grad 1.14 | tok/s 40084
step   2350 | loss 1.4570 | lr 3.00e-04 | grad 1.13 | tok/s 40029
step   2360 | loss 1.4498 | lr 3.00e-04 | grad 1.26 | tok/s 40067
step   2370 | loss 1.3937 | lr 3.00e-04 | grad 1.02 | tok/s 39986
step   2380 | loss 1.3836 | lr 3.00e-04 | grad 1.09 | tok/s 40013
step   2390 | loss 1.3806 | lr 3.00e-04 | grad 1.23 | tok/s 40021
step   2400 | loss 1.3837 | lr 3.00e-04 | grad 1.19 | tok/s 40045
step   2410 | loss 1.3901 | lr 3.00e-04 | grad 1.37 | tok/s 39982
step   2420 | loss 1.7463 | lr 3.00e-04 | grad 1.29 | tok/s 38739
step   2430 | loss 1.1529 | lr 3.00e-04 | grad 1.41 | tok/s 39079
step   2440 | loss 1.6199 | lr 3.00e-04 | grad 1.13 | tok/s 37432
step   2450 | loss 1.5051 | lr 3.00e-04 | grad 1.21 | tok/s 37609
step   2460 | loss 1.6477 | lr 3.00e-04 | grad 1.94 | tok/s 39355
step   2470 | loss 1.5106 | lr 3.00e-04 | grad 1.23 | tok/s 39018
step   2480 | loss 1.6435 | lr 3.00e-04 | grad 1.24 | tok/s 38490
step   2490 | loss 1.6103 | lr 3.00e-04 | grad 1.80 | tok/s 39319
step   2500 | loss 1.8360 | lr 3.00e-04 | grad 2.38 | tok/s 38653
step   2510 | loss 1.6825 | lr 3.00e-04 | grad 3.14 | tok/s 38433
step   2520 | loss 1.5610 | lr 3.00e-04 | grad 1.14 | tok/s 38992
step   2530 | loss 1.7253 | lr 3.00e-04 | grad 1.28 | tok/s 38437
step   2540 | loss 1.5892 | lr 3.00e-04 | grad 1.20 | tok/s 37433
step   2550 | loss 1.5703 | lr 3.00e-04 | grad 1.16 | tok/s 38459
step   2560 | loss 1.5746 | lr 3.00e-04 | grad 1.38 | tok/s 38300
step   2570 | loss 1.6316 | lr 3.00e-04 | grad 1.42 | tok/s 37725
step   2580 | loss 1.8257 | lr 3.00e-04 | grad 1.55 | tok/s 38953
step   2590 | loss 1.5377 | lr 3.00e-04 | grad 1.05 | tok/s 37357
step   2600 | loss 1.5901 | lr 3.00e-04 | grad 1.48 | tok/s 37140
step   2610 | loss 1.7001 | lr 3.00e-04 | grad 1.25 | tok/s 39313
step   2620 | loss 1.6377 | lr 3.00e-04 | grad 1.20 | tok/s 38260
step   2630 | loss 1.4825 | lr 3.00e-04 | grad 1.37 | tok/s 39563
step   2640 | loss 1.4972 | lr 3.00e-04 | grad 1.74 | tok/s 38747
step   2650 | loss 1.4348 | lr 3.00e-04 | grad 1.12 | tok/s 37885
step   2660 | loss 1.5047 | lr 3.00e-04 | grad 1.23 | tok/s 38691
step   2670 | loss 1.4536 | lr 3.00e-04 | grad 1.95 | tok/s 39921
step   2680 | loss 1.5438 | lr 3.00e-04 | grad 1.35 | tok/s 37670
step   2690 | loss 1.4589 | lr 3.00e-04 | grad 1.10 | tok/s 37833
step   2700 | loss 1.5745 | lr 3.00e-04 | grad 1.14 | tok/s 38030
step   2710 | loss 1.6146 | lr 3.00e-04 | grad 1.06 | tok/s 38290
step   2720 | loss 1.8189 | lr 3.00e-04 | grad 1.15 | tok/s 38983
step   2730 | loss 1.5168 | lr 3.00e-04 | grad 1.03 | tok/s 38131
step   2740 | loss 1.6012 | lr 3.00e-04 | grad 1.05 | tok/s 38291
step   2750 | loss 1.6185 | lr 3.00e-04 | grad 1.62 | tok/s 38551
step   2760 | loss 1.4443 | lr 3.00e-04 | grad 1.48 | tok/s 40012
step   2770 | loss 1.6251 | lr 3.00e-04 | grad 3.53 | tok/s 38548
step   2780 | loss 1.4534 | lr 3.00e-04 | grad 1.30 | tok/s 39074
step   2790 | loss 1.5534 | lr 3.00e-04 | grad 1.16 | tok/s 38654
step   2800 | loss 1.6569 | lr 3.00e-04 | grad 0.98 | tok/s 37413
step   2810 | loss 1.5873 | lr 3.00e-04 | grad 1.33 | tok/s 38327
step   2820 | loss 1.5740 | lr 3.00e-04 | grad 1.55 | tok/s 36380
step   2830 | loss 1.3927 | lr 3.00e-04 | grad 1.08 | tok/s 38144
step   2840 | loss 1.4996 | lr 3.00e-04 | grad 1.35 | tok/s 37161
step   2850 | loss 1.3507 | lr 3.00e-04 | grad 1.38 | tok/s 39951
step   2860 | loss 1.2969 | lr 3.00e-04 | grad 1.02 | tok/s 40013
step   2870 | loss 1.5851 | lr 3.00e-04 | grad 1.23 | tok/s 37992
step   2880 | loss 1.5439 | lr 3.00e-04 | grad 1.24 | tok/s 37142
step   2890 | loss 1.6242 | lr 3.00e-04 | grad 1.24 | tok/s 38555

Training complete! Final step: 2898
