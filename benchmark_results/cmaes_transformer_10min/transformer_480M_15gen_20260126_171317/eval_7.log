Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_7/levelllama_100m_20260126_171322
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 361,351,296 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.3376 | lr 3.00e-04 | grad 2.98 | tok/s 6658
step     20 | loss 2.7285 | lr 3.00e-04 | grad 1.37 | tok/s 20734
step     30 | loss 2.7514 | lr 3.00e-04 | grad 1.99 | tok/s 20982
step     40 | loss 2.8440 | lr 3.00e-04 | grad 1.41 | tok/s 20123
step     50 | loss 3.2955 | lr 3.00e-04 | grad 3.62 | tok/s 20468
step     60 | loss 2.4820 | lr 3.00e-04 | grad 6.66 | tok/s 21118
step     70 | loss 2.4387 | lr 3.00e-04 | grad 2.25 | tok/s 21380
step     80 | loss 6.0477 | lr 3.00e-04 | grad 7.41 | tok/s 21512
step     90 | loss 4.5390 | lr 3.00e-04 | grad 1.93 | tok/s 21872
step    100 | loss 3.9553 | lr 3.00e-04 | grad 2.56 | tok/s 21887
step    110 | loss 3.7913 | lr 3.00e-04 | grad 5.72 | tok/s 21877
step    120 | loss 3.7316 | lr 3.00e-04 | grad 6.91 | tok/s 21803
step    130 | loss 3.6752 | lr 3.00e-04 | grad 3.44 | tok/s 21729
step    140 | loss 3.1668 | lr 3.00e-04 | grad 3.30 | tok/s 21749
step    150 | loss 3.6101 | lr 3.00e-04 | grad 5.53 | tok/s 21696
step    160 | loss 3.0174 | lr 3.00e-04 | grad 4.56 | tok/s 21624
step    170 | loss 3.0359 | lr 3.00e-04 | grad 3.72 | tok/s 21591
step    180 | loss 2.8956 | lr 3.00e-04 | grad 3.59 | tok/s 21597
step    190 | loss 2.9931 | lr 3.00e-04 | grad 4.78 | tok/s 21523
step    200 | loss 2.6371 | lr 3.00e-04 | grad 2.73 | tok/s 21519
step    210 | loss 2.5945 | lr 3.00e-04 | grad 3.05 | tok/s 21441
step    220 | loss 2.6673 | lr 3.00e-04 | grad 2.48 | tok/s 21146
step    230 | loss 3.3281 | lr 3.00e-04 | grad 1.57 | tok/s 20903
step    240 | loss 2.5739 | lr 3.00e-04 | grad 2.56 | tok/s 19817
step    250 | loss 2.4403 | lr 3.00e-04 | grad 1.09 | tok/s 20334
step    260 | loss 2.2229 | lr 3.00e-04 | grad 1.23 | tok/s 20950
step    270 | loss 2.4901 | lr 3.00e-04 | grad 1.28 | tok/s 20601
step    280 | loss 2.6494 | lr 3.00e-04 | grad 2.75 | tok/s 20200
step    290 | loss 2.8025 | lr 3.00e-04 | grad 1.44 | tok/s 21219
step    300 | loss 1.7561 | lr 3.00e-04 | grad 1.75 | tok/s 21229
step    310 | loss 2.9253 | lr 3.00e-04 | grad 1.52 | tok/s 20777
step    320 | loss 2.5806 | lr 3.00e-04 | grad 3.05 | tok/s 20350
step    330 | loss 2.3566 | lr 3.00e-04 | grad 1.05 | tok/s 19597
step    340 | loss 2.6026 | lr 3.00e-04 | grad 1.09 | tok/s 19890
step    350 | loss 2.4352 | lr 3.00e-04 | grad 1.54 | tok/s 20427
step    360 | loss 2.6326 | lr 3.00e-04 | grad 2.34 | tok/s 20830
step    370 | loss 2.2542 | lr 3.00e-04 | grad 1.01 | tok/s 18854
step    380 | loss 2.1948 | lr 3.00e-04 | grad 1.23 | tok/s 20049
step    390 | loss 2.0875 | lr 3.00e-04 | grad 1.72 | tok/s 20930
step    400 | loss 2.0597 | lr 3.00e-04 | grad 1.57 | tok/s 20727
step    410 | loss 1.9929 | lr 3.00e-04 | grad 1.02 | tok/s 20186
step    420 | loss 2.1701 | lr 3.00e-04 | grad 1.86 | tok/s 19265
step    430 | loss 2.4726 | lr 3.00e-04 | grad 1.58 | tok/s 20506
step    440 | loss 2.4875 | lr 3.00e-04 | grad 1.52 | tok/s 19332
step    450 | loss 2.3834 | lr 3.00e-04 | grad 1.02 | tok/s 19980
step    460 | loss 2.2096 | lr 3.00e-04 | grad 1.91 | tok/s 19531
step    470 | loss 2.2699 | lr 3.00e-04 | grad 1.22 | tok/s 20142
step    480 | loss 2.7191 | lr 3.00e-04 | grad 2.69 | tok/s 20165
step    490 | loss 2.1682 | lr 3.00e-04 | grad 1.59 | tok/s 19029
step    500 | loss 2.1441 | lr 3.00e-04 | grad 1.50 | tok/s 20285
step    510 | loss 2.1588 | lr 3.00e-04 | grad 1.07 | tok/s 20541
step    520 | loss 2.1524 | lr 3.00e-04 | grad 1.34 | tok/s 20571
step    530 | loss 2.3068 | lr 3.00e-04 | grad 1.17 | tok/s 19777
step    540 | loss 2.0629 | lr 3.00e-04 | grad 1.15 | tok/s 19751
step    550 | loss 1.9217 | lr 3.00e-04 | grad 1.23 | tok/s 19314
step    560 | loss 2.0951 | lr 3.00e-04 | grad 1.23 | tok/s 18869
step    570 | loss 2.0376 | lr 3.00e-04 | grad 1.83 | tok/s 19374
step    580 | loss 1.9257 | lr 3.00e-04 | grad 1.30 | tok/s 19300
step    590 | loss 2.2772 | lr 3.00e-04 | grad 1.30 | tok/s 19764
step    600 | loss 2.1657 | lr 3.00e-04 | grad 1.09 | tok/s 19058
step    610 | loss 1.9986 | lr 3.00e-04 | grad 1.20 | tok/s 20077
step    620 | loss 1.8601 | lr 3.00e-04 | grad 0.98 | tok/s 18943
step    630 | loss 2.0251 | lr 3.00e-04 | grad 1.73 | tok/s 19063
step    640 | loss 2.1930 | lr 3.00e-04 | grad 1.30 | tok/s 19560
step    650 | loss 2.0247 | lr 3.00e-04 | grad 1.45 | tok/s 19711
step    660 | loss 2.0389 | lr 3.00e-04 | grad 0.86 | tok/s 19792
step    670 | loss 2.2650 | lr 3.00e-04 | grad 3.03 | tok/s 19900
step    680 | loss 2.0266 | lr 3.00e-04 | grad 1.07 | tok/s 19508
step    690 | loss 2.3460 | lr 3.00e-04 | grad 1.61 | tok/s 20121
step    700 | loss 2.1766 | lr 3.00e-04 | grad 1.62 | tok/s 20508
step    710 | loss 1.9475 | lr 3.00e-04 | grad 1.41 | tok/s 19206
step    720 | loss 1.7943 | lr 3.00e-04 | grad 1.25 | tok/s 18887
step    730 | loss 1.9058 | lr 3.00e-04 | grad 1.53 | tok/s 20489
step    740 | loss 1.9285 | lr 3.00e-04 | grad 1.29 | tok/s 20159
step    750 | loss 1.7596 | lr 3.00e-04 | grad 1.27 | tok/s 20531
step    760 | loss 1.6297 | lr 3.00e-04 | grad 1.48 | tok/s 20505
step    770 | loss 1.6034 | lr 3.00e-04 | grad 1.06 | tok/s 20502
step    780 | loss 1.5469 | lr 3.00e-04 | grad 1.16 | tok/s 20412
step    790 | loss 1.5930 | lr 3.00e-04 | grad 1.55 | tok/s 19860
step    800 | loss 2.2771 | lr 3.00e-04 | grad 2.36 | tok/s 19799
step    810 | loss 1.9816 | lr 3.00e-04 | grad 1.32 | tok/s 19690
step    820 | loss 1.9896 | lr 3.00e-04 | grad 1.56 | tok/s 18809
step    830 | loss 2.0776 | lr 3.00e-04 | grad 1.20 | tok/s 20314
step    840 | loss 1.9979 | lr 3.00e-04 | grad 1.19 | tok/s 20486
step    850 | loss 2.0199 | lr 3.00e-04 | grad 1.32 | tok/s 20390
step    860 | loss 1.9499 | lr 3.00e-04 | grad 1.90 | tok/s 20098
step    870 | loss 1.8567 | lr 3.00e-04 | grad 1.27 | tok/s 19440
step    880 | loss 2.0179 | lr 3.00e-04 | grad 1.14 | tok/s 19543
step    890 | loss 1.9810 | lr 3.00e-04 | grad 1.62 | tok/s 19807
step    900 | loss 1.8704 | lr 3.00e-04 | grad 1.23 | tok/s 19737
step    910 | loss 1.7346 | lr 3.00e-04 | grad 1.58 | tok/s 19382
step    920 | loss 1.9394 | lr 3.00e-04 | grad 2.12 | tok/s 20168
step    930 | loss 1.8905 | lr 3.00e-04 | grad 1.77 | tok/s 19235
step    940 | loss 1.8662 | lr 3.00e-04 | grad 1.11 | tok/s 20230
step    950 | loss 1.9111 | lr 3.00e-04 | grad 1.33 | tok/s 20400
step    960 | loss 1.8307 | lr 3.00e-04 | grad 1.39 | tok/s 20406
step    970 | loss 1.9644 | lr 3.00e-04 | grad 1.53 | tok/s 19123
step    980 | loss 1.9034 | lr 3.00e-04 | grad 1.18 | tok/s 19683
step    990 | loss 1.8153 | lr 3.00e-04 | grad 1.26 | tok/s 20036
step   1000 | loss 2.1489 | lr 3.00e-04 | grad 5.25 | tok/s 19237
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1489.pt
step   1010 | loss 2.0443 | lr 3.00e-04 | grad 1.39 | tok/s 7214
step   1020 | loss 1.8750 | lr 3.00e-04 | grad 1.08 | tok/s 18902
step   1030 | loss 1.7582 | lr 3.00e-04 | grad 1.28 | tok/s 19654
step   1040 | loss 1.7456 | lr 3.00e-04 | grad 1.05 | tok/s 20271
step   1050 | loss 1.8415 | lr 3.00e-04 | grad 1.50 | tok/s 18718
step   1060 | loss 2.0259 | lr 3.00e-04 | grad 1.55 | tok/s 20231
step   1070 | loss 2.0971 | lr 3.00e-04 | grad 1.38 | tok/s 20127
step   1080 | loss 1.6576 | lr 3.00e-04 | grad 1.01 | tok/s 18308
step   1090 | loss 1.4291 | lr 3.00e-04 | grad 0.74 | tok/s 20198
step   1100 | loss 1.6868 | lr 3.00e-04 | grad 1.89 | tok/s 19612
step   1110 | loss 1.7588 | lr 3.00e-04 | grad 1.11 | tok/s 20583
step   1120 | loss 1.6564 | lr 3.00e-04 | grad 1.45 | tok/s 20537
step   1130 | loss 1.5986 | lr 3.00e-04 | grad 1.15 | tok/s 20481
step   1140 | loss 1.5753 | lr 3.00e-04 | grad 1.25 | tok/s 20508
step   1150 | loss 1.5916 | lr 3.00e-04 | grad 1.16 | tok/s 20523
step   1160 | loss 1.4977 | lr 3.00e-04 | grad 1.09 | tok/s 20515
step   1170 | loss 1.5161 | lr 3.00e-04 | grad 1.21 | tok/s 20485
step   1180 | loss 1.6432 | lr 3.00e-04 | grad 0.97 | tok/s 20492
step   1190 | loss 1.5277 | lr 3.00e-04 | grad 1.37 | tok/s 20579
step   1200 | loss 1.5109 | lr 3.00e-04 | grad 1.33 | tok/s 20529
step   1210 | loss 1.5369 | lr 3.00e-04 | grad 1.37 | tok/s 20490
step   1220 | loss 1.5322 | lr 3.00e-04 | grad 1.38 | tok/s 20480
step   1230 | loss 1.5168 | lr 3.00e-04 | grad 1.13 | tok/s 20504
step   1240 | loss 1.4663 | lr 3.00e-04 | grad 1.05 | tok/s 20512
step   1250 | loss 2.0925 | lr 3.00e-04 | grad 1.59 | tok/s 19413
step   1260 | loss 1.5980 | lr 3.00e-04 | grad 1.92 | tok/s 19140
step   1270 | loss 1.8762 | lr 3.00e-04 | grad 2.88 | tok/s 19158
step   1280 | loss 1.8886 | lr 3.00e-04 | grad 1.18 | tok/s 19763
step   1290 | loss 1.7209 | lr 3.00e-04 | grad 1.37 | tok/s 19634
step   1300 | loss 1.7857 | lr 3.00e-04 | grad 1.34 | tok/s 19690
step   1310 | loss 1.7355 | lr 3.00e-04 | grad 1.33 | tok/s 20033
step   1320 | loss 1.8336 | lr 3.00e-04 | grad 1.29 | tok/s 20129
step   1330 | loss 1.8581 | lr 3.00e-04 | grad 1.46 | tok/s 20150
step   1340 | loss 1.7237 | lr 3.00e-04 | grad 4.50 | tok/s 19192
step   1350 | loss 1.9144 | lr 3.00e-04 | grad 1.43 | tok/s 18606
step   1360 | loss 1.8112 | lr 3.00e-04 | grad 1.54 | tok/s 19755
step   1370 | loss 1.6276 | lr 3.00e-04 | grad 0.91 | tok/s 19458
step   1380 | loss 1.9320 | lr 3.00e-04 | grad 1.05 | tok/s 18718
step   1390 | loss 1.7543 | lr 3.00e-04 | grad 1.10 | tok/s 19902
step   1400 | loss 1.6692 | lr 3.00e-04 | grad 1.16 | tok/s 19216
step   1410 | loss 1.7008 | lr 3.00e-04 | grad 1.88 | tok/s 19255
step   1420 | loss 1.9836 | lr 3.00e-04 | grad 3.02 | tok/s 19260
step   1430 | loss 1.6650 | lr 3.00e-04 | grad 1.18 | tok/s 19626
step   1440 | loss 1.4463 | lr 3.00e-04 | grad 1.23 | tok/s 20294
step   1450 | loss 1.4170 | lr 3.00e-04 | grad 2.86 | tok/s 20383
step   1460 | loss 1.8837 | lr 3.00e-04 | grad 1.23 | tok/s 19231
step   1470 | loss 1.7997 | lr 3.00e-04 | grad 1.14 | tok/s 20021
step   1480 | loss 2.2816 | lr 3.00e-04 | grad 2.38 | tok/s 20108
step   1490 | loss 2.1125 | lr 3.00e-04 | grad 1.27 | tok/s 20379
step   1500 | loss 1.6922 | lr 3.00e-04 | grad 1.20 | tok/s 20433
step   1510 | loss 1.7656 | lr 3.00e-04 | grad 1.28 | tok/s 20253
step   1520 | loss 1.6598 | lr 3.00e-04 | grad 2.42 | tok/s 19788
step   1530 | loss 1.6379 | lr 3.00e-04 | grad 1.08 | tok/s 20187
step   1540 | loss 1.8238 | lr 3.00e-04 | grad 1.23 | tok/s 19083
step   1550 | loss 1.5945 | lr 3.00e-04 | grad 1.80 | tok/s 20331
step   1560 | loss 1.7648 | lr 3.00e-04 | grad 1.80 | tok/s 19219
step   1570 | loss 1.6293 | lr 3.00e-04 | grad 1.25 | tok/s 20411
step   1580 | loss 2.1131 | lr 3.00e-04 | grad 1.89 | tok/s 19985
step   1590 | loss 2.0145 | lr 3.00e-04 | grad 1.48 | tok/s 19228
step   1600 | loss 1.2851 | lr 3.00e-04 | grad 0.86 | tok/s 20429
step   1610 | loss 1.2183 | lr 3.00e-04 | grad 1.66 | tok/s 19882
step   1620 | loss 1.6667 | lr 3.00e-04 | grad 1.71 | tok/s 18580
step   1630 | loss 1.7229 | lr 3.00e-04 | grad 1.34 | tok/s 19885
step   1640 | loss 1.5541 | lr 3.00e-04 | grad 1.41 | tok/s 19344
step   1650 | loss 1.7063 | lr 3.00e-04 | grad 1.31 | tok/s 18646
step   1660 | loss 1.7029 | lr 3.00e-04 | grad 1.17 | tok/s 19864
step   1670 | loss 1.6997 | lr 3.00e-04 | grad 2.34 | tok/s 19741
step   1680 | loss 1.9192 | lr 3.00e-04 | grad 1.23 | tok/s 18977
step   1690 | loss 1.7335 | lr 3.00e-04 | grad 3.02 | tok/s 19385
step   1700 | loss 1.7523 | lr 3.00e-04 | grad 1.45 | tok/s 19759
step   1710 | loss 1.7346 | lr 3.00e-04 | grad 1.13 | tok/s 19421
step   1720 | loss 1.8251 | lr 3.00e-04 | grad 1.66 | tok/s 20307
step   1730 | loss 1.7850 | lr 3.00e-04 | grad 1.45 | tok/s 20507
step   1740 | loss 1.7469 | lr 3.00e-04 | grad 1.65 | tok/s 19914
step   1750 | loss 1.7811 | lr 3.00e-04 | grad 1.62 | tok/s 19594
step   1760 | loss 1.7223 | lr 3.00e-04 | grad 1.30 | tok/s 19702
step   1770 | loss 1.6325 | lr 3.00e-04 | grad 1.29 | tok/s 19353
step   1780 | loss 1.6805 | lr 3.00e-04 | grad 1.18 | tok/s 20036
step   1790 | loss 1.6200 | lr 3.00e-04 | grad 1.10 | tok/s 19592
step   1800 | loss 1.7934 | lr 3.00e-04 | grad 1.44 | tok/s 19799
step   1810 | loss 1.6467 | lr 3.00e-04 | grad 1.26 | tok/s 19005
step   1820 | loss 1.7283 | lr 3.00e-04 | grad 2.53 | tok/s 19248
step   1830 | loss 1.6326 | lr 3.00e-04 | grad 1.43 | tok/s 20115
step   1840 | loss 1.7117 | lr 3.00e-04 | grad 1.48 | tok/s 19221
step   1850 | loss 1.6365 | lr 3.00e-04 | grad 1.20 | tok/s 20074
step   1860 | loss 1.5369 | lr 3.00e-04 | grad 1.28 | tok/s 19493
step   1870 | loss 1.6420 | lr 3.00e-04 | grad 1.95 | tok/s 19591
step   1880 | loss 1.4909 | lr 3.00e-04 | grad 1.38 | tok/s 19140
step   1890 | loss 1.7363 | lr 3.00e-04 | grad 1.14 | tok/s 18139
step   1900 | loss 1.5665 | lr 3.00e-04 | grad 1.48 | tok/s 19685
step   1910 | loss 1.6307 | lr 3.00e-04 | grad 1.37 | tok/s 18626
step   1920 | loss 1.6191 | lr 3.00e-04 | grad 1.25 | tok/s 20356
step   1930 | loss 1.6252 | lr 3.00e-04 | grad 1.52 | tok/s 19211
step   1940 | loss 1.6115 | lr 3.00e-04 | grad 1.25 | tok/s 19923
step   1950 | loss 2.2824 | lr 3.00e-04 | grad 1.99 | tok/s 20164
step   1960 | loss 2.0378 | lr 3.00e-04 | grad 1.91 | tok/s 20452
step   1970 | loss 1.8389 | lr 3.00e-04 | grad 1.58 | tok/s 19898
step   1980 | loss 1.7773 | lr 3.00e-04 | grad 1.31 | tok/s 19019
step   1990 | loss 1.7878 | lr 3.00e-04 | grad 3.28 | tok/s 19418
step   2000 | loss 1.6619 | lr 3.00e-04 | grad 1.22 | tok/s 19699
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6619.pt
step   2010 | loss 1.2134 | lr 3.00e-04 | grad 1.13 | tok/s 7881
step   2020 | loss 1.4858 | lr 3.00e-04 | grad 1.30 | tok/s 19575
step   2030 | loss 1.3838 | lr 3.00e-04 | grad 0.49 | tok/s 20641
step   2040 | loss 1.5987 | lr 3.00e-04 | grad 1.21 | tok/s 20612
step   2050 | loss 1.6106 | lr 3.00e-04 | grad 1.25 | tok/s 20160
step   2060 | loss 1.7531 | lr 3.00e-04 | grad 1.27 | tok/s 18949
step   2070 | loss 1.8203 | lr 3.00e-04 | grad 1.67 | tok/s 19624
step   2080 | loss 2.4197 | lr 3.00e-04 | grad 2.23 | tok/s 20304
step   2090 | loss 1.9594 | lr 3.00e-04 | grad 1.81 | tok/s 20419
step   2100 | loss 1.6661 | lr 3.00e-04 | grad 1.52 | tok/s 19897
step   2110 | loss 1.8403 | lr 3.00e-04 | grad 6.22 | tok/s 19522
step   2120 | loss 1.1787 | lr 3.00e-04 | grad 1.24 | tok/s 20191
step   2130 | loss 1.2795 | lr 3.00e-04 | grad 1.81 | tok/s 20171
step   2140 | loss 1.7160 | lr 3.00e-04 | grad 1.20 | tok/s 19528
step   2150 | loss 1.4640 | lr 3.00e-04 | grad 1.30 | tok/s 20530
step   2160 | loss 1.3809 | lr 3.00e-04 | grad 1.11 | tok/s 20525
step   2170 | loss 1.4222 | lr 3.00e-04 | grad 1.14 | tok/s 20424
step   2180 | loss 1.3791 | lr 3.00e-04 | grad 1.26 | tok/s 20519
step   2190 | loss 1.3818 | lr 3.00e-04 | grad 0.99 | tok/s 20534
step   2200 | loss 1.3906 | lr 3.00e-04 | grad 1.20 | tok/s 20519
step   2210 | loss 1.3161 | lr 3.00e-04 | grad 1.06 | tok/s 20452
step   2220 | loss 1.3195 | lr 3.00e-04 | grad 1.13 | tok/s 20498
step   2230 | loss 1.5116 | lr 3.00e-04 | grad 1.34 | tok/s 20171
step   2240 | loss 1.5663 | lr 3.00e-04 | grad 1.30 | tok/s 20483
step   2250 | loss 1.8675 | lr 3.00e-04 | grad 2.28 | tok/s 19718
step   2260 | loss 1.8559 | lr 3.00e-04 | grad 1.25 | tok/s 19986
step   2270 | loss 2.1405 | lr 3.00e-04 | grad 2.41 | tok/s 20362
step   2280 | loss 1.7279 | lr 3.00e-04 | grad 1.54 | tok/s 20299
step   2290 | loss 1.5617 | lr 3.00e-04 | grad 1.60 | tok/s 19741
step   2300 | loss 2.2617 | lr 3.00e-04 | grad 2.11 | tok/s 20206
step   2310 | loss 1.6905 | lr 3.00e-04 | grad 1.21 | tok/s 19238
step   2320 | loss 1.8162 | lr 3.00e-04 | grad 3.28 | tok/s 19278
step   2330 | loss 1.9314 | lr 3.00e-04 | grad 1.68 | tok/s 19627
step   2340 | loss 1.6248 | lr 3.00e-04 | grad 3.50 | tok/s 19026
step   2350 | loss 1.5481 | lr 3.00e-04 | grad 2.45 | tok/s 20048
step   2360 | loss 1.5934 | lr 3.00e-04 | grad 1.45 | tok/s 20316
step   2370 | loss 1.6846 | lr 3.00e-04 | grad 2.12 | tok/s 20068
step   2380 | loss 1.8887 | lr 3.00e-04 | grad 1.27 | tok/s 20514
step   2390 | loss 1.5353 | lr 3.00e-04 | grad 1.48 | tok/s 20442
step   2400 | loss 1.3547 | lr 3.00e-04 | grad 1.24 | tok/s 20538
step   2410 | loss 1.2711 | lr 3.00e-04 | grad 1.25 | tok/s 19907
step   2420 | loss 1.6298 | lr 3.00e-04 | grad 2.25 | tok/s 19224
step   2430 | loss 1.6148 | lr 3.00e-04 | grad 1.50 | tok/s 19462
step   2440 | loss 1.4707 | lr 3.00e-04 | grad 2.33 | tok/s 20111
step   2450 | loss 1.6188 | lr 3.00e-04 | grad 1.49 | tok/s 19594
step   2460 | loss 1.5790 | lr 3.00e-04 | grad 1.58 | tok/s 20365
step   2470 | loss 1.3952 | lr 3.00e-04 | grad 1.62 | tok/s 20187
step   2480 | loss 1.4741 | lr 3.00e-04 | grad 1.04 | tok/s 20484
step   2490 | loss 1.5003 | lr 3.00e-04 | grad 1.43 | tok/s 19444
step   2500 | loss 1.7618 | lr 3.00e-04 | grad 1.36 | tok/s 20098
step   2510 | loss 1.5932 | lr 3.00e-04 | grad 1.42 | tok/s 20544
step   2520 | loss 1.7376 | lr 3.00e-04 | grad 2.39 | tok/s 20397
step   2530 | loss 1.5159 | lr 3.00e-04 | grad 1.30 | tok/s 19791
step   2540 | loss 1.5787 | lr 3.00e-04 | grad 1.73 | tok/s 19720
step   2550 | loss 1.4228 | lr 3.00e-04 | grad 1.25 | tok/s 20462
step   2560 | loss 1.5984 | lr 3.00e-04 | grad 3.61 | tok/s 19198
step   2570 | loss 1.6236 | lr 3.00e-04 | grad 1.23 | tok/s 19951
step   2580 | loss 1.5350 | lr 3.00e-04 | grad 1.33 | tok/s 18714
step   2590 | loss 1.5813 | lr 3.00e-04 | grad 1.55 | tok/s 19785
step   2600 | loss 1.7794 | lr 3.00e-04 | grad 2.17 | tok/s 19041
step   2610 | loss 1.8317 | lr 3.00e-04 | grad 1.57 | tok/s 20479
step   2620 | loss 1.7054 | lr 3.00e-04 | grad 1.37 | tok/s 19697
step   2630 | loss 1.6005 | lr 3.00e-04 | grad 1.24 | tok/s 20231
step   2640 | loss 1.6130 | lr 3.00e-04 | grad 1.41 | tok/s 19763
step   2650 | loss 1.8881 | lr 3.00e-04 | grad 2.17 | tok/s 20631
step   2660 | loss 1.5235 | lr 3.00e-04 | grad 1.40 | tok/s 19887
step   2670 | loss 1.5744 | lr 3.00e-04 | grad 1.73 | tok/s 19045
step   2680 | loss 1.7934 | lr 3.00e-04 | grad 3.77 | tok/s 19412
step   2690 | loss 1.5328 | lr 3.00e-04 | grad 1.20 | tok/s 20456
step   2700 | loss 1.6417 | lr 3.00e-04 | grad 1.49 | tok/s 19886
step   2710 | loss 1.7962 | lr 3.00e-04 | grad 1.77 | tok/s 19580
step   2720 | loss 1.5075 | lr 3.00e-04 | grad 1.41 | tok/s 18778
step   2730 | loss 1.4725 | lr 3.00e-04 | grad 1.13 | tok/s 20134
step   2740 | loss 1.8314 | lr 3.00e-04 | grad 2.98 | tok/s 19834
step   2750 | loss 1.9366 | lr 3.00e-04 | grad 1.48 | tok/s 20361
step   2760 | loss 1.4644 | lr 3.00e-04 | grad 1.46 | tok/s 18995
step   2770 | loss 1.6982 | lr 3.00e-04 | grad 1.62 | tok/s 19574
step   2780 | loss 1.4408 | lr 3.00e-04 | grad 1.02 | tok/s 20575
step   2790 | loss 1.8090 | lr 3.00e-04 | grad 2.98 | tok/s 19036
step   2800 | loss 1.5581 | lr 3.00e-04 | grad 1.19 | tok/s 19680
step   2810 | loss 1.4270 | lr 3.00e-04 | grad 1.48 | tok/s 19689
step   2820 | loss 1.5509 | lr 3.00e-04 | grad 1.31 | tok/s 18945
step   2830 | loss 1.4895 | lr 3.00e-04 | grad 1.84 | tok/s 20269
step   2840 | loss 1.2281 | lr 3.00e-04 | grad 1.75 | tok/s 20567
step   2850 | loss 1.9346 | lr 3.00e-04 | grad 1.39 | tok/s 19818
step   2860 | loss 1.8708 | lr 3.00e-04 | grad 1.29 | tok/s 19750
step   2870 | loss 1.5025 | lr 3.00e-04 | grad 1.14 | tok/s 19470
step   2880 | loss 1.6966 | lr 3.00e-04 | grad 1.95 | tok/s 20025
step   2890 | loss 1.6391 | lr 3.00e-04 | grad 1.31 | tok/s 20564
step   2900 | loss 1.5865 | lr 3.00e-04 | grad 1.22 | tok/s 19630
step   2910 | loss 1.6140 | lr 3.00e-04 | grad 1.12 | tok/s 19783
step   2920 | loss 1.6155 | lr 3.00e-04 | grad 1.52 | tok/s 19203
step   2930 | loss 1.7830 | lr 3.00e-04 | grad 1.34 | tok/s 20088

Training complete! Final step: 2934
