Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_86/levelllama_100m_20260126_185604
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 321,314,304 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 6.3007 | lr 3.00e-04 | grad 2.83 | tok/s 11045
step     20 | loss 3.0020 | lr 3.00e-04 | grad 2.19 | tok/s 25372
step     30 | loss 3.2854 | lr 3.00e-04 | grad 3.17 | tok/s 26856
step     40 | loss 5.5012 | lr 3.00e-04 | grad 7.50 | tok/s 27292
step     50 | loss 4.4906 | lr 3.00e-04 | grad 4.28 | tok/s 27628
step     60 | loss 3.6916 | lr 3.00e-04 | grad 3.59 | tok/s 27556
step     70 | loss 3.2348 | lr 3.00e-04 | grad 3.56 | tok/s 27543
step     80 | loss 2.9423 | lr 3.00e-04 | grad 2.09 | tok/s 27523
step     90 | loss 2.6615 | lr 3.00e-04 | grad 2.23 | tok/s 27462
step    100 | loss 2.5156 | lr 3.00e-04 | grad 1.64 | tok/s 27421
step    110 | loss 2.6440 | lr 3.00e-04 | grad 2.77 | tok/s 27189
step    120 | loss 3.4619 | lr 3.00e-04 | grad 1.24 | tok/s 25886
step    130 | loss 2.6499 | lr 3.00e-04 | grad 2.67 | tok/s 26498
step    140 | loss 2.9211 | lr 3.00e-04 | grad 5.22 | tok/s 26540
step    150 | loss 2.7045 | lr 3.00e-04 | grad 4.59 | tok/s 27214
step    160 | loss 2.8055 | lr 3.00e-04 | grad 1.71 | tok/s 26240
step    170 | loss 2.7118 | lr 3.00e-04 | grad 1.41 | tok/s 25847
step    180 | loss 2.8605 | lr 3.00e-04 | grad 1.75 | tok/s 26455
step    190 | loss 2.4652 | lr 3.00e-04 | grad 1.98 | tok/s 25913
step    200 | loss 2.3969 | lr 3.00e-04 | grad 1.70 | tok/s 27115
step    210 | loss 2.4116 | lr 3.00e-04 | grad 2.81 | tok/s 25720
step    220 | loss 2.6582 | lr 3.00e-04 | grad 3.17 | tok/s 26006
step    230 | loss 2.4647 | lr 3.00e-04 | grad 2.17 | tok/s 25962
step    240 | loss 2.7666 | lr 3.00e-04 | grad 2.38 | tok/s 26274
step    250 | loss 2.3158 | lr 3.00e-04 | grad 2.00 | tok/s 26068
step    260 | loss 2.4462 | lr 3.00e-04 | grad 1.92 | tok/s 26844
step    270 | loss 2.3052 | lr 3.00e-04 | grad 1.93 | tok/s 26214
step    280 | loss 2.2344 | lr 3.00e-04 | grad 0.84 | tok/s 24604
step    290 | loss 2.1670 | lr 3.00e-04 | grad 2.08 | tok/s 25449
step    300 | loss 2.4211 | lr 3.00e-04 | grad 1.88 | tok/s 25639
step    310 | loss 2.1147 | lr 3.00e-04 | grad 1.38 | tok/s 25570
step    320 | loss 2.3756 | lr 3.00e-04 | grad 3.08 | tok/s 25829
step    330 | loss 2.1722 | lr 3.00e-04 | grad 1.99 | tok/s 26074
step    340 | loss 2.4684 | lr 3.00e-04 | grad 1.63 | tok/s 25958
step    350 | loss 2.3876 | lr 3.00e-04 | grad 1.57 | tok/s 26739
step    360 | loss 2.0675 | lr 3.00e-04 | grad 1.57 | tok/s 25567
step    370 | loss 2.1201 | lr 3.00e-04 | grad 1.78 | tok/s 26925
step    380 | loss 1.9224 | lr 3.00e-04 | grad 1.85 | tok/s 27178
step    390 | loss 1.8376 | lr 3.00e-04 | grad 1.73 | tok/s 27173
step    400 | loss 2.2212 | lr 3.00e-04 | grad 1.21 | tok/s 25722
step    410 | loss 2.1297 | lr 3.00e-04 | grad 1.28 | tok/s 25984
step    420 | loss 2.2654 | lr 3.00e-04 | grad 1.81 | tok/s 27065
step    430 | loss 2.1071 | lr 3.00e-04 | grad 2.02 | tok/s 26655
step    440 | loss 2.1215 | lr 3.00e-04 | grad 1.79 | tok/s 25804
step    450 | loss 2.0153 | lr 3.00e-04 | grad 1.30 | tok/s 26069
step    460 | loss 2.0760 | lr 3.00e-04 | grad 1.39 | tok/s 26440
step    470 | loss 2.0725 | lr 3.00e-04 | grad 1.95 | tok/s 26261
step    480 | loss 2.0799 | lr 3.00e-04 | grad 2.28 | tok/s 26804
step    490 | loss 2.0523 | lr 3.00e-04 | grad 1.92 | tok/s 25750
step    500 | loss 2.1928 | lr 3.00e-04 | grad 1.35 | tok/s 26200
step    510 | loss 2.0525 | lr 3.00e-04 | grad 1.45 | tok/s 25010
step    520 | loss 1.8955 | lr 3.00e-04 | grad 1.08 | tok/s 26186
step    530 | loss 2.0521 | lr 3.00e-04 | grad 1.20 | tok/s 25787
step    540 | loss 2.0123 | lr 3.00e-04 | grad 0.91 | tok/s 25179
step    550 | loss 1.6930 | lr 3.00e-04 | grad 2.44 | tok/s 26376
step    560 | loss 1.8615 | lr 3.00e-04 | grad 1.39 | tok/s 27114
step    570 | loss 1.7482 | lr 3.00e-04 | grad 2.06 | tok/s 27090
step    580 | loss 1.6791 | lr 3.00e-04 | grad 1.16 | tok/s 27123
step    590 | loss 1.7269 | lr 3.00e-04 | grad 1.27 | tok/s 27130
step    600 | loss 1.6602 | lr 3.00e-04 | grad 1.40 | tok/s 27088
step    610 | loss 1.6489 | lr 3.00e-04 | grad 1.26 | tok/s 27150
step    620 | loss 1.6311 | lr 3.00e-04 | grad 1.38 | tok/s 26976
step    630 | loss 1.9144 | lr 3.00e-04 | grad 3.39 | tok/s 25519
step    640 | loss 2.0380 | lr 3.00e-04 | grad 1.24 | tok/s 25841
step    650 | loss 1.8519 | lr 3.00e-04 | grad 1.34 | tok/s 25863
step    660 | loss 1.9181 | lr 3.00e-04 | grad 1.35 | tok/s 26785
step    670 | loss 1.9390 | lr 3.00e-04 | grad 2.75 | tok/s 25962
step    680 | loss 1.9360 | lr 3.00e-04 | grad 1.80 | tok/s 25546
step    690 | loss 1.8895 | lr 3.00e-04 | grad 1.23 | tok/s 25353
step    700 | loss 1.7901 | lr 3.00e-04 | grad 1.11 | tok/s 25914
step    710 | loss 1.9443 | lr 3.00e-04 | grad 2.20 | tok/s 25494
step    720 | loss 1.6770 | lr 3.00e-04 | grad 1.49 | tok/s 26499
step    730 | loss 1.7693 | lr 3.00e-04 | grad 1.09 | tok/s 26053
step    740 | loss 2.1939 | lr 3.00e-04 | grad 2.44 | tok/s 26785
step    750 | loss 1.9691 | lr 3.00e-04 | grad 1.48 | tok/s 27069
step    760 | loss 1.8118 | lr 3.00e-04 | grad 2.30 | tok/s 26501
step    770 | loss 1.8265 | lr 3.00e-04 | grad 1.41 | tok/s 26046
step    780 | loss 1.7695 | lr 3.00e-04 | grad 1.42 | tok/s 26205
step    790 | loss 2.0840 | lr 3.00e-04 | grad 3.41 | tok/s 26741
step    800 | loss 1.6480 | lr 3.00e-04 | grad 0.94 | tok/s 26323
step    810 | loss 1.5987 | lr 3.00e-04 | grad 1.88 | tok/s 25491
step    820 | loss 1.7286 | lr 3.00e-04 | grad 1.30 | tok/s 25959
step    830 | loss 1.7829 | lr 3.00e-04 | grad 1.35 | tok/s 25647
step    840 | loss 1.9029 | lr 3.00e-04 | grad 1.30 | tok/s 25515
step    850 | loss 1.8498 | lr 3.00e-04 | grad 1.26 | tok/s 26078
step    860 | loss 1.9168 | lr 3.00e-04 | grad 1.56 | tok/s 26498
step    870 | loss 1.9045 | lr 3.00e-04 | grad 1.30 | tok/s 26668
step    880 | loss 1.8250 | lr 3.00e-04 | grad 1.17 | tok/s 26150
step    890 | loss 1.7110 | lr 3.00e-04 | grad 1.19 | tok/s 26012
step    900 | loss 1.7650 | lr 3.00e-04 | grad 1.05 | tok/s 25929
step    910 | loss 1.8030 | lr 3.00e-04 | grad 3.39 | tok/s 25673
step    920 | loss 1.7206 | lr 3.00e-04 | grad 1.30 | tok/s 25975
step    930 | loss 1.6698 | lr 3.00e-04 | grad 1.38 | tok/s 26318
step    940 | loss 1.6308 | lr 3.00e-04 | grad 1.13 | tok/s 25709
step    950 | loss 1.7325 | lr 3.00e-04 | grad 1.62 | tok/s 25287
step    960 | loss 1.6741 | lr 3.00e-04 | grad 1.22 | tok/s 25956
step    970 | loss 1.6818 | lr 3.00e-04 | grad 1.20 | tok/s 25995
step    980 | loss 2.3971 | lr 3.00e-04 | grad 2.25 | tok/s 27029
step    990 | loss 1.8547 | lr 3.00e-04 | grad 1.43 | tok/s 25929
step   1000 | loss 1.7872 | lr 3.00e-04 | grad 1.55 | tok/s 25996
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7872.pt
step   1010 | loss 1.5233 | lr 3.00e-04 | grad 1.55 | tok/s 15191
step   1020 | loss 1.5938 | lr 3.00e-04 | grad 1.33 | tok/s 27267
step   1030 | loss 1.7564 | lr 3.00e-04 | grad 1.28 | tok/s 25875
step   1040 | loss 2.2812 | lr 3.00e-04 | grad 3.08 | tok/s 26518
step   1050 | loss 1.8436 | lr 3.00e-04 | grad 1.20 | tok/s 26694
step   1060 | loss 1.4992 | lr 3.00e-04 | grad 1.01 | tok/s 26387
step   1070 | loss 1.6020 | lr 3.00e-04 | grad 1.42 | tok/s 26335
step   1080 | loss 1.4919 | lr 3.00e-04 | grad 1.56 | tok/s 27172
step   1090 | loss 1.4656 | lr 3.00e-04 | grad 1.46 | tok/s 27118
step   1100 | loss 1.4422 | lr 3.00e-04 | grad 1.25 | tok/s 27144
step   1110 | loss 1.3807 | lr 3.00e-04 | grad 1.22 | tok/s 27118
step   1120 | loss 1.6044 | lr 3.00e-04 | grad 1.28 | tok/s 26432
step   1130 | loss 1.9951 | lr 3.00e-04 | grad 1.32 | tok/s 26698
step   1140 | loss 2.0026 | lr 3.00e-04 | grad 1.27 | tok/s 26982
step   1150 | loss 2.1008 | lr 3.00e-04 | grad 1.73 | tok/s 26406
step   1160 | loss 1.8817 | lr 3.00e-04 | grad 2.59 | tok/s 25573
step   1170 | loss 1.7283 | lr 3.00e-04 | grad 1.42 | tok/s 25494
step   1180 | loss 1.6200 | lr 3.00e-04 | grad 1.25 | tok/s 26829
step   1190 | loss 1.9079 | lr 3.00e-04 | grad 1.77 | tok/s 26898
step   1200 | loss 1.4479 | lr 3.00e-04 | grad 1.28 | tok/s 27103
step   1210 | loss 1.5394 | lr 3.00e-04 | grad 1.17 | tok/s 25598
step   1220 | loss 1.6054 | lr 3.00e-04 | grad 1.39 | tok/s 26396
step   1230 | loss 1.6444 | lr 3.00e-04 | grad 1.02 | tok/s 26590
step   1240 | loss 1.5067 | lr 3.00e-04 | grad 1.87 | tok/s 26887
step   1250 | loss 1.7536 | lr 3.00e-04 | grad 1.69 | tok/s 26223
step   1260 | loss 1.7656 | lr 3.00e-04 | grad 1.16 | tok/s 26944
step   1270 | loss 1.5927 | lr 3.00e-04 | grad 1.57 | tok/s 26132
step   1280 | loss 1.5948 | lr 3.00e-04 | grad 1.34 | tok/s 26196
step   1290 | loss 1.5985 | lr 3.00e-04 | grad 1.43 | tok/s 25594
step   1300 | loss 1.8307 | lr 3.00e-04 | grad 3.62 | tok/s 25505
step   1310 | loss 1.8177 | lr 3.00e-04 | grad 1.24 | tok/s 26579
step   1320 | loss 1.6969 | lr 3.00e-04 | grad 2.33 | tok/s 26525
step   1330 | loss 1.7059 | lr 3.00e-04 | grad 1.30 | tok/s 26461
step   1340 | loss 1.7862 | lr 3.00e-04 | grad 1.16 | tok/s 25604
step   1350 | loss 1.6607 | lr 3.00e-04 | grad 1.19 | tok/s 26650
step   1360 | loss 1.7167 | lr 3.00e-04 | grad 1.26 | tok/s 25035
step   1370 | loss 1.8131 | lr 3.00e-04 | grad 2.42 | tok/s 26743
step   1380 | loss 1.6940 | lr 3.00e-04 | grad 1.44 | tok/s 25901
step   1390 | loss 1.6238 | lr 3.00e-04 | grad 1.50 | tok/s 26380
step   1400 | loss 1.7188 | lr 3.00e-04 | grad 1.20 | tok/s 25807
step   1410 | loss 1.5503 | lr 3.00e-04 | grad 1.44 | tok/s 25339
step   1420 | loss 1.5024 | lr 3.00e-04 | grad 1.61 | tok/s 26890
step   1430 | loss 1.9652 | lr 3.00e-04 | grad 1.11 | tok/s 26040
step   1440 | loss 1.6742 | lr 3.00e-04 | grad 1.62 | tok/s 26224
step   1450 | loss 1.6626 | lr 3.00e-04 | grad 1.25 | tok/s 26557
step   1460 | loss 1.7455 | lr 3.00e-04 | grad 1.49 | tok/s 25769
step   1470 | loss 1.5830 | lr 3.00e-04 | grad 1.40 | tok/s 25441
step   1480 | loss 1.5906 | lr 3.00e-04 | grad 1.90 | tok/s 26337
step   1490 | loss 1.8341 | lr 3.00e-04 | grad 6.72 | tok/s 26121
step   1500 | loss 1.8281 | lr 3.00e-04 | grad 1.35 | tok/s 26535
step   1510 | loss 1.4969 | lr 3.00e-04 | grad 1.12 | tok/s 25980
step   1520 | loss 1.6521 | lr 3.00e-04 | grad 1.55 | tok/s 25897
step   1530 | loss 1.5870 | lr 3.00e-04 | grad 1.38 | tok/s 26573
step   1540 | loss 1.6801 | lr 3.00e-04 | grad 1.11 | tok/s 26611
step   1550 | loss 1.6636 | lr 3.00e-04 | grad 2.50 | tok/s 26125
step   1560 | loss 1.4101 | lr 3.00e-04 | grad 1.12 | tok/s 26948
step   1570 | loss 1.5457 | lr 3.00e-04 | grad 1.12 | tok/s 26346
step   1580 | loss 1.4544 | lr 3.00e-04 | grad 1.45 | tok/s 26478
step   1590 | loss 1.6451 | lr 3.00e-04 | grad 2.25 | tok/s 25484
step   1600 | loss 1.4371 | lr 3.00e-04 | grad 4.44 | tok/s 26919
step   1610 | loss 2.0491 | lr 3.00e-04 | grad 2.31 | tok/s 26253
step   1620 | loss 2.2808 | lr 3.00e-04 | grad 1.73 | tok/s 27148
step   1630 | loss 2.0342 | lr 3.00e-04 | grad 2.08 | tok/s 27093
step   1640 | loss 1.8777 | lr 3.00e-04 | grad 2.03 | tok/s 27096
step   1650 | loss 1.7863 | lr 3.00e-04 | grad 1.91 | tok/s 27096
step   1660 | loss 1.7232 | lr 3.00e-04 | grad 1.44 | tok/s 27102
step   1670 | loss 1.7908 | lr 3.00e-04 | grad 1.53 | tok/s 26250
step   1680 | loss 1.5964 | lr 3.00e-04 | grad 1.37 | tok/s 26051
step   1690 | loss 1.6298 | lr 3.00e-04 | grad 1.69 | tok/s 25425
step   1700 | loss 1.5003 | lr 3.00e-04 | grad 1.48 | tok/s 26401
step   1710 | loss 1.4518 | lr 3.00e-04 | grad 1.54 | tok/s 26504
step   1720 | loss 1.6159 | lr 3.00e-04 | grad 1.10 | tok/s 25680
step   1730 | loss 1.6589 | lr 3.00e-04 | grad 2.72 | tok/s 26513
step   1740 | loss 1.5887 | lr 3.00e-04 | grad 1.42 | tok/s 26635
step   1750 | loss 1.4569 | lr 3.00e-04 | grad 1.22 | tok/s 26130
step   1760 | loss 1.5749 | lr 3.00e-04 | grad 1.27 | tok/s 25848
step   1770 | loss 1.8210 | lr 3.00e-04 | grad 1.21 | tok/s 26465
step   1780 | loss 1.8968 | lr 3.00e-04 | grad 1.26 | tok/s 25010
step   1790 | loss 1.4760 | lr 3.00e-04 | grad 1.16 | tok/s 25388
step   1800 | loss 1.4932 | lr 3.00e-04 | grad 1.20 | tok/s 26018
step   1810 | loss 1.5834 | lr 3.00e-04 | grad 1.45 | tok/s 26224
step   1820 | loss 1.6874 | lr 3.00e-04 | grad 1.88 | tok/s 25885
step   1830 | loss 1.5380 | lr 3.00e-04 | grad 1.11 | tok/s 25146
step   1840 | loss 1.5696 | lr 3.00e-04 | grad 1.23 | tok/s 26050
step   1850 | loss 1.6140 | lr 3.00e-04 | grad 1.45 | tok/s 25883
step   1860 | loss 1.5874 | lr 3.00e-04 | grad 1.41 | tok/s 25796
step   1870 | loss 1.6001 | lr 3.00e-04 | grad 2.45 | tok/s 26203
step   1880 | loss 1.6450 | lr 3.00e-04 | grad 1.40 | tok/s 26413
step   1890 | loss 1.4429 | lr 3.00e-04 | grad 1.30 | tok/s 27106
step   1900 | loss 1.3831 | lr 3.00e-04 | grad 1.03 | tok/s 27109
step   1910 | loss 1.3579 | lr 3.00e-04 | grad 1.11 | tok/s 27087
step   1920 | loss 1.3362 | lr 3.00e-04 | grad 1.13 | tok/s 27104
step   1930 | loss 1.3656 | lr 3.00e-04 | grad 1.93 | tok/s 27000
step   1940 | loss 1.7038 | lr 3.00e-04 | grad 1.43 | tok/s 25688
step   1950 | loss 1.5690 | lr 3.00e-04 | grad 0.94 | tok/s 25519

Training complete! Final step: 1954
