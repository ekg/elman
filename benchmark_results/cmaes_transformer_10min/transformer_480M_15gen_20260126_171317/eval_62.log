Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_62/levelllama_100m_20260126_182511
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 418,201,344 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.8649 | lr 3.00e-04 | grad 2.19 | tok/s 6729
step     20 | loss 2.7243 | lr 3.00e-04 | grad 2.77 | tok/s 20611
step     30 | loss 2.7636 | lr 3.00e-04 | grad 2.09 | tok/s 20841
step     40 | loss 2.9432 | lr 3.00e-04 | grad 3.33 | tok/s 19927
step     50 | loss 3.2337 | lr 3.00e-04 | grad 3.28 | tok/s 20266
step     60 | loss 2.5375 | lr 3.00e-04 | grad 7.66 | tok/s 20882
step     70 | loss 2.5015 | lr 3.00e-04 | grad 2.45 | tok/s 21088
step     80 | loss 6.8634 | lr 3.00e-04 | grad 10.69 | tok/s 21277
step     90 | loss 4.8824 | lr 3.00e-04 | grad 2.59 | tok/s 21632
step    100 | loss 3.8574 | lr 3.00e-04 | grad 2.97 | tok/s 21597
step    110 | loss 3.6704 | lr 3.00e-04 | grad 10.31 | tok/s 21596
step    120 | loss 3.5188 | lr 3.00e-04 | grad 7.06 | tok/s 21587
step    130 | loss 3.3675 | lr 3.00e-04 | grad 4.06 | tok/s 21571
step    140 | loss 2.8392 | lr 3.00e-04 | grad 2.59 | tok/s 21474
step    150 | loss 3.0466 | lr 3.00e-04 | grad 5.31 | tok/s 21506
step    160 | loss 2.5454 | lr 3.00e-04 | grad 3.98 | tok/s 21467
step    170 | loss 2.5821 | lr 3.00e-04 | grad 5.00 | tok/s 21417
step    180 | loss 2.3564 | lr 3.00e-04 | grad 3.02 | tok/s 21438
step    190 | loss 2.5518 | lr 3.00e-04 | grad 2.53 | tok/s 21416
step    200 | loss 2.3039 | lr 3.00e-04 | grad 2.23 | tok/s 21414
step    210 | loss 2.2898 | lr 3.00e-04 | grad 2.12 | tok/s 21397
step    220 | loss 2.5740 | lr 3.00e-04 | grad 1.81 | tok/s 21151
step    230 | loss 3.4800 | lr 3.00e-04 | grad 2.31 | tok/s 20907
step    240 | loss 2.6314 | lr 3.00e-04 | grad 3.16 | tok/s 19847
step    250 | loss 2.4685 | lr 3.00e-04 | grad 1.63 | tok/s 20407
step    260 | loss 2.2665 | lr 3.00e-04 | grad 1.79 | tok/s 21044
step    270 | loss 2.5528 | lr 3.00e-04 | grad 1.23 | tok/s 20739
step    280 | loss 2.6686 | lr 3.00e-04 | grad 3.22 | tok/s 20344
step    290 | loss 2.6638 | lr 3.00e-04 | grad 1.77 | tok/s 21445
step    300 | loss 1.6496 | lr 3.00e-04 | grad 2.53 | tok/s 21440
step    310 | loss 2.8444 | lr 3.00e-04 | grad 1.70 | tok/s 21061
step    320 | loss 2.5530 | lr 3.00e-04 | grad 3.27 | tok/s 20624
step    330 | loss 2.3643 | lr 3.00e-04 | grad 1.33 | tok/s 19885
step    340 | loss 2.6280 | lr 3.00e-04 | grad 1.44 | tok/s 20224
step    350 | loss 2.4418 | lr 3.00e-04 | grad 2.05 | tok/s 20686
step    360 | loss 2.5030 | lr 3.00e-04 | grad 2.55 | tok/s 21180
step    370 | loss 2.2525 | lr 3.00e-04 | grad 1.76 | tok/s 19204
step    380 | loss 2.2035 | lr 3.00e-04 | grad 1.45 | tok/s 20448
step    390 | loss 2.0650 | lr 3.00e-04 | grad 1.04 | tok/s 21322
step    400 | loss 2.0557 | lr 3.00e-04 | grad 1.81 | tok/s 21159
step    410 | loss 1.9845 | lr 3.00e-04 | grad 1.02 | tok/s 20695
step    420 | loss 2.1755 | lr 3.00e-04 | grad 2.14 | tok/s 19785
step    430 | loss 2.4478 | lr 3.00e-04 | grad 1.94 | tok/s 21035
step    440 | loss 2.4847 | lr 3.00e-04 | grad 1.89 | tok/s 19869
step    450 | loss 2.2720 | lr 3.00e-04 | grad 1.03 | tok/s 20590
step    460 | loss 2.1905 | lr 3.00e-04 | grad 2.17 | tok/s 20152
step    470 | loss 2.2686 | lr 3.00e-04 | grad 1.51 | tok/s 20772
step    480 | loss 2.6503 | lr 3.00e-04 | grad 2.77 | tok/s 20778
step    490 | loss 2.1512 | lr 3.00e-04 | grad 1.95 | tok/s 19620
step    500 | loss 2.1273 | lr 3.00e-04 | grad 1.77 | tok/s 20925
step    510 | loss 2.1406 | lr 3.00e-04 | grad 1.22 | tok/s 21216
step    520 | loss 2.1340 | lr 3.00e-04 | grad 1.21 | tok/s 21161
step    530 | loss 2.2783 | lr 3.00e-04 | grad 1.31 | tok/s 20361
step    540 | loss 2.0600 | lr 3.00e-04 | grad 1.55 | tok/s 20380
step    550 | loss 1.9118 | lr 3.00e-04 | grad 1.45 | tok/s 19928
step    560 | loss 2.0796 | lr 3.00e-04 | grad 1.55 | tok/s 19430
step    570 | loss 2.0189 | lr 3.00e-04 | grad 2.20 | tok/s 19967
step    580 | loss 1.9102 | lr 3.00e-04 | grad 1.29 | tok/s 19873
step    590 | loss 2.2521 | lr 3.00e-04 | grad 1.40 | tok/s 20440
step    600 | loss 2.1436 | lr 3.00e-04 | grad 1.16 | tok/s 19701
step    610 | loss 1.9820 | lr 3.00e-04 | grad 1.47 | tok/s 20721
step    620 | loss 1.8506 | lr 3.00e-04 | grad 1.09 | tok/s 19587
step    630 | loss 2.0023 | lr 3.00e-04 | grad 2.12 | tok/s 19782
step    640 | loss 2.1682 | lr 3.00e-04 | grad 1.46 | tok/s 20293
step    650 | loss 2.0029 | lr 3.00e-04 | grad 1.71 | tok/s 20408
step    660 | loss 2.0246 | lr 3.00e-04 | grad 1.01 | tok/s 20506
step    670 | loss 2.2444 | lr 3.00e-04 | grad 2.28 | tok/s 20661
step    680 | loss 2.0053 | lr 3.00e-04 | grad 1.22 | tok/s 20232
step    690 | loss 2.3044 | lr 3.00e-04 | grad 1.66 | tok/s 20947
step    700 | loss 2.0571 | lr 3.00e-04 | grad 1.59 | tok/s 21275
step    710 | loss 1.9135 | lr 3.00e-04 | grad 1.62 | tok/s 19958
step    720 | loss 1.7628 | lr 3.00e-04 | grad 1.46 | tok/s 19624
step    730 | loss 1.8391 | lr 3.00e-04 | grad 1.68 | tok/s 21307
step    740 | loss 1.9019 | lr 3.00e-04 | grad 1.41 | tok/s 21000
step    750 | loss 1.7069 | lr 3.00e-04 | grad 1.37 | tok/s 21319
step    760 | loss 1.5647 | lr 3.00e-04 | grad 1.43 | tok/s 21322
step    770 | loss 1.5260 | lr 3.00e-04 | grad 1.14 | tok/s 21376
step    780 | loss 1.4628 | lr 3.00e-04 | grad 1.12 | tok/s 21337
step    790 | loss 1.5242 | lr 3.00e-04 | grad 1.70 | tok/s 20711
step    800 | loss 2.2355 | lr 3.00e-04 | grad 2.67 | tok/s 20619
step    810 | loss 1.9791 | lr 3.00e-04 | grad 1.38 | tok/s 20525
step    820 | loss 1.9707 | lr 3.00e-04 | grad 1.80 | tok/s 19706
step    830 | loss 2.0211 | lr 3.00e-04 | grad 1.30 | tok/s 21168
step    840 | loss 1.9151 | lr 3.00e-04 | grad 1.32 | tok/s 21357
step    850 | loss 1.9554 | lr 3.00e-04 | grad 1.58 | tok/s 21269
step    860 | loss 1.8976 | lr 3.00e-04 | grad 2.14 | tok/s 21035
step    870 | loss 1.8263 | lr 3.00e-04 | grad 1.39 | tok/s 20250
step    880 | loss 1.9857 | lr 3.00e-04 | grad 1.23 | tok/s 20357
step    890 | loss 1.9596 | lr 3.00e-04 | grad 1.63 | tok/s 20614
step    900 | loss 1.8298 | lr 3.00e-04 | grad 1.27 | tok/s 20689
step    910 | loss 1.7046 | lr 3.00e-04 | grad 1.74 | tok/s 20207
step    920 | loss 1.8946 | lr 3.00e-04 | grad 2.25 | tok/s 21023
step    930 | loss 1.8622 | lr 3.00e-04 | grad 1.84 | tok/s 20057
step    940 | loss 1.8093 | lr 3.00e-04 | grad 1.35 | tok/s 21171
step    950 | loss 1.8522 | lr 3.00e-04 | grad 1.41 | tok/s 21236
step    960 | loss 1.7411 | lr 3.00e-04 | grad 1.44 | tok/s 21283
step    970 | loss 1.9315 | lr 3.00e-04 | grad 1.61 | tok/s 20008
step    980 | loss 1.8768 | lr 3.00e-04 | grad 1.23 | tok/s 20550
step    990 | loss 1.7702 | lr 3.00e-04 | grad 1.36 | tok/s 20869
step   1000 | loss 2.1215 | lr 3.00e-04 | grad 5.50 | tok/s 20070
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1215.pt
step   1010 | loss 1.9677 | lr 3.00e-04 | grad 1.55 | tok/s 7606
step   1020 | loss 1.8572 | lr 3.00e-04 | grad 1.14 | tok/s 19586
step   1030 | loss 1.7249 | lr 3.00e-04 | grad 1.35 | tok/s 20382
step   1040 | loss 1.7241 | lr 3.00e-04 | grad 1.18 | tok/s 21073
step   1050 | loss 1.8166 | lr 3.00e-04 | grad 1.62 | tok/s 19506
step   1060 | loss 1.9918 | lr 3.00e-04 | grad 1.53 | tok/s 21058
step   1070 | loss 2.0385 | lr 3.00e-04 | grad 1.38 | tok/s 20960
step   1080 | loss 1.6282 | lr 3.00e-04 | grad 1.17 | tok/s 19031
step   1090 | loss 1.3745 | lr 3.00e-04 | grad 0.92 | tok/s 20999
step   1100 | loss 1.6510 | lr 3.00e-04 | grad 1.91 | tok/s 20373
step   1110 | loss 1.7146 | lr 3.00e-04 | grad 1.20 | tok/s 21399
step   1120 | loss 1.6187 | lr 3.00e-04 | grad 1.83 | tok/s 21346
step   1130 | loss 1.5552 | lr 3.00e-04 | grad 1.27 | tok/s 21411
step   1140 | loss 1.5322 | lr 3.00e-04 | grad 1.56 | tok/s 21393
step   1150 | loss 1.5446 | lr 3.00e-04 | grad 1.28 | tok/s 21392
step   1160 | loss 1.4532 | lr 3.00e-04 | grad 1.20 | tok/s 21383
step   1170 | loss 1.4717 | lr 3.00e-04 | grad 1.52 | tok/s 21362
step   1180 | loss 1.5997 | lr 3.00e-04 | grad 0.99 | tok/s 21377
step   1190 | loss 1.4775 | lr 3.00e-04 | grad 1.36 | tok/s 21357
step   1200 | loss 1.4706 | lr 3.00e-04 | grad 1.33 | tok/s 21365
step   1210 | loss 1.5043 | lr 3.00e-04 | grad 1.49 | tok/s 21367
step   1220 | loss 1.5017 | lr 3.00e-04 | grad 1.45 | tok/s 21383
step   1230 | loss 1.4872 | lr 3.00e-04 | grad 1.16 | tok/s 21339
step   1240 | loss 1.4285 | lr 3.00e-04 | grad 1.11 | tok/s 21360
step   1250 | loss 2.0782 | lr 3.00e-04 | grad 1.66 | tok/s 20248
step   1260 | loss 1.5707 | lr 3.00e-04 | grad 1.88 | tok/s 20054
step   1270 | loss 1.8548 | lr 3.00e-04 | grad 2.89 | tok/s 19985
step   1280 | loss 1.8528 | lr 3.00e-04 | grad 1.22 | tok/s 20566
step   1290 | loss 1.6936 | lr 3.00e-04 | grad 1.39 | tok/s 20434
step   1300 | loss 1.7483 | lr 3.00e-04 | grad 1.33 | tok/s 20592
step   1310 | loss 1.7072 | lr 3.00e-04 | grad 1.40 | tok/s 20929
step   1320 | loss 1.7972 | lr 3.00e-04 | grad 1.31 | tok/s 21024
step   1330 | loss 1.8181 | lr 3.00e-04 | grad 1.43 | tok/s 21019
step   1340 | loss 1.6914 | lr 3.00e-04 | grad 4.69 | tok/s 20070
step   1350 | loss 1.8844 | lr 3.00e-04 | grad 1.48 | tok/s 19401
step   1360 | loss 1.7614 | lr 3.00e-04 | grad 1.43 | tok/s 20626
step   1370 | loss 1.5934 | lr 3.00e-04 | grad 1.04 | tok/s 20372
step   1380 | loss 1.8896 | lr 3.00e-04 | grad 1.15 | tok/s 19562
step   1390 | loss 1.7304 | lr 3.00e-04 | grad 1.25 | tok/s 20791
step   1400 | loss 1.6337 | lr 3.00e-04 | grad 1.13 | tok/s 19994
step   1410 | loss 1.6580 | lr 3.00e-04 | grad 1.77 | tok/s 20091
step   1420 | loss 1.9387 | lr 3.00e-04 | grad 3.22 | tok/s 20123
step   1430 | loss 1.6238 | lr 3.00e-04 | grad 1.14 | tok/s 20469
step   1440 | loss 1.3928 | lr 3.00e-04 | grad 1.24 | tok/s 21109
step   1450 | loss 1.3724 | lr 3.00e-04 | grad 3.05 | tok/s 21286
step   1460 | loss 1.8484 | lr 3.00e-04 | grad 1.23 | tok/s 20067
step   1470 | loss 1.7623 | lr 3.00e-04 | grad 1.23 | tok/s 20817
step   1480 | loss 2.2101 | lr 3.00e-04 | grad 2.16 | tok/s 20923
step   1490 | loss 1.9905 | lr 3.00e-04 | grad 1.40 | tok/s 21266
step   1500 | loss 1.6317 | lr 3.00e-04 | grad 1.18 | tok/s 21300
step   1510 | loss 1.7214 | lr 3.00e-04 | grad 1.39 | tok/s 21099
step   1520 | loss 1.6364 | lr 3.00e-04 | grad 2.61 | tok/s 20591
step   1530 | loss 1.6068 | lr 3.00e-04 | grad 1.09 | tok/s 21121
step   1540 | loss 1.7908 | lr 3.00e-04 | grad 1.34 | tok/s 19856
step   1550 | loss 1.5432 | lr 3.00e-04 | grad 1.68 | tok/s 21200
step   1560 | loss 1.7449 | lr 3.00e-04 | grad 1.73 | tok/s 20085
step   1570 | loss 1.5807 | lr 3.00e-04 | grad 1.27 | tok/s 21359
step   1580 | loss 2.0406 | lr 3.00e-04 | grad 2.33 | tok/s 20845
step   1590 | loss 1.9519 | lr 3.00e-04 | grad 1.42 | tok/s 20054
step   1600 | loss 1.2387 | lr 3.00e-04 | grad 0.97 | tok/s 21406
step   1610 | loss 1.1834 | lr 3.00e-04 | grad 1.56 | tok/s 20717
step   1620 | loss 1.6300 | lr 3.00e-04 | grad 1.82 | tok/s 19390
step   1630 | loss 1.6697 | lr 3.00e-04 | grad 1.48 | tok/s 20766
step   1640 | loss 1.5263 | lr 3.00e-04 | grad 1.65 | tok/s 20293
step   1650 | loss 1.6790 | lr 3.00e-04 | grad 1.27 | tok/s 19409
step   1660 | loss 1.6493 | lr 3.00e-04 | grad 1.20 | tok/s 20734
step   1670 | loss 1.6379 | lr 3.00e-04 | grad 3.75 | tok/s 20666
step   1680 | loss 1.8841 | lr 3.00e-04 | grad 1.33 | tok/s 19848
step   1690 | loss 1.6810 | lr 3.00e-04 | grad 2.84 | tok/s 20180
step   1700 | loss 1.6909 | lr 3.00e-04 | grad 1.43 | tok/s 20669
step   1710 | loss 1.6953 | lr 3.00e-04 | grad 1.27 | tok/s 20260
step   1720 | loss 1.7631 | lr 3.00e-04 | grad 1.60 | tok/s 21126
step   1730 | loss 1.6893 | lr 3.00e-04 | grad 1.42 | tok/s 21340
step   1740 | loss 1.6683 | lr 3.00e-04 | grad 1.67 | tok/s 20789
step   1750 | loss 1.7542 | lr 3.00e-04 | grad 1.62 | tok/s 20413
step   1760 | loss 1.6875 | lr 3.00e-04 | grad 1.30 | tok/s 20542
step   1770 | loss 1.5976 | lr 3.00e-04 | grad 1.37 | tok/s 20101
step   1780 | loss 1.6574 | lr 3.00e-04 | grad 1.27 | tok/s 20955
step   1790 | loss 1.5852 | lr 3.00e-04 | grad 1.13 | tok/s 20409
step   1800 | loss 1.7714 | lr 3.00e-04 | grad 1.47 | tok/s 20620
step   1810 | loss 1.6115 | lr 3.00e-04 | grad 1.30 | tok/s 19811
step   1820 | loss 1.7002 | lr 3.00e-04 | grad 2.91 | tok/s 20111
step   1830 | loss 1.5907 | lr 3.00e-04 | grad 1.59 | tok/s 20926
step   1840 | loss 1.6850 | lr 3.00e-04 | grad 1.51 | tok/s 20034
step   1850 | loss 1.5818 | lr 3.00e-04 | grad 1.23 | tok/s 20993
step   1860 | loss 1.4956 | lr 3.00e-04 | grad 1.37 | tok/s 20280
step   1870 | loss 1.6049 | lr 3.00e-04 | grad 2.11 | tok/s 20370
step   1880 | loss 1.4483 | lr 3.00e-04 | grad 1.37 | tok/s 19969
step   1890 | loss 1.7042 | lr 3.00e-04 | grad 1.18 | tok/s 18961
step   1900 | loss 1.5397 | lr 3.00e-04 | grad 1.49 | tok/s 20539
step   1910 | loss 1.5968 | lr 3.00e-04 | grad 1.40 | tok/s 19454
step   1920 | loss 1.5800 | lr 3.00e-04 | grad 1.31 | tok/s 21341
step   1930 | loss 1.6013 | lr 3.00e-04 | grad 1.64 | tok/s 19981
step   1940 | loss 1.5859 | lr 3.00e-04 | grad 1.32 | tok/s 20789
step   1950 | loss 2.2083 | lr 3.00e-04 | grad 1.88 | tok/s 21108
step   1960 | loss 1.9411 | lr 3.00e-04 | grad 1.97 | tok/s 21314
step   1970 | loss 1.7859 | lr 3.00e-04 | grad 1.54 | tok/s 20785
step   1980 | loss 1.7392 | lr 3.00e-04 | grad 1.38 | tok/s 19859
step   1990 | loss 1.7483 | lr 3.00e-04 | grad 4.06 | tok/s 20274
step   2000 | loss 1.6420 | lr 3.00e-04 | grad 1.40 | tok/s 20512
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6420.pt
step   2010 | loss 1.2172 | lr 3.00e-04 | grad 1.14 | tok/s 8646
step   2020 | loss 1.4631 | lr 3.00e-04 | grad 1.27 | tok/s 20348
step   2030 | loss 1.3319 | lr 3.00e-04 | grad 0.52 | tok/s 21437
step   2040 | loss 1.5466 | lr 3.00e-04 | grad 1.23 | tok/s 21387
step   2050 | loss 1.5331 | lr 3.00e-04 | grad 1.30 | tok/s 20946
step   2060 | loss 1.7180 | lr 3.00e-04 | grad 1.31 | tok/s 19767
step   2070 | loss 1.8005 | lr 3.00e-04 | grad 1.73 | tok/s 20471
step   2080 | loss 2.4134 | lr 3.00e-04 | grad 2.48 | tok/s 21161
step   2090 | loss 1.9208 | lr 3.00e-04 | grad 1.97 | tok/s 21204
step   2100 | loss 1.6082 | lr 3.00e-04 | grad 1.60 | tok/s 20667
step   2110 | loss 1.7803 | lr 3.00e-04 | grad 5.78 | tok/s 20314
step   2120 | loss 1.1245 | lr 3.00e-04 | grad 1.37 | tok/s 21050
step   2130 | loss 1.2329 | lr 3.00e-04 | grad 2.02 | tok/s 21002
step   2140 | loss 1.6819 | lr 3.00e-04 | grad 1.28 | tok/s 20319
step   2150 | loss 1.4393 | lr 3.00e-04 | grad 1.45 | tok/s 21367
step   2160 | loss 1.3414 | lr 3.00e-04 | grad 1.17 | tok/s 21345
step   2170 | loss 1.3927 | lr 3.00e-04 | grad 1.08 | tok/s 21341
step   2180 | loss 1.3464 | lr 3.00e-04 | grad 1.35 | tok/s 21357
step   2190 | loss 1.3548 | lr 3.00e-04 | grad 1.08 | tok/s 21357
step   2200 | loss 1.3562 | lr 3.00e-04 | grad 1.15 | tok/s 21351
step   2210 | loss 1.2874 | lr 3.00e-04 | grad 1.02 | tok/s 21347
step   2220 | loss 1.2913 | lr 3.00e-04 | grad 1.25 | tok/s 21335
step   2230 | loss 1.4867 | lr 3.00e-04 | grad 1.33 | tok/s 20949
step   2240 | loss 1.5107 | lr 3.00e-04 | grad 1.30 | tok/s 21281
step   2250 | loss 1.7920 | lr 3.00e-04 | grad 1.98 | tok/s 20550
step   2260 | loss 1.8050 | lr 3.00e-04 | grad 1.36 | tok/s 20804
step   2270 | loss 2.0976 | lr 3.00e-04 | grad 2.53 | tok/s 21145
step   2280 | loss 1.6911 | lr 3.00e-04 | grad 1.40 | tok/s 21102
step   2290 | loss 1.5169 | lr 3.00e-04 | grad 1.64 | tok/s 20607
step   2300 | loss 2.1746 | lr 3.00e-04 | grad 3.48 | tok/s 21092
step   2310 | loss 1.6464 | lr 3.00e-04 | grad 1.16 | tok/s 19984
step   2320 | loss 1.7675 | lr 3.00e-04 | grad 3.14 | tok/s 20067
step   2330 | loss 1.8979 | lr 3.00e-04 | grad 1.60 | tok/s 20397
step   2340 | loss 1.5991 | lr 3.00e-04 | grad 3.55 | tok/s 19867
step   2350 | loss 1.5105 | lr 3.00e-04 | grad 2.55 | tok/s 20839
step   2360 | loss 1.5430 | lr 3.00e-04 | grad 1.41 | tok/s 21124
step   2370 | loss 1.6438 | lr 3.00e-04 | grad 2.08 | tok/s 20860
step   2380 | loss 1.7946 | lr 3.00e-04 | grad 1.46 | tok/s 21388
step   2390 | loss 1.4622 | lr 3.00e-04 | grad 1.27 | tok/s 21299
step   2400 | loss 1.3113 | lr 3.00e-04 | grad 1.19 | tok/s 21347
step   2410 | loss 1.2294 | lr 3.00e-04 | grad 1.27 | tok/s 20660
step   2420 | loss 1.6052 | lr 3.00e-04 | grad 2.33 | tok/s 19977
step   2430 | loss 1.5798 | lr 3.00e-04 | grad 1.49 | tok/s 20324
step   2440 | loss 1.4231 | lr 3.00e-04 | grad 2.38 | tok/s 20889
step   2450 | loss 1.5937 | lr 3.00e-04 | grad 1.49 | tok/s 20344
step   2460 | loss 1.5332 | lr 3.00e-04 | grad 1.56 | tok/s 21148
step   2470 | loss 1.3403 | lr 3.00e-04 | grad 1.59 | tok/s 21065
step   2480 | loss 1.4210 | lr 3.00e-04 | grad 1.07 | tok/s 21324
step   2490 | loss 1.4737 | lr 3.00e-04 | grad 1.41 | tok/s 20213
step   2500 | loss 1.7231 | lr 3.00e-04 | grad 1.43 | tok/s 20863
step   2510 | loss 1.4694 | lr 3.00e-04 | grad 1.71 | tok/s 21297
step   2520 | loss 1.6660 | lr 3.00e-04 | grad 2.45 | tok/s 21272
step   2530 | loss 1.4863 | lr 3.00e-04 | grad 1.28 | tok/s 20532
step   2540 | loss 1.5475 | lr 3.00e-04 | grad 1.82 | tok/s 20397
step   2550 | loss 1.3818 | lr 3.00e-04 | grad 1.35 | tok/s 21179
step   2560 | loss 1.5561 | lr 3.00e-04 | grad 3.61 | tok/s 19897
step   2570 | loss 1.5818 | lr 3.00e-04 | grad 1.17 | tok/s 20704
step   2580 | loss 1.5053 | lr 3.00e-04 | grad 1.36 | tok/s 19437
step   2590 | loss 1.5204 | lr 3.00e-04 | grad 1.50 | tok/s 20500
step   2600 | loss 1.7293 | lr 3.00e-04 | grad 2.05 | tok/s 19675
step   2610 | loss 1.7044 | lr 3.00e-04 | grad 1.62 | tok/s 21160
step   2620 | loss 1.6792 | lr 3.00e-04 | grad 1.33 | tok/s 20423
step   2630 | loss 1.5738 | lr 3.00e-04 | grad 1.26 | tok/s 21073
step   2640 | loss 1.5855 | lr 3.00e-04 | grad 1.41 | tok/s 20478
step   2650 | loss 1.7891 | lr 3.00e-04 | grad 1.91 | tok/s 21284
step   2660 | loss 1.4816 | lr 3.00e-04 | grad 1.31 | tok/s 20555
step   2670 | loss 1.5506 | lr 3.00e-04 | grad 1.67 | tok/s 19766
step   2680 | loss 1.7582 | lr 3.00e-04 | grad 4.06 | tok/s 20164
step   2690 | loss 1.4843 | lr 3.00e-04 | grad 1.12 | tok/s 21129
step   2700 | loss 1.6062 | lr 3.00e-04 | grad 1.40 | tok/s 20495
step   2710 | loss 1.7482 | lr 3.00e-04 | grad 1.78 | tok/s 20234
step   2720 | loss 1.4792 | lr 3.00e-04 | grad 1.39 | tok/s 19367
step   2730 | loss 1.4067 | lr 3.00e-04 | grad 1.04 | tok/s 20847
step   2740 | loss 1.7965 | lr 3.00e-04 | grad 3.22 | tok/s 20619
step   2750 | loss 1.8677 | lr 3.00e-04 | grad 1.45 | tok/s 21095
step   2760 | loss 1.4407 | lr 3.00e-04 | grad 1.38 | tok/s 19621
step   2770 | loss 1.6568 | lr 3.00e-04 | grad 1.64 | tok/s 20241
step   2780 | loss 1.3543 | lr 3.00e-04 | grad 1.03 | tok/s 21315
step   2790 | loss 1.7874 | lr 3.00e-04 | grad 3.06 | tok/s 19819
step   2800 | loss 1.5221 | lr 3.00e-04 | grad 1.16 | tok/s 20427
step   2810 | loss 1.3916 | lr 3.00e-04 | grad 1.48 | tok/s 20317
step   2820 | loss 1.5229 | lr 3.00e-04 | grad 1.13 | tok/s 19599
step   2830 | loss 1.4251 | lr 3.00e-04 | grad 1.52 | tok/s 20914
step   2840 | loss 1.1479 | lr 3.00e-04 | grad 1.85 | tok/s 21304
step   2850 | loss 1.9044 | lr 3.00e-04 | grad 1.30 | tok/s 20618
step   2860 | loss 1.8293 | lr 3.00e-04 | grad 1.26 | tok/s 20504
step   2870 | loss 1.4766 | lr 3.00e-04 | grad 1.11 | tok/s 20084
step   2880 | loss 1.6547 | lr 3.00e-04 | grad 2.02 | tok/s 20706
step   2890 | loss 1.5474 | lr 3.00e-04 | grad 1.29 | tok/s 21292
step   2900 | loss 1.5569 | lr 3.00e-04 | grad 1.20 | tok/s 20431
step   2910 | loss 1.5791 | lr 3.00e-04 | grad 1.09 | tok/s 20478
step   2920 | loss 1.5969 | lr 3.00e-04 | grad 1.49 | tok/s 19820
step   2930 | loss 1.7468 | lr 3.00e-04 | grad 1.30 | tok/s 20789
step   2940 | loss 1.3919 | lr 3.00e-04 | grad 1.51 | tok/s 19080
step   2950 | loss 1.4967 | lr 3.00e-04 | grad 1.55 | tok/s 20550
step   2960 | loss 1.4611 | lr 3.00e-04 | grad 2.08 | tok/s 20716
step   2970 | loss 1.4580 | lr 3.00e-04 | grad 1.38 | tok/s 20856
step   2980 | loss 1.8144 | lr 3.00e-04 | grad 1.21 | tok/s 20220
step   2990 | loss 2.1511 | lr 3.00e-04 | grad 1.52 | tok/s 20727
step   3000 | loss 1.5271 | lr 3.00e-04 | grad 2.38 | tok/s 20790
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5271.pt
step   3010 | loss 1.2438 | lr 3.00e-04 | grad 5.91 | tok/s 8322

Training complete! Final step: 3016
