Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_28/levelllama_100m_20260126_174411
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 361,351,296 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.3376 | lr 3.00e-04 | grad 3.00 | tok/s 6764
step     20 | loss 2.7286 | lr 3.00e-04 | grad 1.35 | tok/s 20860
step     30 | loss 2.7514 | lr 3.00e-04 | grad 2.02 | tok/s 21174
step     40 | loss 2.8443 | lr 3.00e-04 | grad 1.36 | tok/s 20292
step     50 | loss 3.2949 | lr 3.00e-04 | grad 3.62 | tok/s 20630
step     60 | loss 2.4834 | lr 3.00e-04 | grad 6.72 | tok/s 21295
step     70 | loss 2.4403 | lr 3.00e-04 | grad 2.36 | tok/s 21558
step     80 | loss 6.0497 | lr 3.00e-04 | grad 7.38 | tok/s 21700
step     90 | loss 4.5397 | lr 3.00e-04 | grad 1.93 | tok/s 22102
step    100 | loss 3.9558 | lr 3.00e-04 | grad 2.55 | tok/s 22080
step    110 | loss 3.7917 | lr 3.00e-04 | grad 5.72 | tok/s 22069
step    120 | loss 3.7327 | lr 3.00e-04 | grad 6.94 | tok/s 22037
step    130 | loss 3.6758 | lr 3.00e-04 | grad 3.44 | tok/s 22046
step    140 | loss 3.1670 | lr 3.00e-04 | grad 3.30 | tok/s 21955
step    150 | loss 3.6083 | lr 3.00e-04 | grad 5.53 | tok/s 21926
step    160 | loss 3.0174 | lr 3.00e-04 | grad 4.56 | tok/s 21938
step    170 | loss 3.0316 | lr 3.00e-04 | grad 3.72 | tok/s 21865
step    180 | loss 2.8794 | lr 3.00e-04 | grad 2.45 | tok/s 21888
step    190 | loss 2.9857 | lr 3.00e-04 | grad 4.31 | tok/s 21858
step    200 | loss 2.6292 | lr 3.00e-04 | grad 2.56 | tok/s 21792
step    210 | loss 2.5763 | lr 3.00e-04 | grad 3.38 | tok/s 21760
step    220 | loss 2.6757 | lr 3.00e-04 | grad 2.38 | tok/s 21483
step    230 | loss 3.3436 | lr 3.00e-04 | grad 1.60 | tok/s 21201
step    240 | loss 2.5747 | lr 3.00e-04 | grad 2.58 | tok/s 20123
step    250 | loss 2.4387 | lr 3.00e-04 | grad 1.08 | tok/s 20682
step    260 | loss 2.2201 | lr 3.00e-04 | grad 1.90 | tok/s 21273
step    270 | loss 2.4921 | lr 3.00e-04 | grad 1.23 | tok/s 20984
step    280 | loss 2.6478 | lr 3.00e-04 | grad 2.78 | tok/s 20560
step    290 | loss 2.8177 | lr 3.00e-04 | grad 1.41 | tok/s 21621
step    300 | loss 1.7636 | lr 3.00e-04 | grad 1.88 | tok/s 21611
step    310 | loss 2.9507 | lr 3.00e-04 | grad 1.54 | tok/s 21221
step    320 | loss 2.5867 | lr 3.00e-04 | grad 3.02 | tok/s 20751
step    330 | loss 2.3545 | lr 3.00e-04 | grad 1.09 | tok/s 20030
step    340 | loss 2.6019 | lr 3.00e-04 | grad 1.10 | tok/s 20338
step    350 | loss 2.4344 | lr 3.00e-04 | grad 1.55 | tok/s 20834
step    360 | loss 2.6379 | lr 3.00e-04 | grad 2.36 | tok/s 21335
step    370 | loss 2.2528 | lr 3.00e-04 | grad 1.26 | tok/s 19329
step    380 | loss 2.1928 | lr 3.00e-04 | grad 1.23 | tok/s 20566
step    390 | loss 2.0774 | lr 3.00e-04 | grad 1.48 | tok/s 21425
step    400 | loss 2.0565 | lr 3.00e-04 | grad 1.59 | tok/s 21280
step    410 | loss 1.9939 | lr 3.00e-04 | grad 0.90 | tok/s 20798
step    420 | loss 2.1703 | lr 3.00e-04 | grad 1.87 | tok/s 19876
step    430 | loss 2.4747 | lr 3.00e-04 | grad 1.60 | tok/s 21143
step    440 | loss 2.4884 | lr 3.00e-04 | grad 1.52 | tok/s 19965
step    450 | loss 2.3992 | lr 3.00e-04 | grad 1.02 | tok/s 20667
step    460 | loss 2.2102 | lr 3.00e-04 | grad 2.06 | tok/s 20224
step    470 | loss 2.2640 | lr 3.00e-04 | grad 1.25 | tok/s 20813
step    480 | loss 2.7214 | lr 3.00e-04 | grad 2.70 | tok/s 20772
step    490 | loss 2.1700 | lr 3.00e-04 | grad 1.52 | tok/s 19572
step    500 | loss 2.1443 | lr 3.00e-04 | grad 1.53 | tok/s 20904
step    510 | loss 2.1572 | lr 3.00e-04 | grad 1.03 | tok/s 21199
step    520 | loss 2.1522 | lr 3.00e-04 | grad 1.18 | tok/s 21135
step    530 | loss 2.3066 | lr 3.00e-04 | grad 1.21 | tok/s 20279
step    540 | loss 2.0590 | lr 3.00e-04 | grad 1.17 | tok/s 20286
step    550 | loss 1.9208 | lr 3.00e-04 | grad 1.22 | tok/s 19881
step    560 | loss 2.0953 | lr 3.00e-04 | grad 1.23 | tok/s 19367
step    570 | loss 2.0411 | lr 3.00e-04 | grad 1.90 | tok/s 19929
step    580 | loss 1.9266 | lr 3.00e-04 | grad 1.23 | tok/s 19850
step    590 | loss 2.2785 | lr 3.00e-04 | grad 1.28 | tok/s 20348
step    600 | loss 2.1678 | lr 3.00e-04 | grad 1.10 | tok/s 19638
step    610 | loss 1.9988 | lr 3.00e-04 | grad 1.23 | tok/s 20648
step    620 | loss 1.8600 | lr 3.00e-04 | grad 1.01 | tok/s 19585
step    630 | loss 2.0280 | lr 3.00e-04 | grad 1.73 | tok/s 19739
step    640 | loss 2.1852 | lr 3.00e-04 | grad 1.20 | tok/s 20255
step    650 | loss 2.0264 | lr 3.00e-04 | grad 1.43 | tok/s 20355
step    660 | loss 2.0399 | lr 3.00e-04 | grad 0.87 | tok/s 20419
step    670 | loss 2.2664 | lr 3.00e-04 | grad 2.66 | tok/s 20574
step    680 | loss 2.0281 | lr 3.00e-04 | grad 1.05 | tok/s 20166
step    690 | loss 2.3433 | lr 3.00e-04 | grad 1.60 | tok/s 20830
step    700 | loss 2.1718 | lr 3.00e-04 | grad 1.66 | tok/s 21268
step    710 | loss 1.9535 | lr 3.00e-04 | grad 1.37 | tok/s 19809
step    720 | loss 1.7966 | lr 3.00e-04 | grad 1.24 | tok/s 19548
step    730 | loss 1.9068 | lr 3.00e-04 | grad 1.46 | tok/s 21153
step    740 | loss 1.9253 | lr 3.00e-04 | grad 1.24 | tok/s 20880
step    750 | loss 1.7669 | lr 3.00e-04 | grad 1.23 | tok/s 21213
step    760 | loss 1.6274 | lr 3.00e-04 | grad 1.28 | tok/s 21196
step    770 | loss 1.6075 | lr 3.00e-04 | grad 1.03 | tok/s 21198
step    780 | loss 1.5523 | lr 3.00e-04 | grad 1.09 | tok/s 21195
step    790 | loss 1.5963 | lr 3.00e-04 | grad 1.58 | tok/s 20595
step    800 | loss 2.2809 | lr 3.00e-04 | grad 2.34 | tok/s 20456
step    810 | loss 1.9865 | lr 3.00e-04 | grad 1.62 | tok/s 20376
step    820 | loss 1.9888 | lr 3.00e-04 | grad 1.55 | tok/s 19570
step    830 | loss 2.0761 | lr 3.00e-04 | grad 1.23 | tok/s 21002
step    840 | loss 1.9999 | lr 3.00e-04 | grad 1.27 | tok/s 21199
step    850 | loss 2.0230 | lr 3.00e-04 | grad 1.20 | tok/s 21064
step    860 | loss 1.9686 | lr 3.00e-04 | grad 1.85 | tok/s 20859
step    870 | loss 1.8597 | lr 3.00e-04 | grad 1.27 | tok/s 20108
step    880 | loss 2.0297 | lr 3.00e-04 | grad 1.12 | tok/s 20197
step    890 | loss 1.9819 | lr 3.00e-04 | grad 1.57 | tok/s 20483
step    900 | loss 1.8688 | lr 3.00e-04 | grad 1.18 | tok/s 20524
step    910 | loss 1.7362 | lr 3.00e-04 | grad 1.59 | tok/s 20088
step    920 | loss 1.9388 | lr 3.00e-04 | grad 2.08 | tok/s 20850
step    930 | loss 1.8922 | lr 3.00e-04 | grad 1.77 | tok/s 19943
step    940 | loss 1.8649 | lr 3.00e-04 | grad 1.15 | tok/s 21000
step    950 | loss 1.9246 | lr 3.00e-04 | grad 1.31 | tok/s 21112
step    960 | loss 1.8370 | lr 3.00e-04 | grad 1.36 | tok/s 21151
step    970 | loss 1.9683 | lr 3.00e-04 | grad 1.49 | tok/s 19879
step    980 | loss 1.9073 | lr 3.00e-04 | grad 1.16 | tok/s 20413
step    990 | loss 1.8083 | lr 3.00e-04 | grad 1.27 | tok/s 20755
step   1000 | loss 2.1500 | lr 3.00e-04 | grad 5.31 | tok/s 19944
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1500.pt
step   1010 | loss 2.0326 | lr 3.00e-04 | grad 1.26 | tok/s 8937
step   1020 | loss 1.8898 | lr 3.00e-04 | grad 1.39 | tok/s 19180
step   1030 | loss 1.7576 | lr 3.00e-04 | grad 1.05 | tok/s 20276
step   1040 | loss 1.7492 | lr 3.00e-04 | grad 0.99 | tok/s 20953
step   1050 | loss 1.8041 | lr 3.00e-04 | grad 1.85 | tok/s 19343
step   1060 | loss 1.9998 | lr 3.00e-04 | grad 1.60 | tok/s 20936
step   1070 | loss 2.1119 | lr 3.00e-04 | grad 1.25 | tok/s 21030
step   1080 | loss 1.7422 | lr 3.00e-04 | grad 1.32 | tok/s 19345
step   1090 | loss 1.5014 | lr 3.00e-04 | grad 0.84 | tok/s 20210
step   1100 | loss 1.5532 | lr 3.00e-04 | grad 1.28 | tok/s 20274
step   1110 | loss 1.8010 | lr 3.00e-04 | grad 1.18 | tok/s 21270
step   1120 | loss 1.6629 | lr 3.00e-04 | grad 1.07 | tok/s 21276
step   1130 | loss 1.6136 | lr 3.00e-04 | grad 1.18 | tok/s 21248
step   1140 | loss 1.5729 | lr 3.00e-04 | grad 1.23 | tok/s 21225
step   1150 | loss 1.6020 | lr 3.00e-04 | grad 1.05 | tok/s 21269
step   1160 | loss 1.5006 | lr 3.00e-04 | grad 1.12 | tok/s 21246
step   1170 | loss 1.5099 | lr 3.00e-04 | grad 1.11 | tok/s 21242
step   1180 | loss 1.6568 | lr 3.00e-04 | grad 1.17 | tok/s 21220
step   1190 | loss 1.5281 | lr 3.00e-04 | grad 1.53 | tok/s 21262
step   1200 | loss 1.5058 | lr 3.00e-04 | grad 1.10 | tok/s 21205
step   1210 | loss 1.5343 | lr 3.00e-04 | grad 1.27 | tok/s 21239
step   1220 | loss 1.5497 | lr 3.00e-04 | grad 1.10 | tok/s 21220
step   1230 | loss 1.5217 | lr 3.00e-04 | grad 1.20 | tok/s 21225
step   1240 | loss 1.4703 | lr 3.00e-04 | grad 1.04 | tok/s 21206
step   1250 | loss 2.0316 | lr 3.00e-04 | grad 1.19 | tok/s 20364
step   1260 | loss 1.6989 | lr 3.00e-04 | grad 1.86 | tok/s 19576
step   1270 | loss 1.6859 | lr 3.00e-04 | grad 1.20 | tok/s 19821
step   1280 | loss 2.0080 | lr 3.00e-04 | grad 1.12 | tok/s 20390
step   1290 | loss 1.7351 | lr 3.00e-04 | grad 1.47 | tok/s 20428
step   1300 | loss 1.7734 | lr 3.00e-04 | grad 1.24 | tok/s 20559
step   1310 | loss 1.7397 | lr 3.00e-04 | grad 1.45 | tok/s 20492
step   1320 | loss 1.8345 | lr 3.00e-04 | grad 1.29 | tok/s 20673
step   1330 | loss 1.9152 | lr 3.00e-04 | grad 1.65 | tok/s 20871
step   1340 | loss 1.5554 | lr 3.00e-04 | grad 1.34 | tok/s 19904
step   1350 | loss 2.0440 | lr 3.00e-04 | grad 1.20 | tok/s 19221
step   1360 | loss 1.8072 | lr 3.00e-04 | grad 1.41 | tok/s 20346
step   1370 | loss 1.6712 | lr 3.00e-04 | grad 1.48 | tok/s 20393
step   1380 | loss 1.9020 | lr 3.00e-04 | grad 1.48 | tok/s 19252
step   1390 | loss 1.7624 | lr 3.00e-04 | grad 1.18 | tok/s 20369
step   1400 | loss 1.6781 | lr 3.00e-04 | grad 1.16 | tok/s 19652
step   1410 | loss 1.6633 | lr 3.00e-04 | grad 1.30 | tok/s 19939
step   1420 | loss 1.9639 | lr 3.00e-04 | grad 2.77 | tok/s 19788
step   1430 | loss 1.7222 | lr 3.00e-04 | grad 1.15 | tok/s 20397
step   1440 | loss 1.4654 | lr 3.00e-04 | grad 1.56 | tok/s 20656
step   1450 | loss 1.3763 | lr 3.00e-04 | grad 1.13 | tok/s 20979
step   1460 | loss 1.9019 | lr 3.00e-04 | grad 1.69 | tok/s 19887
step   1470 | loss 1.7961 | lr 3.00e-04 | grad 1.34 | tok/s 20436
step   1480 | loss 2.2300 | lr 3.00e-04 | grad 2.34 | tok/s 20713
step   1490 | loss 2.2044 | lr 3.00e-04 | grad 1.43 | tok/s 20994
step   1500 | loss 1.7000 | lr 3.00e-04 | grad 1.45 | tok/s 21066
step   1510 | loss 1.7432 | lr 3.00e-04 | grad 1.13 | tok/s 20762
step   1520 | loss 1.6541 | lr 3.00e-04 | grad 1.23 | tok/s 20463
step   1530 | loss 1.6792 | lr 3.00e-04 | grad 1.27 | tok/s 21059
step   1540 | loss 1.7715 | lr 3.00e-04 | grad 1.28 | tok/s 19564
step   1550 | loss 1.6441 | lr 3.00e-04 | grad 1.42 | tok/s 20869
step   1560 | loss 1.7355 | lr 3.00e-04 | grad 1.18 | tok/s 19886
step   1570 | loss 1.6192 | lr 3.00e-04 | grad 1.09 | tok/s 21149
step   1580 | loss 2.0513 | lr 3.00e-04 | grad 1.77 | tok/s 20652
step   1590 | loss 2.0903 | lr 3.00e-04 | grad 1.48 | tok/s 19857
step   1600 | loss 1.3902 | lr 3.00e-04 | grad 3.52 | tok/s 21150
step   1610 | loss 1.1252 | lr 3.00e-04 | grad 1.49 | tok/s 20513
step   1620 | loss 1.6427 | lr 3.00e-04 | grad 2.22 | tok/s 19232
step   1630 | loss 1.7686 | lr 3.00e-04 | grad 1.45 | tok/s 20554
step   1640 | loss 1.5625 | lr 3.00e-04 | grad 2.03 | tok/s 20531
step   1650 | loss 1.7062 | lr 3.00e-04 | grad 1.46 | tok/s 19326
step   1660 | loss 1.6843 | lr 3.00e-04 | grad 1.23 | tok/s 19993
step   1670 | loss 1.6486 | lr 3.00e-04 | grad 3.81 | tok/s 20480
step   1680 | loss 1.9708 | lr 3.00e-04 | grad 1.40 | tok/s 19653
step   1690 | loss 1.6977 | lr 3.00e-04 | grad 2.95 | tok/s 20013
step   1700 | loss 1.7902 | lr 3.00e-04 | grad 1.91 | tok/s 20553
step   1710 | loss 1.7234 | lr 3.00e-04 | grad 1.40 | tok/s 20298
step   1720 | loss 1.8039 | lr 3.00e-04 | grad 2.06 | tok/s 20651
step   1730 | loss 1.7924 | lr 3.00e-04 | grad 1.66 | tok/s 21153
step   1740 | loss 1.7335 | lr 3.00e-04 | grad 1.63 | tok/s 20819
step   1750 | loss 1.8177 | lr 3.00e-04 | grad 1.84 | tok/s 20233
step   1760 | loss 1.6742 | lr 3.00e-04 | grad 1.30 | tok/s 20140
step   1770 | loss 1.6469 | lr 3.00e-04 | grad 1.48 | tok/s 19979
step   1780 | loss 1.6936 | lr 3.00e-04 | grad 1.27 | tok/s 20793
step   1790 | loss 1.6423 | lr 3.00e-04 | grad 1.26 | tok/s 20287
step   1800 | loss 1.7588 | lr 3.00e-04 | grad 1.27 | tok/s 20348
step   1810 | loss 1.6622 | lr 3.00e-04 | grad 1.42 | tok/s 19734
step   1820 | loss 1.7120 | lr 3.00e-04 | grad 1.08 | tok/s 19998
step   1830 | loss 1.6533 | lr 3.00e-04 | grad 1.48 | tok/s 20633
step   1840 | loss 1.6966 | lr 3.00e-04 | grad 1.19 | tok/s 19994
step   1850 | loss 1.6760 | lr 3.00e-04 | grad 1.09 | tok/s 20707
step   1860 | loss 1.5047 | lr 3.00e-04 | grad 0.98 | tok/s 20149
step   1870 | loss 1.6625 | lr 3.00e-04 | grad 1.34 | tok/s 20167
step   1880 | loss 1.4902 | lr 3.00e-04 | grad 1.43 | tok/s 19901
step   1890 | loss 1.7307 | lr 3.00e-04 | grad 1.37 | tok/s 18726
step   1900 | loss 1.5501 | lr 3.00e-04 | grad 1.12 | tok/s 20352
step   1910 | loss 1.6302 | lr 3.00e-04 | grad 1.53 | tok/s 19460
step   1920 | loss 1.6432 | lr 3.00e-04 | grad 1.23 | tok/s 20980
step   1930 | loss 1.5966 | lr 3.00e-04 | grad 1.44 | tok/s 19975
step   1940 | loss 1.6259 | lr 3.00e-04 | grad 1.23 | tok/s 20476
step   1950 | loss 2.2510 | lr 3.00e-04 | grad 2.20 | tok/s 20905
step   1960 | loss 2.0228 | lr 3.00e-04 | grad 2.02 | tok/s 21144
step   1970 | loss 1.8751 | lr 3.00e-04 | grad 1.29 | tok/s 20648
step   1980 | loss 1.8005 | lr 3.00e-04 | grad 1.45 | tok/s 19717
step   1990 | loss 1.6576 | lr 3.00e-04 | grad 2.19 | tok/s 20283
step   2000 | loss 1.8167 | lr 3.00e-04 | grad 1.16 | tok/s 20519
  >>> saved checkpoint: checkpoint_step_002000_loss_1.8167.pt
step   2010 | loss 1.2013 | lr 3.00e-04 | grad 0.66 | tok/s 9378
step   2020 | loss 1.4952 | lr 3.00e-04 | grad 1.16 | tok/s 20495
step   2030 | loss 1.5533 | lr 3.00e-04 | grad 2.27 | tok/s 20964
step   2040 | loss 1.3582 | lr 3.00e-04 | grad 1.36 | tok/s 21261
step   2050 | loss 1.6513 | lr 3.00e-04 | grad 1.54 | tok/s 21198
step   2060 | loss 1.7154 | lr 3.00e-04 | grad 1.35 | tok/s 19154
step   2070 | loss 1.8728 | lr 3.00e-04 | grad 1.62 | tok/s 20796
step   2080 | loss 2.2525 | lr 3.00e-04 | grad 1.87 | tok/s 20613
step   2090 | loss 2.0649 | lr 3.00e-04 | grad 1.30 | tok/s 21191
step   2100 | loss 1.6771 | lr 3.00e-04 | grad 1.35 | tok/s 20490
step   2110 | loss 1.7800 | lr 3.00e-04 | grad 1.51 | tok/s 20289
step   2120 | loss 1.4011 | lr 3.00e-04 | grad 1.48 | tok/s 20767
step   2130 | loss 1.0599 | lr 3.00e-04 | grad 1.75 | tok/s 21061
step   2140 | loss 1.8107 | lr 3.00e-04 | grad 1.22 | tok/s 20028
step   2150 | loss 1.4749 | lr 3.00e-04 | grad 1.21 | tok/s 21209
step   2160 | loss 1.3986 | lr 3.00e-04 | grad 1.00 | tok/s 21206
step   2170 | loss 1.4005 | lr 3.00e-04 | grad 1.20 | tok/s 21195
step   2180 | loss 1.3959 | lr 3.00e-04 | grad 1.20 | tok/s 21187
step   2190 | loss 1.3944 | lr 3.00e-04 | grad 1.08 | tok/s 21135
step   2200 | loss 1.3826 | lr 3.00e-04 | grad 1.19 | tok/s 21124
step   2210 | loss 1.3223 | lr 3.00e-04 | grad 1.11 | tok/s 21141
step   2220 | loss 1.3287 | lr 3.00e-04 | grad 1.16 | tok/s 21223
step   2230 | loss 1.4390 | lr 3.00e-04 | grad 1.77 | tok/s 21014
step   2240 | loss 1.5976 | lr 3.00e-04 | grad 1.02 | tok/s 20999
step   2250 | loss 1.7753 | lr 3.00e-04 | grad 2.22 | tok/s 20442
step   2260 | loss 1.9247 | lr 3.00e-04 | grad 2.36 | tok/s 20779
step   2270 | loss 1.9765 | lr 3.00e-04 | grad 2.91 | tok/s 20850
step   2280 | loss 1.8902 | lr 3.00e-04 | grad 1.92 | tok/s 20840
step   2290 | loss 1.5725 | lr 3.00e-04 | grad 1.25 | tok/s 21223
step   2300 | loss 2.1998 | lr 3.00e-04 | grad 2.70 | tok/s 20156
step   2310 | loss 1.7656 | lr 3.00e-04 | grad 2.38 | tok/s 19865
step   2320 | loss 1.7282 | lr 3.00e-04 | grad 2.12 | tok/s 20492
step   2330 | loss 2.0289 | lr 3.00e-04 | grad 1.22 | tok/s 19725
step   2340 | loss 1.5450 | lr 3.00e-04 | grad 1.38 | tok/s 19909
step   2350 | loss 1.5902 | lr 3.00e-04 | grad 1.09 | tok/s 20752
step   2360 | loss 1.6004 | lr 3.00e-04 | grad 1.28 | tok/s 20794
step   2370 | loss 1.6191 | lr 3.00e-04 | grad 2.41 | tok/s 20759
step   2380 | loss 1.9265 | lr 3.00e-04 | grad 1.63 | tok/s 21213
step   2390 | loss 1.6088 | lr 3.00e-04 | grad 1.41 | tok/s 21167
step   2400 | loss 1.3716 | lr 3.00e-04 | grad 1.19 | tok/s 21168
step   2410 | loss 1.2406 | lr 3.00e-04 | grad 1.62 | tok/s 20969
step   2420 | loss 1.5759 | lr 3.00e-04 | grad 2.16 | tok/s 19667
step   2430 | loss 1.6617 | lr 3.00e-04 | grad 1.35 | tok/s 19975
step   2440 | loss 1.4118 | lr 3.00e-04 | grad 1.38 | tok/s 20850
step   2450 | loss 1.6156 | lr 3.00e-04 | grad 1.34 | tok/s 20064
step   2460 | loss 1.6401 | lr 3.00e-04 | grad 1.30 | tok/s 20978
step   2470 | loss 1.3794 | lr 3.00e-04 | grad 1.70 | tok/s 21016
step   2480 | loss 1.5129 | lr 3.00e-04 | grad 1.49 | tok/s 21092
step   2490 | loss 1.4495 | lr 3.00e-04 | grad 1.67 | tok/s 20084
step   2500 | loss 1.6946 | lr 3.00e-04 | grad 2.02 | tok/s 20727
step   2510 | loss 1.6897 | lr 3.00e-04 | grad 1.23 | tok/s 21198
step   2520 | loss 1.6198 | lr 3.00e-04 | grad 1.69 | tok/s 21174
step   2530 | loss 1.6487 | lr 3.00e-04 | grad 1.12 | tok/s 20647
step   2540 | loss 1.4803 | lr 3.00e-04 | grad 1.79 | tok/s 19937
step   2550 | loss 1.5343 | lr 3.00e-04 | grad 1.17 | tok/s 21049
step   2560 | loss 1.3723 | lr 3.00e-04 | grad 3.05 | tok/s 19773
step   2570 | loss 1.8116 | lr 3.00e-04 | grad 1.12 | tok/s 20565
step   2580 | loss 1.4901 | lr 3.00e-04 | grad 1.71 | tok/s 19312
step   2590 | loss 1.6241 | lr 3.00e-04 | grad 1.84 | tok/s 20871
step   2600 | loss 1.6818 | lr 3.00e-04 | grad 2.06 | tok/s 19074
step   2610 | loss 1.9154 | lr 3.00e-04 | grad 1.62 | tok/s 21054
step   2620 | loss 1.7136 | lr 3.00e-04 | grad 1.26 | tok/s 20268
step   2630 | loss 1.6329 | lr 3.00e-04 | grad 1.14 | tok/s 20960
step   2640 | loss 1.6274 | lr 3.00e-04 | grad 1.51 | tok/s 20593
step   2650 | loss 1.7715 | lr 3.00e-04 | grad 1.71 | tok/s 20960
step   2660 | loss 1.6478 | lr 3.00e-04 | grad 1.02 | tok/s 20509
step   2670 | loss 1.5079 | lr 3.00e-04 | grad 1.73 | tok/s 20005
step   2680 | loss 1.7052 | lr 3.00e-04 | grad 2.88 | tok/s 19708
step   2690 | loss 1.6832 | lr 3.00e-04 | grad 1.09 | tok/s 21029
step   2700 | loss 1.5878 | lr 3.00e-04 | grad 2.14 | tok/s 20674
step   2710 | loss 1.7861 | lr 3.00e-04 | grad 4.19 | tok/s 20084
step   2720 | loss 1.5402 | lr 3.00e-04 | grad 2.36 | tok/s 19127
step   2730 | loss 1.5311 | lr 3.00e-04 | grad 1.16 | tok/s 20565
step   2740 | loss 1.5734 | lr 3.00e-04 | grad 1.95 | tok/s 20436
step   2750 | loss 2.1120 | lr 3.00e-04 | grad 1.47 | tok/s 20946
step   2760 | loss 1.5134 | lr 3.00e-04 | grad 1.36 | tok/s 19959
step   2770 | loss 1.6617 | lr 3.00e-04 | grad 1.53 | tok/s 19604
step   2780 | loss 1.4388 | lr 3.00e-04 | grad 1.55 | tok/s 21138
step   2790 | loss 1.7197 | lr 3.00e-04 | grad 3.38 | tok/s 20049
step   2800 | loss 1.7001 | lr 3.00e-04 | grad 1.21 | tok/s 19868
step   2810 | loss 1.3643 | lr 3.00e-04 | grad 1.19 | tok/s 20539
step   2820 | loss 1.5496 | lr 3.00e-04 | grad 1.47 | tok/s 19293
step   2830 | loss 1.5432 | lr 3.00e-04 | grad 1.61 | tok/s 20553
step   2840 | loss 1.2592 | lr 3.00e-04 | grad 1.59 | tok/s 21091
step   2850 | loss 1.8653 | lr 3.00e-04 | grad 2.14 | tok/s 20621
step   2860 | loss 1.8807 | lr 3.00e-04 | grad 1.51 | tok/s 20197
step   2870 | loss 1.5112 | lr 3.00e-04 | grad 1.23 | tok/s 20101
step   2880 | loss 1.6224 | lr 3.00e-04 | grad 1.33 | tok/s 20392
step   2890 | loss 1.6613 | lr 3.00e-04 | grad 1.16 | tok/s 21075
step   2900 | loss 1.6317 | lr 3.00e-04 | grad 1.20 | tok/s 20325
step   2910 | loss 1.6414 | lr 3.00e-04 | grad 1.41 | tok/s 20735
step   2920 | loss 1.5622 | lr 3.00e-04 | grad 1.10 | tok/s 19437
step   2930 | loss 1.8298 | lr 3.00e-04 | grad 1.28 | tok/s 20476
step   2940 | loss 1.4224 | lr 3.00e-04 | grad 1.75 | tok/s 19515
step   2950 | loss 1.5144 | lr 3.00e-04 | grad 1.34 | tok/s 19827
step   2960 | loss 1.5182 | lr 3.00e-04 | grad 1.31 | tok/s 20845
step   2970 | loss 1.4760 | lr 3.00e-04 | grad 1.07 | tok/s 20474
step   2980 | loss 1.8606 | lr 3.00e-04 | grad 1.27 | tok/s 20271
step   2990 | loss 2.2203 | lr 3.00e-04 | grad 1.44 | tok/s 20601
step   3000 | loss 1.5404 | lr 3.00e-04 | grad 1.39 | tok/s 20949
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5404.pt
step   3010 | loss 1.5443 | lr 3.00e-04 | grad 2.00 | tok/s 8936

Training complete! Final step: 3019
