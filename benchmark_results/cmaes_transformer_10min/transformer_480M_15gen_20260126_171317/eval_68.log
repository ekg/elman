Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_68/levelllama_100m_20260126_183528
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 453,453,312 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 6.0637 | lr 3.00e-04 | grad 5.09 | tok/s 6455
step     20 | loss 2.7952 | lr 3.00e-04 | grad 1.48 | tok/s 17932
step     30 | loss 2.7931 | lr 3.00e-04 | grad 2.22 | tok/s 18124
step     40 | loss 2.9869 | lr 3.00e-04 | grad 3.20 | tok/s 17336
step     50 | loss 3.1766 | lr 3.00e-04 | grad 3.81 | tok/s 17569
step     60 | loss 2.5359 | lr 3.00e-04 | grad 6.16 | tok/s 18147
step     70 | loss 2.4857 | lr 3.00e-04 | grad 1.67 | tok/s 18345
step     80 | loss 6.6132 | lr 3.00e-04 | grad 11.50 | tok/s 18552
step     90 | loss 4.6195 | lr 3.00e-04 | grad 2.39 | tok/s 18847
step    100 | loss 3.7759 | lr 3.00e-04 | grad 3.00 | tok/s 18792
step    110 | loss 3.6415 | lr 3.00e-04 | grad 9.62 | tok/s 18784
step    120 | loss 3.5462 | lr 3.00e-04 | grad 9.12 | tok/s 18806
step    130 | loss 3.4317 | lr 3.00e-04 | grad 3.92 | tok/s 18776
step    140 | loss 2.8824 | lr 3.00e-04 | grad 2.22 | tok/s 18723
step    150 | loss 3.1581 | lr 3.00e-04 | grad 5.34 | tok/s 18722
step    160 | loss 2.5858 | lr 3.00e-04 | grad 4.75 | tok/s 18668
step    170 | loss 2.6489 | lr 3.00e-04 | grad 6.75 | tok/s 18645
step    180 | loss 2.4120 | lr 3.00e-04 | grad 4.84 | tok/s 18621
step    190 | loss 2.6496 | lr 3.00e-04 | grad 4.75 | tok/s 18601
step    200 | loss 2.3495 | lr 3.00e-04 | grad 2.66 | tok/s 18579
step    210 | loss 2.3280 | lr 3.00e-04 | grad 2.19 | tok/s 18558
step    220 | loss 2.6137 | lr 3.00e-04 | grad 2.09 | tok/s 18324
step    230 | loss 3.3286 | lr 3.00e-04 | grad 1.78 | tok/s 18104
step    240 | loss 2.6288 | lr 3.00e-04 | grad 3.41 | tok/s 17161
step    250 | loss 2.4710 | lr 3.00e-04 | grad 2.19 | tok/s 17613
step    260 | loss 2.2591 | lr 3.00e-04 | grad 2.09 | tok/s 18166
step    270 | loss 2.5295 | lr 3.00e-04 | grad 1.40 | tok/s 17911
step    280 | loss 2.6437 | lr 3.00e-04 | grad 2.88 | tok/s 17552
step    290 | loss 2.5617 | lr 3.00e-04 | grad 2.05 | tok/s 18469
step    300 | loss 1.5835 | lr 3.00e-04 | grad 1.48 | tok/s 18438
step    310 | loss 2.8434 | lr 3.00e-04 | grad 2.06 | tok/s 18102
step    320 | loss 2.5437 | lr 3.00e-04 | grad 3.33 | tok/s 17714
step    330 | loss 2.3523 | lr 3.00e-04 | grad 1.57 | tok/s 17095
step    340 | loss 2.6120 | lr 3.00e-04 | grad 1.57 | tok/s 17347
step    350 | loss 2.4209 | lr 3.00e-04 | grad 2.06 | tok/s 17773
step    360 | loss 2.4563 | lr 3.00e-04 | grad 2.77 | tok/s 18150
step    370 | loss 2.2406 | lr 3.00e-04 | grad 1.80 | tok/s 16447
step    380 | loss 2.1926 | lr 3.00e-04 | grad 1.57 | tok/s 17495
step    390 | loss 2.0734 | lr 3.00e-04 | grad 2.84 | tok/s 18238
step    400 | loss 2.0592 | lr 3.00e-04 | grad 1.87 | tok/s 18075
step    410 | loss 1.9771 | lr 3.00e-04 | grad 1.25 | tok/s 17678
step    420 | loss 2.1709 | lr 3.00e-04 | grad 2.20 | tok/s 16878
step    430 | loss 2.4467 | lr 3.00e-04 | grad 2.28 | tok/s 17952
step    440 | loss 2.4811 | lr 3.00e-04 | grad 1.92 | tok/s 16966
step    450 | loss 2.4441 | lr 3.00e-04 | grad 1.23 | tok/s 17549
step    460 | loss 2.1826 | lr 3.00e-04 | grad 2.73 | tok/s 17186
step    470 | loss 2.2684 | lr 3.00e-04 | grad 1.90 | tok/s 17718
step    480 | loss 2.6539 | lr 3.00e-04 | grad 2.89 | tok/s 17729
step    490 | loss 2.1463 | lr 3.00e-04 | grad 1.95 | tok/s 16739
step    500 | loss 2.1335 | lr 3.00e-04 | grad 2.02 | tok/s 17876
step    510 | loss 2.1435 | lr 3.00e-04 | grad 1.41 | tok/s 18105
step    520 | loss 2.1309 | lr 3.00e-04 | grad 1.41 | tok/s 18076
step    530 | loss 2.2738 | lr 3.00e-04 | grad 1.59 | tok/s 17383
step    540 | loss 2.0505 | lr 3.00e-04 | grad 1.87 | tok/s 17405
step    550 | loss 1.9115 | lr 3.00e-04 | grad 1.52 | tok/s 17007
step    560 | loss 2.0734 | lr 3.00e-04 | grad 1.61 | tok/s 16582
step    570 | loss 2.0191 | lr 3.00e-04 | grad 2.34 | tok/s 17039
step    580 | loss 1.9087 | lr 3.00e-04 | grad 1.45 | tok/s 16956
step    590 | loss 2.2423 | lr 3.00e-04 | grad 1.38 | tok/s 17420
step    600 | loss 2.1395 | lr 3.00e-04 | grad 1.31 | tok/s 16795
step    610 | loss 1.9773 | lr 3.00e-04 | grad 1.41 | tok/s 17654
step    620 | loss 1.8465 | lr 3.00e-04 | grad 1.11 | tok/s 16709
step    630 | loss 1.9914 | lr 3.00e-04 | grad 2.12 | tok/s 16861
step    640 | loss 2.1686 | lr 3.00e-04 | grad 1.52 | tok/s 17322
step    650 | loss 1.9769 | lr 3.00e-04 | grad 1.57 | tok/s 17419
step    660 | loss 2.0129 | lr 3.00e-04 | grad 1.12 | tok/s 17481
step    670 | loss 2.2392 | lr 3.00e-04 | grad 2.50 | tok/s 17613
step    680 | loss 1.9987 | lr 3.00e-04 | grad 1.29 | tok/s 17256
step    690 | loss 2.2829 | lr 3.00e-04 | grad 1.68 | tok/s 17886
step    700 | loss 2.0183 | lr 3.00e-04 | grad 1.62 | tok/s 18190
step    710 | loss 1.9080 | lr 3.00e-04 | grad 1.91 | tok/s 17000
step    720 | loss 1.7626 | lr 3.00e-04 | grad 1.59 | tok/s 16728
step    730 | loss 1.8243 | lr 3.00e-04 | grad 1.82 | tok/s 18136
step    740 | loss 1.8776 | lr 3.00e-04 | grad 1.56 | tok/s 17911
step    750 | loss 1.6799 | lr 3.00e-04 | grad 1.38 | tok/s 18178
step    760 | loss 1.5279 | lr 3.00e-04 | grad 1.65 | tok/s 18181
step    770 | loss 1.4961 | lr 3.00e-04 | grad 1.25 | tok/s 18167
step    780 | loss 1.4298 | lr 3.00e-04 | grad 1.41 | tok/s 18165
step    790 | loss 1.4949 | lr 3.00e-04 | grad 1.74 | tok/s 17614
step    800 | loss 2.2136 | lr 3.00e-04 | grad 2.59 | tok/s 17553
step    810 | loss 1.9520 | lr 3.00e-04 | grad 1.57 | tok/s 17453
step    820 | loss 1.9579 | lr 3.00e-04 | grad 1.73 | tok/s 16780
step    830 | loss 2.0002 | lr 3.00e-04 | grad 1.29 | tok/s 18024
step    840 | loss 1.8874 | lr 3.00e-04 | grad 1.34 | tok/s 18184
step    850 | loss 1.9352 | lr 3.00e-04 | grad 1.77 | tok/s 18109
step    860 | loss 1.8551 | lr 3.00e-04 | grad 2.12 | tok/s 17879
step    870 | loss 1.8082 | lr 3.00e-04 | grad 1.51 | tok/s 17232
step    880 | loss 1.9729 | lr 3.00e-04 | grad 1.23 | tok/s 17316
step    890 | loss 1.9433 | lr 3.00e-04 | grad 1.67 | tok/s 17546
step    900 | loss 1.8154 | lr 3.00e-04 | grad 1.28 | tok/s 17583
step    910 | loss 1.6824 | lr 3.00e-04 | grad 1.71 | tok/s 17199
step    920 | loss 1.8638 | lr 3.00e-04 | grad 2.47 | tok/s 17873
step    930 | loss 1.8518 | lr 3.00e-04 | grad 1.97 | tok/s 17065
step    940 | loss 1.7791 | lr 3.00e-04 | grad 1.33 | tok/s 17995
step    950 | loss 1.8139 | lr 3.00e-04 | grad 1.62 | tok/s 18062
step    960 | loss 1.6886 | lr 3.00e-04 | grad 1.51 | tok/s 18114
step    970 | loss 1.9252 | lr 3.00e-04 | grad 1.75 | tok/s 17021
step    980 | loss 1.8606 | lr 3.00e-04 | grad 1.23 | tok/s 17481
step    990 | loss 1.7588 | lr 3.00e-04 | grad 1.41 | tok/s 17779
step   1000 | loss 2.0879 | lr 3.00e-04 | grad 5.34 | tok/s 17071
  >>> saved checkpoint: checkpoint_step_001000_loss_2.0879.pt
step   1010 | loss 1.9360 | lr 3.00e-04 | grad 1.53 | tok/s 7329
step   1020 | loss 1.8464 | lr 3.00e-04 | grad 1.19 | tok/s 16671
step   1030 | loss 1.7088 | lr 3.00e-04 | grad 1.44 | tok/s 17386
step   1040 | loss 1.7067 | lr 3.00e-04 | grad 1.29 | tok/s 17936
step   1050 | loss 1.8019 | lr 3.00e-04 | grad 1.66 | tok/s 16577
step   1060 | loss 1.9785 | lr 3.00e-04 | grad 1.65 | tok/s 17929
step   1070 | loss 2.0158 | lr 3.00e-04 | grad 1.38 | tok/s 17853
step   1080 | loss 1.6166 | lr 3.00e-04 | grad 1.15 | tok/s 16209
step   1090 | loss 1.3479 | lr 3.00e-04 | grad 0.75 | tok/s 17855
step   1100 | loss 1.6384 | lr 3.00e-04 | grad 2.08 | tok/s 17322
step   1110 | loss 1.7033 | lr 3.00e-04 | grad 1.54 | tok/s 18234
step   1120 | loss 1.6007 | lr 3.00e-04 | grad 1.66 | tok/s 18211
step   1130 | loss 1.5369 | lr 3.00e-04 | grad 1.39 | tok/s 18209
step   1140 | loss 1.5154 | lr 3.00e-04 | grad 1.57 | tok/s 18235
step   1150 | loss 1.5328 | lr 3.00e-04 | grad 1.44 | tok/s 18212
step   1160 | loss 1.4385 | lr 3.00e-04 | grad 1.34 | tok/s 18205
step   1170 | loss 1.4568 | lr 3.00e-04 | grad 1.40 | tok/s 18181
step   1180 | loss 1.5784 | lr 3.00e-04 | grad 0.97 | tok/s 18203
step   1190 | loss 1.4536 | lr 3.00e-04 | grad 1.47 | tok/s 18212
step   1200 | loss 1.4474 | lr 3.00e-04 | grad 1.41 | tok/s 18211
step   1210 | loss 1.4802 | lr 3.00e-04 | grad 1.48 | tok/s 18239
step   1220 | loss 1.4890 | lr 3.00e-04 | grad 1.49 | tok/s 18207
step   1230 | loss 1.4652 | lr 3.00e-04 | grad 1.24 | tok/s 18212
step   1240 | loss 1.4128 | lr 3.00e-04 | grad 1.16 | tok/s 18201
step   1250 | loss 2.0506 | lr 3.00e-04 | grad 1.70 | tok/s 17232
step   1260 | loss 1.5627 | lr 3.00e-04 | grad 2.20 | tok/s 17048
step   1270 | loss 1.8305 | lr 3.00e-04 | grad 2.98 | tok/s 17029
step   1280 | loss 1.8252 | lr 3.00e-04 | grad 1.33 | tok/s 17537
step   1290 | loss 1.6675 | lr 3.00e-04 | grad 1.47 | tok/s 17406
step   1300 | loss 1.7329 | lr 3.00e-04 | grad 1.33 | tok/s 17532
step   1310 | loss 1.6940 | lr 3.00e-04 | grad 1.49 | tok/s 17871
step   1320 | loss 1.7781 | lr 3.00e-04 | grad 1.28 | tok/s 17889
step   1330 | loss 1.7885 | lr 3.00e-04 | grad 1.37 | tok/s 17920
step   1340 | loss 1.6688 | lr 3.00e-04 | grad 4.66 | tok/s 17088
step   1350 | loss 1.8779 | lr 3.00e-04 | grad 1.52 | tok/s 16530
step   1360 | loss 1.7432 | lr 3.00e-04 | grad 1.44 | tok/s 17544
step   1370 | loss 1.5804 | lr 3.00e-04 | grad 1.06 | tok/s 17320
step   1380 | loss 1.8754 | lr 3.00e-04 | grad 1.18 | tok/s 16660
step   1390 | loss 1.7120 | lr 3.00e-04 | grad 1.30 | tok/s 17706
step   1400 | loss 1.6036 | lr 3.00e-04 | grad 1.23 | tok/s 17044
step   1410 | loss 1.6448 | lr 3.00e-04 | grad 1.79 | tok/s 17109
step   1420 | loss 1.9055 | lr 3.00e-04 | grad 3.20 | tok/s 17136
step   1430 | loss 1.6017 | lr 3.00e-04 | grad 1.17 | tok/s 17445
step   1440 | loss 1.3803 | lr 3.00e-04 | grad 1.34 | tok/s 18023
step   1450 | loss 1.3549 | lr 3.00e-04 | grad 2.64 | tok/s 18148
step   1460 | loss 1.8158 | lr 3.00e-04 | grad 1.27 | tok/s 17071
step   1470 | loss 1.7530 | lr 3.00e-04 | grad 1.16 | tok/s 17696
step   1480 | loss 2.2038 | lr 3.00e-04 | grad 2.30 | tok/s 17832
step   1490 | loss 1.9645 | lr 3.00e-04 | grad 1.31 | tok/s 18087
step   1500 | loss 1.6033 | lr 3.00e-04 | grad 1.10 | tok/s 18151
step   1510 | loss 1.6887 | lr 3.00e-04 | grad 1.36 | tok/s 17913
step   1520 | loss 1.6197 | lr 3.00e-04 | grad 2.52 | tok/s 17545
step   1530 | loss 1.5854 | lr 3.00e-04 | grad 1.16 | tok/s 17967
step   1540 | loss 1.7798 | lr 3.00e-04 | grad 1.35 | tok/s 16903
step   1550 | loss 1.5259 | lr 3.00e-04 | grad 1.70 | tok/s 18031
step   1560 | loss 1.7234 | lr 3.00e-04 | grad 1.70 | tok/s 17087
step   1570 | loss 1.5514 | lr 3.00e-04 | grad 1.31 | tok/s 18161
step   1580 | loss 2.0283 | lr 3.00e-04 | grad 3.14 | tok/s 17742
step   1590 | loss 1.9367 | lr 3.00e-04 | grad 1.49 | tok/s 17058
step   1600 | loss 1.2135 | lr 3.00e-04 | grad 0.99 | tok/s 18267
step   1610 | loss 1.1797 | lr 3.00e-04 | grad 1.62 | tok/s 17644
step   1620 | loss 1.6131 | lr 3.00e-04 | grad 1.73 | tok/s 16522
step   1630 | loss 1.6487 | lr 3.00e-04 | grad 1.42 | tok/s 17683
step   1640 | loss 1.5046 | lr 3.00e-04 | grad 1.49 | tok/s 17280
step   1650 | loss 1.6575 | lr 3.00e-04 | grad 1.27 | tok/s 16554
step   1660 | loss 1.6253 | lr 3.00e-04 | grad 1.20 | tok/s 17651
step   1670 | loss 1.6124 | lr 3.00e-04 | grad 4.47 | tok/s 17630
step   1680 | loss 1.8666 | lr 3.00e-04 | grad 1.28 | tok/s 16897
step   1690 | loss 1.6552 | lr 3.00e-04 | grad 3.33 | tok/s 17216
step   1700 | loss 1.6638 | lr 3.00e-04 | grad 1.48 | tok/s 17592
step   1710 | loss 1.6697 | lr 3.00e-04 | grad 1.20 | tok/s 17270
step   1720 | loss 1.7552 | lr 3.00e-04 | grad 1.52 | tok/s 18010
step   1730 | loss 1.6358 | lr 3.00e-04 | grad 1.40 | tok/s 18195
step   1740 | loss 1.6367 | lr 3.00e-04 | grad 1.65 | tok/s 17709
step   1750 | loss 1.7367 | lr 3.00e-04 | grad 1.54 | tok/s 17429
step   1760 | loss 1.6798 | lr 3.00e-04 | grad 1.34 | tok/s 17454
step   1770 | loss 1.5854 | lr 3.00e-04 | grad 1.33 | tok/s 17132
step   1780 | loss 1.6415 | lr 3.00e-04 | grad 1.27 | tok/s 17827
step   1790 | loss 1.5655 | lr 3.00e-04 | grad 1.12 | tok/s 17356
step   1800 | loss 1.7518 | lr 3.00e-04 | grad 1.38 | tok/s 17504
step   1810 | loss 1.5952 | lr 3.00e-04 | grad 1.30 | tok/s 16861
step   1820 | loss 1.6767 | lr 3.00e-04 | grad 2.80 | tok/s 17094
step   1830 | loss 1.5738 | lr 3.00e-04 | grad 1.52 | tok/s 17820
step   1840 | loss 1.6716 | lr 3.00e-04 | grad 1.59 | tok/s 17061
step   1850 | loss 1.5563 | lr 3.00e-04 | grad 1.27 | tok/s 17868
step   1860 | loss 1.4836 | lr 3.00e-04 | grad 1.30 | tok/s 17253
step   1870 | loss 1.5761 | lr 3.00e-04 | grad 2.33 | tok/s 17327
step   1880 | loss 1.4220 | lr 3.00e-04 | grad 1.31 | tok/s 16991
step   1890 | loss 1.6903 | lr 3.00e-04 | grad 1.19 | tok/s 16161
step   1900 | loss 1.5273 | lr 3.00e-04 | grad 1.41 | tok/s 17490
step   1910 | loss 1.5842 | lr 3.00e-04 | grad 1.34 | tok/s 16595
step   1920 | loss 1.5673 | lr 3.00e-04 | grad 1.31 | tok/s 18177
step   1930 | loss 1.5881 | lr 3.00e-04 | grad 1.64 | tok/s 17060
step   1940 | loss 1.5798 | lr 3.00e-04 | grad 1.29 | tok/s 17729
step   1950 | loss 2.1781 | lr 3.00e-04 | grad 1.90 | tok/s 18005
step   1960 | loss 1.9015 | lr 3.00e-04 | grad 2.12 | tok/s 18212
step   1970 | loss 1.7529 | lr 3.00e-04 | grad 1.60 | tok/s 17754
step   1980 | loss 1.7098 | lr 3.00e-04 | grad 1.27 | tok/s 16971
step   1990 | loss 1.7310 | lr 3.00e-04 | grad 5.47 | tok/s 17269
step   2000 | loss 1.6253 | lr 3.00e-04 | grad 1.33 | tok/s 17469
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6253.pt
step   2010 | loss 1.2021 | lr 3.00e-04 | grad 1.15 | tok/s 7673
step   2020 | loss 1.4476 | lr 3.00e-04 | grad 1.31 | tok/s 17372
step   2030 | loss 1.3074 | lr 3.00e-04 | grad 0.49 | tok/s 18289
step   2040 | loss 1.5144 | lr 3.00e-04 | grad 1.20 | tok/s 18223
step   2050 | loss 1.4875 | lr 3.00e-04 | grad 1.30 | tok/s 17826
step   2060 | loss 1.6975 | lr 3.00e-04 | grad 1.30 | tok/s 16812
step   2070 | loss 1.7810 | lr 3.00e-04 | grad 1.62 | tok/s 17436
step   2080 | loss 2.3989 | lr 3.00e-04 | grad 2.67 | tok/s 18023
step   2090 | loss 1.8868 | lr 3.00e-04 | grad 2.05 | tok/s 18093
step   2100 | loss 1.5926 | lr 3.00e-04 | grad 1.66 | tok/s 17625
step   2110 | loss 1.7467 | lr 3.00e-04 | grad 5.09 | tok/s 17305
step   2120 | loss 1.0790 | lr 3.00e-04 | grad 1.40 | tok/s 17919
step   2130 | loss 1.2090 | lr 3.00e-04 | grad 1.74 | tok/s 17909
step   2140 | loss 1.6672 | lr 3.00e-04 | grad 1.23 | tok/s 17300
step   2150 | loss 1.4267 | lr 3.00e-04 | grad 1.34 | tok/s 18171
step   2160 | loss 1.3338 | lr 3.00e-04 | grad 1.24 | tok/s 18157
step   2170 | loss 1.3753 | lr 3.00e-04 | grad 1.05 | tok/s 18168
step   2180 | loss 1.3348 | lr 3.00e-04 | grad 1.35 | tok/s 18163
step   2190 | loss 1.3409 | lr 3.00e-04 | grad 1.16 | tok/s 18159
step   2200 | loss 1.3394 | lr 3.00e-04 | grad 1.18 | tok/s 18147
step   2210 | loss 1.2692 | lr 3.00e-04 | grad 1.03 | tok/s 18159
step   2220 | loss 1.2756 | lr 3.00e-04 | grad 1.32 | tok/s 18174
step   2230 | loss 1.4712 | lr 3.00e-04 | grad 1.32 | tok/s 17845
step   2240 | loss 1.4928 | lr 3.00e-04 | grad 1.34 | tok/s 18079
step   2250 | loss 1.7629 | lr 3.00e-04 | grad 2.39 | tok/s 17514
step   2260 | loss 1.7571 | lr 3.00e-04 | grad 1.24 | tok/s 17731
step   2270 | loss 2.0659 | lr 3.00e-04 | grad 2.50 | tok/s 17999
step   2280 | loss 1.6562 | lr 3.00e-04 | grad 1.41 | tok/s 17949
step   2290 | loss 1.4892 | lr 3.00e-04 | grad 1.56 | tok/s 17492
step   2300 | loss 2.0616 | lr 3.00e-04 | grad 3.06 | tok/s 17901
step   2310 | loss 1.5891 | lr 3.00e-04 | grad 1.16 | tok/s 16988
step   2320 | loss 1.7424 | lr 3.00e-04 | grad 3.06 | tok/s 17049
step   2330 | loss 1.8691 | lr 3.00e-04 | grad 1.81 | tok/s 17379
step   2340 | loss 1.5734 | lr 3.00e-04 | grad 3.47 | tok/s 16884
step   2350 | loss 1.4873 | lr 3.00e-04 | grad 2.58 | tok/s 17737
step   2360 | loss 1.5075 | lr 3.00e-04 | grad 1.43 | tok/s 17985
step   2370 | loss 1.6187 | lr 3.00e-04 | grad 2.20 | tok/s 17815
step   2380 | loss 1.7824 | lr 3.00e-04 | grad 1.49 | tok/s 18214
step   2390 | loss 1.4336 | lr 3.00e-04 | grad 1.34 | tok/s 18153
step   2400 | loss 1.2733 | lr 3.00e-04 | grad 1.26 | tok/s 18203
step   2410 | loss 1.2082 | lr 3.00e-04 | grad 1.25 | tok/s 17603
step   2420 | loss 1.5874 | lr 3.00e-04 | grad 2.30 | tok/s 17046
step   2430 | loss 1.5613 | lr 3.00e-04 | grad 1.46 | tok/s 17374
step   2440 | loss 1.3946 | lr 3.00e-04 | grad 2.25 | tok/s 17797
step   2450 | loss 1.5836 | lr 3.00e-04 | grad 1.43 | tok/s 17377
step   2460 | loss 1.5032 | lr 3.00e-04 | grad 1.47 | tok/s 18027
step   2470 | loss 1.3105 | lr 3.00e-04 | grad 1.55 | tok/s 17934
step   2480 | loss 1.3924 | lr 3.00e-04 | grad 1.05 | tok/s 18194
step   2490 | loss 1.4537 | lr 3.00e-04 | grad 1.32 | tok/s 17228
step   2500 | loss 1.6889 | lr 3.00e-04 | grad 1.33 | tok/s 17780
step   2510 | loss 1.4147 | lr 3.00e-04 | grad 1.91 | tok/s 18196
step   2520 | loss 1.6279 | lr 3.00e-04 | grad 2.33 | tok/s 18119
step   2530 | loss 1.4723 | lr 3.00e-04 | grad 1.25 | tok/s 17498
step   2540 | loss 1.5307 | lr 3.00e-04 | grad 1.71 | tok/s 17400
step   2550 | loss 1.3512 | lr 3.00e-04 | grad 1.27 | tok/s 18066
step   2560 | loss 1.5452 | lr 3.00e-04 | grad 3.75 | tok/s 16946
step   2570 | loss 1.5597 | lr 3.00e-04 | grad 1.23 | tok/s 17665
step   2580 | loss 1.4882 | lr 3.00e-04 | grad 1.38 | tok/s 16542
step   2590 | loss 1.4955 | lr 3.00e-04 | grad 1.48 | tok/s 17477

Training complete! Final step: 2591
