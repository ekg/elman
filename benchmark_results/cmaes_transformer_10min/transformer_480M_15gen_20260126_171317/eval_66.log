Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_66/levelllama_100m_20260126_183528
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 288,284,160 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 6.4549 | lr 3.00e-04 | grad 3.80 | tok/s 12164
step     20 | loss 2.9549 | lr 3.00e-04 | grad 2.20 | tok/s 32679
step     30 | loss 3.2800 | lr 3.00e-04 | grad 2.84 | tok/s 34558
step     40 | loss 5.6293 | lr 3.00e-04 | grad 7.53 | tok/s 35195
step     50 | loss 4.4139 | lr 3.00e-04 | grad 3.78 | tok/s 35670
step     60 | loss 3.7198 | lr 3.00e-04 | grad 3.80 | tok/s 35565
step     70 | loss 3.2367 | lr 3.00e-04 | grad 4.50 | tok/s 35505
step     80 | loss 2.9694 | lr 3.00e-04 | grad 2.42 | tok/s 35413
step     90 | loss 2.6861 | lr 3.00e-04 | grad 2.08 | tok/s 35349
step    100 | loss 2.5000 | lr 3.00e-04 | grad 2.61 | tok/s 35270
step    110 | loss 2.6240 | lr 3.00e-04 | grad 2.47 | tok/s 34953
step    120 | loss 3.4608 | lr 3.00e-04 | grad 1.77 | tok/s 33274
step    130 | loss 2.6460 | lr 3.00e-04 | grad 2.62 | tok/s 34015
step    140 | loss 2.9397 | lr 3.00e-04 | grad 5.59 | tok/s 34055
step    150 | loss 2.6713 | lr 3.00e-04 | grad 4.19 | tok/s 34870
step    160 | loss 2.7817 | lr 3.00e-04 | grad 1.63 | tok/s 33593
step    170 | loss 2.6988 | lr 3.00e-04 | grad 1.16 | tok/s 33044
step    180 | loss 2.8266 | lr 3.00e-04 | grad 2.20 | tok/s 33790
step    190 | loss 2.4497 | lr 3.00e-04 | grad 2.38 | tok/s 33140
step    200 | loss 2.3914 | lr 3.00e-04 | grad 1.55 | tok/s 34587
step    210 | loss 2.3913 | lr 3.00e-04 | grad 2.48 | tok/s 32787
step    220 | loss 2.6592 | lr 3.00e-04 | grad 4.66 | tok/s 33081
step    230 | loss 2.5181 | lr 3.00e-04 | grad 1.91 | tok/s 33002
step    240 | loss 2.7455 | lr 3.00e-04 | grad 2.33 | tok/s 33308
step    250 | loss 2.3104 | lr 3.00e-04 | grad 1.91 | tok/s 33105
step    260 | loss 2.4408 | lr 3.00e-04 | grad 1.84 | tok/s 33989
step    270 | loss 2.2998 | lr 3.00e-04 | grad 2.08 | tok/s 33118
step    280 | loss 2.2330 | lr 3.00e-04 | grad 0.92 | tok/s 31163
step    290 | loss 2.1775 | lr 3.00e-04 | grad 1.34 | tok/s 32229
step    300 | loss 2.4281 | lr 3.00e-04 | grad 1.84 | tok/s 32339
step    310 | loss 2.1176 | lr 3.00e-04 | grad 1.70 | tok/s 32147
step    320 | loss 2.3756 | lr 3.00e-04 | grad 2.92 | tok/s 32462
step    330 | loss 2.1749 | lr 3.00e-04 | grad 1.59 | tok/s 32808
step    340 | loss 2.4774 | lr 3.00e-04 | grad 1.75 | tok/s 32634
step    350 | loss 2.4090 | lr 3.00e-04 | grad 1.48 | tok/s 33536
step    360 | loss 2.0765 | lr 3.00e-04 | grad 1.45 | tok/s 32083
step    370 | loss 2.1234 | lr 3.00e-04 | grad 1.42 | tok/s 33734
step    380 | loss 1.9281 | lr 3.00e-04 | grad 1.73 | tok/s 34005
step    390 | loss 1.8523 | lr 3.00e-04 | grad 1.84 | tok/s 33952
step    400 | loss 2.2307 | lr 3.00e-04 | grad 1.09 | tok/s 32144
step    410 | loss 2.1395 | lr 3.00e-04 | grad 1.27 | tok/s 32478
step    420 | loss 2.2733 | lr 3.00e-04 | grad 1.69 | tok/s 33811
step    430 | loss 2.0937 | lr 3.00e-04 | grad 2.17 | tok/s 33238
step    440 | loss 2.1306 | lr 3.00e-04 | grad 1.55 | tok/s 32213
step    450 | loss 2.0256 | lr 3.00e-04 | grad 1.16 | tok/s 32588
step    460 | loss 2.0932 | lr 3.00e-04 | grad 1.20 | tok/s 33061
step    470 | loss 2.0872 | lr 3.00e-04 | grad 1.95 | tok/s 32828
step    480 | loss 2.1061 | lr 3.00e-04 | grad 2.20 | tok/s 33478
step    490 | loss 2.0651 | lr 3.00e-04 | grad 1.80 | tok/s 32157
step    500 | loss 2.2043 | lr 3.00e-04 | grad 1.27 | tok/s 32652
step    510 | loss 2.0642 | lr 3.00e-04 | grad 1.09 | tok/s 31235
step    520 | loss 1.9177 | lr 3.00e-04 | grad 1.07 | tok/s 32681
step    530 | loss 2.0707 | lr 3.00e-04 | grad 1.14 | tok/s 32131
step    540 | loss 2.0182 | lr 3.00e-04 | grad 0.95 | tok/s 31439
step    550 | loss 1.7203 | lr 3.00e-04 | grad 2.34 | tok/s 32871
step    560 | loss 1.8943 | lr 3.00e-04 | grad 1.52 | tok/s 33811
step    570 | loss 1.7764 | lr 3.00e-04 | grad 1.69 | tok/s 33774
step    580 | loss 1.7053 | lr 3.00e-04 | grad 1.09 | tok/s 33796
step    590 | loss 1.7465 | lr 3.00e-04 | grad 1.34 | tok/s 33742
step    600 | loss 1.6990 | lr 3.00e-04 | grad 1.53 | tok/s 33787
step    610 | loss 1.6689 | lr 3.00e-04 | grad 1.35 | tok/s 33802
step    620 | loss 1.6496 | lr 3.00e-04 | grad 1.37 | tok/s 33640
step    630 | loss 1.9557 | lr 3.00e-04 | grad 3.45 | tok/s 31806
step    640 | loss 2.0499 | lr 3.00e-04 | grad 1.22 | tok/s 32221
step    650 | loss 1.8705 | lr 3.00e-04 | grad 1.21 | tok/s 32172
step    660 | loss 1.9353 | lr 3.00e-04 | grad 1.35 | tok/s 33451
step    670 | loss 1.9529 | lr 3.00e-04 | grad 2.92 | tok/s 32340
step    680 | loss 1.9491 | lr 3.00e-04 | grad 1.69 | tok/s 31831
step    690 | loss 1.8992 | lr 3.00e-04 | grad 1.26 | tok/s 31567
step    700 | loss 1.8125 | lr 3.00e-04 | grad 1.04 | tok/s 32234
step    710 | loss 1.9620 | lr 3.00e-04 | grad 2.42 | tok/s 31716
step    720 | loss 1.7012 | lr 3.00e-04 | grad 1.34 | tok/s 32950
step    730 | loss 1.7976 | lr 3.00e-04 | grad 0.98 | tok/s 32407
step    740 | loss 2.2175 | lr 3.00e-04 | grad 2.34 | tok/s 33311
step    750 | loss 1.9909 | lr 3.00e-04 | grad 1.71 | tok/s 33736
step    760 | loss 1.8398 | lr 3.00e-04 | grad 2.23 | tok/s 33030
step    770 | loss 1.8468 | lr 3.00e-04 | grad 1.29 | tok/s 32454
step    780 | loss 1.7930 | lr 3.00e-04 | grad 1.49 | tok/s 32676
step    790 | loss 2.0926 | lr 3.00e-04 | grad 3.00 | tok/s 33398
step    800 | loss 1.6721 | lr 3.00e-04 | grad 1.25 | tok/s 32837
step    810 | loss 1.6203 | lr 3.00e-04 | grad 1.95 | tok/s 31752
step    820 | loss 1.7535 | lr 3.00e-04 | grad 1.28 | tok/s 32355
step    830 | loss 1.8042 | lr 3.00e-04 | grad 1.22 | tok/s 31938
step    840 | loss 1.9158 | lr 3.00e-04 | grad 1.30 | tok/s 31806
step    850 | loss 1.8642 | lr 3.00e-04 | grad 1.24 | tok/s 32430
step    860 | loss 1.9246 | lr 3.00e-04 | grad 1.43 | tok/s 32941
step    870 | loss 1.9287 | lr 3.00e-04 | grad 1.26 | tok/s 33266
step    880 | loss 1.8387 | lr 3.00e-04 | grad 1.07 | tok/s 32593
step    890 | loss 1.7306 | lr 3.00e-04 | grad 1.27 | tok/s 32423
step    900 | loss 1.7858 | lr 3.00e-04 | grad 1.02 | tok/s 32294
step    910 | loss 1.8366 | lr 3.00e-04 | grad 3.58 | tok/s 31941
step    920 | loss 1.7383 | lr 3.00e-04 | grad 1.36 | tok/s 32320
step    930 | loss 1.6915 | lr 3.00e-04 | grad 1.36 | tok/s 32746
step    940 | loss 1.6593 | lr 3.00e-04 | grad 1.20 | tok/s 31980
step    950 | loss 1.7490 | lr 3.00e-04 | grad 1.59 | tok/s 31482
step    960 | loss 1.6943 | lr 3.00e-04 | grad 1.13 | tok/s 32355
step    970 | loss 1.6952 | lr 3.00e-04 | grad 1.20 | tok/s 32330
step    980 | loss 2.3496 | lr 3.00e-04 | grad 2.22 | tok/s 33652
step    990 | loss 1.8834 | lr 3.00e-04 | grad 1.32 | tok/s 32259
step   1000 | loss 1.7987 | lr 3.00e-04 | grad 1.40 | tok/s 32384
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7987.pt
step   1010 | loss 1.5460 | lr 3.00e-04 | grad 1.52 | tok/s 17120
step   1020 | loss 1.6029 | lr 3.00e-04 | grad 1.26 | tok/s 34057
step   1030 | loss 1.7758 | lr 3.00e-04 | grad 1.34 | tok/s 32340
step   1040 | loss 2.2984 | lr 3.00e-04 | grad 2.20 | tok/s 33093
step   1050 | loss 1.8666 | lr 3.00e-04 | grad 1.23 | tok/s 33327
step   1060 | loss 1.5266 | lr 3.00e-04 | grad 0.96 | tok/s 32916
step   1070 | loss 1.6190 | lr 3.00e-04 | grad 1.60 | tok/s 32838
step   1080 | loss 1.5119 | lr 3.00e-04 | grad 1.47 | tok/s 33875
step   1090 | loss 1.4862 | lr 3.00e-04 | grad 1.40 | tok/s 33903
step   1100 | loss 1.4599 | lr 3.00e-04 | grad 1.34 | tok/s 33890
step   1110 | loss 1.3974 | lr 3.00e-04 | grad 1.30 | tok/s 33871
step   1120 | loss 1.6226 | lr 3.00e-04 | grad 1.23 | tok/s 32989
step   1130 | loss 2.0242 | lr 3.00e-04 | grad 1.27 | tok/s 33338
step   1140 | loss 2.0159 | lr 3.00e-04 | grad 1.31 | tok/s 33710
step   1150 | loss 2.1458 | lr 3.00e-04 | grad 1.75 | tok/s 32958
step   1160 | loss 1.9018 | lr 3.00e-04 | grad 2.92 | tok/s 31936
step   1170 | loss 1.7478 | lr 3.00e-04 | grad 1.34 | tok/s 31828
step   1180 | loss 1.6467 | lr 3.00e-04 | grad 1.34 | tok/s 33492
step   1190 | loss 1.9340 | lr 3.00e-04 | grad 1.50 | tok/s 33537
step   1200 | loss 1.4702 | lr 3.00e-04 | grad 1.32 | tok/s 33917
step   1210 | loss 1.5527 | lr 3.00e-04 | grad 1.19 | tok/s 31913
step   1220 | loss 1.6280 | lr 3.00e-04 | grad 1.51 | tok/s 32970
step   1230 | loss 1.6623 | lr 3.00e-04 | grad 1.08 | tok/s 33195
step   1240 | loss 1.5196 | lr 3.00e-04 | grad 1.75 | tok/s 33568
step   1250 | loss 1.7704 | lr 3.00e-04 | grad 1.62 | tok/s 32790
step   1260 | loss 1.7919 | lr 3.00e-04 | grad 1.14 | tok/s 33652
step   1270 | loss 1.6152 | lr 3.00e-04 | grad 1.60 | tok/s 32583
step   1280 | loss 1.6273 | lr 3.00e-04 | grad 1.35 | tok/s 32662
step   1290 | loss 1.6131 | lr 3.00e-04 | grad 1.44 | tok/s 32001
step   1300 | loss 1.8432 | lr 3.00e-04 | grad 3.53 | tok/s 31872
step   1310 | loss 1.8416 | lr 3.00e-04 | grad 1.16 | tok/s 33206
step   1320 | loss 1.7200 | lr 3.00e-04 | grad 2.30 | tok/s 33097
step   1330 | loss 1.7389 | lr 3.00e-04 | grad 1.36 | tok/s 33017
step   1340 | loss 1.8055 | lr 3.00e-04 | grad 1.23 | tok/s 31957
step   1350 | loss 1.6833 | lr 3.00e-04 | grad 1.16 | tok/s 33215
step   1360 | loss 1.7417 | lr 3.00e-04 | grad 1.37 | tok/s 31230
step   1370 | loss 1.8393 | lr 3.00e-04 | grad 2.45 | tok/s 33325
step   1380 | loss 1.7080 | lr 3.00e-04 | grad 1.46 | tok/s 32321
step   1390 | loss 1.6510 | lr 3.00e-04 | grad 1.47 | tok/s 32927
step   1400 | loss 1.7444 | lr 3.00e-04 | grad 1.12 | tok/s 32249
step   1410 | loss 1.5726 | lr 3.00e-04 | grad 1.48 | tok/s 31642
step   1420 | loss 1.5319 | lr 3.00e-04 | grad 1.63 | tok/s 33569
step   1430 | loss 1.9824 | lr 3.00e-04 | grad 1.14 | tok/s 32508
step   1440 | loss 1.6887 | lr 3.00e-04 | grad 1.59 | tok/s 32758
step   1450 | loss 1.6762 | lr 3.00e-04 | grad 1.20 | tok/s 33066
step   1460 | loss 1.7630 | lr 3.00e-04 | grad 1.55 | tok/s 32156
step   1470 | loss 1.6112 | lr 3.00e-04 | grad 1.41 | tok/s 31705
step   1480 | loss 1.6055 | lr 3.00e-04 | grad 1.85 | tok/s 32897
step   1490 | loss 1.8376 | lr 3.00e-04 | grad 5.56 | tok/s 32644
step   1500 | loss 1.8431 | lr 3.00e-04 | grad 1.35 | tok/s 33173
step   1510 | loss 1.4958 | lr 3.00e-04 | grad 1.08 | tok/s 32487
step   1520 | loss 1.6684 | lr 3.00e-04 | grad 1.56 | tok/s 32368
step   1530 | loss 1.6028 | lr 3.00e-04 | grad 1.48 | tok/s 33248
step   1540 | loss 1.6972 | lr 3.00e-04 | grad 1.05 | tok/s 33286
step   1550 | loss 1.6785 | lr 3.00e-04 | grad 2.61 | tok/s 32596
step   1560 | loss 1.4203 | lr 3.00e-04 | grad 1.18 | tok/s 33646
step   1570 | loss 1.5625 | lr 3.00e-04 | grad 1.12 | tok/s 32975
step   1580 | loss 1.4688 | lr 3.00e-04 | grad 1.48 | tok/s 33109
step   1590 | loss 1.6706 | lr 3.00e-04 | grad 2.25 | tok/s 31877
step   1600 | loss 1.4441 | lr 3.00e-04 | grad 4.78 | tok/s 33670
step   1610 | loss 2.0983 | lr 3.00e-04 | grad 2.56 | tok/s 32802
step   1620 | loss 2.2474 | lr 3.00e-04 | grad 1.55 | tok/s 33915
step   1630 | loss 2.0001 | lr 3.00e-04 | grad 1.32 | tok/s 33845
step   1640 | loss 1.8403 | lr 3.00e-04 | grad 1.69 | tok/s 33857
step   1650 | loss 1.7555 | lr 3.00e-04 | grad 1.62 | tok/s 33870
step   1660 | loss 1.7054 | lr 3.00e-04 | grad 1.48 | tok/s 33856
step   1670 | loss 1.8131 | lr 3.00e-04 | grad 1.88 | tok/s 32807
step   1680 | loss 1.6204 | lr 3.00e-04 | grad 1.30 | tok/s 32505
step   1690 | loss 1.6486 | lr 3.00e-04 | grad 1.52 | tok/s 31739
step   1700 | loss 1.5167 | lr 3.00e-04 | grad 1.48 | tok/s 32960
step   1710 | loss 1.4691 | lr 3.00e-04 | grad 1.60 | tok/s 33088
step   1720 | loss 1.6317 | lr 3.00e-04 | grad 1.12 | tok/s 32047
step   1730 | loss 1.6773 | lr 3.00e-04 | grad 2.50 | tok/s 33094
step   1740 | loss 1.6025 | lr 3.00e-04 | grad 1.52 | tok/s 33256
step   1750 | loss 1.4841 | lr 3.00e-04 | grad 1.29 | tok/s 32552
step   1760 | loss 1.5920 | lr 3.00e-04 | grad 1.29 | tok/s 32165
step   1770 | loss 1.8624 | lr 3.00e-04 | grad 1.30 | tok/s 32999
step   1780 | loss 1.9015 | lr 3.00e-04 | grad 1.30 | tok/s 31175
step   1790 | loss 1.4916 | lr 3.00e-04 | grad 1.27 | tok/s 31671
step   1800 | loss 1.5125 | lr 3.00e-04 | grad 1.16 | tok/s 32413
step   1810 | loss 1.6023 | lr 3.00e-04 | grad 1.42 | tok/s 32704
step   1820 | loss 1.7048 | lr 3.00e-04 | grad 1.82 | tok/s 32275
step   1830 | loss 1.5497 | lr 3.00e-04 | grad 1.13 | tok/s 31313
step   1840 | loss 1.5953 | lr 3.00e-04 | grad 1.18 | tok/s 32475
step   1850 | loss 1.6307 | lr 3.00e-04 | grad 1.41 | tok/s 32262
step   1860 | loss 1.6018 | lr 3.00e-04 | grad 1.41 | tok/s 32142
step   1870 | loss 1.6088 | lr 3.00e-04 | grad 4.19 | tok/s 32663
step   1880 | loss 1.6597 | lr 3.00e-04 | grad 1.38 | tok/s 32867
step   1890 | loss 1.4545 | lr 3.00e-04 | grad 1.25 | tok/s 33748
step   1900 | loss 1.3918 | lr 3.00e-04 | grad 1.07 | tok/s 33724
step   1910 | loss 1.3682 | lr 3.00e-04 | grad 1.02 | tok/s 33772
step   1920 | loss 1.3506 | lr 3.00e-04 | grad 1.20 | tok/s 33772
step   1930 | loss 1.3767 | lr 3.00e-04 | grad 1.98 | tok/s 33642
step   1940 | loss 1.7245 | lr 3.00e-04 | grad 1.41 | tok/s 31978
step   1950 | loss 1.5942 | lr 3.00e-04 | grad 1.20 | tok/s 31779
step   1960 | loss 1.6977 | lr 3.00e-04 | grad 1.66 | tok/s 32203
step   1970 | loss 1.7337 | lr 3.00e-04 | grad 1.36 | tok/s 32842
step   1980 | loss 1.6157 | lr 3.00e-04 | grad 1.73 | tok/s 31811
step   1990 | loss 1.8095 | lr 3.00e-04 | grad 2.28 | tok/s 32773
step   2000 | loss 1.3458 | lr 3.00e-04 | grad 1.13 | tok/s 33841
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3458.pt
step   2010 | loss 1.5471 | lr 3.00e-04 | grad 1.77 | tok/s 17427
step   2020 | loss 1.5443 | lr 3.00e-04 | grad 1.40 | tok/s 32129
step   2030 | loss 1.8930 | lr 3.00e-04 | grad 12.44 | tok/s 31798
step   2040 | loss 1.6284 | lr 3.00e-04 | grad 1.46 | tok/s 32315
step   2050 | loss 1.5055 | lr 3.00e-04 | grad 1.16 | tok/s 32780
step   2060 | loss 1.7385 | lr 3.00e-04 | grad 2.55 | tok/s 32812
step   2070 | loss 1.4505 | lr 3.00e-04 | grad 1.70 | tok/s 32873
step   2080 | loss 1.4829 | lr 3.00e-04 | grad 1.16 | tok/s 31262
step   2090 | loss 1.5444 | lr 3.00e-04 | grad 2.86 | tok/s 33423
step   2100 | loss 1.9945 | lr 3.00e-04 | grad 1.87 | tok/s 33711
step   2110 | loss 1.6035 | lr 3.00e-04 | grad 1.57 | tok/s 32207
step   2120 | loss 2.3645 | lr 3.00e-04 | grad 1.83 | tok/s 32996
step   2130 | loss 1.6037 | lr 3.00e-04 | grad 1.52 | tok/s 31438
step   2140 | loss 1.7834 | lr 3.00e-04 | grad 1.26 | tok/s 33161
step   2150 | loss 1.8530 | lr 3.00e-04 | grad 1.33 | tok/s 32454
step   2160 | loss 1.6459 | lr 3.00e-04 | grad 1.28 | tok/s 32577
step   2170 | loss 1.5760 | lr 3.00e-04 | grad 3.83 | tok/s 32858
step   2180 | loss 1.3260 | lr 3.00e-04 | grad 1.90 | tok/s 33495
step   2190 | loss 1.7038 | lr 3.00e-04 | grad 1.45 | tok/s 32408
step   2200 | loss 1.5179 | lr 3.00e-04 | grad 2.34 | tok/s 33564
step   2210 | loss 1.6589 | lr 3.00e-04 | grad 1.38 | tok/s 33055
step   2220 | loss 1.5311 | lr 3.00e-04 | grad 1.24 | tok/s 31757
step   2230 | loss 1.7510 | lr 3.00e-04 | grad 1.77 | tok/s 32027
step   2240 | loss 1.4934 | lr 3.00e-04 | grad 1.38 | tok/s 32677
step   2250 | loss 1.5441 | lr 3.00e-04 | grad 1.38 | tok/s 32062
step   2260 | loss 1.6903 | lr 3.00e-04 | grad 2.56 | tok/s 33411
step   2270 | loss 1.7769 | lr 3.00e-04 | grad 1.59 | tok/s 31133
step   2280 | loss 1.6007 | lr 3.00e-04 | grad 1.28 | tok/s 32445
step   2290 | loss 1.4305 | lr 3.00e-04 | grad 1.26 | tok/s 32052
step   2300 | loss 1.7101 | lr 3.00e-04 | grad 1.13 | tok/s 31869
step   2310 | loss 1.5550 | lr 3.00e-04 | grad 1.22 | tok/s 32415
step   2320 | loss 1.5834 | lr 3.00e-04 | grad 1.20 | tok/s 33764
step   2330 | loss 1.5121 | lr 3.00e-04 | grad 1.27 | tok/s 33731
step   2340 | loss 1.4678 | lr 3.00e-04 | grad 1.12 | tok/s 33733
step   2350 | loss 1.4199 | lr 3.00e-04 | grad 1.30 | tok/s 33816
step   2360 | loss 1.4201 | lr 3.00e-04 | grad 1.52 | tok/s 33822
step   2370 | loss 1.3769 | lr 3.00e-04 | grad 1.17 | tok/s 33814
step   2380 | loss 1.3430 | lr 3.00e-04 | grad 1.33 | tok/s 33824
step   2390 | loss 1.3575 | lr 3.00e-04 | grad 1.26 | tok/s 33747
step   2400 | loss 1.3529 | lr 3.00e-04 | grad 1.10 | tok/s 33799
step   2410 | loss 1.3965 | lr 3.00e-04 | grad 1.27 | tok/s 33802
step   2420 | loss 1.6739 | lr 3.00e-04 | grad 1.07 | tok/s 32758
step   2430 | loss 1.1966 | lr 3.00e-04 | grad 1.33 | tok/s 32897

Training complete! Final step: 2433
