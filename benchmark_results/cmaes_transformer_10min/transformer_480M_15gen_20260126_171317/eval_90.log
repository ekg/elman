Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_90/levelllama_100m_20260126_190623
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 591,996,928 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 7.3504 | lr 3.00e-04 | grad 6.62 | tok/s 6302
step     20 | loss 2.8435 | lr 3.00e-04 | grad 8.12 | tok/s 16939
step     30 | loss 2.8181 | lr 3.00e-04 | grad 4.97 | tok/s 17060
step     40 | loss 2.8087 | lr 3.00e-04 | grad 2.81 | tok/s 16351
step     50 | loss 3.1826 | lr 3.00e-04 | grad 4.75 | tok/s 16633
step     60 | loss 2.6552 | lr 3.00e-04 | grad 2.45 | tok/s 17196
step     70 | loss 2.5646 | lr 3.00e-04 | grad 2.00 | tok/s 17352
step     80 | loss 6.2140 | lr 3.00e-04 | grad 14.81 | tok/s 17484
step     90 | loss 4.5434 | lr 3.00e-04 | grad 3.00 | tok/s 17765
step    100 | loss 3.7142 | lr 3.00e-04 | grad 3.27 | tok/s 17723
step    110 | loss 3.5259 | lr 3.00e-04 | grad 8.75 | tok/s 17735
step    120 | loss 3.3362 | lr 3.00e-04 | grad 9.88 | tok/s 17698
step    130 | loss 3.1351 | lr 3.00e-04 | grad 5.91 | tok/s 17666
step    140 | loss 2.7533 | lr 3.00e-04 | grad 3.45 | tok/s 17616
step    150 | loss 2.8795 | lr 3.00e-04 | grad 5.03 | tok/s 17608
step    160 | loss 2.4821 | lr 3.00e-04 | grad 6.47 | tok/s 17583
step    170 | loss 2.5436 | lr 3.00e-04 | grad 5.25 | tok/s 17558
step    180 | loss 2.3811 | lr 3.00e-04 | grad 5.94 | tok/s 17539
step    190 | loss 2.5010 | lr 3.00e-04 | grad 5.78 | tok/s 17513
step    200 | loss 2.2760 | lr 3.00e-04 | grad 2.84 | tok/s 17456
step    210 | loss 2.2889 | lr 3.00e-04 | grad 3.41 | tok/s 17444
step    220 | loss 2.5988 | lr 3.00e-04 | grad 4.00 | tok/s 17213
step    230 | loss 3.2960 | lr 3.00e-04 | grad 3.67 | tok/s 17072
step    240 | loss 2.6789 | lr 3.00e-04 | grad 4.09 | tok/s 16187
step    250 | loss 2.5228 | lr 3.00e-04 | grad 2.89 | tok/s 16626
step    260 | loss 2.3213 | lr 3.00e-04 | grad 3.56 | tok/s 17090
step    270 | loss 2.5594 | lr 3.00e-04 | grad 1.77 | tok/s 16867
step    280 | loss 2.6631 | lr 3.00e-04 | grad 4.53 | tok/s 16536
step    290 | loss 2.5532 | lr 3.00e-04 | grad 2.64 | tok/s 17383
step    300 | loss 1.5934 | lr 3.00e-04 | grad 4.81 | tok/s 17371
step    310 | loss 2.8856 | lr 3.00e-04 | grad 2.66 | tok/s 17091
step    320 | loss 2.5714 | lr 3.00e-04 | grad 3.73 | tok/s 16742
step    330 | loss 2.3729 | lr 3.00e-04 | grad 1.84 | tok/s 16176
step    340 | loss 2.6431 | lr 3.00e-04 | grad 2.80 | tok/s 16408
step    350 | loss 2.4721 | lr 3.00e-04 | grad 2.92 | tok/s 16740
step    360 | loss 2.5114 | lr 3.00e-04 | grad 3.48 | tok/s 17189
step    370 | loss 2.2669 | lr 3.00e-04 | grad 3.00 | tok/s 15520
step    380 | loss 2.2447 | lr 3.00e-04 | grad 2.95 | tok/s 16540
step    390 | loss 2.1444 | lr 3.00e-04 | grad 4.72 | tok/s 17216
step    400 | loss 2.1112 | lr 3.00e-04 | grad 3.14 | tok/s 17057
step    410 | loss 2.0263 | lr 3.00e-04 | grad 1.59 | tok/s 16662
step    420 | loss 2.2075 | lr 3.00e-04 | grad 2.36 | tok/s 15881
step    430 | loss 2.4670 | lr 3.00e-04 | grad 3.75 | tok/s 16927
step    440 | loss 2.5037 | lr 3.00e-04 | grad 2.34 | tok/s 15962
step    450 | loss 2.3128 | lr 3.00e-04 | grad 1.91 | tok/s 16535
step    460 | loss 2.1880 | lr 3.00e-04 | grad 3.48 | tok/s 16190
step    470 | loss 2.2828 | lr 3.00e-04 | grad 3.86 | tok/s 16689
step    480 | loss 2.6523 | lr 3.00e-04 | grad 3.02 | tok/s 16722
step    490 | loss 2.1699 | lr 3.00e-04 | grad 2.75 | tok/s 15790
step    500 | loss 2.1571 | lr 3.00e-04 | grad 2.33 | tok/s 16846
step    510 | loss 2.1626 | lr 3.00e-04 | grad 1.66 | tok/s 17058
step    520 | loss 2.1295 | lr 3.00e-04 | grad 1.91 | tok/s 17054
step    530 | loss 2.2701 | lr 3.00e-04 | grad 2.58 | tok/s 16387
step    540 | loss 2.0730 | lr 3.00e-04 | grad 2.67 | tok/s 16386
step    550 | loss 1.9269 | lr 3.00e-04 | grad 2.52 | tok/s 16037
step    560 | loss 2.0820 | lr 3.00e-04 | grad 1.98 | tok/s 15610
step    570 | loss 2.0241 | lr 3.00e-04 | grad 3.05 | tok/s 16052
step    580 | loss 1.9085 | lr 3.00e-04 | grad 2.12 | tok/s 15966
step    590 | loss 2.2261 | lr 3.00e-04 | grad 2.00 | tok/s 16393
step    600 | loss 2.1276 | lr 3.00e-04 | grad 1.56 | tok/s 15828
step    610 | loss 1.9728 | lr 3.00e-04 | grad 1.98 | tok/s 16624
step    620 | loss 1.8479 | lr 3.00e-04 | grad 1.43 | tok/s 15766
step    630 | loss 1.9800 | lr 3.00e-04 | grad 3.14 | tok/s 15883
step    640 | loss 2.1528 | lr 3.00e-04 | grad 2.05 | tok/s 16326
step    650 | loss 1.9787 | lr 3.00e-04 | grad 2.02 | tok/s 16396
step    660 | loss 2.0129 | lr 3.00e-04 | grad 1.60 | tok/s 16454
step    670 | loss 2.2329 | lr 3.00e-04 | grad 1.91 | tok/s 16591
step    680 | loss 1.9946 | lr 3.00e-04 | grad 1.48 | tok/s 16239
step    690 | loss 2.2425 | lr 3.00e-04 | grad 2.05 | tok/s 16784
step    700 | loss 1.9619 | lr 3.00e-04 | grad 1.99 | tok/s 17095
step    710 | loss 1.8873 | lr 3.00e-04 | grad 2.58 | tok/s 15978
step    720 | loss 1.7388 | lr 3.00e-04 | grad 2.38 | tok/s 15748
step    730 | loss 1.7602 | lr 3.00e-04 | grad 2.44 | tok/s 17071
step    740 | loss 1.8577 | lr 3.00e-04 | grad 1.61 | tok/s 16855
step    750 | loss 1.6096 | lr 3.00e-04 | grad 1.90 | tok/s 17130
step    760 | loss 1.4795 | lr 3.00e-04 | grad 2.34 | tok/s 17104
step    770 | loss 1.4189 | lr 3.00e-04 | grad 1.48 | tok/s 17107
step    780 | loss 1.3553 | lr 3.00e-04 | grad 1.88 | tok/s 17083
step    790 | loss 1.4400 | lr 3.00e-04 | grad 2.22 | tok/s 16546
step    800 | loss 2.1621 | lr 3.00e-04 | grad 2.81 | tok/s 16504
step    810 | loss 1.9245 | lr 3.00e-04 | grad 1.60 | tok/s 16421
step    820 | loss 1.9332 | lr 3.00e-04 | grad 2.22 | tok/s 15788
step    830 | loss 1.9328 | lr 3.00e-04 | grad 1.76 | tok/s 16921
step    840 | loss 1.8268 | lr 3.00e-04 | grad 1.60 | tok/s 17061
step    850 | loss 1.8834 | lr 3.00e-04 | grad 2.25 | tok/s 17029
step    860 | loss 1.8297 | lr 3.00e-04 | grad 2.59 | tok/s 16752
step    870 | loss 1.7796 | lr 3.00e-04 | grad 1.87 | tok/s 16152
step    880 | loss 1.9324 | lr 3.00e-04 | grad 1.65 | tok/s 16229
step    890 | loss 1.9242 | lr 3.00e-04 | grad 2.38 | tok/s 16474
step    900 | loss 1.7841 | lr 3.00e-04 | grad 1.39 | tok/s 16496
step    910 | loss 1.6364 | lr 3.00e-04 | grad 1.86 | tok/s 16114
step    920 | loss 1.8064 | lr 3.00e-04 | grad 2.56 | tok/s 16779
step    930 | loss 1.8321 | lr 3.00e-04 | grad 2.36 | tok/s 16043
step    940 | loss 1.7153 | lr 3.00e-04 | grad 1.46 | tok/s 16912
step    950 | loss 1.7807 | lr 3.00e-04 | grad 1.98 | tok/s 16991
step    960 | loss 1.6272 | lr 3.00e-04 | grad 2.05 | tok/s 17007
step    970 | loss 1.8842 | lr 3.00e-04 | grad 1.89 | tok/s 15972
step    980 | loss 1.8285 | lr 3.00e-04 | grad 1.34 | tok/s 16406
step    990 | loss 1.7199 | lr 3.00e-04 | grad 1.82 | tok/s 16693
step   1000 | loss 2.0558 | lr 3.00e-04 | grad 6.00 | tok/s 16022
  >>> saved checkpoint: checkpoint_step_001000_loss_2.0558.pt
step   1010 | loss 1.9171 | lr 3.00e-04 | grad 1.45 | tok/s 5855
step   1020 | loss 1.8465 | lr 3.00e-04 | grad 1.86 | tok/s 15786
step   1030 | loss 1.6267 | lr 3.00e-04 | grad 1.30 | tok/s 16453
step   1040 | loss 1.7119 | lr 3.00e-04 | grad 2.41 | tok/s 16786
step   1050 | loss 1.7672 | lr 3.00e-04 | grad 1.49 | tok/s 15785
step   1060 | loss 1.9316 | lr 3.00e-04 | grad 1.55 | tok/s 16864
step   1070 | loss 1.9394 | lr 3.00e-04 | grad 1.98 | tok/s 16580
step   1080 | loss 1.5907 | lr 3.00e-04 | grad 1.42 | tok/s 15335
step   1090 | loss 1.1871 | lr 3.00e-04 | grad 0.62 | tok/s 17053
step   1100 | loss 1.7191 | lr 3.00e-04 | grad 1.71 | tok/s 16326
step   1110 | loss 1.6170 | lr 3.00e-04 | grad 1.60 | tok/s 17147
step   1120 | loss 1.5496 | lr 3.00e-04 | grad 1.66 | tok/s 17150
step   1130 | loss 1.4831 | lr 3.00e-04 | grad 1.59 | tok/s 17128
step   1140 | loss 1.4706 | lr 3.00e-04 | grad 1.39 | tok/s 17136
step   1150 | loss 1.4771 | lr 3.00e-04 | grad 1.57 | tok/s 17128
step   1160 | loss 1.3911 | lr 3.00e-04 | grad 1.73 | tok/s 17143
step   1170 | loss 1.4222 | lr 3.00e-04 | grad 1.47 | tok/s 17117
step   1180 | loss 1.5111 | lr 3.00e-04 | grad 1.55 | tok/s 17129
step   1190 | loss 1.4019 | lr 3.00e-04 | grad 1.69 | tok/s 17117
step   1200 | loss 1.4064 | lr 3.00e-04 | grad 1.37 | tok/s 17113
step   1210 | loss 1.4269 | lr 3.00e-04 | grad 1.47 | tok/s 17118
step   1220 | loss 1.4382 | lr 3.00e-04 | grad 1.34 | tok/s 17088
step   1230 | loss 1.4230 | lr 3.00e-04 | grad 1.44 | tok/s 17121
step   1240 | loss 1.4022 | lr 3.00e-04 | grad 1.62 | tok/s 16989
step   1250 | loss 2.0220 | lr 3.00e-04 | grad 1.66 | tok/s 16238
step   1260 | loss 1.4593 | lr 3.00e-04 | grad 1.45 | tok/s 16010
step   1270 | loss 1.9028 | lr 3.00e-04 | grad 1.56 | tok/s 15969
step   1280 | loss 1.7512 | lr 3.00e-04 | grad 1.69 | tok/s 16665
step   1290 | loss 1.6396 | lr 3.00e-04 | grad 1.87 | tok/s 16373
step   1300 | loss 1.6858 | lr 3.00e-04 | grad 1.47 | tok/s 16261
step   1310 | loss 1.6599 | lr 3.00e-04 | grad 1.31 | tok/s 17040
step   1320 | loss 1.7332 | lr 3.00e-04 | grad 1.58 | tok/s 16830
step   1330 | loss 1.6565 | lr 3.00e-04 | grad 1.46 | tok/s 16845
step   1340 | loss 1.7515 | lr 3.00e-04 | grad 2.25 | tok/s 15876
step   1350 | loss 1.8214 | lr 3.00e-04 | grad 1.48 | tok/s 15722
step   1360 | loss 1.6961 | lr 3.00e-04 | grad 1.13 | tok/s 16522
step   1370 | loss 1.6264 | lr 3.00e-04 | grad 4.53 | tok/s 16302
step   1380 | loss 1.7571 | lr 3.00e-04 | grad 2.31 | tok/s 15662
step   1390 | loss 1.6435 | lr 3.00e-04 | grad 2.59 | tok/s 16498
step   1400 | loss 1.5337 | lr 3.00e-04 | grad 1.20 | tok/s 16112
step   1410 | loss 1.7244 | lr 3.00e-04 | grad 6.88 | tok/s 16098
step   1420 | loss 1.7822 | lr 3.00e-04 | grad 1.65 | tok/s 16044
step   1430 | loss 1.5378 | lr 3.00e-04 | grad 1.61 | tok/s 16288
step   1440 | loss 1.3045 | lr 3.00e-04 | grad 1.76 | tok/s 17093
step   1450 | loss 1.2988 | lr 3.00e-04 | grad 1.83 | tok/s 16855
step   1460 | loss 1.7940 | lr 3.00e-04 | grad 1.23 | tok/s 15947
step   1470 | loss 1.7030 | lr 3.00e-04 | grad 1.62 | tok/s 16953
step   1480 | loss 2.1611 | lr 3.00e-04 | grad 2.30 | tok/s 16753
step   1490 | loss 1.8632 | lr 3.00e-04 | grad 1.70 | tok/s 17006
step   1500 | loss 1.5017 | lr 3.00e-04 | grad 1.62 | tok/s 17089
step   1510 | loss 1.6823 | lr 3.00e-04 | grad 2.27 | tok/s 16865
step   1520 | loss 1.5810 | lr 3.00e-04 | grad 1.77 | tok/s 16558
step   1530 | loss 1.5503 | lr 3.00e-04 | grad 1.91 | tok/s 16951
step   1540 | loss 1.7556 | lr 3.00e-04 | grad 1.73 | tok/s 15965
step   1550 | loss 1.4467 | lr 3.00e-04 | grad 1.80 | tok/s 16989
step   1560 | loss 1.6960 | lr 3.00e-04 | grad 1.19 | tok/s 16109
step   1570 | loss 1.4788 | lr 3.00e-04 | grad 1.41 | tok/s 16965
step   1580 | loss 2.0770 | lr 3.00e-04 | grad 3.06 | tok/s 16918
step   1590 | loss 1.7932 | lr 3.00e-04 | grad 1.44 | tok/s 16077
step   1600 | loss 1.0787 | lr 3.00e-04 | grad 1.44 | tok/s 17198
step   1610 | loss 1.2095 | lr 3.00e-04 | grad 1.38 | tok/s 16233
step   1620 | loss 1.6002 | lr 3.00e-04 | grad 2.12 | tok/s 15936
step   1630 | loss 1.5767 | lr 3.00e-04 | grad 1.38 | tok/s 16625
step   1640 | loss 1.4840 | lr 3.00e-04 | grad 1.59 | tok/s 16117
step   1650 | loss 1.6474 | lr 3.00e-04 | grad 1.45 | tok/s 15265
step   1660 | loss 1.5359 | lr 3.00e-04 | grad 1.38 | tok/s 17057
step   1670 | loss 1.6165 | lr 3.00e-04 | grad 2.33 | tok/s 16445
step   1680 | loss 1.7794 | lr 3.00e-04 | grad 1.16 | tok/s 15738
step   1690 | loss 1.6222 | lr 3.00e-04 | grad 2.27 | tok/s 16506
step   1700 | loss 1.6359 | lr 3.00e-04 | grad 1.43 | tok/s 16363
step   1710 | loss 1.6178 | lr 3.00e-04 | grad 1.50 | tok/s 16354
step   1720 | loss 1.7056 | lr 3.00e-04 | grad 1.50 | tok/s 17064
step   1730 | loss 1.5286 | lr 3.00e-04 | grad 2.31 | tok/s 17118
step   1740 | loss 1.6102 | lr 3.00e-04 | grad 1.49 | tok/s 16534
step   1750 | loss 1.6462 | lr 3.00e-04 | grad 2.03 | tok/s 16530
step   1760 | loss 1.6710 | lr 3.00e-04 | grad 1.48 | tok/s 16465
step   1770 | loss 1.5556 | lr 3.00e-04 | grad 1.46 | tok/s 16176
step   1780 | loss 1.5940 | lr 3.00e-04 | grad 1.30 | tok/s 16689
step   1790 | loss 1.5504 | lr 3.00e-04 | grad 2.17 | tok/s 16510
step   1800 | loss 1.6802 | lr 3.00e-04 | grad 1.30 | tok/s 16189
step   1810 | loss 1.5730 | lr 3.00e-04 | grad 2.47 | tok/s 15923
step   1820 | loss 1.6400 | lr 3.00e-04 | grad 6.44 | tok/s 16455
step   1830 | loss 1.5635 | lr 3.00e-04 | grad 2.31 | tok/s 16745
step   1840 | loss 1.5757 | lr 3.00e-04 | grad 1.29 | tok/s 15952
step   1850 | loss 1.4880 | lr 3.00e-04 | grad 1.50 | tok/s 17011
step   1860 | loss 1.4737 | lr 3.00e-04 | grad 1.77 | tok/s 16133
step   1870 | loss 1.5008 | lr 3.00e-04 | grad 1.22 | tok/s 16509
step   1880 | loss 1.3992 | lr 3.00e-04 | grad 1.66 | tok/s 15911
step   1890 | loss 1.6549 | lr 3.00e-04 | grad 1.46 | tok/s 15381
step   1900 | loss 1.4934 | lr 3.00e-04 | grad 1.52 | tok/s 16483
step   1910 | loss 1.5569 | lr 3.00e-04 | grad 1.19 | tok/s 15621
step   1920 | loss 1.5186 | lr 3.00e-04 | grad 1.20 | tok/s 17111
step   1930 | loss 1.5507 | lr 3.00e-04 | grad 1.76 | tok/s 15749
step   1940 | loss 1.5645 | lr 3.00e-04 | grad 1.59 | tok/s 16989
step   1950 | loss 2.1456 | lr 3.00e-04 | grad 2.33 | tok/s 16935
step   1960 | loss 1.8229 | lr 3.00e-04 | grad 2.00 | tok/s 17098
step   1970 | loss 1.6838 | lr 3.00e-04 | grad 1.49 | tok/s 16692
step   1980 | loss 1.6621 | lr 3.00e-04 | grad 1.49 | tok/s 15968
step   1990 | loss 1.7036 | lr 3.00e-04 | grad 1.70 | tok/s 16276
step   2000 | loss 1.6014 | lr 3.00e-04 | grad 1.59 | tok/s 16520
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6014.pt
step   2010 | loss 1.2412 | lr 3.00e-04 | grad 1.32 | tok/s 6247
step   2020 | loss 1.4338 | lr 3.00e-04 | grad 1.84 | tok/s 16788
step   2030 | loss 1.1134 | lr 3.00e-04 | grad 2.11 | tok/s 17277
step   2040 | loss 1.5733 | lr 3.00e-04 | grad 1.59 | tok/s 17196
step   2050 | loss 1.4216 | lr 3.00e-04 | grad 1.28 | tok/s 16587
step   2060 | loss 1.7224 | lr 3.00e-04 | grad 1.22 | tok/s 16133
step   2070 | loss 1.8952 | lr 3.00e-04 | grad 3.45 | tok/s 16314
step   2080 | loss 2.3284 | lr 3.00e-04 | grad 3.41 | tok/s 17204
step   2090 | loss 1.7429 | lr 3.00e-04 | grad 2.14 | tok/s 16845
step   2100 | loss 1.5516 | lr 3.00e-04 | grad 1.62 | tok/s 16868
step   2110 | loss 1.6249 | lr 3.00e-04 | grad 1.60 | tok/s 16006
step   2120 | loss 0.9738 | lr 3.00e-04 | grad 1.33 | tok/s 17295
step   2130 | loss 1.3705 | lr 3.00e-04 | grad 2.00 | tok/s 16548
step   2140 | loss 1.5333 | lr 3.00e-04 | grad 1.38 | tok/s 16670
step   2150 | loss 1.4003 | lr 3.00e-04 | grad 1.77 | tok/s 17151
step   2160 | loss 1.2836 | lr 3.00e-04 | grad 1.53 | tok/s 17136
step   2170 | loss 1.3491 | lr 3.00e-04 | grad 1.23 | tok/s 17136
step   2180 | loss 1.2903 | lr 3.00e-04 | grad 1.16 | tok/s 17141
step   2190 | loss 1.3132 | lr 3.00e-04 | grad 1.50 | tok/s 17136
step   2200 | loss 1.2857 | lr 3.00e-04 | grad 1.38 | tok/s 17130
step   2210 | loss 1.2445 | lr 3.00e-04 | grad 1.59 | tok/s 17143
step   2220 | loss 1.2339 | lr 3.00e-04 | grad 1.52 | tok/s 17129
step   2230 | loss 1.4896 | lr 3.00e-04 | grad 1.77 | tok/s 16796
step   2240 | loss 1.4426 | lr 3.00e-04 | grad 1.38 | tok/s 16528
step   2250 | loss 1.7267 | lr 3.00e-04 | grad 3.14 | tok/s 17139
step   2260 | loss 1.6876 | lr 3.00e-04 | grad 1.40 | tok/s 16532
step   2270 | loss 2.0895 | lr 3.00e-04 | grad 2.03 | tok/s 16928
step   2280 | loss 1.5380 | lr 3.00e-04 | grad 2.06 | tok/s 17079
step   2290 | loss 1.5973 | lr 3.00e-04 | grad 6.09 | tok/s 16473
step   2300 | loss 1.8247 | lr 3.00e-04 | grad 2.00 | tok/s 16767
step   2310 | loss 1.5730 | lr 3.00e-04 | grad 1.66 | tok/s 16150
step   2320 | loss 1.8801 | lr 3.00e-04 | grad 1.87 | tok/s 16108
step   2330 | loss 1.6493 | lr 3.00e-04 | grad 2.09 | tok/s 16190
step   2340 | loss 1.5738 | lr 3.00e-04 | grad 1.57 | tok/s 15978
step   2350 | loss 1.4817 | lr 3.00e-04 | grad 1.84 | tok/s 16712
step   2360 | loss 1.4113 | lr 3.00e-04 | grad 1.19 | tok/s 17119
step   2370 | loss 1.6646 | lr 3.00e-04 | grad 2.36 | tok/s 16776
step   2380 | loss 1.6701 | lr 3.00e-04 | grad 1.51 | tok/s 17148
step   2390 | loss 1.2644 | lr 3.00e-04 | grad 1.29 | tok/s 17095
step   2400 | loss 1.1829 | lr 3.00e-04 | grad 1.46 | tok/s 17113
step   2410 | loss 1.2592 | lr 3.00e-04 | grad 1.25 | tok/s 16435
step   2420 | loss 1.5628 | lr 3.00e-04 | grad 1.41 | tok/s 15817

Training complete! Final step: 2425
