Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_30/levelllama_100m_20260126_174411
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 324,768,384 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.3475 | lr 3.00e-04 | grad 2.47 | tok/s 6690
step     20 | loss 2.7524 | lr 3.00e-04 | grad 1.55 | tok/s 20316
step     30 | loss 2.7989 | lr 3.00e-04 | grad 1.56 | tok/s 20549
step     40 | loss 2.8402 | lr 3.00e-04 | grad 2.39 | tok/s 19696
step     50 | loss 3.3509 | lr 3.00e-04 | grad 4.00 | tok/s 20014
step     60 | loss 2.5012 | lr 3.00e-04 | grad 7.03 | tok/s 20686
step     70 | loss 2.4578 | lr 3.00e-04 | grad 1.56 | tok/s 20939
step     80 | loss 6.4545 | lr 3.00e-04 | grad 10.06 | tok/s 21083
step     90 | loss 4.8020 | lr 3.00e-04 | grad 1.99 | tok/s 21460
step    100 | loss 3.7813 | lr 3.00e-04 | grad 2.44 | tok/s 21447
step    110 | loss 3.6047 | lr 3.00e-04 | grad 5.25 | tok/s 21441
step    120 | loss 3.4772 | lr 3.00e-04 | grad 6.38 | tok/s 21426
step    130 | loss 3.4039 | lr 3.00e-04 | grad 3.05 | tok/s 21433
step    140 | loss 2.9283 | lr 3.00e-04 | grad 2.20 | tok/s 21354
step    150 | loss 3.3008 | lr 3.00e-04 | grad 4.56 | tok/s 21368
step    160 | loss 2.7262 | lr 3.00e-04 | grad 3.22 | tok/s 21354
step    170 | loss 2.7481 | lr 3.00e-04 | grad 4.69 | tok/s 21325
step    180 | loss 2.5684 | lr 3.00e-04 | grad 4.09 | tok/s 21351
step    190 | loss 2.7408 | lr 3.00e-04 | grad 2.11 | tok/s 21320
step    200 | loss 2.4140 | lr 3.00e-04 | grad 2.17 | tok/s 21311
step    210 | loss 2.4012 | lr 3.00e-04 | grad 2.98 | tok/s 21289
step    220 | loss 2.6125 | lr 3.00e-04 | grad 2.62 | tok/s 21042
step    230 | loss 3.5134 | lr 3.00e-04 | grad 1.73 | tok/s 20799
step    240 | loss 2.6104 | lr 3.00e-04 | grad 2.55 | tok/s 19750
step    250 | loss 2.4549 | lr 3.00e-04 | grad 1.20 | tok/s 20310
step    260 | loss 2.2403 | lr 3.00e-04 | grad 1.37 | tok/s 20945
step    270 | loss 2.5008 | lr 3.00e-04 | grad 1.44 | tok/s 20655
step    280 | loss 2.6682 | lr 3.00e-04 | grad 2.75 | tok/s 20249
step    290 | loss 2.7733 | lr 3.00e-04 | grad 1.24 | tok/s 21341
step    300 | loss 1.8101 | lr 3.00e-04 | grad 1.65 | tok/s 21341
step    310 | loss 2.9290 | lr 3.00e-04 | grad 1.49 | tok/s 20964
step    320 | loss 2.5725 | lr 3.00e-04 | grad 3.05 | tok/s 20513
step    330 | loss 2.3529 | lr 3.00e-04 | grad 1.23 | tok/s 19811
step    340 | loss 2.6278 | lr 3.00e-04 | grad 1.03 | tok/s 20112
step    350 | loss 2.4358 | lr 3.00e-04 | grad 1.64 | tok/s 20647
step    360 | loss 2.5738 | lr 3.00e-04 | grad 2.42 | tok/s 21092
step    370 | loss 2.2378 | lr 3.00e-04 | grad 1.17 | tok/s 19119
step    380 | loss 2.2049 | lr 3.00e-04 | grad 1.32 | tok/s 20353
step    390 | loss 2.0883 | lr 3.00e-04 | grad 0.98 | tok/s 21269
step    400 | loss 2.0714 | lr 3.00e-04 | grad 1.45 | tok/s 21058
step    410 | loss 2.0050 | lr 3.00e-04 | grad 1.02 | tok/s 20556
step    420 | loss 2.1753 | lr 3.00e-04 | grad 1.89 | tok/s 19581
step    430 | loss 2.4750 | lr 3.00e-04 | grad 1.62 | tok/s 20887
step    440 | loss 2.4936 | lr 3.00e-04 | grad 1.51 | tok/s 19748
step    450 | loss 2.4021 | lr 3.00e-04 | grad 1.18 | tok/s 20447
step    460 | loss 2.2127 | lr 3.00e-04 | grad 1.98 | tok/s 20020
step    470 | loss 2.2820 | lr 3.00e-04 | grad 1.25 | tok/s 20589
step    480 | loss 2.7203 | lr 3.00e-04 | grad 2.64 | tok/s 20609
step    490 | loss 2.1732 | lr 3.00e-04 | grad 1.72 | tok/s 19458
step    500 | loss 2.1543 | lr 3.00e-04 | grad 1.53 | tok/s 20811
step    510 | loss 2.1618 | lr 3.00e-04 | grad 1.02 | tok/s 21045
step    520 | loss 2.1582 | lr 3.00e-04 | grad 0.98 | tok/s 20999
step    530 | loss 2.3084 | lr 3.00e-04 | grad 1.16 | tok/s 20216
step    540 | loss 2.0665 | lr 3.00e-04 | grad 1.15 | tok/s 20243
step    550 | loss 1.9283 | lr 3.00e-04 | grad 1.20 | tok/s 19833
step    560 | loss 2.1058 | lr 3.00e-04 | grad 1.27 | tok/s 19325
step    570 | loss 2.0442 | lr 3.00e-04 | grad 1.87 | tok/s 19890
step    580 | loss 1.9315 | lr 3.00e-04 | grad 1.25 | tok/s 19826
step    590 | loss 2.2889 | lr 3.00e-04 | grad 1.32 | tok/s 20271
step    600 | loss 2.1738 | lr 3.00e-04 | grad 1.07 | tok/s 19588
step    610 | loss 2.0069 | lr 3.00e-04 | grad 1.27 | tok/s 20612
step    620 | loss 1.8651 | lr 3.00e-04 | grad 0.95 | tok/s 19533
step    630 | loss 2.0393 | lr 3.00e-04 | grad 1.81 | tok/s 19683
step    640 | loss 2.2006 | lr 3.00e-04 | grad 1.21 | tok/s 20215
step    650 | loss 2.0406 | lr 3.00e-04 | grad 1.41 | tok/s 20297
step    660 | loss 2.0487 | lr 3.00e-04 | grad 0.93 | tok/s 20392
step    670 | loss 2.2769 | lr 3.00e-04 | grad 3.45 | tok/s 20531
step    680 | loss 2.0391 | lr 3.00e-04 | grad 1.05 | tok/s 20120
step    690 | loss 2.3473 | lr 3.00e-04 | grad 1.55 | tok/s 20823
step    700 | loss 2.1628 | lr 3.00e-04 | grad 1.56 | tok/s 21225
step    710 | loss 1.9435 | lr 3.00e-04 | grad 1.55 | tok/s 19813
step    720 | loss 1.7962 | lr 3.00e-04 | grad 1.29 | tok/s 19531
step    730 | loss 1.9153 | lr 3.00e-04 | grad 1.56 | tok/s 21185
step    740 | loss 1.9324 | lr 3.00e-04 | grad 1.23 | tok/s 20894
step    750 | loss 1.7706 | lr 3.00e-04 | grad 1.16 | tok/s 21236
step    760 | loss 1.6282 | lr 3.00e-04 | grad 1.34 | tok/s 21254
step    770 | loss 1.6075 | lr 3.00e-04 | grad 1.02 | tok/s 21226
step    780 | loss 1.5481 | lr 3.00e-04 | grad 1.20 | tok/s 21251
step    790 | loss 1.5954 | lr 3.00e-04 | grad 1.48 | tok/s 20576
step    800 | loss 2.3003 | lr 3.00e-04 | grad 2.55 | tok/s 20526
step    810 | loss 1.9897 | lr 3.00e-04 | grad 1.16 | tok/s 20416
step    820 | loss 1.9994 | lr 3.00e-04 | grad 1.68 | tok/s 19607
step    830 | loss 2.0962 | lr 3.00e-04 | grad 1.19 | tok/s 21031
step    840 | loss 2.0040 | lr 3.00e-04 | grad 1.17 | tok/s 21244
step    850 | loss 2.0110 | lr 3.00e-04 | grad 1.31 | tok/s 21126
step    860 | loss 1.9682 | lr 3.00e-04 | grad 1.92 | tok/s 20920
step    870 | loss 1.8557 | lr 3.00e-04 | grad 1.39 | tok/s 20152
step    880 | loss 2.0286 | lr 3.00e-04 | grad 1.05 | tok/s 20224
step    890 | loss 1.9861 | lr 3.00e-04 | grad 1.47 | tok/s 20504
step    900 | loss 1.8701 | lr 3.00e-04 | grad 1.16 | tok/s 20546
step    910 | loss 1.7494 | lr 3.00e-04 | grad 1.62 | tok/s 20080
step    920 | loss 1.9570 | lr 3.00e-04 | grad 2.06 | tok/s 20898
step    930 | loss 1.8955 | lr 3.00e-04 | grad 1.84 | tok/s 19933
step    940 | loss 1.8767 | lr 3.00e-04 | grad 1.16 | tok/s 21034
step    950 | loss 1.9247 | lr 3.00e-04 | grad 1.37 | tok/s 21119
step    960 | loss 1.8441 | lr 3.00e-04 | grad 1.31 | tok/s 21166
step    970 | loss 1.9668 | lr 3.00e-04 | grad 1.48 | tok/s 19903
step    980 | loss 1.9157 | lr 3.00e-04 | grad 1.18 | tok/s 20448
step    990 | loss 1.8215 | lr 3.00e-04 | grad 1.40 | tok/s 20798
step   1000 | loss 2.1530 | lr 3.00e-04 | grad 5.19 | tok/s 19956
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1530.pt
step   1010 | loss 2.0254 | lr 3.00e-04 | grad 1.24 | tok/s 9128
step   1020 | loss 1.9086 | lr 3.00e-04 | grad 1.39 | tok/s 19158
step   1030 | loss 1.7590 | lr 3.00e-04 | grad 1.00 | tok/s 20269
step   1040 | loss 1.7573 | lr 3.00e-04 | grad 1.09 | tok/s 20940
step   1050 | loss 1.8104 | lr 3.00e-04 | grad 1.83 | tok/s 19349
step   1060 | loss 2.0055 | lr 3.00e-04 | grad 1.55 | tok/s 20920
step   1070 | loss 2.1217 | lr 3.00e-04 | grad 1.23 | tok/s 21038
step   1080 | loss 1.7484 | lr 3.00e-04 | grad 1.31 | tok/s 19322
step   1090 | loss 1.4963 | lr 3.00e-04 | grad 0.82 | tok/s 20225
step   1100 | loss 1.5523 | lr 3.00e-04 | grad 1.20 | tok/s 20238
step   1110 | loss 1.7980 | lr 3.00e-04 | grad 1.40 | tok/s 21268
step   1120 | loss 1.6650 | lr 3.00e-04 | grad 1.09 | tok/s 21273
step   1130 | loss 1.6175 | lr 3.00e-04 | grad 1.18 | tok/s 21275
step   1140 | loss 1.5768 | lr 3.00e-04 | grad 1.30 | tok/s 21261
step   1150 | loss 1.5949 | lr 3.00e-04 | grad 1.09 | tok/s 21254
step   1160 | loss 1.5032 | lr 3.00e-04 | grad 1.09 | tok/s 21283
step   1170 | loss 1.5140 | lr 3.00e-04 | grad 1.06 | tok/s 21265
step   1180 | loss 1.6606 | lr 3.00e-04 | grad 1.16 | tok/s 21258
step   1190 | loss 1.5365 | lr 3.00e-04 | grad 1.27 | tok/s 21240
step   1200 | loss 1.5098 | lr 3.00e-04 | grad 1.29 | tok/s 21257
step   1210 | loss 1.5435 | lr 3.00e-04 | grad 1.28 | tok/s 21260
step   1220 | loss 1.5538 | lr 3.00e-04 | grad 1.04 | tok/s 21257
step   1230 | loss 1.5294 | lr 3.00e-04 | grad 1.29 | tok/s 21281
step   1240 | loss 1.4725 | lr 3.00e-04 | grad 1.10 | tok/s 21248
step   1250 | loss 2.0107 | lr 3.00e-04 | grad 1.35 | tok/s 20397
step   1260 | loss 1.7058 | lr 3.00e-04 | grad 1.98 | tok/s 19565
step   1270 | loss 1.6986 | lr 3.00e-04 | grad 1.20 | tok/s 19843
step   1280 | loss 2.0301 | lr 3.00e-04 | grad 1.06 | tok/s 20393
step   1290 | loss 1.7466 | lr 3.00e-04 | grad 1.55 | tok/s 20487
step   1300 | loss 1.7739 | lr 3.00e-04 | grad 1.24 | tok/s 20671
step   1310 | loss 1.7399 | lr 3.00e-04 | grad 1.45 | tok/s 20638
step   1320 | loss 1.8518 | lr 3.00e-04 | grad 1.25 | tok/s 20786
step   1330 | loss 1.9277 | lr 3.00e-04 | grad 1.52 | tok/s 20890
step   1340 | loss 1.5635 | lr 3.00e-04 | grad 1.42 | tok/s 19942
step   1350 | loss 2.0583 | lr 3.00e-04 | grad 1.23 | tok/s 19274
step   1360 | loss 1.8059 | lr 3.00e-04 | grad 1.26 | tok/s 20461
step   1370 | loss 1.6730 | lr 3.00e-04 | grad 1.55 | tok/s 20536
step   1380 | loss 1.9038 | lr 3.00e-04 | grad 1.47 | tok/s 19406
step   1390 | loss 1.7789 | lr 3.00e-04 | grad 1.21 | tok/s 20514
step   1400 | loss 1.6856 | lr 3.00e-04 | grad 1.15 | tok/s 19775
step   1410 | loss 1.6756 | lr 3.00e-04 | grad 1.25 | tok/s 20070
step   1420 | loss 1.9564 | lr 3.00e-04 | grad 2.77 | tok/s 19898
step   1430 | loss 1.7272 | lr 3.00e-04 | grad 1.23 | tok/s 20535
step   1440 | loss 1.4739 | lr 3.00e-04 | grad 1.53 | tok/s 20702
step   1450 | loss 1.3864 | lr 3.00e-04 | grad 1.14 | tok/s 21107
step   1460 | loss 1.8886 | lr 3.00e-04 | grad 1.58 | tok/s 20075
step   1470 | loss 1.8082 | lr 3.00e-04 | grad 1.41 | tok/s 20572
step   1480 | loss 2.2307 | lr 3.00e-04 | grad 2.34 | tok/s 20865
step   1490 | loss 2.1926 | lr 3.00e-04 | grad 1.49 | tok/s 21143
step   1500 | loss 1.7114 | lr 3.00e-04 | grad 1.42 | tok/s 21210
step   1510 | loss 1.7515 | lr 3.00e-04 | grad 1.18 | tok/s 20878
step   1520 | loss 1.6550 | lr 3.00e-04 | grad 1.22 | tok/s 20488
step   1530 | loss 1.6761 | lr 3.00e-04 | grad 1.26 | tok/s 21106
step   1540 | loss 1.7717 | lr 3.00e-04 | grad 1.28 | tok/s 19665
step   1550 | loss 1.6494 | lr 3.00e-04 | grad 1.40 | tok/s 21005
step   1560 | loss 1.7437 | lr 3.00e-04 | grad 1.25 | tok/s 20018
step   1570 | loss 1.6217 | lr 3.00e-04 | grad 1.18 | tok/s 21262
step   1580 | loss 2.0647 | lr 3.00e-04 | grad 1.81 | tok/s 20773
step   1590 | loss 2.1095 | lr 3.00e-04 | grad 1.53 | tok/s 19976
step   1600 | loss 1.3918 | lr 3.00e-04 | grad 3.38 | tok/s 21266
step   1610 | loss 1.1278 | lr 3.00e-04 | grad 1.53 | tok/s 20588
step   1620 | loss 1.6538 | lr 3.00e-04 | grad 2.16 | tok/s 19312
step   1630 | loss 1.7788 | lr 3.00e-04 | grad 1.47 | tok/s 20661
step   1640 | loss 1.5624 | lr 3.00e-04 | grad 1.98 | tok/s 20640
step   1650 | loss 1.7136 | lr 3.00e-04 | grad 1.45 | tok/s 19424
step   1660 | loss 1.6862 | lr 3.00e-04 | grad 1.17 | tok/s 20125
step   1670 | loss 1.6496 | lr 3.00e-04 | grad 3.88 | tok/s 20596
step   1680 | loss 1.9605 | lr 3.00e-04 | grad 1.38 | tok/s 19745
step   1690 | loss 1.7059 | lr 3.00e-04 | grad 2.92 | tok/s 20132
step   1700 | loss 1.7967 | lr 3.00e-04 | grad 1.80 | tok/s 20653
step   1710 | loss 1.7197 | lr 3.00e-04 | grad 1.23 | tok/s 20387
step   1720 | loss 1.8056 | lr 3.00e-04 | grad 2.11 | tok/s 20771
step   1730 | loss 1.8021 | lr 3.00e-04 | grad 1.59 | tok/s 21270
step   1740 | loss 1.7321 | lr 3.00e-04 | grad 1.80 | tok/s 20950
step   1750 | loss 1.8237 | lr 3.00e-04 | grad 1.89 | tok/s 20338
step   1760 | loss 1.6851 | lr 3.00e-04 | grad 1.31 | tok/s 20250
step   1770 | loss 1.6519 | lr 3.00e-04 | grad 1.51 | tok/s 20091
step   1780 | loss 1.6950 | lr 3.00e-04 | grad 1.23 | tok/s 20878
step   1790 | loss 1.6460 | lr 3.00e-04 | grad 1.24 | tok/s 20414
step   1800 | loss 1.7614 | lr 3.00e-04 | grad 1.30 | tok/s 20469
step   1810 | loss 1.6575 | lr 3.00e-04 | grad 1.55 | tok/s 19838
step   1820 | loss 1.7175 | lr 3.00e-04 | grad 1.10 | tok/s 20126
step   1830 | loss 1.6589 | lr 3.00e-04 | grad 1.46 | tok/s 20745
step   1840 | loss 1.7103 | lr 3.00e-04 | grad 1.23 | tok/s 20059
step   1850 | loss 1.6776 | lr 3.00e-04 | grad 1.08 | tok/s 20802
step   1860 | loss 1.5029 | lr 3.00e-04 | grad 0.96 | tok/s 20213
step   1870 | loss 1.6664 | lr 3.00e-04 | grad 1.43 | tok/s 20292
step   1880 | loss 1.4979 | lr 3.00e-04 | grad 1.50 | tok/s 20020
step   1890 | loss 1.7448 | lr 3.00e-04 | grad 1.38 | tok/s 18824
step   1900 | loss 1.5552 | lr 3.00e-04 | grad 1.15 | tok/s 20483
step   1910 | loss 1.6394 | lr 3.00e-04 | grad 1.45 | tok/s 19566
step   1920 | loss 1.6481 | lr 3.00e-04 | grad 1.19 | tok/s 21082
step   1930 | loss 1.6000 | lr 3.00e-04 | grad 1.48 | tok/s 20059
step   1940 | loss 1.6320 | lr 3.00e-04 | grad 1.29 | tok/s 20601
step   1950 | loss 2.2788 | lr 3.00e-04 | grad 2.28 | tok/s 21036
step   1960 | loss 2.0340 | lr 3.00e-04 | grad 2.03 | tok/s 21275
step   1970 | loss 1.8779 | lr 3.00e-04 | grad 1.31 | tok/s 20745
step   1980 | loss 1.8084 | lr 3.00e-04 | grad 1.42 | tok/s 19846
step   1990 | loss 1.6619 | lr 3.00e-04 | grad 2.38 | tok/s 20369
step   2000 | loss 1.8114 | lr 3.00e-04 | grad 1.20 | tok/s 20638
  >>> saved checkpoint: checkpoint_step_002000_loss_1.8114.pt
step   2010 | loss 1.1968 | lr 3.00e-04 | grad 1.42 | tok/s 9127
step   2020 | loss 1.5034 | lr 3.00e-04 | grad 1.20 | tok/s 20580
step   2030 | loss 1.5555 | lr 3.00e-04 | grad 3.08 | tok/s 21057
step   2040 | loss 1.3596 | lr 3.00e-04 | grad 1.30 | tok/s 21302
step   2050 | loss 1.6559 | lr 3.00e-04 | grad 1.52 | tok/s 21289
step   2060 | loss 1.7140 | lr 3.00e-04 | grad 1.25 | tok/s 19176
step   2070 | loss 1.8727 | lr 3.00e-04 | grad 1.54 | tok/s 20811
step   2080 | loss 2.2667 | lr 3.00e-04 | grad 2.03 | tok/s 20600
step   2090 | loss 2.0855 | lr 3.00e-04 | grad 1.41 | tok/s 21232
step   2100 | loss 1.6751 | lr 3.00e-04 | grad 1.38 | tok/s 20458
step   2110 | loss 1.7817 | lr 3.00e-04 | grad 1.52 | tok/s 20291
step   2120 | loss 1.3918 | lr 3.00e-04 | grad 0.73 | tok/s 20775
step   2130 | loss 1.0612 | lr 3.00e-04 | grad 1.75 | tok/s 21070
step   2140 | loss 1.8188 | lr 3.00e-04 | grad 1.23 | tok/s 20034
step   2150 | loss 1.4882 | lr 3.00e-04 | grad 1.24 | tok/s 21148
step   2160 | loss 1.4061 | lr 3.00e-04 | grad 1.00 | tok/s 21156
step   2170 | loss 1.4071 | lr 3.00e-04 | grad 1.16 | tok/s 21244
step   2180 | loss 1.4009 | lr 3.00e-04 | grad 1.13 | tok/s 21261
step   2190 | loss 1.4002 | lr 3.00e-04 | grad 1.12 | tok/s 21279
step   2200 | loss 1.3863 | lr 3.00e-04 | grad 1.16 | tok/s 21297
step   2210 | loss 1.3280 | lr 3.00e-04 | grad 1.13 | tok/s 21297
step   2220 | loss 1.3331 | lr 3.00e-04 | grad 1.26 | tok/s 21301
step   2230 | loss 1.4464 | lr 3.00e-04 | grad 1.77 | tok/s 21111
step   2240 | loss 1.5889 | lr 3.00e-04 | grad 1.09 | tok/s 21076
step   2250 | loss 1.7759 | lr 3.00e-04 | grad 1.73 | tok/s 20541
step   2260 | loss 1.9428 | lr 3.00e-04 | grad 2.22 | tok/s 20854
step   2270 | loss 1.9721 | lr 3.00e-04 | grad 2.75 | tok/s 20973
step   2280 | loss 1.8726 | lr 3.00e-04 | grad 1.84 | tok/s 21026
step   2290 | loss 1.5696 | lr 3.00e-04 | grad 1.35 | tok/s 21267
step   2300 | loss 2.1967 | lr 3.00e-04 | grad 2.70 | tok/s 20203
step   2310 | loss 1.7690 | lr 3.00e-04 | grad 2.44 | tok/s 19861
step   2320 | loss 1.7214 | lr 3.00e-04 | grad 1.98 | tok/s 20456
step   2330 | loss 2.0390 | lr 3.00e-04 | grad 1.32 | tok/s 19739
step   2340 | loss 1.5546 | lr 3.00e-04 | grad 1.34 | tok/s 19861
step   2350 | loss 1.5912 | lr 3.00e-04 | grad 1.07 | tok/s 20792
step   2360 | loss 1.5972 | lr 3.00e-04 | grad 1.28 | tok/s 20790
step   2370 | loss 1.6307 | lr 3.00e-04 | grad 2.45 | tok/s 20773
step   2380 | loss 1.9310 | lr 3.00e-04 | grad 1.71 | tok/s 21149
step   2390 | loss 1.6107 | lr 3.00e-04 | grad 1.38 | tok/s 21096
step   2400 | loss 1.3656 | lr 3.00e-04 | grad 1.22 | tok/s 21130
step   2410 | loss 1.2482 | lr 3.00e-04 | grad 1.63 | tok/s 20991
step   2420 | loss 1.5824 | lr 3.00e-04 | grad 2.09 | tok/s 19772
step   2430 | loss 1.6656 | lr 3.00e-04 | grad 1.30 | tok/s 19998
step   2440 | loss 1.4105 | lr 3.00e-04 | grad 1.49 | tok/s 20903
step   2450 | loss 1.6205 | lr 3.00e-04 | grad 1.45 | tok/s 20113
step   2460 | loss 1.6528 | lr 3.00e-04 | grad 1.30 | tok/s 20999
step   2470 | loss 1.3893 | lr 3.00e-04 | grad 1.68 | tok/s 21081
step   2480 | loss 1.5163 | lr 3.00e-04 | grad 1.51 | tok/s 21155
step   2490 | loss 1.4518 | lr 3.00e-04 | grad 1.76 | tok/s 20127
step   2500 | loss 1.7014 | lr 3.00e-04 | grad 1.99 | tok/s 20791
step   2510 | loss 1.6958 | lr 3.00e-04 | grad 1.26 | tok/s 21261
step   2520 | loss 1.6432 | lr 3.00e-04 | grad 1.70 | tok/s 21242
step   2530 | loss 1.6424 | lr 3.00e-04 | grad 1.12 | tok/s 20708
step   2540 | loss 1.4880 | lr 3.00e-04 | grad 1.76 | tok/s 19990
step   2550 | loss 1.5321 | lr 3.00e-04 | grad 1.16 | tok/s 21100
step   2560 | loss 1.3790 | lr 3.00e-04 | grad 2.86 | tok/s 19837
step   2570 | loss 1.8186 | lr 3.00e-04 | grad 1.13 | tok/s 20651
step   2580 | loss 1.4946 | lr 3.00e-04 | grad 1.65 | tok/s 19356
step   2590 | loss 1.6191 | lr 3.00e-04 | grad 1.79 | tok/s 20949
step   2600 | loss 1.6834 | lr 3.00e-04 | grad 2.03 | tok/s 19117
step   2610 | loss 1.8948 | lr 3.00e-04 | grad 1.66 | tok/s 21131
step   2620 | loss 1.7209 | lr 3.00e-04 | grad 1.23 | tok/s 20336
step   2630 | loss 1.6412 | lr 3.00e-04 | grad 1.16 | tok/s 21011
step   2640 | loss 1.6240 | lr 3.00e-04 | grad 1.62 | tok/s 20617
step   2650 | loss 1.7751 | lr 3.00e-04 | grad 1.52 | tok/s 21012
step   2660 | loss 1.6427 | lr 3.00e-04 | grad 1.02 | tok/s 20533
step   2670 | loss 1.5116 | lr 3.00e-04 | grad 1.81 | tok/s 20044
step   2680 | loss 1.7080 | lr 3.00e-04 | grad 3.05 | tok/s 19735
step   2690 | loss 1.6854 | lr 3.00e-04 | grad 1.17 | tok/s 21065
step   2700 | loss 1.5982 | lr 3.00e-04 | grad 2.25 | tok/s 20730
step   2710 | loss 1.8000 | lr 3.00e-04 | grad 4.38 | tok/s 20197
step   2720 | loss 1.5500 | lr 3.00e-04 | grad 2.25 | tok/s 19254
step   2730 | loss 1.5356 | lr 3.00e-04 | grad 1.14 | tok/s 20676
step   2740 | loss 1.5743 | lr 3.00e-04 | grad 2.06 | tok/s 20555
step   2750 | loss 2.1289 | lr 3.00e-04 | grad 1.48 | tok/s 21075
step   2760 | loss 1.5184 | lr 3.00e-04 | grad 1.42 | tok/s 20053
step   2770 | loss 1.6664 | lr 3.00e-04 | grad 1.64 | tok/s 19703
step   2780 | loss 1.4435 | lr 3.00e-04 | grad 1.45 | tok/s 21260
step   2790 | loss 1.7379 | lr 3.00e-04 | grad 3.25 | tok/s 20152
step   2800 | loss 1.6964 | lr 3.00e-04 | grad 1.18 | tok/s 19938
step   2810 | loss 1.3700 | lr 3.00e-04 | grad 1.16 | tok/s 20638
step   2820 | loss 1.5534 | lr 3.00e-04 | grad 1.50 | tok/s 19394
step   2830 | loss 1.5517 | lr 3.00e-04 | grad 2.12 | tok/s 20667
step   2840 | loss 1.2672 | lr 3.00e-04 | grad 1.51 | tok/s 21251
step   2850 | loss 1.8670 | lr 3.00e-04 | grad 2.05 | tok/s 20712
step   2860 | loss 1.8747 | lr 3.00e-04 | grad 1.47 | tok/s 20286
step   2870 | loss 1.5137 | lr 3.00e-04 | grad 1.21 | tok/s 20200
step   2880 | loss 1.6207 | lr 3.00e-04 | grad 1.28 | tok/s 20464
step   2890 | loss 1.6642 | lr 3.00e-04 | grad 1.21 | tok/s 21141
step   2900 | loss 1.6318 | lr 3.00e-04 | grad 1.20 | tok/s 20383
step   2910 | loss 1.6573 | lr 3.00e-04 | grad 1.40 | tok/s 20833
step   2920 | loss 1.5690 | lr 3.00e-04 | grad 1.09 | tok/s 19551
step   2930 | loss 1.8305 | lr 3.00e-04 | grad 1.23 | tok/s 20572
step   2940 | loss 1.4290 | lr 3.00e-04 | grad 1.85 | tok/s 19647
step   2950 | loss 1.5166 | lr 3.00e-04 | grad 1.38 | tok/s 19951
step   2960 | loss 1.5256 | lr 3.00e-04 | grad 1.34 | tok/s 20969
step   2970 | loss 1.4779 | lr 3.00e-04 | grad 1.03 | tok/s 20603
step   2980 | loss 1.8666 | lr 3.00e-04 | grad 1.29 | tok/s 20369
step   2990 | loss 2.1544 | lr 3.00e-04 | grad 1.50 | tok/s 20706
step   3000 | loss 1.5427 | lr 3.00e-04 | grad 1.34 | tok/s 21011
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5427.pt
step   3010 | loss 1.5453 | lr 3.00e-04 | grad 2.16 | tok/s 8683
step   3020 | loss 1.3492 | lr 3.00e-04 | grad 1.43 | tok/s 20194

Training complete! Final step: 3020
