Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_87/levelllama_100m_20260126_185604
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 484,967,168 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 6.5829 | lr 3.00e-04 | grad 5.44 | tok/s 6307
step     20 | loss 2.8580 | lr 3.00e-04 | grad 4.00 | tok/s 17045
step     30 | loss 2.8294 | lr 3.00e-04 | grad 3.27 | tok/s 17223
step     40 | loss 2.9156 | lr 3.00e-04 | grad 2.22 | tok/s 16441
step     50 | loss 3.2269 | lr 3.00e-04 | grad 2.94 | tok/s 16682
step     60 | loss 2.6713 | lr 3.00e-04 | grad 1.77 | tok/s 17166
step     70 | loss 2.5712 | lr 3.00e-04 | grad 2.33 | tok/s 17332
step     80 | loss 6.6029 | lr 3.00e-04 | grad 11.75 | tok/s 17445
step     90 | loss 4.6105 | lr 3.00e-04 | grad 3.00 | tok/s 17719
step    100 | loss 3.8010 | lr 3.00e-04 | grad 3.19 | tok/s 17730
step    110 | loss 3.6320 | lr 3.00e-04 | grad 7.94 | tok/s 17730
step    120 | loss 3.4129 | lr 3.00e-04 | grad 8.69 | tok/s 17667
step    130 | loss 3.2785 | lr 3.00e-04 | grad 4.28 | tok/s 17638
step    140 | loss 2.7677 | lr 3.00e-04 | grad 2.78 | tok/s 17591
step    150 | loss 3.0836 | lr 3.00e-04 | grad 6.53 | tok/s 17561
step    160 | loss 2.4690 | lr 3.00e-04 | grad 3.16 | tok/s 17516
step    170 | loss 2.6034 | lr 3.00e-04 | grad 7.62 | tok/s 17499
step    180 | loss 2.3888 | lr 3.00e-04 | grad 5.69 | tok/s 17501
step    190 | loss 2.5564 | lr 3.00e-04 | grad 2.28 | tok/s 17457
step    200 | loss 2.2883 | lr 3.00e-04 | grad 3.06 | tok/s 17452
step    210 | loss 2.3056 | lr 3.00e-04 | grad 4.59 | tok/s 17429
step    220 | loss 2.6015 | lr 3.00e-04 | grad 3.64 | tok/s 17232
step    230 | loss 3.2762 | lr 3.00e-04 | grad 3.89 | tok/s 17017
step    240 | loss 2.6700 | lr 3.00e-04 | grad 3.83 | tok/s 16160
step    250 | loss 2.5108 | lr 3.00e-04 | grad 3.00 | tok/s 16603
step    260 | loss 2.3076 | lr 3.00e-04 | grad 3.27 | tok/s 17122
step    270 | loss 2.5551 | lr 3.00e-04 | grad 2.16 | tok/s 16897
step    280 | loss 2.6824 | lr 3.00e-04 | grad 3.66 | tok/s 16597
step    290 | loss 2.5076 | lr 3.00e-04 | grad 1.70 | tok/s 17459
step    300 | loss 1.5313 | lr 3.00e-04 | grad 1.61 | tok/s 17433
step    310 | loss 2.8772 | lr 3.00e-04 | grad 2.52 | tok/s 17135
step    320 | loss 2.5518 | lr 3.00e-04 | grad 3.55 | tok/s 16741
step    330 | loss 2.3611 | lr 3.00e-04 | grad 1.55 | tok/s 16195
step    340 | loss 2.6250 | lr 3.00e-04 | grad 2.12 | tok/s 16443
step    350 | loss 2.4461 | lr 3.00e-04 | grad 2.64 | tok/s 16814
step    360 | loss 2.4557 | lr 3.00e-04 | grad 3.08 | tok/s 17178
step    370 | loss 2.2439 | lr 3.00e-04 | grad 2.17 | tok/s 15608
step    380 | loss 2.2252 | lr 3.00e-04 | grad 1.65 | tok/s 16603
step    390 | loss 2.0908 | lr 3.00e-04 | grad 1.83 | tok/s 17356
step    400 | loss 2.0734 | lr 3.00e-04 | grad 2.22 | tok/s 17198
step    410 | loss 1.9954 | lr 3.00e-04 | grad 1.37 | tok/s 16801
step    420 | loss 2.1839 | lr 3.00e-04 | grad 2.22 | tok/s 16022
step    430 | loss 2.4564 | lr 3.00e-04 | grad 3.16 | tok/s 17068
step    440 | loss 2.4954 | lr 3.00e-04 | grad 2.09 | tok/s 16116
step    450 | loss 2.3208 | lr 3.00e-04 | grad 1.70 | tok/s 16685
step    460 | loss 2.1875 | lr 3.00e-04 | grad 2.83 | tok/s 16318
step    470 | loss 2.2572 | lr 3.00e-04 | grad 2.45 | tok/s 16829
step    480 | loss 2.6434 | lr 3.00e-04 | grad 3.14 | tok/s 16854
step    490 | loss 2.1557 | lr 3.00e-04 | grad 2.25 | tok/s 15909
step    500 | loss 2.1404 | lr 3.00e-04 | grad 2.20 | tok/s 17001
step    510 | loss 2.1442 | lr 3.00e-04 | grad 1.66 | tok/s 17238
step    520 | loss 2.1214 | lr 3.00e-04 | grad 1.88 | tok/s 17199
step    530 | loss 2.2621 | lr 3.00e-04 | grad 1.86 | tok/s 16532
step    540 | loss 2.0586 | lr 3.00e-04 | grad 2.36 | tok/s 16538
step    550 | loss 1.9085 | lr 3.00e-04 | grad 1.98 | tok/s 16200
step    560 | loss 2.0764 | lr 3.00e-04 | grad 1.78 | tok/s 15761
step    570 | loss 2.0118 | lr 3.00e-04 | grad 2.75 | tok/s 16197
step    580 | loss 1.9066 | lr 3.00e-04 | grad 1.88 | tok/s 16132
step    590 | loss 2.2329 | lr 3.00e-04 | grad 1.54 | tok/s 16560
step    600 | loss 2.1140 | lr 3.00e-04 | grad 1.49 | tok/s 15993
step    610 | loss 1.9672 | lr 3.00e-04 | grad 2.02 | tok/s 16815
step    620 | loss 1.8426 | lr 3.00e-04 | grad 1.20 | tok/s 15929
step    630 | loss 1.9874 | lr 3.00e-04 | grad 2.58 | tok/s 16058
step    640 | loss 2.1538 | lr 3.00e-04 | grad 1.65 | tok/s 16486
step    650 | loss 1.9790 | lr 3.00e-04 | grad 1.90 | tok/s 16564
step    660 | loss 2.0094 | lr 3.00e-04 | grad 1.33 | tok/s 16630
step    670 | loss 2.2269 | lr 3.00e-04 | grad 2.22 | tok/s 16746
step    680 | loss 1.9906 | lr 3.00e-04 | grad 1.43 | tok/s 16381
step    690 | loss 2.2550 | lr 3.00e-04 | grad 1.84 | tok/s 16968
step    700 | loss 1.9799 | lr 3.00e-04 | grad 1.78 | tok/s 17295
step    710 | loss 1.8985 | lr 3.00e-04 | grad 2.05 | tok/s 16153
step    720 | loss 1.7404 | lr 3.00e-04 | grad 1.88 | tok/s 15921
step    730 | loss 1.7739 | lr 3.00e-04 | grad 2.16 | tok/s 17247
step    740 | loss 1.8622 | lr 3.00e-04 | grad 1.57 | tok/s 17031
step    750 | loss 1.6285 | lr 3.00e-04 | grad 1.59 | tok/s 17313
step    760 | loss 1.4943 | lr 3.00e-04 | grad 1.83 | tok/s 17292
step    770 | loss 1.4477 | lr 3.00e-04 | grad 1.43 | tok/s 17269
step    780 | loss 1.3960 | lr 3.00e-04 | grad 1.62 | tok/s 17316
step    790 | loss 1.4683 | lr 3.00e-04 | grad 2.03 | tok/s 16759
step    800 | loss 2.1834 | lr 3.00e-04 | grad 2.80 | tok/s 16705
step    810 | loss 1.9357 | lr 3.00e-04 | grad 1.56 | tok/s 16593
step    820 | loss 1.9442 | lr 3.00e-04 | grad 1.93 | tok/s 15955
step    830 | loss 1.9566 | lr 3.00e-04 | grad 1.59 | tok/s 17145
step    840 | loss 1.8580 | lr 3.00e-04 | grad 1.59 | tok/s 17307
step    850 | loss 1.8932 | lr 3.00e-04 | grad 1.94 | tok/s 17223
step    860 | loss 1.8501 | lr 3.00e-04 | grad 2.44 | tok/s 17027
step    870 | loss 1.7918 | lr 3.00e-04 | grad 1.65 | tok/s 16435
step    880 | loss 1.9480 | lr 3.00e-04 | grad 1.45 | tok/s 16487
step    890 | loss 1.9234 | lr 3.00e-04 | grad 2.02 | tok/s 16729
step    900 | loss 1.7988 | lr 3.00e-04 | grad 1.46 | tok/s 16712
step    910 | loss 1.6535 | lr 3.00e-04 | grad 1.80 | tok/s 16349
step    920 | loss 1.8243 | lr 3.00e-04 | grad 2.48 | tok/s 17031
step    930 | loss 1.8417 | lr 3.00e-04 | grad 2.19 | tok/s 16271
step    940 | loss 1.7379 | lr 3.00e-04 | grad 1.37 | tok/s 17133
step    950 | loss 1.7891 | lr 3.00e-04 | grad 1.76 | tok/s 17212
step    960 | loss 1.6461 | lr 3.00e-04 | grad 1.68 | tok/s 17247
step    970 | loss 1.9140 | lr 3.00e-04 | grad 1.91 | tok/s 16188
step    980 | loss 1.8406 | lr 3.00e-04 | grad 1.26 | tok/s 16651
step    990 | loss 1.7332 | lr 3.00e-04 | grad 1.48 | tok/s 16917
step   1000 | loss 2.0871 | lr 3.00e-04 | grad 5.62 | tok/s 16259
  >>> saved checkpoint: checkpoint_step_001000_loss_2.0871.pt
step   1010 | loss 1.9653 | lr 3.00e-04 | grad 1.55 | tok/s 6256
step   1020 | loss 1.8454 | lr 3.00e-04 | grad 1.62 | tok/s 16022
step   1030 | loss 1.6421 | lr 3.00e-04 | grad 1.15 | tok/s 16695
step   1040 | loss 1.7240 | lr 3.00e-04 | grad 2.08 | tok/s 17008
step   1050 | loss 1.7830 | lr 3.00e-04 | grad 1.35 | tok/s 16003
step   1060 | loss 1.9539 | lr 3.00e-04 | grad 1.55 | tok/s 17104
step   1070 | loss 1.9756 | lr 3.00e-04 | grad 1.91 | tok/s 16837
step   1080 | loss 1.5988 | lr 3.00e-04 | grad 1.38 | tok/s 15541
step   1090 | loss 1.2197 | lr 3.00e-04 | grad 0.80 | tok/s 17249
step   1100 | loss 1.7403 | lr 3.00e-04 | grad 1.63 | tok/s 16522
step   1110 | loss 1.6432 | lr 3.00e-04 | grad 1.34 | tok/s 17350
step   1120 | loss 1.5720 | lr 3.00e-04 | grad 1.53 | tok/s 17359
step   1130 | loss 1.5088 | lr 3.00e-04 | grad 1.54 | tok/s 17349
step   1140 | loss 1.4976 | lr 3.00e-04 | grad 1.30 | tok/s 17327
step   1150 | loss 1.5035 | lr 3.00e-04 | grad 1.43 | tok/s 17328
step   1160 | loss 1.4072 | lr 3.00e-04 | grad 1.45 | tok/s 17324
step   1170 | loss 1.4418 | lr 3.00e-04 | grad 1.42 | tok/s 17334
step   1180 | loss 1.5288 | lr 3.00e-04 | grad 1.28 | tok/s 17321
step   1190 | loss 1.4237 | lr 3.00e-04 | grad 1.52 | tok/s 17326
step   1200 | loss 1.4312 | lr 3.00e-04 | grad 1.35 | tok/s 17319
step   1210 | loss 1.4453 | lr 3.00e-04 | grad 1.35 | tok/s 17319
step   1220 | loss 1.4550 | lr 3.00e-04 | grad 1.15 | tok/s 17332
step   1230 | loss 1.4454 | lr 3.00e-04 | grad 1.25 | tok/s 17331
step   1240 | loss 1.4267 | lr 3.00e-04 | grad 1.64 | tok/s 17175
step   1250 | loss 2.0779 | lr 3.00e-04 | grad 1.54 | tok/s 16426
step   1260 | loss 1.4702 | lr 3.00e-04 | grad 1.71 | tok/s 16206
step   1270 | loss 1.9070 | lr 3.00e-04 | grad 1.48 | tok/s 16159
step   1280 | loss 1.7722 | lr 3.00e-04 | grad 1.57 | tok/s 16904
step   1290 | loss 1.6586 | lr 3.00e-04 | grad 1.82 | tok/s 16565
step   1300 | loss 1.6974 | lr 3.00e-04 | grad 1.45 | tok/s 16442
step   1310 | loss 1.6728 | lr 3.00e-04 | grad 1.34 | tok/s 17217
step   1320 | loss 1.7511 | lr 3.00e-04 | grad 1.45 | tok/s 17010
step   1330 | loss 1.6869 | lr 3.00e-04 | grad 1.56 | tok/s 17038
step   1340 | loss 1.7588 | lr 3.00e-04 | grad 2.02 | tok/s 16069
step   1350 | loss 1.8398 | lr 3.00e-04 | grad 1.49 | tok/s 15907
step   1360 | loss 1.7094 | lr 3.00e-04 | grad 1.20 | tok/s 16705
step   1370 | loss 1.6527 | lr 3.00e-04 | grad 4.72 | tok/s 16495
step   1380 | loss 1.7880 | lr 3.00e-04 | grad 2.08 | tok/s 15859
step   1390 | loss 1.6534 | lr 3.00e-04 | grad 2.30 | tok/s 16724
step   1400 | loss 1.5501 | lr 3.00e-04 | grad 1.18 | tok/s 16321
step   1410 | loss 1.7281 | lr 3.00e-04 | grad 5.84 | tok/s 16284
step   1420 | loss 1.8074 | lr 3.00e-04 | grad 1.42 | tok/s 16264
step   1430 | loss 1.5505 | lr 3.00e-04 | grad 1.65 | tok/s 16483
step   1440 | loss 1.3295 | lr 3.00e-04 | grad 1.70 | tok/s 17322
step   1450 | loss 1.3234 | lr 3.00e-04 | grad 1.88 | tok/s 17049
step   1460 | loss 1.8235 | lr 3.00e-04 | grad 1.24 | tok/s 16156
step   1470 | loss 1.7152 | lr 3.00e-04 | grad 1.49 | tok/s 17169
step   1480 | loss 2.1961 | lr 3.00e-04 | grad 2.05 | tok/s 16978
step   1490 | loss 1.8833 | lr 3.00e-04 | grad 1.73 | tok/s 17218
step   1500 | loss 1.5310 | lr 3.00e-04 | grad 1.60 | tok/s 17266
step   1510 | loss 1.7024 | lr 3.00e-04 | grad 1.93 | tok/s 17068
step   1520 | loss 1.5836 | lr 3.00e-04 | grad 1.70 | tok/s 16737
step   1530 | loss 1.5592 | lr 3.00e-04 | grad 1.81 | tok/s 17106
step   1540 | loss 1.7660 | lr 3.00e-04 | grad 1.69 | tok/s 16109
step   1550 | loss 1.4705 | lr 3.00e-04 | grad 1.77 | tok/s 17146
step   1560 | loss 1.7158 | lr 3.00e-04 | grad 1.15 | tok/s 16282
step   1570 | loss 1.5057 | lr 3.00e-04 | grad 1.37 | tok/s 17103
step   1580 | loss 2.0922 | lr 3.00e-04 | grad 5.16 | tok/s 17029
step   1590 | loss 1.8199 | lr 3.00e-04 | grad 1.58 | tok/s 16221
step   1600 | loss 1.0978 | lr 3.00e-04 | grad 1.50 | tok/s 17369
step   1610 | loss 1.2226 | lr 3.00e-04 | grad 1.28 | tok/s 16395
step   1620 | loss 1.6113 | lr 3.00e-04 | grad 1.76 | tok/s 16072
step   1630 | loss 1.5910 | lr 3.00e-04 | grad 1.34 | tok/s 16804
step   1640 | loss 1.5027 | lr 3.00e-04 | grad 1.49 | tok/s 16327
step   1650 | loss 1.6640 | lr 3.00e-04 | grad 1.41 | tok/s 15425
step   1660 | loss 1.5559 | lr 3.00e-04 | grad 1.35 | tok/s 17275
step   1670 | loss 1.6279 | lr 3.00e-04 | grad 2.69 | tok/s 16657
step   1680 | loss 1.8060 | lr 3.00e-04 | grad 1.13 | tok/s 15907
step   1690 | loss 1.6408 | lr 3.00e-04 | grad 1.93 | tok/s 16707
step   1700 | loss 1.6469 | lr 3.00e-04 | grad 1.34 | tok/s 16543
step   1710 | loss 1.6442 | lr 3.00e-04 | grad 1.46 | tok/s 16508
step   1720 | loss 1.7331 | lr 3.00e-04 | grad 1.52 | tok/s 17227
step   1730 | loss 1.5716 | lr 3.00e-04 | grad 2.28 | tok/s 17266
step   1740 | loss 1.6267 | lr 3.00e-04 | grad 1.43 | tok/s 16694
step   1750 | loss 1.6697 | lr 3.00e-04 | grad 2.02 | tok/s 16671
step   1760 | loss 1.6835 | lr 3.00e-04 | grad 1.36 | tok/s 16631
step   1770 | loss 1.5676 | lr 3.00e-04 | grad 1.37 | tok/s 16336
step   1780 | loss 1.6006 | lr 3.00e-04 | grad 1.21 | tok/s 16828
step   1790 | loss 1.5644 | lr 3.00e-04 | grad 1.95 | tok/s 16650
step   1800 | loss 1.6863 | lr 3.00e-04 | grad 1.21 | tok/s 16351
step   1810 | loss 1.5927 | lr 3.00e-04 | grad 2.23 | tok/s 16076
step   1820 | loss 1.6604 | lr 3.00e-04 | grad 3.64 | tok/s 16574
step   1830 | loss 1.5619 | lr 3.00e-04 | grad 2.20 | tok/s 16929
step   1840 | loss 1.5937 | lr 3.00e-04 | grad 1.31 | tok/s 16094
step   1850 | loss 1.5152 | lr 3.00e-04 | grad 1.41 | tok/s 17171
step   1860 | loss 1.4890 | lr 3.00e-04 | grad 1.59 | tok/s 16271
step   1870 | loss 1.5154 | lr 3.00e-04 | grad 1.24 | tok/s 16683
step   1880 | loss 1.4107 | lr 3.00e-04 | grad 1.60 | tok/s 16020
step   1890 | loss 1.6694 | lr 3.00e-04 | grad 1.30 | tok/s 15506
step   1900 | loss 1.5083 | lr 3.00e-04 | grad 1.49 | tok/s 16625
step   1910 | loss 1.5699 | lr 3.00e-04 | grad 1.20 | tok/s 15752
step   1920 | loss 1.5300 | lr 3.00e-04 | grad 1.21 | tok/s 17279
step   1930 | loss 1.5629 | lr 3.00e-04 | grad 1.69 | tok/s 15900
step   1940 | loss 1.5694 | lr 3.00e-04 | grad 1.55 | tok/s 17146
step   1950 | loss 2.1868 | lr 3.00e-04 | grad 2.16 | tok/s 17114
step   1960 | loss 1.8588 | lr 3.00e-04 | grad 2.17 | tok/s 17263
step   1970 | loss 1.7129 | lr 3.00e-04 | grad 1.39 | tok/s 16843
step   1980 | loss 1.6774 | lr 3.00e-04 | grad 1.45 | tok/s 16101
step   1990 | loss 1.7213 | lr 3.00e-04 | grad 1.75 | tok/s 16405
step   2000 | loss 1.6110 | lr 3.00e-04 | grad 1.61 | tok/s 16618
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6110.pt
step   2010 | loss 1.2697 | lr 3.00e-04 | grad 1.34 | tok/s 6405
step   2020 | loss 1.4435 | lr 3.00e-04 | grad 1.80 | tok/s 16992
step   2030 | loss 1.1328 | lr 3.00e-04 | grad 2.22 | tok/s 17513
step   2040 | loss 1.5982 | lr 3.00e-04 | grad 1.48 | tok/s 17428
step   2050 | loss 1.4400 | lr 3.00e-04 | grad 1.24 | tok/s 16784
step   2060 | loss 1.7461 | lr 3.00e-04 | grad 1.21 | tok/s 16344
step   2070 | loss 1.8997 | lr 3.00e-04 | grad 3.62 | tok/s 16486
step   2080 | loss 2.3282 | lr 3.00e-04 | grad 3.12 | tok/s 17414
step   2090 | loss 1.7554 | lr 3.00e-04 | grad 1.90 | tok/s 17025
step   2100 | loss 1.5691 | lr 3.00e-04 | grad 1.52 | tok/s 17060
step   2110 | loss 1.6573 | lr 3.00e-04 | grad 1.58 | tok/s 16173
step   2120 | loss 0.9876 | lr 3.00e-04 | grad 1.21 | tok/s 17508
step   2130 | loss 1.3814 | lr 3.00e-04 | grad 2.02 | tok/s 16717
step   2140 | loss 1.5473 | lr 3.00e-04 | grad 1.40 | tok/s 16855
step   2150 | loss 1.4057 | lr 3.00e-04 | grad 1.56 | tok/s 17341
step   2160 | loss 1.2894 | lr 3.00e-04 | grad 1.38 | tok/s 17355
step   2170 | loss 1.3602 | lr 3.00e-04 | grad 1.18 | tok/s 17356
step   2180 | loss 1.3039 | lr 3.00e-04 | grad 1.12 | tok/s 17348
step   2190 | loss 1.3225 | lr 3.00e-04 | grad 1.48 | tok/s 17330
step   2200 | loss 1.2949 | lr 3.00e-04 | grad 1.20 | tok/s 17331
step   2210 | loss 1.2543 | lr 3.00e-04 | grad 1.46 | tok/s 17334
step   2220 | loss 1.2433 | lr 3.00e-04 | grad 1.38 | tok/s 17332
step   2230 | loss 1.4986 | lr 3.00e-04 | grad 1.59 | tok/s 16997
step   2240 | loss 1.4522 | lr 3.00e-04 | grad 1.34 | tok/s 16716
step   2250 | loss 1.7770 | lr 3.00e-04 | grad 3.17 | tok/s 17331
step   2260 | loss 1.7261 | lr 3.00e-04 | grad 1.36 | tok/s 16741
step   2270 | loss 2.1071 | lr 3.00e-04 | grad 1.72 | tok/s 17144
step   2280 | loss 1.5516 | lr 3.00e-04 | grad 2.12 | tok/s 17309
step   2290 | loss 1.6521 | lr 3.00e-04 | grad 6.75 | tok/s 16698
step   2300 | loss 1.8735 | lr 3.00e-04 | grad 2.16 | tok/s 16967
step   2310 | loss 1.6026 | lr 3.00e-04 | grad 1.81 | tok/s 16324
step   2320 | loss 1.8848 | lr 3.00e-04 | grad 1.64 | tok/s 16268
step   2330 | loss 1.6570 | lr 3.00e-04 | grad 1.75 | tok/s 16373
step   2340 | loss 1.5547 | lr 3.00e-04 | grad 1.50 | tok/s 16141
step   2350 | loss 1.4946 | lr 3.00e-04 | grad 1.89 | tok/s 16905
step   2360 | loss 1.4325 | lr 3.00e-04 | grad 1.04 | tok/s 17329
step   2370 | loss 1.6855 | lr 3.00e-04 | grad 1.98 | tok/s 16955
step   2380 | loss 1.7236 | lr 3.00e-04 | grad 1.51 | tok/s 17336
step   2390 | loss 1.2974 | lr 3.00e-04 | grad 1.27 | tok/s 17264
step   2400 | loss 1.1945 | lr 3.00e-04 | grad 1.48 | tok/s 17286
step   2410 | loss 1.2650 | lr 3.00e-04 | grad 1.20 | tok/s 16596
step   2420 | loss 1.5647 | lr 3.00e-04 | grad 1.40 | tok/s 16001
step   2430 | loss 1.4712 | lr 3.00e-04 | grad 1.10 | tok/s 16894
step   2440 | loss 1.4455 | lr 3.00e-04 | grad 1.17 | tok/s 16715
step   2450 | loss 1.5840 | lr 3.00e-04 | grad 1.20 | tok/s 16675

Training complete! Final step: 2457
