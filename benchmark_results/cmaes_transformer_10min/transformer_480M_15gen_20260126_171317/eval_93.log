Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_93/levelllama_100m_20260126_190623
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 366,056,064 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.2971 | lr 3.00e-04 | grad 2.81 | tok/s 6232
step     20 | loss 2.8026 | lr 3.00e-04 | grad 2.03 | tok/s 16282
step     30 | loss 2.8194 | lr 3.00e-04 | grad 1.93 | tok/s 16451
step     40 | loss 2.8775 | lr 3.00e-04 | grad 1.51 | tok/s 15769
step     50 | loss 3.3602 | lr 3.00e-04 | grad 3.72 | tok/s 16052
step     60 | loss 2.5424 | lr 3.00e-04 | grad 8.19 | tok/s 16601
step     70 | loss 2.4834 | lr 3.00e-04 | grad 1.90 | tok/s 16783
step     80 | loss 5.8896 | lr 3.00e-04 | grad 6.84 | tok/s 16897
step     90 | loss 4.5854 | lr 3.00e-04 | grad 2.02 | tok/s 17235
step    100 | loss 4.0087 | lr 3.00e-04 | grad 2.45 | tok/s 17219
step    110 | loss 3.7902 | lr 3.00e-04 | grad 5.88 | tok/s 17254
step    120 | loss 3.7126 | lr 3.00e-04 | grad 7.03 | tok/s 17228
step    130 | loss 3.6673 | lr 3.00e-04 | grad 3.47 | tok/s 17239
step    140 | loss 3.2225 | lr 3.00e-04 | grad 3.00 | tok/s 17205
step    150 | loss 3.6111 | lr 3.00e-04 | grad 5.22 | tok/s 17214
step    160 | loss 3.0524 | lr 3.00e-04 | grad 4.50 | tok/s 17190
step    170 | loss 3.0704 | lr 3.00e-04 | grad 3.67 | tok/s 17176
step    180 | loss 2.8991 | lr 3.00e-04 | grad 3.61 | tok/s 17186
step    190 | loss 2.9912 | lr 3.00e-04 | grad 4.56 | tok/s 17161
step    200 | loss 2.6284 | lr 3.00e-04 | grad 2.05 | tok/s 17167
step    210 | loss 2.6233 | lr 3.00e-04 | grad 3.03 | tok/s 17144
step    220 | loss 2.7336 | lr 3.00e-04 | grad 2.20 | tok/s 16935
step    230 | loss 3.4808 | lr 3.00e-04 | grad 1.70 | tok/s 16722
step    240 | loss 2.6375 | lr 3.00e-04 | grad 2.59 | tok/s 15888
step    250 | loss 2.4800 | lr 3.00e-04 | grad 1.27 | tok/s 16328
step    260 | loss 2.2795 | lr 3.00e-04 | grad 1.45 | tok/s 16845
step    270 | loss 2.5265 | lr 3.00e-04 | grad 1.57 | tok/s 16611
step    280 | loss 2.6660 | lr 3.00e-04 | grad 2.53 | tok/s 16294
step    290 | loss 2.7357 | lr 3.00e-04 | grad 1.24 | tok/s 17139
step    300 | loss 1.7739 | lr 3.00e-04 | grad 1.64 | tok/s 17144
step    310 | loss 2.9307 | lr 3.00e-04 | grad 1.46 | tok/s 16847
step    320 | loss 2.5868 | lr 3.00e-04 | grad 2.70 | tok/s 16500
step    330 | loss 2.3759 | lr 3.00e-04 | grad 1.23 | tok/s 15924
step    340 | loss 2.6413 | lr 3.00e-04 | grad 1.18 | tok/s 16165
step    350 | loss 2.4655 | lr 3.00e-04 | grad 1.64 | tok/s 16530
step    360 | loss 2.6719 | lr 3.00e-04 | grad 2.23 | tok/s 16934
step    370 | loss 2.2914 | lr 3.00e-04 | grad 1.45 | tok/s 15343
step    380 | loss 2.2254 | lr 3.00e-04 | grad 1.41 | tok/s 16341
step    390 | loss 2.1223 | lr 3.00e-04 | grad 1.82 | tok/s 17067
step    400 | loss 2.1020 | lr 3.00e-04 | grad 1.62 | tok/s 16961
step    410 | loss 2.0421 | lr 3.00e-04 | grad 1.01 | tok/s 16570
step    420 | loss 2.2019 | lr 3.00e-04 | grad 1.89 | tok/s 15816
step    430 | loss 2.4965 | lr 3.00e-04 | grad 1.81 | tok/s 16799
step    440 | loss 2.5128 | lr 3.00e-04 | grad 1.43 | tok/s 15891
step    450 | loss 2.3754 | lr 3.00e-04 | grad 1.10 | tok/s 16453
step    460 | loss 2.2316 | lr 3.00e-04 | grad 2.06 | tok/s 16121
step    470 | loss 2.2936 | lr 3.00e-04 | grad 1.23 | tok/s 16619
step    480 | loss 2.7266 | lr 3.00e-04 | grad 2.53 | tok/s 16612
step    490 | loss 2.1857 | lr 3.00e-04 | grad 1.95 | tok/s 15663
step    500 | loss 2.1641 | lr 3.00e-04 | grad 1.73 | tok/s 16743
step    510 | loss 2.1802 | lr 3.00e-04 | grad 1.05 | tok/s 16963
step    520 | loss 2.1700 | lr 3.00e-04 | grad 1.24 | tok/s 16943
step    530 | loss 2.3136 | lr 3.00e-04 | grad 1.13 | tok/s 16287
step    540 | loss 2.0754 | lr 3.00e-04 | grad 1.09 | tok/s 16291
step    550 | loss 1.9442 | lr 3.00e-04 | grad 1.13 | tok/s 15967
step    560 | loss 2.1158 | lr 3.00e-04 | grad 1.41 | tok/s 15544
step    570 | loss 2.0551 | lr 3.00e-04 | grad 1.79 | tok/s 15968
step    580 | loss 1.9360 | lr 3.00e-04 | grad 1.04 | tok/s 15912
step    590 | loss 2.2902 | lr 3.00e-04 | grad 1.28 | tok/s 16306
step    600 | loss 2.1835 | lr 3.00e-04 | grad 0.99 | tok/s 15751
step    610 | loss 2.0135 | lr 3.00e-04 | grad 1.15 | tok/s 16551
step    620 | loss 1.8735 | lr 3.00e-04 | grad 0.92 | tok/s 15685
step    630 | loss 2.0332 | lr 3.00e-04 | grad 1.77 | tok/s 15816
step    640 | loss 2.1906 | lr 3.00e-04 | grad 1.34 | tok/s 16244
step    650 | loss 2.0496 | lr 3.00e-04 | grad 1.63 | tok/s 16336
step    660 | loss 2.0533 | lr 3.00e-04 | grad 0.89 | tok/s 16395
step    670 | loss 2.2751 | lr 3.00e-04 | grad 2.33 | tok/s 16506
step    680 | loss 2.0361 | lr 3.00e-04 | grad 1.06 | tok/s 16173
step    690 | loss 2.3559 | lr 3.00e-04 | grad 1.57 | tok/s 16746
step    700 | loss 2.1648 | lr 3.00e-04 | grad 1.52 | tok/s 17066
step    710 | loss 1.9525 | lr 3.00e-04 | grad 1.53 | tok/s 15931
step    720 | loss 1.7983 | lr 3.00e-04 | grad 1.24 | tok/s 15709
step    730 | loss 1.9085 | lr 3.00e-04 | grad 1.56 | tok/s 17071
step    740 | loss 1.9372 | lr 3.00e-04 | grad 1.19 | tok/s 16833
step    750 | loss 1.7699 | lr 3.00e-04 | grad 1.22 | tok/s 17089
step    760 | loss 1.6262 | lr 3.00e-04 | grad 1.35 | tok/s 17089
step    770 | loss 1.5966 | lr 3.00e-04 | grad 1.00 | tok/s 17082
step    780 | loss 1.5412 | lr 3.00e-04 | grad 1.19 | tok/s 17079
step    790 | loss 1.5965 | lr 3.00e-04 | grad 1.59 | tok/s 16530
step    800 | loss 2.2818 | lr 3.00e-04 | grad 2.28 | tok/s 16485
step    810 | loss 1.9918 | lr 3.00e-04 | grad 1.31 | tok/s 16407
step    820 | loss 1.9873 | lr 3.00e-04 | grad 1.48 | tok/s 15753
step    830 | loss 2.0751 | lr 3.00e-04 | grad 1.12 | tok/s 16904
step    840 | loss 1.9929 | lr 3.00e-04 | grad 1.23 | tok/s 17102
step    850 | loss 2.0299 | lr 3.00e-04 | grad 1.32 | tok/s 17024
step    860 | loss 1.9419 | lr 3.00e-04 | grad 1.88 | tok/s 16832
step    870 | loss 1.8582 | lr 3.00e-04 | grad 1.30 | tok/s 16215
step    880 | loss 2.0198 | lr 3.00e-04 | grad 1.05 | tok/s 16269
step    890 | loss 1.9867 | lr 3.00e-04 | grad 1.52 | tok/s 16487
step    900 | loss 1.8662 | lr 3.00e-04 | grad 1.15 | tok/s 16508
step    910 | loss 1.7390 | lr 3.00e-04 | grad 1.55 | tok/s 16164
step    920 | loss 1.9465 | lr 3.00e-04 | grad 1.98 | tok/s 16812
step    930 | loss 1.8903 | lr 3.00e-04 | grad 1.88 | tok/s 16057
step    940 | loss 1.8718 | lr 3.00e-04 | grad 1.09 | tok/s 16926
step    950 | loss 1.9093 | lr 3.00e-04 | grad 1.30 | tok/s 17018
step    960 | loss 1.8133 | lr 3.00e-04 | grad 1.33 | tok/s 17028
step    970 | loss 1.9626 | lr 3.00e-04 | grad 1.39 | tok/s 16012
step    980 | loss 1.9050 | lr 3.00e-04 | grad 1.10 | tok/s 16458
step    990 | loss 1.8061 | lr 3.00e-04 | grad 1.31 | tok/s 16730
step   1000 | loss 2.1491 | lr 3.00e-04 | grad 5.03 | tok/s 16060
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1491.pt
step   1010 | loss 2.0257 | lr 3.00e-04 | grad 1.34 | tok/s 7429
step   1020 | loss 1.8804 | lr 3.00e-04 | grad 1.02 | tok/s 15671
step   1030 | loss 1.7498 | lr 3.00e-04 | grad 1.27 | tok/s 16322
step   1040 | loss 1.7453 | lr 3.00e-04 | grad 1.04 | tok/s 16848
step   1050 | loss 1.8381 | lr 3.00e-04 | grad 1.47 | tok/s 15585
step   1060 | loss 2.0196 | lr 3.00e-04 | grad 1.49 | tok/s 16847
step   1070 | loss 2.0910 | lr 3.00e-04 | grad 1.34 | tok/s 16768
step   1080 | loss 1.6603 | lr 3.00e-04 | grad 1.02 | tok/s 15263
step   1090 | loss 1.4213 | lr 3.00e-04 | grad 0.79 | tok/s 16815
step   1100 | loss 1.6861 | lr 3.00e-04 | grad 2.12 | tok/s 16335
step   1110 | loss 1.7579 | lr 3.00e-04 | grad 1.10 | tok/s 17136
step   1120 | loss 1.6602 | lr 3.00e-04 | grad 1.32 | tok/s 17115
step   1130 | loss 1.5975 | lr 3.00e-04 | grad 1.16 | tok/s 17115
step   1140 | loss 1.5693 | lr 3.00e-04 | grad 1.38 | tok/s 17109
step   1150 | loss 1.5850 | lr 3.00e-04 | grad 1.34 | tok/s 17118
step   1160 | loss 1.4938 | lr 3.00e-04 | grad 1.08 | tok/s 17116
step   1170 | loss 1.5135 | lr 3.00e-04 | grad 1.20 | tok/s 17106
step   1180 | loss 1.6375 | lr 3.00e-04 | grad 0.96 | tok/s 17117
step   1190 | loss 1.5173 | lr 3.00e-04 | grad 1.30 | tok/s 17133
step   1200 | loss 1.5039 | lr 3.00e-04 | grad 1.34 | tok/s 17162
step   1210 | loss 1.5379 | lr 3.00e-04 | grad 1.37 | tok/s 17134
step   1220 | loss 1.5290 | lr 3.00e-04 | grad 1.38 | tok/s 17147
step   1230 | loss 1.5125 | lr 3.00e-04 | grad 1.10 | tok/s 17159
step   1240 | loss 1.4630 | lr 3.00e-04 | grad 1.10 | tok/s 17139
step   1250 | loss 2.0858 | lr 3.00e-04 | grad 1.55 | tok/s 16240
step   1260 | loss 1.6038 | lr 3.00e-04 | grad 1.97 | tok/s 16062
step   1270 | loss 1.8755 | lr 3.00e-04 | grad 2.77 | tok/s 16034
step   1280 | loss 1.8945 | lr 3.00e-04 | grad 1.21 | tok/s 16515
step   1290 | loss 1.7266 | lr 3.00e-04 | grad 1.53 | tok/s 16399
step   1300 | loss 1.7834 | lr 3.00e-04 | grad 1.26 | tok/s 16513
step   1310 | loss 1.7377 | lr 3.00e-04 | grad 1.35 | tok/s 16800
step   1320 | loss 1.8356 | lr 3.00e-04 | grad 1.20 | tok/s 16868
step   1330 | loss 1.8592 | lr 3.00e-04 | grad 1.34 | tok/s 16908
step   1340 | loss 1.7213 | lr 3.00e-04 | grad 4.28 | tok/s 16116
step   1350 | loss 1.9164 | lr 3.00e-04 | grad 1.43 | tok/s 15560
step   1360 | loss 1.8091 | lr 3.00e-04 | grad 1.31 | tok/s 16533
step   1370 | loss 1.6260 | lr 3.00e-04 | grad 0.95 | tok/s 16338
step   1380 | loss 1.9417 | lr 3.00e-04 | grad 1.13 | tok/s 15706
step   1390 | loss 1.7600 | lr 3.00e-04 | grad 1.10 | tok/s 16675
step   1400 | loss 1.6673 | lr 3.00e-04 | grad 1.06 | tok/s 16068
step   1410 | loss 1.6908 | lr 3.00e-04 | grad 1.65 | tok/s 16130
step   1420 | loss 1.9757 | lr 3.00e-04 | grad 3.14 | tok/s 16170
step   1430 | loss 1.6636 | lr 3.00e-04 | grad 1.09 | tok/s 16453
step   1440 | loss 1.4456 | lr 3.00e-04 | grad 1.22 | tok/s 16996
step   1450 | loss 1.4221 | lr 3.00e-04 | grad 2.58 | tok/s 17117
step   1460 | loss 1.8953 | lr 3.00e-04 | grad 1.09 | tok/s 16142
step   1470 | loss 1.8040 | lr 3.00e-04 | grad 1.13 | tok/s 16732
step   1480 | loss 2.2921 | lr 3.00e-04 | grad 2.08 | tok/s 16850
step   1490 | loss 2.0945 | lr 3.00e-04 | grad 1.39 | tok/s 17099
step   1500 | loss 1.6824 | lr 3.00e-04 | grad 1.23 | tok/s 17167
step   1510 | loss 1.7537 | lr 3.00e-04 | grad 1.25 | tok/s 16933
step   1520 | loss 1.6572 | lr 3.00e-04 | grad 2.31 | tok/s 16592
step   1530 | loss 1.6324 | lr 3.00e-04 | grad 1.02 | tok/s 16987
step   1540 | loss 1.8185 | lr 3.00e-04 | grad 1.20 | tok/s 15976
step   1550 | loss 1.5873 | lr 3.00e-04 | grad 1.55 | tok/s 17042
step   1560 | loss 1.7651 | lr 3.00e-04 | grad 1.62 | tok/s 16152
step   1570 | loss 1.6228 | lr 3.00e-04 | grad 1.18 | tok/s 17175
step   1580 | loss 2.1100 | lr 3.00e-04 | grad 1.65 | tok/s 16770
step   1590 | loss 2.0093 | lr 3.00e-04 | grad 1.41 | tok/s 16111
step   1600 | loss 1.2794 | lr 3.00e-04 | grad 0.91 | tok/s 17199
step   1610 | loss 1.2175 | lr 3.00e-04 | grad 1.57 | tok/s 16623
step   1620 | loss 1.6677 | lr 3.00e-04 | grad 1.67 | tok/s 15596
step   1630 | loss 1.7167 | lr 3.00e-04 | grad 1.30 | tok/s 16694
step   1640 | loss 1.5543 | lr 3.00e-04 | grad 1.36 | tok/s 16303
step   1650 | loss 1.7040 | lr 3.00e-04 | grad 1.27 | tok/s 15621
step   1660 | loss 1.7018 | lr 3.00e-04 | grad 1.21 | tok/s 16685
step   1670 | loss 1.7125 | lr 3.00e-04 | grad 2.45 | tok/s 16632
step   1680 | loss 1.9071 | lr 3.00e-04 | grad 1.22 | tok/s 15954
step   1690 | loss 1.7190 | lr 3.00e-04 | grad 3.02 | tok/s 16254
step   1700 | loss 1.7488 | lr 3.00e-04 | grad 1.39 | tok/s 16612
step   1710 | loss 1.7291 | lr 3.00e-04 | grad 1.15 | tok/s 16296
step   1720 | loss 1.8148 | lr 3.00e-04 | grad 1.51 | tok/s 17000
step   1730 | loss 1.7690 | lr 3.00e-04 | grad 1.34 | tok/s 17177
step   1740 | loss 1.7261 | lr 3.00e-04 | grad 1.50 | tok/s 16733
step   1750 | loss 1.7785 | lr 3.00e-04 | grad 1.55 | tok/s 16443
step   1760 | loss 1.7190 | lr 3.00e-04 | grad 1.22 | tok/s 16507
step   1770 | loss 1.6302 | lr 3.00e-04 | grad 1.22 | tok/s 16206
step   1780 | loss 1.6792 | lr 3.00e-04 | grad 1.16 | tok/s 16840
step   1790 | loss 1.6151 | lr 3.00e-04 | grad 1.07 | tok/s 16422
step   1800 | loss 1.7893 | lr 3.00e-04 | grad 1.36 | tok/s 16556
step   1810 | loss 1.6441 | lr 3.00e-04 | grad 1.20 | tok/s 15943
step   1820 | loss 1.7411 | lr 3.00e-04 | grad 2.62 | tok/s 16150
step   1830 | loss 1.6388 | lr 3.00e-04 | grad 1.38 | tok/s 16849
step   1840 | loss 1.7052 | lr 3.00e-04 | grad 1.47 | tok/s 16120
step   1850 | loss 1.6293 | lr 3.00e-04 | grad 1.18 | tok/s 16844
step   1860 | loss 1.5275 | lr 3.00e-04 | grad 1.23 | tok/s 16317
step   1870 | loss 1.6303 | lr 3.00e-04 | grad 1.80 | tok/s 16380
step   1880 | loss 1.4839 | lr 3.00e-04 | grad 1.18 | tok/s 16061
step   1890 | loss 1.7371 | lr 3.00e-04 | grad 1.13 | tok/s 15267
step   1900 | loss 1.5618 | lr 3.00e-04 | grad 1.36 | tok/s 16519
step   1910 | loss 1.6232 | lr 3.00e-04 | grad 1.23 | tok/s 15649
step   1920 | loss 1.6120 | lr 3.00e-04 | grad 1.20 | tok/s 17151
step   1930 | loss 1.6229 | lr 3.00e-04 | grad 1.54 | tok/s 16084
step   1940 | loss 1.6107 | lr 3.00e-04 | grad 1.24 | tok/s 16732
step   1950 | loss 2.2916 | lr 3.00e-04 | grad 1.82 | tok/s 16982
step   1960 | loss 2.0402 | lr 3.00e-04 | grad 1.88 | tok/s 17161
step   1970 | loss 1.8319 | lr 3.00e-04 | grad 1.59 | tok/s 16730
step   1980 | loss 1.7709 | lr 3.00e-04 | grad 1.24 | tok/s 16002
step   1990 | loss 1.7883 | lr 3.00e-04 | grad 3.36 | tok/s 16321
step   2000 | loss 1.6614 | lr 3.00e-04 | grad 1.29 | tok/s 16534
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6614.pt
step   2010 | loss 1.2243 | lr 3.00e-04 | grad 1.05 | tok/s 8137
step   2020 | loss 1.4992 | lr 3.00e-04 | grad 1.28 | tok/s 16597
step   2030 | loss 1.4589 | lr 3.00e-04 | grad 0.80 | tok/s 17007
step   2040 | loss 1.4647 | lr 3.00e-04 | grad 1.12 | tok/s 17199
step   2050 | loss 1.6250 | lr 3.00e-04 | grad 1.10 | tok/s 17061
step   2060 | loss 1.7196 | lr 3.00e-04 | grad 1.47 | tok/s 15676
step   2070 | loss 1.8338 | lr 3.00e-04 | grad 1.48 | tok/s 16609
step   2080 | loss 2.3535 | lr 3.00e-04 | grad 1.99 | tok/s 16921
step   2090 | loss 2.0122 | lr 3.00e-04 | grad 1.86 | tok/s 17168
step   2100 | loss 1.6469 | lr 3.00e-04 | grad 1.13 | tok/s 16577
step   2110 | loss 1.7883 | lr 3.00e-04 | grad 1.39 | tok/s 16340
step   2120 | loss 1.3282 | lr 3.00e-04 | grad 1.99 | tok/s 16894
step   2130 | loss 1.1579 | lr 3.00e-04 | grad 3.50 | tok/s 16905
step   2140 | loss 1.7537 | lr 3.00e-04 | grad 1.38 | tok/s 16359
step   2150 | loss 1.4656 | lr 3.00e-04 | grad 1.22 | tok/s 17178
step   2160 | loss 1.3833 | lr 3.00e-04 | grad 1.05 | tok/s 17189
step   2170 | loss 1.4155 | lr 3.00e-04 | grad 1.47 | tok/s 17191
step   2180 | loss 1.3694 | lr 3.00e-04 | grad 1.16 | tok/s 17181
step   2190 | loss 1.3878 | lr 3.00e-04 | grad 0.99 | tok/s 17182
step   2200 | loss 1.3758 | lr 3.00e-04 | grad 1.43 | tok/s 17183
step   2210 | loss 1.3140 | lr 3.00e-04 | grad 1.08 | tok/s 17178
step   2220 | loss 1.3179 | lr 3.00e-04 | grad 1.25 | tok/s 17176
step   2230 | loss 1.4763 | lr 3.00e-04 | grad 1.33 | tok/s 16874
step   2240 | loss 1.5771 | lr 3.00e-04 | grad 1.14 | tok/s 17144
step   2250 | loss 1.8079 | lr 3.00e-04 | grad 2.16 | tok/s 16565
step   2260 | loss 1.8965 | lr 3.00e-04 | grad 1.59 | tok/s 16790
step   2270 | loss 2.0676 | lr 3.00e-04 | grad 2.41 | tok/s 16974
step   2280 | loss 1.7947 | lr 3.00e-04 | grad 1.29 | tok/s 16976
step   2290 | loss 1.5508 | lr 3.00e-04 | grad 2.11 | tok/s 16840
step   2300 | loss 2.2502 | lr 3.00e-04 | grad 2.44 | tok/s 16655
step   2310 | loss 1.7304 | lr 3.00e-04 | grad 1.50 | tok/s 16064
step   2320 | loss 1.7139 | lr 3.00e-04 | grad 1.68 | tok/s 16415
step   2330 | loss 2.0048 | lr 3.00e-04 | grad 1.73 | tok/s 16112
step   2340 | loss 1.5868 | lr 3.00e-04 | grad 2.38 | tok/s 15967
step   2350 | loss 1.5108 | lr 3.00e-04 | grad 0.95 | tok/s 16805
step   2360 | loss 1.6127 | lr 3.00e-04 | grad 1.21 | tok/s 16943
step   2370 | loss 1.6527 | lr 3.00e-04 | grad 1.70 | tok/s 16786
step   2380 | loss 1.9169 | lr 3.00e-04 | grad 1.30 | tok/s 17162
step   2390 | loss 1.5511 | lr 3.00e-04 | grad 1.17 | tok/s 17151
step   2400 | loss 1.3720 | lr 3.00e-04 | grad 1.34 | tok/s 17168
step   2410 | loss 1.2480 | lr 3.00e-04 | grad 1.49 | tok/s 16911
step   2420 | loss 1.5678 | lr 3.00e-04 | grad 1.83 | tok/s 15914
step   2430 | loss 1.6527 | lr 3.00e-04 | grad 1.27 | tok/s 16188
step   2440 | loss 1.3968 | lr 3.00e-04 | grad 1.34 | tok/s 16805

Training complete! Final step: 2445
