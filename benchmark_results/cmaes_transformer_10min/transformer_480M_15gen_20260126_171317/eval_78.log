Using device: cuda
Output directory: benchmark_results/cmaes_transformer_10min/transformer_480M_15gen_20260126_171317/eval_78/levelllama_100m_20260126_184546
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level llama, 390,807,296 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.9819 | lr 3.00e-04 | grad 2.61 | tok/s 7014
step     20 | loss 2.7189 | lr 3.00e-04 | grad 3.22 | tok/s 23749
step     30 | loss 2.7713 | lr 3.00e-04 | grad 2.02 | tok/s 24000
step     40 | loss 2.9274 | lr 3.00e-04 | grad 1.91 | tok/s 22939
step     50 | loss 3.2517 | lr 3.00e-04 | grad 2.91 | tok/s 23350
step     60 | loss 2.5302 | lr 3.00e-04 | grad 3.17 | tok/s 24059
step     70 | loss 2.4922 | lr 3.00e-04 | grad 1.77 | tok/s 24304
step     80 | loss 7.0151 | lr 3.00e-04 | grad 10.81 | tok/s 24470
step     90 | loss 5.0149 | lr 3.00e-04 | grad 2.45 | tok/s 24926
step    100 | loss 3.7891 | lr 3.00e-04 | grad 3.11 | tok/s 24888
step    110 | loss 3.6164 | lr 3.00e-04 | grad 7.59 | tok/s 24910
step    120 | loss 3.5235 | lr 3.00e-04 | grad 7.56 | tok/s 24782
step    130 | loss 3.4418 | lr 3.00e-04 | grad 4.03 | tok/s 24797
step    140 | loss 2.8701 | lr 3.00e-04 | grad 2.19 | tok/s 24709
step    150 | loss 3.1928 | lr 3.00e-04 | grad 4.84 | tok/s 24712
step    160 | loss 2.6092 | lr 3.00e-04 | grad 4.75 | tok/s 24659
step    170 | loss 2.6771 | lr 3.00e-04 | grad 5.06 | tok/s 24658
step    180 | loss 2.4421 | lr 3.00e-04 | grad 3.89 | tok/s 24622
step    190 | loss 2.6191 | lr 3.00e-04 | grad 2.23 | tok/s 24628
step    200 | loss 2.3329 | lr 3.00e-04 | grad 2.62 | tok/s 24577
step    210 | loss 2.3353 | lr 3.00e-04 | grad 2.23 | tok/s 24548
step    220 | loss 2.5851 | lr 3.00e-04 | grad 1.75 | tok/s 24246
step    230 | loss 3.4488 | lr 3.00e-04 | grad 2.00 | tok/s 23961
step    240 | loss 2.6093 | lr 3.00e-04 | grad 2.88 | tok/s 22724
step    250 | loss 2.4522 | lr 3.00e-04 | grad 1.65 | tok/s 23313
step    260 | loss 2.2424 | lr 3.00e-04 | grad 1.70 | tok/s 24051
step    270 | loss 2.5093 | lr 3.00e-04 | grad 1.42 | tok/s 23729
step    280 | loss 2.6594 | lr 3.00e-04 | grad 2.59 | tok/s 23277
step    290 | loss 2.6237 | lr 3.00e-04 | grad 2.20 | tok/s 24561
step    300 | loss 1.6123 | lr 3.00e-04 | grad 1.57 | tok/s 24557
step    310 | loss 2.9148 | lr 3.00e-04 | grad 1.72 | tok/s 24123
step    320 | loss 2.5651 | lr 3.00e-04 | grad 3.28 | tok/s 23625
step    330 | loss 2.3434 | lr 3.00e-04 | grad 1.31 | tok/s 22800
step    340 | loss 2.6118 | lr 3.00e-04 | grad 1.35 | tok/s 23170
step    350 | loss 2.4177 | lr 3.00e-04 | grad 1.50 | tok/s 23687
step    360 | loss 2.4442 | lr 3.00e-04 | grad 2.80 | tok/s 24193
step    370 | loss 2.2456 | lr 3.00e-04 | grad 1.68 | tok/s 21976
step    380 | loss 2.1976 | lr 3.00e-04 | grad 1.56 | tok/s 23384
step    390 | loss 2.0736 | lr 3.00e-04 | grad 1.09 | tok/s 24378
step    400 | loss 2.0532 | lr 3.00e-04 | grad 1.77 | tok/s 24192
step    410 | loss 1.9784 | lr 3.00e-04 | grad 1.16 | tok/s 23658
step    420 | loss 2.1717 | lr 3.00e-04 | grad 2.17 | tok/s 22584
step    430 | loss 2.4646 | lr 3.00e-04 | grad 2.06 | tok/s 24061
step    440 | loss 2.4823 | lr 3.00e-04 | grad 1.84 | tok/s 22745
step    450 | loss 2.3410 | lr 3.00e-04 | grad 1.23 | tok/s 23514
step    460 | loss 2.1685 | lr 3.00e-04 | grad 2.28 | tok/s 23012
step    470 | loss 2.2659 | lr 3.00e-04 | grad 1.60 | tok/s 23714
step    480 | loss 2.6729 | lr 3.00e-04 | grad 2.88 | tok/s 23766
step    490 | loss 2.1461 | lr 3.00e-04 | grad 1.87 | tok/s 22396
step    500 | loss 2.1321 | lr 3.00e-04 | grad 2.08 | tok/s 23924
step    510 | loss 2.1434 | lr 3.00e-04 | grad 1.27 | tok/s 24284
step    520 | loss 2.1367 | lr 3.00e-04 | grad 1.39 | tok/s 24210
step    530 | loss 2.2860 | lr 3.00e-04 | grad 1.38 | tok/s 23283
step    540 | loss 2.0514 | lr 3.00e-04 | grad 1.45 | tok/s 23267
step    550 | loss 1.9094 | lr 3.00e-04 | grad 1.39 | tok/s 22795
step    560 | loss 2.0861 | lr 3.00e-04 | grad 1.51 | tok/s 22208
step    570 | loss 2.0227 | lr 3.00e-04 | grad 2.08 | tok/s 22829
step    580 | loss 1.9089 | lr 3.00e-04 | grad 1.34 | tok/s 22715
step    590 | loss 2.2503 | lr 3.00e-04 | grad 1.32 | tok/s 23292
step    600 | loss 2.1461 | lr 3.00e-04 | grad 1.06 | tok/s 22500
step    610 | loss 1.9807 | lr 3.00e-04 | grad 1.38 | tok/s 23656
step    620 | loss 1.8483 | lr 3.00e-04 | grad 1.08 | tok/s 22399
step    630 | loss 1.9994 | lr 3.00e-04 | grad 2.02 | tok/s 22611
step    640 | loss 2.1761 | lr 3.00e-04 | grad 1.44 | tok/s 23207
step    650 | loss 1.9912 | lr 3.00e-04 | grad 1.75 | tok/s 23319
step    660 | loss 2.0284 | lr 3.00e-04 | grad 1.04 | tok/s 23411
step    670 | loss 2.2529 | lr 3.00e-04 | grad 2.03 | tok/s 23583
step    680 | loss 2.0119 | lr 3.00e-04 | grad 1.19 | tok/s 23105
step    690 | loss 2.2808 | lr 3.00e-04 | grad 1.64 | tok/s 23881
step    700 | loss 2.0394 | lr 3.00e-04 | grad 1.71 | tok/s 24380
step    710 | loss 1.9156 | lr 3.00e-04 | grad 1.49 | tok/s 22753
step    720 | loss 1.7667 | lr 3.00e-04 | grad 1.46 | tok/s 22481
step    730 | loss 1.8516 | lr 3.00e-04 | grad 1.70 | tok/s 24288
step    740 | loss 1.8944 | lr 3.00e-04 | grad 1.38 | tok/s 23978
step    750 | loss 1.7093 | lr 3.00e-04 | grad 1.30 | tok/s 24402
step    760 | loss 1.5648 | lr 3.00e-04 | grad 1.31 | tok/s 24337
step    770 | loss 1.5405 | lr 3.00e-04 | grad 1.24 | tok/s 24348
step    780 | loss 1.4720 | lr 3.00e-04 | grad 1.33 | tok/s 24342
step    790 | loss 1.5365 | lr 3.00e-04 | grad 1.84 | tok/s 23608
step    800 | loss 2.2385 | lr 3.00e-04 | grad 2.48 | tok/s 23534
step    810 | loss 1.9737 | lr 3.00e-04 | grad 1.33 | tok/s 23415
step    820 | loss 1.9721 | lr 3.00e-04 | grad 1.80 | tok/s 22496
step    830 | loss 2.0192 | lr 3.00e-04 | grad 1.30 | tok/s 24131
step    840 | loss 1.9223 | lr 3.00e-04 | grad 1.23 | tok/s 24348
step    850 | loss 1.9301 | lr 3.00e-04 | grad 1.55 | tok/s 24249
step    860 | loss 1.9026 | lr 3.00e-04 | grad 2.17 | tok/s 23980
step    870 | loss 1.8267 | lr 3.00e-04 | grad 1.33 | tok/s 23079
step    880 | loss 1.9862 | lr 3.00e-04 | grad 1.21 | tok/s 23196
step    890 | loss 1.9600 | lr 3.00e-04 | grad 1.73 | tok/s 23500
step    900 | loss 1.8388 | lr 3.00e-04 | grad 1.31 | tok/s 23536
step    910 | loss 1.6955 | lr 3.00e-04 | grad 1.81 | tok/s 23029
step    920 | loss 1.8936 | lr 3.00e-04 | grad 2.22 | tok/s 23976
step    930 | loss 1.8646 | lr 3.00e-04 | grad 1.93 | tok/s 22860
step    940 | loss 1.8145 | lr 3.00e-04 | grad 1.36 | tok/s 24149
step    950 | loss 1.8538 | lr 3.00e-04 | grad 1.57 | tok/s 24259
step    960 | loss 1.7512 | lr 3.00e-04 | grad 1.40 | tok/s 24279
step    970 | loss 1.9492 | lr 3.00e-04 | grad 1.70 | tok/s 22835
step    980 | loss 1.8852 | lr 3.00e-04 | grad 1.28 | tok/s 23420
step    990 | loss 1.7788 | lr 3.00e-04 | grad 1.41 | tok/s 23863
step   1000 | loss 2.1140 | lr 3.00e-04 | grad 5.50 | tok/s 22918
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1140.pt
step   1010 | loss 1.9732 | lr 3.00e-04 | grad 1.52 | tok/s 8541
step   1020 | loss 1.8631 | lr 3.00e-04 | grad 1.19 | tok/s 22431
step   1030 | loss 1.7214 | lr 3.00e-04 | grad 1.37 | tok/s 23341
step   1040 | loss 1.7292 | lr 3.00e-04 | grad 1.27 | tok/s 24095
step   1050 | loss 1.8201 | lr 3.00e-04 | grad 1.59 | tok/s 22274
step   1060 | loss 2.0006 | lr 3.00e-04 | grad 1.57 | tok/s 24081
step   1070 | loss 2.0338 | lr 3.00e-04 | grad 1.41 | tok/s 23997
step   1080 | loss 1.6370 | lr 3.00e-04 | grad 1.12 | tok/s 21794
step   1090 | loss 1.3816 | lr 3.00e-04 | grad 0.75 | tok/s 24041
step   1100 | loss 1.6609 | lr 3.00e-04 | grad 2.02 | tok/s 23334
step   1110 | loss 1.7252 | lr 3.00e-04 | grad 1.24 | tok/s 24455
step   1120 | loss 1.6223 | lr 3.00e-04 | grad 1.78 | tok/s 24502
step   1130 | loss 1.5584 | lr 3.00e-04 | grad 1.30 | tok/s 24490
step   1140 | loss 1.5389 | lr 3.00e-04 | grad 1.52 | tok/s 24432
step   1150 | loss 1.5551 | lr 3.00e-04 | grad 1.28 | tok/s 24449
step   1160 | loss 1.4579 | lr 3.00e-04 | grad 1.23 | tok/s 24502
step   1170 | loss 1.4800 | lr 3.00e-04 | grad 1.29 | tok/s 24481
step   1180 | loss 1.6056 | lr 3.00e-04 | grad 1.02 | tok/s 24477
step   1190 | loss 1.4886 | lr 3.00e-04 | grad 1.46 | tok/s 24493
step   1200 | loss 1.4751 | lr 3.00e-04 | grad 1.44 | tok/s 24448
step   1210 | loss 1.5031 | lr 3.00e-04 | grad 1.48 | tok/s 24510
step   1220 | loss 1.5055 | lr 3.00e-04 | grad 1.42 | tok/s 24463
step   1230 | loss 1.4850 | lr 3.00e-04 | grad 1.19 | tok/s 24439
step   1240 | loss 1.4359 | lr 3.00e-04 | grad 1.14 | tok/s 24448
step   1250 | loss 2.0467 | lr 3.00e-04 | grad 1.69 | tok/s 23184
step   1260 | loss 1.5791 | lr 3.00e-04 | grad 2.02 | tok/s 22939
step   1270 | loss 1.8547 | lr 3.00e-04 | grad 2.88 | tok/s 22842
step   1280 | loss 1.8415 | lr 3.00e-04 | grad 1.28 | tok/s 23533
step   1290 | loss 1.6946 | lr 3.00e-04 | grad 1.49 | tok/s 23428
step   1300 | loss 1.7536 | lr 3.00e-04 | grad 1.41 | tok/s 23561
step   1310 | loss 1.7157 | lr 3.00e-04 | grad 1.46 | tok/s 23955
step   1320 | loss 1.8060 | lr 3.00e-04 | grad 1.27 | tok/s 24031
step   1330 | loss 1.8126 | lr 3.00e-04 | grad 1.49 | tok/s 24076
step   1340 | loss 1.7107 | lr 3.00e-04 | grad 4.91 | tok/s 22970
step   1350 | loss 1.8948 | lr 3.00e-04 | grad 1.57 | tok/s 22207
step   1360 | loss 1.7740 | lr 3.00e-04 | grad 1.55 | tok/s 23557
step   1370 | loss 1.5936 | lr 3.00e-04 | grad 0.97 | tok/s 23314
step   1380 | loss 1.8911 | lr 3.00e-04 | grad 1.20 | tok/s 22401
step   1390 | loss 1.7299 | lr 3.00e-04 | grad 1.25 | tok/s 23794
step   1400 | loss 1.6323 | lr 3.00e-04 | grad 1.16 | tok/s 22958
step   1410 | loss 1.6634 | lr 3.00e-04 | grad 1.86 | tok/s 23011
step   1420 | loss 1.9241 | lr 3.00e-04 | grad 3.36 | tok/s 23070
step   1430 | loss 1.6275 | lr 3.00e-04 | grad 1.21 | tok/s 23450
step   1440 | loss 1.4107 | lr 3.00e-04 | grad 1.25 | tok/s 24226
step   1450 | loss 1.3859 | lr 3.00e-04 | grad 3.06 | tok/s 24399
step   1460 | loss 1.8388 | lr 3.00e-04 | grad 1.38 | tok/s 23024
step   1470 | loss 1.7667 | lr 3.00e-04 | grad 1.34 | tok/s 23859
step   1480 | loss 2.2034 | lr 3.00e-04 | grad 2.58 | tok/s 23985
step   1490 | loss 1.9949 | lr 3.00e-04 | grad 1.34 | tok/s 24369
step   1500 | loss 1.6435 | lr 3.00e-04 | grad 1.15 | tok/s 24440
step   1510 | loss 1.7284 | lr 3.00e-04 | grad 1.44 | tok/s 24111
step   1520 | loss 1.6388 | lr 3.00e-04 | grad 2.41 | tok/s 23617
step   1530 | loss 1.6042 | lr 3.00e-04 | grad 1.14 | tok/s 24179
step   1540 | loss 1.7921 | lr 3.00e-04 | grad 1.35 | tok/s 22764
step   1550 | loss 1.5560 | lr 3.00e-04 | grad 1.73 | tok/s 24236
step   1560 | loss 1.7465 | lr 3.00e-04 | grad 1.73 | tok/s 22944
step   1570 | loss 1.5803 | lr 3.00e-04 | grad 1.30 | tok/s 24454
step   1580 | loss 2.0563 | lr 3.00e-04 | grad 3.56 | tok/s 23900
step   1590 | loss 1.9624 | lr 3.00e-04 | grad 1.52 | tok/s 22955
step   1600 | loss 1.2392 | lr 3.00e-04 | grad 0.92 | tok/s 24520
step   1610 | loss 1.1887 | lr 3.00e-04 | grad 1.66 | tok/s 23745
step   1620 | loss 1.6330 | lr 3.00e-04 | grad 1.76 | tok/s 22235
step   1630 | loss 1.6733 | lr 3.00e-04 | grad 1.23 | tok/s 23774
step   1640 | loss 1.5295 | lr 3.00e-04 | grad 1.55 | tok/s 23206
step   1650 | loss 1.6737 | lr 3.00e-04 | grad 1.34 | tok/s 22233
step   1660 | loss 1.6590 | lr 3.00e-04 | grad 1.15 | tok/s 23768
step   1670 | loss 1.6407 | lr 3.00e-04 | grad 3.84 | tok/s 23662
step   1680 | loss 1.8825 | lr 3.00e-04 | grad 1.28 | tok/s 22755
step   1690 | loss 1.6886 | lr 3.00e-04 | grad 3.16 | tok/s 23149
step   1700 | loss 1.6918 | lr 3.00e-04 | grad 1.48 | tok/s 23658
step   1710 | loss 1.6939 | lr 3.00e-04 | grad 1.21 | tok/s 23234
step   1720 | loss 1.7750 | lr 3.00e-04 | grad 1.62 | tok/s 24179
step   1730 | loss 1.6948 | lr 3.00e-04 | grad 1.66 | tok/s 24444
step   1740 | loss 1.6769 | lr 3.00e-04 | grad 1.62 | tok/s 23853
step   1750 | loss 1.7691 | lr 3.00e-04 | grad 1.60 | tok/s 23419
step   1760 | loss 1.6992 | lr 3.00e-04 | grad 1.36 | tok/s 23555
step   1770 | loss 1.6050 | lr 3.00e-04 | grad 1.38 | tok/s 23108
step   1780 | loss 1.6587 | lr 3.00e-04 | grad 1.23 | tok/s 24039
step   1790 | loss 1.5917 | lr 3.00e-04 | grad 1.09 | tok/s 23428
step   1800 | loss 1.7728 | lr 3.00e-04 | grad 1.45 | tok/s 23591
step   1810 | loss 1.6260 | lr 3.00e-04 | grad 1.32 | tok/s 22767
step   1820 | loss 1.6906 | lr 3.00e-04 | grad 3.59 | tok/s 23088
step   1830 | loss 1.6021 | lr 3.00e-04 | grad 1.59 | tok/s 24041
step   1840 | loss 1.6889 | lr 3.00e-04 | grad 1.71 | tok/s 22998
step   1850 | loss 1.5937 | lr 3.00e-04 | grad 1.27 | tok/s 24097
step   1860 | loss 1.5043 | lr 3.00e-04 | grad 1.36 | tok/s 23272
step   1870 | loss 1.6075 | lr 3.00e-04 | grad 2.16 | tok/s 23359
step   1880 | loss 1.4539 | lr 3.00e-04 | grad 1.41 | tok/s 22899
step   1890 | loss 1.7012 | lr 3.00e-04 | grad 1.23 | tok/s 21781
step   1900 | loss 1.5443 | lr 3.00e-04 | grad 1.56 | tok/s 23538
step   1910 | loss 1.6059 | lr 3.00e-04 | grad 1.50 | tok/s 22288
step   1920 | loss 1.5862 | lr 3.00e-04 | grad 1.32 | tok/s 24468
step   1930 | loss 1.6071 | lr 3.00e-04 | grad 1.55 | tok/s 22929
step   1940 | loss 1.5975 | lr 3.00e-04 | grad 1.30 | tok/s 23869
step   1950 | loss 2.2439 | lr 3.00e-04 | grad 1.91 | tok/s 24189
step   1960 | loss 1.9535 | lr 3.00e-04 | grad 2.05 | tok/s 24433
step   1970 | loss 1.7916 | lr 3.00e-04 | grad 1.55 | tok/s 23835
step   1980 | loss 1.7416 | lr 3.00e-04 | grad 1.37 | tok/s 22827
step   1990 | loss 1.7537 | lr 3.00e-04 | grad 5.16 | tok/s 23236
step   2000 | loss 1.6426 | lr 3.00e-04 | grad 1.41 | tok/s 23502
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6426.pt
step   2010 | loss 1.1947 | lr 3.00e-04 | grad 1.17 | tok/s 9236
step   2020 | loss 1.4737 | lr 3.00e-04 | grad 1.28 | tok/s 23710
step   2030 | loss 1.4142 | lr 3.00e-04 | grad 0.79 | tok/s 24367
step   2040 | loss 1.4321 | lr 3.00e-04 | grad 1.26 | tok/s 24643
step   2050 | loss 1.5636 | lr 3.00e-04 | grad 1.21 | tok/s 24345
step   2060 | loss 1.6944 | lr 3.00e-04 | grad 1.59 | tok/s 22374
step   2070 | loss 1.8176 | lr 3.00e-04 | grad 1.55 | tok/s 23701
step   2080 | loss 2.3123 | lr 3.00e-04 | grad 2.12 | tok/s 24148
step   2090 | loss 1.9515 | lr 3.00e-04 | grad 1.55 | tok/s 24509
step   2100 | loss 1.6027 | lr 3.00e-04 | grad 1.16 | tok/s 23661
step   2110 | loss 1.7480 | lr 3.00e-04 | grad 1.38 | tok/s 23306
step   2120 | loss 1.2667 | lr 3.00e-04 | grad 1.46 | tok/s 24189
step   2130 | loss 1.1198 | lr 3.00e-04 | grad 4.38 | tok/s 24223
step   2140 | loss 1.7413 | lr 3.00e-04 | grad 1.49 | tok/s 23327
step   2150 | loss 1.4432 | lr 3.00e-04 | grad 1.30 | tok/s 24480
step   2160 | loss 1.3643 | lr 3.00e-04 | grad 1.24 | tok/s 24490
step   2170 | loss 1.3919 | lr 3.00e-04 | grad 1.34 | tok/s 24496
step   2180 | loss 1.3483 | lr 3.00e-04 | grad 1.13 | tok/s 24477
step   2190 | loss 1.3679 | lr 3.00e-04 | grad 1.04 | tok/s 24489
step   2200 | loss 1.3550 | lr 3.00e-04 | grad 1.38 | tok/s 24453
step   2210 | loss 1.2887 | lr 3.00e-04 | grad 1.10 | tok/s 24473
step   2220 | loss 1.2964 | lr 3.00e-04 | grad 1.20 | tok/s 24455
step   2230 | loss 1.4584 | lr 3.00e-04 | grad 1.48 | tok/s 24077
step   2240 | loss 1.5425 | lr 3.00e-04 | grad 1.18 | tok/s 24413
step   2250 | loss 1.7412 | lr 3.00e-04 | grad 2.33 | tok/s 23611
step   2260 | loss 1.8127 | lr 3.00e-04 | grad 1.67 | tok/s 23929
step   2270 | loss 2.0061 | lr 3.00e-04 | grad 1.63 | tok/s 24179
step   2280 | loss 1.7419 | lr 3.00e-04 | grad 1.46 | tok/s 24192
step   2290 | loss 1.5199 | lr 3.00e-04 | grad 2.44 | tok/s 24033
step   2300 | loss 2.1308 | lr 3.00e-04 | grad 2.48 | tok/s 23772
step   2310 | loss 1.6365 | lr 3.00e-04 | grad 1.46 | tok/s 22898
step   2320 | loss 1.7032 | lr 3.00e-04 | grad 2.00 | tok/s 23460
step   2330 | loss 1.9936 | lr 3.00e-04 | grad 1.77 | tok/s 22995
step   2340 | loss 1.5604 | lr 3.00e-04 | grad 2.88 | tok/s 22760
step   2350 | loss 1.4869 | lr 3.00e-04 | grad 1.01 | tok/s 23970
step   2360 | loss 1.5893 | lr 3.00e-04 | grad 1.24 | tok/s 24199
step   2370 | loss 1.6246 | lr 3.00e-04 | grad 1.74 | tok/s 23996
step   2380 | loss 1.8406 | lr 3.00e-04 | grad 1.42 | tok/s 24507
step   2390 | loss 1.4847 | lr 3.00e-04 | grad 1.16 | tok/s 24460
step   2400 | loss 1.3309 | lr 3.00e-04 | grad 1.54 | tok/s 24493
step   2410 | loss 1.2221 | lr 3.00e-04 | grad 1.56 | tok/s 24177
step   2420 | loss 1.5543 | lr 3.00e-04 | grad 2.14 | tok/s 22703
step   2430 | loss 1.6359 | lr 3.00e-04 | grad 1.41 | tok/s 23122
step   2440 | loss 1.3642 | lr 3.00e-04 | grad 1.38 | tok/s 23964
step   2450 | loss 1.6237 | lr 3.00e-04 | grad 1.52 | tok/s 23371
step   2460 | loss 1.5776 | lr 3.00e-04 | grad 1.20 | tok/s 24296
step   2470 | loss 1.3428 | lr 3.00e-04 | grad 1.55 | tok/s 24203
step   2480 | loss 1.4595 | lr 3.00e-04 | grad 1.66 | tok/s 24490
step   2490 | loss 1.4478 | lr 3.00e-04 | grad 1.89 | tok/s 23154
step   2500 | loss 1.6896 | lr 3.00e-04 | grad 1.91 | tok/s 23967
step   2510 | loss 1.5253 | lr 3.00e-04 | grad 2.03 | tok/s 24517
step   2520 | loss 1.5623 | lr 3.00e-04 | grad 2.12 | tok/s 24500
step   2530 | loss 1.5725 | lr 3.00e-04 | grad 1.21 | tok/s 23505
step   2540 | loss 1.5242 | lr 3.00e-04 | grad 2.16 | tok/s 23398
step   2550 | loss 1.4253 | lr 3.00e-04 | grad 1.25 | tok/s 24346
step   2560 | loss 1.4636 | lr 3.00e-04 | grad 2.95 | tok/s 22854
step   2570 | loss 1.6799 | lr 3.00e-04 | grad 1.59 | tok/s 23816
step   2580 | loss 1.4708 | lr 3.00e-04 | grad 1.33 | tok/s 22310
step   2590 | loss 1.5579 | lr 3.00e-04 | grad 1.60 | tok/s 23845
step   2600 | loss 1.7152 | lr 3.00e-04 | grad 2.66 | tok/s 22272
step   2610 | loss 1.7237 | lr 3.00e-04 | grad 1.76 | tok/s 24271
step   2620 | loss 1.6856 | lr 3.00e-04 | grad 1.43 | tok/s 23431
step   2630 | loss 1.5955 | lr 3.00e-04 | grad 1.33 | tok/s 24258
step   2640 | loss 1.5881 | lr 3.00e-04 | grad 1.16 | tok/s 23597
step   2650 | loss 1.7742 | lr 3.00e-04 | grad 2.25 | tok/s 24493
step   2660 | loss 1.5319 | lr 3.00e-04 | grad 1.43 | tok/s 23706
step   2670 | loss 1.5260 | lr 3.00e-04 | grad 1.61 | tok/s 22954
step   2680 | loss 1.7061 | lr 3.00e-04 | grad 4.84 | tok/s 22901
step   2690 | loss 1.5456 | lr 3.00e-04 | grad 1.16 | tok/s 24269
step   2700 | loss 1.6220 | lr 3.00e-04 | grad 2.84 | tok/s 23934
step   2710 | loss 1.7208 | lr 3.00e-04 | grad 3.03 | tok/s 23192
step   2720 | loss 1.4970 | lr 3.00e-04 | grad 1.80 | tok/s 22048
step   2730 | loss 1.4555 | lr 3.00e-04 | grad 0.96 | tok/s 23937
step   2740 | loss 1.6864 | lr 3.00e-04 | grad 2.39 | tok/s 23653
step   2750 | loss 1.9835 | lr 3.00e-04 | grad 1.70 | tok/s 24281
step   2760 | loss 1.4676 | lr 3.00e-04 | grad 1.41 | tok/s 22893
step   2770 | loss 1.6290 | lr 3.00e-04 | grad 1.58 | tok/s 22933
step   2780 | loss 1.3696 | lr 3.00e-04 | grad 1.34 | tok/s 24525
step   2790 | loss 1.7049 | lr 3.00e-04 | grad 1.48 | tok/s 22928
step   2800 | loss 1.6063 | lr 3.00e-04 | grad 1.27 | tok/s 23331
step   2810 | loss 1.3490 | lr 3.00e-04 | grad 1.44 | tok/s 23367
step   2820 | loss 1.5525 | lr 3.00e-04 | grad 2.31 | tok/s 22751
step   2830 | loss 1.4486 | lr 3.00e-04 | grad 2.42 | tok/s 23837
step   2840 | loss 1.1242 | lr 3.00e-04 | grad 1.99 | tok/s 24459
step   2850 | loss 1.8737 | lr 3.00e-04 | grad 1.58 | tok/s 23704
step   2860 | loss 1.8513 | lr 3.00e-04 | grad 1.64 | tok/s 23577
step   2870 | loss 1.4789 | lr 3.00e-04 | grad 1.24 | tok/s 23279
step   2880 | loss 1.6399 | lr 3.00e-04 | grad 2.55 | tok/s 23533
step   2890 | loss 1.5623 | lr 3.00e-04 | grad 1.70 | tok/s 24460
step   2900 | loss 1.5839 | lr 3.00e-04 | grad 1.20 | tok/s 23483
step   2910 | loss 1.6067 | lr 3.00e-04 | grad 1.06 | tok/s 23749
step   2920 | loss 1.5462 | lr 3.00e-04 | grad 1.23 | tok/s 22569
step   2930 | loss 1.7960 | lr 3.00e-04 | grad 1.38 | tok/s 23901
step   2940 | loss 1.4156 | lr 3.00e-04 | grad 1.41 | tok/s 22413
step   2950 | loss 1.4957 | lr 3.00e-04 | grad 1.88 | tok/s 23242
step   2960 | loss 1.4478 | lr 3.00e-04 | grad 1.79 | tok/s 23860
step   2970 | loss 1.4602 | lr 3.00e-04 | grad 1.59 | tok/s 24026
step   2980 | loss 1.8436 | lr 3.00e-04 | grad 1.34 | tok/s 23214
step   2990 | loss 2.1733 | lr 3.00e-04 | grad 1.26 | tok/s 23886
step   3000 | loss 1.5161 | lr 3.00e-04 | grad 1.34 | tok/s 24337
  >>> saved checkpoint: checkpoint_step_003000_loss_1.5161.pt
step   3010 | loss 1.3683 | lr 3.00e-04 | grad 2.09 | tok/s 8616
step   3020 | loss 1.4008 | lr 3.00e-04 | grad 1.12 | tok/s 23275
step   3030 | loss 1.5929 | lr 3.00e-04 | grad 2.02 | tok/s 23019
step   3040 | loss 1.5729 | lr 3.00e-04 | grad 1.28 | tok/s 23840
step   3050 | loss 1.5338 | lr 3.00e-04 | grad 1.38 | tok/s 23938
step   3060 | loss 1.4825 | lr 3.00e-04 | grad 1.50 | tok/s 24203
step   3070 | loss 1.7131 | lr 3.00e-04 | grad 2.00 | tok/s 24114
step   3080 | loss 1.5031 | lr 3.00e-04 | grad 1.05 | tok/s 24089
step   3090 | loss 1.5545 | lr 3.00e-04 | grad 1.34 | tok/s 24071
step   3100 | loss 1.6196 | lr 3.00e-04 | grad 1.65 | tok/s 23175
step   3110 | loss 1.4703 | lr 3.00e-04 | grad 1.01 | tok/s 24286
step   3120 | loss 1.0981 | lr 3.00e-04 | grad 1.14 | tok/s 24524
step   3130 | loss 1.4848 | lr 3.00e-04 | grad 3.69 | tok/s 23178
step   3140 | loss 1.3811 | lr 3.00e-04 | grad 1.14 | tok/s 24561
step   3150 | loss 1.2999 | lr 3.00e-04 | grad 0.99 | tok/s 24552
step   3160 | loss 1.4391 | lr 3.00e-04 | grad 1.77 | tok/s 23415
step   3170 | loss 1.6237 | lr 3.00e-04 | grad 1.38 | tok/s 23022
step   3180 | loss 1.5223 | lr 3.00e-04 | grad 2.09 | tok/s 23064
step   3190 | loss 1.2928 | lr 3.00e-04 | grad 1.79 | tok/s 24092
step   3200 | loss 1.2936 | lr 3.00e-04 | grad 4.50 | tok/s 24597
step   3210 | loss 1.6352 | lr 3.00e-04 | grad 1.36 | tok/s 23657
step   3220 | loss 2.3178 | lr 3.00e-04 | grad 1.62 | tok/s 23817
step   3230 | loss 2.1897 | lr 3.00e-04 | grad 1.38 | tok/s 24509
step   3240 | loss 1.9422 | lr 3.00e-04 | grad 1.80 | tok/s 24496
step   3250 | loss 1.8179 | lr 3.00e-04 | grad 1.16 | tok/s 24501
step   3260 | loss 1.7589 | lr 3.00e-04 | grad 1.38 | tok/s 24512
step   3270 | loss 1.6655 | lr 3.00e-04 | grad 1.28 | tok/s 24471
step   3280 | loss 1.6295 | lr 3.00e-04 | grad 1.12 | tok/s 24491
step   3290 | loss 1.5821 | lr 3.00e-04 | grad 1.53 | tok/s 24499
step   3300 | loss 1.5406 | lr 3.00e-04 | grad 1.43 | tok/s 24508
step   3310 | loss 1.5428 | lr 3.00e-04 | grad 1.44 | tok/s 24511
step   3320 | loss 1.5103 | lr 3.00e-04 | grad 1.56 | tok/s 24499
step   3330 | loss 1.5417 | lr 3.00e-04 | grad 1.39 | tok/s 24455
step   3340 | loss 1.8365 | lr 3.00e-04 | grad 1.68 | tok/s 22964
step   3350 | loss 1.5451 | lr 3.00e-04 | grad 1.45 | tok/s 23907
step   3360 | loss 1.5216 | lr 3.00e-04 | grad 1.35 | tok/s 23063
step   3370 | loss 1.4826 | lr 3.00e-04 | grad 1.42 | tok/s 22822
step   3380 | loss 1.6881 | lr 3.00e-04 | grad 2.31 | tok/s 23144
step   3390 | loss 1.5667 | lr 3.00e-04 | grad 1.41 | tok/s 23291
step   3400 | loss 1.2914 | lr 3.00e-04 | grad 2.52 | tok/s 24423
step   3410 | loss 1.2510 | lr 3.00e-04 | grad 1.09 | tok/s 24506
step   3420 | loss 1.5130 | lr 3.00e-04 | grad 1.88 | tok/s 23437
step   3430 | loss 1.5429 | lr 3.00e-04 | grad 1.27 | tok/s 23467
step   3440 | loss 1.5896 | lr 3.00e-04 | grad 1.38 | tok/s 22948
step   3450 | loss 1.4339 | lr 3.00e-04 | grad 1.22 | tok/s 24037

Training complete! Final step: 3456
