Loading data from data/fineweb_100mb.txt...

Creating mamba2 model with ~50m parameters...
Created Mamba2 model: dim=672, depth=18, expand=2, params=50,928,750

============================================================
Training: mamba2 (steps=100)
Parameters: 50.93M
Vocab size: 256
============================================================
[mamba2] step    1 | loss 5.7188 | ppl 304.5 | grad 4.16 | 2363 tok/s | 13.9s | 13867ms/step
[mamba2] step   20 | loss 3.7188 | ppl 41.2 | grad 3.75 | 33707 tok/s | 19.4s | 297ms/step
[mamba2] step   40 | loss 2.3750 | ppl 10.8 | grad 1.51 | 51635 tok/s | 25.4s | 298ms/step
[mamba2] step   60 | loss 1.8906 | ppl 6.6 | grad 1.51 | 62653 tok/s | 31.4s | 301ms/step
[mamba2] step   80 | loss 1.8047 | ppl 6.1 | grad 1.42 | 70045 tok/s | 37.4s | 304ms/step
[mamba2] step  100 | loss 1.6719 | ppl 5.3 | grad 1.54 | 75317 tok/s | 43.5s | 307ms/step

mamba2 Final: loss=2.8633, grad=2.31, steps=100, tokens=3,276,800, time=43.5s

==========================================================================================
BENCHMARK SUMMARY
==========================================================================================
Model           Params       Loss       Steps    Tokens       tok/s      Time    
------------------------------------------------------------------------------------------
mamba2          50.93M       2.8633     100      3,276,800    75317      43.5    s

Results saved to: benchmark_results
