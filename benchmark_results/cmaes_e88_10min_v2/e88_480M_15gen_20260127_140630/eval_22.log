Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_22/levelE88_100m_20260127_142712
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 506,268,666 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.7673 | lr 3.00e-04 | grad 12.31 | tok/s 4766
step     20 | loss 2.6580 | lr 3.00e-04 | grad 5.34 | tok/s 8667
step     30 | loss 2.5606 | lr 3.00e-04 | grad 2.47 | tok/s 8758
step     40 | loss 2.3641 | lr 3.00e-04 | grad 2.64 | tok/s 8382
step     50 | loss 3.1134 | lr 3.00e-04 | grad 13.31 | tok/s 8531
step     60 | loss 2.1526 | lr 3.00e-04 | grad 3.75 | tok/s 8799
step     70 | loss 1.9948 | lr 3.00e-04 | grad 4.06 | tok/s 8910
step     80 | loss 5.0984 | lr 3.00e-04 | grad 92.00 | tok/s 8964
step     90 | loss 5.2110 | lr 3.00e-04 | grad 10.25 | tok/s 8707
step    100 | loss 4.5884 | lr 3.00e-04 | grad 14.25 | tok/s 9109
step    110 | loss 4.3403 | lr 3.00e-04 | grad 22.62 | tok/s 9102
step    120 | loss 3.9778 | lr 3.00e-04 | grad 26.50 | tok/s 9093
step    130 | loss 3.7071 | lr 3.00e-04 | grad 28.50 | tok/s 9090
step    140 | loss 2.9736 | lr 3.00e-04 | grad 17.62 | tok/s 9098
step    150 | loss 3.3713 | lr 3.00e-04 | grad 21.38 | tok/s 9090
step    160 | loss 2.5722 | lr 3.00e-04 | grad 16.50 | tok/s 8926
step    170 | loss 2.6089 | lr 3.00e-04 | grad 13.88 | tok/s 9081
step    180 | loss 2.3890 | lr 3.00e-04 | grad 3.56 | tok/s 9090
step    190 | loss 2.6013 | lr 3.00e-04 | grad 3.62 | tok/s 9089
step    200 | loss 2.2497 | lr 3.00e-04 | grad 7.91 | tok/s 9084
step    210 | loss 2.2036 | lr 3.00e-04 | grad 5.75 | tok/s 9083
step    220 | loss 2.2975 | lr 3.00e-04 | grad 1.96 | tok/s 8646
step    230 | loss 2.2248 | lr 3.00e-04 | grad 2.61 | tok/s 8879
step    240 | loss 2.2813 | lr 3.00e-04 | grad 2.97 | tok/s 8428
step    250 | loss 2.1175 | lr 3.00e-04 | grad 1.59 | tok/s 8670
step    260 | loss 1.6381 | lr 3.00e-04 | grad 1.92 | tok/s 8940
step    270 | loss 2.1257 | lr 3.00e-04 | grad 1.61 | tok/s 8827
step    280 | loss 2.2849 | lr 3.00e-04 | grad 3.48 | tok/s 8648
step    290 | loss 1.5718 | lr 3.00e-04 | grad 2.52 | tok/s 9107
step    300 | loss 0.6205 | lr 3.00e-04 | grad 2.66 | tok/s 9111
step    310 | loss 2.4392 | lr 3.00e-04 | grad 2.72 | tok/s 8954
step    320 | loss 2.0358 | lr 3.00e-04 | grad 4.12 | tok/s 8776
step    330 | loss 1.9589 | lr 3.00e-04 | grad 1.93 | tok/s 8477
step    340 | loss 2.2985 | lr 3.00e-04 | grad 1.77 | tok/s 8601
step    350 | loss 1.9586 | lr 3.00e-04 | grad 4.25 | tok/s 8819
step    360 | loss 1.3638 | lr 3.00e-04 | grad 5.84 | tok/s 9016
step    370 | loss 1.8428 | lr 3.00e-04 | grad 1.70 | tok/s 8162
step    380 | loss 1.8127 | lr 3.00e-04 | grad 1.56 | tok/s 8712
step    390 | loss 1.5665 | lr 3.00e-04 | grad 1.27 | tok/s 9097
step    400 | loss 1.5351 | lr 3.00e-04 | grad 1.70 | tok/s 9021
step    410 | loss 1.3343 | lr 3.00e-04 | grad 1.37 | tok/s 8822
step    420 | loss 1.8317 | lr 3.00e-04 | grad 2.95 | tok/s 8418
step    430 | loss 2.1504 | lr 3.00e-04 | grad 1.91 | tok/s 8954
step    440 | loss 2.1583 | lr 3.00e-04 | grad 2.80 | tok/s 8470
step    450 | loss 1.9005 | lr 3.00e-04 | grad 1.87 | tok/s 8761
step    460 | loss 1.7249 | lr 3.00e-04 | grad 2.00 | tok/s 8579
step    470 | loss 1.8421 | lr 3.00e-04 | grad 1.50 | tok/s 8840
step    480 | loss 2.2626 | lr 3.00e-04 | grad 4.62 | tok/s 8839
step    490 | loss 1.7997 | lr 3.00e-04 | grad 1.60 | tok/s 8357
step    500 | loss 1.7038 | lr 3.00e-04 | grad 2.28 | tok/s 8671
step    510 | loss 1.7294 | lr 3.00e-04 | grad 1.56 | tok/s 9043
step    520 | loss 1.7008 | lr 3.00e-04 | grad 1.36 | tok/s 9022
step    530 | loss 1.9187 | lr 3.00e-04 | grad 1.70 | tok/s 8674
step    540 | loss 1.7419 | lr 3.00e-04 | grad 1.45 | tok/s 8680
step    550 | loss 1.5815 | lr 3.00e-04 | grad 2.02 | tok/s 8497
step    560 | loss 1.7257 | lr 3.00e-04 | grad 1.80 | tok/s 8286
step    570 | loss 1.6664 | lr 3.00e-04 | grad 2.59 | tok/s 8509
step    580 | loss 1.5561 | lr 3.00e-04 | grad 1.47 | tok/s 8479
step    590 | loss 1.8674 | lr 3.00e-04 | grad 2.14 | tok/s 8693
step    600 | loss 1.8155 | lr 3.00e-04 | grad 1.54 | tok/s 8402
step    610 | loss 1.6306 | lr 3.00e-04 | grad 1.57 | tok/s 8817
step    620 | loss 1.5532 | lr 3.00e-04 | grad 1.72 | tok/s 8354
step    630 | loss 1.6683 | lr 3.00e-04 | grad 3.05 | tok/s 8426
step    640 | loss 1.8055 | lr 3.00e-04 | grad 1.73 | tok/s 8658
step    650 | loss 1.6805 | lr 3.00e-04 | grad 1.75 | tok/s 8700
step    660 | loss 1.7005 | lr 3.00e-04 | grad 1.38 | tok/s 8731
step    670 | loss 1.9116 | lr 3.00e-04 | grad 4.25 | tok/s 8591
step    680 | loss 1.7233 | lr 3.00e-04 | grad 1.65 | tok/s 8600
step    690 | loss 1.8230 | lr 3.00e-04 | grad 2.22 | tok/s 8910
step    700 | loss 1.4653 | lr 3.00e-04 | grad 1.99 | tok/s 9089
step    710 | loss 1.5815 | lr 3.00e-04 | grad 1.68 | tok/s 8482
step    720 | loss 1.4631 | lr 3.00e-04 | grad 1.95 | tok/s 8360
step    730 | loss 1.3201 | lr 3.00e-04 | grad 1.89 | tok/s 9069
step    740 | loss 1.5100 | lr 3.00e-04 | grad 1.66 | tok/s 8949
step    750 | loss 1.2358 | lr 3.00e-04 | grad 1.78 | tok/s 9086
step    760 | loss 1.1327 | lr 3.00e-04 | grad 1.68 | tok/s 9086
step    770 | loss 1.0693 | lr 3.00e-04 | grad 1.44 | tok/s 9095
step    780 | loss 1.0073 | lr 3.00e-04 | grad 1.44 | tok/s 8975
step    790 | loss 1.1291 | lr 3.00e-04 | grad 2.55 | tok/s 8801
step    800 | loss 1.8226 | lr 3.00e-04 | grad 4.19 | tok/s 8780
step    810 | loss 1.6910 | lr 3.00e-04 | grad 1.52 | tok/s 8735
step    820 | loss 1.6997 | lr 3.00e-04 | grad 2.91 | tok/s 8392
step    830 | loss 1.5016 | lr 3.00e-04 | grad 1.83 | tok/s 9003
step    840 | loss 1.4060 | lr 3.00e-04 | grad 1.70 | tok/s 9095
step    850 | loss 1.5836 | lr 3.00e-04 | grad 1.54 | tok/s 9044
step    860 | loss 1.4870 | lr 3.00e-04 | grad 2.58 | tok/s 8956
step    870 | loss 1.5026 | lr 3.00e-04 | grad 2.09 | tok/s 8620
step    880 | loss 1.6629 | lr 3.00e-04 | grad 1.79 | tok/s 8564
step    890 | loss 1.6697 | lr 3.00e-04 | grad 2.11 | tok/s 8774
step    900 | loss 1.5490 | lr 3.00e-04 | grad 1.88 | tok/s 8789
step    910 | loss 1.4129 | lr 3.00e-04 | grad 2.78 | tok/s 8607
step    920 | loss 1.5297 | lr 3.00e-04 | grad 2.67 | tok/s 8938
step    930 | loss 1.5896 | lr 3.00e-04 | grad 2.62 | tok/s 8541
step    940 | loss 1.3968 | lr 3.00e-04 | grad 1.31 | tok/s 8999
step    950 | loss 1.4943 | lr 3.00e-04 | grad 2.22 | tok/s 8882
step    960 | loss 1.3397 | lr 3.00e-04 | grad 1.80 | tok/s 9062
step    970 | loss 1.7134 | lr 3.00e-04 | grad 2.66 | tok/s 8523
step    980 | loss 1.6281 | lr 3.00e-04 | grad 1.71 | tok/s 8750
step    990 | loss 1.4521 | lr 3.00e-04 | grad 1.52 | tok/s 8910
step   1000 | loss 1.8191 | lr 3.00e-04 | grad 6.12 | tok/s 8544
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8191.pt
step   1010 | loss 1.7147 | lr 3.00e-04 | grad 1.74 | tok/s 4720
step   1020 | loss 1.6646 | lr 3.00e-04 | grad 1.70 | tok/s 8375
step   1030 | loss 1.4102 | lr 3.00e-04 | grad 1.30 | tok/s 8757
step   1040 | loss 1.5153 | lr 3.00e-04 | grad 2.94 | tok/s 8941
step   1050 | loss 1.5842 | lr 3.00e-04 | grad 1.66 | tok/s 8396
step   1060 | loss 1.6969 | lr 3.00e-04 | grad 1.69 | tok/s 8971
step   1070 | loss 1.6670 | lr 3.00e-04 | grad 2.52 | tok/s 8799
step   1080 | loss 1.3909 | lr 3.00e-04 | grad 1.88 | tok/s 8165
step   1090 | loss 0.9921 | lr 3.00e-04 | grad 0.82 | tok/s 9039
step   1100 | loss 1.5339 | lr 3.00e-04 | grad 2.11 | tok/s 8686
step   1110 | loss 1.4188 | lr 3.00e-04 | grad 1.30 | tok/s 9104
step   1120 | loss 1.3359 | lr 3.00e-04 | grad 1.57 | tok/s 9143
step   1130 | loss 1.2809 | lr 3.00e-04 | grad 1.38 | tok/s 9105
step   1140 | loss 1.2842 | lr 3.00e-04 | grad 1.38 | tok/s 9125
step   1150 | loss 1.2919 | lr 3.00e-04 | grad 1.41 | tok/s 9121
step   1160 | loss 1.2129 | lr 3.00e-04 | grad 1.41 | tok/s 9122
step   1170 | loss 1.2540 | lr 3.00e-04 | grad 1.52 | tok/s 9119
step   1180 | loss 1.3179 | lr 3.00e-04 | grad 1.23 | tok/s 9131
step   1190 | loss 1.2182 | lr 3.00e-04 | grad 1.57 | tok/s 9111
step   1200 | loss 1.2218 | lr 3.00e-04 | grad 1.41 | tok/s 9095
step   1210 | loss 1.2555 | lr 3.00e-04 | grad 1.23 | tok/s 9135
step   1220 | loss 1.2727 | lr 3.00e-04 | grad 1.16 | tok/s 9090
step   1230 | loss 1.2507 | lr 3.00e-04 | grad 1.23 | tok/s 9107
step   1240 | loss 1.2505 | lr 3.00e-04 | grad 2.28 | tok/s 9063
step   1250 | loss 1.7684 | lr 3.00e-04 | grad 1.88 | tok/s 8612
step   1260 | loss 1.3176 | lr 3.00e-04 | grad 2.14 | tok/s 8476
step   1270 | loss 1.7360 | lr 3.00e-04 | grad 2.36 | tok/s 8518
step   1280 | loss 1.5546 | lr 3.00e-04 | grad 1.67 | tok/s 8862
step   1290 | loss 1.4803 | lr 3.00e-04 | grad 2.00 | tok/s 8527
step   1300 | loss 1.5082 | lr 3.00e-04 | grad 1.59 | tok/s 8632

Training complete! Final step: 1304
