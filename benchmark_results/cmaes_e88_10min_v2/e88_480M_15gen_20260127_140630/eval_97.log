Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_97/levelE88_100m_20260127_161136
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 467,422,750 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.1949 | lr 3.00e-04 | grad 8.38 | tok/s 7871
step     20 | loss 2.7731 | lr 3.00e-04 | grad 2.84 | tok/s 12247
step     30 | loss 2.9513 | lr 3.00e-04 | grad 5.09 | tok/s 12876
step     40 | loss 4.3463 | lr 3.00e-04 | grad 32.25 | tok/s 13037
step     50 | loss 4.5407 | lr 3.00e-04 | grad 13.94 | tok/s 13155
step     60 | loss 3.4846 | lr 3.00e-04 | grad 9.75 | tok/s 13100
step     70 | loss 2.8287 | lr 3.00e-04 | grad 5.41 | tok/s 13065
step     80 | loss 2.4909 | lr 3.00e-04 | grad 4.38 | tok/s 13036
step     90 | loss 2.3440 | lr 3.00e-04 | grad 4.12 | tok/s 13009
step    100 | loss 2.1438 | lr 3.00e-04 | grad 2.20 | tok/s 12982
step    110 | loss 2.1957 | lr 3.00e-04 | grad 2.66 | tok/s 12886
step    120 | loss 2.6951 | lr 3.00e-04 | grad 1.71 | tok/s 12255
step    130 | loss 2.1056 | lr 3.00e-04 | grad 4.47 | tok/s 12527
step    140 | loss 2.3983 | lr 3.00e-04 | grad 6.97 | tok/s 12577
step    150 | loss 1.4027 | lr 3.00e-04 | grad 4.53 | tok/s 12876
step    160 | loss 2.3283 | lr 3.00e-04 | grad 1.94 | tok/s 12442
step    170 | loss 2.2821 | lr 3.00e-04 | grad 1.50 | tok/s 12241
step    180 | loss 1.8460 | lr 3.00e-04 | grad 2.59 | tok/s 12539
step    190 | loss 1.9187 | lr 3.00e-04 | grad 1.84 | tok/s 12316
step    200 | loss 1.6630 | lr 3.00e-04 | grad 1.48 | tok/s 12878
step    210 | loss 1.8945 | lr 3.00e-04 | grad 4.22 | tok/s 12205
step    220 | loss 2.2068 | lr 3.00e-04 | grad 2.52 | tok/s 12327
step    230 | loss 1.9633 | lr 3.00e-04 | grad 2.42 | tok/s 12316
step    240 | loss 2.2669 | lr 3.00e-04 | grad 4.69 | tok/s 12483
step    250 | loss 1.7722 | lr 3.00e-04 | grad 1.46 | tok/s 12403
step    260 | loss 1.9010 | lr 3.00e-04 | grad 2.88 | tok/s 12753
step    270 | loss 1.8291 | lr 3.00e-04 | grad 1.63 | tok/s 12463
step    280 | loss 1.7797 | lr 3.00e-04 | grad 1.65 | tok/s 11719
step    290 | loss 1.6752 | lr 3.00e-04 | grad 1.92 | tok/s 12098
step    300 | loss 1.9798 | lr 3.00e-04 | grad 1.97 | tok/s 12197
step    310 | loss 1.6696 | lr 3.00e-04 | grad 1.61 | tok/s 11601
step    320 | loss 1.8803 | lr 3.00e-04 | grad 2.91 | tok/s 12311
step    330 | loss 1.7234 | lr 3.00e-04 | grad 1.59 | tok/s 12427
step    340 | loss 2.0331 | lr 3.00e-04 | grad 1.85 | tok/s 12379
step    350 | loss 1.7299 | lr 3.00e-04 | grad 1.70 | tok/s 12751
step    360 | loss 1.5840 | lr 3.00e-04 | grad 1.73 | tok/s 12155
step    370 | loss 1.4971 | lr 3.00e-04 | grad 1.48 | tok/s 12826
step    380 | loss 1.2320 | lr 3.00e-04 | grad 1.59 | tok/s 12916
step    390 | loss 1.1310 | lr 3.00e-04 | grad 1.31 | tok/s 12939
step    400 | loss 1.7483 | lr 3.00e-04 | grad 1.62 | tok/s 12236
step    410 | loss 1.7492 | lr 3.00e-04 | grad 2.03 | tok/s 12383
step    420 | loss 1.6261 | lr 3.00e-04 | grad 3.27 | tok/s 12843
step    430 | loss 1.6198 | lr 3.00e-04 | grad 1.66 | tok/s 12673
step    440 | loss 1.7040 | lr 3.00e-04 | grad 1.95 | tok/s 12272
step    450 | loss 1.6304 | lr 3.00e-04 | grad 1.34 | tok/s 12385
step    460 | loss 1.6033 | lr 3.00e-04 | grad 1.88 | tok/s 12588
step    470 | loss 1.5658 | lr 3.00e-04 | grad 2.86 | tok/s 12500
step    480 | loss 1.5753 | lr 3.00e-04 | grad 2.48 | tok/s 12784
step    490 | loss 1.7031 | lr 3.00e-04 | grad 2.09 | tok/s 12229
step    500 | loss 1.8098 | lr 3.00e-04 | grad 1.59 | tok/s 12462
step    510 | loss 1.6790 | lr 3.00e-04 | grad 1.34 | tok/s 11894
step    520 | loss 1.5348 | lr 3.00e-04 | grad 1.83 | tok/s 12455
step    530 | loss 1.7130 | lr 3.00e-04 | grad 1.77 | tok/s 12274
step    540 | loss 1.5974 | lr 3.00e-04 | grad 1.42 | tok/s 11970
step    550 | loss 1.3625 | lr 3.00e-04 | grad 2.36 | tok/s 12522
step    560 | loss 1.4408 | lr 3.00e-04 | grad 1.53 | tok/s 12894
step    570 | loss 1.3487 | lr 3.00e-04 | grad 1.59 | tok/s 12916
step    580 | loss 1.3070 | lr 3.00e-04 | grad 1.20 | tok/s 12840
step    590 | loss 1.3389 | lr 3.00e-04 | grad 1.19 | tok/s 12879
step    600 | loss 1.2765 | lr 3.00e-04 | grad 1.48 | tok/s 12769
step    610 | loss 1.3083 | lr 3.00e-04 | grad 1.34 | tok/s 12818
step    620 | loss 1.2959 | lr 3.00e-04 | grad 1.52 | tok/s 12832
step    630 | loss 1.6593 | lr 3.00e-04 | grad 3.80 | tok/s 12114
step    640 | loss 1.7367 | lr 3.00e-04 | grad 1.63 | tok/s 12265
step    650 | loss 1.5535 | lr 3.00e-04 | grad 1.55 | tok/s 12066
step    660 | loss 1.6486 | lr 3.00e-04 | grad 2.55 | tok/s 10059
step    670 | loss 1.5689 | lr 3.00e-04 | grad 1.90 | tok/s 12272
step    680 | loss 1.6125 | lr 3.00e-04 | grad 1.20 | tok/s 11735
step    690 | loss 1.6106 | lr 3.00e-04 | grad 2.31 | tok/s 12166
step    700 | loss 1.4448 | lr 3.00e-04 | grad 1.27 | tok/s 12297
step    710 | loss 1.6548 | lr 3.00e-04 | grad 1.89 | tok/s 11641
step    720 | loss 1.2749 | lr 3.00e-04 | grad 1.28 | tok/s 12610
step    730 | loss 1.5480 | lr 3.00e-04 | grad 3.48 | tok/s 12347
step    740 | loss 1.7593 | lr 3.00e-04 | grad 3.53 | tok/s 12799
step    750 | loss 1.4782 | lr 3.00e-04 | grad 1.20 | tok/s 12858
step    760 | loss 1.5918 | lr 3.00e-04 | grad 2.08 | tok/s 12572
step    770 | loss 1.5642 | lr 3.00e-04 | grad 1.62 | tok/s 12400
step    780 | loss 1.4707 | lr 3.00e-04 | grad 1.36 | tok/s 12451
step    790 | loss 1.6848 | lr 3.00e-04 | grad 2.50 | tok/s 12711
step    800 | loss 1.1869 | lr 3.00e-04 | grad 0.91 | tok/s 12523
step    810 | loss 1.4165 | lr 3.00e-04 | grad 1.95 | tok/s 12062
step    820 | loss 1.4712 | lr 3.00e-04 | grad 3.50 | tok/s 12320
step    830 | loss 1.4270 | lr 3.00e-04 | grad 1.20 | tok/s 12188
step    840 | loss 1.6458 | lr 3.00e-04 | grad 1.51 | tok/s 12029
step    850 | loss 1.5518 | lr 3.00e-04 | grad 1.90 | tok/s 12376
step    860 | loss 1.6012 | lr 3.00e-04 | grad 2.12 | tok/s 12679
step    870 | loss 1.4092 | lr 3.00e-04 | grad 1.83 | tok/s 11944
step    880 | loss 1.5819 | lr 3.00e-04 | grad 1.34 | tok/s 11367
step    890 | loss 1.4974 | lr 3.00e-04 | grad 1.81 | tok/s 12407
step    900 | loss 1.5580 | lr 3.00e-04 | grad 1.74 | tok/s 12043
step    910 | loss 1.5004 | lr 3.00e-04 | grad 2.27 | tok/s 12366
step    920 | loss 1.4716 | lr 3.00e-04 | grad 1.62 | tok/s 12331
step    930 | loss 1.4112 | lr 3.00e-04 | grad 1.87 | tok/s 11255

Training complete! Final step: 930
