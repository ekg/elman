Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_105/levelE88_100m_20260127_162209
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 493,786,518 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2364 | lr 3.00e-04 | grad 10.19 | tok/s 5019
step     20 | loss 2.6084 | lr 3.00e-04 | grad 3.95 | tok/s 10926
step     30 | loss 2.5070 | lr 3.00e-04 | grad 2.39 | tok/s 11073
step     40 | loss 2.3259 | lr 3.00e-04 | grad 2.67 | tok/s 10518
step     50 | loss 2.9034 | lr 3.00e-04 | grad 10.38 | tok/s 10680
step     60 | loss 2.0432 | lr 3.00e-04 | grad 2.83 | tok/s 10998
step     70 | loss 1.9174 | lr 3.00e-04 | grad 3.34 | tok/s 11139
step     80 | loss 5.1231 | lr 3.00e-04 | grad 45.50 | tok/s 11174
step     90 | loss 4.9522 | lr 3.00e-04 | grad 7.47 | tok/s 11391
step    100 | loss 4.0742 | lr 3.00e-04 | grad 6.34 | tok/s 11347
step    110 | loss 3.4886 | lr 3.00e-04 | grad 10.88 | tok/s 11339
step    120 | loss 3.1228 | lr 3.00e-04 | grad 8.38 | tok/s 11300
step    130 | loss 2.7980 | lr 3.00e-04 | grad 10.62 | tok/s 10767
step    140 | loss 2.5814 | lr 3.00e-04 | grad 6.41 | tok/s 11225
step    150 | loss 2.5504 | lr 3.00e-04 | grad 8.75 | tok/s 11227
step    160 | loss 2.1668 | lr 3.00e-04 | grad 5.44 | tok/s 11220
step    170 | loss 2.2433 | lr 3.00e-04 | grad 8.25 | tok/s 11210
step    180 | loss 2.0966 | lr 3.00e-04 | grad 3.30 | tok/s 11211
step    190 | loss 2.2346 | lr 3.00e-04 | grad 7.38 | tok/s 11212
step    200 | loss 1.9430 | lr 3.00e-04 | grad 3.48 | tok/s 11200
step    210 | loss 1.9730 | lr 3.00e-04 | grad 3.83 | tok/s 11181
step    220 | loss 2.0924 | lr 3.00e-04 | grad 2.22 | tok/s 11047
step    230 | loss 2.0062 | lr 3.00e-04 | grad 2.30 | tok/s 10908
step    240 | loss 2.2482 | lr 3.00e-04 | grad 3.22 | tok/s 10377
step    250 | loss 2.0809 | lr 3.00e-04 | grad 1.84 | tok/s 10635
step    260 | loss 1.5623 | lr 3.00e-04 | grad 2.05 | tok/s 10979
step    270 | loss 2.0563 | lr 3.00e-04 | grad 1.91 | tok/s 10799
step    280 | loss 2.2359 | lr 3.00e-04 | grad 3.67 | tok/s 10605
step    290 | loss 1.3483 | lr 3.00e-04 | grad 2.98 | tok/s 11137
step    300 | loss 0.5514 | lr 3.00e-04 | grad 2.05 | tok/s 11117
step    310 | loss 2.3832 | lr 3.00e-04 | grad 2.64 | tok/s 10938
step    320 | loss 1.9342 | lr 3.00e-04 | grad 3.98 | tok/s 10710
step    330 | loss 1.9174 | lr 3.00e-04 | grad 2.05 | tok/s 10346
step    340 | loss 2.2233 | lr 3.00e-04 | grad 1.91 | tok/s 10536
step    350 | loss 1.8654 | lr 3.00e-04 | grad 2.86 | tok/s 10803
step    360 | loss 1.1871 | lr 3.00e-04 | grad 5.09 | tok/s 11034
step    370 | loss 1.7937 | lr 3.00e-04 | grad 1.88 | tok/s 9985
step    380 | loss 1.7503 | lr 3.00e-04 | grad 1.82 | tok/s 10661
step    390 | loss 1.5263 | lr 3.00e-04 | grad 1.42 | tok/s 11113
step    400 | loss 1.4804 | lr 3.00e-04 | grad 1.78 | tok/s 11040
step    410 | loss 1.2819 | lr 3.00e-04 | grad 1.45 | tok/s 10779
step    420 | loss 1.7889 | lr 3.00e-04 | grad 3.09 | tok/s 10297
step    430 | loss 2.1186 | lr 3.00e-04 | grad 2.12 | tok/s 10970
step    440 | loss 2.1190 | lr 3.00e-04 | grad 3.05 | tok/s 10372
step    450 | loss 1.8693 | lr 3.00e-04 | grad 1.98 | tok/s 10745
step    460 | loss 1.6998 | lr 3.00e-04 | grad 2.28 | tok/s 10506
step    470 | loss 1.8061 | lr 3.00e-04 | grad 1.62 | tok/s 10839
step    480 | loss 2.1999 | lr 3.00e-04 | grad 4.94 | tok/s 10826
step    490 | loss 1.7667 | lr 3.00e-04 | grad 1.72 | tok/s 10215
step    500 | loss 1.6612 | lr 3.00e-04 | grad 2.45 | tok/s 10926
step    510 | loss 1.6862 | lr 3.00e-04 | grad 1.62 | tok/s 11050
step    520 | loss 1.6549 | lr 3.00e-04 | grad 1.48 | tok/s 11042
step    530 | loss 1.8797 | lr 3.00e-04 | grad 1.84 | tok/s 10616
step    540 | loss 1.7220 | lr 3.00e-04 | grad 1.58 | tok/s 10609
step    550 | loss 1.5579 | lr 3.00e-04 | grad 2.09 | tok/s 10399
step    560 | loss 1.7026 | lr 3.00e-04 | grad 1.92 | tok/s 10118
step    570 | loss 1.6354 | lr 3.00e-04 | grad 2.70 | tok/s 10396
step    580 | loss 1.5335 | lr 3.00e-04 | grad 1.55 | tok/s 9556
step    590 | loss 1.8422 | lr 3.00e-04 | grad 2.31 | tok/s 10586
step    600 | loss 1.7999 | lr 3.00e-04 | grad 1.66 | tok/s 10252
step    610 | loss 1.6046 | lr 3.00e-04 | grad 1.70 | tok/s 10761
step    620 | loss 1.5322 | lr 3.00e-04 | grad 1.78 | tok/s 10217
step    630 | loss 1.6442 | lr 3.00e-04 | grad 3.23 | tok/s 10310
step    640 | loss 1.7775 | lr 3.00e-04 | grad 1.80 | tok/s 10572
step    650 | loss 1.6381 | lr 3.00e-04 | grad 1.84 | tok/s 10621
step    660 | loss 1.6780 | lr 3.00e-04 | grad 1.51 | tok/s 10672
step    670 | loss 1.8724 | lr 3.00e-04 | grad 2.34 | tok/s 10738
step    680 | loss 1.7034 | lr 3.00e-04 | grad 1.82 | tok/s 10523
step    690 | loss 1.7995 | lr 3.00e-04 | grad 2.36 | tok/s 10892
step    700 | loss 1.4159 | lr 3.00e-04 | grad 2.25 | tok/s 11105
step    710 | loss 1.5635 | lr 3.00e-04 | grad 1.75 | tok/s 10377
step    720 | loss 1.4447 | lr 3.00e-04 | grad 2.25 | tok/s 10219
step    730 | loss 1.2895 | lr 3.00e-04 | grad 2.05 | tok/s 11102
step    740 | loss 1.4803 | lr 3.00e-04 | grad 1.79 | tok/s 10941
step    750 | loss 1.1964 | lr 3.00e-04 | grad 1.95 | tok/s 11122
step    760 | loss 1.1021 | lr 3.00e-04 | grad 1.69 | tok/s 11143
step    770 | loss 1.0468 | lr 3.00e-04 | grad 1.57 | tok/s 11163
step    780 | loss 0.9843 | lr 3.00e-04 | grad 1.59 | tok/s 11145
step    790 | loss 1.1089 | lr 3.00e-04 | grad 2.50 | tok/s 10780
step    800 | loss 1.7892 | lr 3.00e-04 | grad 4.38 | tok/s 10725
step    810 | loss 1.6801 | lr 3.00e-04 | grad 1.59 | tok/s 10681
step    820 | loss 1.6782 | lr 3.00e-04 | grad 2.98 | tok/s 10252
step    830 | loss 1.4768 | lr 3.00e-04 | grad 1.83 | tok/s 11002
step    840 | loss 1.3662 | lr 3.00e-04 | grad 1.71 | tok/s 10634
step    850 | loss 1.5632 | lr 3.00e-04 | grad 1.53 | tok/s 11105
step    860 | loss 1.4529 | lr 3.00e-04 | grad 2.70 | tok/s 11012
step    870 | loss 1.4820 | lr 3.00e-04 | grad 2.05 | tok/s 10610
step    880 | loss 1.6372 | lr 3.00e-04 | grad 1.84 | tok/s 10634
step    890 | loss 1.6549 | lr 3.00e-04 | grad 2.25 | tok/s 10787
step    900 | loss 1.5337 | lr 3.00e-04 | grad 1.98 | tok/s 10768
step    910 | loss 1.4054 | lr 3.00e-04 | grad 2.97 | tok/s 10555
step    920 | loss 1.4932 | lr 3.00e-04 | grad 2.77 | tok/s 10982
step    930 | loss 1.5726 | lr 3.00e-04 | grad 2.67 | tok/s 10466
step    940 | loss 1.3692 | lr 3.00e-04 | grad 1.38 | tok/s 11026
step    950 | loss 1.4574 | lr 3.00e-04 | grad 2.14 | tok/s 11107
step    960 | loss 1.3059 | lr 3.00e-04 | grad 1.86 | tok/s 11108
step    970 | loss 1.7029 | lr 3.00e-04 | grad 2.80 | tok/s 10439
step    980 | loss 1.6140 | lr 3.00e-04 | grad 1.78 | tok/s 10713
step    990 | loss 1.4304 | lr 3.00e-04 | grad 1.59 | tok/s 10910
step   1000 | loss 1.8068 | lr 3.00e-04 | grad 6.81 | tok/s 10468
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8068.pt
step   1010 | loss 1.6919 | lr 3.00e-04 | grad 1.82 | tok/s 4868
step   1020 | loss 1.6503 | lr 3.00e-04 | grad 1.90 | tok/s 10327
step   1030 | loss 1.3944 | lr 3.00e-04 | grad 1.36 | tok/s 10520
step   1040 | loss 1.5011 | lr 3.00e-04 | grad 3.03 | tok/s 10959
step   1050 | loss 1.5751 | lr 3.00e-04 | grad 1.69 | tok/s 10299
step   1060 | loss 1.6663 | lr 3.00e-04 | grad 1.73 | tok/s 11006
step   1070 | loss 1.6344 | lr 3.00e-04 | grad 2.66 | tok/s 10856
step   1080 | loss 1.3808 | lr 3.00e-04 | grad 1.95 | tok/s 10000
step   1090 | loss 0.9818 | lr 3.00e-04 | grad 0.98 | tok/s 11088
step   1100 | loss 1.5240 | lr 3.00e-04 | grad 2.19 | tok/s 10642
step   1110 | loss 1.4010 | lr 3.00e-04 | grad 1.38 | tok/s 11180
step   1120 | loss 1.3158 | lr 3.00e-04 | grad 1.64 | tok/s 11170
step   1130 | loss 1.2654 | lr 3.00e-04 | grad 1.53 | tok/s 11170
step   1140 | loss 1.2700 | lr 3.00e-04 | grad 1.41 | tok/s 11138
step   1150 | loss 1.2749 | lr 3.00e-04 | grad 1.49 | tok/s 11176
step   1160 | loss 1.2001 | lr 3.00e-04 | grad 1.48 | tok/s 11158
step   1170 | loss 1.2387 | lr 3.00e-04 | grad 1.61 | tok/s 10723
step   1180 | loss 1.2972 | lr 3.00e-04 | grad 1.33 | tok/s 11171
step   1190 | loss 1.1985 | lr 3.00e-04 | grad 1.59 | tok/s 11160
step   1200 | loss 1.2032 | lr 3.00e-04 | grad 1.46 | tok/s 11178
step   1210 | loss 1.2435 | lr 3.00e-04 | grad 1.33 | tok/s 11175
step   1220 | loss 1.2604 | lr 3.00e-04 | grad 1.32 | tok/s 11150
step   1230 | loss 1.2336 | lr 3.00e-04 | grad 1.30 | tok/s 11145
step   1240 | loss 1.2377 | lr 3.00e-04 | grad 2.28 | tok/s 11051
step   1250 | loss 1.7139 | lr 3.00e-04 | grad 1.94 | tok/s 10560
step   1260 | loss 1.2843 | lr 3.00e-04 | grad 2.23 | tok/s 10417
step   1270 | loss 1.7292 | lr 3.00e-04 | grad 2.33 | tok/s 10391
step   1280 | loss 1.5374 | lr 3.00e-04 | grad 1.73 | tok/s 10850
step   1290 | loss 1.4647 | lr 3.00e-04 | grad 2.08 | tok/s 10670
step   1300 | loss 1.4914 | lr 3.00e-04 | grad 1.73 | tok/s 10562
step   1310 | loss 1.4315 | lr 3.00e-04 | grad 1.52 | tok/s 11090
step   1320 | loss 1.5554 | lr 3.00e-04 | grad 1.81 | tok/s 10929
step   1330 | loss 1.4856 | lr 3.00e-04 | grad 1.62 | tok/s 10932
step   1340 | loss 1.5489 | lr 3.00e-04 | grad 2.56 | tok/s 10313
step   1350 | loss 1.6687 | lr 3.00e-04 | grad 1.79 | tok/s 10195
step   1360 | loss 1.4549 | lr 3.00e-04 | grad 1.40 | tok/s 10729
step   1370 | loss 1.4599 | lr 3.00e-04 | grad 4.91 | tok/s 10602
step   1380 | loss 1.5427 | lr 3.00e-04 | grad 2.09 | tok/s 10107
step   1390 | loss 1.4473 | lr 3.00e-04 | grad 2.22 | tok/s 10672
step   1400 | loss 1.3409 | lr 3.00e-04 | grad 1.24 | tok/s 10432
step   1410 | loss 1.4838 | lr 3.00e-04 | grad 5.56 | tok/s 10444
step   1420 | loss 1.5850 | lr 3.00e-04 | grad 1.90 | tok/s 10402
step   1430 | loss 1.3214 | lr 3.00e-04 | grad 1.70 | tok/s 10611
step   1440 | loss 1.1133 | lr 3.00e-04 | grad 1.52 | tok/s 11151
step   1450 | loss 1.1416 | lr 3.00e-04 | grad 1.88 | tok/s 11010
step   1460 | loss 1.6332 | lr 3.00e-04 | grad 1.76 | tok/s 10412
step   1470 | loss 1.4864 | lr 3.00e-04 | grad 1.55 | tok/s 10990
step   1480 | loss 1.7810 | lr 3.00e-04 | grad 2.69 | tok/s 10894
step   1490 | loss 1.5162 | lr 3.00e-04 | grad 2.03 | tok/s 11116
step   1500 | loss 1.2771 | lr 3.00e-04 | grad 1.55 | tok/s 11106
step   1510 | loss 1.4927 | lr 3.00e-04 | grad 2.20 | tok/s 10990
step   1520 | loss 1.4057 | lr 3.00e-04 | grad 2.00 | tok/s 10778
step   1530 | loss 1.4017 | lr 3.00e-04 | grad 2.12 | tok/s 11021
step   1540 | loss 1.5753 | lr 3.00e-04 | grad 2.02 | tok/s 10374
step   1550 | loss 1.2471 | lr 3.00e-04 | grad 2.00 | tok/s 11051
step   1560 | loss 1.5552 | lr 3.00e-04 | grad 1.56 | tok/s 10489
step   1570 | loss 1.2521 | lr 3.00e-04 | grad 1.83 | tok/s 11037
step   1580 | loss 1.6604 | lr 3.00e-04 | grad 3.50 | tok/s 10985
step   1590 | loss 1.5427 | lr 3.00e-04 | grad 1.73 | tok/s 10451

Training complete! Final step: 1594
