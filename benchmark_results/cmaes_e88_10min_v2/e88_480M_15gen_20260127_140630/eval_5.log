Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_5/levelE88_100m_20260127_140636
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 489,774,848 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 3.9497 | lr 3.00e-04 | grad 2.45 | tok/s 3028
step     20 | loss 2.6067 | lr 3.00e-04 | grad 1.87 | tok/s 4137
step     30 | loss 2.5100 | lr 3.00e-04 | grad 0.78 | tok/s 4171
step     40 | loss 2.3222 | lr 3.00e-04 | grad 1.11 | tok/s 3979
step     50 | loss 2.8062 | lr 3.00e-04 | grad 4.91 | tok/s 4021
step     60 | loss 2.1414 | lr 3.00e-04 | grad 4.59 | tok/s 4137
step     70 | loss 2.0337 | lr 3.00e-04 | grad 1.59 | tok/s 4159
step     80 | loss 4.4986 | lr 3.00e-04 | grad 13.38 | tok/s 4187
step     90 | loss 4.2676 | lr 3.00e-04 | grad 2.53 | tok/s 4248
step    100 | loss 3.4072 | lr 3.00e-04 | grad 6.03 | tok/s 4239
step    110 | loss 2.9788 | lr 3.00e-04 | grad 1.71 | tok/s 4223
step    120 | loss 2.7554 | lr 3.00e-04 | grad 4.41 | tok/s 4213
step    130 | loss 2.4413 | lr 3.00e-04 | grad 2.77 | tok/s 4208
step    140 | loss 2.4429 | lr 3.00e-04 | grad 1.88 | tok/s 4205
step    150 | loss 2.1924 | lr 3.00e-04 | grad 1.90 | tok/s 4194
step    160 | loss 2.2958 | lr 3.00e-04 | grad 1.36 | tok/s 4198
step    170 | loss 2.0723 | lr 3.00e-04 | grad 1.43 | tok/s 4203
step    180 | loss 2.1359 | lr 3.00e-04 | grad 1.38 | tok/s 4202
step    190 | loss 1.9378 | lr 3.00e-04 | grad 1.57 | tok/s 4202
step    200 | loss 2.0169 | lr 3.00e-04 | grad 1.02 | tok/s 4203
step    210 | loss 2.0713 | lr 3.00e-04 | grad 1.72 | tok/s 4150
step    220 | loss 2.6284 | lr 3.00e-04 | grad 0.95 | tok/s 4070
step    230 | loss 2.2374 | lr 3.00e-04 | grad 0.96 | tok/s 3962
step    240 | loss 1.8645 | lr 3.00e-04 | grad 1.16 | tok/s 4161
step    250 | loss 2.0417 | lr 3.00e-04 | grad 1.82 | tok/s 4005
step    260 | loss 2.2643 | lr 3.00e-04 | grad 1.34 | tok/s 4115
step    270 | loss 1.8774 | lr 3.00e-04 | grad 1.72 | tok/s 4086
step    280 | loss 0.7324 | lr 3.00e-04 | grad 1.39 | tok/s 4203
step    290 | loss 2.4983 | lr 3.00e-04 | grad 2.66 | tok/s 4138
step    300 | loss 2.0602 | lr 3.00e-04 | grad 1.43 | tok/s 3984
step    310 | loss 2.2154 | lr 3.00e-04 | grad 3.62 | tok/s 3957
step    320 | loss 1.8550 | lr 3.00e-04 | grad 1.14 | tok/s 3896
step    330 | loss 1.7437 | lr 3.00e-04 | grad 3.20 | tok/s 4180
step    340 | loss 1.8527 | lr 3.00e-04 | grad 1.47 | tok/s 3831
step    350 | loss 1.7938 | lr 3.00e-04 | grad 1.36 | tok/s 3945
step    360 | loss 1.6360 | lr 3.00e-04 | grad 1.36 | tok/s 4203
step    370 | loss 1.5540 | lr 3.00e-04 | grad 1.20 | tok/s 4164
step    380 | loss 1.4367 | lr 3.00e-04 | grad 1.58 | tok/s 4064
step    390 | loss 1.9977 | lr 3.00e-04 | grad 3.02 | tok/s 3958
step    400 | loss 2.1521 | lr 3.00e-04 | grad 1.68 | tok/s 4034
step    410 | loss 1.9280 | lr 3.00e-04 | grad 1.89 | tok/s 3989
step    420 | loss 1.8992 | lr 3.00e-04 | grad 1.91 | tok/s 3937
step    430 | loss 1.8437 | lr 3.00e-04 | grad 1.46 | tok/s 4008
step    440 | loss 2.0468 | lr 3.00e-04 | grad 2.64 | tok/s 4087
step    450 | loss 1.8606 | lr 3.00e-04 | grad 1.17 | tok/s 3876
step    460 | loss 1.7041 | lr 3.00e-04 | grad 1.67 | tok/s 4115
step    470 | loss 1.7285 | lr 3.00e-04 | grad 1.03 | tok/s 4180
step    480 | loss 1.7647 | lr 3.00e-04 | grad 2.59 | tok/s 4119
step    490 | loss 1.8364 | lr 3.00e-04 | grad 1.32 | tok/s 4061
step    500 | loss 1.6207 | lr 3.00e-04 | grad 1.10 | tok/s 4089
step    510 | loss 1.6203 | lr 3.00e-04 | grad 1.70 | tok/s 3626
step    520 | loss 1.7180 | lr 3.00e-04 | grad 1.23 | tok/s 3975
step    530 | loss 1.6117 | lr 3.00e-04 | grad 1.16 | tok/s 3944
step    540 | loss 1.7200 | lr 3.00e-04 | grad 2.22 | tok/s 3928
step    550 | loss 1.9094 | lr 3.00e-04 | grad 1.43 | tok/s 3873
step    560 | loss 1.6323 | lr 3.00e-04 | grad 1.21 | tok/s 4076
step    570 | loss 1.5704 | lr 3.00e-04 | grad 1.14 | tok/s 3918
step    580 | loss 1.5969 | lr 3.00e-04 | grad 1.41 | tok/s 3907
step    590 | loss 1.8930 | lr 3.00e-04 | grad 1.28 | tok/s 3961
step    600 | loss 1.6925 | lr 3.00e-04 | grad 1.20 | tok/s 4090
step    610 | loss 1.5995 | lr 3.00e-04 | grad 1.46 | tok/s 4080

Training complete! Final step: 612
