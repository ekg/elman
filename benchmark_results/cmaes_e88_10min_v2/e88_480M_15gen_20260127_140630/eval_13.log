Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_13/levelE88_100m_20260127_141655
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 463,170,624 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.8584 | lr 3.00e-04 | grad 9.62 | tok/s 5846
step     20 | loss 2.9658 | lr 3.00e-04 | grad 29.12 | tok/s 7609
step     30 | loss 3.0759 | lr 3.00e-04 | grad 3.33 | tok/s 8132
step     40 | loss 4.6731 | lr 3.00e-04 | grad 37.75 | tok/s 8116
step     50 | loss 4.7998 | lr 3.00e-04 | grad 31.62 | tok/s 8216
step     60 | loss 4.4938 | lr 3.00e-04 | grad 30.88 | tok/s 8179
step     70 | loss 3.6918 | lr 3.00e-04 | grad 20.50 | tok/s 8075
step     80 | loss 3.4980 | lr 3.00e-04 | grad 3.81 | tok/s 8172
step     90 | loss 2.7540 | lr 3.00e-04 | grad 1.84 | tok/s 7832
step    100 | loss 2.6445 | lr 3.00e-04 | grad 7.31 | tok/s 7803
step    110 | loss 2.3730 | lr 3.00e-04 | grad 1.38 | tok/s 7934
step    120 | loss 2.7164 | lr 3.00e-04 | grad 2.64 | tok/s 7820
step    130 | loss 2.1811 | lr 3.00e-04 | grad 2.17 | tok/s 7964
step    140 | loss 2.2400 | lr 3.00e-04 | grad 2.53 | tok/s 7631
step    150 | loss 2.4108 | lr 3.00e-04 | grad 5.34 | tok/s 7587
step    160 | loss 2.1342 | lr 3.00e-04 | grad 1.79 | tok/s 7851
step    170 | loss 1.9988 | lr 3.00e-04 | grad 1.13 | tok/s 7600
step    180 | loss 2.1476 | lr 3.00e-04 | grad 3.28 | tok/s 7716
step    190 | loss 1.9695 | lr 3.00e-04 | grad 1.66 | tok/s 7699
step    200 | loss 2.2195 | lr 3.00e-04 | grad 6.66 | tok/s 7807
step    210 | loss 2.2219 | lr 3.00e-04 | grad 1.30 | tok/s 8044
step    220 | loss 1.8217 | lr 3.00e-04 | grad 1.61 | tok/s 7978
step    230 | loss 1.5521 | lr 3.00e-04 | grad 1.36 | tok/s 8021
step    240 | loss 1.9661 | lr 3.00e-04 | grad 1.52 | tok/s 7719
step    250 | loss 2.0304 | lr 3.00e-04 | grad 1.64 | tok/s 8085
step    260 | loss 1.9470 | lr 3.00e-04 | grad 1.63 | tok/s 7841
step    270 | loss 1.8014 | lr 3.00e-04 | grad 1.57 | tok/s 7879
step    280 | loss 1.9327 | lr 3.00e-04 | grad 2.16 | tok/s 8127
step    290 | loss 1.7793 | lr 3.00e-04 | grad 1.23 | tok/s 7830
step    300 | loss 1.9388 | lr 3.00e-04 | grad 1.41 | tok/s 7611
step    310 | loss 1.6834 | lr 3.00e-04 | grad 1.57 | tok/s 7816
step    320 | loss 1.9253 | lr 3.00e-04 | grad 1.77 | tok/s 7971
step    330 | loss 1.4146 | lr 3.00e-04 | grad 2.42 | tok/s 7852
step    340 | loss 1.5830 | lr 3.00e-04 | grad 1.33 | tok/s 8212
step    350 | loss 1.5045 | lr 3.00e-04 | grad 1.22 | tok/s 8213
step    360 | loss 1.4352 | lr 3.00e-04 | grad 1.62 | tok/s 8201
step    370 | loss 1.3785 | lr 3.00e-04 | grad 1.09 | tok/s 8213
step    380 | loss 1.4023 | lr 3.00e-04 | grad 2.02 | tok/s 8127
step    390 | loss 1.7477 | lr 3.00e-04 | grad 1.70 | tok/s 7892
step    400 | loss 1.6995 | lr 3.00e-04 | grad 2.39 | tok/s 7806
step    410 | loss 1.6624 | lr 3.00e-04 | grad 2.05 | tok/s 7812
step    420 | loss 1.6885 | lr 3.00e-04 | grad 1.15 | tok/s 8011
step    430 | loss 1.6783 | lr 3.00e-04 | grad 2.12 | tok/s 7828
step    440 | loss 1.6582 | lr 3.00e-04 | grad 1.98 | tok/s 7624
step    450 | loss 1.6323 | lr 3.00e-04 | grad 1.55 | tok/s 7845
step    460 | loss 1.6723 | lr 3.00e-04 | grad 1.57 | tok/s 7746
step    470 | loss 1.5639 | lr 3.00e-04 | grad 1.50 | tok/s 7814
step    480 | loss 1.9598 | lr 3.00e-04 | grad 2.06 | tok/s 8158
step    490 | loss 1.5410 | lr 3.00e-04 | grad 1.26 | tok/s 8130
step    500 | loss 1.6266 | lr 3.00e-04 | grad 1.27 | tok/s 7949
step    510 | loss 1.8973 | lr 3.00e-04 | grad 3.34 | tok/s 8068
step    520 | loss 1.3088 | lr 3.00e-04 | grad 1.58 | tok/s 7611
step    530 | loss 1.5814 | lr 3.00e-04 | grad 1.00 | tok/s 7653
step    540 | loss 1.7059 | lr 3.00e-04 | grad 2.05 | tok/s 7721
step    550 | loss 1.6236 | lr 3.00e-04 | grad 3.66 | tok/s 7911
step    560 | loss 1.7790 | lr 3.00e-04 | grad 1.93 | tok/s 8116
step    570 | loss 1.6534 | lr 3.00e-04 | grad 1.80 | tok/s 8023
step    580 | loss 1.5935 | lr 3.00e-04 | grad 2.20 | tok/s 7895
step    590 | loss 1.5717 | lr 3.00e-04 | grad 2.27 | tok/s 7848

Training complete! Final step: 593
