Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_58/levelE88_100m_20260127_151924
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 483,384,244 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0105 | lr 3.00e-04 | grad 10.69 | tok/s 5366
step     20 | loss 2.6530 | lr 3.00e-04 | grad 4.44 | tok/s 13896
step     30 | loss 2.4697 | lr 3.00e-04 | grad 3.09 | tok/s 14124
step     40 | loss 2.3481 | lr 3.00e-04 | grad 3.72 | tok/s 13508
step     50 | loss 2.9187 | lr 3.00e-04 | grad 10.75 | tok/s 13725
step     60 | loss 2.0104 | lr 3.00e-04 | grad 2.89 | tok/s 14108
step     70 | loss 1.8786 | lr 3.00e-04 | grad 3.95 | tok/s 14352
step     80 | loss 5.5550 | lr 3.00e-04 | grad 45.00 | tok/s 14276
step     90 | loss 5.0396 | lr 3.00e-04 | grad 7.84 | tok/s 14542
step    100 | loss 4.0266 | lr 3.00e-04 | grad 7.00 | tok/s 14452
step    110 | loss 3.4380 | lr 3.00e-04 | grad 8.56 | tok/s 14470
step    120 | loss 3.0811 | lr 3.00e-04 | grad 9.50 | tok/s 14544
step    130 | loss 2.8095 | lr 3.00e-04 | grad 10.38 | tok/s 14430
step    140 | loss 2.5667 | lr 3.00e-04 | grad 7.00 | tok/s 14470
step    150 | loss 2.5560 | lr 3.00e-04 | grad 7.41 | tok/s 14362
step    160 | loss 2.2157 | lr 3.00e-04 | grad 7.12 | tok/s 14381
step    170 | loss 2.2863 | lr 3.00e-04 | grad 8.50 | tok/s 14545
step    180 | loss 2.1011 | lr 3.00e-04 | grad 3.72 | tok/s 14404
step    190 | loss 2.2379 | lr 3.00e-04 | grad 3.59 | tok/s 14373
step    200 | loss 1.9791 | lr 3.00e-04 | grad 3.84 | tok/s 14338
step    210 | loss 1.9815 | lr 3.00e-04 | grad 4.50 | tok/s 14324
step    220 | loss 2.1051 | lr 3.00e-04 | grad 2.62 | tok/s 14261
step    230 | loss 2.0212 | lr 3.00e-04 | grad 4.66 | tok/s 14025
step    240 | loss 2.2704 | lr 3.00e-04 | grad 3.58 | tok/s 13354
step    250 | loss 2.0782 | lr 3.00e-04 | grad 2.05 | tok/s 13456
step    260 | loss 1.5522 | lr 3.00e-04 | grad 2.30 | tok/s 14063
step    270 | loss 2.0492 | lr 3.00e-04 | grad 2.17 | tok/s 13999
step    280 | loss 2.2278 | lr 3.00e-04 | grad 4.50 | tok/s 13666
step    290 | loss 1.3634 | lr 3.00e-04 | grad 2.06 | tok/s 14342
step    300 | loss 0.5608 | lr 3.00e-04 | grad 2.33 | tok/s 14337
step    310 | loss 2.3775 | lr 3.00e-04 | grad 2.88 | tok/s 14096
step    320 | loss 1.9265 | lr 3.00e-04 | grad 4.38 | tok/s 13892
step    330 | loss 1.9269 | lr 3.00e-04 | grad 2.28 | tok/s 13375
step    340 | loss 2.2542 | lr 3.00e-04 | grad 2.17 | tok/s 13388
step    350 | loss 1.8707 | lr 3.00e-04 | grad 3.83 | tok/s 13868
step    360 | loss 1.2100 | lr 3.00e-04 | grad 5.56 | tok/s 14214
step    370 | loss 1.8005 | lr 3.00e-04 | grad 2.11 | tok/s 12884
step    380 | loss 1.7520 | lr 3.00e-04 | grad 2.03 | tok/s 13782
step    390 | loss 1.5281 | lr 3.00e-04 | grad 1.64 | tok/s 14428
step    400 | loss 1.4813 | lr 3.00e-04 | grad 2.03 | tok/s 14268
step    410 | loss 1.2740 | lr 3.00e-04 | grad 1.59 | tok/s 13972
step    420 | loss 1.7949 | lr 3.00e-04 | grad 3.42 | tok/s 13291
step    430 | loss 2.1321 | lr 3.00e-04 | grad 2.38 | tok/s 14138
step    440 | loss 2.1267 | lr 3.00e-04 | grad 3.33 | tok/s 13369
step    450 | loss 1.9180 | lr 3.00e-04 | grad 2.14 | tok/s 13923
step    460 | loss 1.7023 | lr 3.00e-04 | grad 2.47 | tok/s 13528
step    470 | loss 1.8098 | lr 3.00e-04 | grad 1.87 | tok/s 13900
step    480 | loss 2.2204 | lr 3.00e-04 | grad 5.31 | tok/s 13937
step    490 | loss 1.7714 | lr 3.00e-04 | grad 1.91 | tok/s 13171
step    500 | loss 1.6680 | lr 3.00e-04 | grad 2.70 | tok/s 14125
step    510 | loss 1.6965 | lr 3.00e-04 | grad 1.84 | tok/s 14399
step    520 | loss 1.6482 | lr 3.00e-04 | grad 1.67 | tok/s 14285
step    530 | loss 1.9001 | lr 3.00e-04 | grad 2.00 | tok/s 13657
step    540 | loss 1.6481 | lr 3.00e-04 | grad 1.91 | tok/s 10569
step    550 | loss 1.5751 | lr 3.00e-04 | grad 2.16 | tok/s 13231
step    560 | loss 1.7064 | lr 3.00e-04 | grad 3.16 | tok/s 13060
step    570 | loss 1.6168 | lr 3.00e-04 | grad 2.88 | tok/s 13591
step    580 | loss 1.5382 | lr 3.00e-04 | grad 1.74 | tok/s 13296
step    590 | loss 1.8624 | lr 3.00e-04 | grad 2.23 | tok/s 13797
step    600 | loss 1.7906 | lr 3.00e-04 | grad 1.66 | tok/s 13250
step    610 | loss 1.5904 | lr 3.00e-04 | grad 1.87 | tok/s 13515
step    620 | loss 1.5742 | lr 3.00e-04 | grad 1.83 | tok/s 13509
step    630 | loss 1.6149 | lr 3.00e-04 | grad 2.22 | tok/s 13349
step    640 | loss 1.8780 | lr 3.00e-04 | grad 5.19 | tok/s 13501
step    650 | loss 1.6106 | lr 3.00e-04 | grad 2.53 | tok/s 13895
step    660 | loss 1.6889 | lr 3.00e-04 | grad 2.50 | tok/s 13972
step    670 | loss 1.9108 | lr 3.00e-04 | grad 2.66 | tok/s 12527
step    680 | loss 1.7078 | lr 3.00e-04 | grad 2.48 | tok/s 13434
step    690 | loss 1.7681 | lr 3.00e-04 | grad 2.27 | tok/s 14204
step    700 | loss 1.4035 | lr 3.00e-04 | grad 2.02 | tok/s 12723
step    710 | loss 1.6000 | lr 3.00e-04 | grad 2.86 | tok/s 13164
step    720 | loss 1.4796 | lr 3.00e-04 | grad 2.30 | tok/s 13463
step    730 | loss 1.2834 | lr 3.00e-04 | grad 2.47 | tok/s 14370
step    740 | loss 1.4356 | lr 3.00e-04 | grad 1.81 | tok/s 14159
step    750 | loss 1.2032 | lr 3.00e-04 | grad 1.59 | tok/s 14386
step    760 | loss 1.0936 | lr 3.00e-04 | grad 1.48 | tok/s 14368
step    770 | loss 1.0613 | lr 3.00e-04 | grad 1.67 | tok/s 14332
step    780 | loss 0.9652 | lr 3.00e-04 | grad 1.59 | tok/s 14350
step    790 | loss 1.1717 | lr 3.00e-04 | grad 2.30 | tok/s 13725
step    800 | loss 1.8733 | lr 3.00e-04 | grad 4.41 | tok/s 13991
step    810 | loss 1.6512 | lr 3.00e-04 | grad 4.44 | tok/s 13534
step    820 | loss 1.6605 | lr 3.00e-04 | grad 7.25 | tok/s 13424
step    830 | loss 1.4332 | lr 3.00e-04 | grad 1.92 | tok/s 14263
step    840 | loss 1.4287 | lr 3.00e-04 | grad 3.38 | tok/s 14507
step    850 | loss 1.5369 | lr 3.00e-04 | grad 3.27 | tok/s 14315
step    860 | loss 1.4582 | lr 3.00e-04 | grad 2.31 | tok/s 14195
step    870 | loss 1.4903 | lr 3.00e-04 | grad 1.91 | tok/s 13784
step    880 | loss 1.6737 | lr 3.00e-04 | grad 2.33 | tok/s 10642
step    890 | loss 1.6502 | lr 3.00e-04 | grad 5.16 | tok/s 13810
step    900 | loss 1.4962 | lr 3.00e-04 | grad 1.87 | tok/s 13783
step    910 | loss 1.4026 | lr 3.00e-04 | grad 2.42 | tok/s 13615
step    920 | loss 1.5796 | lr 3.00e-04 | grad 2.45 | tok/s 14097
step    930 | loss 1.4986 | lr 3.00e-04 | grad 2.84 | tok/s 13380
step    940 | loss 1.3216 | lr 3.00e-04 | grad 1.55 | tok/s 14293
step    950 | loss 1.4799 | lr 3.00e-04 | grad 1.61 | tok/s 14376
step    960 | loss 1.4017 | lr 3.00e-04 | grad 2.59 | tok/s 14258
step    970 | loss 1.7932 | lr 3.00e-04 | grad 2.66 | tok/s 13556
step    980 | loss 1.5378 | lr 3.00e-04 | grad 2.31 | tok/s 13634
step    990 | loss 1.5400 | lr 3.00e-04 | grad 3.39 | tok/s 14031
step   1000 | loss 1.7321 | lr 3.00e-04 | grad 2.25 | tok/s 13716
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7321.pt
step   1010 | loss 1.6412 | lr 3.00e-04 | grad 1.78 | tok/s 3021
step   1020 | loss 1.4542 | lr 3.00e-04 | grad 1.78 | tok/s 13919
step   1030 | loss 1.4552 | lr 3.00e-04 | grad 2.72 | tok/s 14322
step   1040 | loss 1.4897 | lr 3.00e-04 | grad 2.05 | tok/s 13241
step   1050 | loss 1.7168 | lr 3.00e-04 | grad 3.38 | tok/s 14289
step   1060 | loss 1.6729 | lr 3.00e-04 | grad 2.05 | tok/s 14387
step   1070 | loss 1.4640 | lr 3.00e-04 | grad 1.45 | tok/s 13370
step   1080 | loss 1.2476 | lr 3.00e-04 | grad 4.31 | tok/s 13572
step   1090 | loss 1.1970 | lr 3.00e-04 | grad 2.14 | tok/s 13859
step   1100 | loss 1.5162 | lr 3.00e-04 | grad 1.60 | tok/s 14610
step   1110 | loss 1.3343 | lr 3.00e-04 | grad 1.71 | tok/s 14636
step   1120 | loss 1.2870 | lr 3.00e-04 | grad 1.75 | tok/s 14576
step   1130 | loss 1.2470 | lr 3.00e-04 | grad 1.46 | tok/s 14505
step   1140 | loss 1.3094 | lr 3.00e-04 | grad 1.72 | tok/s 14490
step   1150 | loss 1.2012 | lr 3.00e-04 | grad 1.57 | tok/s 14478
step   1160 | loss 1.2262 | lr 3.00e-04 | grad 1.53 | tok/s 14528
step   1170 | loss 1.3321 | lr 3.00e-04 | grad 1.82 | tok/s 14560
step   1180 | loss 1.2153 | lr 3.00e-04 | grad 1.62 | tok/s 12542
step   1190 | loss 1.1838 | lr 3.00e-04 | grad 1.65 | tok/s 14575
step   1200 | loss 1.2475 | lr 3.00e-04 | grad 1.44 | tok/s 14581
step   1210 | loss 1.2871 | lr 3.00e-04 | grad 1.53 | tok/s 14555
step   1220 | loss 1.2393 | lr 3.00e-04 | grad 1.98 | tok/s 14546
step   1230 | loss 1.2193 | lr 3.00e-04 | grad 1.37 | tok/s 14540
step   1240 | loss 1.6731 | lr 3.00e-04 | grad 2.86 | tok/s 13960
step   1250 | loss 1.5674 | lr 3.00e-04 | grad 11.88 | tok/s 13422
step   1260 | loss 1.3648 | lr 3.00e-04 | grad 1.70 | tok/s 14005
step   1270 | loss 1.7186 | lr 3.00e-04 | grad 1.74 | tok/s 13604
step   1280 | loss 1.4634 | lr 3.00e-04 | grad 2.03 | tok/s 14132
step   1290 | loss 1.4776 | lr 3.00e-04 | grad 2.23 | tok/s 14279
step   1300 | loss 1.4253 | lr 3.00e-04 | grad 1.67 | tok/s 13903
step   1310 | loss 1.5739 | lr 3.00e-04 | grad 2.16 | tok/s 14219
step   1320 | loss 1.6633 | lr 3.00e-04 | grad 2.81 | tok/s 14331
step   1330 | loss 1.2578 | lr 3.00e-04 | grad 1.83 | tok/s 13806
step   1340 | loss 1.8065 | lr 3.00e-04 | grad 2.91 | tok/s 13182
step   1350 | loss 1.4934 | lr 3.00e-04 | grad 1.79 | tok/s 13994
step   1360 | loss 1.4299 | lr 3.00e-04 | grad 1.70 | tok/s 13922
step   1370 | loss 1.5913 | lr 3.00e-04 | grad 2.34 | tok/s 13610
step   1380 | loss 1.4802 | lr 3.00e-04 | grad 1.95 | tok/s 13681
step   1390 | loss 1.4460 | lr 3.00e-04 | grad 2.11 | tok/s 13521
step   1400 | loss 1.3470 | lr 3.00e-04 | grad 1.94 | tok/s 13872
step   1410 | loss 1.6038 | lr 3.00e-04 | grad 2.05 | tok/s 13463
step   1420 | loss 1.3797 | lr 3.00e-04 | grad 2.19 | tok/s 14066
step   1430 | loss 1.2079 | lr 3.00e-04 | grad 1.42 | tok/s 13586
step   1440 | loss 1.0975 | lr 3.00e-04 | grad 1.51 | tok/s 14514
step   1450 | loss 1.6008 | lr 3.00e-04 | grad 2.05 | tok/s 13698
step   1460 | loss 1.5081 | lr 3.00e-04 | grad 1.63 | tok/s 14075
step   1470 | loss 1.7156 | lr 3.00e-04 | grad 6.97 | tok/s 14231
step   1480 | loss 1.6472 | lr 3.00e-04 | grad 2.03 | tok/s 14461
step   1490 | loss 1.3176 | lr 3.00e-04 | grad 1.66 | tok/s 14527
step   1500 | loss 1.4792 | lr 3.00e-04 | grad 2.75 | tok/s 14295
step   1510 | loss 1.3864 | lr 3.00e-04 | grad 1.82 | tok/s 14248
step   1520 | loss 1.4461 | lr 3.00e-04 | grad 1.95 | tok/s 14263
step   1530 | loss 1.4990 | lr 3.00e-04 | grad 1.80 | tok/s 13525
step   1540 | loss 1.3861 | lr 3.00e-04 | grad 2.20 | tok/s 14195
step   1550 | loss 1.5010 | lr 3.00e-04 | grad 2.81 | tok/s 13840
step   1560 | loss 1.3222 | lr 3.00e-04 | grad 1.51 | tok/s 14292
step   1570 | loss 1.5946 | lr 3.00e-04 | grad 4.19 | tok/s 14181
step   1580 | loss 1.6522 | lr 3.00e-04 | grad 3.62 | tok/s 13856
step   1590 | loss 1.1182 | lr 3.00e-04 | grad 1.54 | tok/s 14301
step   1600 | loss 0.8894 | lr 3.00e-04 | grad 1.67 | tok/s 14179
step   1610 | loss 1.3750 | lr 3.00e-04 | grad 3.22 | tok/s 13074
step   1620 | loss 1.3577 | lr 3.00e-04 | grad 1.70 | tok/s 14126
step   1630 | loss 1.2432 | lr 3.00e-04 | grad 2.05 | tok/s 14245
step   1640 | loss 1.5469 | lr 3.00e-04 | grad 1.95 | tok/s 13144
step   1650 | loss 1.4082 | lr 3.00e-04 | grad 1.51 | tok/s 13761
step   1660 | loss 1.2335 | lr 3.00e-04 | grad 2.84 | tok/s 14066
step   1670 | loss 1.7647 | lr 3.00e-04 | grad 1.95 | tok/s 13610
step   1680 | loss 1.4186 | lr 3.00e-04 | grad 1.65 | tok/s 13783
step   1690 | loss 1.4886 | lr 3.00e-04 | grad 2.08 | tok/s 13955
step   1700 | loss 1.4086 | lr 3.00e-04 | grad 2.94 | tok/s 13951
step   1710 | loss 1.5216 | lr 3.00e-04 | grad 3.00 | tok/s 14178
step   1720 | loss 1.2983 | lr 3.00e-04 | grad 2.33 | tok/s 14542
step   1730 | loss 1.2222 | lr 3.00e-04 | grad 2.30 | tok/s 14393
step   1740 | loss 1.5550 | lr 3.00e-04 | grad 3.95 | tok/s 13820
step   1750 | loss 1.4906 | lr 3.00e-04 | grad 3.30 | tok/s 13848
step   1760 | loss 1.4698 | lr 3.00e-04 | grad 1.90 | tok/s 14122
step   1770 | loss 1.4679 | lr 3.00e-04 | grad 1.55 | tok/s 13823
step   1780 | loss 1.4403 | lr 3.00e-04 | grad 2.16 | tok/s 13984
step   1790 | loss 1.4961 | lr 3.00e-04 | grad 3.41 | tok/s 13981
step   1800 | loss 1.4200 | lr 3.00e-04 | grad 2.38 | tok/s 13631
step   1810 | loss 1.4584 | lr 3.00e-04 | grad 2.20 | tok/s 13763
step   1820 | loss 1.4264 | lr 3.00e-04 | grad 1.94 | tok/s 14141
step   1830 | loss 1.5258 | lr 3.00e-04 | grad 1.90 | tok/s 13677
step   1840 | loss 1.3429 | lr 3.00e-04 | grad 1.92 | tok/s 14102
step   1850 | loss 1.2392 | lr 3.00e-04 | grad 1.55 | tok/s 14156
step   1860 | loss 1.4273 | lr 3.00e-04 | grad 1.58 | tok/s 13462
step   1870 | loss 1.1734 | lr 3.00e-04 | grad 2.78 | tok/s 13734
step   1880 | loss 1.4503 | lr 3.00e-04 | grad 2.09 | tok/s 12884
step   1890 | loss 1.4052 | lr 3.00e-04 | grad 1.53 | tok/s 13989
step   1900 | loss 1.4007 | lr 3.00e-04 | grad 1.59 | tok/s 13144
step   1910 | loss 1.4417 | lr 3.00e-04 | grad 1.84 | tok/s 14384
step   1920 | loss 1.3756 | lr 3.00e-04 | grad 2.00 | tok/s 13666
step   1930 | loss 1.4450 | lr 3.00e-04 | grad 1.81 | tok/s 14038
step   1940 | loss 1.8488 | lr 3.00e-04 | grad 3.50 | tok/s 14315
step   1950 | loss 1.4144 | lr 3.00e-04 | grad 2.56 | tok/s 14510
step   1960 | loss 1.5199 | lr 3.00e-04 | grad 1.98 | tok/s 14139
step   1970 | loss 1.4695 | lr 3.00e-04 | grad 1.73 | tok/s 13517
step   1980 | loss 1.4340 | lr 3.00e-04 | grad 3.92 | tok/s 13863
step   1990 | loss 1.6039 | lr 3.00e-04 | grad 1.77 | tok/s 14190
step   2000 | loss 1.2136 | lr 3.00e-04 | grad 3.44 | tok/s 13969
  >>> saved checkpoint: checkpoint_step_002000_loss_1.2136.pt
step   2010 | loss 1.2151 | lr 3.00e-04 | grad 2.30 | tok/s 4339

Training complete! Final step: 2012
