Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_76/levelE88_100m_20260127_154022
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 491,075,952 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 3.9603 | lr 3.00e-04 | grad 11.94 | tok/s 5245
step     20 | loss 2.8574 | lr 3.00e-04 | grad 6.25 | tok/s 14715
step     30 | loss 2.4932 | lr 3.00e-04 | grad 3.78 | tok/s 14668
step     40 | loss 2.3788 | lr 3.00e-04 | grad 9.75 | tok/s 13871
step     50 | loss 3.0816 | lr 3.00e-04 | grad 9.94 | tok/s 14530
step     60 | loss 1.9783 | lr 3.00e-04 | grad 3.89 | tok/s 14832
step     70 | loss 1.8320 | lr 3.00e-04 | grad 2.36 | tok/s 14937
step     80 | loss 5.9208 | lr 3.00e-04 | grad 56.25 | tok/s 15273
step     90 | loss 4.4889 | lr 3.00e-04 | grad 13.56 | tok/s 15309
step    100 | loss 3.8368 | lr 3.00e-04 | grad 18.12 | tok/s 15357
step    110 | loss 3.3254 | lr 3.00e-04 | grad 14.31 | tok/s 15293
step    120 | loss 2.9304 | lr 3.00e-04 | grad 19.25 | tok/s 15279
step    130 | loss 2.7467 | lr 3.00e-04 | grad 4.19 | tok/s 15258
step    140 | loss 2.6251 | lr 3.00e-04 | grad 10.38 | tok/s 15223
step    150 | loss 2.5000 | lr 3.00e-04 | grad 5.22 | tok/s 15247
step    160 | loss 2.2073 | lr 3.00e-04 | grad 4.97 | tok/s 15191
step    170 | loss 2.3370 | lr 3.00e-04 | grad 5.72 | tok/s 15179
step    180 | loss 2.0404 | lr 3.00e-04 | grad 3.38 | tok/s 15185
step    190 | loss 2.1768 | lr 3.00e-04 | grad 3.56 | tok/s 15172
step    200 | loss 1.9743 | lr 3.00e-04 | grad 2.86 | tok/s 15189
step    210 | loss 1.9812 | lr 3.00e-04 | grad 2.78 | tok/s 15160
step    220 | loss 2.0584 | lr 3.00e-04 | grad 2.61 | tok/s 14963
step    230 | loss 2.0509 | lr 3.00e-04 | grad 2.50 | tok/s 14692
step    240 | loss 2.2741 | lr 3.00e-04 | grad 3.02 | tok/s 14119
step    250 | loss 2.0235 | lr 3.00e-04 | grad 1.89 | tok/s 14444
step    260 | loss 1.5487 | lr 3.00e-04 | grad 2.70 | tok/s 14902
step    270 | loss 2.0275 | lr 3.00e-04 | grad 1.88 | tok/s 14545
step    280 | loss 2.4183 | lr 3.00e-04 | grad 10.38 | tok/s 14565
step    290 | loss 1.0888 | lr 3.00e-04 | grad 2.17 | tok/s 15097
step    300 | loss 0.7414 | lr 3.00e-04 | grad 3.70 | tok/s 14956
step    310 | loss 2.3461 | lr 3.00e-04 | grad 3.27 | tok/s 15043
step    320 | loss 1.9212 | lr 3.00e-04 | grad 3.03 | tok/s 14477
step    330 | loss 1.9422 | lr 3.00e-04 | grad 2.38 | tok/s 14165
step    340 | loss 2.2434 | lr 3.00e-04 | grad 2.25 | tok/s 14307
step    350 | loss 1.7894 | lr 3.00e-04 | grad 4.59 | tok/s 14624
step    360 | loss 1.2541 | lr 3.00e-04 | grad 4.06 | tok/s 14990
step    370 | loss 1.7820 | lr 3.00e-04 | grad 2.38 | tok/s 13462
step    380 | loss 1.7493 | lr 3.00e-04 | grad 2.25 | tok/s 14620
step    390 | loss 1.5108 | lr 3.00e-04 | grad 1.93 | tok/s 15094
step    400 | loss 1.4859 | lr 3.00e-04 | grad 2.78 | tok/s 14989
step    410 | loss 1.2927 | lr 3.00e-04 | grad 2.72 | tok/s 14626
step    420 | loss 1.9187 | lr 3.00e-04 | grad 10.75 | tok/s 14032
step    430 | loss 2.0019 | lr 3.00e-04 | grad 1.92 | tok/s 14723
step    440 | loss 2.1643 | lr 3.00e-04 | grad 4.84 | tok/s 14222
step    450 | loss 1.8734 | lr 3.00e-04 | grad 1.77 | tok/s 14426
step    460 | loss 1.6399 | lr 3.00e-04 | grad 2.86 | tok/s 14348
step    470 | loss 1.8622 | lr 3.00e-04 | grad 2.47 | tok/s 14619
step    480 | loss 2.2719 | lr 3.00e-04 | grad 3.91 | tok/s 14755
step    490 | loss 1.7155 | lr 3.00e-04 | grad 1.98 | tok/s 13920
step    500 | loss 1.7017 | lr 3.00e-04 | grad 2.36 | tok/s 14778
step    510 | loss 1.6608 | lr 3.00e-04 | grad 1.95 | tok/s 15047
step    520 | loss 1.6419 | lr 3.00e-04 | grad 1.96 | tok/s 14692
step    530 | loss 1.8992 | lr 3.00e-04 | grad 1.81 | tok/s 14586
step    540 | loss 1.7032 | lr 3.00e-04 | grad 2.03 | tok/s 14505
step    550 | loss 1.5685 | lr 3.00e-04 | grad 2.28 | tok/s 12570
step    560 | loss 1.7140 | lr 3.00e-04 | grad 3.20 | tok/s 13782
step    570 | loss 1.6173 | lr 3.00e-04 | grad 3.45 | tok/s 14290
step    580 | loss 1.5382 | lr 3.00e-04 | grad 1.80 | tok/s 13949
step    590 | loss 1.8529 | lr 3.00e-04 | grad 2.38 | tok/s 14449
step    600 | loss 1.7803 | lr 3.00e-04 | grad 1.68 | tok/s 14006
step    610 | loss 1.5851 | lr 3.00e-04 | grad 1.95 | tok/s 14301
step    620 | loss 1.5734 | lr 3.00e-04 | grad 1.89 | tok/s 14252
step    630 | loss 1.6226 | lr 3.00e-04 | grad 2.28 | tok/s 14002
step    640 | loss 1.8720 | lr 3.00e-04 | grad 5.59 | tok/s 14187
step    650 | loss 1.5990 | lr 3.00e-04 | grad 2.70 | tok/s 14560
step    660 | loss 1.6829 | lr 3.00e-04 | grad 2.61 | tok/s 14624
step    670 | loss 1.9128 | lr 3.00e-04 | grad 2.86 | tok/s 14655
step    680 | loss 1.6942 | lr 3.00e-04 | grad 2.62 | tok/s 14229
step    690 | loss 1.7499 | lr 3.00e-04 | grad 2.30 | tok/s 14927
step    700 | loss 1.3879 | lr 3.00e-04 | grad 2.19 | tok/s 15080
step    710 | loss 1.5941 | lr 3.00e-04 | grad 3.02 | tok/s 13823
step    720 | loss 1.4724 | lr 3.00e-04 | grad 2.41 | tok/s 14178
step    730 | loss 1.2746 | lr 3.00e-04 | grad 2.61 | tok/s 15084
step    740 | loss 1.4305 | lr 3.00e-04 | grad 1.86 | tok/s 14883
step    750 | loss 1.1926 | lr 3.00e-04 | grad 1.64 | tok/s 15111
step    760 | loss 1.0874 | lr 3.00e-04 | grad 1.53 | tok/s 15124
step    770 | loss 1.0505 | lr 3.00e-04 | grad 1.76 | tok/s 15130
step    780 | loss 0.9597 | lr 3.00e-04 | grad 1.55 | tok/s 15145
step    790 | loss 1.1647 | lr 3.00e-04 | grad 2.31 | tok/s 14494
step    800 | loss 1.8792 | lr 3.00e-04 | grad 4.69 | tok/s 14806
step    810 | loss 1.6448 | lr 3.00e-04 | grad 4.53 | tok/s 14328
step    820 | loss 1.6506 | lr 3.00e-04 | grad 7.59 | tok/s 14197
step    830 | loss 1.4440 | lr 3.00e-04 | grad 2.00 | tok/s 14977
step    840 | loss 1.4217 | lr 3.00e-04 | grad 3.50 | tok/s 15123
step    850 | loss 1.5307 | lr 3.00e-04 | grad 3.25 | tok/s 14894
step    860 | loss 1.4523 | lr 3.00e-04 | grad 2.30 | tok/s 14838
step    870 | loss 1.4786 | lr 3.00e-04 | grad 1.97 | tok/s 14540
step    880 | loss 1.6765 | lr 3.00e-04 | grad 2.41 | tok/s 14430
step    890 | loss 1.6086 | lr 3.00e-04 | grad 1.73 | tok/s 14471
step    900 | loss 1.5497 | lr 3.00e-04 | grad 1.66 | tok/s 13599
step    910 | loss 1.4116 | lr 3.00e-04 | grad 1.99 | tok/s 14622
step    920 | loss 1.5449 | lr 3.00e-04 | grad 3.23 | tok/s 14903
step    930 | loss 1.5303 | lr 3.00e-04 | grad 1.59 | tok/s 14085
step    940 | loss 1.3504 | lr 3.00e-04 | grad 1.81 | tok/s 15143
step    950 | loss 1.4828 | lr 3.00e-04 | grad 2.03 | tok/s 15070
step    960 | loss 1.3090 | lr 3.00e-04 | grad 1.92 | tok/s 14972
step    970 | loss 1.7929 | lr 3.00e-04 | grad 3.08 | tok/s 14269
step    980 | loss 1.5483 | lr 3.00e-04 | grad 2.06 | tok/s 14441
step    990 | loss 1.4524 | lr 3.00e-04 | grad 1.76 | tok/s 14889
step   1000 | loss 1.8337 | lr 3.00e-04 | grad 4.31 | tok/s 14308
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8337.pt
step   1010 | loss 1.6208 | lr 3.00e-04 | grad 2.59 | tok/s 4394
step   1020 | loss 1.5458 | lr 3.00e-04 | grad 2.16 | tok/s 13854
step   1030 | loss 1.3934 | lr 3.00e-04 | grad 2.23 | tok/s 15017
step   1040 | loss 1.4639 | lr 3.00e-04 | grad 2.14 | tok/s 14327
step   1050 | loss 1.6277 | lr 3.00e-04 | grad 1.91 | tok/s 14637
step   1060 | loss 1.6914 | lr 3.00e-04 | grad 2.27 | tok/s 15021
step   1070 | loss 1.5835 | lr 3.00e-04 | grad 2.14 | tok/s 14477
step   1080 | loss 1.3792 | lr 3.00e-04 | grad 1.78 | tok/s 13876
step   1090 | loss 1.0752 | lr 3.00e-04 | grad 3.00 | tok/s 14938
step   1100 | loss 1.5154 | lr 3.00e-04 | grad 1.70 | tok/s 14852
step   1110 | loss 1.3490 | lr 3.00e-04 | grad 1.44 | tok/s 15242
step   1120 | loss 1.3174 | lr 3.00e-04 | grad 1.84 | tok/s 15209
step   1130 | loss 1.2479 | lr 3.00e-04 | grad 1.67 | tok/s 15191
step   1140 | loss 1.2853 | lr 3.00e-04 | grad 1.73 | tok/s 15203
step   1150 | loss 1.2513 | lr 3.00e-04 | grad 1.67 | tok/s 13182
step   1160 | loss 1.1990 | lr 3.00e-04 | grad 1.70 | tok/s 15208
step   1170 | loss 1.2797 | lr 3.00e-04 | grad 1.48 | tok/s 15156
step   1180 | loss 1.2629 | lr 3.00e-04 | grad 1.73 | tok/s 15162
step   1190 | loss 1.1827 | lr 3.00e-04 | grad 2.03 | tok/s 15173
step   1200 | loss 1.2312 | lr 3.00e-04 | grad 1.66 | tok/s 15185
step   1210 | loss 1.2623 | lr 3.00e-04 | grad 1.45 | tok/s 15151
step   1220 | loss 1.2360 | lr 3.00e-04 | grad 1.73 | tok/s 15185
step   1230 | loss 1.2360 | lr 3.00e-04 | grad 1.53 | tok/s 15185
step   1240 | loss 1.4810 | lr 3.00e-04 | grad 5.12 | tok/s 14646
step   1250 | loss 1.5799 | lr 3.00e-04 | grad 2.09 | tok/s 14187
step   1260 | loss 1.5015 | lr 3.00e-04 | grad 2.08 | tok/s 14611
step   1270 | loss 1.6764 | lr 3.00e-04 | grad 3.38 | tok/s 14059
step   1280 | loss 1.4963 | lr 3.00e-04 | grad 1.80 | tok/s 14800
step   1290 | loss 1.4616 | lr 3.00e-04 | grad 1.89 | tok/s 14809
step   1300 | loss 1.4872 | lr 3.00e-04 | grad 2.42 | tok/s 14397
step   1310 | loss 1.4447 | lr 3.00e-04 | grad 2.05 | tok/s 14988
step   1320 | loss 1.6847 | lr 3.00e-04 | grad 2.34 | tok/s 14992
step   1330 | loss 1.3186 | lr 3.00e-04 | grad 2.06 | tok/s 14594
step   1340 | loss 1.6826 | lr 3.00e-04 | grad 5.00 | tok/s 13729
step   1350 | loss 1.6579 | lr 3.00e-04 | grad 2.20 | tok/s 14319
step   1360 | loss 1.3523 | lr 3.00e-04 | grad 2.11 | tok/s 14329
step   1370 | loss 1.5746 | lr 3.00e-04 | grad 2.75 | tok/s 14819
step   1380 | loss 1.4849 | lr 3.00e-04 | grad 1.79 | tok/s 13695
step   1390 | loss 1.4246 | lr 3.00e-04 | grad 1.94 | tok/s 14353
step   1400 | loss 1.3761 | lr 3.00e-04 | grad 2.77 | tok/s 14575
step   1410 | loss 1.5235 | lr 3.00e-04 | grad 2.95 | tok/s 14104
step   1420 | loss 1.5340 | lr 3.00e-04 | grad 2.09 | tok/s 14589
step   1430 | loss 1.2643 | lr 3.00e-04 | grad 1.83 | tok/s 14421
step   1440 | loss 1.1007 | lr 3.00e-04 | grad 1.59 | tok/s 15142
step   1450 | loss 1.3894 | lr 3.00e-04 | grad 2.64 | tok/s 14782
step   1460 | loss 1.5498 | lr 3.00e-04 | grad 1.65 | tok/s 14176
step   1470 | loss 1.4391 | lr 3.00e-04 | grad 2.27 | tok/s 14840
step   1480 | loss 1.8524 | lr 3.00e-04 | grad 5.19 | tok/s 15149
step   1490 | loss 1.4637 | lr 3.00e-04 | grad 2.08 | tok/s 15104
step   1500 | loss 1.2295 | lr 3.00e-04 | grad 1.95 | tok/s 14972
step   1510 | loss 1.5701 | lr 3.00e-04 | grad 1.81 | tok/s 15131
step   1520 | loss 1.4389 | lr 3.00e-04 | grad 1.83 | tok/s 14639
step   1530 | loss 1.4488 | lr 3.00e-04 | grad 4.62 | tok/s 14482
step   1540 | loss 1.5278 | lr 3.00e-04 | grad 1.69 | tok/s 14624
step   1550 | loss 1.2267 | lr 3.00e-04 | grad 2.53 | tok/s 14971
step   1560 | loss 1.5500 | lr 3.00e-04 | grad 1.59 | tok/s 14302
step   1570 | loss 1.3670 | lr 3.00e-04 | grad 2.05 | tok/s 14984
step   1580 | loss 1.6773 | lr 3.00e-04 | grad 3.12 | tok/s 14894
step   1590 | loss 1.3799 | lr 3.00e-04 | grad 1.45 | tok/s 14268
step   1600 | loss 0.7804 | lr 3.00e-04 | grad 1.96 | tok/s 15163
step   1610 | loss 1.2842 | lr 3.00e-04 | grad 1.52 | tok/s 13706
step   1620 | loss 1.4304 | lr 3.00e-04 | grad 3.53 | tok/s 14355
step   1630 | loss 1.1835 | lr 3.00e-04 | grad 1.47 | tok/s 14992
step   1640 | loss 1.5227 | lr 3.00e-04 | grad 1.77 | tok/s 14098
step   1650 | loss 1.5068 | lr 3.00e-04 | grad 1.59 | tok/s 13712
step   1660 | loss 1.1602 | lr 3.00e-04 | grad 1.57 | tok/s 15148
step   1670 | loss 1.7018 | lr 3.00e-04 | grad 2.89 | tok/s 14007
step   1680 | loss 1.4800 | lr 3.00e-04 | grad 2.41 | tok/s 14116
step   1690 | loss 1.4444 | lr 3.00e-04 | grad 3.84 | tok/s 14912
step   1700 | loss 1.4306 | lr 3.00e-04 | grad 2.16 | tok/s 14232
step   1710 | loss 1.3921 | lr 3.00e-04 | grad 1.88 | tok/s 14728
step   1720 | loss 1.4497 | lr 3.00e-04 | grad 1.81 | tok/s 15127
step   1730 | loss 1.1363 | lr 3.00e-04 | grad 1.86 | tok/s 15141
step   1740 | loss 1.4382 | lr 3.00e-04 | grad 2.20 | tok/s 14473
step   1750 | loss 1.5261 | lr 3.00e-04 | grad 1.90 | tok/s 14520
step   1760 | loss 1.5519 | lr 3.00e-04 | grad 1.91 | tok/s 13768
step   1770 | loss 1.4094 | lr 3.00e-04 | grad 1.93 | tok/s 14376
step   1780 | loss 1.4604 | lr 3.00e-04 | grad 1.94 | tok/s 14723
step   1790 | loss 1.4173 | lr 3.00e-04 | grad 2.09 | tok/s 14503
step   1800 | loss 1.5813 | lr 3.00e-04 | grad 2.33 | tok/s 14252
step   1810 | loss 1.3425 | lr 3.00e-04 | grad 1.94 | tok/s 14272
step   1820 | loss 1.4691 | lr 3.00e-04 | grad 2.73 | tok/s 14749
step   1830 | loss 1.4526 | lr 3.00e-04 | grad 2.44 | tok/s 14575
step   1840 | loss 1.4351 | lr 3.00e-04 | grad 2.20 | tok/s 14318
step   1850 | loss 1.2139 | lr 3.00e-04 | grad 2.11 | tok/s 14806
step   1860 | loss 1.4462 | lr 3.00e-04 | grad 2.31 | tok/s 14238
step   1870 | loss 1.1373 | lr 3.00e-04 | grad 1.39 | tok/s 14909
step   1880 | loss 1.4346 | lr 3.00e-04 | grad 3.41 | tok/s 13401
step   1890 | loss 1.4341 | lr 3.00e-04 | grad 1.52 | tok/s 14377
step   1900 | loss 1.3587 | lr 3.00e-04 | grad 1.59 | tok/s 14244
step   1910 | loss 1.4437 | lr 3.00e-04 | grad 1.58 | tok/s 14157
step   1920 | loss 1.3749 | lr 3.00e-04 | grad 1.91 | tok/s 14928
step   1930 | loss 1.4255 | lr 3.00e-04 | grad 1.59 | tok/s 14148
step   1940 | loss 1.6492 | lr 3.00e-04 | grad 4.69 | tok/s 14879
step   1950 | loss 1.6594 | lr 3.00e-04 | grad 4.88 | tok/s 15137
step   1960 | loss 1.3717 | lr 3.00e-04 | grad 2.38 | tok/s 14808
step   1970 | loss 1.5632 | lr 3.00e-04 | grad 5.00 | tok/s 14869
step   1980 | loss 1.3513 | lr 3.00e-04 | grad 2.06 | tok/s 14353
step   1990 | loss 1.6152 | lr 3.00e-04 | grad 1.92 | tok/s 14250
step   2000 | loss 1.4500 | lr 3.00e-04 | grad 1.88 | tok/s 14648
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4500.pt
step   2010 | loss 1.1501 | lr 3.00e-04 | grad 1.96 | tok/s 5720
step   2020 | loss 1.2715 | lr 3.00e-04 | grad 2.09 | tok/s 14923
step   2030 | loss 0.9999 | lr 3.00e-04 | grad 1.71 | tok/s 15290
step   2040 | loss 1.1803 | lr 3.00e-04 | grad 1.54 | tok/s 15261
step   2050 | loss 1.3869 | lr 3.00e-04 | grad 2.73 | tok/s 14628
step   2060 | loss 1.6468 | lr 3.00e-04 | grad 2.14 | tok/s 14400
step   2070 | loss 1.9659 | lr 3.00e-04 | grad 4.38 | tok/s 14448
step   2080 | loss 1.9625 | lr 3.00e-04 | grad 3.00 | tok/s 15181
step   2090 | loss 1.5261 | lr 3.00e-04 | grad 3.05 | tok/s 14673
step   2100 | loss 1.2683 | lr 3.00e-04 | grad 2.36 | tok/s 14994
step   2110 | loss 1.4045 | lr 3.00e-04 | grad 1.98 | tok/s 14311
step   2120 | loss 0.6901 | lr 3.00e-04 | grad 1.21 | tok/s 14162
step   2130 | loss 1.5337 | lr 3.00e-04 | grad 3.27 | tok/s 14179

Training complete! Final step: 2134
