Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_89/levelE88_100m_20260127_160110
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 488,706,848 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1227 | lr 3.00e-04 | grad 17.38 | tok/s 6063
step     20 | loss 2.9197 | lr 3.00e-04 | grad 9.00 | tok/s 16301
step     30 | loss 2.6095 | lr 3.00e-04 | grad 6.50 | tok/s 16472
step     40 | loss 2.4028 | lr 3.00e-04 | grad 4.38 | tok/s 15700
step     50 | loss 3.0198 | lr 3.00e-04 | grad 14.75 | tok/s 15983
step     60 | loss 2.0608 | lr 3.00e-04 | grad 4.25 | tok/s 16426
step     70 | loss 1.8501 | lr 3.00e-04 | grad 5.12 | tok/s 16602
step     80 | loss 6.3934 | lr 3.00e-04 | grad 53.75 | tok/s 16727
step     90 | loss 5.5600 | lr 3.00e-04 | grad 9.25 | tok/s 16987
step    100 | loss 4.0798 | lr 3.00e-04 | grad 7.84 | tok/s 16978
step    110 | loss 3.5313 | lr 3.00e-04 | grad 13.81 | tok/s 16957
step    120 | loss 3.1925 | lr 3.00e-04 | grad 12.12 | tok/s 16874
step    130 | loss 2.9622 | lr 3.00e-04 | grad 13.25 | tok/s 16874
step    140 | loss 2.6979 | lr 3.00e-04 | grad 8.62 | tok/s 16857
step    150 | loss 2.7884 | lr 3.00e-04 | grad 15.50 | tok/s 16859
step    160 | loss 2.4019 | lr 3.00e-04 | grad 11.31 | tok/s 16823
step    170 | loss 2.4646 | lr 3.00e-04 | grad 12.69 | tok/s 16811
step    180 | loss 2.3287 | lr 3.00e-04 | grad 8.38 | tok/s 16801
step    190 | loss 2.4530 | lr 3.00e-04 | grad 8.94 | tok/s 16780
step    200 | loss 2.1035 | lr 3.00e-04 | grad 5.44 | tok/s 16807
step    210 | loss 2.1692 | lr 3.00e-04 | grad 7.91 | tok/s 16788
step    220 | loss 2.1454 | lr 3.00e-04 | grad 4.03 | tok/s 16581
step    230 | loss 2.0600 | lr 3.00e-04 | grad 5.03 | tok/s 16355
step    240 | loss 2.3050 | lr 3.00e-04 | grad 5.34 | tok/s 15462
step    250 | loss 2.0958 | lr 3.00e-04 | grad 2.86 | tok/s 15944
step    260 | loss 1.5204 | lr 3.00e-04 | grad 3.23 | tok/s 16455
step    270 | loss 2.0658 | lr 3.00e-04 | grad 3.16 | tok/s 16190
step    280 | loss 2.2387 | lr 3.00e-04 | grad 5.41 | tok/s 15920
step    290 | loss 1.4531 | lr 3.00e-04 | grad 2.95 | tok/s 16756
step    300 | loss 0.6091 | lr 3.00e-04 | grad 3.50 | tok/s 16709
step    310 | loss 2.3997 | lr 3.00e-04 | grad 4.09 | tok/s 16486
step    320 | loss 1.8966 | lr 3.00e-04 | grad 6.00 | tok/s 16133
step    330 | loss 1.9354 | lr 3.00e-04 | grad 3.11 | tok/s 15565
step    340 | loss 2.2768 | lr 3.00e-04 | grad 3.09 | tok/s 15818
step    350 | loss 1.8620 | lr 3.00e-04 | grad 4.12 | tok/s 16203
step    360 | loss 1.1949 | lr 3.00e-04 | grad 9.00 | tok/s 16540
step    370 | loss 1.8008 | lr 3.00e-04 | grad 2.77 | tok/s 15027
step    380 | loss 1.7530 | lr 3.00e-04 | grad 2.83 | tok/s 16011
step    390 | loss 1.5164 | lr 3.00e-04 | grad 2.36 | tok/s 16596
step    400 | loss 1.4772 | lr 3.00e-04 | grad 2.89 | tok/s 16509
step    410 | loss 1.2590 | lr 3.00e-04 | grad 2.25 | tok/s 16183
step    420 | loss 1.8057 | lr 3.00e-04 | grad 4.62 | tok/s 15393
step    430 | loss 2.1476 | lr 3.00e-04 | grad 3.27 | tok/s 16433
step    440 | loss 2.1500 | lr 3.00e-04 | grad 4.31 | tok/s 15501
step    450 | loss 2.0253 | lr 3.00e-04 | grad 2.91 | tok/s 16106
step    460 | loss 1.7150 | lr 3.00e-04 | grad 3.33 | tok/s 15644
step    470 | loss 1.8219 | lr 3.00e-04 | grad 2.75 | tok/s 16147
step    480 | loss 2.2373 | lr 3.00e-04 | grad 7.22 | tok/s 16213
step    490 | loss 1.7858 | lr 3.00e-04 | grad 2.81 | tok/s 15322
step    500 | loss 1.6736 | lr 3.00e-04 | grad 3.78 | tok/s 16289
step    510 | loss 1.7039 | lr 3.00e-04 | grad 2.66 | tok/s 16546
step    520 | loss 1.6466 | lr 3.00e-04 | grad 2.28 | tok/s 16539
step    530 | loss 1.9139 | lr 3.00e-04 | grad 2.64 | tok/s 15845
step    540 | loss 1.7278 | lr 3.00e-04 | grad 2.56 | tok/s 12992
step    550 | loss 1.5681 | lr 3.00e-04 | grad 3.17 | tok/s 15492
step    560 | loss 1.7219 | lr 3.00e-04 | grad 2.86 | tok/s 15156
step    570 | loss 1.6521 | lr 3.00e-04 | grad 3.88 | tok/s 15589
step    580 | loss 1.5433 | lr 3.00e-04 | grad 2.41 | tok/s 15440
step    590 | loss 1.8495 | lr 3.00e-04 | grad 3.38 | tok/s 15795
step    600 | loss 1.8254 | lr 3.00e-04 | grad 2.41 | tok/s 15341
step    610 | loss 1.6182 | lr 3.00e-04 | grad 2.62 | tok/s 16214
step    620 | loss 1.5459 | lr 3.00e-04 | grad 2.69 | tok/s 15287
step    630 | loss 1.6539 | lr 3.00e-04 | grad 4.62 | tok/s 15398
step    640 | loss 1.8096 | lr 3.00e-04 | grad 2.59 | tok/s 15809
step    650 | loss 1.6769 | lr 3.00e-04 | grad 2.83 | tok/s 15946
step    660 | loss 1.6890 | lr 3.00e-04 | grad 2.22 | tok/s 15947
step    670 | loss 1.9122 | lr 3.00e-04 | grad 3.41 | tok/s 16036
step    680 | loss 1.7234 | lr 3.00e-04 | grad 2.50 | tok/s 15802
step    690 | loss 1.8315 | lr 3.00e-04 | grad 3.62 | tok/s 16365
step    700 | loss 1.4097 | lr 3.00e-04 | grad 3.06 | tok/s 16712
step    710 | loss 1.5860 | lr 3.00e-04 | grad 2.56 | tok/s 15550
step    720 | loss 1.4729 | lr 3.00e-04 | grad 3.66 | tok/s 15358
step    730 | loss 1.2831 | lr 3.00e-04 | grad 3.06 | tok/s 16656
step    740 | loss 1.4968 | lr 3.00e-04 | grad 2.50 | tok/s 16481
step    750 | loss 1.1934 | lr 3.00e-04 | grad 2.75 | tok/s 16620
step    760 | loss 1.1004 | lr 3.00e-04 | grad 2.28 | tok/s 16608
step    770 | loss 1.0526 | lr 3.00e-04 | grad 2.27 | tok/s 16652
step    780 | loss 0.9867 | lr 3.00e-04 | grad 2.12 | tok/s 16620
step    790 | loss 1.1236 | lr 3.00e-04 | grad 3.45 | tok/s 16158
step    800 | loss 1.8216 | lr 3.00e-04 | grad 5.72 | tok/s 16093
step    810 | loss 1.7066 | lr 3.00e-04 | grad 2.30 | tok/s 16027
step    820 | loss 1.7150 | lr 3.00e-04 | grad 4.12 | tok/s 15350
step    830 | loss 1.4925 | lr 3.00e-04 | grad 2.42 | tok/s 16406
step    840 | loss 1.3481 | lr 3.00e-04 | grad 2.31 | tok/s 16714
step    850 | loss 1.5860 | lr 3.00e-04 | grad 2.19 | tok/s 16656
step    860 | loss 1.4688 | lr 3.00e-04 | grad 3.92 | tok/s 16452
step    870 | loss 1.4981 | lr 3.00e-04 | grad 2.91 | tok/s 15754
step    880 | loss 1.6806 | lr 3.00e-04 | grad 2.73 | tok/s 15853
step    890 | loss 1.6818 | lr 3.00e-04 | grad 3.12 | tok/s 16030
step    900 | loss 1.5660 | lr 3.00e-04 | grad 2.62 | tok/s 13695
step    910 | loss 1.4184 | lr 3.00e-04 | grad 3.94 | tok/s 15818
step    920 | loss 1.5273 | lr 3.00e-04 | grad 3.80 | tok/s 16372
step    930 | loss 1.5988 | lr 3.00e-04 | grad 3.61 | tok/s 15594
step    940 | loss 1.3874 | lr 3.00e-04 | grad 2.11 | tok/s 16400
step    950 | loss 1.4939 | lr 3.00e-04 | grad 3.38 | tok/s 16512
step    960 | loss 1.3278 | lr 3.00e-04 | grad 2.72 | tok/s 16506
step    970 | loss 1.7479 | lr 3.00e-04 | grad 3.80 | tok/s 15607
step    980 | loss 1.6431 | lr 3.00e-04 | grad 2.69 | tok/s 16099
step    990 | loss 1.4487 | lr 3.00e-04 | grad 2.30 | tok/s 16230
step   1000 | loss 1.8387 | lr 3.00e-04 | grad 9.25 | tok/s 15523
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8387.pt
step   1010 | loss 1.6532 | lr 3.00e-04 | grad 3.28 | tok/s 4493
step   1020 | loss 1.6183 | lr 3.00e-04 | grad 2.53 | tok/s 15344
step   1030 | loss 1.3900 | lr 3.00e-04 | grad 2.48 | tok/s 16454
step   1040 | loss 1.5115 | lr 3.00e-04 | grad 2.39 | tok/s 16035
step   1050 | loss 1.6389 | lr 3.00e-04 | grad 2.66 | tok/s 15875
step   1060 | loss 1.6984 | lr 3.00e-04 | grad 3.08 | tok/s 16435
step   1070 | loss 1.6415 | lr 3.00e-04 | grad 3.17 | tok/s 15995
step   1080 | loss 1.3954 | lr 3.00e-04 | grad 2.52 | tok/s 15271
step   1090 | loss 1.0363 | lr 3.00e-04 | grad 2.91 | tok/s 16527
step   1100 | loss 1.5777 | lr 3.00e-04 | grad 3.23 | tok/s 16424
step   1110 | loss 1.3719 | lr 3.00e-04 | grad 2.28 | tok/s 16841
step   1120 | loss 1.3246 | lr 3.00e-04 | grad 2.25 | tok/s 16797
step   1130 | loss 1.2654 | lr 3.00e-04 | grad 2.09 | tok/s 16776
step   1140 | loss 1.2870 | lr 3.00e-04 | grad 2.12 | tok/s 13708
step   1150 | loss 1.2718 | lr 3.00e-04 | grad 1.98 | tok/s 16745
step   1160 | loss 1.1970 | lr 3.00e-04 | grad 2.02 | tok/s 16813
step   1170 | loss 1.2980 | lr 3.00e-04 | grad 2.20 | tok/s 16788
step   1180 | loss 1.2749 | lr 3.00e-04 | grad 2.09 | tok/s 16687
step   1190 | loss 1.1988 | lr 3.00e-04 | grad 1.88 | tok/s 16709
step   1200 | loss 1.2377 | lr 3.00e-04 | grad 1.88 | tok/s 16778
step   1210 | loss 1.2716 | lr 3.00e-04 | grad 2.12 | tok/s 16829
step   1220 | loss 1.2534 | lr 3.00e-04 | grad 1.91 | tok/s 16679
step   1230 | loss 1.2519 | lr 3.00e-04 | grad 2.02 | tok/s 16584
step   1240 | loss 1.3962 | lr 3.00e-04 | grad 2.77 | tok/s 16205
step   1250 | loss 1.7195 | lr 3.00e-04 | grad 2.45 | tok/s 15814
step   1260 | loss 1.4513 | lr 3.00e-04 | grad 6.25 | tok/s 15651
step   1270 | loss 1.6278 | lr 3.00e-04 | grad 3.25 | tok/s 15318
step   1280 | loss 1.6049 | lr 3.00e-04 | grad 4.16 | tok/s 16372
step   1290 | loss 1.4754 | lr 3.00e-04 | grad 2.42 | tok/s 15985
step   1300 | loss 1.5138 | lr 3.00e-04 | grad 2.27 | tok/s 15793
step   1310 | loss 1.4550 | lr 3.00e-04 | grad 2.30 | tok/s 16397
step   1320 | loss 1.7042 | lr 3.00e-04 | grad 4.62 | tok/s 16424
step   1330 | loss 1.3719 | lr 3.00e-04 | grad 3.77 | tok/s 16115
step   1340 | loss 1.6441 | lr 3.00e-04 | grad 5.72 | tok/s 15205
step   1350 | loss 1.7536 | lr 3.00e-04 | grad 3.50 | tok/s 15457
step   1360 | loss 1.3924 | lr 3.00e-04 | grad 2.34 | tok/s 15735
step   1370 | loss 1.5978 | lr 3.00e-04 | grad 3.41 | tok/s 16070
step   1380 | loss 1.5641 | lr 3.00e-04 | grad 2.92 | tok/s 15293
step   1390 | loss 1.4057 | lr 3.00e-04 | grad 2.36 | tok/s 15435
step   1400 | loss 1.4097 | lr 3.00e-04 | grad 2.28 | tok/s 16136
step   1410 | loss 1.5546 | lr 3.00e-04 | grad 2.58 | tok/s 15619
step   1420 | loss 1.6034 | lr 3.00e-04 | grad 2.39 | tok/s 15757
step   1430 | loss 1.2923 | lr 3.00e-04 | grad 1.87 | tok/s 15768
step   1440 | loss 1.1341 | lr 3.00e-04 | grad 1.91 | tok/s 16617
step   1450 | loss 1.3568 | lr 3.00e-04 | grad 5.50 | tok/s 16422
step   1460 | loss 1.6187 | lr 3.00e-04 | grad 2.62 | tok/s 15397
step   1470 | loss 1.4393 | lr 3.00e-04 | grad 2.19 | tok/s 16517
step   1480 | loss 1.8946 | lr 3.00e-04 | grad 5.91 | tok/s 16519
step   1490 | loss 1.5546 | lr 3.00e-04 | grad 2.39 | tok/s 16577
step   1500 | loss 1.2414 | lr 3.00e-04 | grad 2.23 | tok/s 16717
step   1510 | loss 1.6135 | lr 3.00e-04 | grad 2.62 | tok/s 16477
step   1520 | loss 1.4738 | lr 3.00e-04 | grad 2.80 | tok/s 16134
step   1530 | loss 1.3965 | lr 3.00e-04 | grad 2.39 | tok/s 16048
step   1540 | loss 1.6531 | lr 3.00e-04 | grad 2.25 | tok/s 15839
step   1550 | loss 1.1979 | lr 3.00e-04 | grad 1.91 | tok/s 16283
step   1560 | loss 1.6310 | lr 3.00e-04 | grad 2.11 | tok/s 15582
step   1570 | loss 1.3598 | lr 3.00e-04 | grad 2.75 | tok/s 16434
step   1580 | loss 1.6825 | lr 3.00e-04 | grad 3.41 | tok/s 16315
step   1590 | loss 1.5002 | lr 3.00e-04 | grad 1.93 | tok/s 15605
step   1600 | loss 0.7742 | lr 3.00e-04 | grad 2.64 | tok/s 16587
step   1610 | loss 1.3013 | lr 3.00e-04 | grad 2.16 | tok/s 15259
step   1620 | loss 1.3825 | lr 3.00e-04 | grad 4.00 | tok/s 15737
step   1630 | loss 1.3065 | lr 3.00e-04 | grad 2.08 | tok/s 16115
step   1640 | loss 1.5173 | lr 3.00e-04 | grad 5.25 | tok/s 15562
step   1650 | loss 1.5411 | lr 3.00e-04 | grad 2.34 | tok/s 14709
step   1660 | loss 1.2103 | lr 3.00e-04 | grad 1.92 | tok/s 16646
step   1670 | loss 1.6338 | lr 3.00e-04 | grad 2.75 | tok/s 15649
step   1680 | loss 1.5430 | lr 3.00e-04 | grad 2.16 | tok/s 15234
step   1690 | loss 1.4490 | lr 3.00e-04 | grad 4.28 | tok/s 16252
step   1700 | loss 1.5270 | lr 3.00e-04 | grad 3.08 | tok/s 15490
step   1710 | loss 1.4425 | lr 3.00e-04 | grad 2.30 | tok/s 16010
step   1720 | loss 1.4927 | lr 3.00e-04 | grad 3.12 | tok/s 16575
step   1730 | loss 1.1889 | lr 3.00e-04 | grad 2.50 | tok/s 16505
step   1740 | loss 1.4263 | lr 3.00e-04 | grad 2.89 | tok/s 12028
step   1750 | loss 1.5476 | lr 3.00e-04 | grad 2.36 | tok/s 15984
step   1760 | loss 1.5809 | lr 3.00e-04 | grad 2.42 | tok/s 16103
step   1770 | loss 1.4317 | lr 3.00e-04 | grad 2.45 | tok/s 15815
step   1780 | loss 1.4847 | lr 3.00e-04 | grad 2.44 | tok/s 16067
step   1790 | loss 1.4485 | lr 3.00e-04 | grad 2.66 | tok/s 15822
step   1800 | loss 1.6270 | lr 3.00e-04 | grad 2.98 | tok/s 15596
step   1810 | loss 1.3819 | lr 3.00e-04 | grad 2.34 | tok/s 15608
step   1820 | loss 1.4861 | lr 3.00e-04 | grad 3.48 | tok/s 16141
step   1830 | loss 1.4798 | lr 3.00e-04 | grad 3.64 | tok/s 15991
step   1840 | loss 1.4708 | lr 3.00e-04 | grad 2.83 | tok/s 15670
step   1850 | loss 1.2254 | lr 3.00e-04 | grad 2.67 | tok/s 16267
step   1860 | loss 1.4737 | lr 3.00e-04 | grad 2.91 | tok/s 15617
step   1870 | loss 1.1590 | lr 3.00e-04 | grad 1.71 | tok/s 16321
step   1880 | loss 1.4677 | lr 3.00e-04 | grad 3.83 | tok/s 14703
step   1890 | loss 1.4561 | lr 3.00e-04 | grad 2.03 | tok/s 15593
step   1900 | loss 1.3802 | lr 3.00e-04 | grad 2.02 | tok/s 15505
step   1910 | loss 1.4773 | lr 3.00e-04 | grad 2.09 | tok/s 15499
step   1920 | loss 1.3870 | lr 3.00e-04 | grad 2.31 | tok/s 16396
step   1930 | loss 1.4459 | lr 3.00e-04 | grad 2.16 | tok/s 15621
step   1940 | loss 1.6951 | lr 3.00e-04 | grad 5.53 | tok/s 16072
step   1950 | loss 1.6720 | lr 3.00e-04 | grad 5.66 | tok/s 16470
step   1960 | loss 1.3851 | lr 3.00e-04 | grad 2.97 | tok/s 16130
step   1970 | loss 1.6111 | lr 3.00e-04 | grad 5.69 | tok/s 16350
step   1980 | loss 1.3704 | lr 3.00e-04 | grad 3.02 | tok/s 15839
step   1990 | loss 1.6874 | lr 3.00e-04 | grad 2.38 | tok/s 15705
step   2000 | loss 1.4758 | lr 3.00e-04 | grad 2.22 | tok/s 16003
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4758.pt
step   2010 | loss 1.2486 | lr 3.00e-04 | grad 2.05 | tok/s 4413
step   2020 | loss 1.3452 | lr 3.00e-04 | grad 4.19 | tok/s 16576
step   2030 | loss 0.9954 | lr 3.00e-04 | grad 2.53 | tok/s 16349
step   2040 | loss 1.1650 | lr 3.00e-04 | grad 2.33 | tok/s 16744
step   2050 | loss 1.5281 | lr 3.00e-04 | grad 10.50 | tok/s 15544
step   2060 | loss 1.6891 | lr 3.00e-04 | grad 4.09 | tok/s 16050
step   2070 | loss 2.0938 | lr 3.00e-04 | grad 5.97 | tok/s 16207
step   2080 | loss 1.8964 | lr 3.00e-04 | grad 3.09 | tok/s 16773
step   2090 | loss 1.4735 | lr 3.00e-04 | grad 2.75 | tok/s 12460
step   2100 | loss 1.3921 | lr 3.00e-04 | grad 3.41 | tok/s 16203
step   2110 | loss 1.2827 | lr 3.00e-04 | grad 32.25 | tok/s 16015
step   2120 | loss 0.7261 | lr 3.00e-04 | grad 1.95 | tok/s 16779
step   2130 | loss 1.6751 | lr 3.00e-04 | grad 3.52 | tok/s 15662
step   2140 | loss 1.3190 | lr 3.00e-04 | grad 2.02 | tok/s 16778
step   2150 | loss 1.2063 | lr 3.00e-04 | grad 1.64 | tok/s 16637
step   2160 | loss 1.2223 | lr 3.00e-04 | grad 1.81 | tok/s 16570
step   2170 | loss 1.1889 | lr 3.00e-04 | grad 1.69 | tok/s 16690
step   2180 | loss 1.2204 | lr 3.00e-04 | grad 1.98 | tok/s 16636
step   2190 | loss 1.1832 | lr 3.00e-04 | grad 1.71 | tok/s 16617
step   2200 | loss 1.1384 | lr 3.00e-04 | grad 1.80 | tok/s 16776
step   2210 | loss 1.1519 | lr 3.00e-04 | grad 1.98 | tok/s 16667
step   2220 | loss 1.1945 | lr 3.00e-04 | grad 3.19 | tok/s 16528
step   2230 | loss 1.4255 | lr 3.00e-04 | grad 2.11 | tok/s 16366
step   2240 | loss 1.4524 | lr 3.00e-04 | grad 3.94 | tok/s 15935
step   2250 | loss 1.5867 | lr 3.00e-04 | grad 3.94 | tok/s 16493
step   2260 | loss 1.6988 | lr 3.00e-04 | grad 8.62 | tok/s 16114
step   2270 | loss 1.7189 | lr 3.00e-04 | grad 2.62 | tok/s 16487
step   2280 | loss 1.3284 | lr 3.00e-04 | grad 2.03 | tok/s 16720
step   2290 | loss 1.8365 | lr 3.00e-04 | grad 9.00 | tok/s 15757
step   2300 | loss 1.2455 | lr 3.00e-04 | grad 3.34 | tok/s 15488
step   2310 | loss 1.5029 | lr 3.00e-04 | grad 6.78 | tok/s 16202
step   2320 | loss 1.9624 | lr 3.00e-04 | grad 3.94 | tok/s 15429
step   2330 | loss 1.3232 | lr 3.00e-04 | grad 1.98 | tok/s 15332

Training complete! Final step: 2332
