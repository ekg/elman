Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_81/levelE88_100m_20260127_155052
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 489,510,970 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1216 | lr 3.00e-04 | grad 23.38 | tok/s 5892
step     20 | loss 2.8471 | lr 3.00e-04 | grad 11.69 | tok/s 16050
step     30 | loss 2.7473 | lr 3.00e-04 | grad 7.44 | tok/s 16185
step     40 | loss 2.4994 | lr 3.00e-04 | grad 5.19 | tok/s 15489
step     50 | loss 3.0973 | lr 3.00e-04 | grad 15.62 | tok/s 15717
step     60 | loss 2.1095 | lr 3.00e-04 | grad 4.62 | tok/s 16181
step     70 | loss 1.9270 | lr 3.00e-04 | grad 5.94 | tok/s 16347
step     80 | loss 6.5905 | lr 3.00e-04 | grad 140.00 | tok/s 16434
step     90 | loss 6.3021 | lr 3.00e-04 | grad 15.12 | tok/s 16671
step    100 | loss 4.7960 | lr 3.00e-04 | grad 13.12 | tok/s 16631
step    110 | loss 4.1283 | lr 3.00e-04 | grad 37.25 | tok/s 16625
step    120 | loss 3.5774 | lr 3.00e-04 | grad 25.12 | tok/s 16619
step    130 | loss 3.2788 | lr 3.00e-04 | grad 28.75 | tok/s 14907
step    140 | loss 2.8713 | lr 3.00e-04 | grad 15.06 | tok/s 16507
step    150 | loss 3.1210 | lr 3.00e-04 | grad 28.50 | tok/s 16493
step    160 | loss 2.4567 | lr 3.00e-04 | grad 18.75 | tok/s 16496
step    170 | loss 2.5937 | lr 3.00e-04 | grad 20.75 | tok/s 16512
step    180 | loss 2.4134 | lr 3.00e-04 | grad 11.88 | tok/s 16486
step    190 | loss 2.5761 | lr 3.00e-04 | grad 20.25 | tok/s 16467
step    200 | loss 2.2918 | lr 3.00e-04 | grad 11.81 | tok/s 16477
step    210 | loss 2.2417 | lr 3.00e-04 | grad 8.25 | tok/s 16459
step    220 | loss 2.2796 | lr 3.00e-04 | grad 4.03 | tok/s 16216
step    230 | loss 2.0950 | lr 3.00e-04 | grad 4.28 | tok/s 16037
step    240 | loss 2.3345 | lr 3.00e-04 | grad 5.66 | tok/s 15217
step    250 | loss 2.1320 | lr 3.00e-04 | grad 2.94 | tok/s 15618
step    260 | loss 1.5755 | lr 3.00e-04 | grad 3.28 | tok/s 16075
step    270 | loss 2.1277 | lr 3.00e-04 | grad 3.08 | tok/s 15895
step    280 | loss 2.2808 | lr 3.00e-04 | grad 5.19 | tok/s 15572
step    290 | loss 1.4151 | lr 3.00e-04 | grad 4.00 | tok/s 16424
step    300 | loss 0.5900 | lr 3.00e-04 | grad 3.08 | tok/s 16359
step    310 | loss 2.4230 | lr 3.00e-04 | grad 3.98 | tok/s 16144
step    320 | loss 1.9512 | lr 3.00e-04 | grad 6.22 | tok/s 15807
step    330 | loss 1.9690 | lr 3.00e-04 | grad 3.20 | tok/s 15253
step    340 | loss 2.3052 | lr 3.00e-04 | grad 3.14 | tok/s 15492
step    350 | loss 1.8932 | lr 3.00e-04 | grad 4.56 | tok/s 15839
step    360 | loss 1.2138 | lr 3.00e-04 | grad 7.41 | tok/s 16174
step    370 | loss 1.8242 | lr 3.00e-04 | grad 2.73 | tok/s 14706
step    380 | loss 1.7892 | lr 3.00e-04 | grad 2.77 | tok/s 15672
step    390 | loss 1.5467 | lr 3.00e-04 | grad 2.34 | tok/s 16332
step    400 | loss 1.5049 | lr 3.00e-04 | grad 2.80 | tok/s 16177
step    410 | loss 1.2841 | lr 3.00e-04 | grad 2.17 | tok/s 15819
step    420 | loss 1.8345 | lr 3.00e-04 | grad 4.75 | tok/s 15136
step    430 | loss 2.1759 | lr 3.00e-04 | grad 3.17 | tok/s 16103
step    440 | loss 2.1751 | lr 3.00e-04 | grad 4.44 | tok/s 15212
step    450 | loss 2.0035 | lr 3.00e-04 | grad 2.94 | tok/s 15756
step    460 | loss 1.7475 | lr 3.00e-04 | grad 3.17 | tok/s 15391
step    470 | loss 1.8579 | lr 3.00e-04 | grad 2.72 | tok/s 15891
step    480 | loss 2.2896 | lr 3.00e-04 | grad 7.28 | tok/s 15901
step    490 | loss 1.8106 | lr 3.00e-04 | grad 2.97 | tok/s 15029
step    500 | loss 1.7055 | lr 3.00e-04 | grad 3.53 | tok/s 16015
step    510 | loss 1.7297 | lr 3.00e-04 | grad 2.72 | tok/s 16247
step    520 | loss 1.6773 | lr 3.00e-04 | grad 2.20 | tok/s 16249
step    530 | loss 1.9237 | lr 3.00e-04 | grad 2.59 | tok/s 15625
step    540 | loss 1.7509 | lr 3.00e-04 | grad 2.44 | tok/s 15639
step    550 | loss 1.5811 | lr 3.00e-04 | grad 3.38 | tok/s 14342
step    560 | loss 1.7379 | lr 3.00e-04 | grad 2.72 | tok/s 14913
step    570 | loss 1.6832 | lr 3.00e-04 | grad 3.92 | tok/s 15338
step    580 | loss 1.5623 | lr 3.00e-04 | grad 2.30 | tok/s 15301
step    590 | loss 1.8736 | lr 3.00e-04 | grad 3.31 | tok/s 15670
step    600 | loss 1.8386 | lr 3.00e-04 | grad 2.44 | tok/s 15096
step    610 | loss 1.6384 | lr 3.00e-04 | grad 2.47 | tok/s 15869
step    620 | loss 1.5615 | lr 3.00e-04 | grad 2.53 | tok/s 15052
step    630 | loss 1.6767 | lr 3.00e-04 | grad 4.81 | tok/s 15171
step    640 | loss 1.8351 | lr 3.00e-04 | grad 2.58 | tok/s 15579
step    650 | loss 1.6885 | lr 3.00e-04 | grad 2.69 | tok/s 15585
step    660 | loss 1.7125 | lr 3.00e-04 | grad 2.19 | tok/s 15692
step    670 | loss 1.9578 | lr 3.00e-04 | grad 3.34 | tok/s 15812
step    680 | loss 1.7370 | lr 3.00e-04 | grad 2.52 | tok/s 15511
step    690 | loss 1.8453 | lr 3.00e-04 | grad 3.38 | tok/s 16043
step    700 | loss 1.4381 | lr 3.00e-04 | grad 3.09 | tok/s 16368
step    710 | loss 1.6072 | lr 3.00e-04 | grad 2.53 | tok/s 15274
step    720 | loss 1.4841 | lr 3.00e-04 | grad 3.55 | tok/s 15059
step    730 | loss 1.2961 | lr 3.00e-04 | grad 2.91 | tok/s 16345
step    740 | loss 1.5160 | lr 3.00e-04 | grad 2.47 | tok/s 16113
step    750 | loss 1.2155 | lr 3.00e-04 | grad 2.64 | tok/s 16356
step    760 | loss 1.1181 | lr 3.00e-04 | grad 2.27 | tok/s 16362
step    770 | loss 1.0684 | lr 3.00e-04 | grad 2.17 | tok/s 16338
step    780 | loss 1.0043 | lr 3.00e-04 | grad 2.17 | tok/s 16366
step    790 | loss 1.1396 | lr 3.00e-04 | grad 3.30 | tok/s 15833
step    800 | loss 1.8344 | lr 3.00e-04 | grad 5.72 | tok/s 14799
step    810 | loss 1.7185 | lr 3.00e-04 | grad 2.19 | tok/s 15720
step    820 | loss 1.7309 | lr 3.00e-04 | grad 4.03 | tok/s 15131
step    830 | loss 1.5061 | lr 3.00e-04 | grad 2.38 | tok/s 16222
step    840 | loss 1.3733 | lr 3.00e-04 | grad 2.31 | tok/s 16386
step    850 | loss 1.6164 | lr 3.00e-04 | grad 2.17 | tok/s 16302
step    860 | loss 1.4947 | lr 3.00e-04 | grad 3.73 | tok/s 16108
step    870 | loss 1.5199 | lr 3.00e-04 | grad 2.80 | tok/s 15543
step    880 | loss 1.7017 | lr 3.00e-04 | grad 2.61 | tok/s 15593
step    890 | loss 1.6950 | lr 3.00e-04 | grad 3.08 | tok/s 15808
step    900 | loss 1.5884 | lr 3.00e-04 | grad 2.62 | tok/s 15828
step    910 | loss 1.4387 | lr 3.00e-04 | grad 4.09 | tok/s 15482
step    920 | loss 1.5383 | lr 3.00e-04 | grad 3.69 | tok/s 16083
step    930 | loss 1.6217 | lr 3.00e-04 | grad 3.72 | tok/s 15361
step    940 | loss 1.3978 | lr 3.00e-04 | grad 2.00 | tok/s 16186
step    950 | loss 1.5145 | lr 3.00e-04 | grad 2.95 | tok/s 16282
step    960 | loss 1.3349 | lr 3.00e-04 | grad 2.67 | tok/s 16312
step    970 | loss 1.7662 | lr 3.00e-04 | grad 3.81 | tok/s 15339
step    980 | loss 1.6664 | lr 3.00e-04 | grad 2.53 | tok/s 14803
step    990 | loss 1.4676 | lr 3.00e-04 | grad 2.25 | tok/s 16038
step   1000 | loss 1.8556 | lr 3.00e-04 | grad 8.81 | tok/s 15400
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8556.pt
step   1010 | loss 1.7508 | lr 3.00e-04 | grad 2.55 | tok/s 6190
step   1020 | loss 1.7025 | lr 3.00e-04 | grad 2.64 | tok/s 15193
step   1030 | loss 1.4272 | lr 3.00e-04 | grad 1.85 | tok/s 15824
step   1040 | loss 1.5400 | lr 3.00e-04 | grad 4.25 | tok/s 16143
step   1050 | loss 1.6219 | lr 3.00e-04 | grad 2.42 | tok/s 15187
step   1060 | loss 1.7173 | lr 3.00e-04 | grad 2.52 | tok/s 16194
step   1070 | loss 1.6713 | lr 3.00e-04 | grad 3.52 | tok/s 15929
step   1080 | loss 1.4217 | lr 3.00e-04 | grad 2.62 | tok/s 14757
step   1090 | loss 1.0141 | lr 3.00e-04 | grad 2.70 | tok/s 16365
step   1100 | loss 1.5848 | lr 3.00e-04 | grad 2.86 | tok/s 15702
step   1110 | loss 1.4365 | lr 3.00e-04 | grad 2.17 | tok/s 16472
step   1120 | loss 1.3437 | lr 3.00e-04 | grad 2.39 | tok/s 16469
step   1130 | loss 1.2902 | lr 3.00e-04 | grad 2.20 | tok/s 16464
step   1140 | loss 1.2975 | lr 3.00e-04 | grad 2.05 | tok/s 16452
step   1150 | loss 1.2973 | lr 3.00e-04 | grad 2.12 | tok/s 16466
step   1160 | loss 1.2220 | lr 3.00e-04 | grad 2.08 | tok/s 15449
step   1170 | loss 1.2588 | lr 3.00e-04 | grad 2.23 | tok/s 16456
step   1180 | loss 1.3210 | lr 3.00e-04 | grad 1.84 | tok/s 16462
step   1190 | loss 1.2239 | lr 3.00e-04 | grad 2.27 | tok/s 16440
step   1200 | loss 1.2266 | lr 3.00e-04 | grad 1.98 | tok/s 16448
step   1210 | loss 1.2663 | lr 3.00e-04 | grad 1.83 | tok/s 16442
step   1220 | loss 1.2898 | lr 3.00e-04 | grad 1.91 | tok/s 16414
step   1230 | loss 1.2634 | lr 3.00e-04 | grad 1.78 | tok/s 16381
step   1240 | loss 1.2692 | lr 3.00e-04 | grad 2.92 | tok/s 16295
step   1250 | loss 1.8418 | lr 3.00e-04 | grad 2.58 | tok/s 15577
step   1260 | loss 1.3254 | lr 3.00e-04 | grad 7.06 | tok/s 15343
step   1270 | loss 1.7808 | lr 3.00e-04 | grad 3.12 | tok/s 15300
step   1280 | loss 1.6013 | lr 3.00e-04 | grad 2.59 | tok/s 15999
step   1290 | loss 1.5070 | lr 3.00e-04 | grad 2.80 | tok/s 15687
step   1300 | loss 1.5359 | lr 3.00e-04 | grad 2.28 | tok/s 14410
step   1310 | loss 1.4675 | lr 3.00e-04 | grad 2.05 | tok/s 16292
step   1320 | loss 1.6009 | lr 3.00e-04 | grad 2.52 | tok/s 16096
step   1330 | loss 1.5457 | lr 3.00e-04 | grad 2.36 | tok/s 16098
step   1340 | loss 1.6002 | lr 3.00e-04 | grad 3.62 | tok/s 15143
step   1350 | loss 1.7440 | lr 3.00e-04 | grad 2.44 | tok/s 15020
step   1360 | loss 1.4892 | lr 3.00e-04 | grad 1.91 | tok/s 15748
step   1370 | loss 1.5332 | lr 3.00e-04 | grad 7.41 | tok/s 15579
step   1380 | loss 1.6233 | lr 3.00e-04 | grad 3.27 | tok/s 14961
step   1390 | loss 1.4997 | lr 3.00e-04 | grad 4.28 | tok/s 15777
step   1400 | loss 1.3930 | lr 3.00e-04 | grad 1.76 | tok/s 15417
step   1410 | loss 1.5417 | lr 3.00e-04 | grad 7.94 | tok/s 15387
step   1420 | loss 1.6647 | lr 3.00e-04 | grad 2.45 | tok/s 15361
step   1430 | loss 1.3444 | lr 3.00e-04 | grad 2.39 | tok/s 15583
step   1440 | loss 1.1458 | lr 3.00e-04 | grad 2.19 | tok/s 16369
step   1450 | loss 1.1717 | lr 3.00e-04 | grad 2.48 | tok/s 16164
step   1460 | loss 1.7199 | lr 3.00e-04 | grad 2.34 | tok/s 15253
step   1470 | loss 1.5291 | lr 3.00e-04 | grad 2.19 | tok/s 16197
step   1480 | loss 1.8673 | lr 3.00e-04 | grad 3.69 | tok/s 16034
step   1490 | loss 1.5964 | lr 3.00e-04 | grad 2.77 | tok/s 16267
step   1500 | loss 1.3059 | lr 3.00e-04 | grad 2.19 | tok/s 16303
step   1510 | loss 1.5668 | lr 3.00e-04 | grad 2.81 | tok/s 16109
step   1520 | loss 1.4483 | lr 3.00e-04 | grad 2.95 | tok/s 15828
step   1530 | loss 1.4529 | lr 3.00e-04 | grad 3.05 | tok/s 16183
step   1540 | loss 1.6514 | lr 3.00e-04 | grad 2.75 | tok/s 15213
step   1550 | loss 1.2778 | lr 3.00e-04 | grad 2.81 | tok/s 16198
step   1560 | loss 1.6026 | lr 3.00e-04 | grad 2.11 | tok/s 15365
step   1570 | loss 1.2851 | lr 3.00e-04 | grad 2.28 | tok/s 16207
step   1580 | loss 1.7464 | lr 3.00e-04 | grad 4.62 | tok/s 16138
step   1590 | loss 1.6016 | lr 3.00e-04 | grad 2.33 | tok/s 15379
step   1600 | loss 0.9230 | lr 3.00e-04 | grad 1.02 | tok/s 16415
step   1610 | loss 1.1118 | lr 3.00e-04 | grad 1.93 | tok/s 15526
step   1620 | loss 1.4086 | lr 3.00e-04 | grad 3.33 | tok/s 15206
step   1630 | loss 1.3751 | lr 3.00e-04 | grad 1.87 | tok/s 15908
step   1640 | loss 1.3743 | lr 3.00e-04 | grad 2.25 | tok/s 15461
step   1650 | loss 1.5730 | lr 3.00e-04 | grad 2.81 | tok/s 14603
step   1660 | loss 1.3398 | lr 3.00e-04 | grad 1.74 | tok/s 16278
step   1670 | loss 1.4483 | lr 3.00e-04 | grad 4.19 | tok/s 15742
step   1680 | loss 1.6951 | lr 3.00e-04 | grad 1.88 | tok/s 15077
step   1690 | loss 1.5190 | lr 3.00e-04 | grad 3.38 | tok/s 15804
step   1700 | loss 1.5272 | lr 3.00e-04 | grad 2.14 | tok/s 15665
step   1710 | loss 1.4347 | lr 3.00e-04 | grad 2.33 | tok/s 15636
step   1720 | loss 1.5403 | lr 3.00e-04 | grad 2.78 | tok/s 15127
step   1730 | loss 1.1981 | lr 3.00e-04 | grad 2.83 | tok/s 16379
step   1740 | loss 1.4110 | lr 3.00e-04 | grad 2.69 | tok/s 15804
step   1750 | loss 1.5587 | lr 3.00e-04 | grad 2.77 | tok/s 15831
step   1760 | loss 1.5817 | lr 3.00e-04 | grad 2.23 | tok/s 15768
step   1770 | loss 1.4591 | lr 3.00e-04 | grad 2.38 | tok/s 15464
step   1780 | loss 1.5004 | lr 3.00e-04 | grad 2.00 | tok/s 15965
step   1790 | loss 1.4424 | lr 3.00e-04 | grad 3.08 | tok/s 15848
step   1800 | loss 1.5956 | lr 3.00e-04 | grad 2.08 | tok/s 15568
step   1810 | loss 1.4958 | lr 3.00e-04 | grad 3.80 | tok/s 15265
step   1820 | loss 1.4925 | lr 3.00e-04 | grad 6.00 | tok/s 15709
step   1830 | loss 1.4562 | lr 3.00e-04 | grad 3.81 | tok/s 16087
step   1840 | loss 1.4950 | lr 3.00e-04 | grad 1.96 | tok/s 15290
step   1850 | loss 1.2835 | lr 3.00e-04 | grad 1.99 | tok/s 16335
step   1860 | loss 1.3708 | lr 3.00e-04 | grad 2.84 | tok/s 15436
step   1870 | loss 1.3837 | lr 3.00e-04 | grad 1.78 | tok/s 15786
step   1880 | loss 1.2881 | lr 3.00e-04 | grad 3.02 | tok/s 15190
step   1890 | loss 1.5489 | lr 3.00e-04 | grad 2.11 | tok/s 14760
step   1900 | loss 1.3980 | lr 3.00e-04 | grad 2.30 | tok/s 15828
step   1910 | loss 1.4995 | lr 3.00e-04 | grad 2.31 | tok/s 14998
step   1920 | loss 1.3877 | lr 3.00e-04 | grad 2.02 | tok/s 16443
step   1930 | loss 1.4692 | lr 3.00e-04 | grad 3.41 | tok/s 15128
step   1940 | loss 1.4624 | lr 3.00e-04 | grad 2.34 | tok/s 16307
step   1950 | loss 1.8650 | lr 3.00e-04 | grad 3.36 | tok/s 16248
step   1960 | loss 1.4537 | lr 3.00e-04 | grad 4.22 | tok/s 16452
step   1970 | loss 1.5071 | lr 3.00e-04 | grad 2.52 | tok/s 16059
step   1980 | loss 1.5801 | lr 3.00e-04 | grad 2.36 | tok/s 14415
step   1990 | loss 1.6563 | lr 3.00e-04 | grad 2.59 | tok/s 15617
step   2000 | loss 1.5149 | lr 3.00e-04 | grad 2.56 | tok/s 15849
  >>> saved checkpoint: checkpoint_step_002000_loss_1.5149.pt
step   2010 | loss 1.1865 | lr 3.00e-04 | grad 2.20 | tok/s 6319
step   2020 | loss 1.3267 | lr 3.00e-04 | grad 2.88 | tok/s 16166
step   2030 | loss 0.9581 | lr 3.00e-04 | grad 4.94 | tok/s 16639
step   2040 | loss 1.3387 | lr 3.00e-04 | grad 2.61 | tok/s 16578
step   2050 | loss 1.2615 | lr 3.00e-04 | grad 2.23 | tok/s 16034
step   2060 | loss 1.6407 | lr 3.00e-04 | grad 2.27 | tok/s 15594
step   2070 | loss 1.8374 | lr 3.00e-04 | grad 6.97 | tok/s 15737
step   2080 | loss 2.1533 | lr 3.00e-04 | grad 4.28 | tok/s 16587
step   2090 | loss 1.6428 | lr 3.00e-04 | grad 2.66 | tok/s 16243
step   2100 | loss 1.4113 | lr 3.00e-04 | grad 2.61 | tok/s 16281
step   2110 | loss 1.4754 | lr 3.00e-04 | grad 2.17 | tok/s 15430
step   2120 | loss 0.8628 | lr 3.00e-04 | grad 1.85 | tok/s 16611
step   2130 | loss 1.2723 | lr 3.00e-04 | grad 3.92 | tok/s 15921
step   2140 | loss 1.4638 | lr 3.00e-04 | grad 1.88 | tok/s 16074
step   2150 | loss 1.2983 | lr 3.00e-04 | grad 2.09 | tok/s 16544
step   2160 | loss 1.1844 | lr 3.00e-04 | grad 2.22 | tok/s 15764
step   2170 | loss 1.2506 | lr 3.00e-04 | grad 1.66 | tok/s 16525
step   2180 | loss 1.1927 | lr 3.00e-04 | grad 1.80 | tok/s 16530
step   2190 | loss 1.2174 | lr 3.00e-04 | grad 2.06 | tok/s 16517
step   2200 | loss 1.1784 | lr 3.00e-04 | grad 1.76 | tok/s 16531
step   2210 | loss 1.1475 | lr 3.00e-04 | grad 2.08 | tok/s 16515
step   2220 | loss 1.1410 | lr 3.00e-04 | grad 1.86 | tok/s 16499
step   2230 | loss 1.4093 | lr 3.00e-04 | grad 2.64 | tok/s 16178
step   2240 | loss 1.3207 | lr 3.00e-04 | grad 2.12 | tok/s 15923
step   2250 | loss 1.6257 | lr 3.00e-04 | grad 7.66 | tok/s 16529
step   2260 | loss 1.6107 | lr 3.00e-04 | grad 2.41 | tok/s 15977
step   2270 | loss 1.9607 | lr 3.00e-04 | grad 3.12 | tok/s 16364
step   2280 | loss 1.4393 | lr 3.00e-04 | grad 3.31 | tok/s 16549
step   2290 | loss 1.4790 | lr 3.00e-04 | grad 6.28 | tok/s 15924
step   2300 | loss 1.4350 | lr 3.00e-04 | grad 3.22 | tok/s 15311
step   2310 | loss 1.4335 | lr 3.00e-04 | grad 2.84 | tok/s 15768
step   2320 | loss 1.8628 | lr 3.00e-04 | grad 3.42 | tok/s 15692

Training complete! Final step: 2321
