Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_88/levelE88_100m_20260127_155052
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 479,142,902 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.0286 | lr 3.00e-04 | grad 9.06 | tok/s 7914
step     20 | loss 2.7231 | lr 3.00e-04 | grad 2.86 | tok/s 12822
step     30 | loss 2.9623 | lr 3.00e-04 | grad 6.19 | tok/s 13446
step     40 | loss 4.2708 | lr 3.00e-04 | grad 28.50 | tok/s 13629
step     50 | loss 4.3261 | lr 3.00e-04 | grad 12.44 | tok/s 13771
step     60 | loss 3.3270 | lr 3.00e-04 | grad 9.44 | tok/s 13731
step     70 | loss 2.7503 | lr 3.00e-04 | grad 5.78 | tok/s 13711
step     80 | loss 2.4808 | lr 3.00e-04 | grad 4.31 | tok/s 13677
step     90 | loss 2.3299 | lr 3.00e-04 | grad 3.56 | tok/s 13658
step    100 | loss 2.1581 | lr 3.00e-04 | grad 3.09 | tok/s 13634
step    110 | loss 2.1959 | lr 3.00e-04 | grad 2.81 | tok/s 13539
step    120 | loss 2.6777 | lr 3.00e-04 | grad 1.83 | tok/s 12870
step    130 | loss 2.1048 | lr 3.00e-04 | grad 4.72 | tok/s 13180
step    140 | loss 2.3637 | lr 3.00e-04 | grad 6.72 | tok/s 13186
step    150 | loss 1.3820 | lr 3.00e-04 | grad 4.62 | tok/s 13502
step    160 | loss 2.3166 | lr 3.00e-04 | grad 2.03 | tok/s 13075
step    170 | loss 2.2871 | lr 3.00e-04 | grad 1.62 | tok/s 12860
step    180 | loss 1.8331 | lr 3.00e-04 | grad 2.73 | tok/s 13187
step    190 | loss 1.9186 | lr 3.00e-04 | grad 2.05 | tok/s 12938
step    200 | loss 1.6620 | lr 3.00e-04 | grad 1.54 | tok/s 13541
step    210 | loss 1.8798 | lr 3.00e-04 | grad 4.72 | tok/s 12862
step    220 | loss 2.2085 | lr 3.00e-04 | grad 3.00 | tok/s 12980
step    230 | loss 1.9534 | lr 3.00e-04 | grad 2.38 | tok/s 12976
step    240 | loss 2.2698 | lr 3.00e-04 | grad 5.03 | tok/s 13145
step    250 | loss 1.7719 | lr 3.00e-04 | grad 1.48 | tok/s 13080
step    260 | loss 1.8954 | lr 3.00e-04 | grad 2.81 | tok/s 13438
step    270 | loss 1.8222 | lr 3.00e-04 | grad 1.74 | tok/s 13130
step    280 | loss 1.7769 | lr 3.00e-04 | grad 1.66 | tok/s 12326
step    290 | loss 1.6711 | lr 3.00e-04 | grad 1.95 | tok/s 12752
step    300 | loss 1.9715 | lr 3.00e-04 | grad 1.87 | tok/s 12853
step    310 | loss 1.6676 | lr 3.00e-04 | grad 1.62 | tok/s 12807
step    320 | loss 1.8744 | lr 3.00e-04 | grad 2.58 | tok/s 12947
step    330 | loss 1.7156 | lr 3.00e-04 | grad 1.62 | tok/s 13090
step    340 | loss 2.0242 | lr 3.00e-04 | grad 2.08 | tok/s 13024
step    350 | loss 1.7217 | lr 3.00e-04 | grad 1.77 | tok/s 13402
step    360 | loss 1.5842 | lr 3.00e-04 | grad 1.84 | tok/s 12831
step    370 | loss 1.4857 | lr 3.00e-04 | grad 1.56 | tok/s 13516
step    380 | loss 1.2237 | lr 3.00e-04 | grad 1.57 | tok/s 13639
step    390 | loss 1.1225 | lr 3.00e-04 | grad 1.38 | tok/s 13633
step    400 | loss 1.7408 | lr 3.00e-04 | grad 1.63 | tok/s 12911
step    410 | loss 1.7515 | lr 3.00e-04 | grad 2.08 | tok/s 13035
step    420 | loss 1.6271 | lr 3.00e-04 | grad 3.20 | tok/s 13590
step    430 | loss 1.6151 | lr 3.00e-04 | grad 1.72 | tok/s 13389
step    440 | loss 1.6976 | lr 3.00e-04 | grad 2.05 | tok/s 12972
step    450 | loss 1.6260 | lr 3.00e-04 | grad 1.39 | tok/s 13103
step    460 | loss 1.5973 | lr 3.00e-04 | grad 1.88 | tok/s 13318
step    470 | loss 1.5599 | lr 3.00e-04 | grad 2.92 | tok/s 13208
step    480 | loss 1.5738 | lr 3.00e-04 | grad 2.48 | tok/s 13486
step    490 | loss 1.6977 | lr 3.00e-04 | grad 2.17 | tok/s 12938
step    500 | loss 1.8044 | lr 3.00e-04 | grad 1.60 | tok/s 13148
step    510 | loss 1.6691 | lr 3.00e-04 | grad 1.38 | tok/s 12559
step    520 | loss 1.5330 | lr 3.00e-04 | grad 1.84 | tok/s 13177
step    530 | loss 1.7106 | lr 3.00e-04 | grad 1.86 | tok/s 12946
step    540 | loss 1.5926 | lr 3.00e-04 | grad 1.46 | tok/s 12687
step    550 | loss 1.3614 | lr 3.00e-04 | grad 2.44 | tok/s 12994
step    560 | loss 1.4413 | lr 3.00e-04 | grad 1.58 | tok/s 13637
step    570 | loss 1.3483 | lr 3.00e-04 | grad 1.56 | tok/s 13617
step    580 | loss 1.3027 | lr 3.00e-04 | grad 1.23 | tok/s 13618
step    590 | loss 1.3346 | lr 3.00e-04 | grad 1.23 | tok/s 13615
step    600 | loss 1.2749 | lr 3.00e-04 | grad 1.51 | tok/s 13626
step    610 | loss 1.3056 | lr 3.00e-04 | grad 1.36 | tok/s 13640
step    620 | loss 1.2961 | lr 3.00e-04 | grad 1.48 | tok/s 13588
step    630 | loss 1.6568 | lr 3.00e-04 | grad 4.12 | tok/s 12816
step    640 | loss 1.7301 | lr 3.00e-04 | grad 1.53 | tok/s 12991
step    650 | loss 1.5488 | lr 3.00e-04 | grad 1.59 | tok/s 12989
step    660 | loss 1.5978 | lr 3.00e-04 | grad 1.59 | tok/s 13478
step    670 | loss 1.6184 | lr 3.00e-04 | grad 4.62 | tok/s 13055
step    680 | loss 1.6351 | lr 3.00e-04 | grad 1.77 | tok/s 12822
step    690 | loss 1.5654 | lr 3.00e-04 | grad 1.70 | tok/s 12740
step    700 | loss 1.4780 | lr 3.00e-04 | grad 1.27 | tok/s 13012
step    710 | loss 1.6434 | lr 3.00e-04 | grad 2.80 | tok/s 12813
step    720 | loss 1.3059 | lr 3.00e-04 | grad 1.39 | tok/s 13332
step    730 | loss 1.4684 | lr 3.00e-04 | grad 1.34 | tok/s 13111
step    740 | loss 1.7696 | lr 3.00e-04 | grad 3.20 | tok/s 13472
step    750 | loss 1.5339 | lr 3.00e-04 | grad 1.30 | tok/s 13638
step    760 | loss 1.5353 | lr 3.00e-04 | grad 2.88 | tok/s 13367
step    770 | loss 1.5746 | lr 3.00e-04 | grad 1.70 | tok/s 13124
step    780 | loss 1.4843 | lr 3.00e-04 | grad 1.68 | tok/s 13225
step    790 | loss 1.6321 | lr 3.00e-04 | grad 4.25 | tok/s 13512
step    800 | loss 1.3254 | lr 3.00e-04 | grad 1.12 | tok/s 13272
step    810 | loss 1.3125 | lr 3.00e-04 | grad 2.48 | tok/s 12818
step    820 | loss 1.4130 | lr 3.00e-04 | grad 1.67 | tok/s 13108
step    830 | loss 1.4947 | lr 3.00e-04 | grad 1.21 | tok/s 12982
step    840 | loss 1.6070 | lr 3.00e-04 | grad 1.42 | tok/s 12915
step    850 | loss 1.5424 | lr 3.00e-04 | grad 1.38 | tok/s 13206
step    860 | loss 1.5866 | lr 3.00e-04 | grad 2.16 | tok/s 13401
step    870 | loss 1.4049 | lr 3.00e-04 | grad 1.67 | tok/s 13485
step    880 | loss 1.5892 | lr 3.00e-04 | grad 1.53 | tok/s 13253
step    890 | loss 1.4867 | lr 3.00e-04 | grad 1.21 | tok/s 13064
step    900 | loss 1.5333 | lr 3.00e-04 | grad 1.52 | tok/s 13096
step    910 | loss 1.5213 | lr 3.00e-04 | grad 6.16 | tok/s 13000
step    920 | loss 1.4816 | lr 3.00e-04 | grad 1.45 | tok/s 13131
step    930 | loss 1.3915 | lr 3.00e-04 | grad 1.70 | tok/s 13239
step    940 | loss 1.3532 | lr 3.00e-04 | grad 1.62 | tok/s 12966
step    950 | loss 1.4932 | lr 3.00e-04 | grad 2.02 | tok/s 12789
step    960 | loss 1.4411 | lr 3.00e-04 | grad 1.22 | tok/s 13114
step    970 | loss 1.4730 | lr 3.00e-04 | grad 1.42 | tok/s 13126
step    980 | loss 1.8973 | lr 3.00e-04 | grad 3.02 | tok/s 13653

Training complete! Final step: 988
