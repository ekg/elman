Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_114/levelE88_100m_20260127_163240
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 500,601,192 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 5.0332 | lr 3.00e-04 | grad 32.75 | tok/s 4960
step     20 | loss 2.8041 | lr 3.00e-04 | grad 8.81 | tok/s 11953
step     30 | loss 2.5852 | lr 3.00e-04 | grad 5.19 | tok/s 11852
step     40 | loss 2.4341 | lr 3.00e-04 | grad 36.50 | tok/s 11281
step     50 | loss 3.3732 | lr 3.00e-04 | grad 21.12 | tok/s 11744
step     60 | loss 2.0845 | lr 3.00e-04 | grad 8.94 | tok/s 12054
step     70 | loss 1.9750 | lr 3.00e-04 | grad 2.77 | tok/s 11953
step     80 | loss 5.9242 | lr 3.00e-04 | grad 32.25 | tok/s 9994
step     90 | loss 5.6850 | lr 3.00e-04 | grad 130.00 | tok/s 12431
step    100 | loss 5.0117 | lr 3.00e-04 | grad 83.00 | tok/s 12391
step    110 | loss 4.5266 | lr 3.00e-04 | grad 21.00 | tok/s 12535
step    120 | loss 4.3250 | lr 3.00e-04 | grad 60.75 | tok/s 8990
step    130 | loss 3.7831 | lr 3.00e-04 | grad 6.94 | tok/s 12239
step    140 | loss 3.4475 | lr 3.00e-04 | grad 40.00 | tok/s 12447
step    150 | loss 3.6967 | lr 3.00e-04 | grad 8.25 | tok/s 9780
step    160 | loss 2.8965 | lr 3.00e-04 | grad 31.38 | tok/s 12410
step    170 | loss 2.8671 | lr 3.00e-04 | grad 15.69 | tok/s 12474
step    180 | loss 2.8026 | lr 3.00e-04 | grad 22.38 | tok/s 12369
step    190 | loss 2.7615 | lr 3.00e-04 | grad 18.12 | tok/s 12391
step    200 | loss 2.4232 | lr 3.00e-04 | grad 9.44 | tok/s 12501
step    210 | loss 2.5086 | lr 3.00e-04 | grad 5.62 | tok/s 12145
step    220 | loss 2.1273 | lr 3.00e-04 | grad 3.36 | tok/s 12215
step    230 | loss 2.4881 | lr 3.00e-04 | grad 2.28 | tok/s 10375
step    240 | loss 2.2700 | lr 3.00e-04 | grad 2.33 | tok/s 11701
step    250 | loss 1.9705 | lr 3.00e-04 | grad 2.12 | tok/s 11647
step    260 | loss 1.7581 | lr 3.00e-04 | grad 7.31 | tok/s 12063
step    270 | loss 2.1150 | lr 3.00e-04 | grad 2.55 | tok/s 12004
step    280 | loss 2.4973 | lr 3.00e-04 | grad 10.62 | tok/s 11985
step    290 | loss 1.1852 | lr 3.00e-04 | grad 5.16 | tok/s 12248
step    300 | loss 1.2183 | lr 3.00e-04 | grad 4.38 | tok/s 12070
step    310 | loss 2.2248 | lr 3.00e-04 | grad 3.12 | tok/s 11189
step    320 | loss 2.0100 | lr 3.00e-04 | grad 2.55 | tok/s 11503
step    330 | loss 2.0815 | lr 3.00e-04 | grad 4.44 | tok/s 11727
step    340 | loss 2.2557 | lr 3.00e-04 | grad 2.17 | tok/s 11895
step    350 | loss 1.8540 | lr 3.00e-04 | grad 4.12 | tok/s 12085
step    360 | loss 1.5223 | lr 3.00e-04 | grad 3.05 | tok/s 11889
step    370 | loss 1.8134 | lr 3.00e-04 | grad 1.91 | tok/s 11093
step    380 | loss 1.8584 | lr 3.00e-04 | grad 2.14 | tok/s 12187
step    390 | loss 1.5518 | lr 3.00e-04 | grad 1.91 | tok/s 9993
step    400 | loss 1.5075 | lr 3.00e-04 | grad 2.06 | tok/s 12130
step    410 | loss 1.4836 | lr 3.00e-04 | grad 2.36 | tok/s 11442
step    420 | loss 2.1106 | lr 3.00e-04 | grad 3.94 | tok/s 11867
step    430 | loss 2.2617 | lr 3.00e-04 | grad 2.66 | tok/s 11682
step    440 | loss 1.9872 | lr 3.00e-04 | grad 5.91 | tok/s 11684
step    450 | loss 1.9450 | lr 3.00e-04 | grad 2.47 | tok/s 11672
step    460 | loss 1.8141 | lr 3.00e-04 | grad 3.05 | tok/s 12016
step    470 | loss 1.8774 | lr 3.00e-04 | grad 2.55 | tok/s 9636
step    480 | loss 2.3451 | lr 3.00e-04 | grad 2.09 | tok/s 11945
step    490 | loss 1.6296 | lr 3.00e-04 | grad 2.59 | tok/s 11630
step    500 | loss 1.7928 | lr 3.00e-04 | grad 2.53 | tok/s 12189
step    510 | loss 1.8114 | lr 3.00e-04 | grad 2.73 | tok/s 12206
step    520 | loss 1.8290 | lr 3.00e-04 | grad 3.77 | tok/s 11980
step    530 | loss 1.9061 | lr 3.00e-04 | grad 4.25 | tok/s 11955
step    540 | loss 1.5833 | lr 3.00e-04 | grad 2.20 | tok/s 11726
step    550 | loss 1.7535 | lr 3.00e-04 | grad 13.38 | tok/s 8858
step    560 | loss 1.6915 | lr 3.00e-04 | grad 2.16 | tok/s 11889
step    570 | loss 1.6520 | lr 3.00e-04 | grad 2.03 | tok/s 11589
step    580 | loss 1.5702 | lr 3.00e-04 | grad 1.75 | tok/s 11492
step    590 | loss 2.1097 | lr 3.00e-04 | grad 3.00 | tok/s 11770
step    600 | loss 1.7210 | lr 3.00e-04 | grad 2.70 | tok/s 11657
step    610 | loss 1.5901 | lr 3.00e-04 | grad 1.64 | tok/s 11480
step    620 | loss 1.6893 | lr 3.00e-04 | grad 4.25 | tok/s 11456
step    630 | loss 1.7419 | lr 3.00e-04 | grad 2.28 | tok/s 9591
step    640 | loss 1.7162 | lr 3.00e-04 | grad 2.25 | tok/s 11711
step    650 | loss 1.7813 | lr 3.00e-04 | grad 2.61 | tok/s 11709
step    660 | loss 1.7708 | lr 3.00e-04 | grad 10.38 | tok/s 11920
step    670 | loss 1.9273 | lr 3.00e-04 | grad 1.87 | tok/s 12125
step    680 | loss 1.8390 | lr 3.00e-04 | grad 2.09 | tok/s 11662
step    690 | loss 1.6163 | lr 3.00e-04 | grad 2.41 | tok/s 12373
step    700 | loss 1.5955 | lr 3.00e-04 | grad 2.11 | tok/s 11677
step    710 | loss 1.5097 | lr 3.00e-04 | grad 2.05 | tok/s 9257
step    720 | loss 1.3764 | lr 3.00e-04 | grad 1.59 | tok/s 12480
step    730 | loss 1.5323 | lr 3.00e-04 | grad 1.98 | tok/s 12255
step    740 | loss 1.2699 | lr 3.00e-04 | grad 1.83 | tok/s 12298
step    750 | loss 1.1628 | lr 3.00e-04 | grad 1.91 | tok/s 12237
step    760 | loss 1.1062 | lr 3.00e-04 | grad 1.88 | tok/s 12289
step    770 | loss 1.0435 | lr 3.00e-04 | grad 1.70 | tok/s 12225
step    780 | loss 1.0257 | lr 3.00e-04 | grad 2.19 | tok/s 12093
step    790 | loss 1.7699 | lr 3.00e-04 | grad 2.80 | tok/s 9215
step    800 | loss 1.8201 | lr 3.00e-04 | grad 1.91 | tok/s 11884
step    810 | loss 1.6990 | lr 3.00e-04 | grad 1.86 | tok/s 10552
step    820 | loss 1.5843 | lr 3.00e-04 | grad 2.52 | tok/s 5416
step    830 | loss 1.6149 | lr 3.00e-04 | grad 2.53 | tok/s 7097
step    840 | loss 1.5926 | lr 3.00e-04 | grad 2.62 | tok/s 5241
step    850 | loss 1.5919 | lr 3.00e-04 | grad 2.33 | tok/s 10388
step    860 | loss 1.7114 | lr 3.00e-04 | grad 3.23 | tok/s 11108
step    870 | loss 1.6268 | lr 3.00e-04 | grad 1.80 | tok/s 6569
step    880 | loss 1.5889 | lr 3.00e-04 | grad 1.71 | tok/s 11974
step    890 | loss 1.4630 | lr 3.00e-04 | grad 2.39 | tok/s 12066
step    900 | loss 1.5960 | lr 3.00e-04 | grad 3.36 | tok/s 11042
step    910 | loss 1.5699 | lr 3.00e-04 | grad 1.60 | tok/s 11516
step    920 | loss 1.4036 | lr 3.00e-04 | grad 1.81 | tok/s 12353
step    930 | loss 1.5589 | lr 3.00e-04 | grad 1.99 | tok/s 12166
step    940 | loss 1.3658 | lr 3.00e-04 | grad 1.98 | tok/s 9434
step    950 | loss 1.8073 | lr 3.00e-04 | grad 2.86 | tok/s 7674
step    960 | loss 1.5945 | lr 3.00e-04 | grad 2.42 | tok/s 7887
step    970 | loss 1.5720 | lr 3.00e-04 | grad 3.55 | tok/s 9134
step    980 | loss 1.7708 | lr 3.00e-04 | grad 2.31 | tok/s 11758
step    990 | loss 1.6077 | lr 3.00e-04 | grad 2.20 | tok/s 11073
step   1000 | loss 1.6757 | lr 3.00e-04 | grad 1.91 | tok/s 6408
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6757.pt
step   1010 | loss 1.5735 | lr 3.00e-04 | grad 2.36 | tok/s 2094
step   1020 | loss 1.6890 | lr 3.00e-04 | grad 3.16 | tok/s 3897
step   1030 | loss 1.7613 | lr 3.00e-04 | grad 3.75 | tok/s 8183
step   1040 | loss 1.5653 | lr 3.00e-04 | grad 1.95 | tok/s 11861
step   1050 | loss 1.3960 | lr 3.00e-04 | grad 1.95 | tok/s 10824
step   1060 | loss 1.1152 | lr 3.00e-04 | grad 1.97 | tok/s 12006
step   1070 | loss 1.5484 | lr 3.00e-04 | grad 1.72 | tok/s 12135
step   1080 | loss 1.3866 | lr 3.00e-04 | grad 1.77 | tok/s 12572
step   1090 | loss 1.3539 | lr 3.00e-04 | grad 1.77 | tok/s 12644
step   1100 | loss 1.2730 | lr 3.00e-04 | grad 1.62 | tok/s 11127
step   1110 | loss 1.3244 | lr 3.00e-04 | grad 1.61 | tok/s 12591
step   1120 | loss 1.2665 | lr 3.00e-04 | grad 1.42 | tok/s 12541
step   1130 | loss 1.2405 | lr 3.00e-04 | grad 1.60 | tok/s 12419
step   1140 | loss 1.3369 | lr 3.00e-04 | grad 2.11 | tok/s 12460
step   1150 | loss 1.2744 | lr 3.00e-04 | grad 1.58 | tok/s 12399
step   1160 | loss 1.2124 | lr 3.00e-04 | grad 1.91 | tok/s 12369
step   1170 | loss 1.2665 | lr 3.00e-04 | grad 1.61 | tok/s 12535
step   1180 | loss 1.2994 | lr 3.00e-04 | grad 1.80 | tok/s 12023
step   1190 | loss 1.2526 | lr 3.00e-04 | grad 1.32 | tok/s 12289
step   1200 | loss 1.2765 | lr 3.00e-04 | grad 1.57 | tok/s 12427
step   1210 | loss 1.6354 | lr 3.00e-04 | grad 3.72 | tok/s 12005
step   1220 | loss 1.6342 | lr 3.00e-04 | grad 3.67 | tok/s 11555
step   1230 | loss 1.4141 | lr 3.00e-04 | grad 2.06 | tok/s 11871
step   1240 | loss 1.7486 | lr 3.00e-04 | grad 3.34 | tok/s 11515
step   1250 | loss 1.5049 | lr 3.00e-04 | grad 1.90 | tok/s 11688
step   1260 | loss 1.5851 | lr 3.00e-04 | grad 2.59 | tok/s 9530
step   1270 | loss 1.4630 | lr 3.00e-04 | grad 1.98 | tok/s 11607
step   1280 | loss 1.5578 | lr 3.00e-04 | grad 2.88 | tok/s 12216
step   1290 | loss 1.6970 | lr 3.00e-04 | grad 2.03 | tok/s 12399
step   1300 | loss 1.3338 | lr 3.00e-04 | grad 3.61 | tok/s 11588
step   1310 | loss 1.7799 | lr 3.00e-04 | grad 1.98 | tok/s 11441
step   1320 | loss 1.6676 | lr 3.00e-04 | grad 1.77 | tok/s 11867
step   1330 | loss 1.4288 | lr 3.00e-04 | grad 1.93 | tok/s 11636
step   1340 | loss 1.6367 | lr 3.00e-04 | grad 4.28 | tok/s 9294
step   1350 | loss 1.5370 | lr 3.00e-04 | grad 1.62 | tok/s 11702
step   1360 | loss 1.5055 | lr 3.00e-04 | grad 2.50 | tok/s 11605
step   1370 | loss 1.3855 | lr 3.00e-04 | grad 1.77 | tok/s 11774
step   1380 | loss 1.6564 | lr 3.00e-04 | grad 8.12 | tok/s 11458
step   1390 | loss 1.4227 | lr 3.00e-04 | grad 1.70 | tok/s 11999
step   1400 | loss 1.2833 | lr 3.00e-04 | grad 1.62 | tok/s 11954
step   1410 | loss 1.1290 | lr 3.00e-04 | grad 1.55 | tok/s 9845
step   1420 | loss 1.6087 | lr 3.00e-04 | grad 2.02 | tok/s 11725
step   1430 | loss 1.5480 | lr 3.00e-04 | grad 1.72 | tok/s 12048
step   1440 | loss 1.7817 | lr 3.00e-04 | grad 7.16 | tok/s 12203
step   1450 | loss 1.7071 | lr 3.00e-04 | grad 2.09 | tok/s 12401
step   1460 | loss 1.3556 | lr 3.00e-04 | grad 1.91 | tok/s 12423
step   1470 | loss 1.5290 | lr 3.00e-04 | grad 3.16 | tok/s 12152
step   1480 | loss 1.4201 | lr 3.00e-04 | grad 1.91 | tok/s 12103
step   1490 | loss 1.5007 | lr 3.00e-04 | grad 2.06 | tok/s 10351
step   1500 | loss 1.5593 | lr 3.00e-04 | grad 1.83 | tok/s 11575
step   1510 | loss 1.4144 | lr 3.00e-04 | grad 2.23 | tok/s 12058
step   1520 | loss 1.5317 | lr 3.00e-04 | grad 2.97 | tok/s 11793
step   1530 | loss 1.3484 | lr 3.00e-04 | grad 1.57 | tok/s 12207
step   1540 | loss 1.6556 | lr 3.00e-04 | grad 4.25 | tok/s 12103
step   1550 | loss 1.7249 | lr 3.00e-04 | grad 3.73 | tok/s 11863
step   1560 | loss 1.1456 | lr 3.00e-04 | grad 1.59 | tok/s 12315
step   1570 | loss 0.9111 | lr 3.00e-04 | grad 1.78 | tok/s 11140
step   1580 | loss 1.4081 | lr 3.00e-04 | grad 3.42 | tok/s 11228
step   1590 | loss 1.4031 | lr 3.00e-04 | grad 1.86 | tok/s 12170
step   1600 | loss 1.2624 | lr 3.00e-04 | grad 2.16 | tok/s 12258

Training complete! Final step: 1604
