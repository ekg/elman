Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_51/levelE88_100m_20260127_150847
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 495,127,040 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0119 | lr 3.00e-04 | grad 10.94 | tok/s 5149
step     20 | loss 2.6689 | lr 3.00e-04 | grad 4.84 | tok/s 12279
step     30 | loss 2.4855 | lr 3.00e-04 | grad 2.75 | tok/s 12494
step     40 | loss 2.3242 | lr 3.00e-04 | grad 3.08 | tok/s 11906
step     50 | loss 2.9329 | lr 3.00e-04 | grad 10.94 | tok/s 12224
step     60 | loss 2.0317 | lr 3.00e-04 | grad 2.64 | tok/s 12586
step     70 | loss 1.8759 | lr 3.00e-04 | grad 3.67 | tok/s 12615
step     80 | loss 5.1636 | lr 3.00e-04 | grad 43.25 | tok/s 12705
step     90 | loss 4.7141 | lr 3.00e-04 | grad 7.09 | tok/s 12950
step    100 | loss 3.8935 | lr 3.00e-04 | grad 6.12 | tok/s 12943
step    110 | loss 3.2751 | lr 3.00e-04 | grad 9.25 | tok/s 12862
step    120 | loss 3.0052 | lr 3.00e-04 | grad 8.62 | tok/s 12835
step    130 | loss 2.7758 | lr 3.00e-04 | grad 10.12 | tok/s 12845
step    140 | loss 2.5819 | lr 3.00e-04 | grad 7.19 | tok/s 12888
step    150 | loss 2.5612 | lr 3.00e-04 | grad 7.03 | tok/s 12751
step    160 | loss 2.2259 | lr 3.00e-04 | grad 6.19 | tok/s 12777
step    170 | loss 2.3082 | lr 3.00e-04 | grad 8.19 | tok/s 12789
step    180 | loss 2.1123 | lr 3.00e-04 | grad 4.94 | tok/s 11854
step    190 | loss 2.2160 | lr 3.00e-04 | grad 3.58 | tok/s 12387
step    200 | loss 1.9270 | lr 3.00e-04 | grad 3.45 | tok/s 12742
step    210 | loss 1.9782 | lr 3.00e-04 | grad 4.34 | tok/s 12740
step    220 | loss 2.0880 | lr 3.00e-04 | grad 2.39 | tok/s 9971
step    230 | loss 2.1193 | lr 3.00e-04 | grad 2.38 | tok/s 12094
step    240 | loss 2.2574 | lr 3.00e-04 | grad 2.72 | tok/s 11934
step    250 | loss 2.0047 | lr 3.00e-04 | grad 1.73 | tok/s 12245
step    260 | loss 1.5498 | lr 3.00e-04 | grad 2.47 | tok/s 12511
step    270 | loss 2.0114 | lr 3.00e-04 | grad 1.73 | tok/s 12252
step    280 | loss 2.3966 | lr 3.00e-04 | grad 9.44 | tok/s 12256
step    290 | loss 1.0980 | lr 3.00e-04 | grad 4.78 | tok/s 12791
step    300 | loss 0.7355 | lr 3.00e-04 | grad 3.42 | tok/s 12037
step    310 | loss 2.3309 | lr 3.00e-04 | grad 2.91 | tok/s 12584
step    320 | loss 1.9251 | lr 3.00e-04 | grad 2.80 | tok/s 12242
step    330 | loss 1.9298 | lr 3.00e-04 | grad 2.14 | tok/s 11956
step    340 | loss 2.2231 | lr 3.00e-04 | grad 2.12 | tok/s 12035
step    350 | loss 1.7880 | lr 3.00e-04 | grad 4.22 | tok/s 11293
step    360 | loss 1.2337 | lr 3.00e-04 | grad 3.34 | tok/s 12605
step    370 | loss 1.7699 | lr 3.00e-04 | grad 2.23 | tok/s 11320
step    380 | loss 1.7494 | lr 3.00e-04 | grad 2.09 | tok/s 12346
step    390 | loss 1.5049 | lr 3.00e-04 | grad 1.83 | tok/s 12717
step    400 | loss 1.4846 | lr 3.00e-04 | grad 2.55 | tok/s 12583
step    410 | loss 1.2904 | lr 3.00e-04 | grad 2.52 | tok/s 12264
step    420 | loss 1.9051 | lr 3.00e-04 | grad 9.19 | tok/s 11805
step    430 | loss 1.9981 | lr 3.00e-04 | grad 1.83 | tok/s 12396
step    440 | loss 2.1602 | lr 3.00e-04 | grad 4.41 | tok/s 11944
step    450 | loss 1.8523 | lr 3.00e-04 | grad 1.64 | tok/s 12142
step    460 | loss 1.6418 | lr 3.00e-04 | grad 2.88 | tok/s 12064
step    470 | loss 1.8523 | lr 3.00e-04 | grad 2.38 | tok/s 12241
step    480 | loss 2.2691 | lr 3.00e-04 | grad 3.73 | tok/s 12477
step    490 | loss 1.7040 | lr 3.00e-04 | grad 1.85 | tok/s 11718
step    500 | loss 1.6927 | lr 3.00e-04 | grad 2.22 | tok/s 12493
step    510 | loss 1.6545 | lr 3.00e-04 | grad 1.84 | tok/s 12365
step    520 | loss 1.6398 | lr 3.00e-04 | grad 1.84 | tok/s 12347
step    530 | loss 1.8974 | lr 3.00e-04 | grad 1.73 | tok/s 12299
step    540 | loss 1.7030 | lr 3.00e-04 | grad 1.86 | tok/s 12195
step    550 | loss 1.5658 | lr 3.00e-04 | grad 2.12 | tok/s 11689
step    560 | loss 1.7106 | lr 3.00e-04 | grad 2.95 | tok/s 11558
step    570 | loss 1.6092 | lr 3.00e-04 | grad 3.50 | tok/s 11924
step    580 | loss 1.5346 | lr 3.00e-04 | grad 1.70 | tok/s 11710
step    590 | loss 1.8512 | lr 3.00e-04 | grad 2.25 | tok/s 12223
step    600 | loss 1.7859 | lr 3.00e-04 | grad 1.61 | tok/s 11742
step    610 | loss 1.5865 | lr 3.00e-04 | grad 1.87 | tok/s 11944
step    620 | loss 1.5676 | lr 3.00e-04 | grad 1.80 | tok/s 11933
step    630 | loss 1.6129 | lr 3.00e-04 | grad 2.19 | tok/s 11775
step    640 | loss 1.8692 | lr 3.00e-04 | grad 5.16 | tok/s 11895
step    650 | loss 1.6027 | lr 3.00e-04 | grad 2.50 | tok/s 12185
step    660 | loss 1.6812 | lr 3.00e-04 | grad 2.47 | tok/s 12364
step    670 | loss 1.9033 | lr 3.00e-04 | grad 2.56 | tok/s 12327
step    680 | loss 1.7000 | lr 3.00e-04 | grad 2.41 | tok/s 11957
step    690 | loss 1.7609 | lr 3.00e-04 | grad 2.27 | tok/s 12588
step    700 | loss 1.3928 | lr 3.00e-04 | grad 2.03 | tok/s 12728
step    710 | loss 1.6004 | lr 3.00e-04 | grad 2.86 | tok/s 11683
step    720 | loss 1.4758 | lr 3.00e-04 | grad 2.30 | tok/s 11949
step    730 | loss 1.2773 | lr 3.00e-04 | grad 2.50 | tok/s 12802
step    740 | loss 1.4267 | lr 3.00e-04 | grad 1.72 | tok/s 12606
step    750 | loss 1.1938 | lr 3.00e-04 | grad 1.52 | tok/s 12745
step    760 | loss 1.0824 | lr 3.00e-04 | grad 1.45 | tok/s 12726
step    770 | loss 1.0488 | lr 3.00e-04 | grad 1.65 | tok/s 12725
step    780 | loss 0.9595 | lr 3.00e-04 | grad 1.53 | tok/s 12746
step    790 | loss 1.1640 | lr 3.00e-04 | grad 2.27 | tok/s 12187
step    800 | loss 1.8694 | lr 3.00e-04 | grad 4.38 | tok/s 12459
step    810 | loss 1.6431 | lr 3.00e-04 | grad 4.66 | tok/s 12082
step    820 | loss 1.6579 | lr 3.00e-04 | grad 7.00 | tok/s 11885
step    830 | loss 1.4305 | lr 3.00e-04 | grad 1.88 | tok/s 12612
step    840 | loss 1.4232 | lr 3.00e-04 | grad 3.69 | tok/s 11279
step    850 | loss 1.5315 | lr 3.00e-04 | grad 3.23 | tok/s 12474
step    860 | loss 1.4503 | lr 3.00e-04 | grad 2.22 | tok/s 12392
step    870 | loss 1.4812 | lr 3.00e-04 | grad 1.84 | tok/s 12146
step    880 | loss 1.6769 | lr 3.00e-04 | grad 2.28 | tok/s 12111
step    890 | loss 1.6104 | lr 3.00e-04 | grad 1.67 | tok/s 12094
step    900 | loss 1.5426 | lr 3.00e-04 | grad 1.58 | tok/s 12101
step    910 | loss 1.4116 | lr 3.00e-04 | grad 1.96 | tok/s 12282
step    920 | loss 1.5466 | lr 3.00e-04 | grad 3.05 | tok/s 8951
step    930 | loss 1.5262 | lr 3.00e-04 | grad 1.52 | tok/s 11774
step    940 | loss 1.3568 | lr 3.00e-04 | grad 1.71 | tok/s 12707
step    950 | loss 1.4731 | lr 3.00e-04 | grad 2.03 | tok/s 12722
step    960 | loss 1.3149 | lr 3.00e-04 | grad 1.78 | tok/s 8904
step    970 | loss 1.7871 | lr 3.00e-04 | grad 2.95 | tok/s 11964
step    980 | loss 1.5511 | lr 3.00e-04 | grad 1.96 | tok/s 12104
step    990 | loss 1.4516 | lr 3.00e-04 | grad 1.65 | tok/s 12629
step   1000 | loss 1.8307 | lr 3.00e-04 | grad 5.47 | tok/s 12034
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8307.pt
step   1010 | loss 1.6536 | lr 3.00e-04 | grad 3.42 | tok/s 3739
step   1020 | loss 1.5165 | lr 3.00e-04 | grad 5.75 | tok/s 11798
step   1030 | loss 1.3671 | lr 3.00e-04 | grad 1.88 | tok/s 12743
step   1040 | loss 1.4476 | lr 3.00e-04 | grad 2.16 | tok/s 11874
step   1050 | loss 1.6823 | lr 3.00e-04 | grad 2.95 | tok/s 12629
step   1060 | loss 1.7044 | lr 3.00e-04 | grad 3.59 | tok/s 12653
step   1070 | loss 1.5070 | lr 3.00e-04 | grad 1.84 | tok/s 12113
step   1080 | loss 1.3510 | lr 3.00e-04 | grad 1.72 | tok/s 11810
step   1090 | loss 1.0820 | lr 3.00e-04 | grad 1.86 | tok/s 12571
step   1100 | loss 1.5004 | lr 3.00e-04 | grad 1.55 | tok/s 12509
step   1110 | loss 1.3456 | lr 3.00e-04 | grad 1.66 | tok/s 12879
step   1120 | loss 1.3148 | lr 3.00e-04 | grad 1.65 | tok/s 12888
step   1130 | loss 1.2389 | lr 3.00e-04 | grad 1.61 | tok/s 12900
step   1140 | loss 1.2901 | lr 3.00e-04 | grad 1.52 | tok/s 12817
step   1150 | loss 1.2316 | lr 3.00e-04 | grad 1.33 | tok/s 12724
step   1160 | loss 1.2116 | lr 3.00e-04 | grad 1.49 | tok/s 12715
step   1170 | loss 1.3046 | lr 3.00e-04 | grad 1.99 | tok/s 12680
step   1180 | loss 1.2364 | lr 3.00e-04 | grad 1.44 | tok/s 10479
step   1190 | loss 1.1768 | lr 3.00e-04 | grad 1.72 | tok/s 12290
step   1200 | loss 1.2333 | lr 3.00e-04 | grad 1.51 | tok/s 12832
step   1210 | loss 1.2686 | lr 3.00e-04 | grad 1.66 | tok/s 12736
step   1220 | loss 1.2214 | lr 3.00e-04 | grad 1.20 | tok/s 12795
step   1230 | loss 1.2441 | lr 3.00e-04 | grad 1.51 | tok/s 12917
step   1240 | loss 1.5307 | lr 3.00e-04 | grad 3.31 | tok/s 12310
step   1250 | loss 1.5954 | lr 3.00e-04 | grad 3.62 | tok/s 11935
step   1260 | loss 1.3759 | lr 3.00e-04 | grad 1.84 | tok/s 12249
step   1270 | loss 1.6927 | lr 3.00e-04 | grad 2.84 | tok/s 11804
step   1280 | loss 1.4676 | lr 3.00e-04 | grad 1.79 | tok/s 11839
step   1290 | loss 1.4769 | lr 3.00e-04 | grad 1.95 | tok/s 12201
step   1300 | loss 1.4583 | lr 3.00e-04 | grad 1.93 | tok/s 11836
step   1310 | loss 1.4830 | lr 3.00e-04 | grad 3.28 | tok/s 12425
step   1320 | loss 1.6573 | lr 3.00e-04 | grad 1.63 | tok/s 12788
step   1330 | loss 1.3036 | lr 3.00e-04 | grad 2.27 | tok/s 12172
step   1340 | loss 1.7250 | lr 3.00e-04 | grad 2.75 | tok/s 7899
step   1350 | loss 1.6203 | lr 3.00e-04 | grad 2.27 | tok/s 11522
step   1360 | loss 1.3683 | lr 3.00e-04 | grad 1.61 | tok/s 7545
step   1370 | loss 1.5611 | lr 3.00e-04 | grad 2.05 | tok/s 6897
step   1380 | loss 1.4978 | lr 3.00e-04 | grad 1.98 | tok/s 11788
step   1390 | loss 1.4066 | lr 3.00e-04 | grad 2.88 | tok/s 12057
step   1400 | loss 1.3968 | lr 3.00e-04 | grad 3.50 | tok/s 10529
step   1410 | loss 1.4885 | lr 3.00e-04 | grad 1.74 | tok/s 11291
step   1420 | loss 1.5492 | lr 3.00e-04 | grad 1.81 | tok/s 6605
step   1430 | loss 1.2502 | lr 3.00e-04 | grad 1.47 | tok/s 10188
step   1440 | loss 1.0956 | lr 3.00e-04 | grad 1.34 | tok/s 12888
step   1450 | loss 1.4845 | lr 3.00e-04 | grad 2.45 | tok/s 10601
step   1460 | loss 1.5226 | lr 3.00e-04 | grad 1.76 | tok/s 9959
step   1470 | loss 1.5813 | lr 3.00e-04 | grad 4.00 | tok/s 12117
step   1480 | loss 1.7392 | lr 3.00e-04 | grad 2.72 | tok/s 12703
step   1490 | loss 1.3725 | lr 3.00e-04 | grad 1.72 | tok/s 8718
step   1500 | loss 1.3999 | lr 3.00e-04 | grad 3.98 | tok/s 12634
step   1510 | loss 1.4400 | lr 3.00e-04 | grad 2.09 | tok/s 12699
step   1520 | loss 1.4419 | lr 3.00e-04 | grad 1.88 | tok/s 11035
step   1530 | loss 1.4817 | lr 3.00e-04 | grad 2.14 | tok/s 11988
step   1540 | loss 1.4348 | lr 3.00e-04 | grad 1.45 | tok/s 7486
step   1550 | loss 1.3095 | lr 3.00e-04 | grad 1.92 | tok/s 6252
step   1560 | loss 1.4861 | lr 3.00e-04 | grad 1.54 | tok/s 12086
step   1570 | loss 1.4487 | lr 3.00e-04 | grad 4.22 | tok/s 12553
step   1580 | loss 1.6604 | lr 3.00e-04 | grad 2.17 | tok/s 12532
step   1590 | loss 1.2376 | lr 3.00e-04 | grad 1.44 | tok/s 12379
step   1600 | loss 0.8400 | lr 3.00e-04 | grad 1.62 | tok/s 12622
step   1610 | loss 1.3047 | lr 3.00e-04 | grad 1.59 | tok/s 11541
step   1620 | loss 1.4591 | lr 3.00e-04 | grad 2.47 | tok/s 12207
step   1630 | loss 1.1753 | lr 3.00e-04 | grad 2.28 | tok/s 12705
step   1640 | loss 1.5196 | lr 3.00e-04 | grad 3.39 | tok/s 11544
step   1650 | loss 1.4625 | lr 3.00e-04 | grad 1.53 | tok/s 11936
step   1660 | loss 1.1607 | lr 3.00e-04 | grad 2.42 | tok/s 12398
step   1670 | loss 1.7266 | lr 3.00e-04 | grad 2.14 | tok/s 11851
step   1680 | loss 1.4660 | lr 3.00e-04 | grad 2.44 | tok/s 12037
step   1690 | loss 1.4661 | lr 3.00e-04 | grad 2.08 | tok/s 12481
step   1700 | loss 1.3810 | lr 3.00e-04 | grad 4.16 | tok/s 11920
step   1710 | loss 1.4779 | lr 3.00e-04 | grad 3.42 | tok/s 12488
step   1720 | loss 1.3180 | lr 3.00e-04 | grad 2.95 | tok/s 12702
step   1730 | loss 1.1453 | lr 3.00e-04 | grad 1.39 | tok/s 12593
step   1740 | loss 1.4683 | lr 3.00e-04 | grad 1.74 | tok/s 12261

Training complete! Final step: 1740
