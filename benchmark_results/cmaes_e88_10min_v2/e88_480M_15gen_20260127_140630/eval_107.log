Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_107/levelE88_100m_20260127_162209
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 463,409,152 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.1552 | lr 3.00e-04 | grad 9.38 | tok/s 7645
step     20 | loss 2.7868 | lr 3.00e-04 | grad 2.98 | tok/s 12375
step     30 | loss 2.9968 | lr 3.00e-04 | grad 5.88 | tok/s 13059
step     40 | loss 4.3842 | lr 3.00e-04 | grad 40.50 | tok/s 13254
step     50 | loss 4.6348 | lr 3.00e-04 | grad 18.12 | tok/s 13410
step     60 | loss 3.6634 | lr 3.00e-04 | grad 11.81 | tok/s 13361
step     70 | loss 2.9059 | lr 3.00e-04 | grad 8.12 | tok/s 13346
step     80 | loss 2.5681 | lr 3.00e-04 | grad 5.25 | tok/s 13279
step     90 | loss 2.3770 | lr 3.00e-04 | grad 3.77 | tok/s 13285
step    100 | loss 2.1931 | lr 3.00e-04 | grad 2.41 | tok/s 13238
step    110 | loss 2.2243 | lr 3.00e-04 | grad 2.67 | tok/s 13134
step    120 | loss 2.7089 | lr 3.00e-04 | grad 1.56 | tok/s 12519
step    130 | loss 2.1170 | lr 3.00e-04 | grad 4.41 | tok/s 12808
step    140 | loss 2.3768 | lr 3.00e-04 | grad 6.41 | tok/s 12837
step    150 | loss 1.3847 | lr 3.00e-04 | grad 4.47 | tok/s 13135
step    160 | loss 2.3300 | lr 3.00e-04 | grad 1.88 | tok/s 12703
step    170 | loss 2.2806 | lr 3.00e-04 | grad 1.45 | tok/s 12499
step    180 | loss 1.8862 | lr 3.00e-04 | grad 2.52 | tok/s 12769
step    190 | loss 1.9319 | lr 3.00e-04 | grad 1.77 | tok/s 12528
step    200 | loss 1.6788 | lr 3.00e-04 | grad 1.51 | tok/s 13145
step    210 | loss 1.9023 | lr 3.00e-04 | grad 3.88 | tok/s 12470
step    220 | loss 2.2069 | lr 3.00e-04 | grad 2.30 | tok/s 12588
step    230 | loss 1.9628 | lr 3.00e-04 | grad 2.38 | tok/s 12579
step    240 | loss 2.2801 | lr 3.00e-04 | grad 4.59 | tok/s 12738
step    250 | loss 1.7864 | lr 3.00e-04 | grad 1.41 | tok/s 12674
step    260 | loss 1.9077 | lr 3.00e-04 | grad 2.66 | tok/s 13029
step    270 | loss 1.8361 | lr 3.00e-04 | grad 1.67 | tok/s 12728
step    280 | loss 1.7873 | lr 3.00e-04 | grad 1.59 | tok/s 11946
step    290 | loss 1.6835 | lr 3.00e-04 | grad 1.86 | tok/s 12356
step    300 | loss 1.9782 | lr 3.00e-04 | grad 1.85 | tok/s 12458
step    310 | loss 1.6765 | lr 3.00e-04 | grad 1.58 | tok/s 12395
step    320 | loss 1.8845 | lr 3.00e-04 | grad 2.52 | tok/s 12528
step    330 | loss 1.7225 | lr 3.00e-04 | grad 1.60 | tok/s 12674
step    340 | loss 2.0401 | lr 3.00e-04 | grad 2.27 | tok/s 12597
step    350 | loss 1.7476 | lr 3.00e-04 | grad 1.74 | tok/s 12964
step    360 | loss 1.5900 | lr 3.00e-04 | grad 1.77 | tok/s 12393
step    370 | loss 1.5040 | lr 3.00e-04 | grad 1.45 | tok/s 13048
step    380 | loss 1.2418 | lr 3.00e-04 | grad 1.56 | tok/s 13188
step    390 | loss 1.1400 | lr 3.00e-04 | grad 1.39 | tok/s 13163
step    400 | loss 1.7510 | lr 3.00e-04 | grad 1.60 | tok/s 11891
step    410 | loss 1.7610 | lr 3.00e-04 | grad 2.05 | tok/s 12583
step    420 | loss 1.6415 | lr 3.00e-04 | grad 3.09 | tok/s 13153
step    430 | loss 1.6222 | lr 3.00e-04 | grad 1.71 | tok/s 12944
step    440 | loss 1.6996 | lr 3.00e-04 | grad 1.95 | tok/s 12531
step    450 | loss 1.6325 | lr 3.00e-04 | grad 1.35 | tok/s 12680
step    460 | loss 1.6013 | lr 3.00e-04 | grad 1.84 | tok/s 12892
step    470 | loss 1.5721 | lr 3.00e-04 | grad 3.00 | tok/s 12754
step    480 | loss 1.5905 | lr 3.00e-04 | grad 2.39 | tok/s 13048
step    490 | loss 1.7034 | lr 3.00e-04 | grad 2.14 | tok/s 12533
step    500 | loss 1.8080 | lr 3.00e-04 | grad 1.57 | tok/s 12744
step    510 | loss 1.6759 | lr 3.00e-04 | grad 1.32 | tok/s 12178
step    520 | loss 1.5405 | lr 3.00e-04 | grad 1.87 | tok/s 12758
step    530 | loss 1.7215 | lr 3.00e-04 | grad 1.82 | tok/s 12548
step    540 | loss 1.6048 | lr 3.00e-04 | grad 1.44 | tok/s 12276
step    550 | loss 1.3619 | lr 3.00e-04 | grad 2.36 | tok/s 12814
step    560 | loss 1.4493 | lr 3.00e-04 | grad 1.57 | tok/s 13199
step    570 | loss 1.3507 | lr 3.00e-04 | grad 1.59 | tok/s 13192
step    580 | loss 1.3086 | lr 3.00e-04 | grad 1.18 | tok/s 13197
step    590 | loss 1.3437 | lr 3.00e-04 | grad 1.18 | tok/s 13213
step    600 | loss 1.2799 | lr 3.00e-04 | grad 1.47 | tok/s 13204
step    610 | loss 1.3111 | lr 3.00e-04 | grad 1.34 | tok/s 13201
step    620 | loss 1.3008 | lr 3.00e-04 | grad 1.46 | tok/s 13140
step    630 | loss 1.6609 | lr 3.00e-04 | grad 3.78 | tok/s 12405
step    640 | loss 1.7406 | lr 3.00e-04 | grad 1.55 | tok/s 12577
step    650 | loss 1.5584 | lr 3.00e-04 | grad 1.56 | tok/s 12262
step    660 | loss 1.6066 | lr 3.00e-04 | grad 1.59 | tok/s 13049
step    670 | loss 1.6285 | lr 3.00e-04 | grad 4.56 | tok/s 12630
step    680 | loss 1.6360 | lr 3.00e-04 | grad 1.77 | tok/s 12425
step    690 | loss 1.5715 | lr 3.00e-04 | grad 1.67 | tok/s 12326
step    700 | loss 1.4796 | lr 3.00e-04 | grad 1.28 | tok/s 12611
step    710 | loss 1.6396 | lr 3.00e-04 | grad 2.80 | tok/s 12414
step    720 | loss 1.3099 | lr 3.00e-04 | grad 1.36 | tok/s 12895
step    730 | loss 1.4733 | lr 3.00e-04 | grad 1.31 | tok/s 12661
step    740 | loss 1.7842 | lr 3.00e-04 | grad 3.14 | tok/s 13006
step    750 | loss 1.5390 | lr 3.00e-04 | grad 1.31 | tok/s 13154
step    760 | loss 1.5384 | lr 3.00e-04 | grad 2.84 | tok/s 12884
step    770 | loss 1.5833 | lr 3.00e-04 | grad 1.72 | tok/s 12665
step    780 | loss 1.4919 | lr 3.00e-04 | grad 1.66 | tok/s 12747
step    790 | loss 1.6481 | lr 3.00e-04 | grad 4.16 | tok/s 13036
step    800 | loss 1.3312 | lr 3.00e-04 | grad 1.09 | tok/s 12766
step    810 | loss 1.3212 | lr 3.00e-04 | grad 2.47 | tok/s 12356
step    820 | loss 1.4215 | lr 3.00e-04 | grad 1.70 | tok/s 12609
step    830 | loss 1.4998 | lr 3.00e-04 | grad 1.21 | tok/s 12423
step    840 | loss 1.6172 | lr 3.00e-04 | grad 1.41 | tok/s 11956
step    850 | loss 1.5627 | lr 3.00e-04 | grad 1.38 | tok/s 12647
step    860 | loss 1.5930 | lr 3.00e-04 | grad 2.09 | tok/s 12890
step    870 | loss 1.4187 | lr 3.00e-04 | grad 1.64 | tok/s 12999
step    880 | loss 1.5916 | lr 3.00e-04 | grad 1.51 | tok/s 12708
step    890 | loss 1.4897 | lr 3.00e-04 | grad 1.16 | tok/s 12662
step    900 | loss 1.5384 | lr 3.00e-04 | grad 1.51 | tok/s 12584
step    910 | loss 1.5317 | lr 3.00e-04 | grad 6.03 | tok/s 12469
step    920 | loss 1.4903 | lr 3.00e-04 | grad 1.41 | tok/s 12608
step    930 | loss 1.3942 | lr 3.00e-04 | grad 1.73 | tok/s 12771
step    940 | loss 1.3639 | lr 3.00e-04 | grad 1.65 | tok/s 12484
step    950 | loss 1.5000 | lr 3.00e-04 | grad 1.96 | tok/s 12272

Training complete! Final step: 955
