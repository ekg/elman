Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_55/levelE88_100m_20260127_150846
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 487,400,910 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0418 | lr 3.00e-04 | grad 11.06 | tok/s 5238
step     20 | loss 2.6132 | lr 3.00e-04 | grad 5.75 | tok/s 12432
step     30 | loss 2.4778 | lr 3.00e-04 | grad 2.89 | tok/s 12552
step     40 | loss 2.3235 | lr 3.00e-04 | grad 3.08 | tok/s 12002
step     50 | loss 2.8889 | lr 3.00e-04 | grad 11.25 | tok/s 12288
step     60 | loss 2.0086 | lr 3.00e-04 | grad 2.72 | tok/s 12533
step     70 | loss 1.8601 | lr 3.00e-04 | grad 3.80 | tok/s 12695
step     80 | loss 5.5609 | lr 3.00e-04 | grad 50.25 | tok/s 12734
step     90 | loss 5.0936 | lr 3.00e-04 | grad 7.91 | tok/s 12948
step    100 | loss 4.0624 | lr 3.00e-04 | grad 6.94 | tok/s 12950
step    110 | loss 3.4300 | lr 3.00e-04 | grad 9.62 | tok/s 12954
step    120 | loss 3.0833 | lr 3.00e-04 | grad 9.62 | tok/s 12944
step    130 | loss 2.8037 | lr 3.00e-04 | grad 10.75 | tok/s 12886
step    140 | loss 2.6066 | lr 3.00e-04 | grad 6.97 | tok/s 12716
step    150 | loss 2.5817 | lr 3.00e-04 | grad 10.19 | tok/s 12850
step    160 | loss 2.2255 | lr 3.00e-04 | grad 6.22 | tok/s 12838
step    170 | loss 2.2541 | lr 3.00e-04 | grad 8.38 | tok/s 12796
step    180 | loss 2.0784 | lr 3.00e-04 | grad 3.62 | tok/s 12766
step    190 | loss 2.1936 | lr 3.00e-04 | grad 5.94 | tok/s 12787
step    200 | loss 1.9428 | lr 3.00e-04 | grad 3.44 | tok/s 12862
step    210 | loss 1.9506 | lr 3.00e-04 | grad 5.06 | tok/s 12753
step    220 | loss 2.1000 | lr 3.00e-04 | grad 2.55 | tok/s 12586
step    230 | loss 1.9885 | lr 3.00e-04 | grad 2.64 | tok/s 12401
step    240 | loss 2.2538 | lr 3.00e-04 | grad 3.69 | tok/s 11787
step    250 | loss 2.0755 | lr 3.00e-04 | grad 2.02 | tok/s 12175
step    260 | loss 1.5355 | lr 3.00e-04 | grad 2.28 | tok/s 12459
step    270 | loss 2.0510 | lr 3.00e-04 | grad 2.17 | tok/s 12400
step    280 | loss 2.2203 | lr 3.00e-04 | grad 4.41 | tok/s 12094
step    290 | loss 1.3389 | lr 3.00e-04 | grad 2.39 | tok/s 12675
step    300 | loss 0.5843 | lr 3.00e-04 | grad 3.19 | tok/s 12664
step    310 | loss 2.3703 | lr 3.00e-04 | grad 2.97 | tok/s 11462
step    320 | loss 1.9132 | lr 3.00e-04 | grad 4.25 | tok/s 12302
step    330 | loss 1.9186 | lr 3.00e-04 | grad 2.33 | tok/s 11846
step    340 | loss 2.2464 | lr 3.00e-04 | grad 2.22 | tok/s 12076
step    350 | loss 1.8700 | lr 3.00e-04 | grad 2.92 | tok/s 12364
step    360 | loss 1.1912 | lr 3.00e-04 | grad 5.28 | tok/s 12676
step    370 | loss 1.7853 | lr 3.00e-04 | grad 2.12 | tok/s 11458
step    380 | loss 1.7436 | lr 3.00e-04 | grad 1.98 | tok/s 12215
step    390 | loss 1.5231 | lr 3.00e-04 | grad 1.63 | tok/s 12732
step    400 | loss 1.4734 | lr 3.00e-04 | grad 2.02 | tok/s 12625
step    410 | loss 1.2698 | lr 3.00e-04 | grad 1.61 | tok/s 12459
step    420 | loss 1.7943 | lr 3.00e-04 | grad 3.45 | tok/s 11813
step    430 | loss 2.1312 | lr 3.00e-04 | grad 2.38 | tok/s 12539
step    440 | loss 2.1175 | lr 3.00e-04 | grad 3.31 | tok/s 11828
step    450 | loss 1.9113 | lr 3.00e-04 | grad 2.11 | tok/s 12215
step    460 | loss 1.7070 | lr 3.00e-04 | grad 2.33 | tok/s 11894
step    470 | loss 1.8100 | lr 3.00e-04 | grad 1.84 | tok/s 12353
step    480 | loss 2.2181 | lr 3.00e-04 | grad 5.41 | tok/s 12335
step    490 | loss 1.7711 | lr 3.00e-04 | grad 1.95 | tok/s 11652
step    500 | loss 1.6581 | lr 3.00e-04 | grad 2.70 | tok/s 12392
step    510 | loss 1.6919 | lr 3.00e-04 | grad 1.85 | tok/s 12651
step    520 | loss 1.6464 | lr 3.00e-04 | grad 1.66 | tok/s 12620
step    530 | loss 1.8965 | lr 3.00e-04 | grad 2.02 | tok/s 12099
step    540 | loss 1.7185 | lr 3.00e-04 | grad 1.75 | tok/s 12179
step    550 | loss 1.5557 | lr 3.00e-04 | grad 2.30 | tok/s 11872
step    560 | loss 1.6811 | lr 3.00e-04 | grad 3.11 | tok/s 9160
step    570 | loss 1.6216 | lr 3.00e-04 | grad 2.97 | tok/s 12092
step    580 | loss 1.5342 | lr 3.00e-04 | grad 1.73 | tok/s 11760
step    590 | loss 1.8609 | lr 3.00e-04 | grad 2.19 | tok/s 12221
step    600 | loss 1.7836 | lr 3.00e-04 | grad 1.62 | tok/s 11773
step    610 | loss 1.5853 | lr 3.00e-04 | grad 1.93 | tok/s 11928
step    620 | loss 1.5714 | lr 3.00e-04 | grad 1.80 | tok/s 11878
step    630 | loss 1.6171 | lr 3.00e-04 | grad 2.20 | tok/s 11823
step    640 | loss 1.8625 | lr 3.00e-04 | grad 5.03 | tok/s 11974
step    650 | loss 1.5962 | lr 3.00e-04 | grad 2.56 | tok/s 12221
step    660 | loss 1.6829 | lr 3.00e-04 | grad 2.48 | tok/s 12341
step    670 | loss 1.9342 | lr 3.00e-04 | grad 2.64 | tok/s 12302
step    680 | loss 1.6983 | lr 3.00e-04 | grad 2.44 | tok/s 11968
step    690 | loss 1.7643 | lr 3.00e-04 | grad 2.28 | tok/s 12663
step    700 | loss 1.3998 | lr 3.00e-04 | grad 2.06 | tok/s 12691
step    710 | loss 1.5926 | lr 3.00e-04 | grad 3.02 | tok/s 11626
step    720 | loss 1.4815 | lr 3.00e-04 | grad 2.31 | tok/s 11887
step    730 | loss 1.2775 | lr 3.00e-04 | grad 2.48 | tok/s 12718
step    740 | loss 1.4293 | lr 3.00e-04 | grad 1.81 | tok/s 12510
step    750 | loss 1.2024 | lr 3.00e-04 | grad 1.58 | tok/s 12699
step    760 | loss 1.0917 | lr 3.00e-04 | grad 1.48 | tok/s 12586
step    770 | loss 1.0517 | lr 3.00e-04 | grad 1.68 | tok/s 12696
step    780 | loss 0.9653 | lr 3.00e-04 | grad 1.55 | tok/s 12671
step    790 | loss 1.1692 | lr 3.00e-04 | grad 2.31 | tok/s 12109
step    800 | loss 1.8862 | lr 3.00e-04 | grad 4.47 | tok/s 12392
step    810 | loss 1.6499 | lr 3.00e-04 | grad 4.59 | tok/s 12049
step    820 | loss 1.6496 | lr 3.00e-04 | grad 6.88 | tok/s 11884
step    830 | loss 1.4412 | lr 3.00e-04 | grad 1.93 | tok/s 12506
step    840 | loss 1.4223 | lr 3.00e-04 | grad 3.45 | tok/s 12687
step    850 | loss 1.5066 | lr 3.00e-04 | grad 3.17 | tok/s 12501
step    860 | loss 1.4554 | lr 3.00e-04 | grad 2.23 | tok/s 12420
step    870 | loss 1.4846 | lr 3.00e-04 | grad 1.88 | tok/s 12155
step    880 | loss 1.6755 | lr 3.00e-04 | grad 2.34 | tok/s 12063
step    890 | loss 1.6125 | lr 3.00e-04 | grad 1.69 | tok/s 12236
step    900 | loss 1.5482 | lr 3.00e-04 | grad 1.61 | tok/s 12157
step    910 | loss 1.4154 | lr 3.00e-04 | grad 1.93 | tok/s 12257
step    920 | loss 1.5489 | lr 3.00e-04 | grad 3.14 | tok/s 12496
step    930 | loss 1.5245 | lr 3.00e-04 | grad 1.59 | tok/s 11823
step    940 | loss 1.3561 | lr 3.00e-04 | grad 1.74 | tok/s 12665
step    950 | loss 1.4817 | lr 3.00e-04 | grad 2.00 | tok/s 11938
step    960 | loss 1.3190 | lr 3.00e-04 | grad 1.84 | tok/s 12529
step    970 | loss 1.7915 | lr 3.00e-04 | grad 2.97 | tok/s 11963
step    980 | loss 1.5506 | lr 3.00e-04 | grad 1.99 | tok/s 12108
step    990 | loss 1.4555 | lr 3.00e-04 | grad 1.68 | tok/s 12565
step   1000 | loss 1.8300 | lr 3.00e-04 | grad 5.59 | tok/s 12091
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8300.pt
step   1010 | loss 1.6431 | lr 3.00e-04 | grad 1.80 | tok/s 2526
step   1020 | loss 1.4445 | lr 3.00e-04 | grad 1.49 | tok/s 12312
step   1030 | loss 1.4571 | lr 3.00e-04 | grad 1.61 | tok/s 12531
step   1040 | loss 1.5531 | lr 3.00e-04 | grad 4.03 | tok/s 11768
step   1050 | loss 1.7119 | lr 3.00e-04 | grad 2.94 | tok/s 11960
step   1060 | loss 1.6662 | lr 3.00e-04 | grad 2.78 | tok/s 12723
step   1070 | loss 1.4161 | lr 3.00e-04 | grad 1.62 | tok/s 9339
step   1080 | loss 1.0974 | lr 3.00e-04 | grad 1.01 | tok/s 12542
step   1090 | loss 1.4230 | lr 3.00e-04 | grad 2.78 | tok/s 12192
step   1100 | loss 1.4475 | lr 3.00e-04 | grad 1.68 | tok/s 12893
step   1110 | loss 1.3208 | lr 3.00e-04 | grad 1.74 | tok/s 12908
step   1120 | loss 1.2783 | lr 3.00e-04 | grad 1.56 | tok/s 12960
step   1130 | loss 1.2701 | lr 3.00e-04 | grad 1.77 | tok/s 12917
step   1140 | loss 1.2843 | lr 3.00e-04 | grad 1.48 | tok/s 12686
step   1150 | loss 1.2013 | lr 3.00e-04 | grad 1.46 | tok/s 12780
step   1160 | loss 1.2286 | lr 3.00e-04 | grad 1.68 | tok/s 12801
step   1170 | loss 1.3285 | lr 3.00e-04 | grad 1.41 | tok/s 12726
step   1180 | loss 1.2047 | lr 3.00e-04 | grad 1.80 | tok/s 12498
step   1190 | loss 1.1991 | lr 3.00e-04 | grad 1.64 | tok/s 12694
step   1200 | loss 1.2520 | lr 3.00e-04 | grad 1.67 | tok/s 12301
step   1210 | loss 1.2745 | lr 3.00e-04 | grad 1.68 | tok/s 12834
step   1220 | loss 1.2421 | lr 3.00e-04 | grad 1.48 | tok/s 12791
step   1230 | loss 1.2058 | lr 3.00e-04 | grad 1.30 | tok/s 12482
step   1240 | loss 1.7521 | lr 3.00e-04 | grad 3.03 | tok/s 12037
step   1250 | loss 1.3705 | lr 3.00e-04 | grad 14.19 | tok/s 11913
step   1260 | loss 1.6418 | lr 3.00e-04 | grad 4.12 | tok/s 11903
step   1270 | loss 1.5955 | lr 3.00e-04 | grad 1.52 | tok/s 12213
step   1280 | loss 1.4593 | lr 3.00e-04 | grad 1.71 | tok/s 12151
step   1290 | loss 1.4981 | lr 3.00e-04 | grad 2.11 | tok/s 12309
step   1300 | loss 1.4418 | lr 3.00e-04 | grad 1.95 | tok/s 12511
step   1310 | loss 1.5664 | lr 3.00e-04 | grad 1.89 | tok/s 12569
step   1320 | loss 1.5817 | lr 3.00e-04 | grad 1.95 | tok/s 12558
step   1330 | loss 1.4649 | lr 3.00e-04 | grad 8.12 | tok/s 11997
step   1340 | loss 1.6961 | lr 3.00e-04 | grad 2.06 | tok/s 11608
step   1350 | loss 1.4770 | lr 3.00e-04 | grad 1.97 | tok/s 12303
step   1360 | loss 1.3933 | lr 3.00e-04 | grad 1.30 | tok/s 12113
step   1370 | loss 1.6225 | lr 3.00e-04 | grad 1.97 | tok/s 11670
step   1380 | loss 1.4972 | lr 3.00e-04 | grad 1.45 | tok/s 12435
step   1390 | loss 1.3846 | lr 3.00e-04 | grad 1.48 | tok/s 11977
step   1400 | loss 1.4342 | lr 3.00e-04 | grad 2.50 | tok/s 12019
step   1410 | loss 1.6335 | lr 3.00e-04 | grad 3.73 | tok/s 12084
step   1420 | loss 1.3283 | lr 3.00e-04 | grad 1.66 | tok/s 12271
step   1430 | loss 1.1315 | lr 3.00e-04 | grad 1.53 | tok/s 12650
step   1440 | loss 1.1496 | lr 3.00e-04 | grad 3.66 | tok/s 12661
step   1450 | loss 1.6380 | lr 3.00e-04 | grad 1.73 | tok/s 11935
step   1460 | loss 1.4967 | lr 3.00e-04 | grad 1.55 | tok/s 12378
step   1470 | loss 1.7770 | lr 3.00e-04 | grad 3.53 | tok/s 12498
step   1480 | loss 1.5381 | lr 3.00e-04 | grad 1.46 | tok/s 12619
step   1490 | loss 1.3294 | lr 3.00e-04 | grad 1.45 | tok/s 12694
step   1500 | loss 1.4914 | lr 3.00e-04 | grad 1.66 | tok/s 12509
step   1510 | loss 1.4078 | lr 3.00e-04 | grad 3.08 | tok/s 12226
step   1520 | loss 1.4186 | lr 3.00e-04 | grad 1.41 | tok/s 12518
step   1530 | loss 1.5868 | lr 3.00e-04 | grad 2.03 | tok/s 11731
step   1540 | loss 1.2771 | lr 3.00e-04 | grad 1.98 | tok/s 12509
step   1550 | loss 1.5572 | lr 3.00e-04 | grad 2.17 | tok/s 11928
step   1560 | loss 1.2641 | lr 3.00e-04 | grad 1.84 | tok/s 12678
step   1570 | loss 1.6947 | lr 3.00e-04 | grad 3.52 | tok/s 12338
step   1580 | loss 1.5744 | lr 3.00e-04 | grad 2.05 | tok/s 11912
step   1590 | loss 0.9894 | lr 3.00e-04 | grad 1.36 | tok/s 12664
step   1600 | loss 1.0163 | lr 3.00e-04 | grad 2.08 | tok/s 12225
step   1610 | loss 1.3965 | lr 3.00e-04 | grad 2.47 | tok/s 11517
step   1620 | loss 1.3300 | lr 3.00e-04 | grad 1.86 | tok/s 12332
step   1630 | loss 1.3084 | lr 3.00e-04 | grad 1.80 | tok/s 11989
step   1640 | loss 1.5052 | lr 3.00e-04 | grad 2.17 | tok/s 11555
step   1650 | loss 1.3749 | lr 3.00e-04 | grad 1.47 | tok/s 12340
step   1660 | loss 1.3729 | lr 3.00e-04 | grad 7.50 | tok/s 12252
step   1670 | loss 1.6841 | lr 3.00e-04 | grad 1.69 | tok/s 11794
step   1680 | loss 1.4629 | lr 3.00e-04 | grad 3.50 | tok/s 11298
step   1690 | loss 1.4895 | lr 3.00e-04 | grad 1.95 | tok/s 12303
step   1700 | loss 1.3936 | lr 3.00e-04 | grad 1.84 | tok/s 12094
step   1710 | loss 1.4861 | lr 3.00e-04 | grad 2.23 | tok/s 12521
step   1720 | loss 1.2053 | lr 3.00e-04 | grad 2.38 | tok/s 12696
step   1730 | loss 1.3047 | lr 3.00e-04 | grad 2.30 | tok/s 12325
step   1740 | loss 1.5584 | lr 3.00e-04 | grad 2.12 | tok/s 12179
step   1750 | loss 1.5219 | lr 3.00e-04 | grad 1.96 | tok/s 12189
step   1760 | loss 1.4149 | lr 3.00e-04 | grad 1.93 | tok/s 11980
step   1770 | loss 1.4876 | lr 3.00e-04 | grad 1.52 | tok/s 12431
step   1780 | loss 1.3778 | lr 3.00e-04 | grad 1.41 | tok/s 12160
step   1790 | loss 1.5837 | lr 3.00e-04 | grad 2.11 | tok/s 12203

Training complete! Final step: 1791
