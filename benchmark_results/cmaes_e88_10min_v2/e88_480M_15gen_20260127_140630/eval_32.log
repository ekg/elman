Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_32/levelE88_100m_20260127_143730
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 490,666,800 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.7358 | lr 3.00e-04 | grad 6.31 | tok/s 4077
step     20 | loss 2.7089 | lr 3.00e-04 | grad 3.75 | tok/s 6598
step     30 | loss 2.5952 | lr 3.00e-04 | grad 1.51 | tok/s 6660
step     40 | loss 2.3704 | lr 3.00e-04 | grad 1.81 | tok/s 6347
step     50 | loss 3.1879 | lr 3.00e-04 | grad 13.00 | tok/s 6428
step     60 | loss 2.2263 | lr 3.00e-04 | grad 2.69 | tok/s 6619
step     70 | loss 2.0970 | lr 3.00e-04 | grad 2.95 | tok/s 6711
step     80 | loss 4.7628 | lr 3.00e-04 | grad 63.25 | tok/s 6514
step     90 | loss 4.9656 | lr 3.00e-04 | grad 7.91 | tok/s 6873
step    100 | loss 4.5240 | lr 3.00e-04 | grad 11.19 | tok/s 6845
step    110 | loss 4.2620 | lr 3.00e-04 | grad 16.38 | tok/s 6832
step    120 | loss 3.8872 | lr 3.00e-04 | grad 20.12 | tok/s 6839
step    130 | loss 3.6115 | lr 3.00e-04 | grad 22.38 | tok/s 6835
step    140 | loss 2.8571 | lr 3.00e-04 | grad 13.38 | tok/s 6830
step    150 | loss 3.2328 | lr 3.00e-04 | grad 11.44 | tok/s 6828
step    160 | loss 2.4809 | lr 3.00e-04 | grad 10.94 | tok/s 6727
step    170 | loss 2.6285 | lr 3.00e-04 | grad 7.38 | tok/s 6826
step    180 | loss 2.2946 | lr 3.00e-04 | grad 1.86 | tok/s 6822
step    190 | loss 2.5184 | lr 3.00e-04 | grad 2.17 | tok/s 6830
step    200 | loss 2.2166 | lr 3.00e-04 | grad 3.67 | tok/s 6842
step    210 | loss 2.1523 | lr 3.00e-04 | grad 3.58 | tok/s 6833
step    220 | loss 2.3051 | lr 3.00e-04 | grad 1.48 | tok/s 6746
step    230 | loss 2.3373 | lr 3.00e-04 | grad 1.81 | tok/s 6658
step    240 | loss 2.2935 | lr 3.00e-04 | grad 2.28 | tok/s 6223
step    250 | loss 2.1460 | lr 3.00e-04 | grad 1.23 | tok/s 6510
step    260 | loss 1.7316 | lr 3.00e-04 | grad 1.50 | tok/s 6711
step    270 | loss 2.1498 | lr 3.00e-04 | grad 1.29 | tok/s 6618
step    280 | loss 2.3042 | lr 3.00e-04 | grad 2.50 | tok/s 6500
step    290 | loss 1.7574 | lr 3.00e-04 | grad 3.22 | tok/s 6843
step    300 | loss 0.6780 | lr 3.00e-04 | grad 1.66 | tok/s 6837
step    310 | loss 2.4853 | lr 3.00e-04 | grad 2.33 | tok/s 6731
step    320 | loss 2.1084 | lr 3.00e-04 | grad 3.39 | tok/s 6587
step    330 | loss 1.9641 | lr 3.00e-04 | grad 1.41 | tok/s 6286
step    340 | loss 2.2819 | lr 3.00e-04 | grad 1.31 | tok/s 6456
step    350 | loss 1.9933 | lr 3.00e-04 | grad 3.11 | tok/s 6628
step    360 | loss 1.4734 | lr 3.00e-04 | grad 4.62 | tok/s 6781
step    370 | loss 1.8783 | lr 3.00e-04 | grad 1.43 | tok/s 6132
step    380 | loss 1.8257 | lr 3.00e-04 | grad 1.37 | tok/s 6549
step    390 | loss 1.5963 | lr 3.00e-04 | grad 1.06 | tok/s 6864
step    400 | loss 1.5627 | lr 3.00e-04 | grad 1.42 | tok/s 6783
step    410 | loss 1.3814 | lr 3.00e-04 | grad 1.30 | tok/s 6534
step    420 | loss 1.8466 | lr 3.00e-04 | grad 2.42 | tok/s 6339
step    430 | loss 2.1372 | lr 3.00e-04 | grad 1.60 | tok/s 6745
step    440 | loss 2.1648 | lr 3.00e-04 | grad 2.38 | tok/s 6379
step    450 | loss 1.9299 | lr 3.00e-04 | grad 1.58 | tok/s 6600
step    460 | loss 1.7553 | lr 3.00e-04 | grad 1.55 | tok/s 6454
step    470 | loss 1.8310 | lr 3.00e-04 | grad 1.37 | tok/s 6657
step    480 | loss 2.2430 | lr 3.00e-04 | grad 3.97 | tok/s 6681
step    490 | loss 1.8032 | lr 3.00e-04 | grad 1.38 | tok/s 6249
step    500 | loss 1.7255 | lr 3.00e-04 | grad 1.98 | tok/s 6740
step    510 | loss 1.7404 | lr 3.00e-04 | grad 1.27 | tok/s 6835
step    520 | loss 1.7162 | lr 3.00e-04 | grad 1.24 | tok/s 6830
step    530 | loss 1.9252 | lr 3.00e-04 | grad 1.46 | tok/s 6553
step    540 | loss 1.7532 | lr 3.00e-04 | grad 1.27 | tok/s 6565
step    550 | loss 1.5950 | lr 3.00e-04 | grad 1.72 | tok/s 6408
step    560 | loss 1.7437 | lr 3.00e-04 | grad 1.55 | tok/s 6254
step    570 | loss 1.6706 | lr 3.00e-04 | grad 2.30 | tok/s 6423
step    580 | loss 1.5742 | lr 3.00e-04 | grad 1.25 | tok/s 6302
step    590 | loss 1.8688 | lr 3.00e-04 | grad 1.84 | tok/s 6573
step    600 | loss 1.8267 | lr 3.00e-04 | grad 1.30 | tok/s 6341
step    610 | loss 1.6467 | lr 3.00e-04 | grad 1.38 | tok/s 6673
step    620 | loss 1.5617 | lr 3.00e-04 | grad 1.42 | tok/s 6318
step    630 | loss 1.6725 | lr 3.00e-04 | grad 2.58 | tok/s 6376
step    640 | loss 1.8090 | lr 3.00e-04 | grad 1.55 | tok/s 6545
step    650 | loss 1.6717 | lr 3.00e-04 | grad 1.48 | tok/s 6576
step    660 | loss 1.7077 | lr 3.00e-04 | grad 1.23 | tok/s 6540
step    670 | loss 1.8814 | lr 3.00e-04 | grad 4.03 | tok/s 6650
step    680 | loss 1.7338 | lr 3.00e-04 | grad 1.44 | tok/s 6522
step    690 | loss 1.8472 | lr 3.00e-04 | grad 1.99 | tok/s 6752
step    700 | loss 1.4782 | lr 3.00e-04 | grad 1.92 | tok/s 6893
step    710 | loss 1.5982 | lr 3.00e-04 | grad 1.48 | tok/s 6420
step    720 | loss 1.4731 | lr 3.00e-04 | grad 1.78 | tok/s 6318
step    730 | loss 1.3495 | lr 3.00e-04 | grad 1.82 | tok/s 6865
step    740 | loss 1.5195 | lr 3.00e-04 | grad 1.52 | tok/s 6659
step    750 | loss 1.2537 | lr 3.00e-04 | grad 1.61 | tok/s 6872
step    760 | loss 1.1508 | lr 3.00e-04 | grad 1.48 | tok/s 6878
step    770 | loss 1.0926 | lr 3.00e-04 | grad 1.34 | tok/s 6878
step    780 | loss 1.0299 | lr 3.00e-04 | grad 1.41 | tok/s 6876
step    790 | loss 1.1420 | lr 3.00e-04 | grad 2.27 | tok/s 6663
step    800 | loss 1.8252 | lr 3.00e-04 | grad 3.97 | tok/s 6642
step    810 | loss 1.6863 | lr 3.00e-04 | grad 1.32 | tok/s 6599
step    820 | loss 1.7006 | lr 3.00e-04 | grad 2.47 | tok/s 6342
step    830 | loss 1.5108 | lr 3.00e-04 | grad 1.62 | tok/s 6756
step    840 | loss 1.4324 | lr 3.00e-04 | grad 1.50 | tok/s 6875
step    850 | loss 1.5831 | lr 3.00e-04 | grad 1.41 | tok/s 6839
step    860 | loss 1.5008 | lr 3.00e-04 | grad 2.33 | tok/s 6770
step    870 | loss 1.5129 | lr 3.00e-04 | grad 1.76 | tok/s 6516
step    880 | loss 1.6528 | lr 3.00e-04 | grad 1.62 | tok/s 6546
step    890 | loss 1.6681 | lr 3.00e-04 | grad 1.89 | tok/s 6632
step    900 | loss 1.5492 | lr 3.00e-04 | grad 1.66 | tok/s 6638
step    910 | loss 1.4223 | lr 3.00e-04 | grad 2.45 | tok/s 6334
step    920 | loss 1.5428 | lr 3.00e-04 | grad 2.53 | tok/s 6766
step    930 | loss 1.5957 | lr 3.00e-04 | grad 2.38 | tok/s 6457
step    940 | loss 1.4150 | lr 3.00e-04 | grad 1.20 | tok/s 6810
step    950 | loss 1.4857 | lr 3.00e-04 | grad 2.16 | tok/s 6840
step    960 | loss 1.3662 | lr 3.00e-04 | grad 1.63 | tok/s 6846
step    970 | loss 1.7033 | lr 3.00e-04 | grad 2.34 | tok/s 6439
step    980 | loss 1.6245 | lr 3.00e-04 | grad 1.42 | tok/s 6616
step    990 | loss 1.4602 | lr 3.00e-04 | grad 1.30 | tok/s 6611

Training complete! Final step: 991
