Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_7/levelE88_100m_20260127_140637
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 482,366,168 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.8936 | lr 3.00e-04 | grad 17.88 | tok/s 4909
step     20 | loss 2.7292 | lr 3.00e-04 | grad 6.47 | tok/s 9264
step     30 | loss 2.5967 | lr 3.00e-04 | grad 3.05 | tok/s 9353
step     40 | loss 2.4128 | lr 3.00e-04 | grad 2.64 | tok/s 8938
step     50 | loss 3.2718 | lr 3.00e-04 | grad 19.38 | tok/s 9052
step     60 | loss 2.2064 | lr 3.00e-04 | grad 4.34 | tok/s 9352
step     70 | loss 2.0415 | lr 3.00e-04 | grad 4.41 | tok/s 9423
step     80 | loss 5.1593 | lr 3.00e-04 | grad 137.00 | tok/s 9473
step     90 | loss 5.2686 | lr 3.00e-04 | grad 12.12 | tok/s 9147
step    100 | loss 4.7587 | lr 3.00e-04 | grad 18.50 | tok/s 9577
step    110 | loss 4.5869 | lr 3.00e-04 | grad 34.25 | tok/s 9535
step    120 | loss 4.2089 | lr 3.00e-04 | grad 36.75 | tok/s 9521
step    130 | loss 3.9799 | lr 3.00e-04 | grad 39.25 | tok/s 9468
step    140 | loss 3.2008 | lr 3.00e-04 | grad 23.75 | tok/s 9449
step    150 | loss 3.6240 | lr 3.00e-04 | grad 29.12 | tok/s 9410
step    160 | loss 2.6855 | lr 3.00e-04 | grad 23.25 | tok/s 9113
step    170 | loss 2.7590 | lr 3.00e-04 | grad 19.25 | tok/s 9395
step    180 | loss 2.5055 | lr 3.00e-04 | grad 3.84 | tok/s 9399
step    190 | loss 2.7190 | lr 3.00e-04 | grad 4.75 | tok/s 9353
step    200 | loss 2.3178 | lr 3.00e-04 | grad 10.94 | tok/s 9342
step    210 | loss 2.2884 | lr 3.00e-04 | grad 9.00 | tok/s 9312
step    220 | loss 2.3903 | lr 3.00e-04 | grad 2.12 | tok/s 9185
step    230 | loss 2.3175 | lr 3.00e-04 | grad 2.94 | tok/s 8790
step    240 | loss 2.3052 | lr 3.00e-04 | grad 3.12 | tok/s 8607
step    250 | loss 2.1471 | lr 3.00e-04 | grad 1.59 | tok/s 8835
step    260 | loss 1.6783 | lr 3.00e-04 | grad 1.95 | tok/s 9111
step    270 | loss 2.1550 | lr 3.00e-04 | grad 1.63 | tok/s 8981
step    280 | loss 2.3143 | lr 3.00e-04 | grad 3.61 | tok/s 8789
step    290 | loss 1.6993 | lr 3.00e-04 | grad 3.69 | tok/s 9251
step    300 | loss 0.6865 | lr 3.00e-04 | grad 2.50 | tok/s 9233
step    310 | loss 2.4562 | lr 3.00e-04 | grad 2.27 | tok/s 9077
step    320 | loss 2.0721 | lr 3.00e-04 | grad 4.50 | tok/s 8885
step    330 | loss 1.9866 | lr 3.00e-04 | grad 1.91 | tok/s 8584
step    340 | loss 2.3211 | lr 3.00e-04 | grad 1.82 | tok/s 8713
step    350 | loss 1.9968 | lr 3.00e-04 | grad 4.81 | tok/s 8929
step    360 | loss 1.4282 | lr 3.00e-04 | grad 6.00 | tok/s 9131
step    370 | loss 1.8681 | lr 3.00e-04 | grad 1.70 | tok/s 8280
step    380 | loss 1.8362 | lr 3.00e-04 | grad 1.58 | tok/s 8812
step    390 | loss 1.5982 | lr 3.00e-04 | grad 1.27 | tok/s 9201
step    400 | loss 1.5581 | lr 3.00e-04 | grad 1.75 | tok/s 9116
step    410 | loss 1.3693 | lr 3.00e-04 | grad 1.43 | tok/s 8916
step    420 | loss 1.8586 | lr 3.00e-04 | grad 3.06 | tok/s 8504
step    430 | loss 2.1849 | lr 3.00e-04 | grad 1.92 | tok/s 9039
step    440 | loss 2.1875 | lr 3.00e-04 | grad 2.84 | tok/s 8548
step    450 | loss 1.9306 | lr 3.00e-04 | grad 1.86 | tok/s 8835
step    460 | loss 1.7469 | lr 3.00e-04 | grad 2.05 | tok/s 8660
step    470 | loss 1.8664 | lr 3.00e-04 | grad 1.52 | tok/s 8926
step    480 | loss 2.2921 | lr 3.00e-04 | grad 4.66 | tok/s 8922
step    490 | loss 1.8222 | lr 3.00e-04 | grad 1.64 | tok/s 8170
step    500 | loss 1.7356 | lr 3.00e-04 | grad 2.28 | tok/s 9011
step    510 | loss 1.7465 | lr 3.00e-04 | grad 1.50 | tok/s 9133
step    520 | loss 1.7159 | lr 3.00e-04 | grad 1.40 | tok/s 9116
step    530 | loss 1.9409 | lr 3.00e-04 | grad 1.71 | tok/s 8756
step    540 | loss 1.7633 | lr 3.00e-04 | grad 1.47 | tok/s 8763
step    550 | loss 1.5965 | lr 3.00e-04 | grad 2.09 | tok/s 8565
step    560 | loss 1.7541 | lr 3.00e-04 | grad 1.76 | tok/s 8352
step    570 | loss 1.6920 | lr 3.00e-04 | grad 2.59 | tok/s 8582
step    580 | loss 1.5704 | lr 3.00e-04 | grad 1.46 | tok/s 8549
step    590 | loss 1.8957 | lr 3.00e-04 | grad 2.16 | tok/s 8772
step    600 | loss 1.8402 | lr 3.00e-04 | grad 1.56 | tok/s 8473
step    610 | loss 1.6535 | lr 3.00e-04 | grad 1.60 | tok/s 8904
step    620 | loss 1.5680 | lr 3.00e-04 | grad 1.62 | tok/s 8429
step    630 | loss 1.6863 | lr 3.00e-04 | grad 2.98 | tok/s 8508
step    640 | loss 1.8277 | lr 3.00e-04 | grad 1.70 | tok/s 8743
step    650 | loss 1.6779 | lr 3.00e-04 | grad 1.73 | tok/s 8769
step    660 | loss 1.7205 | lr 3.00e-04 | grad 1.48 | tok/s 8560
step    670 | loss 1.9375 | lr 3.00e-04 | grad 4.47 | tok/s 8888
step    680 | loss 1.7424 | lr 3.00e-04 | grad 1.67 | tok/s 8709
step    690 | loss 1.8735 | lr 3.00e-04 | grad 2.41 | tok/s 8994
step    700 | loss 1.5039 | lr 3.00e-04 | grad 2.27 | tok/s 9166
step    710 | loss 1.6061 | lr 3.00e-04 | grad 1.64 | tok/s 8559
step    720 | loss 1.4889 | lr 3.00e-04 | grad 2.44 | tok/s 8418
step    730 | loss 1.3501 | lr 3.00e-04 | grad 1.92 | tok/s 9149
step    740 | loss 1.5320 | lr 3.00e-04 | grad 1.66 | tok/s 9014
step    750 | loss 1.2559 | lr 3.00e-04 | grad 1.86 | tok/s 9171
step    760 | loss 1.1451 | lr 3.00e-04 | grad 1.60 | tok/s 9163
step    770 | loss 1.0908 | lr 3.00e-04 | grad 1.45 | tok/s 9162
step    780 | loss 1.0256 | lr 3.00e-04 | grad 1.48 | tok/s 9017
step    790 | loss 1.1466 | lr 3.00e-04 | grad 2.64 | tok/s 8882
step    800 | loss 1.8432 | lr 3.00e-04 | grad 4.31 | tok/s 8852
step    810 | loss 1.7070 | lr 3.00e-04 | grad 1.53 | tok/s 8817
step    820 | loss 1.7265 | lr 3.00e-04 | grad 2.84 | tok/s 8462
step    830 | loss 1.5272 | lr 3.00e-04 | grad 1.84 | tok/s 9072
step    840 | loss 1.4259 | lr 3.00e-04 | grad 1.67 | tok/s 9180
step    850 | loss 1.6185 | lr 3.00e-04 | grad 1.54 | tok/s 9116
step    860 | loss 1.5151 | lr 3.00e-04 | grad 2.64 | tok/s 9038
step    870 | loss 1.5195 | lr 3.00e-04 | grad 1.99 | tok/s 8593
step    880 | loss 1.6827 | lr 3.00e-04 | grad 1.86 | tok/s 8743
step    890 | loss 1.6866 | lr 3.00e-04 | grad 2.14 | tok/s 8855
step    900 | loss 1.5666 | lr 3.00e-04 | grad 1.91 | tok/s 8860
step    910 | loss 1.4333 | lr 3.00e-04 | grad 2.77 | tok/s 8677
step    920 | loss 1.5472 | lr 3.00e-04 | grad 2.83 | tok/s 9026
step    930 | loss 1.6105 | lr 3.00e-04 | grad 2.59 | tok/s 8606
step    940 | loss 1.4164 | lr 3.00e-04 | grad 1.34 | tok/s 8959
step    950 | loss 1.5107 | lr 3.00e-04 | grad 1.85 | tok/s 9142
step    960 | loss 1.3637 | lr 3.00e-04 | grad 1.84 | tok/s 9143
step    970 | loss 1.7300 | lr 3.00e-04 | grad 2.72 | tok/s 8593
step    980 | loss 1.6484 | lr 3.00e-04 | grad 1.70 | tok/s 8845
step    990 | loss 1.4679 | lr 3.00e-04 | grad 1.52 | tok/s 8994
step   1000 | loss 1.8295 | lr 3.00e-04 | grad 5.78 | tok/s 8616
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8295.pt
step   1010 | loss 1.6336 | lr 3.00e-04 | grad 2.28 | tok/s 4762
step   1020 | loss 1.6437 | lr 3.00e-04 | grad 1.32 | tok/s 8445
step   1030 | loss 1.4654 | lr 3.00e-04 | grad 1.45 | tok/s 8791
step   1040 | loss 1.4939 | lr 3.00e-04 | grad 1.53 | tok/s 9075
step   1050 | loss 1.6180 | lr 3.00e-04 | grad 2.42 | tok/s 8383
step   1060 | loss 1.7439 | lr 3.00e-04 | grad 2.52 | tok/s 9068
step   1070 | loss 1.6819 | lr 3.00e-04 | grad 2.08 | tok/s 9029
step   1080 | loss 1.4065 | lr 3.00e-04 | grad 1.47 | tok/s 8184
step   1090 | loss 1.1160 | lr 3.00e-04 | grad 1.00 | tok/s 9028
step   1100 | loss 1.4294 | lr 3.00e-04 | grad 2.52 | tok/s 8748
step   1110 | loss 1.4676 | lr 3.00e-04 | grad 1.44 | tok/s 9208
step   1120 | loss 1.3445 | lr 3.00e-04 | grad 1.52 | tok/s 9211
step   1130 | loss 1.3002 | lr 3.00e-04 | grad 1.38 | tok/s 9195
step   1140 | loss 1.2868 | lr 3.00e-04 | grad 1.58 | tok/s 9185
step   1150 | loss 1.3063 | lr 3.00e-04 | grad 1.34 | tok/s 9200
step   1160 | loss 1.2253 | lr 3.00e-04 | grad 1.33 | tok/s 9180
step   1170 | loss 1.2487 | lr 3.00e-04 | grad 1.55 | tok/s 9195
step   1180 | loss 1.3534 | lr 3.00e-04 | grad 1.26 | tok/s 9186
step   1190 | loss 1.2314 | lr 3.00e-04 | grad 1.62 | tok/s 9188
step   1200 | loss 1.2290 | lr 3.00e-04 | grad 1.54 | tok/s 9187
step   1210 | loss 1.2761 | lr 3.00e-04 | grad 1.51 | tok/s 9192
step   1220 | loss 1.2911 | lr 3.00e-04 | grad 1.45 | tok/s 9178
step   1230 | loss 1.2601 | lr 3.00e-04 | grad 1.27 | tok/s 9182
step   1240 | loss 1.2241 | lr 3.00e-04 | grad 1.20 | tok/s 9185
step   1250 | loss 1.7796 | lr 3.00e-04 | grad 2.64 | tok/s 8695
step   1260 | loss 1.3660 | lr 3.00e-04 | grad 2.58 | tok/s 8579
step   1270 | loss 1.6539 | lr 3.00e-04 | grad 3.66 | tok/s 8283
step   1280 | loss 1.6063 | lr 3.00e-04 | grad 1.34 | tok/s 8829
step   1290 | loss 1.4765 | lr 3.00e-04 | grad 1.60 | tok/s 8782
step   1300 | loss 1.5253 | lr 3.00e-04 | grad 1.86 | tok/s 8837
step   1310 | loss 1.4694 | lr 3.00e-04 | grad 1.71 | tok/s 8996
step   1320 | loss 1.5895 | lr 3.00e-04 | grad 1.66 | tok/s 9027

Training complete! Final step: 1324
