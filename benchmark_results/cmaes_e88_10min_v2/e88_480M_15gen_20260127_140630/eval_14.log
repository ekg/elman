Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_14/levelE88_100m_20260127_141655
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 481,081,536 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.6599 | lr 3.00e-04 | grad 12.12 | tok/s 4948
step     20 | loss 2.6673 | lr 3.00e-04 | grad 5.88 | tok/s 9473
step     30 | loss 2.5761 | lr 3.00e-04 | grad 2.84 | tok/s 9601
step     40 | loss 2.3931 | lr 3.00e-04 | grad 2.98 | tok/s 9176
step     50 | loss 3.1796 | lr 3.00e-04 | grad 17.88 | tok/s 9311
step     60 | loss 2.1752 | lr 3.00e-04 | grad 4.25 | tok/s 9606
step     70 | loss 2.0577 | lr 3.00e-04 | grad 4.25 | tok/s 9731
step     80 | loss 5.4168 | lr 3.00e-04 | grad 125.00 | tok/s 9789
step     90 | loss 5.5340 | lr 3.00e-04 | grad 11.38 | tok/s 9968
step    100 | loss 4.7822 | lr 3.00e-04 | grad 18.38 | tok/s 9960
step    110 | loss 4.4974 | lr 3.00e-04 | grad 22.50 | tok/s 9948
step    120 | loss 4.0578 | lr 3.00e-04 | grad 32.25 | tok/s 9944
step    130 | loss 3.7409 | lr 3.00e-04 | grad 31.50 | tok/s 9529
step    140 | loss 3.0131 | lr 3.00e-04 | grad 18.25 | tok/s 9951
step    150 | loss 3.3531 | lr 3.00e-04 | grad 20.75 | tok/s 9953
step    160 | loss 2.5815 | lr 3.00e-04 | grad 18.75 | tok/s 9950
step    170 | loss 2.6140 | lr 3.00e-04 | grad 14.75 | tok/s 9942
step    180 | loss 2.3837 | lr 3.00e-04 | grad 3.72 | tok/s 9961
step    190 | loss 2.6068 | lr 3.00e-04 | grad 4.06 | tok/s 9957
step    200 | loss 2.2476 | lr 3.00e-04 | grad 9.00 | tok/s 9952
step    210 | loss 2.2131 | lr 3.00e-04 | grad 7.22 | tok/s 9955
step    220 | loss 2.3303 | lr 3.00e-04 | grad 1.98 | tok/s 9834
step    230 | loss 2.2276 | lr 3.00e-04 | grad 3.03 | tok/s 9711
step    240 | loss 2.2930 | lr 3.00e-04 | grad 3.34 | tok/s 9223
step    250 | loss 2.1402 | lr 3.00e-04 | grad 1.62 | tok/s 9488
step    260 | loss 1.6593 | lr 3.00e-04 | grad 2.03 | tok/s 9778
step    270 | loss 2.1508 | lr 3.00e-04 | grad 1.71 | tok/s 9250
step    280 | loss 2.3106 | lr 3.00e-04 | grad 3.84 | tok/s 9472
step    290 | loss 1.5721 | lr 3.00e-04 | grad 3.12 | tok/s 9969
step    300 | loss 0.6597 | lr 3.00e-04 | grad 2.62 | tok/s 9975
step    310 | loss 2.4538 | lr 3.00e-04 | grad 2.75 | tok/s 9803
step    320 | loss 2.0526 | lr 3.00e-04 | grad 4.56 | tok/s 9594
step    330 | loss 1.9794 | lr 3.00e-04 | grad 1.99 | tok/s 9271
step    340 | loss 2.3293 | lr 3.00e-04 | grad 1.88 | tok/s 9411
step    350 | loss 1.9877 | lr 3.00e-04 | grad 4.94 | tok/s 9656
step    360 | loss 1.3783 | lr 3.00e-04 | grad 5.19 | tok/s 9864
step    370 | loss 1.8669 | lr 3.00e-04 | grad 1.83 | tok/s 8938
step    380 | loss 1.8372 | lr 3.00e-04 | grad 1.70 | tok/s 9521
step    390 | loss 1.5856 | lr 3.00e-04 | grad 1.32 | tok/s 9957
step    400 | loss 1.5489 | lr 3.00e-04 | grad 1.74 | tok/s 9861
step    410 | loss 1.3543 | lr 3.00e-04 | grad 1.42 | tok/s 9367
step    420 | loss 1.8585 | lr 3.00e-04 | grad 3.23 | tok/s 9207
step    430 | loss 2.2012 | lr 3.00e-04 | grad 1.98 | tok/s 9798
step    440 | loss 2.1858 | lr 3.00e-04 | grad 2.88 | tok/s 9270
step    450 | loss 1.9242 | lr 3.00e-04 | grad 1.95 | tok/s 9575
step    460 | loss 1.7522 | lr 3.00e-04 | grad 2.19 | tok/s 9381
step    470 | loss 1.8633 | lr 3.00e-04 | grad 1.62 | tok/s 9677
step    480 | loss 2.2998 | lr 3.00e-04 | grad 5.06 | tok/s 9679
step    490 | loss 1.8153 | lr 3.00e-04 | grad 1.68 | tok/s 9141
step    500 | loss 1.7260 | lr 3.00e-04 | grad 2.36 | tok/s 9761
step    510 | loss 1.7420 | lr 3.00e-04 | grad 1.60 | tok/s 9891
step    520 | loss 1.7083 | lr 3.00e-04 | grad 1.44 | tok/s 9869
step    530 | loss 1.9402 | lr 3.00e-04 | grad 1.79 | tok/s 9497
step    540 | loss 1.7647 | lr 3.00e-04 | grad 1.51 | tok/s 9497
step    550 | loss 1.5943 | lr 3.00e-04 | grad 2.09 | tok/s 9303
step    560 | loss 1.7425 | lr 3.00e-04 | grad 1.85 | tok/s 8885
step    570 | loss 1.6925 | lr 3.00e-04 | grad 2.67 | tok/s 9313
step    580 | loss 1.5722 | lr 3.00e-04 | grad 1.50 | tok/s 9273
step    590 | loss 1.8892 | lr 3.00e-04 | grad 2.20 | tok/s 9521
step    600 | loss 1.8291 | lr 3.00e-04 | grad 1.65 | tok/s 9192
step    610 | loss 1.6501 | lr 3.00e-04 | grad 1.64 | tok/s 9662
step    620 | loss 1.5665 | lr 3.00e-04 | grad 1.73 | tok/s 9156
step    630 | loss 1.6807 | lr 3.00e-04 | grad 3.02 | tok/s 9233
step    640 | loss 1.8327 | lr 3.00e-04 | grad 1.80 | tok/s 9503
step    650 | loss 1.6817 | lr 3.00e-04 | grad 1.79 | tok/s 9553
step    660 | loss 1.7176 | lr 3.00e-04 | grad 1.56 | tok/s 9596
step    670 | loss 1.9378 | lr 3.00e-04 | grad 2.89 | tok/s 9655
step    680 | loss 1.7381 | lr 3.00e-04 | grad 1.73 | tok/s 9461
step    690 | loss 1.8617 | lr 3.00e-04 | grad 2.39 | tok/s 9786
step    700 | loss 1.4849 | lr 3.00e-04 | grad 2.22 | tok/s 9840
step    710 | loss 1.6004 | lr 3.00e-04 | grad 1.72 | tok/s 9327
step    720 | loss 1.4799 | lr 3.00e-04 | grad 2.52 | tok/s 9177
step    730 | loss 1.3361 | lr 3.00e-04 | grad 2.02 | tok/s 9957
step    740 | loss 1.5262 | lr 3.00e-04 | grad 1.76 | tok/s 9835
step    750 | loss 1.2531 | lr 3.00e-04 | grad 1.90 | tok/s 9989
step    760 | loss 1.1504 | lr 3.00e-04 | grad 1.63 | tok/s 9980
step    770 | loss 1.0904 | lr 3.00e-04 | grad 1.52 | tok/s 9978
step    780 | loss 1.0249 | lr 3.00e-04 | grad 1.51 | tok/s 9984
step    790 | loss 1.1444 | lr 3.00e-04 | grad 2.56 | tok/s 9679
step    800 | loss 1.8380 | lr 3.00e-04 | grad 4.47 | tok/s 9639
step    810 | loss 1.7093 | lr 3.00e-04 | grad 1.60 | tok/s 9591
step    820 | loss 1.7155 | lr 3.00e-04 | grad 2.84 | tok/s 9211
step    830 | loss 1.5221 | lr 3.00e-04 | grad 1.87 | tok/s 9876
step    840 | loss 1.4168 | lr 3.00e-04 | grad 1.74 | tok/s 9986
step    850 | loss 1.6039 | lr 3.00e-04 | grad 1.58 | tok/s 9703
step    860 | loss 1.5049 | lr 3.00e-04 | grad 2.67 | tok/s 9830
step    870 | loss 1.5180 | lr 3.00e-04 | grad 2.11 | tok/s 9475
step    880 | loss 1.6797 | lr 3.00e-04 | grad 1.95 | tok/s 9508
step    890 | loss 1.6841 | lr 3.00e-04 | grad 2.20 | tok/s 9651
step    900 | loss 1.5634 | lr 3.00e-04 | grad 2.00 | tok/s 9658
step    910 | loss 1.4277 | lr 3.00e-04 | grad 2.83 | tok/s 9450
step    920 | loss 1.5419 | lr 3.00e-04 | grad 2.70 | tok/s 9825
step    930 | loss 1.6019 | lr 3.00e-04 | grad 2.75 | tok/s 9374
step    940 | loss 1.4132 | lr 3.00e-04 | grad 1.38 | tok/s 9890
step    950 | loss 1.5086 | lr 3.00e-04 | grad 2.03 | tok/s 9941
step    960 | loss 1.3520 | lr 3.00e-04 | grad 1.91 | tok/s 9955
step    970 | loss 1.7366 | lr 3.00e-04 | grad 2.80 | tok/s 9361
step    980 | loss 1.6500 | lr 3.00e-04 | grad 1.80 | tok/s 9612
step    990 | loss 1.4620 | lr 3.00e-04 | grad 1.55 | tok/s 9614
step   1000 | loss 1.8351 | lr 3.00e-04 | grad 5.91 | tok/s 9384
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8351.pt
step   1010 | loss 1.6252 | lr 3.00e-04 | grad 2.47 | tok/s 5072
step   1020 | loss 1.6479 | lr 3.00e-04 | grad 1.41 | tok/s 9170
step   1030 | loss 1.4680 | lr 3.00e-04 | grad 1.52 | tok/s 9533
step   1040 | loss 1.4886 | lr 3.00e-04 | grad 1.59 | tok/s 9847
step   1050 | loss 1.6158 | lr 3.00e-04 | grad 2.50 | tok/s 9099
step   1060 | loss 1.7339 | lr 3.00e-04 | grad 2.62 | tok/s 9835
step   1070 | loss 1.6789 | lr 3.00e-04 | grad 2.11 | tok/s 9786
step   1080 | loss 1.3995 | lr 3.00e-04 | grad 1.50 | tok/s 8885
step   1090 | loss 1.1159 | lr 3.00e-04 | grad 1.02 | tok/s 9785
step   1100 | loss 1.4329 | lr 3.00e-04 | grad 2.61 | tok/s 9511
step   1110 | loss 1.4682 | lr 3.00e-04 | grad 1.48 | tok/s 10000
step   1120 | loss 1.3452 | lr 3.00e-04 | grad 1.59 | tok/s 9990
step   1130 | loss 1.2976 | lr 3.00e-04 | grad 1.46 | tok/s 9745
step   1140 | loss 1.2850 | lr 3.00e-04 | grad 1.60 | tok/s 9991
step   1150 | loss 1.3060 | lr 3.00e-04 | grad 1.36 | tok/s 9996
step   1160 | loss 1.2207 | lr 3.00e-04 | grad 1.35 | tok/s 9984
step   1170 | loss 1.2444 | lr 3.00e-04 | grad 1.61 | tok/s 9996
step   1180 | loss 1.3489 | lr 3.00e-04 | grad 1.32 | tok/s 9992
step   1190 | loss 1.2277 | lr 3.00e-04 | grad 1.63 | tok/s 9989
step   1200 | loss 1.2233 | lr 3.00e-04 | grad 1.59 | tok/s 9991
step   1210 | loss 1.2716 | lr 3.00e-04 | grad 1.53 | tok/s 9986
step   1220 | loss 1.2880 | lr 3.00e-04 | grad 1.55 | tok/s 9995
step   1230 | loss 1.2578 | lr 3.00e-04 | grad 1.31 | tok/s 9992
step   1240 | loss 1.2222 | lr 3.00e-04 | grad 1.25 | tok/s 9980
step   1250 | loss 1.7892 | lr 3.00e-04 | grad 2.77 | tok/s 9449
step   1260 | loss 1.3616 | lr 3.00e-04 | grad 4.00 | tok/s 9330
step   1270 | loss 1.6602 | lr 3.00e-04 | grad 3.86 | tok/s 9030
step   1280 | loss 1.6105 | lr 3.00e-04 | grad 1.35 | tok/s 9600
step   1290 | loss 1.4773 | lr 3.00e-04 | grad 1.58 | tok/s 9550
step   1300 | loss 1.5244 | lr 3.00e-04 | grad 1.94 | tok/s 9620
step   1310 | loss 1.4629 | lr 3.00e-04 | grad 1.81 | tok/s 9788
step   1320 | loss 1.5836 | lr 3.00e-04 | grad 1.68 | tok/s 9806
step   1330 | loss 1.5870 | lr 3.00e-04 | grad 1.77 | tok/s 9828
step   1340 | loss 1.4905 | lr 3.00e-04 | grad 8.12 | tok/s 9374
step   1350 | loss 1.7110 | lr 3.00e-04 | grad 1.80 | tok/s 9055
step   1360 | loss 1.5006 | lr 3.00e-04 | grad 1.80 | tok/s 9633
step   1370 | loss 1.4082 | lr 3.00e-04 | grad 1.20 | tok/s 9513
step   1380 | loss 1.6173 | lr 3.00e-04 | grad 1.98 | tok/s 9133
step   1390 | loss 1.5212 | lr 3.00e-04 | grad 1.34 | tok/s 9706
step   1400 | loss 1.4003 | lr 3.00e-04 | grad 1.41 | tok/s 9349
step   1410 | loss 1.4500 | lr 3.00e-04 | grad 2.36 | tok/s 9384
step   1420 | loss 1.6537 | lr 3.00e-04 | grad 3.53 | tok/s 9221

Training complete! Final step: 1428
