Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_42/levelE88_100m_20260127_145817
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 482,698,384 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1967 | lr 3.00e-04 | grad 12.69 | tok/s 5354
step     20 | loss 2.6407 | lr 3.00e-04 | grad 4.97 | tok/s 12055
step     30 | loss 2.5190 | lr 3.00e-04 | grad 2.86 | tok/s 12176
step     40 | loss 2.3578 | lr 3.00e-04 | grad 2.81 | tok/s 11623
step     50 | loss 2.9810 | lr 3.00e-04 | grad 8.81 | tok/s 11816
step     60 | loss 2.0849 | lr 3.00e-04 | grad 12.00 | tok/s 12171
step     70 | loss 1.9233 | lr 3.00e-04 | grad 3.84 | tok/s 12319
step     80 | loss 5.4871 | lr 3.00e-04 | grad 62.50 | tok/s 12455
step     90 | loss 5.2340 | lr 3.00e-04 | grad 9.25 | tok/s 12611
step    100 | loss 4.2148 | lr 3.00e-04 | grad 8.94 | tok/s 12600
step    110 | loss 3.7260 | lr 3.00e-04 | grad 13.19 | tok/s 12594
step    120 | loss 3.3153 | lr 3.00e-04 | grad 13.19 | tok/s 12590
step    130 | loss 2.9885 | lr 3.00e-04 | grad 13.81 | tok/s 12562
step    140 | loss 2.6087 | lr 3.00e-04 | grad 8.06 | tok/s 12569
step    150 | loss 2.7422 | lr 3.00e-04 | grad 9.50 | tok/s 12531
step    160 | loss 2.2603 | lr 3.00e-04 | grad 7.44 | tok/s 12554
step    170 | loss 2.3488 | lr 3.00e-04 | grad 9.44 | tok/s 12538
step    180 | loss 2.1568 | lr 3.00e-04 | grad 3.58 | tok/s 12525
step    190 | loss 2.3100 | lr 3.00e-04 | grad 9.19 | tok/s 12514
step    200 | loss 2.0418 | lr 3.00e-04 | grad 4.75 | tok/s 12510
step    210 | loss 2.0178 | lr 3.00e-04 | grad 4.44 | tok/s 12550
step    220 | loss 2.1533 | lr 3.00e-04 | grad 2.42 | tok/s 12379
step    230 | loss 2.0324 | lr 3.00e-04 | grad 2.39 | tok/s 11499
step    240 | loss 2.2700 | lr 3.00e-04 | grad 3.52 | tok/s 11620
step    250 | loss 2.0945 | lr 3.00e-04 | grad 1.86 | tok/s 11959
step    260 | loss 1.5735 | lr 3.00e-04 | grad 2.17 | tok/s 12351
step    270 | loss 2.0924 | lr 3.00e-04 | grad 2.03 | tok/s 12129
step    280 | loss 2.2527 | lr 3.00e-04 | grad 4.22 | tok/s 11942
step    290 | loss 1.4704 | lr 3.00e-04 | grad 2.80 | tok/s 12563
step    300 | loss 0.6040 | lr 3.00e-04 | grad 1.71 | tok/s 12541
step    310 | loss 2.4100 | lr 3.00e-04 | grad 2.89 | tok/s 12350
step    320 | loss 1.9481 | lr 3.00e-04 | grad 4.28 | tok/s 12098
step    330 | loss 1.9375 | lr 3.00e-04 | grad 2.19 | tok/s 11605
step    340 | loss 2.2547 | lr 3.00e-04 | grad 2.05 | tok/s 11833
step    350 | loss 1.8955 | lr 3.00e-04 | grad 3.70 | tok/s 12135
step    360 | loss 1.2429 | lr 3.00e-04 | grad 5.06 | tok/s 12338
step    370 | loss 1.8026 | lr 3.00e-04 | grad 2.00 | tok/s 11157
step    380 | loss 1.7694 | lr 3.00e-04 | grad 1.87 | tok/s 11972
step    390 | loss 1.5389 | lr 3.00e-04 | grad 1.53 | tok/s 12451
step    400 | loss 1.4968 | lr 3.00e-04 | grad 1.91 | tok/s 12339
step    410 | loss 1.2902 | lr 3.00e-04 | grad 1.52 | tok/s 12111
step    420 | loss 1.8123 | lr 3.00e-04 | grad 3.34 | tok/s 9995
step    430 | loss 2.1581 | lr 3.00e-04 | grad 2.23 | tok/s 12313
step    440 | loss 2.1365 | lr 3.00e-04 | grad 3.19 | tok/s 11658
step    450 | loss 1.8973 | lr 3.00e-04 | grad 2.08 | tok/s 12041
step    460 | loss 1.7220 | lr 3.00e-04 | grad 2.12 | tok/s 11810
step    470 | loss 1.8187 | lr 3.00e-04 | grad 1.70 | tok/s 12185
step    480 | loss 2.2240 | lr 3.00e-04 | grad 5.22 | tok/s 12167
step    490 | loss 1.7821 | lr 3.00e-04 | grad 1.91 | tok/s 11486
step    500 | loss 1.6729 | lr 3.00e-04 | grad 2.53 | tok/s 12179
step    510 | loss 1.7042 | lr 3.00e-04 | grad 1.83 | tok/s 12407
step    520 | loss 1.6672 | lr 3.00e-04 | grad 1.57 | tok/s 12286
step    530 | loss 1.9102 | lr 3.00e-04 | grad 1.94 | tok/s 11945
step    540 | loss 1.7318 | lr 3.00e-04 | grad 1.66 | tok/s 11923
step    550 | loss 1.5646 | lr 3.00e-04 | grad 2.17 | tok/s 11740
step    560 | loss 1.7155 | lr 3.00e-04 | grad 2.00 | tok/s 9968
step    570 | loss 1.6554 | lr 3.00e-04 | grad 2.78 | tok/s 11737
step    580 | loss 1.5381 | lr 3.00e-04 | grad 1.59 | tok/s 11669
step    590 | loss 1.8484 | lr 3.00e-04 | grad 2.44 | tok/s 11981
step    600 | loss 1.8007 | lr 3.00e-04 | grad 1.80 | tok/s 11575
step    610 | loss 1.6182 | lr 3.00e-04 | grad 1.82 | tok/s 12093
step    620 | loss 1.5382 | lr 3.00e-04 | grad 1.91 | tok/s 11471
step    630 | loss 1.6586 | lr 3.00e-04 | grad 3.44 | tok/s 11629
step    640 | loss 1.7995 | lr 3.00e-04 | grad 1.91 | tok/s 11943
step    650 | loss 1.6531 | lr 3.00e-04 | grad 1.98 | tok/s 11967
step    660 | loss 1.6902 | lr 3.00e-04 | grad 1.80 | tok/s 12064
step    670 | loss 1.9052 | lr 3.00e-04 | grad 2.50 | tok/s 11612
step    680 | loss 1.7201 | lr 3.00e-04 | grad 1.91 | tok/s 11745
step    690 | loss 1.8119 | lr 3.00e-04 | grad 2.48 | tok/s 12309
step    700 | loss 1.4370 | lr 3.00e-04 | grad 2.45 | tok/s 12291
step    710 | loss 1.5771 | lr 3.00e-04 | grad 1.83 | tok/s 11659
step    720 | loss 1.4642 | lr 3.00e-04 | grad 2.75 | tok/s 11228
step    730 | loss 1.3033 | lr 3.00e-04 | grad 2.12 | tok/s 10240
step    740 | loss 1.4974 | lr 3.00e-04 | grad 1.84 | tok/s 12231
step    750 | loss 1.2047 | lr 3.00e-04 | grad 2.00 | tok/s 12433
step    760 | loss 1.1131 | lr 3.00e-04 | grad 1.74 | tok/s 12063
step    770 | loss 1.0591 | lr 3.00e-04 | grad 1.56 | tok/s 12412
step    780 | loss 0.9932 | lr 3.00e-04 | grad 1.58 | tok/s 11227
step    790 | loss 1.1247 | lr 3.00e-04 | grad 2.64 | tok/s 12034
step    800 | loss 1.8060 | lr 3.00e-04 | grad 4.53 | tok/s 11914
step    810 | loss 1.6882 | lr 3.00e-04 | grad 1.66 | tok/s 12020
step    820 | loss 1.6928 | lr 3.00e-04 | grad 3.08 | tok/s 11426
step    830 | loss 1.4805 | lr 3.00e-04 | grad 1.88 | tok/s 12370
step    840 | loss 1.3744 | lr 3.00e-04 | grad 1.80 | tok/s 12398
step    850 | loss 1.5908 | lr 3.00e-04 | grad 1.64 | tok/s 12302
step    860 | loss 1.4763 | lr 3.00e-04 | grad 2.92 | tok/s 12293
step    870 | loss 1.4974 | lr 3.00e-04 | grad 2.11 | tok/s 11794
step    880 | loss 1.6592 | lr 3.00e-04 | grad 2.09 | tok/s 11906
step    890 | loss 1.6668 | lr 3.00e-04 | grad 2.38 | tok/s 12076
step    900 | loss 1.5478 | lr 3.00e-04 | grad 2.06 | tok/s 12023
step    910 | loss 1.4098 | lr 3.00e-04 | grad 3.08 | tok/s 11783
step    920 | loss 1.5182 | lr 3.00e-04 | grad 2.80 | tok/s 12275
step    930 | loss 1.5837 | lr 3.00e-04 | grad 2.86 | tok/s 11697
step    940 | loss 1.3883 | lr 3.00e-04 | grad 1.46 | tok/s 12339
step    950 | loss 1.4857 | lr 3.00e-04 | grad 2.70 | tok/s 12408
step    960 | loss 1.3241 | lr 3.00e-04 | grad 1.96 | tok/s 12449
step    970 | loss 1.7221 | lr 3.00e-04 | grad 2.91 | tok/s 11660
step    980 | loss 1.6317 | lr 3.00e-04 | grad 1.87 | tok/s 12011
step    990 | loss 1.4432 | lr 3.00e-04 | grad 1.64 | tok/s 12241
step   1000 | loss 1.8306 | lr 3.00e-04 | grad 6.72 | tok/s 9182
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8306.pt
step   1010 | loss 1.6566 | lr 3.00e-04 | grad 1.79 | tok/s 3165
step   1020 | loss 1.4816 | lr 3.00e-04 | grad 2.66 | tok/s 11637
step   1030 | loss 1.4220 | lr 3.00e-04 | grad 1.60 | tok/s 12354
step   1040 | loss 1.4732 | lr 3.00e-04 | grad 1.98 | tok/s 11290
step   1050 | loss 1.7322 | lr 3.00e-04 | grad 2.27 | tok/s 12370
step   1060 | loss 1.7081 | lr 3.00e-04 | grad 3.06 | tok/s 12347
step   1070 | loss 1.5061 | lr 3.00e-04 | grad 1.80 | tok/s 11717
step   1080 | loss 1.3308 | lr 3.00e-04 | grad 1.67 | tok/s 11465
step   1090 | loss 1.1019 | lr 3.00e-04 | grad 1.55 | tok/s 12099
step   1100 | loss 1.5218 | lr 3.00e-04 | grad 1.62 | tok/s 12296
step   1110 | loss 1.3503 | lr 3.00e-04 | grad 1.52 | tok/s 12545
step   1120 | loss 1.3169 | lr 3.00e-04 | grad 1.70 | tok/s 12431
step   1130 | loss 1.2480 | lr 3.00e-04 | grad 1.57 | tok/s 12420
step   1140 | loss 1.3017 | lr 3.00e-04 | grad 1.41 | tok/s 12519
step   1150 | loss 1.2315 | lr 3.00e-04 | grad 1.44 | tok/s 12499
step   1160 | loss 1.2205 | lr 3.00e-04 | grad 1.38 | tok/s 12495
step   1170 | loss 1.3257 | lr 3.00e-04 | grad 1.60 | tok/s 12515
step   1180 | loss 1.2475 | lr 3.00e-04 | grad 2.31 | tok/s 12420
step   1190 | loss 1.1717 | lr 3.00e-04 | grad 1.58 | tok/s 12420
step   1200 | loss 1.2507 | lr 3.00e-04 | grad 1.41 | tok/s 12444
step   1210 | loss 1.2872 | lr 3.00e-04 | grad 1.68 | tok/s 12438
step   1220 | loss 1.2263 | lr 3.00e-04 | grad 1.63 | tok/s 12446
step   1230 | loss 1.2485 | lr 3.00e-04 | grad 1.52 | tok/s 12416
step   1240 | loss 1.6072 | lr 3.00e-04 | grad 2.38 | tok/s 12083
step   1250 | loss 1.6221 | lr 3.00e-04 | grad 2.27 | tok/s 11694
step   1260 | loss 1.3490 | lr 3.00e-04 | grad 1.73 | tok/s 11903
step   1270 | loss 1.7287 | lr 3.00e-04 | grad 2.89 | tok/s 11459
step   1280 | loss 1.4556 | lr 3.00e-04 | grad 1.66 | tok/s 12140
step   1290 | loss 1.5138 | lr 3.00e-04 | grad 2.42 | tok/s 12188
step   1300 | loss 1.4332 | lr 3.00e-04 | grad 1.81 | tok/s 11813
step   1310 | loss 1.5256 | lr 3.00e-04 | grad 2.61 | tok/s 12209
step   1320 | loss 1.6498 | lr 3.00e-04 | grad 1.84 | tok/s 12433
step   1330 | loss 1.3007 | lr 3.00e-04 | grad 3.42 | tok/s 11714
step   1340 | loss 1.7243 | lr 3.00e-04 | grad 1.84 | tok/s 11430
step   1350 | loss 1.6158 | lr 3.00e-04 | grad 1.59 | tok/s 11930
step   1360 | loss 1.4002 | lr 3.00e-04 | grad 1.80 | tok/s 11793
step   1370 | loss 1.5823 | lr 3.00e-04 | grad 1.72 | tok/s 12043
step   1380 | loss 1.5008 | lr 3.00e-04 | grad 1.62 | tok/s 11454
step   1390 | loss 1.4652 | lr 3.00e-04 | grad 3.31 | tok/s 11592
step   1400 | loss 1.3653 | lr 3.00e-04 | grad 1.94 | tok/s 12114
step   1410 | loss 1.4851 | lr 3.00e-04 | grad 1.87 | tok/s 11625
step   1420 | loss 1.5155 | lr 3.00e-04 | grad 1.56 | tok/s 12253
step   1430 | loss 1.2513 | lr 3.00e-04 | grad 1.40 | tok/s 11939
step   1440 | loss 1.0998 | lr 3.00e-04 | grad 1.34 | tok/s 12545
step   1450 | loss 1.5019 | lr 3.00e-04 | grad 2.45 | tok/s 10876
step   1460 | loss 1.5361 | lr 3.00e-04 | grad 1.72 | tok/s 11879
step   1470 | loss 1.5961 | lr 3.00e-04 | grad 3.97 | tok/s 12302
step   1480 | loss 1.7409 | lr 3.00e-04 | grad 2.70 | tok/s 12540
step   1490 | loss 1.3879 | lr 3.00e-04 | grad 1.64 | tok/s 12514
step   1500 | loss 1.4083 | lr 3.00e-04 | grad 3.64 | tok/s 12381
step   1510 | loss 1.4500 | lr 3.00e-04 | grad 2.06 | tok/s 12527
step   1520 | loss 1.4432 | lr 3.00e-04 | grad 1.87 | tok/s 12160
step   1530 | loss 1.4903 | lr 3.00e-04 | grad 2.39 | tok/s 11796
step   1540 | loss 1.4479 | lr 3.00e-04 | grad 1.44 | tok/s 12321
step   1550 | loss 1.3206 | lr 3.00e-04 | grad 1.86 | tok/s 12081
step   1560 | loss 1.4939 | lr 3.00e-04 | grad 1.51 | tok/s 12186
step   1570 | loss 1.4681 | lr 3.00e-04 | grad 4.00 | tok/s 12248
step   1580 | loss 1.6854 | lr 3.00e-04 | grad 2.08 | tok/s 12239
step   1590 | loss 1.2463 | lr 3.00e-04 | grad 1.37 | tok/s 12047
step   1600 | loss 0.8399 | lr 3.00e-04 | grad 1.60 | tok/s 12397
step   1610 | loss 1.3125 | lr 3.00e-04 | grad 1.56 | tok/s 11301
step   1620 | loss 1.4827 | lr 3.00e-04 | grad 2.34 | tok/s 11985
step   1630 | loss 1.1915 | lr 3.00e-04 | grad 2.34 | tok/s 12476
step   1640 | loss 1.5289 | lr 3.00e-04 | grad 3.16 | tok/s 11242
step   1650 | loss 1.4708 | lr 3.00e-04 | grad 1.45 | tok/s 11673
step   1660 | loss 1.1711 | lr 3.00e-04 | grad 2.31 | tok/s 12250
step   1670 | loss 1.7780 | lr 3.00e-04 | grad 2.11 | tok/s 11651
step   1680 | loss 1.4747 | lr 3.00e-04 | grad 2.25 | tok/s 11854
step   1690 | loss 1.4759 | lr 3.00e-04 | grad 2.09 | tok/s 12337
step   1700 | loss 1.3908 | lr 3.00e-04 | grad 4.09 | tok/s 10477
step   1710 | loss 1.4763 | lr 3.00e-04 | grad 3.36 | tok/s 12266
step   1720 | loss 1.3310 | lr 3.00e-04 | grad 2.73 | tok/s 12515
step   1730 | loss 1.1498 | lr 3.00e-04 | grad 1.37 | tok/s 12404
step   1740 | loss 1.4787 | lr 3.00e-04 | grad 1.75 | tok/s 12108
step   1750 | loss 1.5260 | lr 3.00e-04 | grad 1.66 | tok/s 11924
step   1760 | loss 1.5902 | lr 3.00e-04 | grad 1.55 | tok/s 12185

Training complete! Final step: 1762
