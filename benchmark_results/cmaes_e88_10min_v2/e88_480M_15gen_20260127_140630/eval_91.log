Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_91/levelE88_100m_20260127_160111
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 472,296,904 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.0291 | lr 3.00e-04 | grad 7.41 | tok/s 5935
step     20 | loss 2.6742 | lr 3.00e-04 | grad 1.79 | tok/s 7910
step     30 | loss 2.9860 | lr 3.00e-04 | grad 3.72 | tok/s 8332
step     40 | loss 3.9747 | lr 3.00e-04 | grad 19.75 | tok/s 8470
step     50 | loss 4.1220 | lr 3.00e-04 | grad 7.44 | tok/s 8556
step     60 | loss 3.2431 | lr 3.00e-04 | grad 6.00 | tok/s 8526
step     70 | loss 2.6347 | lr 3.00e-04 | grad 3.70 | tok/s 8524
step     80 | loss 2.3936 | lr 3.00e-04 | grad 2.89 | tok/s 8509
step     90 | loss 2.2528 | lr 3.00e-04 | grad 2.53 | tok/s 8513
step    100 | loss 2.0539 | lr 3.00e-04 | grad 1.78 | tok/s 8522
step    110 | loss 2.1474 | lr 3.00e-04 | grad 2.20 | tok/s 8458
step    120 | loss 2.6255 | lr 3.00e-04 | grad 1.27 | tok/s 8047
step    130 | loss 2.1129 | lr 3.00e-04 | grad 3.64 | tok/s 8236
step    140 | loss 2.3639 | lr 3.00e-04 | grad 5.28 | tok/s 8263
step    150 | loss 1.4265 | lr 3.00e-04 | grad 3.83 | tok/s 8451
step    160 | loss 2.3109 | lr 3.00e-04 | grad 1.44 | tok/s 8185
step    170 | loss 2.2578 | lr 3.00e-04 | grad 1.12 | tok/s 8055
step    180 | loss 1.8754 | lr 3.00e-04 | grad 1.95 | tok/s 8259
step    190 | loss 1.9083 | lr 3.00e-04 | grad 1.66 | tok/s 8086
step    200 | loss 1.6689 | lr 3.00e-04 | grad 1.23 | tok/s 8467
step    210 | loss 1.9060 | lr 3.00e-04 | grad 1.77 | tok/s 8133
step    220 | loss 2.2002 | lr 3.00e-04 | grad 6.56 | tok/s 7929
step    230 | loss 1.9345 | lr 3.00e-04 | grad 1.80 | tok/s 8113
step    240 | loss 2.1339 | lr 3.00e-04 | grad 1.42 | tok/s 8172
step    250 | loss 1.8082 | lr 3.00e-04 | grad 1.33 | tok/s 8321
step    260 | loss 1.8998 | lr 3.00e-04 | grad 2.47 | tok/s 8336
step    270 | loss 1.7454 | lr 3.00e-04 | grad 1.27 | tok/s 8138
step    280 | loss 1.7825 | lr 3.00e-04 | grad 3.36 | tok/s 7801
step    290 | loss 1.7218 | lr 3.00e-04 | grad 4.50 | tok/s 7973
step    300 | loss 1.8539 | lr 3.00e-04 | grad 1.17 | tok/s 8064
step    310 | loss 1.6775 | lr 3.00e-04 | grad 2.03 | tok/s 7964
step    320 | loss 1.8020 | lr 3.00e-04 | grad 1.59 | tok/s 8148
step    330 | loss 1.8596 | lr 3.00e-04 | grad 5.69 | tok/s 8155
step    340 | loss 1.8907 | lr 3.00e-04 | grad 1.69 | tok/s 8195
step    350 | loss 1.6532 | lr 3.00e-04 | grad 1.27 | tok/s 8297
step    360 | loss 1.4847 | lr 3.00e-04 | grad 1.08 | tok/s 8128
step    370 | loss 1.4904 | lr 3.00e-04 | grad 1.43 | tok/s 8445
step    380 | loss 1.2016 | lr 3.00e-04 | grad 1.23 | tok/s 8536
step    390 | loss 1.1136 | lr 3.00e-04 | grad 1.57 | tok/s 8480
step    400 | loss 1.8515 | lr 3.00e-04 | grad 1.59 | tok/s 8128
step    410 | loss 1.7004 | lr 3.00e-04 | grad 1.56 | tok/s 8146
step    420 | loss 1.5887 | lr 3.00e-04 | grad 3.05 | tok/s 8509
step    430 | loss 1.5573 | lr 3.00e-04 | grad 1.46 | tok/s 8232
step    440 | loss 1.7062 | lr 3.00e-04 | grad 1.38 | tok/s 8184
step    450 | loss 1.5379 | lr 3.00e-04 | grad 3.11 | tok/s 8115
step    460 | loss 1.6194 | lr 3.00e-04 | grad 1.97 | tok/s 8206
step    470 | loss 1.5405 | lr 3.00e-04 | grad 1.52 | tok/s 8432
step    480 | loss 1.5417 | lr 3.00e-04 | grad 1.50 | tok/s 8224
step    490 | loss 1.6389 | lr 3.00e-04 | grad 1.09 | tok/s 8244
step    500 | loss 1.8264 | lr 3.00e-04 | grad 3.55 | tok/s 8153
step    510 | loss 1.6300 | lr 3.00e-04 | grad 2.69 | tok/s 7752
step    520 | loss 1.4635 | lr 3.00e-04 | grad 1.34 | tok/s 8091
step    530 | loss 1.7537 | lr 3.00e-04 | grad 1.93 | tok/s 8359
step    540 | loss 1.5008 | lr 3.00e-04 | grad 1.26 | tok/s 7882
step    550 | loss 1.3629 | lr 3.00e-04 | grad 1.29 | tok/s 8296
step    560 | loss 1.3923 | lr 3.00e-04 | grad 1.20 | tok/s 8516
step    570 | loss 1.3203 | lr 3.00e-04 | grad 1.05 | tok/s 8518
step    580 | loss 1.2724 | lr 3.00e-04 | grad 1.18 | tok/s 8516
step    590 | loss 1.3261 | lr 3.00e-04 | grad 1.12 | tok/s 8520
step    600 | loss 1.2579 | lr 3.00e-04 | grad 1.05 | tok/s 8513
step    610 | loss 1.2824 | lr 3.00e-04 | grad 1.15 | tok/s 8511

Training complete! Final step: 618
