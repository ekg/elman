Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_48/levelE88_100m_20260127_145817
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 489,095,536 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2595 | lr 3.00e-04 | grad 11.94 | tok/s 5177
step     20 | loss 2.6014 | lr 3.00e-04 | grad 4.47 | tok/s 11293
step     30 | loss 2.4919 | lr 3.00e-04 | grad 2.81 | tok/s 11452
step     40 | loss 2.3405 | lr 3.00e-04 | grad 2.84 | tok/s 10914
step     50 | loss 2.9766 | lr 3.00e-04 | grad 8.75 | tok/s 11081
step     60 | loss 2.0360 | lr 3.00e-04 | grad 2.77 | tok/s 11404
step     70 | loss 1.9061 | lr 3.00e-04 | grad 3.75 | tok/s 11572
step     80 | loss 5.5185 | lr 3.00e-04 | grad 85.00 | tok/s 11626
step     90 | loss 5.4183 | lr 3.00e-04 | grad 9.44 | tok/s 11830
step    100 | loss 4.3999 | lr 3.00e-04 | grad 9.81 | tok/s 11796
step    110 | loss 3.9717 | lr 3.00e-04 | grad 15.44 | tok/s 11801
step    120 | loss 3.4568 | lr 3.00e-04 | grad 14.50 | tok/s 11778
step    130 | loss 3.0700 | lr 3.00e-04 | grad 15.19 | tok/s 11781
step    140 | loss 2.6473 | lr 3.00e-04 | grad 8.69 | tok/s 11802
step    150 | loss 2.8522 | lr 3.00e-04 | grad 12.94 | tok/s 11735
step    160 | loss 2.3009 | lr 3.00e-04 | grad 9.00 | tok/s 11747
step    170 | loss 2.3891 | lr 3.00e-04 | grad 8.62 | tok/s 11793
step    180 | loss 2.1925 | lr 3.00e-04 | grad 5.25 | tok/s 11768
step    190 | loss 2.3332 | lr 3.00e-04 | grad 7.19 | tok/s 11725
step    200 | loss 2.0762 | lr 3.00e-04 | grad 4.59 | tok/s 11763
step    210 | loss 2.0612 | lr 3.00e-04 | grad 4.12 | tok/s 11813
step    220 | loss 2.1656 | lr 3.00e-04 | grad 2.27 | tok/s 11606
step    230 | loss 2.0315 | lr 3.00e-04 | grad 2.88 | tok/s 11442
step    240 | loss 2.2649 | lr 3.00e-04 | grad 3.38 | tok/s 10923
step    250 | loss 2.0927 | lr 3.00e-04 | grad 1.80 | tok/s 11264
step    260 | loss 1.5805 | lr 3.00e-04 | grad 2.14 | tok/s 11554
step    270 | loss 2.0977 | lr 3.00e-04 | grad 2.02 | tok/s 11406
step    280 | loss 2.2597 | lr 3.00e-04 | grad 4.47 | tok/s 11189
step    290 | loss 1.4375 | lr 3.00e-04 | grad 2.53 | tok/s 11780
step    300 | loss 0.5659 | lr 3.00e-04 | grad 1.62 | tok/s 11767
step    310 | loss 2.4054 | lr 3.00e-04 | grad 2.61 | tok/s 11493
step    320 | loss 1.9622 | lr 3.00e-04 | grad 4.03 | tok/s 11278
step    330 | loss 1.9409 | lr 3.00e-04 | grad 2.14 | tok/s 10884
step    340 | loss 2.2646 | lr 3.00e-04 | grad 1.95 | tok/s 11083
step    350 | loss 1.8997 | lr 3.00e-04 | grad 3.31 | tok/s 11305
step    360 | loss 1.2476 | lr 3.00e-04 | grad 5.44 | tok/s 11557
step    370 | loss 1.8135 | lr 3.00e-04 | grad 1.93 | tok/s 10501
step    380 | loss 1.7740 | lr 3.00e-04 | grad 1.80 | tok/s 11210
step    390 | loss 1.5448 | lr 3.00e-04 | grad 1.46 | tok/s 9967
step    400 | loss 1.5014 | lr 3.00e-04 | grad 1.87 | tok/s 11630
step    410 | loss 1.2952 | lr 3.00e-04 | grad 1.48 | tok/s 11362
step    420 | loss 1.8137 | lr 3.00e-04 | grad 3.25 | tok/s 10333
step    430 | loss 2.1496 | lr 3.00e-04 | grad 2.22 | tok/s 11460
step    440 | loss 2.1426 | lr 3.00e-04 | grad 3.23 | tok/s 10905
step    450 | loss 1.9072 | lr 3.00e-04 | grad 2.05 | tok/s 11282
step    460 | loss 1.7327 | lr 3.00e-04 | grad 2.20 | tok/s 11056
step    470 | loss 1.8238 | lr 3.00e-04 | grad 1.73 | tok/s 11414
step    480 | loss 2.2240 | lr 3.00e-04 | grad 5.06 | tok/s 11329
step    490 | loss 1.7869 | lr 3.00e-04 | grad 1.89 | tok/s 10755
step    500 | loss 1.6792 | lr 3.00e-04 | grad 2.48 | tok/s 11430
step    510 | loss 1.7067 | lr 3.00e-04 | grad 1.75 | tok/s 11623
step    520 | loss 1.6717 | lr 3.00e-04 | grad 1.57 | tok/s 11695
step    530 | loss 1.9076 | lr 3.00e-04 | grad 1.96 | tok/s 11292
step    540 | loss 1.7326 | lr 3.00e-04 | grad 1.66 | tok/s 11289
step    550 | loss 1.5665 | lr 3.00e-04 | grad 2.19 | tok/s 11043
step    560 | loss 1.7293 | lr 3.00e-04 | grad 1.95 | tok/s 10758
step    570 | loss 1.6573 | lr 3.00e-04 | grad 2.91 | tok/s 11042
step    580 | loss 1.5455 | lr 3.00e-04 | grad 1.64 | tok/s 10933
step    590 | loss 1.8598 | lr 3.00e-04 | grad 2.36 | tok/s 11254
step    600 | loss 1.8042 | lr 3.00e-04 | grad 1.78 | tok/s 10853
step    610 | loss 1.6214 | lr 3.00e-04 | grad 1.77 | tok/s 11452
step    620 | loss 1.5440 | lr 3.00e-04 | grad 1.84 | tok/s 10885
step    630 | loss 1.6544 | lr 3.00e-04 | grad 3.39 | tok/s 10858
step    640 | loss 1.7945 | lr 3.00e-04 | grad 1.91 | tok/s 11095
step    650 | loss 1.6585 | lr 3.00e-04 | grad 1.94 | tok/s 10227
step    660 | loss 1.6956 | lr 3.00e-04 | grad 1.68 | tok/s 11117
step    670 | loss 1.9011 | lr 3.00e-04 | grad 2.44 | tok/s 11359
step    680 | loss 1.7186 | lr 3.00e-04 | grad 1.85 | tok/s 11171
step    690 | loss 1.8296 | lr 3.00e-04 | grad 2.50 | tok/s 10705
step    700 | loss 1.4420 | lr 3.00e-04 | grad 2.30 | tok/s 11643
step    710 | loss 1.5838 | lr 3.00e-04 | grad 1.80 | tok/s 9930
step    720 | loss 1.4609 | lr 3.00e-04 | grad 2.64 | tok/s 10772
step    730 | loss 1.3028 | lr 3.00e-04 | grad 2.14 | tok/s 11207
step    740 | loss 1.5071 | lr 3.00e-04 | grad 1.85 | tok/s 11500
step    750 | loss 1.2163 | lr 3.00e-04 | grad 1.92 | tok/s 10821
step    760 | loss 1.1201 | lr 3.00e-04 | grad 1.71 | tok/s 11692
step    770 | loss 1.0686 | lr 3.00e-04 | grad 1.54 | tok/s 11540
step    780 | loss 1.0046 | lr 3.00e-04 | grad 1.67 | tok/s 11696
step    790 | loss 1.1262 | lr 3.00e-04 | grad 2.67 | tok/s 10588
step    800 | loss 1.8064 | lr 3.00e-04 | grad 4.44 | tok/s 10758
step    810 | loss 1.6955 | lr 3.00e-04 | grad 1.70 | tok/s 11269
step    820 | loss 1.7011 | lr 3.00e-04 | grad 3.08 | tok/s 10762
step    830 | loss 1.4884 | lr 3.00e-04 | grad 1.89 | tok/s 10379
step    840 | loss 1.3832 | lr 3.00e-04 | grad 1.80 | tok/s 11701
step    850 | loss 1.5759 | lr 3.00e-04 | grad 1.64 | tok/s 11609
step    860 | loss 1.4772 | lr 3.00e-04 | grad 2.77 | tok/s 11547
step    870 | loss 1.4924 | lr 3.00e-04 | grad 2.06 | tok/s 11132
step    880 | loss 1.6674 | lr 3.00e-04 | grad 2.27 | tok/s 11168
step    890 | loss 1.6686 | lr 3.00e-04 | grad 2.39 | tok/s 11301
step    900 | loss 1.5515 | lr 3.00e-04 | grad 2.03 | tok/s 11318
step    910 | loss 1.4125 | lr 3.00e-04 | grad 3.05 | tok/s 11075
step    920 | loss 1.5166 | lr 3.00e-04 | grad 2.75 | tok/s 11551
step    930 | loss 1.5860 | lr 3.00e-04 | grad 2.77 | tok/s 10993
step    940 | loss 1.3915 | lr 3.00e-04 | grad 1.48 | tok/s 11607
step    950 | loss 1.4908 | lr 3.00e-04 | grad 2.06 | tok/s 11660
step    960 | loss 1.3228 | lr 3.00e-04 | grad 1.93 | tok/s 11667
step    970 | loss 1.7259 | lr 3.00e-04 | grad 2.81 | tok/s 9266
step    980 | loss 1.6319 | lr 3.00e-04 | grad 1.90 | tok/s 11262
step    990 | loss 1.4456 | lr 3.00e-04 | grad 1.67 | tok/s 11462
step   1000 | loss 1.8197 | lr 3.00e-04 | grad 6.12 | tok/s 10963
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8197.pt
step   1010 | loss 1.6216 | lr 3.00e-04 | grad 2.31 | tok/s 3967
step   1020 | loss 1.5944 | lr 3.00e-04 | grad 1.91 | tok/s 10652
step   1030 | loss 1.3892 | lr 3.00e-04 | grad 1.70 | tok/s 11406
step   1040 | loss 1.5005 | lr 3.00e-04 | grad 1.86 | tok/s 11263
step   1050 | loss 1.6298 | lr 3.00e-04 | grad 1.82 | tok/s 11216
step   1060 | loss 1.6953 | lr 3.00e-04 | grad 2.28 | tok/s 11506
step   1070 | loss 1.6373 | lr 3.00e-04 | grad 2.62 | tok/s 11179
step   1080 | loss 1.3825 | lr 3.00e-04 | grad 1.95 | tok/s 10688
step   1090 | loss 1.0169 | lr 3.00e-04 | grad 2.17 | tok/s 11557
step   1100 | loss 1.5540 | lr 3.00e-04 | grad 2.03 | tok/s 11463
step   1110 | loss 1.3678 | lr 3.00e-04 | grad 1.52 | tok/s 11779
step   1120 | loss 1.3268 | lr 3.00e-04 | grad 1.52 | tok/s 11774
step   1130 | loss 1.2640 | lr 3.00e-04 | grad 1.36 | tok/s 10850
step   1140 | loss 1.2820 | lr 3.00e-04 | grad 1.48 | tok/s 11792
step   1150 | loss 1.2773 | lr 3.00e-04 | grad 1.41 | tok/s 11761
step   1160 | loss 1.1970 | lr 3.00e-04 | grad 1.40 | tok/s 11738
step   1170 | loss 1.2996 | lr 3.00e-04 | grad 1.57 | tok/s 11736
step   1180 | loss 1.2863 | lr 3.00e-04 | grad 1.64 | tok/s 11745
step   1190 | loss 1.1968 | lr 3.00e-04 | grad 1.48 | tok/s 11719
step   1200 | loss 1.2360 | lr 3.00e-04 | grad 1.46 | tok/s 11725
step   1210 | loss 1.2689 | lr 3.00e-04 | grad 1.62 | tok/s 11752
step   1220 | loss 1.2499 | lr 3.00e-04 | grad 1.34 | tok/s 11765
step   1230 | loss 1.2516 | lr 3.00e-04 | grad 1.38 | tok/s 11776
step   1240 | loss 1.3820 | lr 3.00e-04 | grad 2.09 | tok/s 11458
step   1250 | loss 1.6951 | lr 3.00e-04 | grad 2.02 | tok/s 11234
step   1260 | loss 1.4120 | lr 3.00e-04 | grad 4.84 | tok/s 11105
step   1270 | loss 1.6148 | lr 3.00e-04 | grad 2.45 | tok/s 10910
step   1280 | loss 1.5825 | lr 3.00e-04 | grad 2.94 | tok/s 11626
step   1290 | loss 1.4641 | lr 3.00e-04 | grad 1.69 | tok/s 11365
step   1300 | loss 1.5030 | lr 3.00e-04 | grad 1.68 | tok/s 11167
step   1310 | loss 1.4427 | lr 3.00e-04 | grad 1.73 | tok/s 11649
step   1320 | loss 1.6894 | lr 3.00e-04 | grad 3.28 | tok/s 11626
step   1330 | loss 1.3497 | lr 3.00e-04 | grad 2.70 | tok/s 11472
step   1340 | loss 1.6353 | lr 3.00e-04 | grad 4.00 | tok/s 10770
step   1350 | loss 1.7210 | lr 3.00e-04 | grad 2.64 | tok/s 10910
step   1360 | loss 1.3865 | lr 3.00e-04 | grad 1.75 | tok/s 11222
step   1370 | loss 1.5570 | lr 3.00e-04 | grad 2.48 | tok/s 11408
step   1380 | loss 1.5331 | lr 3.00e-04 | grad 1.91 | tok/s 10854
step   1390 | loss 1.3899 | lr 3.00e-04 | grad 1.58 | tok/s 10996
step   1400 | loss 1.4004 | lr 3.00e-04 | grad 1.79 | tok/s 11435
step   1410 | loss 1.5337 | lr 3.00e-04 | grad 1.88 | tok/s 11113
step   1420 | loss 1.5806 | lr 3.00e-04 | grad 1.88 | tok/s 11108
step   1430 | loss 1.2837 | lr 3.00e-04 | grad 1.45 | tok/s 11209
step   1440 | loss 1.1249 | lr 3.00e-04 | grad 1.40 | tok/s 11769
step   1450 | loss 1.3235 | lr 3.00e-04 | grad 3.50 | tok/s 11610
step   1460 | loss 1.5880 | lr 3.00e-04 | grad 1.95 | tok/s 10874
step   1470 | loss 1.4305 | lr 3.00e-04 | grad 1.63 | tok/s 11620
step   1480 | loss 1.8363 | lr 3.00e-04 | grad 4.06 | tok/s 11658
step   1490 | loss 1.5194 | lr 3.00e-04 | grad 1.87 | tok/s 11714
step   1500 | loss 1.2369 | lr 3.00e-04 | grad 1.37 | tok/s 11776
step   1510 | loss 1.5733 | lr 3.00e-04 | grad 2.02 | tok/s 11571
step   1520 | loss 1.4490 | lr 3.00e-04 | grad 1.97 | tok/s 11345
step   1530 | loss 1.3723 | lr 3.00e-04 | grad 1.66 | tok/s 11303
step   1540 | loss 1.6315 | lr 3.00e-04 | grad 1.78 | tok/s 11242
step   1550 | loss 1.1941 | lr 3.00e-04 | grad 1.55 | tok/s 11616
step   1560 | loss 1.6181 | lr 3.00e-04 | grad 1.49 | tok/s 11089
step   1570 | loss 1.3555 | lr 3.00e-04 | grad 2.03 | tok/s 10355
step   1580 | loss 1.6572 | lr 3.00e-04 | grad 2.72 | tok/s 11548
step   1590 | loss 1.4740 | lr 3.00e-04 | grad 1.41 | tok/s 11060
step   1600 | loss 0.7725 | lr 3.00e-04 | grad 1.23 | tok/s 11758
step   1610 | loss 1.2862 | lr 3.00e-04 | grad 1.48 | tok/s 10836
step   1620 | loss 1.3602 | lr 3.00e-04 | grad 3.39 | tok/s 11120
step   1630 | loss 1.2976 | lr 3.00e-04 | grad 1.60 | tok/s 11380
step   1640 | loss 1.5195 | lr 3.00e-04 | grad 3.95 | tok/s 11014
step   1650 | loss 1.5187 | lr 3.00e-04 | grad 1.83 | tok/s 10337
step   1660 | loss 1.2064 | lr 3.00e-04 | grad 1.41 | tok/s 11671

Training complete! Final step: 1663
