Using device: cuda
Output directory: benchmark_results/cmaes_e88_10min_v2/e88_480M_15gen_20260127_140630/eval_61/levelE88_100m_20260127_151924
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88, 489,660,612 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1605 | lr 3.00e-04 | grad 11.00 | tok/s 5124
step     20 | loss 2.5669 | lr 3.00e-04 | grad 4.19 | tok/s 11639
step     30 | loss 2.4820 | lr 3.00e-04 | grad 2.62 | tok/s 11776
step     40 | loss 2.3297 | lr 3.00e-04 | grad 2.80 | tok/s 11324
step     50 | loss 2.9265 | lr 3.00e-04 | grad 10.06 | tok/s 11452
step     60 | loss 2.0178 | lr 3.00e-04 | grad 2.75 | tok/s 11864
step     70 | loss 1.8817 | lr 3.00e-04 | grad 3.83 | tok/s 11404
step     80 | loss 5.3251 | lr 3.00e-04 | grad 59.00 | tok/s 10562
step     90 | loss 5.1003 | lr 3.00e-04 | grad 8.44 | tok/s 12207
step    100 | loss 4.1797 | lr 3.00e-04 | grad 7.56 | tok/s 12206
step    110 | loss 3.5911 | lr 3.00e-04 | grad 14.81 | tok/s 12124
step    120 | loss 3.2443 | lr 3.00e-04 | grad 10.81 | tok/s 12180
step    130 | loss 2.9158 | lr 3.00e-04 | grad 12.38 | tok/s 12167
step    140 | loss 2.5813 | lr 3.00e-04 | grad 7.72 | tok/s 12188
step    150 | loss 2.6047 | lr 3.00e-04 | grad 8.38 | tok/s 12171
step    160 | loss 2.2413 | lr 3.00e-04 | grad 6.41 | tok/s 12178
step    170 | loss 2.3260 | lr 3.00e-04 | grad 9.88 | tok/s 12081
step    180 | loss 2.1370 | lr 3.00e-04 | grad 4.16 | tok/s 12142
step    190 | loss 2.2975 | lr 3.00e-04 | grad 8.56 | tok/s 12148
step    200 | loss 2.0126 | lr 3.00e-04 | grad 4.16 | tok/s 12051
step    210 | loss 2.0043 | lr 3.00e-04 | grad 4.12 | tok/s 12074
step    220 | loss 2.1116 | lr 3.00e-04 | grad 2.38 | tok/s 11904
step    230 | loss 1.9888 | lr 3.00e-04 | grad 3.36 | tok/s 11794
step    240 | loss 2.2569 | lr 3.00e-04 | grad 3.58 | tok/s 11186
step    250 | loss 2.0809 | lr 3.00e-04 | grad 1.89 | tok/s 11466
step    260 | loss 1.5590 | lr 3.00e-04 | grad 2.19 | tok/s 11817
step    270 | loss 2.0798 | lr 3.00e-04 | grad 2.05 | tok/s 11748
step    280 | loss 2.2495 | lr 3.00e-04 | grad 4.41 | tok/s 11486
step    290 | loss 1.3526 | lr 3.00e-04 | grad 3.23 | tok/s 12031
step    300 | loss 0.5559 | lr 3.00e-04 | grad 1.85 | tok/s 12027
step    310 | loss 2.3816 | lr 3.00e-04 | grad 2.97 | tok/s 11850
step    320 | loss 1.9410 | lr 3.00e-04 | grad 4.16 | tok/s 11633
step    330 | loss 1.9295 | lr 3.00e-04 | grad 2.16 | tok/s 11229
step    340 | loss 2.2334 | lr 3.00e-04 | grad 2.11 | tok/s 11404
step    350 | loss 1.8777 | lr 3.00e-04 | grad 3.39 | tok/s 11690
step    360 | loss 1.2218 | lr 3.00e-04 | grad 5.69 | tok/s 11725
step    370 | loss 1.7982 | lr 3.00e-04 | grad 2.03 | tok/s 10847
step    380 | loss 1.7567 | lr 3.00e-04 | grad 1.94 | tok/s 11587
step    390 | loss 1.5345 | lr 3.00e-04 | grad 1.50 | tok/s 12026
step    400 | loss 1.5300 | lr 3.00e-04 | grad 2.64 | tok/s 9588
step    410 | loss 1.3153 | lr 3.00e-04 | grad 2.41 | tok/s 11708
step    420 | loss 1.9124 | lr 3.00e-04 | grad 8.19 | tok/s 11235
step    430 | loss 2.0045 | lr 3.00e-04 | grad 1.73 | tok/s 11851
step    440 | loss 2.1738 | lr 3.00e-04 | grad 4.38 | tok/s 11470
step    450 | loss 1.8492 | lr 3.00e-04 | grad 1.60 | tok/s 11493
step    460 | loss 1.6399 | lr 3.00e-04 | grad 2.55 | tok/s 11432
step    470 | loss 1.8678 | lr 3.00e-04 | grad 2.27 | tok/s 11637
step    480 | loss 2.2685 | lr 3.00e-04 | grad 3.70 | tok/s 11818
step    490 | loss 1.7191 | lr 3.00e-04 | grad 1.84 | tok/s 11151
step    500 | loss 1.7010 | lr 3.00e-04 | grad 2.17 | tok/s 11087
step    510 | loss 1.6630 | lr 3.00e-04 | grad 1.76 | tok/s 12017
step    520 | loss 1.6530 | lr 3.00e-04 | grad 1.80 | tok/s 11714
step    530 | loss 1.8994 | lr 3.00e-04 | grad 1.67 | tok/s 11647
step    540 | loss 1.7078 | lr 3.00e-04 | grad 1.82 | tok/s 11651
step    550 | loss 1.5744 | lr 3.00e-04 | grad 2.03 | tok/s 11157
step    560 | loss 1.7213 | lr 3.00e-04 | grad 3.03 | tok/s 8887
step    570 | loss 1.6113 | lr 3.00e-04 | grad 2.92 | tok/s 11414
step    580 | loss 1.5407 | lr 3.00e-04 | grad 1.65 | tok/s 10740
step    590 | loss 1.8654 | lr 3.00e-04 | grad 2.12 | tok/s 10522
step    600 | loss 1.7852 | lr 3.00e-04 | grad 1.55 | tok/s 11176
step    610 | loss 1.5881 | lr 3.00e-04 | grad 1.80 | tok/s 11406
step    620 | loss 1.5750 | lr 3.00e-04 | grad 1.76 | tok/s 11351
step    630 | loss 1.6206 | lr 3.00e-04 | grad 2.14 | tok/s 11236
step    640 | loss 1.8611 | lr 3.00e-04 | grad 4.94 | tok/s 11307
step    650 | loss 1.5999 | lr 3.00e-04 | grad 2.64 | tok/s 11597
step    660 | loss 1.6740 | lr 3.00e-04 | grad 1.87 | tok/s 9372
step    670 | loss 1.9434 | lr 3.00e-04 | grad 2.23 | tok/s 11633
step    680 | loss 1.7786 | lr 3.00e-04 | grad 4.19 | tok/s 11441
step    690 | loss 1.6688 | lr 3.00e-04 | grad 2.47 | tok/s 11900
step    700 | loss 1.4792 | lr 3.00e-04 | grad 10.38 | tok/s 12109
step    710 | loss 1.5259 | lr 3.00e-04 | grad 2.03 | tok/s 11149
step    720 | loss 1.4801 | lr 3.00e-04 | grad 1.94 | tok/s 11350
step    730 | loss 1.2989 | lr 3.00e-04 | grad 1.98 | tok/s 12031
step    740 | loss 1.3838 | lr 3.00e-04 | grad 1.69 | tok/s 11811
step    750 | loss 1.1977 | lr 3.00e-04 | grad 1.81 | tok/s 12018
step    760 | loss 1.0904 | lr 3.00e-04 | grad 1.78 | tok/s 12048
step    770 | loss 1.0414 | lr 3.00e-04 | grad 1.55 | tok/s 12052
step    780 | loss 0.9772 | lr 3.00e-04 | grad 1.61 | tok/s 12033
step    790 | loss 1.2269 | lr 3.00e-04 | grad 2.41 | tok/s 11418
step    800 | loss 1.8714 | lr 3.00e-04 | grad 2.05 | tok/s 11649
step    810 | loss 1.6453 | lr 3.00e-04 | grad 2.33 | tok/s 11574
step    820 | loss 1.5700 | lr 3.00e-04 | grad 3.61 | tok/s 11407
step    830 | loss 1.5080 | lr 3.00e-04 | grad 1.95 | tok/s 11878
step    840 | loss 1.4680 | lr 3.00e-04 | grad 2.05 | tok/s 9598
step    850 | loss 1.5591 | lr 3.00e-04 | grad 2.16 | tok/s 12029
step    860 | loss 1.4337 | lr 3.00e-04 | grad 1.91 | tok/s 11691
step    870 | loss 1.4782 | lr 3.00e-04 | grad 1.89 | tok/s 11467
step    880 | loss 1.7088 | lr 3.00e-04 | grad 2.92 | tok/s 11523
step    890 | loss 1.6866 | lr 3.00e-04 | grad 3.47 | tok/s 11626
step    900 | loss 1.4221 | lr 3.00e-04 | grad 1.73 | tok/s 11641
step    910 | loss 1.5027 | lr 3.00e-04 | grad 3.11 | tok/s 11606
step    920 | loss 1.4984 | lr 3.00e-04 | grad 1.89 | tok/s 11854
step    930 | loss 1.5072 | lr 3.00e-04 | grad 1.78 | tok/s 11263
step    940 | loss 1.3852 | lr 3.00e-04 | grad 3.11 | tok/s 12059
step    950 | loss 1.3911 | lr 3.00e-04 | grad 2.03 | tok/s 12131
step    960 | loss 1.4370 | lr 3.00e-04 | grad 2.38 | tok/s 11919
step    970 | loss 1.8385 | lr 3.00e-04 | grad 2.36 | tok/s 11390
step    980 | loss 1.4968 | lr 3.00e-04 | grad 2.23 | tok/s 11493
step    990 | loss 1.5683 | lr 3.00e-04 | grad 3.20 | tok/s 10039
step   1000 | loss 1.7077 | lr 3.00e-04 | grad 1.95 | tok/s 11671
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7077.pt
step   1010 | loss 1.6503 | lr 3.00e-04 | grad 3.31 | tok/s 4587
step   1020 | loss 1.5174 | lr 3.00e-04 | grad 5.59 | tok/s 11140
step   1030 | loss 1.3679 | lr 3.00e-04 | grad 1.81 | tok/s 12017
step   1040 | loss 1.4507 | lr 3.00e-04 | grad 2.12 | tok/s 11162
step   1050 | loss 1.6863 | lr 3.00e-04 | grad 2.83 | tok/s 11892
step   1060 | loss 1.7131 | lr 3.00e-04 | grad 3.48 | tok/s 11976
step   1070 | loss 1.5157 | lr 3.00e-04 | grad 1.77 | tok/s 11434
step   1080 | loss 1.3590 | lr 3.00e-04 | grad 1.70 | tok/s 11158
step   1090 | loss 1.0834 | lr 3.00e-04 | grad 1.80 | tok/s 11912
step   1100 | loss 1.5036 | lr 3.00e-04 | grad 1.48 | tok/s 11829
step   1110 | loss 1.3495 | lr 3.00e-04 | grad 1.65 | tok/s 12185
step   1120 | loss 1.3187 | lr 3.00e-04 | grad 1.61 | tok/s 12192
step   1130 | loss 1.2399 | lr 3.00e-04 | grad 1.52 | tok/s 12221
step   1140 | loss 1.2899 | lr 3.00e-04 | grad 1.48 | tok/s 12156
step   1150 | loss 1.2355 | lr 3.00e-04 | grad 1.29 | tok/s 12191
step   1160 | loss 1.2134 | lr 3.00e-04 | grad 1.48 | tok/s 12179
step   1170 | loss 1.3060 | lr 3.00e-04 | grad 1.93 | tok/s 12192
step   1180 | loss 1.2402 | lr 3.00e-04 | grad 1.41 | tok/s 12182
step   1190 | loss 1.1817 | lr 3.00e-04 | grad 1.73 | tok/s 12187
step   1200 | loss 1.2369 | lr 3.00e-04 | grad 1.48 | tok/s 12188
step   1210 | loss 1.2689 | lr 3.00e-04 | grad 1.59 | tok/s 12177
step   1220 | loss 1.2240 | lr 3.00e-04 | grad 1.20 | tok/s 12169
step   1230 | loss 1.2427 | lr 3.00e-04 | grad 1.49 | tok/s 12136
step   1240 | loss 1.5534 | lr 3.00e-04 | grad 3.94 | tok/s 11743
step   1250 | loss 1.5989 | lr 3.00e-04 | grad 3.55 | tok/s 11327
step   1260 | loss 1.3741 | lr 3.00e-04 | grad 1.77 | tok/s 11700
step   1270 | loss 1.7025 | lr 3.00e-04 | grad 2.94 | tok/s 11181
step   1280 | loss 1.4635 | lr 3.00e-04 | grad 1.74 | tok/s 11880
step   1290 | loss 1.4854 | lr 3.00e-04 | grad 1.95 | tok/s 11892
step   1300 | loss 1.4613 | lr 3.00e-04 | grad 1.84 | tok/s 11534
step   1310 | loss 1.4861 | lr 3.00e-04 | grad 3.27 | tok/s 11866
step   1320 | loss 1.6647 | lr 3.00e-04 | grad 1.59 | tok/s 12135
step   1330 | loss 1.3048 | lr 3.00e-04 | grad 2.27 | tok/s 11535
step   1340 | loss 1.7256 | lr 3.00e-04 | grad 2.72 | tok/s 11182
step   1350 | loss 1.6245 | lr 3.00e-04 | grad 2.14 | tok/s 11544
step   1360 | loss 1.3668 | lr 3.00e-04 | grad 1.56 | tok/s 11518
step   1370 | loss 1.5650 | lr 3.00e-04 | grad 2.02 | tok/s 11819
step   1380 | loss 1.4900 | lr 3.00e-04 | grad 1.86 | tok/s 11118
step   1390 | loss 1.4097 | lr 3.00e-04 | grad 2.67 | tok/s 11442
step   1400 | loss 1.4000 | lr 3.00e-04 | grad 3.45 | tok/s 11629
step   1410 | loss 1.4904 | lr 3.00e-04 | grad 1.74 | tok/s 11344
step   1420 | loss 1.5450 | lr 3.00e-04 | grad 1.91 | tok/s 11889
step   1430 | loss 1.2592 | lr 3.00e-04 | grad 1.82 | tok/s 10943
step   1440 | loss 1.0975 | lr 3.00e-04 | grad 1.62 | tok/s 12133
step   1450 | loss 1.4264 | lr 3.00e-04 | grad 2.41 | tok/s 11769
step   1460 | loss 1.5382 | lr 3.00e-04 | grad 1.69 | tok/s 11448
step   1470 | loss 1.5359 | lr 3.00e-04 | grad 3.27 | tok/s 11953
step   1480 | loss 1.7490 | lr 3.00e-04 | grad 3.34 | tok/s 12103
step   1490 | loss 1.4536 | lr 3.00e-04 | grad 1.84 | tok/s 12070
step   1500 | loss 1.3180 | lr 3.00e-04 | grad 4.16 | tok/s 12034
step   1510 | loss 1.4937 | lr 3.00e-04 | grad 1.58 | tok/s 12168
step   1520 | loss 1.4424 | lr 3.00e-04 | grad 1.79 | tok/s 11778
step   1530 | loss 1.4996 | lr 3.00e-04 | grad 4.75 | tok/s 11645
step   1540 | loss 1.4510 | lr 3.00e-04 | grad 1.42 | tok/s 11740
step   1550 | loss 1.2980 | lr 3.00e-04 | grad 2.69 | tok/s 11992
step   1560 | loss 1.4936 | lr 3.00e-04 | grad 1.91 | tok/s 11481
step   1570 | loss 1.3864 | lr 3.00e-04 | grad 1.90 | tok/s 11822
step   1580 | loss 1.7357 | lr 3.00e-04 | grad 3.39 | tok/s 12101
step   1590 | loss 1.2810 | lr 3.00e-04 | grad 1.31 | tok/s 11418
step   1600 | loss 0.8129 | lr 3.00e-04 | grad 1.73 | tok/s 12060
step   1610 | loss 1.2876 | lr 3.00e-04 | grad 1.64 | tok/s 10827
step   1620 | loss 1.4721 | lr 3.00e-04 | grad 2.56 | tok/s 11636
step   1630 | loss 1.1895 | lr 3.00e-04 | grad 4.22 | tok/s 12078
step   1640 | loss 1.4611 | lr 3.00e-04 | grad 1.65 | tok/s 11016
step   1650 | loss 1.5386 | lr 3.00e-04 | grad 1.59 | tok/s 11203
step   1660 | loss 1.1369 | lr 3.00e-04 | grad 1.80 | tok/s 12019
step   1670 | loss 1.7722 | lr 3.00e-04 | grad 2.50 | tok/s 11171
step   1680 | loss 1.4898 | lr 3.00e-04 | grad 4.50 | tok/s 11406
step   1690 | loss 1.4518 | lr 3.00e-04 | grad 2.83 | tok/s 10322
step   1700 | loss 1.3953 | lr 3.00e-04 | grad 1.64 | tok/s 11319
step   1710 | loss 1.3975 | lr 3.00e-04 | grad 2.00 | tok/s 11834

Training complete! Final step: 1713
