/home/erikg/elman/elman/models/multiscale_elman.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  logit = torch.log(torch.tensor(decay / (1 - decay)))
e10_k8: dim=800 depth=6 k=8 batch=160 params=50,179,200
Step 100 | 50s | Loss 2.0156 | Avg100 2.5053 | 164704 tok/s | Mem 29.2GB
Step 200 | 101s | Loss 1.7656 | Avg100 1.8605 | 162678 tok/s | Mem 29.2GB
Step 300 | 153s | Loss 1.6406 | Avg100 1.6795 | 160938 tok/s | Mem 29.2GB
Step 400 | 205s | Loss 1.5547 | Avg100 1.5999 | 160086 tok/s | Mem 29.2GB
Step 500 | 257s | Loss 1.5156 | Avg100 1.5502 | 159580 tok/s | Mem 29.2GB
Step 600 | 309s | Loss 1.4922 | Avg100 1.5221 | 159245 tok/s | Mem 29.2GB
Step 700 | 361s | Loss 1.4609 | Avg100 1.4914 | 159005 tok/s | Mem 29.2GB
Step 800 | 413s | Loss 1.5000 | Avg100 1.4798 | 158827 tok/s | Mem 29.2GB
Step 900 | 465s | Loss 1.4531 | Avg100 1.4668 | 158688 tok/s | Mem 29.2GB
Step 1000 | 517s | Loss 1.4219 | Avg100 1.4548 | 158577 tok/s | Mem 29.2GB
Step 1100 | 569s | Loss 1.4141 | Avg100 1.4438 | 158486 tok/s | Mem 29.2GB
DONE: e10_k8 | Steps=1161 | Time=600s | Last100=1.4430 | 158439 tok/s | PeakMem=29.2GB
les/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/elman/elman/models/multiscale_elman.py", line 255, in forward
    xz = self.in_proj(x)  # [B, T, d_inner + (1+n_banks)*d_inner]
         ^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.22 GiB. GPU 0 has a total capacity of 47.38 GiB of which 1.20 GiB is free. Process 1458993 has 28.94 GiB memory in use. Including non-PyTorch memory, this process has 17.23 GiB memory in use. Of the allocated memory 16.63 GiB is allocated by PyTorch, and 105.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
