/home/erikg/elman/elman/models/multiscale_elman.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  logit = torch.log(torch.tensor(decay / (1 - decay)))
e10_k4: dim=960 depth=6 k=4 batch=192 params=50,054,400
Step 100 | 49s | Loss 1.9297 | Avg100 2.4632 | 199087 tok/s | Mem 26.8GB
Step 200 | 100s | Loss 1.7344 | Avg100 1.7834 | 196405 tok/s | Mem 26.8GB
Step 300 | 152s | Loss 1.5625 | Avg100 1.6247 | 194033 tok/s | Mem 26.8GB
Step 400 | 204s | Loss 1.5078 | Avg100 1.5540 | 192778 tok/s | Mem 26.8GB
Step 500 | 256s | Loss 1.4922 | Avg100 1.5192 | 192032 tok/s | Mem 26.8GB
Step 600 | 308s | Loss 1.4922 | Avg100 1.4821 | 191538 tok/s | Mem 26.8GB
Step 700 | 360s | Loss 1.4375 | Avg100 1.4648 | 191186 tok/s | Mem 26.8GB
Step 800 | 412s | Loss 1.4062 | Avg100 1.4526 | 190923 tok/s | Mem 26.8GB
Step 900 | 464s | Loss 1.4453 | Avg100 1.4398 | 190719 tok/s | Mem 26.8GB
Step 1000 | 516s | Loss 1.4922 | Avg100 1.4299 | 190557 tok/s | Mem 26.8GB
Step 1100 | 568s | Loss 1.4297 | Avg100 1.4177 | 190423 tok/s | Mem 26.8GB
DONE: e10_k4 | Steps=1162 | Time=600s | Last100=1.4127 | 190353 tok/s | PeakMem=26.8GB
les/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/elman/elman/models/multiscale_elman.py", line 255, in forward
    xz = self.in_proj(x)  # [B, T, d_inner + (1+n_banks)*d_inner]
         ^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 47.38 GiB of which 1.03 GiB is free. Process 1458992 has 26.71 GiB memory in use. Including non-PyTorch memory, this process has 19.63 GiB memory in use. Of the allocated memory 19.12 GiB is allocated by PyTorch, and 17.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
