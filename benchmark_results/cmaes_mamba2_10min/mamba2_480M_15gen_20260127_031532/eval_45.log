Using device: cuda
Output directory: benchmark_results/cmaes_mamba2_10min/mamba2_480M_15gen_20260127_031532/eval_45/levelmamba2_100m_20260127_040713
Model: Level mamba2, 462,443,968 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 6.5283 | lr 3.00e-04 | grad 17.00 | tok/s 4520
step     20 | loss 3.0214 | lr 3.00e-04 | grad 3.42 | tok/s 21528
step     30 | loss 3.9480 | lr 3.00e-04 | grad 9.50 | tok/s 22082
step     40 | loss 3.6984 | lr 3.00e-04 | grad 11.44 | tok/s 22278
step     50 | loss 2.5454 | lr 3.00e-04 | grad 5.34 | tok/s 22166
step     60 | loss 2.2416 | lr 3.00e-04 | grad 3.77 | tok/s 22044
step     70 | loss 2.0542 | lr 3.00e-04 | grad 2.66 | tok/s 21970
step     80 | loss 1.9539 | lr 3.00e-04 | grad 4.44 | tok/s 21858
step     90 | loss 1.8346 | lr 3.00e-04 | grad 1.93 | tok/s 21837
step    100 | loss 1.9927 | lr 3.00e-04 | grad 6.34 | tok/s 21646
step    110 | loss 2.7295 | lr 3.00e-04 | grad 5.59 | tok/s 20721
step    120 | loss 1.9310 | lr 3.00e-04 | grad 4.34 | tok/s 21020
step    130 | loss 2.3610 | lr 3.00e-04 | grad 9.00 | tok/s 20846
step    140 | loss 1.3289 | lr 3.00e-04 | grad 3.70 | tok/s 21531
step    150 | loss 2.4085 | lr 3.00e-04 | grad 3.64 | tok/s 21146
step    160 | loss 2.1660 | lr 3.00e-04 | grad 3.39 | tok/s 20520
step    170 | loss 1.7911 | lr 3.00e-04 | grad 6.16 | tok/s 21093
step    180 | loss 1.8463 | lr 3.00e-04 | grad 3.39 | tok/s 20250
step    190 | loss 1.5736 | lr 3.00e-04 | grad 4.25 | tok/s 21510
step    200 | loss 1.6995 | lr 3.00e-04 | grad 3.64 | tok/s 20428
step    210 | loss 2.0829 | lr 3.00e-04 | grad 5.34 | tok/s 20804
step    220 | loss 1.8154 | lr 3.00e-04 | grad 2.66 | tok/s 20525
step    230 | loss 2.0777 | lr 3.00e-04 | grad 2.83 | tok/s 20912
step    240 | loss 1.7426 | lr 3.00e-04 | grad 2.30 | tok/s 20811
step    250 | loss 1.7451 | lr 3.00e-04 | grad 2.84 | tok/s 21369
step    260 | loss 1.7603 | lr 3.00e-04 | grad 3.06 | tok/s 20938
step    270 | loss 1.6383 | lr 3.00e-04 | grad 2.47 | tok/s 19777
step    280 | loss 1.5700 | lr 3.00e-04 | grad 2.61 | tok/s 20423
step    290 | loss 1.8643 | lr 3.00e-04 | grad 2.11 | tok/s 20431
step    300 | loss 1.5863 | lr 3.00e-04 | grad 1.76 | tok/s 20279
step    310 | loss 1.7724 | lr 3.00e-04 | grad 5.19 | tok/s 20384
step    320 | loss 1.6543 | lr 3.00e-04 | grad 3.28 | tok/s 20895
step    330 | loss 1.8834 | lr 3.00e-04 | grad 5.84 | tok/s 20645
step    340 | loss 1.6661 | lr 3.00e-04 | grad 4.88 | tok/s 21538
step    350 | loss 1.5122 | lr 3.00e-04 | grad 2.50 | tok/s 20099
step    360 | loss 1.4439 | lr 3.00e-04 | grad 1.76 | tok/s 21492
step    370 | loss 1.2280 | lr 3.00e-04 | grad 2.12 | tok/s 21707
step    380 | loss 1.0931 | lr 3.00e-04 | grad 1.62 | tok/s 21713
step    390 | loss 1.6281 | lr 3.00e-04 | grad 2.86 | tok/s 20760
step    400 | loss 1.6447 | lr 3.00e-04 | grad 7.69 | tok/s 20711
step    410 | loss 1.5862 | lr 3.00e-04 | grad 2.22 | tok/s 21546
step    420 | loss 1.5491 | lr 3.00e-04 | grad 1.78 | tok/s 21468
step    430 | loss 1.5992 | lr 3.00e-04 | grad 2.91 | tok/s 20829
step    440 | loss 1.5874 | lr 3.00e-04 | grad 2.11 | tok/s 20779
step    450 | loss 1.5315 | lr 3.00e-04 | grad 2.31 | tok/s 21194
step    460 | loss 1.4431 | lr 3.00e-04 | grad 1.68 | tok/s 20950
step    470 | loss 1.6092 | lr 3.00e-04 | grad 2.00 | tok/s 21604
step    480 | loss 1.6406 | lr 3.00e-04 | grad 2.12 | tok/s 20584
step    490 | loss 1.7330 | lr 3.00e-04 | grad 3.47 | tok/s 21075
step    500 | loss 1.6138 | lr 3.00e-04 | grad 1.70 | tok/s 20095
step    510 | loss 1.4872 | lr 3.00e-04 | grad 3.91 | tok/s 21092
step    520 | loss 1.6246 | lr 3.00e-04 | grad 2.88 | tok/s 20640
step    530 | loss 1.5798 | lr 3.00e-04 | grad 1.56 | tok/s 20686
step    540 | loss 1.2470 | lr 3.00e-04 | grad 1.98 | tok/s 20749
step    550 | loss 1.4548 | lr 3.00e-04 | grad 1.93 | tok/s 21791
step    560 | loss 1.3105 | lr 3.00e-04 | grad 1.94 | tok/s 21812
step    570 | loss 1.2839 | lr 3.00e-04 | grad 2.39 | tok/s 21809
step    580 | loss 1.3146 | lr 3.00e-04 | grad 1.95 | tok/s 21832
step    590 | loss 1.2312 | lr 3.00e-04 | grad 2.06 | tok/s 21833
step    600 | loss 1.2861 | lr 3.00e-04 | grad 2.28 | tok/s 21769
step    610 | loss 1.2416 | lr 3.00e-04 | grad 1.26 | tok/s 21813
step    620 | loss 1.6305 | lr 3.00e-04 | grad 4.19 | tok/s 20542
step    630 | loss 1.6091 | lr 3.00e-04 | grad 2.75 | tok/s 20697
step    640 | loss 1.4988 | lr 3.00e-04 | grad 1.89 | tok/s 21122
step    650 | loss 1.5437 | lr 3.00e-04 | grad 2.16 | tok/s 21273
step    660 | loss 1.5067 | lr 3.00e-04 | grad 2.20 | tok/s 20988
step    670 | loss 1.6220 | lr 3.00e-04 | grad 1.73 | tok/s 20396
step    680 | loss 1.5195 | lr 3.00e-04 | grad 1.77 | tok/s 20494
step    690 | loss 1.4634 | lr 3.00e-04 | grad 2.20 | tok/s 20688
step    700 | loss 1.5211 | lr 3.00e-04 | grad 3.17 | tok/s 20573
step    710 | loss 1.3058 | lr 3.00e-04 | grad 2.17 | tok/s 21266
step    720 | loss 1.3721 | lr 3.00e-04 | grad 2.14 | tok/s 21213
step    730 | loss 1.6661 | lr 3.00e-04 | grad 6.25 | tok/s 21293
step    740 | loss 1.5586 | lr 3.00e-04 | grad 1.79 | tok/s 21817
step    750 | loss 1.4294 | lr 3.00e-04 | grad 1.56 | tok/s 21385
step    760 | loss 1.5204 | lr 3.00e-04 | grad 1.71 | tok/s 21051
step    770 | loss 1.4514 | lr 3.00e-04 | grad 2.52 | tok/s 21090
step    780 | loss 1.5349 | lr 3.00e-04 | grad 4.16 | tok/s 21602
step    790 | loss 1.4117 | lr 3.00e-04 | grad 1.33 | tok/s 21211
step    800 | loss 1.1868 | lr 3.00e-04 | grad 3.55 | tok/s 20577
step    810 | loss 1.3916 | lr 3.00e-04 | grad 2.48 | tok/s 21258
step    820 | loss 1.4597 | lr 3.00e-04 | grad 1.86 | tok/s 20352
step    830 | loss 1.5454 | lr 3.00e-04 | grad 2.48 | tok/s 20750
step    840 | loss 1.4673 | lr 3.00e-04 | grad 2.34 | tok/s 20966
step    850 | loss 1.5062 | lr 3.00e-04 | grad 2.72 | tok/s 21185
step    860 | loss 1.3359 | lr 3.00e-04 | grad 2.11 | tok/s 21696
step    870 | loss 1.5270 | lr 3.00e-04 | grad 2.42 | tok/s 20887
step    880 | loss 1.4644 | lr 3.00e-04 | grad 1.95 | tok/s 21058
step    890 | loss 1.4796 | lr 3.00e-04 | grad 2.47 | tok/s 21018
step    900 | loss 1.4154 | lr 3.00e-04 | grad 2.11 | tok/s 20539
step    910 | loss 1.4577 | lr 3.00e-04 | grad 2.23 | tok/s 20984
step    920 | loss 1.3387 | lr 3.00e-04 | grad 1.73 | tok/s 21130
step    930 | loss 1.3193 | lr 3.00e-04 | grad 2.44 | tok/s 20700
step    940 | loss 1.4211 | lr 3.00e-04 | grad 1.55 | tok/s 20233
step    950 | loss 1.4224 | lr 3.00e-04 | grad 2.17 | tok/s 20904
step    960 | loss 1.4162 | lr 3.00e-04 | grad 1.61 | tok/s 20908
step    970 | loss 1.8117 | lr 3.00e-04 | grad 3.12 | tok/s 21733
step    980 | loss 1.5443 | lr 3.00e-04 | grad 1.77 | tok/s 20876
step    990 | loss 1.5060 | lr 3.00e-04 | grad 1.66 | tok/s 21121
step   1000 | loss 1.2404 | lr 3.00e-04 | grad 2.09 | tok/s 21264
  >>> saved checkpoint: checkpoint_step_001000_loss_1.2404.pt
step   1010 | loss 1.2100 | lr 3.00e-04 | grad 1.30 | tok/s 10114
step   1020 | loss 1.4999 | lr 3.00e-04 | grad 2.20 | tok/s 21113
step   1030 | loss 2.0320 | lr 3.00e-04 | grad 3.72 | tok/s 21538
step   1040 | loss 1.4329 | lr 3.00e-04 | grad 2.39 | tok/s 21662
step   1050 | loss 1.0969 | lr 3.00e-04 | grad 2.92 | tok/s 21448
step   1060 | loss 1.3886 | lr 3.00e-04 | grad 2.34 | tok/s 21313
step   1070 | loss 1.2420 | lr 3.00e-04 | grad 1.58 | tok/s 22059
step   1080 | loss 1.2075 | lr 3.00e-04 | grad 1.64 | tok/s 22045
step   1090 | loss 1.1938 | lr 3.00e-04 | grad 1.98 | tok/s 22019
step   1100 | loss 1.1349 | lr 3.00e-04 | grad 1.96 | tok/s 22011
step   1110 | loss 1.4077 | lr 3.00e-04 | grad 3.61 | tok/s 21343
step   1120 | loss 1.5605 | lr 3.00e-04 | grad 1.79 | tok/s 21638
step   1130 | loss 1.7116 | lr 3.00e-04 | grad 1.92 | tok/s 21866
step   1140 | loss 1.5914 | lr 3.00e-04 | grad 2.28 | tok/s 21189
step   1150 | loss 1.6785 | lr 3.00e-04 | grad 2.92 | tok/s 20871
step   1160 | loss 1.4440 | lr 3.00e-04 | grad 2.05 | tok/s 20601
step   1170 | loss 1.3082 | lr 3.00e-04 | grad 3.33 | tok/s 21660
step   1180 | loss 1.5912 | lr 3.00e-04 | grad 2.64 | tok/s 21851
step   1190 | loss 1.1049 | lr 3.00e-04 | grad 4.16 | tok/s 21924
step   1200 | loss 1.3423 | lr 3.00e-04 | grad 1.77 | tok/s 20459
step   1210 | loss 1.3428 | lr 3.00e-04 | grad 2.03 | tok/s 21462
step   1220 | loss 1.3019 | lr 3.00e-04 | grad 1.34 | tok/s 21502
step   1230 | loss 1.2764 | lr 3.00e-04 | grad 1.82 | tok/s 21603
step   1240 | loss 1.4253 | lr 3.00e-04 | grad 2.30 | tok/s 21274
step   1250 | loss 1.3345 | lr 3.00e-04 | grad 2.22 | tok/s 21714
step   1260 | loss 1.3470 | lr 3.00e-04 | grad 1.77 | tok/s 21095
step   1270 | loss 1.3351 | lr 3.00e-04 | grad 1.78 | tok/s 20864
step   1280 | loss 1.3106 | lr 3.00e-04 | grad 2.09 | tok/s 20893
step   1290 | loss 1.6056 | lr 3.00e-04 | grad 5.75 | tok/s 20638
step   1300 | loss 1.4672 | lr 3.00e-04 | grad 2.00 | tok/s 21416
step   1310 | loss 1.4352 | lr 3.00e-04 | grad 1.73 | tok/s 21412
step   1320 | loss 1.3852 | lr 3.00e-04 | grad 1.70 | tok/s 21187
step   1330 | loss 1.4860 | lr 3.00e-04 | grad 2.28 | tok/s 20738
step   1340 | loss 1.3737 | lr 3.00e-04 | grad 1.46 | tok/s 21149
step   1350 | loss 1.4274 | lr 3.00e-04 | grad 1.77 | tok/s 20456
step   1360 | loss 1.5507 | lr 3.00e-04 | grad 2.69 | tok/s 21529
step   1370 | loss 1.3917 | lr 3.00e-04 | grad 1.65 | tok/s 20561
step   1380 | loss 1.2946 | lr 3.00e-04 | grad 2.95 | tok/s 21547
step   1390 | loss 1.4920 | lr 3.00e-04 | grad 2.25 | tok/s 20793
step   1400 | loss 1.3704 | lr 3.00e-04 | grad 3.59 | tok/s 20336
step   1410 | loss 1.1391 | lr 3.00e-04 | grad 4.78 | tok/s 21687
step   1420 | loss 1.6256 | lr 3.00e-04 | grad 2.14 | tok/s 20885
step   1430 | loss 1.4037 | lr 3.00e-04 | grad 2.06 | tok/s 21435
step   1440 | loss 1.4012 | lr 3.00e-04 | grad 7.97 | tok/s 21418
step   1450 | loss 1.5186 | lr 3.00e-04 | grad 3.86 | tok/s 20821
step   1460 | loss 1.3085 | lr 3.00e-04 | grad 2.25 | tok/s 20337
step   1470 | loss 1.3242 | lr 3.00e-04 | grad 1.55 | tok/s 21421
step   1480 | loss 1.7589 | lr 3.00e-04 | grad 9.31 | tok/s 21144
step   1490 | loss 1.4145 | lr 3.00e-04 | grad 1.76 | tok/s 21159
step   1500 | loss 1.2391 | lr 3.00e-04 | grad 2.02 | tok/s 21169
step   1510 | loss 1.4268 | lr 3.00e-04 | grad 1.76 | tok/s 20978
step   1520 | loss 1.3556 | lr 3.00e-04 | grad 1.74 | tok/s 21334
step   1530 | loss 1.4669 | lr 3.00e-04 | grad 1.88 | tok/s 21556
step   1540 | loss 1.4372 | lr 3.00e-04 | grad 2.05 | tok/s 21111

Training complete! Final step: 1540
