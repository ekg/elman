Using device: cuda
Output directory: benchmark_results/cmaes_mamba2_10min/mamba2_480M_15gen_20260127_031532/eval_57/levelmamba2_100m_20260127_042803
Model: Level mamba2, 958,039,680 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 8.6941 | lr 3.00e-04 | grad 17.00 | tok/s 2388
step     20 | loss 3.1248 | lr 3.00e-04 | grad 5.44 | tok/s 11355
step     30 | loss 2.4723 | lr 3.00e-04 | grad 5.75 | tok/s 10823
step     40 | loss 2.7108 | lr 3.00e-04 | grad 7.69 | tok/s 10816
step     50 | loss 2.1023 | lr 3.00e-04 | grad 8.38 | tok/s 11356
step     60 | loss 1.7586 | lr 3.00e-04 | grad 3.70 | tok/s 11359
step     70 | loss 4.7521 | lr 3.00e-04 | grad 11.38 | tok/s 11306
step     80 | loss 3.9913 | lr 3.00e-04 | grad 18.25 | tok/s 11589
step     90 | loss 3.1426 | lr 3.00e-04 | grad 15.00 | tok/s 11556
step    100 | loss 2.6807 | lr 3.00e-04 | grad 19.88 | tok/s 11570
step    110 | loss 2.4209 | lr 3.00e-04 | grad 5.62 | tok/s 11480
step    120 | loss 2.2896 | lr 3.00e-04 | grad 4.41 | tok/s 11473
step    130 | loss 2.1579 | lr 3.00e-04 | grad 5.12 | tok/s 11474
step    140 | loss 2.0744 | lr 3.00e-04 | grad 6.94 | tok/s 11457
step    150 | loss 1.9123 | lr 3.00e-04 | grad 6.25 | tok/s 11496
step    160 | loss 1.9819 | lr 3.00e-04 | grad 6.69 | tok/s 11474
step    170 | loss 1.8375 | lr 3.00e-04 | grad 5.84 | tok/s 11390
step    180 | loss 1.9371 | lr 3.00e-04 | grad 13.38 | tok/s 11446
step    190 | loss 1.7527 | lr 3.00e-04 | grad 5.50 | tok/s 11442
step    200 | loss 1.8111 | lr 3.00e-04 | grad 5.22 | tok/s 11384
step    210 | loss 2.0838 | lr 3.00e-04 | grad 9.75 | tok/s 11293
step    220 | loss 2.5844 | lr 3.00e-04 | grad 7.78 | tok/s 11328
step    230 | loss 2.3179 | lr 3.00e-04 | grad 4.94 | tok/s 10483
step    240 | loss 2.2357 | lr 3.00e-04 | grad 6.06 | tok/s 10813
step    250 | loss 1.7170 | lr 3.00e-04 | grad 5.12 | tok/s 11399
step    260 | loss 2.1669 | lr 3.00e-04 | grad 3.88 | tok/s 10906
step    270 | loss 2.3518 | lr 3.00e-04 | grad 6.72 | tok/s 11084
step    280 | loss 1.9605 | lr 3.00e-04 | grad 3.70 | tok/s 11234
step    290 | loss 0.7050 | lr 3.00e-04 | grad 2.56 | tok/s 11482
step    300 | loss 2.5269 | lr 3.00e-04 | grad 8.88 | tok/s 11244
step    310 | loss 2.0023 | lr 3.00e-04 | grad 4.66 | tok/s 11153
step    320 | loss 2.0409 | lr 3.00e-04 | grad 2.64 | tok/s 10502
step    330 | loss 2.2682 | lr 3.00e-04 | grad 6.09 | tok/s 10849
step    340 | loss 1.9622 | lr 3.00e-04 | grad 3.44 | tok/s 11048
step    350 | loss 1.3892 | lr 3.00e-04 | grad 9.81 | tok/s 11366
step    360 | loss 1.9290 | lr 3.00e-04 | grad 3.05 | tok/s 10237
step    370 | loss 1.8049 | lr 3.00e-04 | grad 3.36 | tok/s 10945
step    380 | loss 1.5934 | lr 3.00e-04 | grad 1.98 | tok/s 11413
step    390 | loss 1.5069 | lr 3.00e-04 | grad 3.42 | tok/s 11316
step    400 | loss 1.3987 | lr 3.00e-04 | grad 2.08 | tok/s 11443
step    410 | loss 1.6890 | lr 3.00e-04 | grad 3.11 | tok/s 10287
step    420 | loss 2.2390 | lr 3.00e-04 | grad 3.30 | tok/s 11197
step    430 | loss 2.1470 | lr 3.00e-04 | grad 7.19 | tok/s 10717
step    440 | loss 1.9470 | lr 3.00e-04 | grad 27.88 | tok/s 10940
step    450 | loss 1.8829 | lr 3.00e-04 | grad 3.30 | tok/s 10778
step    460 | loss 1.7992 | lr 3.00e-04 | grad 3.28 | tok/s 11132
step    470 | loss 2.1589 | lr 3.00e-04 | grad 13.19 | tok/s 11094
step    480 | loss 1.8937 | lr 3.00e-04 | grad 3.23 | tok/s 10526
step    490 | loss 1.6693 | lr 3.00e-04 | grad 3.59 | tok/s 11201
step    500 | loss 1.7302 | lr 3.00e-04 | grad 2.42 | tok/s 11363
step    510 | loss 1.7267 | lr 3.00e-04 | grad 2.94 | tok/s 11360
step    520 | loss 1.8995 | lr 3.00e-04 | grad 2.98 | tok/s 10946
step    530 | loss 1.7728 | lr 3.00e-04 | grad 2.39 | tok/s 10903
step    540 | loss 1.5501 | lr 3.00e-04 | grad 2.22 | tok/s 10724
step    550 | loss 1.7539 | lr 3.00e-04 | grad 5.50 | tok/s 10395
step    560 | loss 1.6752 | lr 3.00e-04 | grad 2.81 | tok/s 10817
step    570 | loss 1.5386 | lr 3.00e-04 | grad 2.83 | tok/s 10570
step    580 | loss 1.8259 | lr 3.00e-04 | grad 16.50 | tok/s 10984
step    590 | loss 1.8573 | lr 3.00e-04 | grad 3.45 | tok/s 10507
step    600 | loss 1.6455 | lr 3.00e-04 | grad 4.91 | tok/s 11110
step    610 | loss 1.5646 | lr 3.00e-04 | grad 7.12 | tok/s 10604
step    620 | loss 1.6558 | lr 3.00e-04 | grad 3.06 | tok/s 10509
step    630 | loss 1.7977 | lr 3.00e-04 | grad 5.53 | tok/s 10900
step    640 | loss 1.6701 | lr 3.00e-04 | grad 7.62 | tok/s 10972
step    650 | loss 1.7639 | lr 3.00e-04 | grad 3.72 | tok/s 11065
step    660 | loss 1.8762 | lr 3.00e-04 | grad 3.73 | tok/s 11006
step    670 | loss 1.7552 | lr 3.00e-04 | grad 3.02 | tok/s 10847
step    680 | loss 1.8763 | lr 3.00e-04 | grad 2.78 | tok/s 11195
step    690 | loss 1.5536 | lr 3.00e-04 | grad 3.39 | tok/s 11421
step    700 | loss 1.6089 | lr 3.00e-04 | grad 2.41 | tok/s 10819
step    710 | loss 1.4589 | lr 3.00e-04 | grad 4.88 | tok/s 10408
step    720 | loss 1.3703 | lr 3.00e-04 | grad 1.75 | tok/s 11421
step    730 | loss 1.5943 | lr 3.00e-04 | grad 2.42 | tok/s 11281
step    740 | loss 1.3034 | lr 3.00e-04 | grad 4.09 | tok/s 11436
step    750 | loss 1.1971 | lr 3.00e-04 | grad 2.59 | tok/s 11425
step    760 | loss 1.1269 | lr 3.00e-04 | grad 2.77 | tok/s 11431
step    770 | loss 1.0648 | lr 3.00e-04 | grad 2.30 | tok/s 11431
step    780 | loss 1.1136 | lr 3.00e-04 | grad 2.81 | tok/s 11183
step    790 | loss 1.7808 | lr 3.00e-04 | grad 3.59 | tok/s 10932
step    800 | loss 1.8165 | lr 3.00e-04 | grad 2.38 | tok/s 10978
step    810 | loss 1.6716 | lr 3.00e-04 | grad 2.64 | tok/s 10611
step    820 | loss 1.6047 | lr 3.00e-04 | grad 3.48 | tok/s 11327
step    830 | loss 1.4421 | lr 3.00e-04 | grad 3.36 | tok/s 11448
step    840 | loss 1.5910 | lr 3.00e-04 | grad 2.59 | tok/s 11381
step    850 | loss 1.4390 | lr 3.00e-04 | grad 2.61 | tok/s 11316
step    860 | loss 1.5838 | lr 3.00e-04 | grad 4.00 | tok/s 10790
step    870 | loss 1.7118 | lr 3.00e-04 | grad 4.53 | tok/s 11026
step    880 | loss 1.6553 | lr 3.00e-04 | grad 2.84 | tok/s 10941
step    890 | loss 1.5665 | lr 3.00e-04 | grad 3.83 | tok/s 11073
step    900 | loss 1.4162 | lr 3.00e-04 | grad 2.83 | tok/s 10855
step    910 | loss 1.5824 | lr 3.00e-04 | grad 7.16 | tok/s 11255
step    920 | loss 1.5856 | lr 3.00e-04 | grad 2.67 | tok/s 10755
step    930 | loss 1.4429 | lr 3.00e-04 | grad 2.53 | tok/s 11332
step    940 | loss 1.5560 | lr 3.00e-04 | grad 2.61 | tok/s 11427
step    950 | loss 1.4086 | lr 3.00e-04 | grad 3.81 | tok/s 11355
step    960 | loss 1.6785 | lr 3.00e-04 | grad 4.34 | tok/s 10735
step    970 | loss 1.6980 | lr 3.00e-04 | grad 2.89 | tok/s 11165
step    980 | loss 1.4684 | lr 3.00e-04 | grad 3.19 | tok/s 11061
step    990 | loss 1.7764 | lr 3.00e-04 | grad 5.53 | tok/s 10776
step   1000 | loss 1.7609 | lr 3.00e-04 | grad 3.28 | tok/s 11110
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7609.pt
step   1010 | loss 1.5414 | lr 3.00e-04 | grad 7.12 | tok/s 3016
step   1020 | loss 1.4012 | lr 3.00e-04 | grad 2.59 | tok/s 11586
step   1030 | loss 1.4783 | lr 3.00e-04 | grad 2.59 | tok/s 10769
step   1040 | loss 1.7076 | lr 3.00e-04 | grad 5.09 | tok/s 11462
step   1050 | loss 1.7631 | lr 3.00e-04 | grad 17.62 | tok/s 11511
step   1060 | loss 1.6031 | lr 3.00e-04 | grad 3.48 | tok/s 10986
step   1070 | loss 1.3778 | lr 3.00e-04 | grad 2.16 | tok/s 10707
step   1080 | loss 1.1098 | lr 3.00e-04 | grad 2.33 | tok/s 11502
step   1090 | loss 1.5061 | lr 3.00e-04 | grad 1.83 | tok/s 11320
step   1100 | loss 1.3732 | lr 3.00e-04 | grad 2.59 | tok/s 11611
step   1110 | loss 1.3396 | lr 3.00e-04 | grad 2.69 | tok/s 11597
step   1120 | loss 1.2536 | lr 3.00e-04 | grad 2.95 | tok/s 11609
step   1130 | loss 1.3064 | lr 3.00e-04 | grad 2.20 | tok/s 11602
step   1140 | loss 1.2562 | lr 3.00e-04 | grad 2.05 | tok/s 11605
step   1150 | loss 1.2310 | lr 3.00e-04 | grad 2.56 | tok/s 11586
step   1160 | loss 1.3322 | lr 3.00e-04 | grad 2.36 | tok/s 11572
step   1170 | loss 1.2660 | lr 3.00e-04 | grad 2.66 | tok/s 11597
step   1180 | loss 1.1973 | lr 3.00e-04 | grad 2.86 | tok/s 11561
step   1190 | loss 1.2572 | lr 3.00e-04 | grad 2.34 | tok/s 11578
step   1200 | loss 1.2934 | lr 3.00e-04 | grad 2.95 | tok/s 11550
step   1210 | loss 1.2366 | lr 3.00e-04 | grad 2.25 | tok/s 11540
step   1220 | loss 1.2648 | lr 3.00e-04 | grad 1.99 | tok/s 11537
step   1230 | loss 1.6029 | lr 3.00e-04 | grad 4.81 | tok/s 11129
step   1240 | loss 1.6112 | lr 3.00e-04 | grad 3.83 | tok/s 10796
step   1250 | loss 1.3836 | lr 3.00e-04 | grad 2.34 | tok/s 11146
step   1260 | loss 1.6994 | lr 3.00e-04 | grad 3.31 | tok/s 10599
step   1270 | loss 1.4885 | lr 3.00e-04 | grad 2.75 | tok/s 11238
step   1280 | loss 1.5000 | lr 3.00e-04 | grad 2.31 | tok/s 11295
step   1290 | loss 1.4883 | lr 3.00e-04 | grad 5.38 | tok/s 10936
step   1300 | loss 1.5051 | lr 3.00e-04 | grad 6.09 | tok/s 11259
step   1310 | loss 1.7093 | lr 3.00e-04 | grad 4.00 | tok/s 11476
step   1320 | loss 1.3273 | lr 3.00e-04 | grad 2.78 | tok/s 10955
step   1330 | loss 1.7577 | lr 3.00e-04 | grad 5.75 | tok/s 10587
step   1340 | loss 1.6368 | lr 3.00e-04 | grad 3.17 | tok/s 10915
step   1350 | loss 1.4101 | lr 3.00e-04 | grad 2.94 | tok/s 10871
step   1360 | loss 1.5853 | lr 3.00e-04 | grad 2.62 | tok/s 11190
step   1370 | loss 1.5253 | lr 3.00e-04 | grad 2.70 | tok/s 10528
step   1380 | loss 1.4063 | lr 3.00e-04 | grad 3.77 | tok/s 10818
step   1390 | loss 1.4034 | lr 3.00e-04 | grad 3.45 | tok/s 11006
step   1400 | loss 1.5024 | lr 3.00e-04 | grad 5.97 | tok/s 10753
step   1410 | loss 1.5760 | lr 3.00e-04 | grad 2.80 | tok/s 11283
step   1420 | loss 1.2703 | lr 3.00e-04 | grad 3.64 | tok/s 10963
step   1430 | loss 1.1188 | lr 3.00e-04 | grad 2.73 | tok/s 11489
step   1440 | loss 1.4076 | lr 3.00e-04 | grad 3.62 | tok/s 11168
step   1450 | loss 1.5452 | lr 3.00e-04 | grad 2.25 | tok/s 10815
step   1460 | loss 1.5579 | lr 3.00e-04 | grad 6.28 | tok/s 11265
step   1470 | loss 1.8355 | lr 3.00e-04 | grad 5.22 | tok/s 11474
step   1480 | loss 1.4988 | lr 3.00e-04 | grad 3.45 | tok/s 11435
step   1490 | loss 1.3276 | lr 3.00e-04 | grad 9.94 | tok/s 11351
step   1500 | loss 1.5173 | lr 3.00e-04 | grad 3.03 | tok/s 11465
step   1510 | loss 1.4421 | lr 3.00e-04 | grad 6.09 | tok/s 11092
step   1520 | loss 1.5030 | lr 3.00e-04 | grad 5.00 | tok/s 10984
step   1530 | loss 1.4715 | lr 3.00e-04 | grad 2.02 | tok/s 11072
step   1540 | loss 1.3145 | lr 3.00e-04 | grad 3.38 | tok/s 11320
step   1550 | loss 1.5103 | lr 3.00e-04 | grad 3.17 | tok/s 10887
step   1560 | loss 1.4167 | lr 3.00e-04 | grad 2.97 | tok/s 11219
step   1570 | loss 1.8250 | lr 3.00e-04 | grad 5.72 | tok/s 11418
step   1580 | loss 1.3127 | lr 3.00e-04 | grad 1.67 | tok/s 10825
step   1590 | loss 0.8308 | lr 3.00e-04 | grad 2.33 | tok/s 11585

Training complete! Final step: 1593
