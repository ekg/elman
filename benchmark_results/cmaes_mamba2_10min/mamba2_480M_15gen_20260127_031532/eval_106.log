Using device: cuda
Output directory: benchmark_results/cmaes_mamba2_10min/mamba2_480M_15gen_20260127_031532/eval_106/levelmamba2_100m_20260127_053016
Model: Level mamba2, 451,796,120 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 5.5505 | lr 3.00e-04 | grad 24.62 | tok/s 4755
step     20 | loss 3.0161 | lr 3.00e-04 | grad 3.62 | tok/s 25011
step     30 | loss 3.9284 | lr 3.00e-04 | grad 6.75 | tok/s 25682
step     40 | loss 3.4744 | lr 3.00e-04 | grad 9.50 | tok/s 25980
step     50 | loss 2.5958 | lr 3.00e-04 | grad 4.09 | tok/s 25867
step     60 | loss 2.2374 | lr 3.00e-04 | grad 2.45 | tok/s 25856
step     70 | loss 2.0240 | lr 3.00e-04 | grad 2.75 | tok/s 25749
step     80 | loss 1.9198 | lr 3.00e-04 | grad 3.33 | tok/s 25674
step     90 | loss 1.7916 | lr 3.00e-04 | grad 2.16 | tok/s 25601
step    100 | loss 1.9679 | lr 3.00e-04 | grad 6.03 | tok/s 25451
step    110 | loss 2.6945 | lr 3.00e-04 | grad 3.77 | tok/s 24427
step    120 | loss 1.8731 | lr 3.00e-04 | grad 3.33 | tok/s 24799
step    130 | loss 2.3267 | lr 3.00e-04 | grad 8.50 | tok/s 24655
step    140 | loss 1.3716 | lr 3.00e-04 | grad 4.81 | tok/s 25479
step    150 | loss 2.5018 | lr 3.00e-04 | grad 2.95 | tok/s 24927
step    160 | loss 2.1358 | lr 3.00e-04 | grad 2.41 | tok/s 24198
step    170 | loss 1.6966 | lr 3.00e-04 | grad 2.31 | tok/s 24889
step    180 | loss 1.7979 | lr 3.00e-04 | grad 2.62 | tok/s 23958
step    190 | loss 1.5273 | lr 3.00e-04 | grad 5.31 | tok/s 25382
step    200 | loss 1.6741 | lr 3.00e-04 | grad 3.12 | tok/s 24119
step    210 | loss 2.0616 | lr 3.00e-04 | grad 5.56 | tok/s 24531
step    220 | loss 1.7842 | lr 3.00e-04 | grad 2.19 | tok/s 24217
step    230 | loss 2.0777 | lr 3.00e-04 | grad 2.36 | tok/s 24625
step    240 | loss 1.7128 | lr 3.00e-04 | grad 1.92 | tok/s 24544
step    250 | loss 1.7159 | lr 3.00e-04 | grad 2.44 | tok/s 25104
step    260 | loss 1.7377 | lr 3.00e-04 | grad 2.41 | tok/s 24617
step    270 | loss 1.6198 | lr 3.00e-04 | grad 1.93 | tok/s 23279
step    280 | loss 1.5493 | lr 3.00e-04 | grad 2.02 | tok/s 24131
step    290 | loss 1.8468 | lr 3.00e-04 | grad 1.69 | tok/s 24159
step    300 | loss 1.5665 | lr 3.00e-04 | grad 1.49 | tok/s 23988
step    310 | loss 1.7438 | lr 3.00e-04 | grad 4.09 | tok/s 24100
step    320 | loss 1.6236 | lr 3.00e-04 | grad 2.64 | tok/s 24680
step    330 | loss 1.8717 | lr 3.00e-04 | grad 4.97 | tok/s 24417
step    340 | loss 1.6418 | lr 3.00e-04 | grad 4.19 | tok/s 25402
step    350 | loss 1.5006 | lr 3.00e-04 | grad 1.95 | tok/s 23708
step    360 | loss 1.4229 | lr 3.00e-04 | grad 1.48 | tok/s 25304
step    370 | loss 1.1992 | lr 3.00e-04 | grad 1.48 | tok/s 25537
step    380 | loss 1.0721 | lr 3.00e-04 | grad 1.68 | tok/s 25539
step    390 | loss 1.6101 | lr 3.00e-04 | grad 2.47 | tok/s 24429
step    400 | loss 1.6319 | lr 3.00e-04 | grad 7.16 | tok/s 24370
step    410 | loss 1.5591 | lr 3.00e-04 | grad 2.03 | tok/s 25319
step    420 | loss 1.5249 | lr 3.00e-04 | grad 1.66 | tok/s 25209
step    430 | loss 1.5791 | lr 3.00e-04 | grad 2.50 | tok/s 24482
step    440 | loss 1.5638 | lr 3.00e-04 | grad 1.72 | tok/s 24450
step    450 | loss 1.5091 | lr 3.00e-04 | grad 2.05 | tok/s 24909
step    460 | loss 1.4167 | lr 3.00e-04 | grad 1.42 | tok/s 24624
step    470 | loss 1.5710 | lr 3.00e-04 | grad 1.91 | tok/s 25396
step    480 | loss 1.6216 | lr 3.00e-04 | grad 1.86 | tok/s 24155
step    490 | loss 1.7185 | lr 3.00e-04 | grad 2.83 | tok/s 24711
step    500 | loss 1.6029 | lr 3.00e-04 | grad 1.44 | tok/s 23605
step    510 | loss 1.4644 | lr 3.00e-04 | grad 3.98 | tok/s 24737
step    520 | loss 1.6051 | lr 3.00e-04 | grad 2.48 | tok/s 24210
step    530 | loss 1.5571 | lr 3.00e-04 | grad 1.41 | tok/s 24262
step    540 | loss 1.2323 | lr 3.00e-04 | grad 1.60 | tok/s 24428
step    550 | loss 1.4314 | lr 3.00e-04 | grad 1.60 | tok/s 25478
step    560 | loss 1.2905 | lr 3.00e-04 | grad 1.51 | tok/s 25487
step    570 | loss 1.2581 | lr 3.00e-04 | grad 1.83 | tok/s 25486
step    580 | loss 1.2901 | lr 3.00e-04 | grad 1.51 | tok/s 25513
step    590 | loss 1.2109 | lr 3.00e-04 | grad 1.39 | tok/s 25530
step    600 | loss 1.2646 | lr 3.00e-04 | grad 1.70 | tok/s 25530
step    610 | loss 1.2205 | lr 3.00e-04 | grad 0.98 | tok/s 25525
step    620 | loss 1.6078 | lr 3.00e-04 | grad 3.45 | tok/s 24118
step    630 | loss 1.5840 | lr 3.00e-04 | grad 1.87 | tok/s 24282
step    640 | loss 1.4616 | lr 3.00e-04 | grad 1.67 | tok/s 24779
step    650 | loss 1.5230 | lr 3.00e-04 | grad 1.83 | tok/s 24884
step    660 | loss 1.4911 | lr 3.00e-04 | grad 1.91 | tok/s 24580
step    670 | loss 1.5962 | lr 3.00e-04 | grad 1.38 | tok/s 23990
step    680 | loss 1.4926 | lr 3.00e-04 | grad 1.67 | tok/s 24060
step    690 | loss 1.4441 | lr 3.00e-04 | grad 1.82 | tok/s 24285
step    700 | loss 1.5053 | lr 3.00e-04 | grad 2.89 | tok/s 24081
step    710 | loss 1.2874 | lr 3.00e-04 | grad 1.55 | tok/s 24896
step    720 | loss 1.3456 | lr 3.00e-04 | grad 1.80 | tok/s 24798
step    730 | loss 1.6546 | lr 3.00e-04 | grad 6.25 | tok/s 24928
step    740 | loss 1.5504 | lr 3.00e-04 | grad 1.56 | tok/s 25503
step    750 | loss 1.4074 | lr 3.00e-04 | grad 1.44 | tok/s 24998
step    760 | loss 1.4883 | lr 3.00e-04 | grad 1.43 | tok/s 24580
step    770 | loss 1.4382 | lr 3.00e-04 | grad 2.11 | tok/s 24627
step    780 | loss 1.5166 | lr 3.00e-04 | grad 3.42 | tok/s 25238
step    790 | loss 1.3996 | lr 3.00e-04 | grad 1.46 | tok/s 24806
step    800 | loss 1.1732 | lr 3.00e-04 | grad 3.22 | tok/s 24177
step    810 | loss 1.3656 | lr 3.00e-04 | grad 2.23 | tok/s 24833
step    820 | loss 1.4446 | lr 3.00e-04 | grad 1.45 | tok/s 23805
step    830 | loss 1.5222 | lr 3.00e-04 | grad 1.82 | tok/s 24262
step    840 | loss 1.4459 | lr 3.00e-04 | grad 2.14 | tok/s 24500
step    850 | loss 1.4967 | lr 3.00e-04 | grad 2.64 | tok/s 24773
step    860 | loss 1.3294 | lr 3.00e-04 | grad 1.84 | tok/s 25355
step    870 | loss 1.5079 | lr 3.00e-04 | grad 2.11 | tok/s 24396
step    880 | loss 1.4439 | lr 3.00e-04 | grad 1.55 | tok/s 24616
step    890 | loss 1.4642 | lr 3.00e-04 | grad 2.19 | tok/s 24575
step    900 | loss 1.3912 | lr 3.00e-04 | grad 1.80 | tok/s 24014
step    910 | loss 1.4418 | lr 3.00e-04 | grad 1.92 | tok/s 24514
step    920 | loss 1.3195 | lr 3.00e-04 | grad 1.38 | tok/s 24692
step    930 | loss 1.3063 | lr 3.00e-04 | grad 2.11 | tok/s 24244
step    940 | loss 1.4085 | lr 3.00e-04 | grad 1.37 | tok/s 23640
step    950 | loss 1.4041 | lr 3.00e-04 | grad 1.71 | tok/s 24431
step    960 | loss 1.3999 | lr 3.00e-04 | grad 1.53 | tok/s 24461
step    970 | loss 1.8507 | lr 3.00e-04 | grad 2.84 | tok/s 25423
step    980 | loss 1.5310 | lr 3.00e-04 | grad 1.45 | tok/s 24425
step    990 | loss 1.4913 | lr 3.00e-04 | grad 1.42 | tok/s 24697
step   1000 | loss 1.1626 | lr 3.00e-04 | grad 1.61 | tok/s 24945
  >>> saved checkpoint: checkpoint_step_001000_loss_1.1626.pt
step   1010 | loss 1.2195 | lr 3.00e-04 | grad 1.62 | tok/s 12473
step   1020 | loss 1.4111 | lr 3.00e-04 | grad 1.90 | tok/s 24533
step   1030 | loss 1.9972 | lr 3.00e-04 | grad 3.81 | tok/s 25090
step   1040 | loss 1.4697 | lr 3.00e-04 | grad 1.42 | tok/s 25258
step   1050 | loss 1.1617 | lr 3.00e-04 | grad 1.73 | tok/s 25008
step   1060 | loss 1.3027 | lr 3.00e-04 | grad 1.53 | tok/s 24908
step   1070 | loss 1.2198 | lr 3.00e-04 | grad 1.46 | tok/s 25638
step   1080 | loss 1.1993 | lr 3.00e-04 | grad 1.51 | tok/s 25587
step   1090 | loss 1.1743 | lr 3.00e-04 | grad 1.43 | tok/s 25592
step   1100 | loss 1.1222 | lr 3.00e-04 | grad 1.30 | tok/s 25577
step   1110 | loss 1.3348 | lr 3.00e-04 | grad 1.66 | tok/s 24939
step   1120 | loss 1.5699 | lr 3.00e-04 | grad 1.45 | tok/s 25189
step   1130 | loss 1.6935 | lr 3.00e-04 | grad 1.52 | tok/s 25514
step   1140 | loss 1.5720 | lr 3.00e-04 | grad 2.88 | tok/s 24911
step   1150 | loss 1.5844 | lr 3.00e-04 | grad 3.66 | tok/s 24153
step   1160 | loss 1.4736 | lr 3.00e-04 | grad 1.87 | tok/s 24076
step   1170 | loss 1.3107 | lr 3.00e-04 | grad 1.38 | tok/s 25275
step   1180 | loss 1.5276 | lr 3.00e-04 | grad 2.45 | tok/s 25321
step   1190 | loss 1.1121 | lr 3.00e-04 | grad 1.30 | tok/s 25583
step   1200 | loss 1.2737 | lr 3.00e-04 | grad 1.51 | tok/s 24205
step   1210 | loss 1.3136 | lr 3.00e-04 | grad 1.69 | tok/s 24932
step   1220 | loss 1.3498 | lr 3.00e-04 | grad 1.37 | tok/s 25086
step   1230 | loss 1.2086 | lr 3.00e-04 | grad 2.09 | tok/s 25326
step   1240 | loss 1.4220 | lr 3.00e-04 | grad 2.17 | tok/s 24710
step   1250 | loss 1.2958 | lr 3.00e-04 | grad 1.49 | tok/s 25318
step   1260 | loss 1.3208 | lr 3.00e-04 | grad 2.23 | tok/s 24610
step   1270 | loss 1.3222 | lr 3.00e-04 | grad 2.03 | tok/s 24663
step   1280 | loss 1.3008 | lr 3.00e-04 | grad 1.84 | tok/s 24105
step   1290 | loss 1.5156 | lr 3.00e-04 | grad 7.09 | tok/s 24063
step   1300 | loss 1.4426 | lr 3.00e-04 | grad 1.95 | tok/s 25036
step   1310 | loss 1.4263 | lr 3.00e-04 | grad 3.19 | tok/s 24955
step   1320 | loss 1.3713 | lr 3.00e-04 | grad 1.54 | tok/s 24864
step   1330 | loss 1.4636 | lr 3.00e-04 | grad 1.40 | tok/s 24121
step   1340 | loss 1.3630 | lr 3.00e-04 | grad 1.45 | tok/s 25046
step   1350 | loss 1.4120 | lr 3.00e-04 | grad 1.52 | tok/s 23551
step   1360 | loss 1.4658 | lr 3.00e-04 | grad 3.34 | tok/s 25119
step   1370 | loss 1.4120 | lr 3.00e-04 | grad 1.74 | tok/s 24366
step   1380 | loss 1.2859 | lr 3.00e-04 | grad 2.19 | tok/s 24845
step   1390 | loss 1.4716 | lr 3.00e-04 | grad 1.30 | tok/s 24298
step   1400 | loss 1.3029 | lr 3.00e-04 | grad 1.55 | tok/s 23874
step   1410 | loss 1.0612 | lr 3.00e-04 | grad 1.61 | tok/s 25305
step   1420 | loss 1.6380 | lr 3.00e-04 | grad 1.24 | tok/s 24473
step   1430 | loss 1.3948 | lr 3.00e-04 | grad 2.08 | tok/s 24711
step   1440 | loss 1.3534 | lr 3.00e-04 | grad 1.41 | tok/s 25015
step   1450 | loss 1.4552 | lr 3.00e-04 | grad 2.33 | tok/s 24274
step   1460 | loss 1.3384 | lr 3.00e-04 | grad 1.62 | tok/s 23974
step   1470 | loss 1.3147 | lr 3.00e-04 | grad 2.38 | tok/s 24829
step   1480 | loss 1.5904 | lr 3.00e-04 | grad 6.03 | tok/s 24592
step   1490 | loss 1.5206 | lr 3.00e-04 | grad 1.38 | tok/s 24943
step   1500 | loss 1.2248 | lr 3.00e-04 | grad 1.45 | tok/s 24508
step   1510 | loss 1.4114 | lr 3.00e-04 | grad 1.95 | tok/s 24387
step   1520 | loss 1.3303 | lr 3.00e-04 | grad 1.68 | tok/s 25016
step   1530 | loss 1.4469 | lr 3.00e-04 | grad 1.43 | tok/s 25065
step   1540 | loss 1.4127 | lr 3.00e-04 | grad 4.47 | tok/s 24622
step   1550 | loss 1.1004 | lr 3.00e-04 | grad 1.05 | tok/s 25372
step   1560 | loss 1.2540 | lr 3.00e-04 | grad 1.31 | tok/s 24839
step   1570 | loss 1.1782 | lr 3.00e-04 | grad 1.67 | tok/s 24913
step   1580 | loss 1.3862 | lr 3.00e-04 | grad 3.20 | tok/s 24021
step   1590 | loss 1.1816 | lr 3.00e-04 | grad 5.56 | tok/s 25370
step   1600 | loss 1.7995 | lr 3.00e-04 | grad 3.12 | tok/s 24708
step   1610 | loss 1.9696 | lr 3.00e-04 | grad 2.31 | tok/s 25494
step   1620 | loss 1.6343 | lr 3.00e-04 | grad 2.42 | tok/s 25493
step   1630 | loss 1.4691 | lr 3.00e-04 | grad 2.50 | tok/s 25487
step   1640 | loss 1.3642 | lr 3.00e-04 | grad 2.14 | tok/s 25481
step   1650 | loss 1.3204 | lr 3.00e-04 | grad 1.88 | tok/s 25503
step   1660 | loss 1.4474 | lr 3.00e-04 | grad 2.06 | tok/s 24721
step   1670 | loss 1.3483 | lr 3.00e-04 | grad 1.77 | tok/s 24493
step   1680 | loss 1.4217 | lr 3.00e-04 | grad 2.50 | tok/s 23947
step   1690 | loss 1.2810 | lr 3.00e-04 | grad 1.38 | tok/s 24840
step   1700 | loss 1.1844 | lr 3.00e-04 | grad 2.50 | tok/s 24902
step   1710 | loss 1.3967 | lr 3.00e-04 | grad 1.36 | tok/s 24164
step   1720 | loss 1.3634 | lr 3.00e-04 | grad 2.75 | tok/s 24911
step   1730 | loss 1.3479 | lr 3.00e-04 | grad 1.89 | tok/s 25066
step   1740 | loss 1.2079 | lr 3.00e-04 | grad 1.64 | tok/s 24536
step   1750 | loss 1.3509 | lr 3.00e-04 | grad 1.61 | tok/s 24334
step   1760 | loss 1.5213 | lr 3.00e-04 | grad 1.79 | tok/s 24890
step   1770 | loss 1.6900 | lr 3.00e-04 | grad 1.50 | tok/s 23546
step   1780 | loss 1.2602 | lr 3.00e-04 | grad 2.00 | tok/s 23941
step   1790 | loss 1.1722 | lr 3.00e-04 | grad 1.41 | tok/s 24459
step   1800 | loss 1.3733 | lr 3.00e-04 | grad 1.82 | tok/s 24635

Training complete! Final step: 1805
