Using device: cuda
Output directory: benchmark_results/cmaes_mamba2_10min/mamba2_480M_15gen_20260127_031532/eval_52/levelmamba2_100m_20260127_041737
Model: Level mamba2, 997,930,480 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 7.4923 | lr 3.00e-04 | grad 13.88 | tok/s 2391
step     20 | loss 3.0148 | lr 3.00e-04 | grad 5.75 | tok/s 11501
step     30 | loss 2.4685 | lr 3.00e-04 | grad 5.94 | tok/s 10984
step     40 | loss 2.7319 | lr 3.00e-04 | grad 8.56 | tok/s 10988
step     50 | loss 2.1066 | lr 3.00e-04 | grad 7.62 | tok/s 11518
step     60 | loss 1.7685 | lr 3.00e-04 | grad 4.16 | tok/s 11554
step     70 | loss 4.8498 | lr 3.00e-04 | grad 11.12 | tok/s 11473
step     80 | loss 3.8059 | lr 3.00e-04 | grad 17.88 | tok/s 11764
step     90 | loss 2.9430 | lr 3.00e-04 | grad 11.19 | tok/s 11705
step    100 | loss 2.5992 | lr 3.00e-04 | grad 16.62 | tok/s 11724
step    110 | loss 2.3280 | lr 3.00e-04 | grad 5.19 | tok/s 11688
step    120 | loss 2.2341 | lr 3.00e-04 | grad 6.50 | tok/s 11680
step    130 | loss 2.1511 | lr 3.00e-04 | grad 4.16 | tok/s 11680
step    140 | loss 2.0018 | lr 3.00e-04 | grad 5.34 | tok/s 11678
step    150 | loss 1.8978 | lr 3.00e-04 | grad 3.77 | tok/s 11676
step    160 | loss 1.9575 | lr 3.00e-04 | grad 8.81 | tok/s 11653
step    170 | loss 1.8165 | lr 3.00e-04 | grad 2.61 | tok/s 11652
step    180 | loss 1.9152 | lr 3.00e-04 | grad 3.38 | tok/s 11639
step    190 | loss 1.7369 | lr 3.00e-04 | grad 5.19 | tok/s 11654
step    200 | loss 1.7629 | lr 3.00e-04 | grad 3.88 | tok/s 11613
step    210 | loss 1.9768 | lr 3.00e-04 | grad 5.75 | tok/s 11523
step    220 | loss 2.2389 | lr 3.00e-04 | grad 7.22 | tok/s 11554
step    230 | loss 2.1865 | lr 3.00e-04 | grad 4.62 | tok/s 10764
step    240 | loss 2.1013 | lr 3.00e-04 | grad 4.50 | tok/s 11117
step    250 | loss 1.5300 | lr 3.00e-04 | grad 3.34 | tok/s 11679
step    260 | loss 1.9828 | lr 3.00e-04 | grad 4.06 | tok/s 11140
step    270 | loss 2.1930 | lr 3.00e-04 | grad 5.19 | tok/s 11352
step    280 | loss 1.5502 | lr 3.00e-04 | grad 3.41 | tok/s 11517
step    290 | loss 0.6089 | lr 3.00e-04 | grad 2.42 | tok/s 11725
step    300 | loss 2.3152 | lr 3.00e-04 | grad 5.69 | tok/s 11463
step    310 | loss 1.7753 | lr 3.00e-04 | grad 5.69 | tok/s 11343
step    320 | loss 1.8989 | lr 3.00e-04 | grad 3.48 | tok/s 10728
step    330 | loss 2.1534 | lr 3.00e-04 | grad 4.00 | tok/s 11082
step    340 | loss 1.8135 | lr 3.00e-04 | grad 3.17 | tok/s 11265
step    350 | loss 1.1654 | lr 3.00e-04 | grad 3.27 | tok/s 11585
step    360 | loss 1.7766 | lr 3.00e-04 | grad 2.78 | tok/s 10468
step    370 | loss 1.6664 | lr 3.00e-04 | grad 3.73 | tok/s 11153
step    380 | loss 1.4747 | lr 3.00e-04 | grad 3.62 | tok/s 11606
step    390 | loss 1.4114 | lr 3.00e-04 | grad 3.75 | tok/s 11511
step    400 | loss 1.2975 | lr 3.00e-04 | grad 2.64 | tok/s 11625
step    410 | loss 1.5822 | lr 3.00e-04 | grad 3.17 | tok/s 10517
step    420 | loss 2.0659 | lr 3.00e-04 | grad 2.34 | tok/s 11471
step    430 | loss 2.0294 | lr 3.00e-04 | grad 3.84 | tok/s 10958
step    440 | loss 1.8235 | lr 3.00e-04 | grad 3.89 | tok/s 11168
step    450 | loss 1.7351 | lr 3.00e-04 | grad 2.88 | tok/s 10992
step    460 | loss 1.6718 | lr 3.00e-04 | grad 3.38 | tok/s 11347
step    470 | loss 2.0275 | lr 3.00e-04 | grad 5.00 | tok/s 11307
step    480 | loss 1.7604 | lr 3.00e-04 | grad 2.03 | tok/s 10734
step    490 | loss 1.5589 | lr 3.00e-04 | grad 3.23 | tok/s 11393
step    500 | loss 1.6221 | lr 3.00e-04 | grad 2.95 | tok/s 11535
step    510 | loss 1.6064 | lr 3.00e-04 | grad 2.34 | tok/s 11525
step    520 | loss 1.7783 | lr 3.00e-04 | grad 2.75 | tok/s 11151
step    530 | loss 1.6567 | lr 3.00e-04 | grad 2.19 | tok/s 11089
step    540 | loss 1.4676 | lr 3.00e-04 | grad 1.92 | tok/s 10890
step    550 | loss 1.6356 | lr 3.00e-04 | grad 3.17 | tok/s 10590
step    560 | loss 1.5637 | lr 3.00e-04 | grad 2.86 | tok/s 10997
step    570 | loss 1.4560 | lr 3.00e-04 | grad 2.61 | tok/s 10791
step    580 | loss 1.7103 | lr 3.00e-04 | grad 6.22 | tok/s 11153
step    590 | loss 1.7536 | lr 3.00e-04 | grad 2.47 | tok/s 10687
step    600 | loss 1.5420 | lr 3.00e-04 | grad 2.77 | tok/s 11328
step    610 | loss 1.4831 | lr 3.00e-04 | grad 2.39 | tok/s 10796
step    620 | loss 1.5576 | lr 3.00e-04 | grad 2.50 | tok/s 10690
step    630 | loss 1.6896 | lr 3.00e-04 | grad 3.02 | tok/s 11098
step    640 | loss 1.6030 | lr 3.00e-04 | grad 1.97 | tok/s 11171
step    650 | loss 1.6430 | lr 3.00e-04 | grad 3.44 | tok/s 11257
step    660 | loss 1.7427 | lr 3.00e-04 | grad 3.61 | tok/s 11215
step    670 | loss 1.6637 | lr 3.00e-04 | grad 2.59 | tok/s 11022
step    680 | loss 1.7107 | lr 3.00e-04 | grad 2.45 | tok/s 11372
step    690 | loss 1.3807 | lr 3.00e-04 | grad 2.89 | tok/s 11621
step    700 | loss 1.4992 | lr 3.00e-04 | grad 2.25 | tok/s 10994
step    710 | loss 1.3690 | lr 3.00e-04 | grad 4.12 | tok/s 10638
step    720 | loss 1.2975 | lr 3.00e-04 | grad 2.50 | tok/s 11617
step    730 | loss 1.4846 | lr 3.00e-04 | grad 2.64 | tok/s 11428
step    740 | loss 1.1999 | lr 3.00e-04 | grad 2.53 | tok/s 11606
step    750 | loss 1.1014 | lr 3.00e-04 | grad 2.05 | tok/s 11618
step    760 | loss 1.0400 | lr 3.00e-04 | grad 1.52 | tok/s 11625
step    770 | loss 0.9909 | lr 3.00e-04 | grad 1.60 | tok/s 11616
step    780 | loss 1.0312 | lr 3.00e-04 | grad 2.50 | tok/s 11355
step    790 | loss 1.6607 | lr 3.00e-04 | grad 2.81 | tok/s 11101
step    800 | loss 1.7168 | lr 3.00e-04 | grad 2.84 | tok/s 11156
step    810 | loss 1.5780 | lr 3.00e-04 | grad 2.14 | tok/s 10726
step    820 | loss 1.4962 | lr 3.00e-04 | grad 2.23 | tok/s 11514
step    830 | loss 1.3422 | lr 3.00e-04 | grad 3.03 | tok/s 11634
step    840 | loss 1.5015 | lr 3.00e-04 | grad 2.62 | tok/s 11555
step    850 | loss 1.3233 | lr 3.00e-04 | grad 2.23 | tok/s 11507
step    860 | loss 1.4961 | lr 3.00e-04 | grad 2.08 | tok/s 10944
step    870 | loss 1.5648 | lr 3.00e-04 | grad 3.08 | tok/s 11159
step    880 | loss 1.5702 | lr 3.00e-04 | grad 2.41 | tok/s 11113
step    890 | loss 1.4849 | lr 3.00e-04 | grad 3.31 | tok/s 11282
step    900 | loss 1.3343 | lr 3.00e-04 | grad 2.80 | tok/s 10988
step    910 | loss 1.4913 | lr 3.00e-04 | grad 4.25 | tok/s 11425
step    920 | loss 1.5170 | lr 3.00e-04 | grad 2.19 | tok/s 10960
step    930 | loss 1.3617 | lr 3.00e-04 | grad 1.96 | tok/s 11501
step    940 | loss 1.4571 | lr 3.00e-04 | grad 2.47 | tok/s 11586
step    950 | loss 1.2666 | lr 3.00e-04 | grad 3.16 | tok/s 11591
step    960 | loss 1.5810 | lr 3.00e-04 | grad 4.06 | tok/s 10891
step    970 | loss 1.5954 | lr 3.00e-04 | grad 3.48 | tok/s 11313
step    980 | loss 1.3826 | lr 3.00e-04 | grad 2.38 | tok/s 11233
step    990 | loss 1.6816 | lr 3.00e-04 | grad 5.22 | tok/s 10950
step   1000 | loss 1.6913 | lr 3.00e-04 | grad 2.84 | tok/s 11267
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6913.pt
step   1010 | loss 1.4619 | lr 3.00e-04 | grad 6.38 | tok/s 2926
step   1020 | loss 1.3255 | lr 3.00e-04 | grad 2.17 | tok/s 11694
step   1030 | loss 1.3944 | lr 3.00e-04 | grad 2.20 | tok/s 10889
step   1040 | loss 1.6264 | lr 3.00e-04 | grad 4.38 | tok/s 11592
step   1050 | loss 1.6476 | lr 3.00e-04 | grad 4.31 | tok/s 11636
step   1060 | loss 1.4693 | lr 3.00e-04 | grad 2.30 | tok/s 11093
step   1070 | loss 1.3089 | lr 3.00e-04 | grad 2.28 | tok/s 10815
step   1080 | loss 1.0395 | lr 3.00e-04 | grad 2.12 | tok/s 11678
step   1090 | loss 1.4508 | lr 3.00e-04 | grad 1.55 | tok/s 11435
step   1100 | loss 1.3199 | lr 3.00e-04 | grad 2.42 | tok/s 11738
step   1110 | loss 1.2839 | lr 3.00e-04 | grad 2.23 | tok/s 11704
step   1120 | loss 1.2037 | lr 3.00e-04 | grad 2.50 | tok/s 11724
step   1130 | loss 1.2504 | lr 3.00e-04 | grad 2.00 | tok/s 11696
step   1140 | loss 1.1942 | lr 3.00e-04 | grad 2.05 | tok/s 11702
step   1150 | loss 1.1768 | lr 3.00e-04 | grad 2.25 | tok/s 11703
step   1160 | loss 1.2731 | lr 3.00e-04 | grad 2.47 | tok/s 11708
step   1170 | loss 1.2056 | lr 3.00e-04 | grad 1.47 | tok/s 11679
step   1180 | loss 1.1449 | lr 3.00e-04 | grad 2.47 | tok/s 11645
step   1190 | loss 1.1967 | lr 3.00e-04 | grad 2.30 | tok/s 11653
step   1200 | loss 1.2340 | lr 3.00e-04 | grad 2.42 | tok/s 11617
step   1210 | loss 1.1837 | lr 3.00e-04 | grad 1.88 | tok/s 11617
step   1220 | loss 1.2066 | lr 3.00e-04 | grad 2.14 | tok/s 11616
step   1230 | loss 1.5293 | lr 3.00e-04 | grad 3.77 | tok/s 11251
step   1240 | loss 1.5257 | lr 3.00e-04 | grad 4.03 | tok/s 10923
step   1250 | loss 1.3055 | lr 3.00e-04 | grad 1.99 | tok/s 11284
step   1260 | loss 1.6319 | lr 3.00e-04 | grad 3.19 | tok/s 10722
step   1270 | loss 1.4357 | lr 3.00e-04 | grad 2.44 | tok/s 11391
step   1280 | loss 1.4223 | lr 3.00e-04 | grad 1.91 | tok/s 11452
step   1290 | loss 1.4386 | lr 3.00e-04 | grad 2.81 | tok/s 11072
step   1300 | loss 1.4350 | lr 3.00e-04 | grad 3.47 | tok/s 11375
step   1310 | loss 1.6104 | lr 3.00e-04 | grad 1.62 | tok/s 11607
step   1320 | loss 1.2596 | lr 3.00e-04 | grad 2.56 | tok/s 11105
step   1330 | loss 1.6460 | lr 3.00e-04 | grad 3.08 | tok/s 10752
step   1340 | loss 1.5549 | lr 3.00e-04 | grad 2.66 | tok/s 11077
step   1350 | loss 1.3464 | lr 3.00e-04 | grad 2.31 | tok/s 11011
step   1360 | loss 1.4937 | lr 3.00e-04 | grad 2.61 | tok/s 11305
step   1370 | loss 1.4371 | lr 3.00e-04 | grad 2.53 | tok/s 10668
step   1380 | loss 1.3529 | lr 3.00e-04 | grad 3.39 | tok/s 10984
step   1390 | loss 1.3284 | lr 3.00e-04 | grad 3.50 | tok/s 11131
step   1400 | loss 1.4164 | lr 3.00e-04 | grad 2.34 | tok/s 10883
step   1410 | loss 1.4984 | lr 3.00e-04 | grad 2.92 | tok/s 11399
step   1420 | loss 1.2225 | lr 3.00e-04 | grad 4.50 | tok/s 11094
step   1430 | loss 1.0826 | lr 3.00e-04 | grad 2.41 | tok/s 11636
step   1440 | loss 1.3483 | lr 3.00e-04 | grad 2.52 | tok/s 11327
step   1450 | loss 1.4845 | lr 3.00e-04 | grad 2.88 | tok/s 10975
step   1460 | loss 1.4954 | lr 3.00e-04 | grad 5.03 | tok/s 11431
step   1470 | loss 1.7022 | lr 3.00e-04 | grad 4.59 | tok/s 11665
step   1480 | loss 1.4442 | lr 3.00e-04 | grad 2.19 | tok/s 11567
step   1490 | loss 1.2829 | lr 3.00e-04 | grad 5.81 | tok/s 11477
step   1500 | loss 1.4594 | lr 3.00e-04 | grad 2.03 | tok/s 11594
step   1510 | loss 1.3991 | lr 3.00e-04 | grad 2.12 | tok/s 11281
step   1520 | loss 1.4379 | lr 3.00e-04 | grad 4.28 | tok/s 11131
step   1530 | loss 1.4159 | lr 3.00e-04 | grad 2.80 | tok/s 11228
step   1540 | loss 1.2747 | lr 3.00e-04 | grad 3.11 | tok/s 11455
step   1550 | loss 1.4637 | lr 3.00e-04 | grad 2.52 | tok/s 11053
step   1560 | loss 1.3459 | lr 3.00e-04 | grad 2.28 | tok/s 11354
step   1570 | loss 1.6344 | lr 3.00e-04 | grad 3.59 | tok/s 11563
step   1580 | loss 1.2541 | lr 3.00e-04 | grad 1.80 | tok/s 10999
step   1590 | loss 0.7879 | lr 3.00e-04 | grad 2.77 | tok/s 11743
step   1600 | loss 1.2467 | lr 3.00e-04 | grad 2.72 | tok/s 10427
step   1610 | loss 1.4744 | lr 3.00e-04 | grad 5.06 | tok/s 11143

Training complete! Final step: 1614
