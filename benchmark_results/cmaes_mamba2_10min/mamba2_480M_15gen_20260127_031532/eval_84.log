Using device: cuda
Output directory: benchmark_results/cmaes_mamba2_10min/mamba2_480M_15gen_20260127_031532/eval_84/levelmamba2_100m_20260127_045915
Model: Level mamba2, 967,823,272 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 9.0199 | lr 3.00e-04 | grad 46.50 | tok/s 2388
step     20 | loss 3.6164 | lr 3.00e-04 | grad 7.94 | tok/s 11090
step     30 | loss 2.5664 | lr 3.00e-04 | grad 8.69 | tok/s 10590
step     40 | loss 3.0829 | lr 3.00e-04 | grad 8.75 | tok/s 10566
step     50 | loss 2.2603 | lr 3.00e-04 | grad 10.69 | tok/s 11129
step     60 | loss 1.9292 | lr 3.00e-04 | grad 3.02 | tok/s 11134
step     70 | loss 4.9669 | lr 3.00e-04 | grad 15.06 | tok/s 11081
step     80 | loss 4.2280 | lr 3.00e-04 | grad 19.50 | tok/s 11384
step     90 | loss 3.2063 | lr 3.00e-04 | grad 14.31 | tok/s 11382
step    100 | loss 2.9705 | lr 3.00e-04 | grad 18.75 | tok/s 11337
step    110 | loss 2.6131 | lr 3.00e-04 | grad 6.31 | tok/s 11318
step    120 | loss 2.4273 | lr 3.00e-04 | grad 3.91 | tok/s 11313
step    130 | loss 2.3329 | lr 3.00e-04 | grad 10.25 | tok/s 11317
step    140 | loss 2.1929 | lr 3.00e-04 | grad 5.16 | tok/s 11299
step    150 | loss 2.0604 | lr 3.00e-04 | grad 5.09 | tok/s 11292
step    160 | loss 2.1642 | lr 3.00e-04 | grad 11.56 | tok/s 11285
step    170 | loss 1.9720 | lr 3.00e-04 | grad 4.56 | tok/s 11284
step    180 | loss 2.0928 | lr 3.00e-04 | grad 7.88 | tok/s 11278
step    190 | loss 1.8602 | lr 3.00e-04 | grad 5.44 | tok/s 11297
step    200 | loss 1.9428 | lr 3.00e-04 | grad 3.53 | tok/s 11275
step    210 | loss 2.2783 | lr 3.00e-04 | grad 6.09 | tok/s 11151
step    220 | loss 2.5577 | lr 3.00e-04 | grad 4.81 | tok/s 11155
step    230 | loss 2.3320 | lr 3.00e-04 | grad 4.22 | tok/s 10376
step    240 | loss 2.2563 | lr 3.00e-04 | grad 3.95 | tok/s 10709
step    250 | loss 1.7524 | lr 3.00e-04 | grad 3.64 | tok/s 11284
step    260 | loss 2.1712 | lr 3.00e-04 | grad 4.81 | tok/s 10782
step    270 | loss 2.3398 | lr 3.00e-04 | grad 3.64 | tok/s 10973
step    280 | loss 1.7955 | lr 3.00e-04 | grad 3.91 | tok/s 11101
step    290 | loss 0.7685 | lr 3.00e-04 | grad 2.58 | tok/s 11309
step    300 | loss 2.5465 | lr 3.00e-04 | grad 8.62 | tok/s 11135
step    310 | loss 2.0954 | lr 3.00e-04 | grad 17.75 | tok/s 11025
step    320 | loss 2.1320 | lr 3.00e-04 | grad 3.86 | tok/s 10388
step    330 | loss 2.3174 | lr 3.00e-04 | grad 4.25 | tok/s 10736
step    340 | loss 2.0178 | lr 3.00e-04 | grad 3.73 | tok/s 10912
step    350 | loss 1.4711 | lr 3.00e-04 | grad 3.19 | tok/s 11235
step    360 | loss 1.9627 | lr 3.00e-04 | grad 2.38 | tok/s 10107
step    370 | loss 1.8567 | lr 3.00e-04 | grad 4.03 | tok/s 10797
step    380 | loss 1.6322 | lr 3.00e-04 | grad 3.84 | tok/s 11280
step    390 | loss 1.5538 | lr 3.00e-04 | grad 4.09 | tok/s 11174
step    400 | loss 1.4438 | lr 3.00e-04 | grad 2.39 | tok/s 11277
step    410 | loss 1.7326 | lr 3.00e-04 | grad 3.81 | tok/s 10149
step    420 | loss 2.2221 | lr 3.00e-04 | grad 4.09 | tok/s 11075
step    430 | loss 2.2009 | lr 3.00e-04 | grad 4.66 | tok/s 10586
step    440 | loss 1.9971 | lr 3.00e-04 | grad 3.30 | tok/s 10804
step    450 | loss 1.8734 | lr 3.00e-04 | grad 6.12 | tok/s 10644
step    460 | loss 1.8500 | lr 3.00e-04 | grad 4.06 | tok/s 10966
step    470 | loss 2.2281 | lr 3.00e-04 | grad 7.34 | tok/s 10977
step    480 | loss 1.9381 | lr 3.00e-04 | grad 2.11 | tok/s 10392
step    490 | loss 1.7272 | lr 3.00e-04 | grad 4.47 | tok/s 11072
step    500 | loss 1.7768 | lr 3.00e-04 | grad 5.44 | tok/s 11217
step    510 | loss 1.8003 | lr 3.00e-04 | grad 2.92 | tok/s 11215
step    520 | loss 1.9491 | lr 3.00e-04 | grad 6.44 | tok/s 10783
step    530 | loss 1.8105 | lr 3.00e-04 | grad 2.77 | tok/s 10793
step    540 | loss 1.5799 | lr 3.00e-04 | grad 5.59 | tok/s 10568
step    550 | loss 1.7806 | lr 3.00e-04 | grad 3.98 | tok/s 10260
step    560 | loss 1.7202 | lr 3.00e-04 | grad 6.53 | tok/s 10636
step    570 | loss 1.5664 | lr 3.00e-04 | grad 3.22 | tok/s 10443
step    580 | loss 1.8516 | lr 3.00e-04 | grad 6.34 | tok/s 10849
step    590 | loss 1.8607 | lr 3.00e-04 | grad 3.11 | tok/s 10363
step    600 | loss 1.6676 | lr 3.00e-04 | grad 3.98 | tok/s 10978
step    610 | loss 1.5920 | lr 3.00e-04 | grad 3.05 | tok/s 10466
step    620 | loss 1.6945 | lr 3.00e-04 | grad 2.91 | tok/s 10391
step    630 | loss 1.8263 | lr 3.00e-04 | grad 4.03 | tok/s 10774
step    640 | loss 1.6942 | lr 3.00e-04 | grad 2.42 | tok/s 10836
step    650 | loss 1.7826 | lr 3.00e-04 | grad 3.92 | tok/s 10943
step    660 | loss 1.8696 | lr 3.00e-04 | grad 4.84 | tok/s 10850
step    670 | loss 1.7716 | lr 3.00e-04 | grad 2.84 | tok/s 10712
step    680 | loss 1.8770 | lr 3.00e-04 | grad 2.83 | tok/s 11034
step    690 | loss 1.4991 | lr 3.00e-04 | grad 4.22 | tok/s 11282
step    700 | loss 1.6130 | lr 3.00e-04 | grad 2.55 | tok/s 10678
step    710 | loss 1.4726 | lr 3.00e-04 | grad 3.73 | tok/s 10273
step    720 | loss 1.3796 | lr 3.00e-04 | grad 2.77 | tok/s 11296
step    730 | loss 1.6017 | lr 3.00e-04 | grad 2.95 | tok/s 11115
step    740 | loss 1.3148 | lr 3.00e-04 | grad 3.59 | tok/s 11308
step    750 | loss 1.2196 | lr 3.00e-04 | grad 2.48 | tok/s 11313
step    760 | loss 1.1488 | lr 3.00e-04 | grad 4.69 | tok/s 11310
step    770 | loss 1.0818 | lr 3.00e-04 | grad 1.91 | tok/s 11316
step    780 | loss 1.1241 | lr 3.00e-04 | grad 2.89 | tok/s 11059
step    790 | loss 1.7995 | lr 3.00e-04 | grad 3.44 | tok/s 10831
step    800 | loss 1.8368 | lr 3.00e-04 | grad 3.09 | tok/s 10868
step    810 | loss 1.7110 | lr 3.00e-04 | grad 2.89 | tok/s 10457
step    820 | loss 1.6371 | lr 3.00e-04 | grad 2.97 | tok/s 11175
step    830 | loss 1.4563 | lr 3.00e-04 | grad 3.34 | tok/s 11284
step    840 | loss 1.5868 | lr 3.00e-04 | grad 3.22 | tok/s 11235
step    850 | loss 1.4506 | lr 3.00e-04 | grad 2.03 | tok/s 11202
step    860 | loss 1.6069 | lr 3.00e-04 | grad 2.66 | tok/s 10648
step    870 | loss 1.7345 | lr 3.00e-04 | grad 9.75 | tok/s 10891
step    880 | loss 1.6847 | lr 3.00e-04 | grad 2.86 | tok/s 10802
step    890 | loss 1.5797 | lr 3.00e-04 | grad 3.53 | tok/s 10950
step    900 | loss 1.4201 | lr 3.00e-04 | grad 3.61 | tok/s 10698
step    910 | loss 1.5879 | lr 3.00e-04 | grad 3.58 | tok/s 11122
step    920 | loss 1.6045 | lr 3.00e-04 | grad 2.61 | tok/s 10612
step    930 | loss 1.4698 | lr 3.00e-04 | grad 2.77 | tok/s 11196
step    940 | loss 1.5736 | lr 3.00e-04 | grad 3.19 | tok/s 11238
step    950 | loss 1.4194 | lr 3.00e-04 | grad 3.80 | tok/s 11249
step    960 | loss 1.6792 | lr 3.00e-04 | grad 5.12 | tok/s 10586
step    970 | loss 1.6951 | lr 3.00e-04 | grad 3.08 | tok/s 11020
step    980 | loss 1.4775 | lr 3.00e-04 | grad 3.42 | tok/s 10915
step    990 | loss 1.7794 | lr 3.00e-04 | grad 5.06 | tok/s 10610
step   1000 | loss 1.7663 | lr 3.00e-04 | grad 4.66 | tok/s 10950
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7663.pt
step   1010 | loss 1.5577 | lr 3.00e-04 | grad 6.66 | tok/s 2982
step   1020 | loss 1.4157 | lr 3.00e-04 | grad 3.14 | tok/s 11386
step   1030 | loss 1.4861 | lr 3.00e-04 | grad 2.33 | tok/s 10577
step   1040 | loss 1.7336 | lr 3.00e-04 | grad 5.47 | tok/s 11259
step   1050 | loss 1.7868 | lr 3.00e-04 | grad 4.62 | tok/s 11300
step   1060 | loss 1.5889 | lr 3.00e-04 | grad 3.23 | tok/s 10776
step   1070 | loss 1.3939 | lr 3.00e-04 | grad 2.05 | tok/s 10486
step   1080 | loss 1.1430 | lr 3.00e-04 | grad 2.55 | tok/s 11245
step   1090 | loss 1.5359 | lr 3.00e-04 | grad 2.14 | tok/s 11115
step   1100 | loss 1.4051 | lr 3.00e-04 | grad 3.02 | tok/s 11415
step   1110 | loss 1.3703 | lr 3.00e-04 | grad 2.94 | tok/s 11392
step   1120 | loss 1.2783 | lr 3.00e-04 | grad 2.67 | tok/s 11396
step   1130 | loss 1.3313 | lr 3.00e-04 | grad 2.53 | tok/s 11383
step   1140 | loss 1.2884 | lr 3.00e-04 | grad 2.77 | tok/s 11368
step   1150 | loss 1.2572 | lr 3.00e-04 | grad 2.42 | tok/s 11354
step   1160 | loss 1.3568 | lr 3.00e-04 | grad 3.00 | tok/s 11343
step   1170 | loss 1.3005 | lr 3.00e-04 | grad 1.85 | tok/s 11351
step   1180 | loss 1.2122 | lr 3.00e-04 | grad 3.02 | tok/s 11332
step   1190 | loss 1.2809 | lr 3.00e-04 | grad 2.72 | tok/s 11336
step   1200 | loss 1.3112 | lr 3.00e-04 | grad 2.16 | tok/s 11329
step   1210 | loss 1.2594 | lr 3.00e-04 | grad 1.74 | tok/s 11328
step   1220 | loss 1.2855 | lr 3.00e-04 | grad 2.34 | tok/s 11326
step   1230 | loss 1.6306 | lr 3.00e-04 | grad 4.66 | tok/s 10919
step   1240 | loss 1.6285 | lr 3.00e-04 | grad 5.50 | tok/s 10594
step   1250 | loss 1.3914 | lr 3.00e-04 | grad 2.31 | tok/s 10917
step   1260 | loss 1.7195 | lr 3.00e-04 | grad 3.33 | tok/s 10403
step   1270 | loss 1.5151 | lr 3.00e-04 | grad 2.75 | tok/s 11048
step   1280 | loss 1.5374 | lr 3.00e-04 | grad 2.08 | tok/s 11102
step   1290 | loss 1.5029 | lr 3.00e-04 | grad 3.12 | tok/s 10734
step   1300 | loss 1.5175 | lr 3.00e-04 | grad 3.70 | tok/s 11073
step   1310 | loss 1.7180 | lr 3.00e-04 | grad 2.41 | tok/s 11299
step   1320 | loss 1.3600 | lr 3.00e-04 | grad 2.66 | tok/s 10781
step   1330 | loss 1.7433 | lr 3.00e-04 | grad 3.25 | tok/s 10400
step   1340 | loss 1.6486 | lr 3.00e-04 | grad 3.09 | tok/s 10732
step   1350 | loss 1.4205 | lr 3.00e-04 | grad 3.02 | tok/s 10681
step   1360 | loss 1.5984 | lr 3.00e-04 | grad 2.95 | tok/s 10987
step   1370 | loss 1.5244 | lr 3.00e-04 | grad 3.03 | tok/s 10340
step   1380 | loss 1.4214 | lr 3.00e-04 | grad 3.88 | tok/s 10629
step   1390 | loss 1.4290 | lr 3.00e-04 | grad 4.31 | tok/s 10806
step   1400 | loss 1.5348 | lr 3.00e-04 | grad 2.97 | tok/s 10554
step   1410 | loss 1.5692 | lr 3.00e-04 | grad 2.55 | tok/s 11071
step   1420 | loss 1.2877 | lr 3.00e-04 | grad 2.67 | tok/s 10759
step   1430 | loss 1.1276 | lr 3.00e-04 | grad 2.78 | tok/s 11302
step   1440 | loss 1.4200 | lr 3.00e-04 | grad 3.09 | tok/s 10995
step   1450 | loss 1.5691 | lr 3.00e-04 | grad 2.30 | tok/s 10649
step   1460 | loss 1.5639 | lr 3.00e-04 | grad 5.44 | tok/s 11101
step   1470 | loss 1.8311 | lr 3.00e-04 | grad 3.69 | tok/s 11320
step   1480 | loss 1.5363 | lr 3.00e-04 | grad 2.28 | tok/s 11253
step   1490 | loss 1.3475 | lr 3.00e-04 | grad 6.78 | tok/s 11167
step   1500 | loss 1.5382 | lr 3.00e-04 | grad 3.06 | tok/s 11292
step   1510 | loss 1.4688 | lr 3.00e-04 | grad 2.70 | tok/s 10949
step   1520 | loss 1.5121 | lr 3.00e-04 | grad 19.50 | tok/s 10824
step   1530 | loss 1.4991 | lr 3.00e-04 | grad 2.11 | tok/s 10902
step   1540 | loss 1.3293 | lr 3.00e-04 | grad 3.50 | tok/s 11143
step   1550 | loss 1.5525 | lr 3.00e-04 | grad 3.03 | tok/s 10719
step   1560 | loss 1.4507 | lr 3.00e-04 | grad 2.66 | tok/s 11045

Training complete! Final step: 1569
