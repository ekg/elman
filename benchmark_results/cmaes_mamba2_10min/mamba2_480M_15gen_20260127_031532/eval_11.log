Using device: cuda
Output directory: benchmark_results/cmaes_mamba2_10min/mamba2_480M_15gen_20260127_031532/eval_11/levelmamba2_100m_20260127_032552
Model: Level mamba2, 450,636,560 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 6.3243 | lr 3.00e-04 | grad 16.75 | tok/s 4658
step     20 | loss 3.1191 | lr 3.00e-04 | grad 8.50 | tok/s 23459
step     30 | loss 4.0409 | lr 3.00e-04 | grad 18.50 | tok/s 24069
step     40 | loss 3.3550 | lr 3.00e-04 | grad 7.66 | tok/s 24251
step     50 | loss 2.5535 | lr 3.00e-04 | grad 3.58 | tok/s 24081
step     60 | loss 2.2590 | lr 3.00e-04 | grad 7.31 | tok/s 23920
step     70 | loss 2.0413 | lr 3.00e-04 | grad 2.73 | tok/s 23822
step     80 | loss 1.9458 | lr 3.00e-04 | grad 3.38 | tok/s 23709
step     90 | loss 1.8382 | lr 3.00e-04 | grad 2.23 | tok/s 23601
step    100 | loss 2.0027 | lr 3.00e-04 | grad 5.97 | tok/s 23369
step    110 | loss 2.7449 | lr 3.00e-04 | grad 4.88 | tok/s 22261
step    120 | loss 1.9356 | lr 3.00e-04 | grad 3.86 | tok/s 22535
step    130 | loss 2.3353 | lr 3.00e-04 | grad 8.38 | tok/s 22313
step    140 | loss 1.3111 | lr 3.00e-04 | grad 3.09 | tok/s 22926
step    150 | loss 2.3878 | lr 3.00e-04 | grad 3.62 | tok/s 22434
step    160 | loss 2.1702 | lr 3.00e-04 | grad 2.72 | tok/s 21717
step    170 | loss 1.7944 | lr 3.00e-04 | grad 7.06 | tok/s 22249
step    180 | loss 1.8398 | lr 3.00e-04 | grad 2.88 | tok/s 21346
step    190 | loss 1.5643 | lr 3.00e-04 | grad 3.92 | tok/s 22654
step    200 | loss 1.6907 | lr 3.00e-04 | grad 3.17 | tok/s 21430
step    210 | loss 2.0729 | lr 3.00e-04 | grad 5.03 | tok/s 21763
step    220 | loss 1.7383 | lr 3.00e-04 | grad 2.30 | tok/s 21414
step    230 | loss 2.0774 | lr 3.00e-04 | grad 2.91 | tok/s 21744
step    240 | loss 1.7355 | lr 3.00e-04 | grad 2.05 | tok/s 21627
step    250 | loss 1.7416 | lr 3.00e-04 | grad 2.77 | tok/s 22078
step    260 | loss 1.7619 | lr 3.00e-04 | grad 2.88 | tok/s 21563
step    270 | loss 1.6402 | lr 3.00e-04 | grad 2.16 | tok/s 20314
step    280 | loss 1.5623 | lr 3.00e-04 | grad 2.33 | tok/s 21057
step    290 | loss 1.8578 | lr 3.00e-04 | grad 1.91 | tok/s 20996
step    300 | loss 1.5798 | lr 3.00e-04 | grad 1.53 | tok/s 20819
step    310 | loss 1.7726 | lr 3.00e-04 | grad 4.62 | tok/s 20900
step    320 | loss 1.6520 | lr 3.00e-04 | grad 3.00 | tok/s 21384
step    330 | loss 1.8842 | lr 3.00e-04 | grad 5.34 | tok/s 21084
step    340 | loss 1.6634 | lr 3.00e-04 | grad 4.56 | tok/s 21947
step    350 | loss 1.5109 | lr 3.00e-04 | grad 2.17 | tok/s 20449
step    360 | loss 1.4482 | lr 3.00e-04 | grad 1.73 | tok/s 21856
step    370 | loss 1.2288 | lr 3.00e-04 | grad 1.91 | tok/s 22031
step    380 | loss 1.0893 | lr 3.00e-04 | grad 1.74 | tok/s 22011
step    390 | loss 1.6250 | lr 3.00e-04 | grad 2.91 | tok/s 21023
step    400 | loss 1.6413 | lr 3.00e-04 | grad 7.00 | tok/s 20962
step    410 | loss 1.5825 | lr 3.00e-04 | grad 2.14 | tok/s 21791
step    420 | loss 1.5402 | lr 3.00e-04 | grad 1.76 | tok/s 21662
step    430 | loss 1.5953 | lr 3.00e-04 | grad 2.97 | tok/s 21001
step    440 | loss 1.5806 | lr 3.00e-04 | grad 1.87 | tok/s 20956
step    450 | loss 1.5321 | lr 3.00e-04 | grad 2.20 | tok/s 21323
step    460 | loss 1.4401 | lr 3.00e-04 | grad 1.59 | tok/s 21066
step    470 | loss 1.5909 | lr 3.00e-04 | grad 1.88 | tok/s 21742
step    480 | loss 1.6319 | lr 3.00e-04 | grad 1.94 | tok/s 20664
step    490 | loss 1.7150 | lr 3.00e-04 | grad 3.00 | tok/s 21149
step    500 | loss 1.6036 | lr 3.00e-04 | grad 1.59 | tok/s 20147
step    510 | loss 1.4750 | lr 3.00e-04 | grad 3.34 | tok/s 21126
step    520 | loss 1.6210 | lr 3.00e-04 | grad 2.84 | tok/s 20656
step    530 | loss 1.5737 | lr 3.00e-04 | grad 1.60 | tok/s 20735
step    540 | loss 1.2426 | lr 3.00e-04 | grad 1.80 | tok/s 20763
step    550 | loss 1.4517 | lr 3.00e-04 | grad 1.88 | tok/s 21764
step    560 | loss 1.3093 | lr 3.00e-04 | grad 1.79 | tok/s 21744
step    570 | loss 1.2768 | lr 3.00e-04 | grad 2.11 | tok/s 21736
step    580 | loss 1.3079 | lr 3.00e-04 | grad 1.77 | tok/s 21734
step    590 | loss 1.2270 | lr 3.00e-04 | grad 1.59 | tok/s 21721
step    600 | loss 1.2782 | lr 3.00e-04 | grad 2.06 | tok/s 21718
step    610 | loss 1.2346 | lr 3.00e-04 | grad 1.09 | tok/s 21690
step    620 | loss 1.6154 | lr 3.00e-04 | grad 3.56 | tok/s 20452
step    630 | loss 1.6087 | lr 3.00e-04 | grad 2.78 | tok/s 20596
step    640 | loss 1.4853 | lr 3.00e-04 | grad 1.78 | tok/s 20988
step    650 | loss 1.5365 | lr 3.00e-04 | grad 1.95 | tok/s 21123
step    660 | loss 1.5092 | lr 3.00e-04 | grad 2.12 | tok/s 20870
step    670 | loss 1.6170 | lr 3.00e-04 | grad 1.51 | tok/s 20293
step    680 | loss 1.4971 | lr 3.00e-04 | grad 1.80 | tok/s 20340
step    690 | loss 1.4569 | lr 3.00e-04 | grad 1.92 | tok/s 20527
step    700 | loss 1.5219 | lr 3.00e-04 | grad 3.03 | tok/s 20375
step    710 | loss 1.2955 | lr 3.00e-04 | grad 1.91 | tok/s 21074
step    720 | loss 1.3583 | lr 3.00e-04 | grad 2.09 | tok/s 21013
step    730 | loss 1.6548 | lr 3.00e-04 | grad 6.09 | tok/s 21106
step    740 | loss 1.5591 | lr 3.00e-04 | grad 1.77 | tok/s 21615
step    750 | loss 1.4270 | lr 3.00e-04 | grad 1.54 | tok/s 21160
step    760 | loss 1.5130 | lr 3.00e-04 | grad 1.64 | tok/s 20791
step    770 | loss 1.4499 | lr 3.00e-04 | grad 2.39 | tok/s 20847
step    780 | loss 1.5312 | lr 3.00e-04 | grad 3.91 | tok/s 21369
step    790 | loss 1.4150 | lr 3.00e-04 | grad 1.55 | tok/s 20981
step    800 | loss 1.1855 | lr 3.00e-04 | grad 3.44 | tok/s 20330
step    810 | loss 1.3915 | lr 3.00e-04 | grad 2.41 | tok/s 21021
step    820 | loss 1.4548 | lr 3.00e-04 | grad 1.63 | tok/s 20109
step    830 | loss 1.5350 | lr 3.00e-04 | grad 2.22 | tok/s 20500
step    840 | loss 1.4589 | lr 3.00e-04 | grad 2.41 | tok/s 20691
step    850 | loss 1.5021 | lr 3.00e-04 | grad 2.67 | tok/s 20872
step    860 | loss 1.3563 | lr 3.00e-04 | grad 1.90 | tok/s 21367
step    870 | loss 1.5161 | lr 3.00e-04 | grad 2.39 | tok/s 20582
step    880 | loss 1.4570 | lr 3.00e-04 | grad 1.81 | tok/s 20766
step    890 | loss 1.4783 | lr 3.00e-04 | grad 2.45 | tok/s 20711
step    900 | loss 1.4089 | lr 3.00e-04 | grad 1.92 | tok/s 20223
step    910 | loss 1.4467 | lr 3.00e-04 | grad 2.05 | tok/s 20673
step    920 | loss 1.3362 | lr 3.00e-04 | grad 1.68 | tok/s 20793
step    930 | loss 1.3221 | lr 3.00e-04 | grad 2.34 | tok/s 20414
step    940 | loss 1.4181 | lr 3.00e-04 | grad 1.50 | tok/s 19909
step    950 | loss 1.4187 | lr 3.00e-04 | grad 1.79 | tok/s 20611
step    960 | loss 1.4088 | lr 3.00e-04 | grad 1.62 | tok/s 20607
step    970 | loss 1.8111 | lr 3.00e-04 | grad 3.12 | tok/s 21436
step    980 | loss 1.5445 | lr 3.00e-04 | grad 1.63 | tok/s 20592
step    990 | loss 1.4977 | lr 3.00e-04 | grad 1.55 | tok/s 20823
step   1000 | loss 1.1722 | lr 3.00e-04 | grad 1.77 | tok/s 20974
  >>> saved checkpoint: checkpoint_step_001000_loss_1.1722.pt
step   1010 | loss 1.2269 | lr 3.00e-04 | grad 1.77 | tok/s 11513
step   1020 | loss 1.4264 | lr 3.00e-04 | grad 1.98 | tok/s 20793
step   1030 | loss 2.0024 | lr 3.00e-04 | grad 4.69 | tok/s 21278
step   1040 | loss 1.4950 | lr 3.00e-04 | grad 1.50 | tok/s 21415
step   1050 | loss 1.1908 | lr 3.00e-04 | grad 1.50 | tok/s 21101
step   1060 | loss 1.3171 | lr 3.00e-04 | grad 1.98 | tok/s 21048
step   1070 | loss 1.2350 | lr 3.00e-04 | grad 1.65 | tok/s 21742
step   1080 | loss 1.2170 | lr 3.00e-04 | grad 1.70 | tok/s 21725
step   1090 | loss 1.1897 | lr 3.00e-04 | grad 1.63 | tok/s 21711
step   1100 | loss 1.1363 | lr 3.00e-04 | grad 1.48 | tok/s 21715
step   1110 | loss 1.3459 | lr 3.00e-04 | grad 1.80 | tok/s 21117
step   1120 | loss 1.5640 | lr 3.00e-04 | grad 1.57 | tok/s 21310
step   1130 | loss 1.7146 | lr 3.00e-04 | grad 1.64 | tok/s 21551
step   1140 | loss 1.6118 | lr 3.00e-04 | grad 3.88 | tok/s 21091
step   1150 | loss 1.6010 | lr 3.00e-04 | grad 4.19 | tok/s 20406
step   1160 | loss 1.4880 | lr 3.00e-04 | grad 2.03 | tok/s 20365
step   1170 | loss 1.3219 | lr 3.00e-04 | grad 1.50 | tok/s 21401
step   1180 | loss 1.5310 | lr 3.00e-04 | grad 2.66 | tok/s 21419
step   1190 | loss 1.1317 | lr 3.00e-04 | grad 1.48 | tok/s 21616
step   1200 | loss 1.2834 | lr 3.00e-04 | grad 1.61 | tok/s 20358
step   1210 | loss 1.3285 | lr 3.00e-04 | grad 1.80 | tok/s 21004
step   1220 | loss 1.3607 | lr 3.00e-04 | grad 1.54 | tok/s 21169
step   1230 | loss 1.2221 | lr 3.00e-04 | grad 2.12 | tok/s 21390
step   1240 | loss 1.4350 | lr 3.00e-04 | grad 2.70 | tok/s 20886
step   1250 | loss 1.3169 | lr 3.00e-04 | grad 1.61 | tok/s 21445
step   1260 | loss 1.3340 | lr 3.00e-04 | grad 2.41 | tok/s 20786
step   1270 | loss 1.3336 | lr 3.00e-04 | grad 2.11 | tok/s 20844
step   1280 | loss 1.3188 | lr 3.00e-04 | grad 2.03 | tok/s 20388
step   1290 | loss 1.5300 | lr 3.00e-04 | grad 7.44 | tok/s 20334
step   1300 | loss 1.4688 | lr 3.00e-04 | grad 2.14 | tok/s 21193
step   1310 | loss 1.4358 | lr 3.00e-04 | grad 3.28 | tok/s 21136
step   1320 | loss 1.3729 | lr 3.00e-04 | grad 1.70 | tok/s 21062
step   1330 | loss 1.4639 | lr 3.00e-04 | grad 1.66 | tok/s 20390
step   1340 | loss 1.3861 | lr 3.00e-04 | grad 1.60 | tok/s 21188
step   1350 | loss 1.4317 | lr 3.00e-04 | grad 1.64 | tok/s 19930
step   1360 | loss 1.4729 | lr 3.00e-04 | grad 3.61 | tok/s 21259
step   1370 | loss 1.4271 | lr 3.00e-04 | grad 2.00 | tok/s 20595
step   1380 | loss 1.2978 | lr 3.00e-04 | grad 2.31 | tok/s 21001
step   1390 | loss 1.4808 | lr 3.00e-04 | grad 1.63 | tok/s 20550
step   1400 | loss 1.3173 | lr 3.00e-04 | grad 1.67 | tok/s 20213
step   1410 | loss 1.1122 | lr 3.00e-04 | grad 1.83 | tok/s 21439
step   1420 | loss 1.6621 | lr 3.00e-04 | grad 1.34 | tok/s 20759
step   1430 | loss 1.4065 | lr 3.00e-04 | grad 2.19 | tok/s 20936
step   1440 | loss 1.3676 | lr 3.00e-04 | grad 1.54 | tok/s 21140
step   1450 | loss 1.4701 | lr 3.00e-04 | grad 2.44 | tok/s 20531
step   1460 | loss 1.3452 | lr 3.00e-04 | grad 1.75 | tok/s 20248
step   1470 | loss 1.3325 | lr 3.00e-04 | grad 2.73 | tok/s 20985
step   1480 | loss 1.6019 | lr 3.00e-04 | grad 6.25 | tok/s 20804
step   1490 | loss 1.5378 | lr 3.00e-04 | grad 1.62 | tok/s 21127
step   1500 | loss 1.2371 | lr 3.00e-04 | grad 1.70 | tok/s 20726
step   1510 | loss 1.4275 | lr 3.00e-04 | grad 2.16 | tok/s 20629
step   1520 | loss 1.3434 | lr 3.00e-04 | grad 1.70 | tok/s 21182
step   1530 | loss 1.4470 | lr 3.00e-04 | grad 1.64 | tok/s 21215
step   1540 | loss 1.4290 | lr 3.00e-04 | grad 4.53 | tok/s 20813
step   1550 | loss 1.1169 | lr 3.00e-04 | grad 1.28 | tok/s 21509

Training complete! Final step: 1551
