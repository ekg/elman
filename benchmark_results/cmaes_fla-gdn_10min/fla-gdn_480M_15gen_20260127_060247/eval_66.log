Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_66/levelfla-gdn_100m_20260127_072503
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 473,801,056 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 4.0636 | lr 3.00e-04 | grad 19.25 | tok/s 10936
step     20 | loss 2.7985 | lr 3.00e-04 | grad 5.19 | tok/s 24417
step     30 | loss 3.0790 | lr 3.00e-04 | grad 5.56 | tok/s 25745
step     40 | loss 4.2389 | lr 3.00e-04 | grad 25.38 | tok/s 26224
step     50 | loss 4.1654 | lr 3.00e-04 | grad 12.75 | tok/s 26496
step     60 | loss 3.3604 | lr 3.00e-04 | grad 12.25 | tok/s 26396
step     70 | loss 2.8047 | lr 3.00e-04 | grad 7.19 | tok/s 26330
step     80 | loss 2.5006 | lr 3.00e-04 | grad 6.00 | tok/s 26235
step     90 | loss 2.3728 | lr 3.00e-04 | grad 5.50 | tok/s 26158
step    100 | loss 2.1499 | lr 3.00e-04 | grad 5.06 | tok/s 26111
step    110 | loss 2.1739 | lr 3.00e-04 | grad 4.22 | tok/s 25904
step    120 | loss 2.7560 | lr 3.00e-04 | grad 3.22 | tok/s 24626
step    130 | loss 2.0306 | lr 3.00e-04 | grad 5.66 | tok/s 25191
step    140 | loss 2.2965 | lr 3.00e-04 | grad 9.00 | tok/s 25244
step    150 | loss 1.4795 | lr 3.00e-04 | grad 6.47 | tok/s 25893
step    160 | loss 2.2508 | lr 3.00e-04 | grad 2.67 | tok/s 24983
step    170 | loss 2.1546 | lr 3.00e-04 | grad 2.27 | tok/s 24594
step    180 | loss 1.7420 | lr 3.00e-04 | grad 3.47 | tok/s 25142
step    190 | loss 1.8006 | lr 3.00e-04 | grad 2.56 | tok/s 24688
step    200 | loss 1.5311 | lr 3.00e-04 | grad 1.98 | tok/s 25757
step    210 | loss 1.7408 | lr 3.00e-04 | grad 3.92 | tok/s 24498
step    220 | loss 2.1046 | lr 3.00e-04 | grad 3.69 | tok/s 24695
step    230 | loss 1.7949 | lr 3.00e-04 | grad 2.77 | tok/s 24673
step    240 | loss 2.1523 | lr 3.00e-04 | grad 6.12 | tok/s 24986
step    250 | loss 1.6414 | lr 3.00e-04 | grad 1.73 | tok/s 24822
step    260 | loss 1.7730 | lr 3.00e-04 | grad 3.20 | tok/s 25468
step    270 | loss 1.7082 | lr 3.00e-04 | grad 2.06 | tok/s 24906
step    280 | loss 1.6609 | lr 3.00e-04 | grad 1.95 | tok/s 23434
step    290 | loss 1.5489 | lr 3.00e-04 | grad 2.41 | tok/s 24189
step    300 | loss 1.8391 | lr 3.00e-04 | grad 2.61 | tok/s 24400
step    310 | loss 1.5670 | lr 3.00e-04 | grad 1.84 | tok/s 24295
step    320 | loss 1.7691 | lr 3.00e-04 | grad 4.56 | tok/s 24574
step    330 | loss 1.6095 | lr 3.00e-04 | grad 2.09 | tok/s 24823
step    340 | loss 1.9199 | lr 3.00e-04 | grad 2.33 | tok/s 24718
step    350 | loss 1.6221 | lr 3.00e-04 | grad 2.11 | tok/s 25391
step    360 | loss 1.4785 | lr 3.00e-04 | grad 2.11 | tok/s 24370
step    370 | loss 1.3937 | lr 3.00e-04 | grad 1.67 | tok/s 25658
step    380 | loss 1.1203 | lr 3.00e-04 | grad 1.64 | tok/s 25872
step    390 | loss 1.0227 | lr 3.00e-04 | grad 1.41 | tok/s 25834
step    400 | loss 1.6536 | lr 3.00e-04 | grad 1.63 | tok/s 24504
step    410 | loss 1.6441 | lr 3.00e-04 | grad 2.64 | tok/s 24738
step    420 | loss 1.5463 | lr 3.00e-04 | grad 2.83 | tok/s 25750
step    430 | loss 1.4766 | lr 3.00e-04 | grad 1.85 | tok/s 25325
step    440 | loss 1.5992 | lr 3.00e-04 | grad 2.42 | tok/s 24599
step    450 | loss 1.5266 | lr 3.00e-04 | grad 1.46 | tok/s 24867
step    460 | loss 1.5136 | lr 3.00e-04 | grad 1.87 | tok/s 25239
step    470 | loss 1.4777 | lr 3.00e-04 | grad 3.52 | tok/s 25035
step    480 | loss 1.5404 | lr 3.00e-04 | grad 2.84 | tok/s 25585
step    490 | loss 1.5877 | lr 3.00e-04 | grad 2.47 | tok/s 24600
step    500 | loss 1.7086 | lr 3.00e-04 | grad 1.53 | tok/s 24959
step    510 | loss 1.5986 | lr 3.00e-04 | grad 1.41 | tok/s 23884
step    520 | loss 1.4482 | lr 3.00e-04 | grad 3.47 | tok/s 24949
step    530 | loss 1.6185 | lr 3.00e-04 | grad 2.11 | tok/s 24580
step    540 | loss 1.5120 | lr 3.00e-04 | grad 1.67 | tok/s 24080
step    550 | loss 1.2744 | lr 3.00e-04 | grad 3.31 | tok/s 25212
step    560 | loss 1.3717 | lr 3.00e-04 | grad 1.91 | tok/s 25863
step    570 | loss 1.2741 | lr 3.00e-04 | grad 1.86 | tok/s 25830
step    580 | loss 1.2320 | lr 3.00e-04 | grad 1.35 | tok/s 25863
step    590 | loss 1.2679 | lr 3.00e-04 | grad 1.48 | tok/s 25882
step    600 | loss 1.1939 | lr 3.00e-04 | grad 1.47 | tok/s 25868
step    610 | loss 1.2380 | lr 3.00e-04 | grad 1.70 | tok/s 25884
step    620 | loss 1.2189 | lr 3.00e-04 | grad 1.77 | tok/s 25728
step    630 | loss 1.5431 | lr 3.00e-04 | grad 7.38 | tok/s 24398
step    640 | loss 1.6522 | lr 3.00e-04 | grad 2.09 | tok/s 24711
step    650 | loss 1.4667 | lr 3.00e-04 | grad 1.75 | tok/s 24715
step    660 | loss 1.5233 | lr 3.00e-04 | grad 2.06 | tok/s 25604
step    670 | loss 1.5289 | lr 3.00e-04 | grad 5.00 | tok/s 24799
step    680 | loss 1.5423 | lr 3.00e-04 | grad 2.23 | tok/s 24413
step    690 | loss 1.4819 | lr 3.00e-04 | grad 1.88 | tok/s 24244
step    700 | loss 1.3945 | lr 3.00e-04 | grad 1.39 | tok/s 24757
step    710 | loss 1.5358 | lr 3.00e-04 | grad 4.88 | tok/s 24406
step    720 | loss 1.2305 | lr 3.00e-04 | grad 1.61 | tok/s 25292
step    730 | loss 1.3668 | lr 3.00e-04 | grad 1.47 | tok/s 24915
step    740 | loss 1.6750 | lr 3.00e-04 | grad 4.56 | tok/s 25598
step    750 | loss 1.4586 | lr 3.00e-04 | grad 1.73 | tok/s 25845
step    760 | loss 1.4307 | lr 3.00e-04 | grad 3.91 | tok/s 25343
step    770 | loss 1.4914 | lr 3.00e-04 | grad 1.87 | tok/s 24941
step    780 | loss 1.4077 | lr 3.00e-04 | grad 1.77 | tok/s 25103
step    790 | loss 1.5560 | lr 3.00e-04 | grad 6.38 | tok/s 25593
step    800 | loss 1.2570 | lr 3.00e-04 | grad 1.84 | tok/s 25282
step    810 | loss 1.2445 | lr 3.00e-04 | grad 2.66 | tok/s 24435
step    820 | loss 1.3424 | lr 3.00e-04 | grad 1.68 | tok/s 24866
step    830 | loss 1.4122 | lr 3.00e-04 | grad 1.41 | tok/s 24532
step    840 | loss 1.5215 | lr 3.00e-04 | grad 1.70 | tok/s 24424
step    850 | loss 1.4290 | lr 3.00e-04 | grad 1.45 | tok/s 24953
step    860 | loss 1.4855 | lr 3.00e-04 | grad 2.66 | tok/s 25346
step    870 | loss 1.2881 | lr 3.00e-04 | grad 1.73 | tok/s 25525
step    880 | loss 1.5105 | lr 3.00e-04 | grad 1.66 | tok/s 25054
step    890 | loss 1.4192 | lr 3.00e-04 | grad 1.35 | tok/s 24929
step    900 | loss 1.4533 | lr 3.00e-04 | grad 1.53 | tok/s 24855
step    910 | loss 1.4228 | lr 3.00e-04 | grad 7.56 | tok/s 24584
step    920 | loss 1.3986 | lr 3.00e-04 | grad 1.72 | tok/s 24854
step    930 | loss 1.3162 | lr 3.00e-04 | grad 1.73 | tok/s 25149
step    940 | loss 1.2769 | lr 3.00e-04 | grad 1.59 | tok/s 24656
step    950 | loss 1.4209 | lr 3.00e-04 | grad 2.28 | tok/s 24265
step    960 | loss 1.3669 | lr 3.00e-04 | grad 1.49 | tok/s 24896
step    970 | loss 1.4060 | lr 3.00e-04 | grad 1.59 | tok/s 24893
step    980 | loss 1.7859 | lr 3.00e-04 | grad 3.61 | tok/s 25878
step    990 | loss 1.4848 | lr 3.00e-04 | grad 1.52 | tok/s 24842
step   1000 | loss 1.4980 | lr 3.00e-04 | grad 2.34 | tok/s 24907
  >>> saved checkpoint: checkpoint_step_001000_loss_1.4980.pt
step   1010 | loss 1.2853 | lr 3.00e-04 | grad 1.82 | tok/s 11772
step   1020 | loss 1.1364 | lr 3.00e-04 | grad 1.39 | tok/s 26423
step   1030 | loss 1.5182 | lr 3.00e-04 | grad 1.70 | tok/s 24868
step   1040 | loss 1.9839 | lr 3.00e-04 | grad 2.72 | tok/s 25694
step   1050 | loss 1.3651 | lr 3.00e-04 | grad 1.75 | tok/s 25366
step   1060 | loss 1.0432 | lr 3.00e-04 | grad 1.27 | tok/s 25964
step   1070 | loss 1.3851 | lr 3.00e-04 | grad 1.55 | tok/s 25311
step   1080 | loss 1.1977 | lr 3.00e-04 | grad 1.55 | tok/s 26195
step   1090 | loss 1.1754 | lr 3.00e-04 | grad 1.41 | tok/s 26208
step   1100 | loss 1.1339 | lr 3.00e-04 | grad 1.50 | tok/s 26171
step   1110 | loss 1.1204 | lr 3.00e-04 | grad 1.49 | tok/s 26149
step   1120 | loss 1.4127 | lr 3.00e-04 | grad 2.81 | tok/s 25446
step   1130 | loss 1.5243 | lr 3.00e-04 | grad 2.45 | tok/s 25703
step   1140 | loss 1.6276 | lr 3.00e-04 | grad 1.38 | tok/s 26033
step   1150 | loss 1.5859 | lr 3.00e-04 | grad 3.61 | tok/s 24776
step   1160 | loss 1.6784 | lr 3.00e-04 | grad 6.94 | tok/s 25131
step   1170 | loss 1.3557 | lr 3.00e-04 | grad 1.75 | tok/s 24790
step   1180 | loss 1.2714 | lr 3.00e-04 | grad 1.94 | tok/s 25655
step   1190 | loss 1.4485 | lr 3.00e-04 | grad 5.25 | tok/s 26136
step   1200 | loss 1.0644 | lr 3.00e-04 | grad 3.36 | tok/s 26145
step   1210 | loss 1.3727 | lr 3.00e-04 | grad 2.27 | tok/s 24395
step   1220 | loss 1.2760 | lr 3.00e-04 | grad 1.44 | tok/s 25342
step   1230 | loss 1.2397 | lr 3.00e-04 | grad 1.23 | tok/s 25929
step   1240 | loss 1.2553 | lr 3.00e-04 | grad 1.30 | tok/s 25533
step   1250 | loss 1.3897 | lr 3.00e-04 | grad 3.97 | tok/s 25582
step   1260 | loss 1.3086 | lr 3.00e-04 | grad 1.86 | tok/s 25839
step   1270 | loss 1.2931 | lr 3.00e-04 | grad 1.45 | tok/s 25308
step   1280 | loss 1.3402 | lr 3.00e-04 | grad 1.74 | tok/s 24925
step   1290 | loss 1.2454 | lr 3.00e-04 | grad 1.60 | tok/s 25000
step   1300 | loss 1.5360 | lr 3.00e-04 | grad 4.91 | tok/s 24569
step   1310 | loss 1.4061 | lr 3.00e-04 | grad 1.64 | tok/s 25477
step   1320 | loss 1.4242 | lr 3.00e-04 | grad 2.89 | tok/s 25658
step   1330 | loss 1.3246 | lr 3.00e-04 | grad 1.73 | tok/s 25345
step   1340 | loss 1.4616 | lr 3.00e-04 | grad 1.71 | tok/s 24870
step   1350 | loss 1.3683 | lr 3.00e-04 | grad 4.31 | tok/s 25234
step   1360 | loss 1.3147 | lr 3.00e-04 | grad 1.60 | tok/s 24573
step   1370 | loss 1.5656 | lr 3.00e-04 | grad 2.89 | tok/s 25686
step   1380 | loss 1.3328 | lr 3.00e-04 | grad 2.41 | tok/s 24540
step   1390 | loss 1.2395 | lr 3.00e-04 | grad 2.05 | tok/s 25794
step   1400 | loss 1.3621 | lr 3.00e-04 | grad 1.34 | tok/s 24972
step   1410 | loss 1.3638 | lr 3.00e-04 | grad 6.06 | tok/s 24383
step   1420 | loss 1.1800 | lr 3.00e-04 | grad 6.94 | tok/s 25894
step   1430 | loss 1.4615 | lr 3.00e-04 | grad 1.61 | tok/s 24931
step   1440 | loss 1.3435 | lr 3.00e-04 | grad 1.97 | tok/s 25702
step   1450 | loss 1.3405 | lr 3.00e-04 | grad 1.86 | tok/s 25554
step   1460 | loss 1.5015 | lr 3.00e-04 | grad 3.73 | tok/s 24960
step   1470 | loss 1.2510 | lr 3.00e-04 | grad 1.41 | tok/s 24112
step   1480 | loss 1.2937 | lr 3.00e-04 | grad 2.19 | tok/s 25814
step   1490 | loss 1.7920 | lr 3.00e-04 | grad 4.12 | tok/s 25159
step   1500 | loss 1.3406 | lr 3.00e-04 | grad 1.66 | tok/s 25371
step   1510 | loss 1.1532 | lr 3.00e-04 | grad 1.27 | tok/s 25208
step   1520 | loss 1.3993 | lr 3.00e-04 | grad 1.73 | tok/s 25305
step   1530 | loss 1.3215 | lr 3.00e-04 | grad 2.31 | tok/s 25529
step   1540 | loss 1.4401 | lr 3.00e-04 | grad 1.51 | tok/s 25736
step   1550 | loss 1.3883 | lr 3.00e-04 | grad 2.69 | tok/s 25259
step   1560 | loss 1.0499 | lr 3.00e-04 | grad 1.45 | tok/s 26174
step   1570 | loss 1.1790 | lr 3.00e-04 | grad 1.30 | tok/s 25493
step   1580 | loss 1.2990 | lr 3.00e-04 | grad 6.75 | tok/s 25363
step   1590 | loss 1.3039 | lr 3.00e-04 | grad 1.68 | tok/s 24925
step   1600 | loss 1.2043 | lr 3.00e-04 | grad 2.03 | tok/s 25544
step   1610 | loss 1.9218 | lr 3.00e-04 | grad 2.44 | tok/s 25804
step   1620 | loss 1.8256 | lr 3.00e-04 | grad 2.55 | tok/s 26143
step   1630 | loss 1.5698 | lr 3.00e-04 | grad 1.96 | tok/s 26162
step   1640 | loss 1.4064 | lr 3.00e-04 | grad 2.12 | tok/s 26156
step   1650 | loss 1.3285 | lr 3.00e-04 | grad 2.36 | tok/s 26116
step   1660 | loss 1.2761 | lr 3.00e-04 | grad 1.61 | tok/s 26107
step   1670 | loss 1.4266 | lr 3.00e-04 | grad 2.97 | tok/s 25281
step   1680 | loss 1.3408 | lr 3.00e-04 | grad 1.42 | tok/s 24622
step   1690 | loss 1.4059 | lr 3.00e-04 | grad 1.33 | tok/s 24808
step   1700 | loss 1.2060 | lr 3.00e-04 | grad 1.42 | tok/s 25726
step   1710 | loss 1.2038 | lr 3.00e-04 | grad 1.58 | tok/s 23544
step   1720 | loss 1.3811 | lr 3.00e-04 | grad 1.77 | tok/s 25097
step   1730 | loss 1.3315 | lr 3.00e-04 | grad 1.57 | tok/s 25411
step   1740 | loss 1.3406 | lr 3.00e-04 | grad 1.30 | tok/s 25907
step   1750 | loss 1.1674 | lr 3.00e-04 | grad 1.54 | tok/s 24887
step   1760 | loss 1.4023 | lr 3.00e-04 | grad 2.50 | tok/s 24987
step   1770 | loss 1.4706 | lr 3.00e-04 | grad 2.56 | tok/s 25556
step   1780 | loss 1.6664 | lr 3.00e-04 | grad 2.50 | tok/s 24069
step   1790 | loss 1.1635 | lr 3.00e-04 | grad 2.20 | tok/s 24865
step   1800 | loss 1.2787 | lr 3.00e-04 | grad 1.91 | tok/s 24829
step   1810 | loss 1.3003 | lr 3.00e-04 | grad 1.94 | tok/s 25361
step   1820 | loss 1.4410 | lr 3.00e-04 | grad 1.67 | tok/s 24743
step   1830 | loss 1.3177 | lr 3.00e-04 | grad 1.43 | tok/s 24468
step   1840 | loss 1.2331 | lr 3.00e-04 | grad 1.26 | tok/s 25326
step   1850 | loss 1.3232 | lr 3.00e-04 | grad 3.33 | tok/s 24534
step   1860 | loss 1.4123 | lr 3.00e-04 | grad 2.75 | tok/s 25276

Training complete! Final step: 1864
