Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_53/levelfla-gdn_100m_20260127_070427
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 503,382,782 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1220 | lr 3.00e-04 | grad 20.50 | tok/s 6751
step     20 | loss 2.6973 | lr 3.00e-04 | grad 9.19 | tok/s 20585
step     30 | loss 2.5208 | lr 3.00e-04 | grad 5.19 | tok/s 20708
step     40 | loss 2.3758 | lr 3.00e-04 | grad 4.44 | tok/s 19875
step     50 | loss 2.9484 | lr 3.00e-04 | grad 18.00 | tok/s 20133
step     60 | loss 1.9882 | lr 3.00e-04 | grad 6.62 | tok/s 20756
step     70 | loss 1.8072 | lr 3.00e-04 | grad 5.34 | tok/s 20947
step     80 | loss 5.3061 | lr 3.00e-04 | grad 44.25 | tok/s 21079
step     90 | loss 4.7521 | lr 3.00e-04 | grad 6.81 | tok/s 21418
step    100 | loss 3.6446 | lr 3.00e-04 | grad 7.12 | tok/s 21323
step    110 | loss 3.2156 | lr 3.00e-04 | grad 18.12 | tok/s 21327
step    120 | loss 3.0062 | lr 3.00e-04 | grad 13.31 | tok/s 21271
step    130 | loss 2.7740 | lr 3.00e-04 | grad 16.50 | tok/s 21239
step    140 | loss 2.5009 | lr 3.00e-04 | grad 9.56 | tok/s 21224
step    150 | loss 2.5409 | lr 3.00e-04 | grad 8.69 | tok/s 21218
step    160 | loss 2.1843 | lr 3.00e-04 | grad 7.78 | tok/s 21129
step    170 | loss 2.2159 | lr 3.00e-04 | grad 9.44 | tok/s 21169
step    180 | loss 2.0436 | lr 3.00e-04 | grad 6.38 | tok/s 21141
step    190 | loss 2.2146 | lr 3.00e-04 | grad 9.69 | tok/s 21178
step    200 | loss 1.9076 | lr 3.00e-04 | grad 4.75 | tok/s 21119
step    210 | loss 1.9256 | lr 3.00e-04 | grad 5.78 | tok/s 21118
step    220 | loss 2.0297 | lr 3.00e-04 | grad 2.86 | tok/s 20897
step    230 | loss 2.0990 | lr 3.00e-04 | grad 4.72 | tok/s 20640
step    240 | loss 2.2176 | lr 3.00e-04 | grad 4.22 | tok/s 19603
step    250 | loss 1.9932 | lr 3.00e-04 | grad 2.52 | tok/s 20188
step    260 | loss 1.4654 | lr 3.00e-04 | grad 2.89 | tok/s 20751
step    270 | loss 1.9999 | lr 3.00e-04 | grad 2.58 | tok/s 20460
step    280 | loss 2.1695 | lr 3.00e-04 | grad 4.38 | tok/s 20096
step    290 | loss 1.4097 | lr 3.00e-04 | grad 3.38 | tok/s 21166
step    300 | loss 0.5770 | lr 3.00e-04 | grad 4.59 | tok/s 21160
step    310 | loss 2.4016 | lr 3.00e-04 | grad 3.58 | tok/s 20750
step    320 | loss 1.8466 | lr 3.00e-04 | grad 6.44 | tok/s 20338
step    330 | loss 1.8304 | lr 3.00e-04 | grad 2.69 | tok/s 19692
step    340 | loss 2.1316 | lr 3.00e-04 | grad 2.42 | tok/s 19990
step    350 | loss 1.7594 | lr 3.00e-04 | grad 5.34 | tok/s 20436
step    360 | loss 1.1016 | lr 3.00e-04 | grad 8.94 | tok/s 20836
step    370 | loss 1.7063 | lr 3.00e-04 | grad 2.33 | tok/s 18988
step    380 | loss 1.6822 | lr 3.00e-04 | grad 2.52 | tok/s 20188
step    390 | loss 1.4491 | lr 3.00e-04 | grad 1.95 | tok/s 21061
step    400 | loss 1.4060 | lr 3.00e-04 | grad 2.28 | tok/s 20846
step    410 | loss 1.2051 | lr 3.00e-04 | grad 1.90 | tok/s 20369
step    420 | loss 1.7064 | lr 3.00e-04 | grad 4.06 | tok/s 19537
step    430 | loss 2.0248 | lr 3.00e-04 | grad 2.62 | tok/s 20792
step    440 | loss 2.0646 | lr 3.00e-04 | grad 3.33 | tok/s 19663
step    450 | loss 1.7600 | lr 3.00e-04 | grad 2.31 | tok/s 20294
step    460 | loss 1.6132 | lr 3.00e-04 | grad 2.19 | tok/s 19880
step    470 | loss 1.7219 | lr 3.00e-04 | grad 2.17 | tok/s 20509
step    480 | loss 2.1466 | lr 3.00e-04 | grad 6.12 | tok/s 20509
step    490 | loss 1.6679 | lr 3.00e-04 | grad 1.95 | tok/s 19390
step    500 | loss 1.5706 | lr 3.00e-04 | grad 3.23 | tok/s 20661
step    510 | loss 1.5935 | lr 3.00e-04 | grad 2.12 | tok/s 20973
step    520 | loss 1.5728 | lr 3.00e-04 | grad 1.84 | tok/s 20911
step    530 | loss 1.8036 | lr 3.00e-04 | grad 1.91 | tok/s 20123
step    540 | loss 1.6210 | lr 3.00e-04 | grad 1.91 | tok/s 20119
step    550 | loss 1.4806 | lr 3.00e-04 | grad 2.36 | tok/s 19706
step    560 | loss 1.6116 | lr 3.00e-04 | grad 2.30 | tok/s 19231
step    570 | loss 1.5456 | lr 3.00e-04 | grad 2.67 | tok/s 19765
step    580 | loss 1.4496 | lr 3.00e-04 | grad 1.98 | tok/s 19634
step    590 | loss 1.7615 | lr 3.00e-04 | grad 2.64 | tok/s 20107
step    600 | loss 1.7075 | lr 3.00e-04 | grad 1.88 | tok/s 19492
step    610 | loss 1.5345 | lr 3.00e-04 | grad 2.00 | tok/s 20463
step    620 | loss 1.4572 | lr 3.00e-04 | grad 2.03 | tok/s 19409
step    630 | loss 1.5435 | lr 3.00e-04 | grad 3.70 | tok/s 19520
step    640 | loss 1.6916 | lr 3.00e-04 | grad 1.94 | tok/s 20010
step    650 | loss 1.5812 | lr 3.00e-04 | grad 2.20 | tok/s 20153
step    660 | loss 1.5947 | lr 3.00e-04 | grad 1.70 | tok/s 20248
step    670 | loss 1.8286 | lr 3.00e-04 | grad 41.75 | tok/s 20401
step    680 | loss 1.6371 | lr 3.00e-04 | grad 2.11 | tok/s 19969
step    690 | loss 1.6955 | lr 3.00e-04 | grad 2.91 | tok/s 20617
step    700 | loss 1.3375 | lr 3.00e-04 | grad 2.34 | tok/s 21082
step    710 | loss 1.4899 | lr 3.00e-04 | grad 2.00 | tok/s 19688
step    720 | loss 1.3760 | lr 3.00e-04 | grad 2.91 | tok/s 19413
step    730 | loss 1.2332 | lr 3.00e-04 | grad 2.34 | tok/s 20980
step    740 | loss 1.4214 | lr 3.00e-04 | grad 1.94 | tok/s 20716
step    750 | loss 1.1269 | lr 3.00e-04 | grad 2.17 | tok/s 21052
step    760 | loss 1.0323 | lr 3.00e-04 | grad 1.85 | tok/s 21081
step    770 | loss 0.9861 | lr 3.00e-04 | grad 1.73 | tok/s 21112
step    780 | loss 0.9255 | lr 3.00e-04 | grad 1.51 | tok/s 21061
step    790 | loss 1.0501 | lr 3.00e-04 | grad 2.69 | tok/s 20422
step    800 | loss 1.7118 | lr 3.00e-04 | grad 4.97 | tok/s 20362
step    810 | loss 1.6175 | lr 3.00e-04 | grad 1.70 | tok/s 20262
step    820 | loss 1.5871 | lr 3.00e-04 | grad 3.06 | tok/s 19488
step    830 | loss 1.4060 | lr 3.00e-04 | grad 2.02 | tok/s 20894
step    840 | loss 1.3059 | lr 3.00e-04 | grad 1.92 | tok/s 21065
step    850 | loss 1.4542 | lr 3.00e-04 | grad 1.62 | tok/s 21066
step    860 | loss 1.3815 | lr 3.00e-04 | grad 3.56 | tok/s 20773
step    870 | loss 1.4082 | lr 3.00e-04 | grad 2.31 | tok/s 20029
step    880 | loss 1.5534 | lr 3.00e-04 | grad 2.31 | tok/s 20127
step    890 | loss 1.5737 | lr 3.00e-04 | grad 2.53 | tok/s 20426
step    900 | loss 1.4647 | lr 3.00e-04 | grad 2.22 | tok/s 20436
step    910 | loss 1.3513 | lr 3.00e-04 | grad 3.14 | tok/s 19998
step    920 | loss 1.4515 | lr 3.00e-04 | grad 3.06 | tok/s 20779
step    930 | loss 1.4900 | lr 3.00e-04 | grad 2.77 | tok/s 19864
step    940 | loss 1.2955 | lr 3.00e-04 | grad 1.57 | tok/s 20956
step    950 | loss 1.4199 | lr 3.00e-04 | grad 2.33 | tok/s 20994
step    960 | loss 1.2501 | lr 3.00e-04 | grad 2.20 | tok/s 21084
step    970 | loss 1.6159 | lr 3.00e-04 | grad 2.97 | tok/s 19861
step    980 | loss 1.5311 | lr 3.00e-04 | grad 1.98 | tok/s 20357
step    990 | loss 1.3648 | lr 3.00e-04 | grad 1.80 | tok/s 20692
step   1000 | loss 1.7269 | lr 3.00e-04 | grad 8.81 | tok/s 19873
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7269.pt
step   1010 | loss 1.5437 | lr 3.00e-04 | grad 2.95 | tok/s 7756
step   1020 | loss 1.5462 | lr 3.00e-04 | grad 1.59 | tok/s 19525
step   1030 | loss 1.3708 | lr 3.00e-04 | grad 1.99 | tok/s 20306
step   1040 | loss 1.4096 | lr 3.00e-04 | grad 1.66 | tok/s 20979
step   1050 | loss 1.5060 | lr 3.00e-04 | grad 2.67 | tok/s 19424
step   1060 | loss 1.6292 | lr 3.00e-04 | grad 3.77 | tok/s 20989
step   1070 | loss 1.5428 | lr 3.00e-04 | grad 2.47 | tok/s 20840
step   1080 | loss 1.3060 | lr 3.00e-04 | grad 1.77 | tok/s 18984
step   1090 | loss 1.0321 | lr 3.00e-04 | grad 2.45 | tok/s 20925
step   1100 | loss 1.3380 | lr 3.00e-04 | grad 3.19 | tok/s 20322
step   1110 | loss 1.3738 | lr 3.00e-04 | grad 1.82 | tok/s 21266
step   1120 | loss 1.2588 | lr 3.00e-04 | grad 2.08 | tok/s 21249
step   1130 | loss 1.2165 | lr 3.00e-04 | grad 1.56 | tok/s 21212
step   1140 | loss 1.2030 | lr 3.00e-04 | grad 1.88 | tok/s 21210
step   1150 | loss 1.2104 | lr 3.00e-04 | grad 1.60 | tok/s 21212
step   1160 | loss 1.1378 | lr 3.00e-04 | grad 1.79 | tok/s 21197
step   1170 | loss 1.1618 | lr 3.00e-04 | grad 1.80 | tok/s 21210
step   1180 | loss 1.2672 | lr 3.00e-04 | grad 1.45 | tok/s 21194
step   1190 | loss 1.1372 | lr 3.00e-04 | grad 1.81 | tok/s 21245
step   1200 | loss 1.1298 | lr 3.00e-04 | grad 1.79 | tok/s 21202
step   1210 | loss 1.1873 | lr 3.00e-04 | grad 1.81 | tok/s 21210
step   1220 | loss 1.2076 | lr 3.00e-04 | grad 1.94 | tok/s 21235
step   1230 | loss 1.1684 | lr 3.00e-04 | grad 1.62 | tok/s 21185
step   1240 | loss 1.1387 | lr 3.00e-04 | grad 1.26 | tok/s 21293
step   1250 | loss 1.6401 | lr 3.00e-04 | grad 2.92 | tok/s 20067
step   1260 | loss 1.2940 | lr 3.00e-04 | grad 5.84 | tok/s 19893
step   1270 | loss 1.5592 | lr 3.00e-04 | grad 4.84 | tok/s 19868
step   1280 | loss 1.5273 | lr 3.00e-04 | grad 1.91 | tok/s 20405
step   1290 | loss 1.3847 | lr 3.00e-04 | grad 1.68 | tok/s 20278
step   1300 | loss 1.4211 | lr 3.00e-04 | grad 2.09 | tok/s 20473
step   1310 | loss 1.3767 | lr 3.00e-04 | grad 2.30 | tok/s 20783
step   1320 | loss 1.4874 | lr 3.00e-04 | grad 2.08 | tok/s 20822
step   1330 | loss 1.4988 | lr 3.00e-04 | grad 2.14 | tok/s 20916
step   1340 | loss 1.3734 | lr 3.00e-04 | grad 7.72 | tok/s 19942
step   1350 | loss 1.5840 | lr 3.00e-04 | grad 2.30 | tok/s 19273
step   1360 | loss 1.3899 | lr 3.00e-04 | grad 2.31 | tok/s 20458
step   1370 | loss 1.3444 | lr 3.00e-04 | grad 1.48 | tok/s 20229
step   1380 | loss 1.4922 | lr 3.00e-04 | grad 2.05 | tok/s 19466
step   1390 | loss 1.4208 | lr 3.00e-04 | grad 1.48 | tok/s 20599
step   1400 | loss 1.2851 | lr 3.00e-04 | grad 1.60 | tok/s 19856
step   1410 | loss 1.3435 | lr 3.00e-04 | grad 2.70 | tok/s 19956
step   1420 | loss 1.5197 | lr 3.00e-04 | grad 5.03 | tok/s 20020
step   1430 | loss 1.2536 | lr 3.00e-04 | grad 1.73 | tok/s 20309
step   1440 | loss 1.0770 | lr 3.00e-04 | grad 1.76 | tok/s 20999
step   1450 | loss 1.0927 | lr 3.00e-04 | grad 3.86 | tok/s 21158
step   1460 | loss 1.5059 | lr 3.00e-04 | grad 1.81 | tok/s 19938
step   1470 | loss 1.4167 | lr 3.00e-04 | grad 1.64 | tok/s 20698
step   1480 | loss 1.6342 | lr 3.00e-04 | grad 3.56 | tok/s 20818
step   1490 | loss 1.4176 | lr 3.00e-04 | grad 1.56 | tok/s 21072
step   1500 | loss 1.2705 | lr 3.00e-04 | grad 1.56 | tok/s 21201
step   1510 | loss 1.3893 | lr 3.00e-04 | grad 1.73 | tok/s 20921
step   1520 | loss 1.3312 | lr 3.00e-04 | grad 3.83 | tok/s 20485
step   1530 | loss 1.3639 | lr 3.00e-04 | grad 1.40 | tok/s 20992
step   1540 | loss 1.4884 | lr 3.00e-04 | grad 2.12 | tok/s 19757
step   1550 | loss 1.2115 | lr 3.00e-04 | grad 2.14 | tok/s 21036
step   1560 | loss 1.4814 | lr 3.00e-04 | grad 2.20 | tok/s 19980
step   1570 | loss 1.2092 | lr 3.00e-04 | grad 1.99 | tok/s 21202
step   1580 | loss 1.5469 | lr 3.00e-04 | grad 3.97 | tok/s 20719
step   1590 | loss 1.4817 | lr 3.00e-04 | grad 2.09 | tok/s 19941
step   1600 | loss 0.9420 | lr 3.00e-04 | grad 1.80 | tok/s 21296
step   1610 | loss 0.9709 | lr 3.00e-04 | grad 2.03 | tok/s 20682
step   1620 | loss 1.3033 | lr 3.00e-04 | grad 2.27 | tok/s 19302
step   1630 | loss 1.2480 | lr 3.00e-04 | grad 2.30 | tok/s 20599
step   1640 | loss 1.2296 | lr 3.00e-04 | grad 1.77 | tok/s 20132
step   1650 | loss 1.4038 | lr 3.00e-04 | grad 2.30 | tok/s 19326
step   1660 | loss 1.3274 | lr 3.00e-04 | grad 1.41 | tok/s 20556
step   1670 | loss 1.2717 | lr 3.00e-04 | grad 9.56 | tok/s 20538
step   1680 | loss 1.5982 | lr 3.00e-04 | grad 1.77 | tok/s 19718
step   1690 | loss 1.3573 | lr 3.00e-04 | grad 3.45 | tok/s 17974
step   1700 | loss 1.3670 | lr 3.00e-04 | grad 2.06 | tok/s 20438
step   1710 | loss 1.3028 | lr 3.00e-04 | grad 1.83 | tok/s 20171
step   1720 | loss 1.3959 | lr 3.00e-04 | grad 2.41 | tok/s 21020
step   1730 | loss 1.0985 | lr 3.00e-04 | grad 2.61 | tok/s 21202
step   1740 | loss 1.2130 | lr 3.00e-04 | grad 2.17 | tok/s 20698
step   1750 | loss 1.5009 | lr 3.00e-04 | grad 2.28 | tok/s 20323
step   1760 | loss 1.4313 | lr 3.00e-04 | grad 1.83 | tok/s 20404
step   1770 | loss 1.3409 | lr 3.00e-04 | grad 2.06 | tok/s 20065
step   1780 | loss 1.4195 | lr 3.00e-04 | grad 1.77 | tok/s 20830
step   1790 | loss 1.2948 | lr 3.00e-04 | grad 1.43 | tok/s 20297
step   1800 | loss 1.5106 | lr 3.00e-04 | grad 1.94 | tok/s 20527
step   1810 | loss 1.3199 | lr 3.00e-04 | grad 1.93 | tok/s 19768
step   1820 | loss 1.3621 | lr 3.00e-04 | grad 5.06 | tok/s 20060
step   1830 | loss 1.3016 | lr 3.00e-04 | grad 1.94 | tok/s 20881
step   1840 | loss 1.4198 | lr 3.00e-04 | grad 2.17 | tok/s 20000
step   1850 | loss 1.2115 | lr 3.00e-04 | grad 1.55 | tok/s 20908
step   1860 | loss 1.2297 | lr 3.00e-04 | grad 2.16 | tok/s 20250
step   1870 | loss 1.3123 | lr 3.00e-04 | grad 2.95 | tok/s 20321
step   1880 | loss 1.1289 | lr 3.00e-04 | grad 1.83 | tok/s 19927
step   1890 | loss 1.4057 | lr 3.00e-04 | grad 1.58 | tok/s 18962
step   1900 | loss 1.3184 | lr 3.00e-04 | grad 2.12 | tok/s 20427
step   1910 | loss 1.3619 | lr 3.00e-04 | grad 2.27 | tok/s 19392
step   1920 | loss 1.3159 | lr 3.00e-04 | grad 1.75 | tok/s 21231
step   1930 | loss 1.3701 | lr 3.00e-04 | grad 2.05 | tok/s 19920
step   1940 | loss 1.3575 | lr 3.00e-04 | grad 1.88 | tok/s 20731
step   1950 | loss 1.7409 | lr 3.00e-04 | grad 4.09 | tok/s 20990
step   1960 | loss 1.3440 | lr 3.00e-04 | grad 4.12 | tok/s 21228
step   1970 | loss 1.3911 | lr 3.00e-04 | grad 2.19 | tok/s 20682
step   1980 | loss 1.4283 | lr 3.00e-04 | grad 1.74 | tok/s 19784
step   1990 | loss 1.4562 | lr 3.00e-04 | grad 8.06 | tok/s 20205
step   2000 | loss 1.3905 | lr 3.00e-04 | grad 1.74 | tok/s 20432
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3905.pt
step   2010 | loss 1.0043 | lr 3.00e-04 | grad 1.57 | tok/s 8306
step   2020 | loss 1.2081 | lr 3.00e-04 | grad 1.81 | tok/s 20385
step   2030 | loss 1.0146 | lr 3.00e-04 | grad 0.93 | tok/s 21507
step   2040 | loss 1.1402 | lr 3.00e-04 | grad 1.80 | tok/s 21414
step   2050 | loss 1.1114 | lr 3.00e-04 | grad 2.03 | tok/s 20925
step   2060 | loss 1.4419 | lr 3.00e-04 | grad 2.11 | tok/s 19751
step   2070 | loss 1.5664 | lr 3.00e-04 | grad 2.20 | tok/s 20473
step   2080 | loss 2.0838 | lr 3.00e-04 | grad 4.41 | tok/s 21114
step   2090 | loss 1.5763 | lr 3.00e-04 | grad 4.56 | tok/s 21190
step   2100 | loss 1.2393 | lr 3.00e-04 | grad 2.38 | tok/s 20684
step   2110 | loss 1.3884 | lr 3.00e-04 | grad 15.25 | tok/s 20308
step   2120 | loss 0.8595 | lr 3.00e-04 | grad 2.50 | tok/s 21095
step   2130 | loss 0.9425 | lr 3.00e-04 | grad 3.05 | tok/s 21174
step   2140 | loss 1.4223 | lr 3.00e-04 | grad 1.52 | tok/s 20253
step   2150 | loss 1.2060 | lr 3.00e-04 | grad 1.82 | tok/s 21308
step   2160 | loss 1.1084 | lr 3.00e-04 | grad 1.32 | tok/s 21267
step   2170 | loss 1.1589 | lr 3.00e-04 | grad 1.36 | tok/s 21281
step   2180 | loss 1.1161 | lr 3.00e-04 | grad 1.74 | tok/s 21263
step   2190 | loss 1.1282 | lr 3.00e-04 | grad 1.31 | tok/s 21254
step   2200 | loss 1.1160 | lr 3.00e-04 | grad 1.46 | tok/s 21266
step   2210 | loss 1.0717 | lr 3.00e-04 | grad 1.34 | tok/s 21251
step   2220 | loss 1.0612 | lr 3.00e-04 | grad 1.27 | tok/s 21296
step   2230 | loss 1.2655 | lr 3.00e-04 | grad 1.62 | tok/s 20916
step   2240 | loss 1.2592 | lr 3.00e-04 | grad 1.72 | tok/s 21187
step   2250 | loss 1.3808 | lr 3.00e-04 | grad 2.97 | tok/s 20539
step   2260 | loss 1.4087 | lr 3.00e-04 | grad 1.76 | tok/s 20724
step   2270 | loss 1.7980 | lr 3.00e-04 | grad 4.75 | tok/s 21106
step   2280 | loss 1.3898 | lr 3.00e-04 | grad 2.14 | tok/s 21051
step   2290 | loss 1.1968 | lr 3.00e-04 | grad 2.28 | tok/s 20547
step   2300 | loss 1.5540 | lr 3.00e-04 | grad 4.25 | tok/s 21018
step   2310 | loss 1.2721 | lr 3.00e-04 | grad 1.42 | tok/s 19912
step   2320 | loss 1.4769 | lr 3.00e-04 | grad 4.50 | tok/s 20047
step   2330 | loss 1.6952 | lr 3.00e-04 | grad 1.95 | tok/s 20364
step   2340 | loss 1.3140 | lr 3.00e-04 | grad 5.25 | tok/s 19837
step   2350 | loss 1.2394 | lr 3.00e-04 | grad 4.12 | tok/s 20810
step   2360 | loss 1.2187 | lr 3.00e-04 | grad 2.05 | tok/s 21065
step   2370 | loss 1.3292 | lr 3.00e-04 | grad 3.20 | tok/s 20815
step   2380 | loss 1.3731 | lr 3.00e-04 | grad 2.34 | tok/s 21301
step   2390 | loss 1.0803 | lr 3.00e-04 | grad 1.64 | tok/s 21234
step   2400 | loss 1.0260 | lr 3.00e-04 | grad 1.41 | tok/s 21257
step   2410 | loss 1.0197 | lr 3.00e-04 | grad 1.69 | tok/s 20639
step   2420 | loss 1.3570 | lr 3.00e-04 | grad 3.69 | tok/s 19959
step   2430 | loss 1.3017 | lr 3.00e-04 | grad 1.76 | tok/s 20254
step   2440 | loss 1.1199 | lr 3.00e-04 | grad 3.34 | tok/s 20837
step   2450 | loss 1.3603 | lr 3.00e-04 | grad 1.93 | tok/s 20280
step   2460 | loss 1.2271 | lr 3.00e-04 | grad 1.90 | tok/s 21037
step   2470 | loss 1.0464 | lr 3.00e-04 | grad 2.06 | tok/s 20997
step   2480 | loss 1.1676 | lr 3.00e-04 | grad 1.51 | tok/s 21262
step   2490 | loss 1.2150 | lr 3.00e-04 | grad 1.65 | tok/s 20128
step   2500 | loss 1.4194 | lr 3.00e-04 | grad 2.28 | tok/s 20794
step   2510 | loss 1.0203 | lr 3.00e-04 | grad 2.58 | tok/s 21246
step   2520 | loss 1.2634 | lr 3.00e-04 | grad 4.91 | tok/s 21160
step   2530 | loss 1.2543 | lr 3.00e-04 | grad 1.56 | tok/s 20452
step   2540 | loss 1.2879 | lr 3.00e-04 | grad 2.75 | tok/s 20325
step   2550 | loss 1.0965 | lr 3.00e-04 | grad 1.62 | tok/s 21122
step   2560 | loss 1.3188 | lr 3.00e-04 | grad 6.41 | tok/s 19853
step   2570 | loss 1.2884 | lr 3.00e-04 | grad 1.61 | tok/s 20628
step   2580 | loss 1.2477 | lr 3.00e-04 | grad 2.12 | tok/s 19403
step   2590 | loss 1.2042 | lr 3.00e-04 | grad 2.06 | tok/s 20484
step   2600 | loss 1.4413 | lr 3.00e-04 | grad 4.03 | tok/s 19674
step   2610 | loss 1.1762 | lr 3.00e-04 | grad 2.31 | tok/s 21128
step   2620 | loss 1.4255 | lr 3.00e-04 | grad 1.83 | tok/s 20333
step   2630 | loss 1.3310 | lr 3.00e-04 | grad 1.67 | tok/s 21029
step   2640 | loss 1.3380 | lr 3.00e-04 | grad 1.91 | tok/s 20459
step   2650 | loss 1.3855 | lr 3.00e-04 | grad 2.83 | tok/s 21229
step   2660 | loss 1.2263 | lr 3.00e-04 | grad 1.91 | tok/s 20511
step   2670 | loss 1.3032 | lr 3.00e-04 | grad 2.41 | tok/s 19725
step   2680 | loss 1.4221 | lr 3.00e-04 | grad 12.94 | tok/s 20118
step   2690 | loss 1.1840 | lr 3.00e-04 | grad 1.48 | tok/s 21118
step   2700 | loss 1.3162 | lr 3.00e-04 | grad 1.69 | tok/s 20481
step   2710 | loss 1.3854 | lr 3.00e-04 | grad 2.58 | tok/s 20162
step   2720 | loss 1.2325 | lr 3.00e-04 | grad 1.78 | tok/s 19376
step   2730 | loss 1.0681 | lr 3.00e-04 | grad 1.77 | tok/s 20780
step   2740 | loss 1.5196 | lr 3.00e-04 | grad 5.88 | tok/s 20581
step   2750 | loss 1.4574 | lr 3.00e-04 | grad 1.91 | tok/s 21061
step   2760 | loss 1.2164 | lr 3.00e-04 | grad 1.77 | tok/s 19597
step   2770 | loss 1.3913 | lr 3.00e-04 | grad 2.59 | tok/s 20202
step   2780 | loss 0.9785 | lr 3.00e-04 | grad 1.51 | tok/s 21214
step   2790 | loss 1.4790 | lr 3.00e-04 | grad 4.72 | tok/s 19753
step   2800 | loss 1.2850 | lr 3.00e-04 | grad 1.33 | tok/s 20362
step   2810 | loss 1.1503 | lr 3.00e-04 | grad 1.81 | tok/s 20280
step   2820 | loss 1.3015 | lr 3.00e-04 | grad 1.48 | tok/s 19546
step   2830 | loss 0.9589 | lr 3.00e-04 | grad 1.83 | tok/s 20849
step   2840 | loss 0.5958 | lr 3.00e-04 | grad 2.03 | tok/s 21186
step   2850 | loss 1.6124 | lr 3.00e-04 | grad 1.99 | tok/s 20514
step   2860 | loss 1.4765 | lr 3.00e-04 | grad 1.49 | tok/s 20456
step   2870 | loss 1.2545 | lr 3.00e-04 | grad 1.80 | tok/s 20033
step   2880 | loss 1.3744 | lr 3.00e-04 | grad 2.83 | tok/s 20637
step   2890 | loss 1.1259 | lr 3.00e-04 | grad 2.19 | tok/s 21194
step   2900 | loss 1.3220 | lr 3.00e-04 | grad 1.54 | tok/s 20396
step   2910 | loss 1.2313 | lr 3.00e-04 | grad 1.54 | tok/s 20404
step   2920 | loss 1.4127 | lr 3.00e-04 | grad 2.09 | tok/s 19801
step   2930 | loss 1.4349 | lr 3.00e-04 | grad 1.61 | tok/s 20724
step   2940 | loss 1.2003 | lr 3.00e-04 | grad 1.98 | tok/s 19085
step   2950 | loss 1.2610 | lr 3.00e-04 | grad 2.14 | tok/s 20512
step   2960 | loss 1.1928 | lr 3.00e-04 | grad 2.48 | tok/s 20655
step   2970 | loss 1.1963 | lr 3.00e-04 | grad 1.98 | tok/s 20829
step   2980 | loss 1.6096 | lr 3.00e-04 | grad 1.61 | tok/s 20195
step   2990 | loss 1.7824 | lr 3.00e-04 | grad 2.39 | tok/s 20657
step   3000 | loss 1.2468 | lr 3.00e-04 | grad 3.77 | tok/s 20739
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2468.pt

Training complete! Final step: 3000
