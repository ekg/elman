Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_81/levelfla-gdn_100m_20260127_074535
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 492,772,976 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.3785 | lr 3.00e-04 | grad 33.00 | tok/s 6576
step     20 | loss 2.9456 | lr 3.00e-04 | grad 12.19 | tok/s 19778
step     30 | loss 2.8103 | lr 3.00e-04 | grad 7.44 | tok/s 19949
step     40 | loss 2.6081 | lr 3.00e-04 | grad 5.44 | tok/s 19091
step     50 | loss 3.4231 | lr 3.00e-04 | grad 36.25 | tok/s 19271
step     60 | loss 2.2317 | lr 3.00e-04 | grad 6.31 | tok/s 19955
step     70 | loss 2.0235 | lr 3.00e-04 | grad 6.50 | tok/s 20181
step     80 | loss 4.9975 | lr 3.00e-04 | grad 56.25 | tok/s 20383
step     90 | loss 4.6388 | lr 3.00e-04 | grad 7.28 | tok/s 20549
step    100 | loss 3.8575 | lr 3.00e-04 | grad 14.75 | tok/s 20432
step    110 | loss 3.5621 | lr 3.00e-04 | grad 21.25 | tok/s 20444
step    120 | loss 3.2854 | lr 3.00e-04 | grad 23.75 | tok/s 20413
step    130 | loss 3.0237 | lr 3.00e-04 | grad 20.00 | tok/s 20339
step    140 | loss 2.6743 | lr 3.00e-04 | grad 14.00 | tok/s 20325
step    150 | loss 2.8441 | lr 3.00e-04 | grad 15.44 | tok/s 20246
step    160 | loss 2.3624 | lr 3.00e-04 | grad 15.31 | tok/s 20187
step    170 | loss 2.4799 | lr 3.00e-04 | grad 12.88 | tok/s 20119
step    180 | loss 2.1833 | lr 3.00e-04 | grad 5.50 | tok/s 20034
step    190 | loss 2.3815 | lr 3.00e-04 | grad 6.75 | tok/s 19984
step    200 | loss 2.1055 | lr 3.00e-04 | grad 8.44 | tok/s 20023
step    210 | loss 2.1033 | lr 3.00e-04 | grad 9.31 | tok/s 19960
step    220 | loss 2.2086 | lr 3.00e-04 | grad 2.61 | tok/s 19664
step    230 | loss 2.4528 | lr 3.00e-04 | grad 4.06 | tok/s 19377
step    240 | loss 2.2451 | lr 3.00e-04 | grad 3.72 | tok/s 18407
step    250 | loss 2.0638 | lr 3.00e-04 | grad 2.23 | tok/s 18858
step    260 | loss 1.5334 | lr 3.00e-04 | grad 2.98 | tok/s 19392
step    270 | loss 2.0581 | lr 3.00e-04 | grad 2.41 | tok/s 18858
step    280 | loss 2.2397 | lr 3.00e-04 | grad 4.56 | tok/s 18736
step    290 | loss 1.5394 | lr 3.00e-04 | grad 3.88 | tok/s 19743
step    300 | loss 0.6304 | lr 3.00e-04 | grad 5.84 | tok/s 19697
step    310 | loss 2.4218 | lr 3.00e-04 | grad 2.88 | tok/s 19290
step    320 | loss 1.8906 | lr 3.00e-04 | grad 6.06 | tok/s 18841
step    330 | loss 1.8839 | lr 3.00e-04 | grad 2.52 | tok/s 18202
step    340 | loss 2.1842 | lr 3.00e-04 | grad 2.14 | tok/s 18455
step    350 | loss 1.8455 | lr 3.00e-04 | grad 5.00 | tok/s 18855
step    360 | loss 1.2319 | lr 3.00e-04 | grad 8.06 | tok/s 19294
step    370 | loss 1.7445 | lr 3.00e-04 | grad 2.11 | tok/s 17494
step    380 | loss 1.7146 | lr 3.00e-04 | grad 2.16 | tok/s 18560
step    390 | loss 1.4781 | lr 3.00e-04 | grad 1.62 | tok/s 19314
step    400 | loss 1.4368 | lr 3.00e-04 | grad 2.00 | tok/s 19114
step    410 | loss 1.2381 | lr 3.00e-04 | grad 1.88 | tok/s 18691
step    420 | loss 1.7436 | lr 3.00e-04 | grad 3.97 | tok/s 16229
step    430 | loss 2.0572 | lr 3.00e-04 | grad 2.34 | tok/s 18968
step    440 | loss 2.1029 | lr 3.00e-04 | grad 3.23 | tok/s 17900
step    450 | loss 1.8821 | lr 3.00e-04 | grad 2.38 | tok/s 18492
step    460 | loss 1.6683 | lr 3.00e-04 | grad 2.19 | tok/s 18105
step    470 | loss 1.7423 | lr 3.00e-04 | grad 1.80 | tok/s 18597
step    480 | loss 2.1749 | lr 3.00e-04 | grad 5.78 | tok/s 18606
step    490 | loss 1.7076 | lr 3.00e-04 | grad 2.14 | tok/s 17559
step    500 | loss 1.6031 | lr 3.00e-04 | grad 2.92 | tok/s 18743
step    510 | loss 1.6195 | lr 3.00e-04 | grad 1.82 | tok/s 18966
step    520 | loss 1.6010 | lr 3.00e-04 | grad 1.66 | tok/s 18889
step    530 | loss 1.8389 | lr 3.00e-04 | grad 1.80 | tok/s 18220
step    540 | loss 1.6478 | lr 3.00e-04 | grad 1.62 | tok/s 18169
step    550 | loss 1.4989 | lr 3.00e-04 | grad 2.16 | tok/s 17790
step    560 | loss 1.6367 | lr 3.00e-04 | grad 2.08 | tok/s 17312
step    570 | loss 1.5647 | lr 3.00e-04 | grad 2.59 | tok/s 17788
step    580 | loss 1.4655 | lr 3.00e-04 | grad 1.64 | tok/s 17743
step    590 | loss 1.7738 | lr 3.00e-04 | grad 2.56 | tok/s 18084
step    600 | loss 1.7074 | lr 3.00e-04 | grad 1.75 | tok/s 17470
step    610 | loss 1.5586 | lr 3.00e-04 | grad 1.69 | tok/s 18369
step    620 | loss 1.4746 | lr 3.00e-04 | grad 1.85 | tok/s 17440
step    630 | loss 1.5754 | lr 3.00e-04 | grad 3.28 | tok/s 17506
step    640 | loss 1.7126 | lr 3.00e-04 | grad 1.78 | tok/s 17955
step    650 | loss 1.5912 | lr 3.00e-04 | grad 1.93 | tok/s 18065
step    660 | loss 1.6155 | lr 3.00e-04 | grad 1.51 | tok/s 18143
step    670 | loss 1.8473 | lr 3.00e-04 | grad 29.38 | tok/s 18281
step    680 | loss 1.6562 | lr 3.00e-04 | grad 1.95 | tok/s 17854
step    690 | loss 1.7439 | lr 3.00e-04 | grad 2.61 | tok/s 18475
step    700 | loss 1.3703 | lr 3.00e-04 | grad 2.38 | tok/s 18821
step    710 | loss 1.5153 | lr 3.00e-04 | grad 1.81 | tok/s 17565
step    720 | loss 1.3876 | lr 3.00e-04 | grad 2.52 | tok/s 17361
step    730 | loss 1.2474 | lr 3.00e-04 | grad 2.19 | tok/s 18773
step    740 | loss 1.4402 | lr 3.00e-04 | grad 1.77 | tok/s 18550
step    750 | loss 1.1477 | lr 3.00e-04 | grad 1.97 | tok/s 18801
step    760 | loss 1.0492 | lr 3.00e-04 | grad 1.59 | tok/s 18759
step    770 | loss 0.9999 | lr 3.00e-04 | grad 1.51 | tok/s 18771
step    780 | loss 0.9418 | lr 3.00e-04 | grad 1.45 | tok/s 18772
step    790 | loss 1.0650 | lr 3.00e-04 | grad 2.56 | tok/s 18192
step    800 | loss 1.7540 | lr 3.00e-04 | grad 4.97 | tok/s 18132
step    810 | loss 1.6372 | lr 3.00e-04 | grad 1.52 | tok/s 18010
step    820 | loss 1.6145 | lr 3.00e-04 | grad 2.98 | tok/s 17299
step    830 | loss 1.4371 | lr 3.00e-04 | grad 1.89 | tok/s 18542
step    840 | loss 1.3259 | lr 3.00e-04 | grad 1.77 | tok/s 18709
step    850 | loss 1.4519 | lr 3.00e-04 | grad 1.52 | tok/s 18642
step    860 | loss 1.4046 | lr 3.00e-04 | grad 3.19 | tok/s 18403
step    870 | loss 1.4254 | lr 3.00e-04 | grad 2.11 | tok/s 17790
step    880 | loss 1.5767 | lr 3.00e-04 | grad 2.39 | tok/s 17865
step    890 | loss 1.5909 | lr 3.00e-04 | grad 2.23 | tok/s 18074
step    900 | loss 1.4846 | lr 3.00e-04 | grad 2.02 | tok/s 18090
step    910 | loss 1.3640 | lr 3.00e-04 | grad 3.00 | tok/s 17659
step    920 | loss 1.4574 | lr 3.00e-04 | grad 2.67 | tok/s 18308
step    930 | loss 1.5062 | lr 3.00e-04 | grad 2.66 | tok/s 17537
step    940 | loss 1.3165 | lr 3.00e-04 | grad 1.44 | tok/s 17054
step    950 | loss 1.4192 | lr 3.00e-04 | grad 2.44 | tok/s 18585
step    960 | loss 1.2699 | lr 3.00e-04 | grad 2.03 | tok/s 18636
step    970 | loss 1.6414 | lr 3.00e-04 | grad 2.75 | tok/s 17512
step    980 | loss 1.5480 | lr 3.00e-04 | grad 1.80 | tok/s 17995
step    990 | loss 1.3834 | lr 3.00e-04 | grad 1.57 | tok/s 18241
step   1000 | loss 1.7481 | lr 3.00e-04 | grad 8.06 | tok/s 17601
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7481.pt
step   1010 | loss 1.6926 | lr 3.00e-04 | grad 1.77 | tok/s 6296
step   1020 | loss 1.5970 | lr 3.00e-04 | grad 2.09 | tok/s 17300
step   1030 | loss 1.3390 | lr 3.00e-04 | grad 1.30 | tok/s 18040
step   1040 | loss 1.4716 | lr 3.00e-04 | grad 2.91 | tok/s 18366
step   1050 | loss 1.5159 | lr 3.00e-04 | grad 1.73 | tok/s 17287
step   1060 | loss 1.6219 | lr 3.00e-04 | grad 1.76 | tok/s 18430
step   1070 | loss 1.5917 | lr 3.00e-04 | grad 2.78 | tok/s 18133
step   1080 | loss 1.3252 | lr 3.00e-04 | grad 1.88 | tok/s 16804
step   1090 | loss 0.9515 | lr 3.00e-04 | grad 1.33 | tok/s 18713
step   1100 | loss 1.4624 | lr 3.00e-04 | grad 2.34 | tok/s 17838
step   1110 | loss 1.3533 | lr 3.00e-04 | grad 1.47 | tok/s 18717
step   1120 | loss 1.2687 | lr 3.00e-04 | grad 1.59 | tok/s 18731
step   1130 | loss 1.2173 | lr 3.00e-04 | grad 1.52 | tok/s 18681
step   1140 | loss 1.2241 | lr 3.00e-04 | grad 1.52 | tok/s 18797
step   1150 | loss 1.2227 | lr 3.00e-04 | grad 1.51 | tok/s 18668
step   1160 | loss 1.1536 | lr 3.00e-04 | grad 1.45 | tok/s 18699
step   1170 | loss 1.1888 | lr 3.00e-04 | grad 1.61 | tok/s 18709
step   1180 | loss 1.2629 | lr 3.00e-04 | grad 1.30 | tok/s 18676
step   1190 | loss 1.1515 | lr 3.00e-04 | grad 1.58 | tok/s 18665
step   1200 | loss 1.1592 | lr 3.00e-04 | grad 1.45 | tok/s 18632
step   1210 | loss 1.1948 | lr 3.00e-04 | grad 1.34 | tok/s 18629
step   1220 | loss 1.2165 | lr 3.00e-04 | grad 1.29 | tok/s 18637
step   1230 | loss 1.1805 | lr 3.00e-04 | grad 1.23 | tok/s 18613
step   1240 | loss 1.1884 | lr 3.00e-04 | grad 2.27 | tok/s 18473
step   1250 | loss 1.6581 | lr 3.00e-04 | grad 1.88 | tok/s 17661
step   1260 | loss 1.2297 | lr 3.00e-04 | grad 2.69 | tok/s 17484
step   1270 | loss 1.6662 | lr 3.00e-04 | grad 2.38 | tok/s 17385
step   1280 | loss 1.5177 | lr 3.00e-04 | grad 1.86 | tok/s 18153
step   1290 | loss 1.4102 | lr 3.00e-04 | grad 2.12 | tok/s 17839
step   1300 | loss 1.4396 | lr 3.00e-04 | grad 1.63 | tok/s 17709
step   1310 | loss 1.3886 | lr 3.00e-04 | grad 1.57 | tok/s 18505
step   1320 | loss 1.5136 | lr 3.00e-04 | grad 1.92 | tok/s 18323
step   1330 | loss 1.4420 | lr 3.00e-04 | grad 1.53 | tok/s 18319
step   1340 | loss 1.4932 | lr 3.00e-04 | grad 2.77 | tok/s 17313
step   1350 | loss 1.5946 | lr 3.00e-04 | grad 1.73 | tok/s 17080
step   1360 | loss 1.4060 | lr 3.00e-04 | grad 1.43 | tok/s 17903
step   1370 | loss 1.4188 | lr 3.00e-04 | grad 5.41 | tok/s 17728
step   1380 | loss 1.4944 | lr 3.00e-04 | grad 2.44 | tok/s 17072
step   1390 | loss 1.3922 | lr 3.00e-04 | grad 1.65 | tok/s 17950
step   1400 | loss 1.2935 | lr 3.00e-04 | grad 1.37 | tok/s 17523
step   1410 | loss 1.4055 | lr 3.00e-04 | grad 5.94 | tok/s 17471
step   1420 | loss 1.5341 | lr 3.00e-04 | grad 2.42 | tok/s 17459
step   1430 | loss 1.2699 | lr 3.00e-04 | grad 1.62 | tok/s 17701
step   1440 | loss 1.0805 | lr 3.00e-04 | grad 1.55 | tok/s 16882
step   1450 | loss 1.1018 | lr 3.00e-04 | grad 2.00 | tok/s 18368
step   1460 | loss 1.5428 | lr 3.00e-04 | grad 1.79 | tok/s 17371
step   1470 | loss 1.4381 | lr 3.00e-04 | grad 1.55 | tok/s 18404
step   1480 | loss 1.7216 | lr 3.00e-04 | grad 2.84 | tok/s 18229
step   1490 | loss 1.4654 | lr 3.00e-04 | grad 2.17 | tok/s 18469
step   1500 | loss 1.2580 | lr 3.00e-04 | grad 1.53 | tok/s 18576
step   1510 | loss 1.4262 | lr 3.00e-04 | grad 2.06 | tok/s 18330
step   1520 | loss 1.3580 | lr 3.00e-04 | grad 2.31 | tok/s 17966
step   1530 | loss 1.3679 | lr 3.00e-04 | grad 2.31 | tok/s 18406
step   1540 | loss 1.5160 | lr 3.00e-04 | grad 2.09 | tok/s 17333
step   1550 | loss 1.2065 | lr 3.00e-04 | grad 1.89 | tok/s 18447
step   1560 | loss 1.5068 | lr 3.00e-04 | grad 1.61 | tok/s 17482
step   1570 | loss 1.2079 | lr 3.00e-04 | grad 1.68 | tok/s 18361
step   1580 | loss 1.6035 | lr 3.00e-04 | grad 4.41 | tok/s 18373
step   1590 | loss 1.4957 | lr 3.00e-04 | grad 1.71 | tok/s 17491
step   1600 | loss 0.8742 | lr 3.00e-04 | grad 2.05 | tok/s 18788
step   1610 | loss 1.0380 | lr 3.00e-04 | grad 1.40 | tok/s 17700
step   1620 | loss 1.3049 | lr 3.00e-04 | grad 2.69 | tok/s 17375
step   1630 | loss 1.2899 | lr 3.00e-04 | grad 1.37 | tok/s 18158
step   1640 | loss 1.2778 | lr 3.00e-04 | grad 1.51 | tok/s 17572
step   1650 | loss 1.4470 | lr 3.00e-04 | grad 2.25 | tok/s 16651
step   1660 | loss 1.2778 | lr 3.00e-04 | grad 1.30 | tok/s 18533
step   1670 | loss 1.3313 | lr 3.00e-04 | grad 2.77 | tok/s 17892
step   1680 | loss 1.5889 | lr 3.00e-04 | grad 1.29 | tok/s 17136
step   1690 | loss 1.3725 | lr 3.00e-04 | grad 2.45 | tok/s 17971
step   1700 | loss 1.4070 | lr 3.00e-04 | grad 1.62 | tok/s 17819
step   1710 | loss 1.3317 | lr 3.00e-04 | grad 1.66 | tok/s 17818
step   1720 | loss 1.4083 | lr 3.00e-04 | grad 2.28 | tok/s 18567
step   1730 | loss 1.0954 | lr 3.00e-04 | grad 2.05 | tok/s 18632
step   1740 | loss 1.2964 | lr 3.00e-04 | grad 2.06 | tok/s 17987
step   1750 | loss 1.4718 | lr 3.00e-04 | grad 1.95 | tok/s 17985
step   1760 | loss 1.4770 | lr 3.00e-04 | grad 1.61 | tok/s 17907
step   1770 | loss 1.3723 | lr 3.00e-04 | grad 1.72 | tok/s 17625
step   1780 | loss 1.4102 | lr 3.00e-04 | grad 1.41 | tok/s 18168
step   1790 | loss 1.3424 | lr 3.00e-04 | grad 2.41 | tok/s 18013
step   1800 | loss 1.4959 | lr 3.00e-04 | grad 1.72 | tok/s 17626
step   1810 | loss 1.3737 | lr 3.00e-04 | grad 3.00 | tok/s 17360
step   1820 | loss 1.3658 | lr 3.00e-04 | grad 5.19 | tok/s 17887
step   1830 | loss 1.3601 | lr 3.00e-04 | grad 3.23 | tok/s 18271
step   1840 | loss 1.3843 | lr 3.00e-04 | grad 1.43 | tok/s 17398
step   1850 | loss 1.2237 | lr 3.00e-04 | grad 1.50 | tok/s 18502
step   1860 | loss 1.2800 | lr 3.00e-04 | grad 1.98 | tok/s 17568
step   1870 | loss 1.2879 | lr 3.00e-04 | grad 1.31 | tok/s 17956
step   1880 | loss 1.1841 | lr 3.00e-04 | grad 2.20 | tok/s 17305
step   1890 | loss 1.4430 | lr 3.00e-04 | grad 1.54 | tok/s 16764
step   1900 | loss 1.3288 | lr 3.00e-04 | grad 1.69 | tok/s 17944
step   1910 | loss 1.3786 | lr 3.00e-04 | grad 1.60 | tok/s 17031
step   1920 | loss 1.3177 | lr 3.00e-04 | grad 1.48 | tok/s 18607
step   1930 | loss 1.3876 | lr 3.00e-04 | grad 2.81 | tok/s 17150
step   1940 | loss 1.3827 | lr 3.00e-04 | grad 1.77 | tok/s 18457
step   1950 | loss 1.7784 | lr 3.00e-04 | grad 2.84 | tok/s 16810
step   1960 | loss 1.3728 | lr 3.00e-04 | grad 3.28 | tok/s 18610
step   1970 | loss 1.3907 | lr 3.00e-04 | grad 2.09 | tok/s 18150
step   1980 | loss 1.4498 | lr 3.00e-04 | grad 1.78 | tok/s 17370
step   1990 | loss 1.4999 | lr 3.00e-04 | grad 1.77 | tok/s 17699
step   2000 | loss 1.4155 | lr 3.00e-04 | grad 2.00 | tok/s 17944
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4155.pt
step   2010 | loss 1.0835 | lr 3.00e-04 | grad 1.64 | tok/s 6572
step   2020 | loss 1.2408 | lr 3.00e-04 | grad 2.11 | tok/s 18378
step   2030 | loss 0.8876 | lr 3.00e-04 | grad 4.28 | tok/s 19030
step   2040 | loss 1.2662 | lr 3.00e-04 | grad 2.03 | tok/s 18822
step   2050 | loss 1.1717 | lr 3.00e-04 | grad 1.61 | tok/s 18129
step   2060 | loss 1.5283 | lr 3.00e-04 | grad 1.72 | tok/s 17669
step   2070 | loss 1.7142 | lr 3.00e-04 | grad 6.25 | tok/s 17801
step   2080 | loss 1.9578 | lr 3.00e-04 | grad 3.53 | tok/s 18753
step   2090 | loss 1.4867 | lr 3.00e-04 | grad 1.78 | tok/s 18371
step   2100 | loss 1.2696 | lr 3.00e-04 | grad 1.98 | tok/s 18402
step   2110 | loss 1.3558 | lr 3.00e-04 | grad 1.76 | tok/s 17480
step   2120 | loss 0.8169 | lr 3.00e-04 | grad 1.59 | tok/s 18965
step   2130 | loss 1.1471 | lr 3.00e-04 | grad 3.23 | tok/s 18064
step   2140 | loss 1.3507 | lr 3.00e-04 | grad 1.31 | tok/s 18191
step   2150 | loss 1.2197 | lr 3.00e-04 | grad 1.52 | tok/s 18664
step   2160 | loss 1.1131 | lr 3.00e-04 | grad 1.52 | tok/s 18683
step   2170 | loss 1.1770 | lr 3.00e-04 | grad 1.23 | tok/s 18702
step   2180 | loss 1.1254 | lr 3.00e-04 | grad 1.30 | tok/s 18692
step   2190 | loss 1.1472 | lr 3.00e-04 | grad 1.41 | tok/s 18688
step   2200 | loss 1.1129 | lr 3.00e-04 | grad 1.30 | tok/s 18664
step   2210 | loss 1.0861 | lr 3.00e-04 | grad 1.41 | tok/s 18683
step   2220 | loss 1.0729 | lr 3.00e-04 | grad 1.41 | tok/s 18670
step   2230 | loss 1.3236 | lr 3.00e-04 | grad 1.97 | tok/s 18327
step   2240 | loss 1.2566 | lr 3.00e-04 | grad 1.69 | tok/s 18046
step   2250 | loss 1.4174 | lr 3.00e-04 | grad 4.81 | tok/s 18672
step   2260 | loss 1.4778 | lr 3.00e-04 | grad 1.80 | tok/s 18096
step   2270 | loss 1.8744 | lr 3.00e-04 | grad 2.61 | tok/s 18497
step   2280 | loss 1.3349 | lr 3.00e-04 | grad 2.31 | tok/s 18689
step   2290 | loss 1.4082 | lr 3.00e-04 | grad 13.69 | tok/s 18021
step   2300 | loss 1.3582 | lr 3.00e-04 | grad 2.67 | tok/s 18350
step   2310 | loss 1.3314 | lr 3.00e-04 | grad 2.06 | tok/s 17612
step   2320 | loss 1.7399 | lr 3.00e-04 | grad 2.70 | tok/s 17560
step   2330 | loss 1.4671 | lr 3.00e-04 | grad 2.84 | tok/s 17702
step   2340 | loss 1.3429 | lr 3.00e-04 | grad 1.95 | tok/s 17446
step   2350 | loss 1.2936 | lr 3.00e-04 | grad 2.23 | tok/s 16727
step   2360 | loss 1.1897 | lr 3.00e-04 | grad 1.35 | tok/s 18694
step   2370 | loss 1.4339 | lr 3.00e-04 | grad 3.41 | tok/s 18318
step   2380 | loss 1.3262 | lr 3.00e-04 | grad 1.95 | tok/s 18704
step   2390 | loss 1.0729 | lr 3.00e-04 | grad 1.41 | tok/s 18667
step   2400 | loss 0.9947 | lr 3.00e-04 | grad 1.27 | tok/s 18673
step   2410 | loss 1.1157 | lr 3.00e-04 | grad 1.39 | tok/s 17960
step   2420 | loss 1.3803 | lr 3.00e-04 | grad 2.03 | tok/s 17300
step   2430 | loss 1.2544 | lr 3.00e-04 | grad 2.02 | tok/s 18276
step   2440 | loss 1.2179 | lr 3.00e-04 | grad 1.88 | tok/s 18087
step   2450 | loss 1.3974 | lr 3.00e-04 | grad 1.59 | tok/s 18032
step   2460 | loss 1.1321 | lr 3.00e-04 | grad 1.37 | tok/s 18586
step   2470 | loss 1.1087 | lr 3.00e-04 | grad 1.46 | tok/s 18422
step   2480 | loss 1.1646 | lr 3.00e-04 | grad 2.33 | tok/s 18544
step   2490 | loss 1.3102 | lr 3.00e-04 | grad 2.12 | tok/s 17694
step   2500 | loss 1.3983 | lr 3.00e-04 | grad 2.81 | tok/s 18456
step   2510 | loss 0.9809 | lr 3.00e-04 | grad 1.73 | tok/s 18641
step   2520 | loss 1.4120 | lr 3.00e-04 | grad 1.64 | tok/s 18404
step   2530 | loss 1.2182 | lr 3.00e-04 | grad 1.74 | tok/s 18018
step   2540 | loss 1.2934 | lr 3.00e-04 | grad 2.03 | tok/s 17966
step   2550 | loss 1.0856 | lr 3.00e-04 | grad 1.20 | tok/s 18641
step   2560 | loss 1.4340 | lr 3.00e-04 | grad 2.25 | tok/s 17374
step   2570 | loss 1.2320 | lr 3.00e-04 | grad 2.06 | tok/s 17884
step   2580 | loss 1.2674 | lr 3.00e-04 | grad 1.97 | tok/s 17319
step   2590 | loss 1.3076 | lr 3.00e-04 | grad 1.69 | tok/s 17745
step   2600 | loss 1.5389 | lr 3.00e-04 | grad 3.81 | tok/s 17385
step   2610 | loss 1.0832 | lr 3.00e-04 | grad 2.05 | tok/s 18512
step   2620 | loss 1.4425 | lr 3.00e-04 | grad 1.55 | tok/s 18022
step   2630 | loss 1.2895 | lr 3.00e-04 | grad 1.51 | tok/s 18453
step   2640 | loss 1.4620 | lr 3.00e-04 | grad 2.25 | tok/s 17956
step   2650 | loss 1.3178 | lr 3.00e-04 | grad 1.59 | tok/s 18330
step   2660 | loss 1.2502 | lr 3.00e-04 | grad 2.03 | tok/s 18038
step   2670 | loss 1.3245 | lr 3.00e-04 | grad 1.66 | tok/s 17325

Training complete! Final step: 2671
