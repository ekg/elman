Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_72/levelfla-gdn_100m_20260127_072502
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 503,382,782 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.0895 | lr 3.00e-04 | grad 20.00 | tok/s 6804
step     20 | loss 2.6939 | lr 3.00e-04 | grad 10.69 | tok/s 21107
step     30 | loss 2.5296 | lr 3.00e-04 | grad 5.22 | tok/s 21311
step     40 | loss 2.3743 | lr 3.00e-04 | grad 5.03 | tok/s 20384
step     50 | loss 2.8784 | lr 3.00e-04 | grad 13.62 | tok/s 20686
step     60 | loss 1.9579 | lr 3.00e-04 | grad 5.56 | tok/s 21322
step     70 | loss 1.8024 | lr 3.00e-04 | grad 5.25 | tok/s 21508
step     80 | loss 5.4116 | lr 3.00e-04 | grad 47.75 | tok/s 21631
step     90 | loss 4.7484 | lr 3.00e-04 | grad 7.03 | tok/s 22012
step    100 | loss 3.6866 | lr 3.00e-04 | grad 9.69 | tok/s 21944
step    110 | loss 3.1246 | lr 3.00e-04 | grad 20.88 | tok/s 21883
step    120 | loss 2.9852 | lr 3.00e-04 | grad 11.50 | tok/s 21824
step    130 | loss 2.8902 | lr 3.00e-04 | grad 16.00 | tok/s 21794
step    140 | loss 2.5230 | lr 3.00e-04 | grad 8.81 | tok/s 21817
step    150 | loss 2.5432 | lr 3.00e-04 | grad 8.75 | tok/s 21748
step    160 | loss 2.1945 | lr 3.00e-04 | grad 8.38 | tok/s 21693
step    170 | loss 2.2264 | lr 3.00e-04 | grad 8.81 | tok/s 21703
step    180 | loss 2.0471 | lr 3.00e-04 | grad 5.91 | tok/s 21655
step    190 | loss 2.2017 | lr 3.00e-04 | grad 4.75 | tok/s 21653
step    200 | loss 1.9093 | lr 3.00e-04 | grad 4.47 | tok/s 21629
step    210 | loss 1.9256 | lr 3.00e-04 | grad 7.84 | tok/s 21614
step    220 | loss 2.0280 | lr 3.00e-04 | grad 3.02 | tok/s 21328
step    230 | loss 2.1936 | lr 3.00e-04 | grad 4.56 | tok/s 21129
step    240 | loss 2.2008 | lr 3.00e-04 | grad 4.50 | tok/s 20047
step    250 | loss 1.9904 | lr 3.00e-04 | grad 2.44 | tok/s 20572
step    260 | loss 1.4659 | lr 3.00e-04 | grad 2.94 | tok/s 21185
step    270 | loss 1.9919 | lr 3.00e-04 | grad 2.72 | tok/s 20930
step    280 | loss 2.1666 | lr 3.00e-04 | grad 4.41 | tok/s 20514
step    290 | loss 1.4593 | lr 3.00e-04 | grad 3.73 | tok/s 21623
step    300 | loss 0.5977 | lr 3.00e-04 | grad 4.03 | tok/s 21620
step    310 | loss 2.3991 | lr 3.00e-04 | grad 3.58 | tok/s 21201
step    320 | loss 1.8403 | lr 3.00e-04 | grad 6.50 | tok/s 20784
step    330 | loss 1.8323 | lr 3.00e-04 | grad 2.81 | tok/s 20093
step    340 | loss 2.1378 | lr 3.00e-04 | grad 2.53 | tok/s 20391
step    350 | loss 1.7714 | lr 3.00e-04 | grad 5.00 | tok/s 20895
step    360 | loss 1.1158 | lr 3.00e-04 | grad 8.56 | tok/s 21342
step    370 | loss 1.6972 | lr 3.00e-04 | grad 2.31 | tok/s 19412
step    380 | loss 1.6680 | lr 3.00e-04 | grad 2.59 | tok/s 20653
step    390 | loss 1.4500 | lr 3.00e-04 | grad 1.90 | tok/s 21499
step    400 | loss 1.4106 | lr 3.00e-04 | grad 2.33 | tok/s 21311
step    410 | loss 1.2081 | lr 3.00e-04 | grad 1.95 | tok/s 20839
step    420 | loss 1.7047 | lr 3.00e-04 | grad 4.09 | tok/s 19940
step    430 | loss 2.0166 | lr 3.00e-04 | grad 2.61 | tok/s 21205
step    440 | loss 2.0761 | lr 3.00e-04 | grad 3.48 | tok/s 20046
step    450 | loss 1.7577 | lr 3.00e-04 | grad 2.39 | tok/s 20746
step    460 | loss 1.6195 | lr 3.00e-04 | grad 2.19 | tok/s 20301
step    470 | loss 1.7253 | lr 3.00e-04 | grad 2.23 | tok/s 20924
step    480 | loss 2.1300 | lr 3.00e-04 | grad 5.91 | tok/s 20946
step    490 | loss 1.6712 | lr 3.00e-04 | grad 2.14 | tok/s 19794
step    500 | loss 1.5693 | lr 3.00e-04 | grad 3.34 | tok/s 21071
step    510 | loss 1.5922 | lr 3.00e-04 | grad 2.08 | tok/s 21349
step    520 | loss 1.5679 | lr 3.00e-04 | grad 1.85 | tok/s 21306
step    530 | loss 1.8065 | lr 3.00e-04 | grad 1.98 | tok/s 20568
step    540 | loss 1.6211 | lr 3.00e-04 | grad 1.96 | tok/s 20554
step    550 | loss 1.4824 | lr 3.00e-04 | grad 2.39 | tok/s 20147
step    560 | loss 1.6115 | lr 3.00e-04 | grad 2.34 | tok/s 19601
step    570 | loss 1.5439 | lr 3.00e-04 | grad 2.73 | tok/s 20145
step    580 | loss 1.4541 | lr 3.00e-04 | grad 2.02 | tok/s 20076
step    590 | loss 1.7565 | lr 3.00e-04 | grad 2.69 | tok/s 20580
step    600 | loss 1.7019 | lr 3.00e-04 | grad 2.03 | tok/s 19901
step    610 | loss 1.5319 | lr 3.00e-04 | grad 2.00 | tok/s 20878
step    620 | loss 1.4616 | lr 3.00e-04 | grad 2.08 | tok/s 19803
step    630 | loss 1.5498 | lr 3.00e-04 | grad 3.72 | tok/s 19993
step    640 | loss 1.6883 | lr 3.00e-04 | grad 1.94 | tok/s 20507
step    650 | loss 1.5864 | lr 3.00e-04 | grad 2.25 | tok/s 20601
step    660 | loss 1.5961 | lr 3.00e-04 | grad 1.69 | tok/s 20712
step    670 | loss 1.7959 | lr 3.00e-04 | grad 8.12 | tok/s 20830
step    680 | loss 1.6390 | lr 3.00e-04 | grad 2.12 | tok/s 20419
step    690 | loss 1.6931 | lr 3.00e-04 | grad 2.89 | tok/s 21121
step    700 | loss 1.3405 | lr 3.00e-04 | grad 2.45 | tok/s 21485
step    710 | loss 1.4913 | lr 3.00e-04 | grad 2.05 | tok/s 20129
step    720 | loss 1.3724 | lr 3.00e-04 | grad 2.88 | tok/s 19844
step    730 | loss 1.2277 | lr 3.00e-04 | grad 2.42 | tok/s 21484
step    740 | loss 1.4225 | lr 3.00e-04 | grad 1.99 | tok/s 21216
step    750 | loss 1.1278 | lr 3.00e-04 | grad 2.27 | tok/s 21532
step    760 | loss 1.0359 | lr 3.00e-04 | grad 1.84 | tok/s 21511
step    770 | loss 0.9880 | lr 3.00e-04 | grad 1.76 | tok/s 21528
step    780 | loss 0.9299 | lr 3.00e-04 | grad 1.54 | tok/s 21526
step    790 | loss 1.0515 | lr 3.00e-04 | grad 2.70 | tok/s 20896
step    800 | loss 1.7168 | lr 3.00e-04 | grad 5.06 | tok/s 20786
step    810 | loss 1.6202 | lr 3.00e-04 | grad 1.68 | tok/s 20674
step    820 | loss 1.5873 | lr 3.00e-04 | grad 2.98 | tok/s 19905
step    830 | loss 1.3984 | lr 3.00e-04 | grad 2.09 | tok/s 21345
step    840 | loss 1.3008 | lr 3.00e-04 | grad 1.92 | tok/s 21508
step    850 | loss 1.4623 | lr 3.00e-04 | grad 1.74 | tok/s 21444
step    860 | loss 1.3824 | lr 3.00e-04 | grad 3.56 | tok/s 21173
step    870 | loss 1.4112 | lr 3.00e-04 | grad 2.28 | tok/s 20433
step    880 | loss 1.5529 | lr 3.00e-04 | grad 2.73 | tok/s 20556
step    890 | loss 1.5740 | lr 3.00e-04 | grad 2.53 | tok/s 20812
step    900 | loss 1.4618 | lr 3.00e-04 | grad 2.25 | tok/s 20845
step    910 | loss 1.3529 | lr 3.00e-04 | grad 3.16 | tok/s 20407
step    920 | loss 1.4504 | lr 3.00e-04 | grad 3.06 | tok/s 21184
step    930 | loss 1.4942 | lr 3.00e-04 | grad 2.70 | tok/s 20224
step    940 | loss 1.3008 | lr 3.00e-04 | grad 1.59 | tok/s 21304
step    950 | loss 1.4163 | lr 3.00e-04 | grad 2.00 | tok/s 21401
step    960 | loss 1.2583 | lr 3.00e-04 | grad 2.20 | tok/s 21454
step    970 | loss 1.6236 | lr 3.00e-04 | grad 3.00 | tok/s 20167
step    980 | loss 1.5316 | lr 3.00e-04 | grad 1.93 | tok/s 20715
step    990 | loss 1.3676 | lr 3.00e-04 | grad 1.77 | tok/s 21060
step   1000 | loss 1.7311 | lr 3.00e-04 | grad 9.88 | tok/s 20221
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7311.pt
step   1010 | loss 1.5606 | lr 3.00e-04 | grad 2.95 | tok/s 7403
step   1020 | loss 1.5475 | lr 3.00e-04 | grad 1.62 | tok/s 20006
step   1030 | loss 1.3721 | lr 3.00e-04 | grad 1.90 | tok/s 20730
step   1040 | loss 1.4136 | lr 3.00e-04 | grad 1.81 | tok/s 21375
step   1050 | loss 1.5117 | lr 3.00e-04 | grad 2.89 | tok/s 19817
step   1060 | loss 1.6243 | lr 3.00e-04 | grad 3.62 | tok/s 21431
step   1070 | loss 1.5504 | lr 3.00e-04 | grad 2.52 | tok/s 21358
step   1080 | loss 1.3075 | lr 3.00e-04 | grad 1.76 | tok/s 19330
step   1090 | loss 1.0303 | lr 3.00e-04 | grad 4.56 | tok/s 21380
step   1100 | loss 1.3408 | lr 3.00e-04 | grad 3.30 | tok/s 20696
step   1110 | loss 1.3746 | lr 3.00e-04 | grad 1.80 | tok/s 21675
step   1120 | loss 1.2565 | lr 3.00e-04 | grad 2.03 | tok/s 21670
step   1130 | loss 1.2149 | lr 3.00e-04 | grad 1.55 | tok/s 21651
step   1140 | loss 1.2034 | lr 3.00e-04 | grad 1.85 | tok/s 21655
step   1150 | loss 1.2119 | lr 3.00e-04 | grad 1.59 | tok/s 21650
step   1160 | loss 1.1401 | lr 3.00e-04 | grad 1.73 | tok/s 21647
step   1170 | loss 1.1642 | lr 3.00e-04 | grad 1.90 | tok/s 21702
step   1180 | loss 1.2687 | lr 3.00e-04 | grad 1.43 | tok/s 21685
step   1190 | loss 1.1402 | lr 3.00e-04 | grad 1.82 | tok/s 21671
step   1200 | loss 1.1310 | lr 3.00e-04 | grad 1.76 | tok/s 21658
step   1210 | loss 1.1908 | lr 3.00e-04 | grad 1.80 | tok/s 21664
step   1220 | loss 1.2104 | lr 3.00e-04 | grad 2.05 | tok/s 21690
step   1230 | loss 1.1707 | lr 3.00e-04 | grad 1.65 | tok/s 21700
step   1240 | loss 1.1390 | lr 3.00e-04 | grad 1.30 | tok/s 21701
step   1250 | loss 1.6211 | lr 3.00e-04 | grad 2.95 | tok/s 20571
step   1260 | loss 1.3053 | lr 3.00e-04 | grad 29.00 | tok/s 20379
step   1270 | loss 1.5606 | lr 3.00e-04 | grad 4.84 | tok/s 20280
step   1280 | loss 1.5315 | lr 3.00e-04 | grad 1.80 | tok/s 20877
step   1290 | loss 1.3878 | lr 3.00e-04 | grad 1.67 | tok/s 20757
step   1300 | loss 1.4247 | lr 3.00e-04 | grad 2.12 | tok/s 20922
step   1310 | loss 1.3764 | lr 3.00e-04 | grad 2.42 | tok/s 21225
step   1320 | loss 1.4942 | lr 3.00e-04 | grad 2.12 | tok/s 21305
step   1330 | loss 1.4937 | lr 3.00e-04 | grad 2.06 | tok/s 21330
step   1340 | loss 1.3790 | lr 3.00e-04 | grad 8.12 | tok/s 20354
step   1350 | loss 1.5842 | lr 3.00e-04 | grad 2.27 | tok/s 19696
step   1360 | loss 1.3908 | lr 3.00e-04 | grad 2.19 | tok/s 20896
step   1370 | loss 1.3484 | lr 3.00e-04 | grad 1.48 | tok/s 20657
step   1380 | loss 1.4961 | lr 3.00e-04 | grad 2.19 | tok/s 19845
step   1390 | loss 1.4206 | lr 3.00e-04 | grad 1.55 | tok/s 21059
step   1400 | loss 1.2905 | lr 3.00e-04 | grad 1.61 | tok/s 20318
step   1410 | loss 1.3421 | lr 3.00e-04 | grad 2.80 | tok/s 20384
step   1420 | loss 1.5296 | lr 3.00e-04 | grad 5.25 | tok/s 20423
step   1430 | loss 1.2734 | lr 3.00e-04 | grad 1.71 | tok/s 20780
step   1440 | loss 1.0807 | lr 3.00e-04 | grad 1.72 | tok/s 21462
step   1450 | loss 1.0931 | lr 3.00e-04 | grad 4.03 | tok/s 21601
step   1460 | loss 1.4968 | lr 3.00e-04 | grad 1.82 | tok/s 20387
step   1470 | loss 1.4264 | lr 3.00e-04 | grad 1.68 | tok/s 21111
step   1480 | loss 1.6663 | lr 3.00e-04 | grad 3.97 | tok/s 21229
step   1490 | loss 1.4473 | lr 3.00e-04 | grad 1.62 | tok/s 21551
step   1500 | loss 1.2724 | lr 3.00e-04 | grad 1.62 | tok/s 21660
step   1510 | loss 1.3945 | lr 3.00e-04 | grad 1.66 | tok/s 21421
step   1520 | loss 1.3349 | lr 3.00e-04 | grad 3.73 | tok/s 20957
step   1530 | loss 1.3674 | lr 3.00e-04 | grad 1.93 | tok/s 21458
step   1540 | loss 1.4824 | lr 3.00e-04 | grad 2.12 | tok/s 20207
step   1550 | loss 1.2140 | lr 3.00e-04 | grad 2.05 | tok/s 21506
step   1560 | loss 1.4787 | lr 3.00e-04 | grad 2.12 | tok/s 20414
step   1570 | loss 1.2047 | lr 3.00e-04 | grad 1.97 | tok/s 21666
step   1580 | loss 1.5526 | lr 3.00e-04 | grad 3.88 | tok/s 21164
step   1590 | loss 1.4914 | lr 3.00e-04 | grad 2.14 | tok/s 20342
step   1600 | loss 0.9431 | lr 3.00e-04 | grad 1.79 | tok/s 21759
step   1610 | loss 0.9633 | lr 3.00e-04 | grad 1.99 | tok/s 21096
step   1620 | loss 1.3115 | lr 3.00e-04 | grad 2.33 | tok/s 19753
step   1630 | loss 1.2533 | lr 3.00e-04 | grad 2.30 | tok/s 21083
step   1640 | loss 1.2323 | lr 3.00e-04 | grad 1.80 | tok/s 20609
step   1650 | loss 1.4101 | lr 3.00e-04 | grad 2.27 | tok/s 19762
step   1660 | loss 1.3264 | lr 3.00e-04 | grad 1.51 | tok/s 21068
step   1670 | loss 1.2565 | lr 3.00e-04 | grad 7.66 | tok/s 20993
step   1680 | loss 1.5965 | lr 3.00e-04 | grad 1.73 | tok/s 20203
step   1690 | loss 1.3569 | lr 3.00e-04 | grad 3.58 | tok/s 19150
step   1700 | loss 1.3731 | lr 3.00e-04 | grad 2.03 | tok/s 21009
step   1710 | loss 1.3047 | lr 3.00e-04 | grad 1.85 | tok/s 20643
step   1720 | loss 1.3896 | lr 3.00e-04 | grad 2.56 | tok/s 21467
step   1730 | loss 1.1003 | lr 3.00e-04 | grad 2.47 | tok/s 21702
step   1740 | loss 1.2139 | lr 3.00e-04 | grad 2.16 | tok/s 21146
step   1750 | loss 1.4915 | lr 3.00e-04 | grad 2.27 | tok/s 20791
step   1760 | loss 1.4373 | lr 3.00e-04 | grad 1.89 | tok/s 20854
step   1770 | loss 1.3447 | lr 3.00e-04 | grad 2.05 | tok/s 20512
step   1780 | loss 1.4191 | lr 3.00e-04 | grad 1.73 | tok/s 21316
step   1790 | loss 1.2978 | lr 3.00e-04 | grad 1.40 | tok/s 20781
step   1800 | loss 1.5167 | lr 3.00e-04 | grad 1.93 | tok/s 20925
step   1810 | loss 1.3212 | lr 3.00e-04 | grad 1.91 | tok/s 20208
step   1820 | loss 1.3637 | lr 3.00e-04 | grad 5.19 | tok/s 20470
step   1830 | loss 1.3005 | lr 3.00e-04 | grad 1.94 | tok/s 21313
step   1840 | loss 1.4100 | lr 3.00e-04 | grad 2.20 | tok/s 20425
step   1850 | loss 1.2140 | lr 3.00e-04 | grad 1.48 | tok/s 21326
step   1860 | loss 1.2362 | lr 3.00e-04 | grad 2.16 | tok/s 20652
step   1870 | loss 1.3127 | lr 3.00e-04 | grad 2.66 | tok/s 20758
step   1880 | loss 1.1307 | lr 3.00e-04 | grad 1.80 | tok/s 20333
step   1890 | loss 1.4040 | lr 3.00e-04 | grad 1.58 | tok/s 19331
step   1900 | loss 1.3240 | lr 3.00e-04 | grad 2.16 | tok/s 20898
step   1910 | loss 1.3674 | lr 3.00e-04 | grad 2.31 | tok/s 19843
step   1920 | loss 1.3194 | lr 3.00e-04 | grad 1.73 | tok/s 21693
step   1930 | loss 1.3721 | lr 3.00e-04 | grad 2.00 | tok/s 20376
step   1940 | loss 1.3607 | lr 3.00e-04 | grad 1.84 | tok/s 21168
step   1950 | loss 1.7572 | lr 3.00e-04 | grad 4.06 | tok/s 21481
step   1960 | loss 1.3522 | lr 3.00e-04 | grad 4.03 | tok/s 21695
step   1970 | loss 1.3958 | lr 3.00e-04 | grad 2.14 | tok/s 21164
step   1980 | loss 1.4310 | lr 3.00e-04 | grad 1.80 | tok/s 20269
step   1990 | loss 1.4426 | lr 3.00e-04 | grad 5.81 | tok/s 20632
step   2000 | loss 1.3967 | lr 3.00e-04 | grad 1.80 | tok/s 20887
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3967.pt
step   2010 | loss 0.9879 | lr 3.00e-04 | grad 1.52 | tok/s 7892
step   2020 | loss 1.2101 | lr 3.00e-04 | grad 1.85 | tok/s 20871
step   2030 | loss 1.0152 | lr 3.00e-04 | grad 0.92 | tok/s 22082
step   2040 | loss 1.1553 | lr 3.00e-04 | grad 1.90 | tok/s 21949
step   2050 | loss 1.1098 | lr 3.00e-04 | grad 2.08 | tok/s 21466
step   2060 | loss 1.4446 | lr 3.00e-04 | grad 2.17 | tok/s 20253
step   2070 | loss 1.5730 | lr 3.00e-04 | grad 2.22 | tok/s 20993
step   2080 | loss 2.0691 | lr 3.00e-04 | grad 4.12 | tok/s 21681
step   2090 | loss 1.5653 | lr 3.00e-04 | grad 4.19 | tok/s 21719
step   2100 | loss 1.2498 | lr 3.00e-04 | grad 2.34 | tok/s 21229
step   2110 | loss 1.4014 | lr 3.00e-04 | grad 16.00 | tok/s 20821
step   2120 | loss 0.8570 | lr 3.00e-04 | grad 2.70 | tok/s 21615
step   2130 | loss 0.9478 | lr 3.00e-04 | grad 3.09 | tok/s 21591
step   2140 | loss 1.4292 | lr 3.00e-04 | grad 1.57 | tok/s 20808
step   2150 | loss 1.2080 | lr 3.00e-04 | grad 1.91 | tok/s 21837
step   2160 | loss 1.1134 | lr 3.00e-04 | grad 1.34 | tok/s 21752
step   2170 | loss 1.1615 | lr 3.00e-04 | grad 1.34 | tok/s 21861
step   2180 | loss 1.1187 | lr 3.00e-04 | grad 1.72 | tok/s 21841
step   2190 | loss 1.1319 | lr 3.00e-04 | grad 1.28 | tok/s 21868
step   2200 | loss 1.1186 | lr 3.00e-04 | grad 1.48 | tok/s 21845
step   2210 | loss 1.0722 | lr 3.00e-04 | grad 1.28 | tok/s 21856
step   2220 | loss 1.0620 | lr 3.00e-04 | grad 1.30 | tok/s 21806
step   2230 | loss 1.2670 | lr 3.00e-04 | grad 1.59 | tok/s 21457
step   2240 | loss 1.2594 | lr 3.00e-04 | grad 1.66 | tok/s 21761
step   2250 | loss 1.3858 | lr 3.00e-04 | grad 2.84 | tok/s 21045
step   2260 | loss 1.4306 | lr 3.00e-04 | grad 1.73 | tok/s 21284
step   2270 | loss 1.8079 | lr 3.00e-04 | grad 4.25 | tok/s 21623
step   2280 | loss 1.3883 | lr 3.00e-04 | grad 2.22 | tok/s 21560
step   2290 | loss 1.2052 | lr 3.00e-04 | grad 2.39 | tok/s 21039
step   2300 | loss 1.5480 | lr 3.00e-04 | grad 4.00 | tok/s 21516
step   2310 | loss 1.2467 | lr 3.00e-04 | grad 1.48 | tok/s 20423
step   2320 | loss 1.4871 | lr 3.00e-04 | grad 4.47 | tok/s 20523
step   2330 | loss 1.7091 | lr 3.00e-04 | grad 1.92 | tok/s 20884
step   2340 | loss 1.3265 | lr 3.00e-04 | grad 5.44 | tok/s 20290
step   2350 | loss 1.2440 | lr 3.00e-04 | grad 3.88 | tok/s 21286
step   2360 | loss 1.2239 | lr 3.00e-04 | grad 2.14 | tok/s 21548
step   2370 | loss 1.3324 | lr 3.00e-04 | grad 3.02 | tok/s 21302
step   2380 | loss 1.3741 | lr 3.00e-04 | grad 2.14 | tok/s 21792
step   2390 | loss 1.0929 | lr 3.00e-04 | grad 1.62 | tok/s 21737
step   2400 | loss 1.0263 | lr 3.00e-04 | grad 1.47 | tok/s 21758
step   2410 | loss 1.0087 | lr 3.00e-04 | grad 1.73 | tok/s 21117
step   2420 | loss 1.3652 | lr 3.00e-04 | grad 3.59 | tok/s 20409
step   2430 | loss 1.3093 | lr 3.00e-04 | grad 1.78 | tok/s 20761
step   2440 | loss 1.1219 | lr 3.00e-04 | grad 3.28 | tok/s 21356
step   2450 | loss 1.3630 | lr 3.00e-04 | grad 1.94 | tok/s 20783
step   2460 | loss 1.2241 | lr 3.00e-04 | grad 1.91 | tok/s 21568
step   2470 | loss 1.0547 | lr 3.00e-04 | grad 2.11 | tok/s 21528
step   2480 | loss 1.1751 | lr 3.00e-04 | grad 1.42 | tok/s 21760
step   2490 | loss 1.2231 | lr 3.00e-04 | grad 1.62 | tok/s 20633
step   2500 | loss 1.4363 | lr 3.00e-04 | grad 2.16 | tok/s 21297
step   2510 | loss 1.0314 | lr 3.00e-04 | grad 2.45 | tok/s 21771
step   2520 | loss 1.2794 | lr 3.00e-04 | grad 4.94 | tok/s 21700
step   2530 | loss 1.2556 | lr 3.00e-04 | grad 1.55 | tok/s 20996
step   2540 | loss 1.2889 | lr 3.00e-04 | grad 2.67 | tok/s 20848
step   2550 | loss 1.1019 | lr 3.00e-04 | grad 1.52 | tok/s 21648
step   2560 | loss 1.3203 | lr 3.00e-04 | grad 6.25 | tok/s 20347
step   2570 | loss 1.2900 | lr 3.00e-04 | grad 1.62 | tok/s 21175
step   2580 | loss 1.2538 | lr 3.00e-04 | grad 2.22 | tok/s 19910
step   2590 | loss 1.2125 | lr 3.00e-04 | grad 2.09 | tok/s 20990
step   2600 | loss 1.4576 | lr 3.00e-04 | grad 4.19 | tok/s 20158
step   2610 | loss 1.1794 | lr 3.00e-04 | grad 2.25 | tok/s 21618
step   2620 | loss 1.4241 | lr 3.00e-04 | grad 1.87 | tok/s 20900
step   2630 | loss 1.3318 | lr 3.00e-04 | grad 1.66 | tok/s 21555
step   2640 | loss 1.3425 | lr 3.00e-04 | grad 2.00 | tok/s 20989
step   2650 | loss 1.3939 | lr 3.00e-04 | grad 2.72 | tok/s 21761
step   2660 | loss 1.2279 | lr 3.00e-04 | grad 1.95 | tok/s 21030
step   2670 | loss 1.3076 | lr 3.00e-04 | grad 2.47 | tok/s 20278
step   2680 | loss 1.4150 | lr 3.00e-04 | grad 9.25 | tok/s 20659
step   2690 | loss 1.1851 | lr 3.00e-04 | grad 1.52 | tok/s 21628
step   2700 | loss 1.3314 | lr 3.00e-04 | grad 1.72 | tok/s 21018
step   2710 | loss 1.4044 | lr 3.00e-04 | grad 2.50 | tok/s 20712
step   2720 | loss 1.2410 | lr 3.00e-04 | grad 1.81 | tok/s 19848
step   2730 | loss 1.0722 | lr 3.00e-04 | grad 1.78 | tok/s 21354
step   2740 | loss 1.5259 | lr 3.00e-04 | grad 5.97 | tok/s 21092
step   2750 | loss 1.4720 | lr 3.00e-04 | grad 1.94 | tok/s 21628
step   2760 | loss 1.2262 | lr 3.00e-04 | grad 1.83 | tok/s 20115
step   2770 | loss 1.3834 | lr 3.00e-04 | grad 2.55 | tok/s 20740
step   2780 | loss 0.9771 | lr 3.00e-04 | grad 1.54 | tok/s 21783
step   2790 | loss 1.4850 | lr 3.00e-04 | grad 4.72 | tok/s 20300
step   2800 | loss 1.2965 | lr 3.00e-04 | grad 1.27 | tok/s 20888
step   2810 | loss 1.1476 | lr 3.00e-04 | grad 1.76 | tok/s 20837
step   2820 | loss 1.3150 | lr 3.00e-04 | grad 1.58 | tok/s 20085
step   2830 | loss 0.9628 | lr 3.00e-04 | grad 1.80 | tok/s 21393
step   2840 | loss 0.6061 | lr 3.00e-04 | grad 2.05 | tok/s 21734
step   2850 | loss 1.6066 | lr 3.00e-04 | grad 1.98 | tok/s 21064
step   2860 | loss 1.4840 | lr 3.00e-04 | grad 1.36 | tok/s 20930
step   2870 | loss 1.2644 | lr 3.00e-04 | grad 1.86 | tok/s 20529
step   2880 | loss 1.3771 | lr 3.00e-04 | grad 2.95 | tok/s 21145
step   2890 | loss 1.1258 | lr 3.00e-04 | grad 2.09 | tok/s 21710
step   2900 | loss 1.3285 | lr 3.00e-04 | grad 1.52 | tok/s 20889
step   2910 | loss 1.2487 | lr 3.00e-04 | grad 1.62 | tok/s 20896
step   2920 | loss 1.4117 | lr 3.00e-04 | grad 2.09 | tok/s 20277
step   2930 | loss 1.4333 | lr 3.00e-04 | grad 1.61 | tok/s 21228
step   2940 | loss 1.1962 | lr 3.00e-04 | grad 2.00 | tok/s 19557
step   2950 | loss 1.2645 | lr 3.00e-04 | grad 2.22 | tok/s 21013
step   2960 | loss 1.2038 | lr 3.00e-04 | grad 2.53 | tok/s 21230
step   2970 | loss 1.2017 | lr 3.00e-04 | grad 1.95 | tok/s 21346
step   2980 | loss 1.6058 | lr 3.00e-04 | grad 1.62 | tok/s 20670
step   2990 | loss 1.8258 | lr 3.00e-04 | grad 2.36 | tok/s 21166
step   3000 | loss 1.2444 | lr 3.00e-04 | grad 3.83 | tok/s 21234
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2444.pt
step   3010 | loss 0.9456 | lr 3.00e-04 | grad 14.19 | tok/s 7464
step   3020 | loss 1.2401 | lr 3.00e-04 | grad 1.66 | tok/s 20688
step   3030 | loss 1.3568 | lr 3.00e-04 | grad 2.23 | tok/s 20861
step   3040 | loss 1.3304 | lr 3.00e-04 | grad 1.85 | tok/s 21337

Training complete! Final step: 3049
