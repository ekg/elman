Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_116/levelfla-gdn_100m_20260127_082642
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 503,382,782 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1197 | lr 3.00e-04 | grad 20.88 | tok/s 6667
step     20 | loss 2.7238 | lr 3.00e-04 | grad 8.12 | tok/s 21639
step     30 | loss 2.5646 | lr 3.00e-04 | grad 5.62 | tok/s 21872
step     40 | loss 2.3861 | lr 3.00e-04 | grad 4.47 | tok/s 20960
step     50 | loss 3.0395 | lr 3.00e-04 | grad 19.62 | tok/s 21239
step     60 | loss 2.0205 | lr 3.00e-04 | grad 5.69 | tok/s 21914
step     70 | loss 1.8116 | lr 3.00e-04 | grad 5.31 | tok/s 22170
step     80 | loss 5.2491 | lr 3.00e-04 | grad 42.00 | tok/s 22248
step     90 | loss 4.5848 | lr 3.00e-04 | grad 6.38 | tok/s 22601
step    100 | loss 3.6057 | lr 3.00e-04 | grad 7.88 | tok/s 22576
step    110 | loss 3.1461 | lr 3.00e-04 | grad 15.75 | tok/s 22527
step    120 | loss 2.9335 | lr 3.00e-04 | grad 11.38 | tok/s 22455
step    130 | loss 2.7120 | lr 3.00e-04 | grad 13.00 | tok/s 22447
step    140 | loss 2.5010 | lr 3.00e-04 | grad 14.88 | tok/s 22432
step    150 | loss 2.5214 | lr 3.00e-04 | grad 12.50 | tok/s 22433
step    160 | loss 2.1333 | lr 3.00e-04 | grad 9.44 | tok/s 22367
step    170 | loss 2.2255 | lr 3.00e-04 | grad 11.56 | tok/s 22338
step    180 | loss 2.0657 | lr 3.00e-04 | grad 5.19 | tok/s 22356
step    190 | loss 2.1932 | lr 3.00e-04 | grad 9.88 | tok/s 22284
step    200 | loss 1.9045 | lr 3.00e-04 | grad 4.69 | tok/s 22271
step    210 | loss 1.9043 | lr 3.00e-04 | grad 6.97 | tok/s 22301
step    220 | loss 2.0199 | lr 3.00e-04 | grad 2.94 | tok/s 22002
step    230 | loss 2.1588 | lr 3.00e-04 | grad 3.34 | tok/s 21741
step    240 | loss 2.1914 | lr 3.00e-04 | grad 4.03 | tok/s 20666
step    250 | loss 1.9907 | lr 3.00e-04 | grad 2.42 | tok/s 21221
step    260 | loss 1.4644 | lr 3.00e-04 | grad 2.92 | tok/s 21856
step    270 | loss 1.9940 | lr 3.00e-04 | grad 2.67 | tok/s 21607
step    280 | loss 2.1627 | lr 3.00e-04 | grad 4.72 | tok/s 21212
step    290 | loss 1.4713 | lr 3.00e-04 | grad 3.41 | tok/s 22360
step    300 | loss 0.5850 | lr 3.00e-04 | grad 3.38 | tok/s 22300
step    310 | loss 2.4108 | lr 3.00e-04 | grad 3.48 | tok/s 21865
step    320 | loss 1.8510 | lr 3.00e-04 | grad 6.34 | tok/s 21391
step    330 | loss 1.8361 | lr 3.00e-04 | grad 2.62 | tok/s 20706
step    340 | loss 2.1191 | lr 3.00e-04 | grad 2.47 | tok/s 20999
step    350 | loss 1.7714 | lr 3.00e-04 | grad 5.53 | tok/s 21510
step    360 | loss 1.1232 | lr 3.00e-04 | grad 11.75 | tok/s 21971
step    370 | loss 1.6989 | lr 3.00e-04 | grad 2.31 | tok/s 19985
step    380 | loss 1.6688 | lr 3.00e-04 | grad 2.52 | tok/s 21247
step    390 | loss 1.4464 | lr 3.00e-04 | grad 1.90 | tok/s 22177
step    400 | loss 1.4100 | lr 3.00e-04 | grad 2.30 | tok/s 21939
step    410 | loss 1.2043 | lr 3.00e-04 | grad 1.81 | tok/s 21497
step    420 | loss 1.7035 | lr 3.00e-04 | grad 4.06 | tok/s 20508
step    430 | loss 2.0182 | lr 3.00e-04 | grad 2.56 | tok/s 21855
step    440 | loss 2.0653 | lr 3.00e-04 | grad 3.47 | tok/s 20682
step    450 | loss 1.7708 | lr 3.00e-04 | grad 2.36 | tok/s 21327
step    460 | loss 1.6292 | lr 3.00e-04 | grad 2.22 | tok/s 20935
step    470 | loss 1.7261 | lr 3.00e-04 | grad 2.19 | tok/s 21533
step    480 | loss 2.1372 | lr 3.00e-04 | grad 6.12 | tok/s 21525
step    490 | loss 1.6745 | lr 3.00e-04 | grad 1.98 | tok/s 20402
step    500 | loss 1.5735 | lr 3.00e-04 | grad 3.33 | tok/s 21752
step    510 | loss 1.5946 | lr 3.00e-04 | grad 2.06 | tok/s 22069
step    520 | loss 1.5691 | lr 3.00e-04 | grad 1.85 | tok/s 21954
step    530 | loss 1.8118 | lr 3.00e-04 | grad 1.92 | tok/s 21238
step    540 | loss 1.6222 | lr 3.00e-04 | grad 2.00 | tok/s 21200
step    550 | loss 1.4848 | lr 3.00e-04 | grad 2.42 | tok/s 20735
step    560 | loss 1.6183 | lr 3.00e-04 | grad 2.28 | tok/s 20233
step    570 | loss 1.5564 | lr 3.00e-04 | grad 2.67 | tok/s 20795
step    580 | loss 1.4517 | lr 3.00e-04 | grad 1.99 | tok/s 20689
step    590 | loss 1.7562 | lr 3.00e-04 | grad 2.64 | tok/s 21186
step    600 | loss 1.7006 | lr 3.00e-04 | grad 1.95 | tok/s 20485
step    610 | loss 1.5359 | lr 3.00e-04 | grad 1.99 | tok/s 21519
step    620 | loss 1.4579 | lr 3.00e-04 | grad 1.97 | tok/s 20423
step    630 | loss 1.5526 | lr 3.00e-04 | grad 3.78 | tok/s 20596
step    640 | loss 1.6892 | lr 3.00e-04 | grad 1.92 | tok/s 21148
step    650 | loss 1.5935 | lr 3.00e-04 | grad 2.17 | tok/s 21205
step    660 | loss 1.5942 | lr 3.00e-04 | grad 1.73 | tok/s 21308
step    670 | loss 1.8027 | lr 3.00e-04 | grad 3.97 | tok/s 21449
step    680 | loss 1.6393 | lr 3.00e-04 | grad 2.17 | tok/s 21025
step    690 | loss 1.6896 | lr 3.00e-04 | grad 2.89 | tok/s 21740
step    700 | loss 1.3402 | lr 3.00e-04 | grad 2.48 | tok/s 22149
step    710 | loss 1.4871 | lr 3.00e-04 | grad 2.05 | tok/s 20714
step    720 | loss 1.3771 | lr 3.00e-04 | grad 2.91 | tok/s 20449
step    730 | loss 1.2244 | lr 3.00e-04 | grad 2.34 | tok/s 22117
step    740 | loss 1.4198 | lr 3.00e-04 | grad 1.91 | tok/s 21867
step    750 | loss 1.1250 | lr 3.00e-04 | grad 2.12 | tok/s 22194
step    760 | loss 1.0308 | lr 3.00e-04 | grad 1.78 | tok/s 22193
step    770 | loss 0.9856 | lr 3.00e-04 | grad 1.68 | tok/s 22213
step    780 | loss 0.9293 | lr 3.00e-04 | grad 1.47 | tok/s 22193
step    790 | loss 1.0472 | lr 3.00e-04 | grad 2.67 | tok/s 21522
step    800 | loss 1.7285 | lr 3.00e-04 | grad 4.94 | tok/s 21456
step    810 | loss 1.6230 | lr 3.00e-04 | grad 1.81 | tok/s 21333
step    820 | loss 1.5801 | lr 3.00e-04 | grad 3.02 | tok/s 20501
step    830 | loss 1.4156 | lr 3.00e-04 | grad 2.05 | tok/s 21979
step    840 | loss 1.3041 | lr 3.00e-04 | grad 1.92 | tok/s 22138
step    850 | loss 1.4510 | lr 3.00e-04 | grad 1.67 | tok/s 22033
step    860 | loss 1.3857 | lr 3.00e-04 | grad 3.64 | tok/s 21813
step    870 | loss 1.4100 | lr 3.00e-04 | grad 2.23 | tok/s 21031
step    880 | loss 1.5486 | lr 3.00e-04 | grad 2.44 | tok/s 21111
step    890 | loss 1.5762 | lr 3.00e-04 | grad 2.48 | tok/s 21404
step    900 | loss 1.4651 | lr 3.00e-04 | grad 2.16 | tok/s 21457
step    910 | loss 1.3472 | lr 3.00e-04 | grad 3.25 | tok/s 21000
step    920 | loss 1.4440 | lr 3.00e-04 | grad 2.98 | tok/s 21803
step    930 | loss 1.4898 | lr 3.00e-04 | grad 2.67 | tok/s 20857
step    940 | loss 1.3027 | lr 3.00e-04 | grad 1.59 | tok/s 21967
step    950 | loss 1.4213 | lr 3.00e-04 | grad 2.27 | tok/s 22072
step    960 | loss 1.2576 | lr 3.00e-04 | grad 2.28 | tok/s 22108
step    970 | loss 1.6137 | lr 3.00e-04 | grad 2.95 | tok/s 20806
step    980 | loss 1.5368 | lr 3.00e-04 | grad 2.06 | tok/s 21317
step    990 | loss 1.3628 | lr 3.00e-04 | grad 1.79 | tok/s 21719
step   1000 | loss 1.7243 | lr 3.00e-04 | grad 9.25 | tok/s 20869
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7243.pt
step   1010 | loss 1.5528 | lr 3.00e-04 | grad 2.94 | tok/s 6917
step   1020 | loss 1.5480 | lr 3.00e-04 | grad 1.64 | tok/s 20535
step   1030 | loss 1.3670 | lr 3.00e-04 | grad 1.93 | tok/s 21301
step   1040 | loss 1.4170 | lr 3.00e-04 | grad 1.93 | tok/s 21976
step   1050 | loss 1.5065 | lr 3.00e-04 | grad 2.80 | tok/s 20377
step   1060 | loss 1.6318 | lr 3.00e-04 | grad 3.47 | tok/s 21956
step   1070 | loss 1.5549 | lr 3.00e-04 | grad 2.56 | tok/s 21878
step   1080 | loss 1.3058 | lr 3.00e-04 | grad 1.74 | tok/s 19925
step   1090 | loss 1.0322 | lr 3.00e-04 | grad 5.25 | tok/s 21945
step   1100 | loss 1.3332 | lr 3.00e-04 | grad 3.23 | tok/s 21282
step   1110 | loss 1.3767 | lr 3.00e-04 | grad 1.89 | tok/s 22267
step   1120 | loss 1.2606 | lr 3.00e-04 | grad 2.16 | tok/s 22286
step   1130 | loss 1.2159 | lr 3.00e-04 | grad 1.59 | tok/s 22292
step   1140 | loss 1.2057 | lr 3.00e-04 | grad 1.88 | tok/s 22279
step   1150 | loss 1.2130 | lr 3.00e-04 | grad 1.55 | tok/s 22231
step   1160 | loss 1.1415 | lr 3.00e-04 | grad 1.70 | tok/s 22277
step   1170 | loss 1.1620 | lr 3.00e-04 | grad 1.82 | tok/s 22251
step   1180 | loss 1.2676 | lr 3.00e-04 | grad 1.45 | tok/s 22251
step   1190 | loss 1.1400 | lr 3.00e-04 | grad 1.79 | tok/s 22236
step   1200 | loss 1.1339 | lr 3.00e-04 | grad 1.88 | tok/s 22224
step   1210 | loss 1.1909 | lr 3.00e-04 | grad 1.79 | tok/s 22276
step   1220 | loss 1.2105 | lr 3.00e-04 | grad 1.84 | tok/s 22291
step   1230 | loss 1.1715 | lr 3.00e-04 | grad 1.62 | tok/s 22278
step   1240 | loss 1.1435 | lr 3.00e-04 | grad 1.30 | tok/s 22242
step   1250 | loss 1.6342 | lr 3.00e-04 | grad 2.83 | tok/s 21108
step   1260 | loss 1.2889 | lr 3.00e-04 | grad 3.05 | tok/s 20940
step   1270 | loss 1.5563 | lr 3.00e-04 | grad 4.88 | tok/s 20840
step   1280 | loss 1.5349 | lr 3.00e-04 | grad 1.98 | tok/s 21418
step   1290 | loss 1.3881 | lr 3.00e-04 | grad 1.64 | tok/s 21288
step   1300 | loss 1.4315 | lr 3.00e-04 | grad 2.08 | tok/s 21457
step   1310 | loss 1.3795 | lr 3.00e-04 | grad 2.36 | tok/s 21777
step   1320 | loss 1.4904 | lr 3.00e-04 | grad 2.06 | tok/s 21825
step   1330 | loss 1.4967 | lr 3.00e-04 | grad 2.06 | tok/s 21859
step   1340 | loss 1.3791 | lr 3.00e-04 | grad 8.31 | tok/s 20897
step   1350 | loss 1.5843 | lr 3.00e-04 | grad 2.25 | tok/s 20216
step   1360 | loss 1.3926 | lr 3.00e-04 | grad 2.22 | tok/s 21405
step   1370 | loss 1.3495 | lr 3.00e-04 | grad 1.40 | tok/s 21150
step   1380 | loss 1.4891 | lr 3.00e-04 | grad 2.17 | tok/s 20383
step   1390 | loss 1.4206 | lr 3.00e-04 | grad 1.48 | tok/s 21573
step   1400 | loss 1.2902 | lr 3.00e-04 | grad 1.55 | tok/s 20818
step   1410 | loss 1.3513 | lr 3.00e-04 | grad 2.77 | tok/s 20908
step   1420 | loss 1.5291 | lr 3.00e-04 | grad 4.84 | tok/s 20930
step   1430 | loss 1.2477 | lr 3.00e-04 | grad 1.70 | tok/s 21272
step   1440 | loss 1.0794 | lr 3.00e-04 | grad 1.77 | tok/s 21966
step   1450 | loss 1.0964 | lr 3.00e-04 | grad 3.94 | tok/s 22053
step   1460 | loss 1.4966 | lr 3.00e-04 | grad 1.81 | tok/s 20859
step   1470 | loss 1.4231 | lr 3.00e-04 | grad 1.62 | tok/s 21632
step   1480 | loss 1.6671 | lr 3.00e-04 | grad 4.12 | tok/s 21731
step   1490 | loss 1.4425 | lr 3.00e-04 | grad 1.59 | tok/s 22061
step   1500 | loss 1.2680 | lr 3.00e-04 | grad 1.59 | tok/s 22167
step   1510 | loss 1.3912 | lr 3.00e-04 | grad 1.60 | tok/s 21892
step   1520 | loss 1.3382 | lr 3.00e-04 | grad 3.77 | tok/s 21458
step   1530 | loss 1.3648 | lr 3.00e-04 | grad 1.76 | tok/s 21972
step   1540 | loss 1.4902 | lr 3.00e-04 | grad 2.16 | tok/s 20681
step   1550 | loss 1.2112 | lr 3.00e-04 | grad 2.11 | tok/s 21995
step   1560 | loss 1.4780 | lr 3.00e-04 | grad 2.17 | tok/s 20874
step   1570 | loss 1.2091 | lr 3.00e-04 | grad 1.98 | tok/s 22146
step   1580 | loss 1.5611 | lr 3.00e-04 | grad 3.45 | tok/s 21658
step   1590 | loss 1.4869 | lr 3.00e-04 | grad 2.14 | tok/s 20837
step   1600 | loss 0.9461 | lr 3.00e-04 | grad 1.81 | tok/s 22241
step   1610 | loss 0.9614 | lr 3.00e-04 | grad 2.02 | tok/s 21589
step   1620 | loss 1.3092 | lr 3.00e-04 | grad 2.36 | tok/s 20185
step   1630 | loss 1.2520 | lr 3.00e-04 | grad 2.27 | tok/s 21521
step   1640 | loss 1.2340 | lr 3.00e-04 | grad 1.77 | tok/s 21068
step   1650 | loss 1.4084 | lr 3.00e-04 | grad 2.25 | tok/s 20185
step   1660 | loss 1.3223 | lr 3.00e-04 | grad 1.47 | tok/s 21512
step   1670 | loss 1.2546 | lr 3.00e-04 | grad 5.00 | tok/s 21484
step   1680 | loss 1.6013 | lr 3.00e-04 | grad 1.73 | tok/s 20621
step   1690 | loss 1.3623 | lr 3.00e-04 | grad 3.72 | tok/s 17296
step   1700 | loss 1.3786 | lr 3.00e-04 | grad 2.00 | tok/s 21462
step   1710 | loss 1.3161 | lr 3.00e-04 | grad 1.78 | tok/s 21062
step   1720 | loss 1.3986 | lr 3.00e-04 | grad 2.45 | tok/s 21929
step   1730 | loss 1.1045 | lr 3.00e-04 | grad 2.45 | tok/s 22165
step   1740 | loss 1.2196 | lr 3.00e-04 | grad 2.17 | tok/s 21623
step   1750 | loss 1.5038 | lr 3.00e-04 | grad 2.22 | tok/s 21261
step   1760 | loss 1.4364 | lr 3.00e-04 | grad 1.81 | tok/s 21355
step   1770 | loss 1.3433 | lr 3.00e-04 | grad 2.06 | tok/s 20962
step   1780 | loss 1.4237 | lr 3.00e-04 | grad 1.76 | tok/s 21776
step   1790 | loss 1.2951 | lr 3.00e-04 | grad 1.38 | tok/s 21205
step   1800 | loss 1.5142 | lr 3.00e-04 | grad 1.98 | tok/s 21403
step   1810 | loss 1.3199 | lr 3.00e-04 | grad 1.85 | tok/s 20654
step   1820 | loss 1.3567 | lr 3.00e-04 | grad 4.91 | tok/s 20887
step   1830 | loss 1.3005 | lr 3.00e-04 | grad 1.97 | tok/s 21752
step   1840 | loss 1.4106 | lr 3.00e-04 | grad 2.28 | tok/s 20868
step   1850 | loss 1.2182 | lr 3.00e-04 | grad 1.59 | tok/s 21833
step   1860 | loss 1.2363 | lr 3.00e-04 | grad 2.14 | tok/s 21110
step   1870 | loss 1.3141 | lr 3.00e-04 | grad 2.72 | tok/s 21206
step   1880 | loss 1.1352 | lr 3.00e-04 | grad 1.77 | tok/s 20786
step   1890 | loss 1.4096 | lr 3.00e-04 | grad 1.53 | tok/s 19768
step   1900 | loss 1.3215 | lr 3.00e-04 | grad 2.14 | tok/s 21292
step   1910 | loss 1.3677 | lr 3.00e-04 | grad 2.34 | tok/s 20228
step   1920 | loss 1.3210 | lr 3.00e-04 | grad 1.81 | tok/s 22156
step   1930 | loss 1.3693 | lr 3.00e-04 | grad 2.06 | tok/s 20782
step   1940 | loss 1.3556 | lr 3.00e-04 | grad 1.88 | tok/s 21593
step   1950 | loss 1.7314 | lr 3.00e-04 | grad 4.25 | tok/s 21939
step   1960 | loss 1.3559 | lr 3.00e-04 | grad 4.28 | tok/s 22132
step   1970 | loss 1.3929 | lr 3.00e-04 | grad 2.19 | tok/s 21605
step   1980 | loss 1.4204 | lr 3.00e-04 | grad 1.69 | tok/s 20710
step   1990 | loss 1.4502 | lr 3.00e-04 | grad 9.94 | tok/s 21080
step   2000 | loss 1.3900 | lr 3.00e-04 | grad 1.70 | tok/s 21357
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3900.pt
step   2010 | loss 1.0483 | lr 3.00e-04 | grad 2.00 | tok/s 7069
step   2020 | loss 1.2191 | lr 3.00e-04 | grad 2.47 | tok/s 21625
step   2030 | loss 0.9262 | lr 3.00e-04 | grad 1.55 | tok/s 22585
step   2040 | loss 1.2177 | lr 3.00e-04 | grad 2.02 | tok/s 22309
step   2050 | loss 1.1459 | lr 3.00e-04 | grad 2.02 | tok/s 21723
step   2060 | loss 1.4646 | lr 3.00e-04 | grad 3.27 | tok/s 20784
step   2070 | loss 1.6406 | lr 3.00e-04 | grad 8.25 | tok/s 21170
step   2080 | loss 2.0140 | lr 3.00e-04 | grad 2.94 | tok/s 22255
step   2090 | loss 1.5231 | lr 3.00e-04 | grad 1.82 | tok/s 21822
step   2100 | loss 1.2575 | lr 3.00e-04 | grad 1.62 | tok/s 21870
step   2110 | loss 1.3603 | lr 3.00e-04 | grad 2.34 | tok/s 20754
step   2120 | loss 0.8227 | lr 3.00e-04 | grad 3.92 | tok/s 22491
step   2130 | loss 1.0509 | lr 3.00e-04 | grad 4.12 | tok/s 21657
step   2140 | loss 1.3828 | lr 3.00e-04 | grad 1.83 | tok/s 21535
step   2150 | loss 1.2133 | lr 3.00e-04 | grad 1.86 | tok/s 22221
step   2160 | loss 1.1004 | lr 3.00e-04 | grad 1.34 | tok/s 22187
step   2170 | loss 1.1697 | lr 3.00e-04 | grad 1.44 | tok/s 22181
step   2180 | loss 1.1192 | lr 3.00e-04 | grad 1.32 | tok/s 22205
step   2190 | loss 1.1217 | lr 3.00e-04 | grad 1.41 | tok/s 22210
step   2200 | loss 1.1194 | lr 3.00e-04 | grad 1.39 | tok/s 22204
step   2210 | loss 1.0689 | lr 3.00e-04 | grad 1.50 | tok/s 22172
step   2220 | loss 1.0611 | lr 3.00e-04 | grad 1.57 | tok/s 22206
step   2230 | loss 1.2921 | lr 3.00e-04 | grad 1.49 | tok/s 21751
step   2240 | loss 1.2680 | lr 3.00e-04 | grad 1.98 | tok/s 22084
step   2250 | loss 1.3856 | lr 3.00e-04 | grad 3.47 | tok/s 21530
step   2260 | loss 1.4268 | lr 3.00e-04 | grad 1.52 | tok/s 21448
step   2270 | loss 1.8404 | lr 3.00e-04 | grad 5.38 | tok/s 22176
step   2280 | loss 1.3280 | lr 3.00e-04 | grad 1.97 | tok/s 21930
step   2290 | loss 1.2867 | lr 3.00e-04 | grad 8.62 | tok/s 21439
step   2300 | loss 1.3941 | lr 3.00e-04 | grad 2.73 | tok/s 21877
step   2310 | loss 1.3412 | lr 3.00e-04 | grad 1.80 | tok/s 20811
step   2320 | loss 1.5971 | lr 3.00e-04 | grad 4.09 | tok/s 20880
step   2330 | loss 1.5642 | lr 3.00e-04 | grad 1.55 | tok/s 21260
step   2340 | loss 1.3101 | lr 3.00e-04 | grad 2.11 | tok/s 20588
step   2350 | loss 1.2955 | lr 3.00e-04 | grad 2.28 | tok/s 21599
step   2360 | loss 1.2083 | lr 3.00e-04 | grad 1.72 | tok/s 22139
step   2370 | loss 1.3406 | lr 3.00e-04 | grad 2.70 | tok/s 21762
step   2380 | loss 1.3716 | lr 3.00e-04 | grad 3.11 | tok/s 22228
step   2390 | loss 1.0643 | lr 3.00e-04 | grad 1.52 | tok/s 22165
step   2400 | loss 0.9977 | lr 3.00e-04 | grad 1.32 | tok/s 22152
step   2410 | loss 1.0637 | lr 3.00e-04 | grad 2.03 | tok/s 21282
step   2420 | loss 1.3550 | lr 3.00e-04 | grad 1.80 | tok/s 20999
step   2430 | loss 1.2954 | lr 3.00e-04 | grad 1.78 | tok/s 21157
step   2440 | loss 1.1582 | lr 3.00e-04 | grad 2.14 | tok/s 21627
step   2450 | loss 1.3695 | lr 3.00e-04 | grad 1.59 | tok/s 21201
step   2460 | loss 1.1779 | lr 3.00e-04 | grad 1.75 | tok/s 22015
step   2470 | loss 1.0762 | lr 3.00e-04 | grad 1.63 | tok/s 21894
step   2480 | loss 1.1464 | lr 3.00e-04 | grad 2.22 | tok/s 22134
step   2490 | loss 1.2577 | lr 3.00e-04 | grad 2.22 | tok/s 20964
step   2500 | loss 1.4052 | lr 3.00e-04 | grad 2.08 | tok/s 21691
step   2510 | loss 0.9859 | lr 3.00e-04 | grad 1.90 | tok/s 22147
step   2520 | loss 1.3471 | lr 3.00e-04 | grad 2.27 | tok/s 22009
step   2530 | loss 1.2126 | lr 3.00e-04 | grad 1.46 | tok/s 21391
step   2540 | loss 1.2864 | lr 3.00e-04 | grad 2.84 | tok/s 21162
step   2550 | loss 1.0926 | lr 3.00e-04 | grad 1.34 | tok/s 22029
step   2560 | loss 1.3552 | lr 3.00e-04 | grad 3.41 | tok/s 20644
step   2570 | loss 1.2596 | lr 3.00e-04 | grad 1.62 | tok/s 21603
step   2580 | loss 1.2570 | lr 3.00e-04 | grad 1.85 | tok/s 20200
step   2590 | loss 1.2849 | lr 3.00e-04 | grad 5.62 | tok/s 21310
step   2600 | loss 1.4692 | lr 3.00e-04 | grad 7.81 | tok/s 20355
step   2610 | loss 1.0827 | lr 3.00e-04 | grad 1.90 | tok/s 21962
step   2620 | loss 1.4571 | lr 3.00e-04 | grad 1.73 | tok/s 21427
step   2630 | loss 1.3101 | lr 3.00e-04 | grad 1.98 | tok/s 21919
step   2640 | loss 1.4001 | lr 3.00e-04 | grad 3.91 | tok/s 21336
step   2650 | loss 1.3338 | lr 3.00e-04 | grad 2.98 | tok/s 22138
step   2660 | loss 1.2014 | lr 3.00e-04 | grad 1.70 | tok/s 21054
step   2670 | loss 1.3284 | lr 3.00e-04 | grad 1.82 | tok/s 20700
step   2680 | loss 1.4436 | lr 3.00e-04 | grad 2.41 | tok/s 21204
step   2690 | loss 1.1497 | lr 3.00e-04 | grad 1.48 | tok/s 21922
step   2700 | loss 1.3647 | lr 3.00e-04 | grad 1.94 | tok/s 21324
step   2710 | loss 1.3910 | lr 3.00e-04 | grad 2.09 | tok/s 20978
step   2720 | loss 1.2287 | lr 3.00e-04 | grad 1.60 | tok/s 19925
step   2730 | loss 1.0606 | lr 3.00e-04 | grad 2.12 | tok/s 22062
step   2740 | loss 1.5733 | lr 3.00e-04 | grad 3.50 | tok/s 21448
step   2750 | loss 1.4379 | lr 3.00e-04 | grad 2.05 | tok/s 21947
step   2760 | loss 1.2469 | lr 3.00e-04 | grad 2.23 | tok/s 20296
step   2770 | loss 1.3378 | lr 3.00e-04 | grad 1.92 | tok/s 21196
step   2780 | loss 1.0049 | lr 3.00e-04 | grad 3.28 | tok/s 22147
step   2790 | loss 1.5646 | lr 3.00e-04 | grad 4.34 | tok/s 20486
step   2800 | loss 1.1888 | lr 3.00e-04 | grad 1.38 | tok/s 21411
step   2810 | loss 1.1749 | lr 3.00e-04 | grad 1.39 | tok/s 21198
step   2820 | loss 1.3020 | lr 3.00e-04 | grad 2.00 | tok/s 20325
step   2830 | loss 0.9488 | lr 3.00e-04 | grad 4.53 | tok/s 21853
step   2840 | loss 0.6838 | lr 3.00e-04 | grad 2.31 | tok/s 22129
step   2850 | loss 1.6060 | lr 3.00e-04 | grad 2.16 | tok/s 21277
step   2860 | loss 1.4361 | lr 3.00e-04 | grad 1.44 | tok/s 21357
step   2870 | loss 1.2991 | lr 3.00e-04 | grad 2.28 | tok/s 20959
step   2880 | loss 1.3525 | lr 3.00e-04 | grad 2.62 | tok/s 21733
step   2890 | loss 1.1416 | lr 3.00e-04 | grad 2.47 | tok/s 22152
step   2900 | loss 1.3348 | lr 3.00e-04 | grad 1.52 | tok/s 21286
step   2910 | loss 1.2431 | lr 3.00e-04 | grad 2.42 | tok/s 21214
step   2920 | loss 1.4022 | lr 3.00e-04 | grad 1.59 | tok/s 20769
step   2930 | loss 1.4383 | lr 3.00e-04 | grad 1.77 | tok/s 21447
step   2940 | loss 1.2071 | lr 3.00e-04 | grad 2.27 | tok/s 20180
step   2950 | loss 1.2396 | lr 3.00e-04 | grad 1.77 | tok/s 21422
step   2960 | loss 1.2300 | lr 3.00e-04 | grad 2.42 | tok/s 21607
step   2970 | loss 1.2149 | lr 3.00e-04 | grad 1.80 | tok/s 21284
step   2980 | loss 1.6499 | lr 3.00e-04 | grad 3.61 | tok/s 21435
step   2990 | loss 1.7510 | lr 3.00e-04 | grad 2.20 | tok/s 21688
step   3000 | loss 1.2321 | lr 3.00e-04 | grad 1.86 | tok/s 21641
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2321.pt
step   3010 | loss 0.8842 | lr 3.00e-04 | grad 1.92 | tok/s 7023
step   3020 | loss 1.3168 | lr 3.00e-04 | grad 1.39 | tok/s 21271
step   3030 | loss 1.2841 | lr 3.00e-04 | grad 1.94 | tok/s 21343
step   3040 | loss 1.4069 | lr 3.00e-04 | grad 1.52 | tok/s 21726
step   3050 | loss 1.3265 | lr 3.00e-04 | grad 2.09 | tok/s 21496
step   3060 | loss 1.2116 | lr 3.00e-04 | grad 2.52 | tok/s 22005
step   3070 | loss 1.4740 | lr 3.00e-04 | grad 2.22 | tok/s 22208
step   3080 | loss 1.2940 | lr 3.00e-04 | grad 1.70 | tok/s 21648
step   3090 | loss 1.2491 | lr 3.00e-04 | grad 1.59 | tok/s 21748
step   3100 | loss 1.4056 | lr 3.00e-04 | grad 3.48 | tok/s 21324
step   3110 | loss 1.0207 | lr 3.00e-04 | grad 1.65 | tok/s 22273

Training complete! Final step: 3113
