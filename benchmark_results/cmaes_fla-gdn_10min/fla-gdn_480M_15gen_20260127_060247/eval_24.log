Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_24/levelfla-gdn_100m_20260127_062324
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 489,333,692 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.2012 | lr 3.00e-04 | grad 21.62 | tok/s 6655
step     20 | loss 2.8063 | lr 3.00e-04 | grad 9.50 | tok/s 22688
step     30 | loss 2.6915 | lr 3.00e-04 | grad 6.50 | tok/s 22892
step     40 | loss 2.5129 | lr 3.00e-04 | grad 5.16 | tok/s 22010
step     50 | loss 3.2612 | lr 3.00e-04 | grad 27.38 | tok/s 22259
step     60 | loss 2.1383 | lr 3.00e-04 | grad 5.72 | tok/s 23005
step     70 | loss 1.9258 | lr 3.00e-04 | grad 5.91 | tok/s 23216
step     80 | loss 5.2197 | lr 3.00e-04 | grad 51.00 | tok/s 23454
step     90 | loss 4.6166 | lr 3.00e-04 | grad 7.84 | tok/s 23720
step    100 | loss 3.7852 | lr 3.00e-04 | grad 9.94 | tok/s 23640
step    110 | loss 3.2997 | lr 3.00e-04 | grad 16.38 | tok/s 23579
step    120 | loss 3.1709 | lr 3.00e-04 | grad 27.25 | tok/s 23584
step    130 | loss 2.9145 | lr 3.00e-04 | grad 19.12 | tok/s 23537
step    140 | loss 2.5563 | lr 3.00e-04 | grad 11.38 | tok/s 23613
step    150 | loss 2.6629 | lr 3.00e-04 | grad 11.19 | tok/s 23415
step    160 | loss 2.2993 | lr 3.00e-04 | grad 10.69 | tok/s 23431
step    170 | loss 2.3542 | lr 3.00e-04 | grad 11.56 | tok/s 23364
step    180 | loss 2.1280 | lr 3.00e-04 | grad 8.06 | tok/s 23278
step    190 | loss 2.3459 | lr 3.00e-04 | grad 9.12 | tok/s 23291
step    200 | loss 2.0280 | lr 3.00e-04 | grad 6.31 | tok/s 23274
step    210 | loss 2.0444 | lr 3.00e-04 | grad 6.34 | tok/s 23238
step    220 | loss 2.1448 | lr 3.00e-04 | grad 2.75 | tok/s 22889
step    230 | loss 2.3290 | lr 3.00e-04 | grad 3.78 | tok/s 22588
step    240 | loss 2.2315 | lr 3.00e-04 | grad 3.75 | tok/s 21462
step    250 | loss 2.0477 | lr 3.00e-04 | grad 2.45 | tok/s 21919
step    260 | loss 1.5130 | lr 3.00e-04 | grad 2.94 | tok/s 22553
step    270 | loss 2.0393 | lr 3.00e-04 | grad 2.52 | tok/s 22310
step    280 | loss 2.2208 | lr 3.00e-04 | grad 4.00 | tok/s 21930
step    290 | loss 1.5574 | lr 3.00e-04 | grad 3.80 | tok/s 23024
step    300 | loss 0.6215 | lr 3.00e-04 | grad 4.19 | tok/s 22956
step    310 | loss 2.4134 | lr 3.00e-04 | grad 3.22 | tok/s 22470
step    320 | loss 1.8854 | lr 3.00e-04 | grad 6.19 | tok/s 22027
step    330 | loss 1.8726 | lr 3.00e-04 | grad 2.55 | tok/s 21154
step    340 | loss 2.1793 | lr 3.00e-04 | grad 2.19 | tok/s 21498
step    350 | loss 1.8076 | lr 3.00e-04 | grad 5.31 | tok/s 22064
step    360 | loss 1.1826 | lr 3.00e-04 | grad 6.81 | tok/s 22487
step    370 | loss 1.7487 | lr 3.00e-04 | grad 2.14 | tok/s 20427
step    380 | loss 1.7030 | lr 3.00e-04 | grad 2.22 | tok/s 21713
step    390 | loss 1.4754 | lr 3.00e-04 | grad 1.68 | tok/s 22577
step    400 | loss 1.4341 | lr 3.00e-04 | grad 2.03 | tok/s 22385
step    410 | loss 1.2336 | lr 3.00e-04 | grad 1.84 | tok/s 21814
step    420 | loss 1.7248 | lr 3.00e-04 | grad 3.72 | tok/s 20870
step    430 | loss 2.0375 | lr 3.00e-04 | grad 2.28 | tok/s 22179
step    440 | loss 2.0921 | lr 3.00e-04 | grad 3.22 | tok/s 20948
step    450 | loss 1.8346 | lr 3.00e-04 | grad 2.36 | tok/s 21625
step    460 | loss 1.6416 | lr 3.00e-04 | grad 1.98 | tok/s 21160
step    470 | loss 1.7415 | lr 3.00e-04 | grad 1.91 | tok/s 21773
step    480 | loss 2.1657 | lr 3.00e-04 | grad 5.44 | tok/s 21747
step    490 | loss 1.7003 | lr 3.00e-04 | grad 1.77 | tok/s 20593
step    500 | loss 1.5937 | lr 3.00e-04 | grad 2.92 | tok/s 21973
step    510 | loss 1.6109 | lr 3.00e-04 | grad 1.91 | tok/s 22212
step    520 | loss 1.5905 | lr 3.00e-04 | grad 1.72 | tok/s 22130
step    530 | loss 1.8355 | lr 3.00e-04 | grad 1.81 | tok/s 21260
step    540 | loss 1.6381 | lr 3.00e-04 | grad 1.69 | tok/s 21202
step    550 | loss 1.4957 | lr 3.00e-04 | grad 2.16 | tok/s 20774
step    560 | loss 1.6403 | lr 3.00e-04 | grad 2.06 | tok/s 20217
step    570 | loss 1.5643 | lr 3.00e-04 | grad 2.59 | tok/s 20743
step    580 | loss 1.4687 | lr 3.00e-04 | grad 1.72 | tok/s 20651
step    590 | loss 1.7753 | lr 3.00e-04 | grad 2.53 | tok/s 21170
step    600 | loss 1.7163 | lr 3.00e-04 | grad 1.76 | tok/s 20427
step    610 | loss 1.5492 | lr 3.00e-04 | grad 1.72 | tok/s 21457
step    620 | loss 1.4651 | lr 3.00e-04 | grad 1.86 | tok/s 20337
step    630 | loss 1.5706 | lr 3.00e-04 | grad 3.45 | tok/s 20472
step    640 | loss 1.7074 | lr 3.00e-04 | grad 1.84 | tok/s 21013
step    650 | loss 1.6003 | lr 3.00e-04 | grad 1.99 | tok/s 21093
step    660 | loss 1.6086 | lr 3.00e-04 | grad 1.59 | tok/s 21163
step    670 | loss 1.8482 | lr 3.00e-04 | grad 35.00 | tok/s 21316
step    680 | loss 1.6489 | lr 3.00e-04 | grad 1.88 | tok/s 20870
step    690 | loss 1.7280 | lr 3.00e-04 | grad 2.72 | tok/s 21547
step    700 | loss 1.3655 | lr 3.00e-04 | grad 2.28 | tok/s 21950
step    710 | loss 1.4875 | lr 3.00e-04 | grad 1.87 | tok/s 20497
step    720 | loss 1.3829 | lr 3.00e-04 | grad 2.59 | tok/s 20191
step    730 | loss 1.2426 | lr 3.00e-04 | grad 2.16 | tok/s 21860
step    740 | loss 1.4414 | lr 3.00e-04 | grad 1.77 | tok/s 21557
step    750 | loss 1.1426 | lr 3.00e-04 | grad 1.96 | tok/s 21898
step    760 | loss 1.0443 | lr 3.00e-04 | grad 1.65 | tok/s 21867
step    770 | loss 1.0029 | lr 3.00e-04 | grad 1.53 | tok/s 21897
step    780 | loss 0.9402 | lr 3.00e-04 | grad 1.39 | tok/s 21787
step    790 | loss 1.0619 | lr 3.00e-04 | grad 2.48 | tok/s 21170
step    800 | loss 1.7377 | lr 3.00e-04 | grad 4.66 | tok/s 21082
step    810 | loss 1.6339 | lr 3.00e-04 | grad 1.55 | tok/s 20960
step    820 | loss 1.6036 | lr 3.00e-04 | grad 2.91 | tok/s 20159
step    830 | loss 1.4291 | lr 3.00e-04 | grad 1.95 | tok/s 21602
step    840 | loss 1.3226 | lr 3.00e-04 | grad 1.76 | tok/s 21793
step    850 | loss 1.4381 | lr 3.00e-04 | grad 1.55 | tok/s 21710
step    860 | loss 1.4051 | lr 3.00e-04 | grad 3.22 | tok/s 21434
step    870 | loss 1.4222 | lr 3.00e-04 | grad 2.09 | tok/s 20670
step    880 | loss 1.5748 | lr 3.00e-04 | grad 2.92 | tok/s 20766
step    890 | loss 1.5878 | lr 3.00e-04 | grad 2.33 | tok/s 21047
step    900 | loss 1.4774 | lr 3.00e-04 | grad 2.00 | tok/s 21060
step    910 | loss 1.3618 | lr 3.00e-04 | grad 3.00 | tok/s 20617
step    920 | loss 1.4590 | lr 3.00e-04 | grad 2.91 | tok/s 21383
step    930 | loss 1.5086 | lr 3.00e-04 | grad 2.66 | tok/s 20435
step    940 | loss 1.3184 | lr 3.00e-04 | grad 1.47 | tok/s 21597
step    950 | loss 1.4376 | lr 3.00e-04 | grad 2.09 | tok/s 21507
step    960 | loss 1.2645 | lr 3.00e-04 | grad 1.92 | tok/s 21618
step    970 | loss 1.6330 | lr 3.00e-04 | grad 2.72 | tok/s 20336
step    980 | loss 1.5398 | lr 3.00e-04 | grad 1.84 | tok/s 20905
step    990 | loss 1.3763 | lr 3.00e-04 | grad 1.59 | tok/s 21219
step   1000 | loss 1.7371 | lr 3.00e-04 | grad 8.94 | tok/s 20361
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7371.pt
step   1010 | loss 1.5848 | lr 3.00e-04 | grad 2.77 | tok/s 6885
step   1020 | loss 1.5581 | lr 3.00e-04 | grad 1.48 | tok/s 20074
step   1030 | loss 1.3833 | lr 3.00e-04 | grad 1.64 | tok/s 20875
step   1040 | loss 1.4240 | lr 3.00e-04 | grad 2.45 | tok/s 21487
step   1050 | loss 1.5215 | lr 3.00e-04 | grad 2.47 | tok/s 19904
step   1060 | loss 1.6509 | lr 3.00e-04 | grad 3.39 | tok/s 21479
step   1070 | loss 1.5747 | lr 3.00e-04 | grad 2.25 | tok/s 21391
step   1080 | loss 1.3143 | lr 3.00e-04 | grad 1.70 | tok/s 19463
step   1090 | loss 1.0351 | lr 3.00e-04 | grad 2.03 | tok/s 21446
step   1100 | loss 1.3468 | lr 3.00e-04 | grad 2.72 | tok/s 20817
step   1110 | loss 1.3819 | lr 3.00e-04 | grad 1.62 | tok/s 21780
step   1120 | loss 1.2679 | lr 3.00e-04 | grad 1.68 | tok/s 21760
step   1130 | loss 1.2229 | lr 3.00e-04 | grad 1.51 | tok/s 21742
step   1140 | loss 1.2105 | lr 3.00e-04 | grad 1.66 | tok/s 21748
step   1150 | loss 1.2215 | lr 3.00e-04 | grad 1.37 | tok/s 21769
step   1160 | loss 1.1479 | lr 3.00e-04 | grad 1.48 | tok/s 21765
step   1170 | loss 1.1703 | lr 3.00e-04 | grad 1.58 | tok/s 21701
step   1180 | loss 1.2827 | lr 3.00e-04 | grad 1.31 | tok/s 21700
step   1190 | loss 1.1460 | lr 3.00e-04 | grad 1.63 | tok/s 21720
step   1200 | loss 1.1449 | lr 3.00e-04 | grad 1.59 | tok/s 21712
step   1210 | loss 1.1978 | lr 3.00e-04 | grad 1.59 | tok/s 21683
step   1220 | loss 1.2195 | lr 3.00e-04 | grad 1.70 | tok/s 21669
step   1230 | loss 1.1800 | lr 3.00e-04 | grad 1.35 | tok/s 21674
step   1240 | loss 1.1506 | lr 3.00e-04 | grad 1.23 | tok/s 21690
step   1250 | loss 1.6333 | lr 3.00e-04 | grad 2.72 | tok/s 20563
step   1260 | loss 1.3057 | lr 3.00e-04 | grad 23.88 | tok/s 20348
step   1270 | loss 1.5683 | lr 3.00e-04 | grad 4.19 | tok/s 20279
step   1280 | loss 1.5432 | lr 3.00e-04 | grad 1.66 | tok/s 20844
step   1290 | loss 1.3953 | lr 3.00e-04 | grad 1.50 | tok/s 20731
step   1300 | loss 1.4387 | lr 3.00e-04 | grad 1.95 | tok/s 20872
step   1310 | loss 1.3910 | lr 3.00e-04 | grad 1.91 | tok/s 21183
step   1320 | loss 1.5011 | lr 3.00e-04 | grad 1.87 | tok/s 21261
step   1330 | loss 1.5074 | lr 3.00e-04 | grad 1.85 | tok/s 21311
step   1340 | loss 1.3946 | lr 3.00e-04 | grad 7.16 | tok/s 20319
step   1350 | loss 1.6019 | lr 3.00e-04 | grad 2.05 | tok/s 19647
step   1360 | loss 1.4071 | lr 3.00e-04 | grad 2.02 | tok/s 20862
step   1370 | loss 1.3532 | lr 3.00e-04 | grad 1.29 | tok/s 20582
step   1380 | loss 1.5084 | lr 3.00e-04 | grad 2.30 | tok/s 19797
step   1390 | loss 1.4355 | lr 3.00e-04 | grad 1.39 | tok/s 20993
step   1400 | loss 1.3097 | lr 3.00e-04 | grad 1.61 | tok/s 20260
step   1410 | loss 1.3602 | lr 3.00e-04 | grad 2.52 | tok/s 20334
step   1420 | loss 1.5548 | lr 3.00e-04 | grad 4.72 | tok/s 20371
step   1430 | loss 1.2658 | lr 3.00e-04 | grad 1.56 | tok/s 20734
step   1440 | loss 1.0826 | lr 3.00e-04 | grad 1.56 | tok/s 21398
step   1450 | loss 1.0950 | lr 3.00e-04 | grad 3.48 | tok/s 21518
step   1460 | loss 1.5131 | lr 3.00e-04 | grad 1.65 | tok/s 20315
step   1470 | loss 1.4334 | lr 3.00e-04 | grad 1.53 | tok/s 21100
step   1480 | loss 1.6846 | lr 3.00e-04 | grad 3.28 | tok/s 21166
step   1490 | loss 1.4572 | lr 3.00e-04 | grad 1.41 | tok/s 18965
step   1500 | loss 1.2855 | lr 3.00e-04 | grad 1.39 | tok/s 21570
step   1510 | loss 1.4106 | lr 3.00e-04 | grad 1.59 | tok/s 21313
step   1520 | loss 1.3457 | lr 3.00e-04 | grad 3.05 | tok/s 20894
step   1530 | loss 1.3708 | lr 3.00e-04 | grad 1.42 | tok/s 21343
step   1540 | loss 1.5038 | lr 3.00e-04 | grad 1.95 | tok/s 20127
step   1550 | loss 1.2202 | lr 3.00e-04 | grad 1.91 | tok/s 21451
step   1560 | loss 1.4884 | lr 3.00e-04 | grad 1.91 | tok/s 20330
step   1570 | loss 1.2161 | lr 3.00e-04 | grad 1.73 | tok/s 21556
step   1580 | loss 1.5816 | lr 3.00e-04 | grad 3.38 | tok/s 21082
step   1590 | loss 1.4944 | lr 3.00e-04 | grad 1.97 | tok/s 20263
step   1600 | loss 0.9512 | lr 3.00e-04 | grad 1.58 | tok/s 21647
step   1610 | loss 0.9714 | lr 3.00e-04 | grad 1.91 | tok/s 20963
step   1620 | loss 1.3224 | lr 3.00e-04 | grad 2.14 | tok/s 19603
step   1630 | loss 1.2682 | lr 3.00e-04 | grad 2.12 | tok/s 20943
step   1640 | loss 1.2516 | lr 3.00e-04 | grad 1.59 | tok/s 20485
step   1650 | loss 1.4277 | lr 3.00e-04 | grad 2.12 | tok/s 19664
step   1660 | loss 1.3311 | lr 3.00e-04 | grad 1.38 | tok/s 20931
step   1670 | loss 1.2803 | lr 3.00e-04 | grad 6.44 | tok/s 20906
step   1680 | loss 1.6171 | lr 3.00e-04 | grad 1.60 | tok/s 20106
step   1690 | loss 1.3712 | lr 3.00e-04 | grad 3.33 | tok/s 20463
step   1700 | loss 1.3903 | lr 3.00e-04 | grad 1.84 | tok/s 20901
step   1710 | loss 1.3238 | lr 3.00e-04 | grad 1.70 | tok/s 20512
step   1720 | loss 1.4144 | lr 3.00e-04 | grad 2.17 | tok/s 21381
step   1730 | loss 1.1193 | lr 3.00e-04 | grad 2.44 | tok/s 21595
step   1740 | loss 1.2339 | lr 3.00e-04 | grad 2.23 | tok/s 21049
step   1750 | loss 1.5026 | lr 3.00e-04 | grad 2.06 | tok/s 20714
step   1760 | loss 1.4524 | lr 3.00e-04 | grad 1.75 | tok/s 20758
step   1770 | loss 1.3565 | lr 3.00e-04 | grad 1.87 | tok/s 20381
step   1780 | loss 1.4311 | lr 3.00e-04 | grad 1.47 | tok/s 21217
step   1790 | loss 1.3119 | lr 3.00e-04 | grad 1.28 | tok/s 20655
step   1800 | loss 1.5274 | lr 3.00e-04 | grad 1.80 | tok/s 20807
step   1810 | loss 1.3345 | lr 3.00e-04 | grad 1.70 | tok/s 20072
step   1820 | loss 1.3766 | lr 3.00e-04 | grad 4.72 | tok/s 20335
step   1830 | loss 1.3115 | lr 3.00e-04 | grad 1.80 | tok/s 21140
step   1840 | loss 1.4259 | lr 3.00e-04 | grad 2.12 | tok/s 20294
step   1850 | loss 1.2233 | lr 3.00e-04 | grad 1.44 | tok/s 21222
step   1860 | loss 1.2469 | lr 3.00e-04 | grad 1.91 | tok/s 20511
step   1870 | loss 1.3271 | lr 3.00e-04 | grad 2.39 | tok/s 20632
step   1880 | loss 1.1439 | lr 3.00e-04 | grad 1.74 | tok/s 20211
step   1890 | loss 1.4210 | lr 3.00e-04 | grad 1.41 | tok/s 19228
step   1900 | loss 1.3285 | lr 3.00e-04 | grad 2.05 | tok/s 20626
step   1910 | loss 1.3731 | lr 3.00e-04 | grad 2.11 | tok/s 19698
step   1920 | loss 1.3315 | lr 3.00e-04 | grad 1.55 | tok/s 21537
step   1930 | loss 1.3812 | lr 3.00e-04 | grad 1.92 | tok/s 20252
step   1940 | loss 1.3698 | lr 3.00e-04 | grad 1.58 | tok/s 20993
step   1950 | loss 1.7927 | lr 3.00e-04 | grad 3.11 | tok/s 21313
step   1960 | loss 1.3774 | lr 3.00e-04 | grad 3.61 | tok/s 21583
step   1970 | loss 1.4057 | lr 3.00e-04 | grad 1.96 | tok/s 21037
step   1980 | loss 1.4393 | lr 3.00e-04 | grad 1.63 | tok/s 20134
step   1990 | loss 1.4524 | lr 3.00e-04 | grad 5.91 | tok/s 20515
step   2000 | loss 1.4029 | lr 3.00e-04 | grad 1.62 | tok/s 20804
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4029.pt
step   2010 | loss 0.9946 | lr 3.00e-04 | grad 1.38 | tok/s 7403
step   2020 | loss 1.2206 | lr 3.00e-04 | grad 1.73 | tok/s 20823
step   2030 | loss 1.0234 | lr 3.00e-04 | grad 0.86 | tok/s 21984
step   2040 | loss 1.1587 | lr 3.00e-04 | grad 1.76 | tok/s 21833
step   2050 | loss 1.1282 | lr 3.00e-04 | grad 1.87 | tok/s 21295
step   2060 | loss 1.4605 | lr 3.00e-04 | grad 1.84 | tok/s 20110
step   2070 | loss 1.5795 | lr 3.00e-04 | grad 1.95 | tok/s 20844
step   2080 | loss 2.0937 | lr 3.00e-04 | grad 3.75 | tok/s 21552
step   2090 | loss 1.5822 | lr 3.00e-04 | grad 3.94 | tok/s 21595
step   2100 | loss 1.2698 | lr 3.00e-04 | grad 2.19 | tok/s 21095
step   2110 | loss 1.4289 | lr 3.00e-04 | grad 19.00 | tok/s 20596
step   2120 | loss 0.8601 | lr 3.00e-04 | grad 1.96 | tok/s 21478
step   2130 | loss 0.9641 | lr 3.00e-04 | grad 2.77 | tok/s 21408
step   2140 | loss 1.4388 | lr 3.00e-04 | grad 1.33 | tok/s 20639
step   2150 | loss 1.2132 | lr 3.00e-04 | grad 1.58 | tok/s 21653
step   2160 | loss 1.1199 | lr 3.00e-04 | grad 1.17 | tok/s 21644
step   2170 | loss 1.1693 | lr 3.00e-04 | grad 1.24 | tok/s 21636
step   2180 | loss 1.1255 | lr 3.00e-04 | grad 1.55 | tok/s 21602
step   2190 | loss 1.1380 | lr 3.00e-04 | grad 1.16 | tok/s 21631
step   2200 | loss 1.1242 | lr 3.00e-04 | grad 1.35 | tok/s 21616
step   2210 | loss 1.0792 | lr 3.00e-04 | grad 1.20 | tok/s 21655
step   2220 | loss 1.0725 | lr 3.00e-04 | grad 1.20 | tok/s 21659
step   2230 | loss 1.2750 | lr 3.00e-04 | grad 1.53 | tok/s 21231
step   2240 | loss 1.2715 | lr 3.00e-04 | grad 1.42 | tok/s 21578
step   2250 | loss 1.3964 | lr 3.00e-04 | grad 2.88 | tok/s 20886
step   2260 | loss 1.4338 | lr 3.00e-04 | grad 1.63 | tok/s 21122
step   2270 | loss 1.8184 | lr 3.00e-04 | grad 3.67 | tok/s 21404
step   2280 | loss 1.3985 | lr 3.00e-04 | grad 1.97 | tok/s 21356
step   2290 | loss 1.2117 | lr 3.00e-04 | grad 2.23 | tok/s 20892
step   2300 | loss 1.5730 | lr 3.00e-04 | grad 3.95 | tok/s 21343
step   2310 | loss 1.2821 | lr 3.00e-04 | grad 1.38 | tok/s 20303
step   2320 | loss 1.4945 | lr 3.00e-04 | grad 3.83 | tok/s 20357
step   2330 | loss 1.7211 | lr 3.00e-04 | grad 1.59 | tok/s 20688
step   2340 | loss 1.3393 | lr 3.00e-04 | grad 5.03 | tok/s 20159
step   2350 | loss 1.2582 | lr 3.00e-04 | grad 3.80 | tok/s 21146
step   2360 | loss 1.2398 | lr 3.00e-04 | grad 1.88 | tok/s 21415
step   2370 | loss 1.3469 | lr 3.00e-04 | grad 2.72 | tok/s 21184
step   2380 | loss 1.3944 | lr 3.00e-04 | grad 1.95 | tok/s 21668
step   2390 | loss 1.1052 | lr 3.00e-04 | grad 1.52 | tok/s 21597
step   2400 | loss 1.0369 | lr 3.00e-04 | grad 1.44 | tok/s 21653
step   2410 | loss 1.0164 | lr 3.00e-04 | grad 1.63 | tok/s 21012
step   2420 | loss 1.3760 | lr 3.00e-04 | grad 3.36 | tok/s 20333
step   2430 | loss 1.3228 | lr 3.00e-04 | grad 1.64 | tok/s 20660
step   2440 | loss 1.1379 | lr 3.00e-04 | grad 3.08 | tok/s 21214
step   2450 | loss 1.3681 | lr 3.00e-04 | grad 1.75 | tok/s 20669
step   2460 | loss 1.2377 | lr 3.00e-04 | grad 1.77 | tok/s 21458
step   2470 | loss 1.0675 | lr 3.00e-04 | grad 1.95 | tok/s 21395
step   2480 | loss 1.1784 | lr 3.00e-04 | grad 1.34 | tok/s 21622
step   2490 | loss 1.2290 | lr 3.00e-04 | grad 1.51 | tok/s 20497
step   2500 | loss 1.4396 | lr 3.00e-04 | grad 2.02 | tok/s 21154
step   2510 | loss 1.0449 | lr 3.00e-04 | grad 2.14 | tok/s 21602
step   2520 | loss 1.2854 | lr 3.00e-04 | grad 4.66 | tok/s 21509
step   2530 | loss 1.2704 | lr 3.00e-04 | grad 1.42 | tok/s 20799
step   2540 | loss 1.3043 | lr 3.00e-04 | grad 2.59 | tok/s 20661
step   2550 | loss 1.1042 | lr 3.00e-04 | grad 1.41 | tok/s 21463
step   2560 | loss 1.3328 | lr 3.00e-04 | grad 5.91 | tok/s 20182
step   2570 | loss 1.3053 | lr 3.00e-04 | grad 1.47 | tok/s 20998
step   2580 | loss 1.2602 | lr 3.00e-04 | grad 2.03 | tok/s 19724
step   2590 | loss 1.2192 | lr 3.00e-04 | grad 1.93 | tok/s 20792
step   2600 | loss 1.4373 | lr 3.00e-04 | grad 2.48 | tok/s 19981
step   2610 | loss 1.1876 | lr 3.00e-04 | grad 2.09 | tok/s 21446
step   2620 | loss 1.4419 | lr 3.00e-04 | grad 1.62 | tok/s 20686
step   2630 | loss 1.3435 | lr 3.00e-04 | grad 1.48 | tok/s 21348
step   2640 | loss 1.3534 | lr 3.00e-04 | grad 1.77 | tok/s 20779
step   2650 | loss 1.4048 | lr 3.00e-04 | grad 2.56 | tok/s 21570
step   2660 | loss 1.2389 | lr 3.00e-04 | grad 1.65 | tok/s 20849
step   2670 | loss 1.3182 | lr 3.00e-04 | grad 2.38 | tok/s 20055
step   2680 | loss 1.4375 | lr 3.00e-04 | grad 9.25 | tok/s 20509
step   2690 | loss 1.2020 | lr 3.00e-04 | grad 1.32 | tok/s 21421
step   2700 | loss 1.3354 | lr 3.00e-04 | grad 1.62 | tok/s 20847
step   2710 | loss 1.4190 | lr 3.00e-04 | grad 2.38 | tok/s 20538
step   2720 | loss 1.2496 | lr 3.00e-04 | grad 1.61 | tok/s 19691
step   2730 | loss 1.0882 | lr 3.00e-04 | grad 1.70 | tok/s 21135
step   2740 | loss 1.5488 | lr 3.00e-04 | grad 5.34 | tok/s 20899
step   2750 | loss 1.4789 | lr 3.00e-04 | grad 1.77 | tok/s 21390
step   2760 | loss 1.2300 | lr 3.00e-04 | grad 1.65 | tok/s 19915
step   2770 | loss 1.4001 | lr 3.00e-04 | grad 2.41 | tok/s 20555
step   2780 | loss 0.9915 | lr 3.00e-04 | grad 1.43 | tok/s 21593
step   2790 | loss 1.5111 | lr 3.00e-04 | grad 4.31 | tok/s 20120
step   2800 | loss 1.2983 | lr 3.00e-04 | grad 1.19 | tok/s 20679
step   2810 | loss 1.1590 | lr 3.00e-04 | grad 1.71 | tok/s 20614
step   2820 | loss 1.3170 | lr 3.00e-04 | grad 1.40 | tok/s 19884
step   2830 | loss 1.0122 | lr 3.00e-04 | grad 1.94 | tok/s 21188
step   2840 | loss 0.6298 | lr 3.00e-04 | grad 1.84 | tok/s 21549
step   2850 | loss 1.6002 | lr 3.00e-04 | grad 1.79 | tok/s 20867
step   2860 | loss 1.4966 | lr 3.00e-04 | grad 1.37 | tok/s 20766
step   2870 | loss 1.2665 | lr 3.00e-04 | grad 1.66 | tok/s 20351
step   2880 | loss 1.3924 | lr 3.00e-04 | grad 2.56 | tok/s 21009
step   2890 | loss 1.1482 | lr 3.00e-04 | grad 2.02 | tok/s 21550
step   2900 | loss 1.3390 | lr 3.00e-04 | grad 1.37 | tok/s 20725
step   2910 | loss 1.2482 | lr 3.00e-04 | grad 1.50 | tok/s 20730
step   2920 | loss 1.4230 | lr 3.00e-04 | grad 1.92 | tok/s 20104
step   2930 | loss 1.4596 | lr 3.00e-04 | grad 1.48 | tok/s 21062
step   2940 | loss 1.2097 | lr 3.00e-04 | grad 1.84 | tok/s 19382
step   2950 | loss 1.2743 | lr 3.00e-04 | grad 2.14 | tok/s 20803
step   2960 | loss 1.2075 | lr 3.00e-04 | grad 2.36 | tok/s 20989
step   2970 | loss 1.2198 | lr 3.00e-04 | grad 1.80 | tok/s 21142
step   2980 | loss 1.6229 | lr 3.00e-04 | grad 1.46 | tok/s 20502
step   2990 | loss 1.8389 | lr 3.00e-04 | grad 2.12 | tok/s 20998
step   3000 | loss 1.2556 | lr 3.00e-04 | grad 3.38 | tok/s 21046
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2556.pt
step   3010 | loss 0.8743 | lr 3.00e-04 | grad 1.48 | tok/s 7280
step   3020 | loss 1.2482 | lr 3.00e-04 | grad 1.54 | tok/s 20462
step   3030 | loss 1.3689 | lr 3.00e-04 | grad 2.08 | tok/s 20643
step   3040 | loss 1.3459 | lr 3.00e-04 | grad 1.59 | tok/s 21111
step   3050 | loss 1.3297 | lr 3.00e-04 | grad 1.55 | tok/s 20894
step   3060 | loss 1.1950 | lr 3.00e-04 | grad 1.52 | tok/s 21521
step   3070 | loss 1.4879 | lr 3.00e-04 | grad 1.77 | tok/s 21535

Training complete! Final step: 3073
