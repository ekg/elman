Using device: cuda
Output directory: benchmark_results/cmaes_fla-gdn_10min/fla-gdn_480M_15gen_20260127_060247/eval_19/levelfla-gdn_100m_20260127_062324
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 489,333,692 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 10.0 minutes
step     10 | loss 4.1603 | lr 3.00e-04 | grad 24.00 | tok/s 6740
step     20 | loss 2.7344 | lr 3.00e-04 | grad 10.50 | tok/s 20730
step     30 | loss 2.6239 | lr 3.00e-04 | grad 6.50 | tok/s 20985
step     40 | loss 2.4663 | lr 3.00e-04 | grad 4.38 | tok/s 20138
step     50 | loss 3.1893 | lr 3.00e-04 | grad 24.38 | tok/s 20435
step     60 | loss 2.1175 | lr 3.00e-04 | grad 4.91 | tok/s 21097
step     70 | loss 1.9044 | lr 3.00e-04 | grad 5.66 | tok/s 21265
step     80 | loss 5.2112 | lr 3.00e-04 | grad 46.25 | tok/s 21367
step     90 | loss 4.5444 | lr 3.00e-04 | grad 7.03 | tok/s 21709
step    100 | loss 3.7826 | lr 3.00e-04 | grad 8.62 | tok/s 20236
step    110 | loss 3.3300 | lr 3.00e-04 | grad 17.88 | tok/s 21679
step    120 | loss 3.0406 | lr 3.00e-04 | grad 13.19 | tok/s 21614
step    130 | loss 2.8353 | lr 3.00e-04 | grad 16.00 | tok/s 21609
step    140 | loss 2.5054 | lr 3.00e-04 | grad 13.69 | tok/s 21550
step    150 | loss 2.6592 | lr 3.00e-04 | grad 19.12 | tok/s 21527
step    160 | loss 2.2264 | lr 3.00e-04 | grad 13.31 | tok/s 21491
step    170 | loss 2.3082 | lr 3.00e-04 | grad 11.12 | tok/s 21416
step    180 | loss 2.1811 | lr 3.00e-04 | grad 4.31 | tok/s 21479
step    190 | loss 2.2642 | lr 3.00e-04 | grad 5.44 | tok/s 21383
step    200 | loss 2.0034 | lr 3.00e-04 | grad 6.28 | tok/s 21475
step    210 | loss 2.0330 | lr 3.00e-04 | grad 7.09 | tok/s 21403
step    220 | loss 2.1320 | lr 3.00e-04 | grad 2.59 | tok/s 21136
step    230 | loss 2.3917 | lr 3.00e-04 | grad 3.59 | tok/s 20873
step    240 | loss 2.2216 | lr 3.00e-04 | grad 3.89 | tok/s 19867
step    250 | loss 2.0303 | lr 3.00e-04 | grad 2.33 | tok/s 20362
step    260 | loss 1.5006 | lr 3.00e-04 | grad 2.70 | tok/s 20996
step    270 | loss 2.0288 | lr 3.00e-04 | grad 2.34 | tok/s 20713
step    280 | loss 2.2060 | lr 3.00e-04 | grad 4.28 | tok/s 20332
step    290 | loss 1.4927 | lr 3.00e-04 | grad 4.09 | tok/s 21367
step    300 | loss 0.6530 | lr 3.00e-04 | grad 4.22 | tok/s 21398
step    310 | loss 2.4248 | lr 3.00e-04 | grad 3.02 | tok/s 20916
step    320 | loss 1.8741 | lr 3.00e-04 | grad 6.22 | tok/s 20540
step    330 | loss 1.8652 | lr 3.00e-04 | grad 2.59 | tok/s 19886
step    340 | loss 2.1526 | lr 3.00e-04 | grad 2.19 | tok/s 20163
step    350 | loss 1.8151 | lr 3.00e-04 | grad 4.97 | tok/s 20617
step    360 | loss 1.1997 | lr 3.00e-04 | grad 8.75 | tok/s 21110
step    370 | loss 1.7361 | lr 3.00e-04 | grad 2.12 | tok/s 19175
step    380 | loss 1.6969 | lr 3.00e-04 | grad 2.19 | tok/s 20349
step    390 | loss 1.4716 | lr 3.00e-04 | grad 1.62 | tok/s 21306
step    400 | loss 1.4268 | lr 3.00e-04 | grad 2.02 | tok/s 21072
step    410 | loss 1.2256 | lr 3.00e-04 | grad 1.99 | tok/s 20537
step    420 | loss 1.7259 | lr 3.00e-04 | grad 3.81 | tok/s 19723
step    430 | loss 2.0390 | lr 3.00e-04 | grad 2.33 | tok/s 20898
step    440 | loss 2.0879 | lr 3.00e-04 | grad 3.22 | tok/s 19871
step    450 | loss 1.8883 | lr 3.00e-04 | grad 2.33 | tok/s 20477
step    460 | loss 1.6501 | lr 3.00e-04 | grad 2.02 | tok/s 20047
step    470 | loss 1.7347 | lr 3.00e-04 | grad 1.87 | tok/s 20693
step    480 | loss 2.1617 | lr 3.00e-04 | grad 5.72 | tok/s 20643
step    490 | loss 1.7014 | lr 3.00e-04 | grad 1.80 | tok/s 19591
step    500 | loss 1.5920 | lr 3.00e-04 | grad 2.89 | tok/s 20846
step    510 | loss 1.6129 | lr 3.00e-04 | grad 1.81 | tok/s 21145
step    520 | loss 1.5889 | lr 3.00e-04 | grad 1.70 | tok/s 21100
step    530 | loss 1.8253 | lr 3.00e-04 | grad 1.85 | tok/s 20309
step    540 | loss 1.6447 | lr 3.00e-04 | grad 1.69 | tok/s 20321
step    550 | loss 1.4957 | lr 3.00e-04 | grad 2.16 | tok/s 19893
step    560 | loss 1.6366 | lr 3.00e-04 | grad 2.09 | tok/s 19362
step    570 | loss 1.5604 | lr 3.00e-04 | grad 2.56 | tok/s 19943
step    580 | loss 1.4620 | lr 3.00e-04 | grad 1.73 | tok/s 19799
step    590 | loss 1.7732 | lr 3.00e-04 | grad 2.50 | tok/s 20367
step    600 | loss 1.7207 | lr 3.00e-04 | grad 1.86 | tok/s 19647
step    610 | loss 1.5505 | lr 3.00e-04 | grad 1.83 | tok/s 20610
step    620 | loss 1.4674 | lr 3.00e-04 | grad 1.85 | tok/s 19596
step    630 | loss 1.5668 | lr 3.00e-04 | grad 3.48 | tok/s 19679
step    640 | loss 1.7081 | lr 3.00e-04 | grad 1.82 | tok/s 20282
step    650 | loss 1.6015 | lr 3.00e-04 | grad 1.99 | tok/s 20344
step    660 | loss 1.6100 | lr 3.00e-04 | grad 1.59 | tok/s 20433
step    670 | loss 1.8492 | lr 3.00e-04 | grad 20.75 | tok/s 20613
step    680 | loss 1.6495 | lr 3.00e-04 | grad 1.95 | tok/s 20124
step    690 | loss 1.7274 | lr 3.00e-04 | grad 2.67 | tok/s 20870
step    700 | loss 1.3596 | lr 3.00e-04 | grad 2.34 | tok/s 21249
step    710 | loss 1.5029 | lr 3.00e-04 | grad 1.85 | tok/s 19829
step    720 | loss 1.3784 | lr 3.00e-04 | grad 2.62 | tok/s 19596
step    730 | loss 1.2346 | lr 3.00e-04 | grad 2.14 | tok/s 21142
step    740 | loss 1.4331 | lr 3.00e-04 | grad 1.82 | tok/s 20875
step    750 | loss 1.1367 | lr 3.00e-04 | grad 1.96 | tok/s 21275
step    760 | loss 1.0476 | lr 3.00e-04 | grad 1.67 | tok/s 21196
step    770 | loss 1.0016 | lr 3.00e-04 | grad 1.60 | tok/s 21259
step    780 | loss 0.9371 | lr 3.00e-04 | grad 1.46 | tok/s 21258
step    790 | loss 1.0584 | lr 3.00e-04 | grad 2.52 | tok/s 20538
step    800 | loss 1.7341 | lr 3.00e-04 | grad 4.72 | tok/s 20553
step    810 | loss 1.6354 | lr 3.00e-04 | grad 1.52 | tok/s 20412
step    820 | loss 1.6062 | lr 3.00e-04 | grad 3.03 | tok/s 19582
step    830 | loss 1.4386 | lr 3.00e-04 | grad 2.02 | tok/s 21089
step    840 | loss 1.3266 | lr 3.00e-04 | grad 1.78 | tok/s 21201
step    850 | loss 1.4516 | lr 3.00e-04 | grad 1.53 | tok/s 21125
step    860 | loss 1.3998 | lr 3.00e-04 | grad 3.19 | tok/s 20921
step    870 | loss 1.4244 | lr 3.00e-04 | grad 2.14 | tok/s 20102
step    880 | loss 1.5734 | lr 3.00e-04 | grad 1.75 | tok/s 20303
step    890 | loss 1.5850 | lr 3.00e-04 | grad 2.33 | tok/s 20537
step    900 | loss 1.4807 | lr 3.00e-04 | grad 2.06 | tok/s 20528
step    910 | loss 1.3561 | lr 3.00e-04 | grad 2.95 | tok/s 20163
step    920 | loss 1.4595 | lr 3.00e-04 | grad 2.66 | tok/s 20893
step    930 | loss 1.5048 | lr 3.00e-04 | grad 2.69 | tok/s 20041
step    940 | loss 1.3111 | lr 3.00e-04 | grad 1.47 | tok/s 21063
step    950 | loss 1.4104 | lr 3.00e-04 | grad 2.42 | tok/s 21140
step    960 | loss 1.2562 | lr 3.00e-04 | grad 2.06 | tok/s 21216
step    970 | loss 1.6279 | lr 3.00e-04 | grad 2.75 | tok/s 19894
step    980 | loss 1.5422 | lr 3.00e-04 | grad 1.79 | tok/s 20539
step    990 | loss 1.3766 | lr 3.00e-04 | grad 1.62 | tok/s 20819
step   1000 | loss 1.7403 | lr 3.00e-04 | grad 9.00 | tok/s 19994
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7403.pt
step   1010 | loss 1.5852 | lr 3.00e-04 | grad 2.86 | tok/s 7410
step   1020 | loss 1.5605 | lr 3.00e-04 | grad 1.48 | tok/s 19736
step   1030 | loss 1.3764 | lr 3.00e-04 | grad 1.59 | tok/s 20511
step   1040 | loss 1.4289 | lr 3.00e-04 | grad 2.12 | tok/s 21114
step   1050 | loss 1.5215 | lr 3.00e-04 | grad 2.53 | tok/s 19623
step   1060 | loss 1.6477 | lr 3.00e-04 | grad 3.34 | tok/s 21102
step   1070 | loss 1.5671 | lr 3.00e-04 | grad 2.39 | tok/s 21078
step   1080 | loss 1.3196 | lr 3.00e-04 | grad 1.73 | tok/s 19158
step   1090 | loss 1.0457 | lr 3.00e-04 | grad 4.03 | tok/s 21080
step   1100 | loss 1.3449 | lr 3.00e-04 | grad 2.88 | tok/s 20514
step   1110 | loss 1.3876 | lr 3.00e-04 | grad 1.70 | tok/s 21408
step   1120 | loss 1.2733 | lr 3.00e-04 | grad 1.67 | tok/s 21448
step   1130 | loss 1.2276 | lr 3.00e-04 | grad 1.50 | tok/s 21395
step   1140 | loss 1.2148 | lr 3.00e-04 | grad 1.71 | tok/s 21435
step   1150 | loss 1.2261 | lr 3.00e-04 | grad 1.37 | tok/s 21397
step   1160 | loss 1.1504 | lr 3.00e-04 | grad 1.47 | tok/s 21414
step   1170 | loss 1.1724 | lr 3.00e-04 | grad 1.59 | tok/s 21395
step   1180 | loss 1.2815 | lr 3.00e-04 | grad 1.33 | tok/s 21403
step   1190 | loss 1.1501 | lr 3.00e-04 | grad 1.66 | tok/s 21439
step   1200 | loss 1.1440 | lr 3.00e-04 | grad 1.57 | tok/s 21395
step   1210 | loss 1.1960 | lr 3.00e-04 | grad 1.61 | tok/s 21432
step   1220 | loss 1.2202 | lr 3.00e-04 | grad 1.70 | tok/s 21384
step   1230 | loss 1.1808 | lr 3.00e-04 | grad 1.38 | tok/s 21388
step   1240 | loss 1.1539 | lr 3.00e-04 | grad 1.21 | tok/s 21379
step   1250 | loss 1.6435 | lr 3.00e-04 | grad 2.67 | tok/s 20277
step   1260 | loss 1.2967 | lr 3.00e-04 | grad 11.44 | tok/s 20118
step   1270 | loss 1.5712 | lr 3.00e-04 | grad 4.34 | tok/s 20006
step   1280 | loss 1.5426 | lr 3.00e-04 | grad 1.57 | tok/s 20479
step   1290 | loss 1.4000 | lr 3.00e-04 | grad 1.52 | tok/s 20480
step   1300 | loss 1.4386 | lr 3.00e-04 | grad 1.90 | tok/s 20627
step   1310 | loss 1.3890 | lr 3.00e-04 | grad 2.03 | tok/s 20977
step   1320 | loss 1.5024 | lr 3.00e-04 | grad 1.91 | tok/s 20977
step   1330 | loss 1.5139 | lr 3.00e-04 | grad 1.84 | tok/s 21056
step   1340 | loss 1.3914 | lr 3.00e-04 | grad 7.38 | tok/s 20072
step   1350 | loss 1.5997 | lr 3.00e-04 | grad 2.11 | tok/s 19451
step   1360 | loss 1.4084 | lr 3.00e-04 | grad 1.98 | tok/s 20544
step   1370 | loss 1.3573 | lr 3.00e-04 | grad 1.30 | tok/s 20372
step   1380 | loss 1.5132 | lr 3.00e-04 | grad 2.14 | tok/s 19534
step   1390 | loss 1.4328 | lr 3.00e-04 | grad 1.36 | tok/s 20768
step   1400 | loss 1.3075 | lr 3.00e-04 | grad 1.53 | tok/s 19990
step   1410 | loss 1.3591 | lr 3.00e-04 | grad 2.55 | tok/s 20113
step   1420 | loss 1.5453 | lr 3.00e-04 | grad 4.38 | tok/s 20150
step   1430 | loss 1.2624 | lr 3.00e-04 | grad 1.58 | tok/s 20503
step   1440 | loss 1.0851 | lr 3.00e-04 | grad 1.51 | tok/s 21093
step   1450 | loss 1.0989 | lr 3.00e-04 | grad 3.48 | tok/s 21231
step   1460 | loss 1.5118 | lr 3.00e-04 | grad 1.64 | tok/s 20105
step   1470 | loss 1.4327 | lr 3.00e-04 | grad 1.58 | tok/s 20751
step   1480 | loss 1.6901 | lr 3.00e-04 | grad 3.64 | tok/s 20960
step   1490 | loss 1.4610 | lr 3.00e-04 | grad 1.44 | tok/s 19662
step   1500 | loss 1.2914 | lr 3.00e-04 | grad 1.39 | tok/s 21292
step   1510 | loss 1.4112 | lr 3.00e-04 | grad 1.53 | tok/s 21127
step   1520 | loss 1.3412 | lr 3.00e-04 | grad 3.19 | tok/s 20653
step   1530 | loss 1.3702 | lr 3.00e-04 | grad 1.29 | tok/s 21152
step   1540 | loss 1.5021 | lr 3.00e-04 | grad 1.91 | tok/s 19904
step   1550 | loss 1.2203 | lr 3.00e-04 | grad 1.99 | tok/s 21218
step   1560 | loss 1.4909 | lr 3.00e-04 | grad 2.03 | tok/s 20103
step   1570 | loss 1.2194 | lr 3.00e-04 | grad 1.74 | tok/s 21371
step   1580 | loss 1.5992 | lr 3.00e-04 | grad 4.00 | tok/s 20861
step   1590 | loss 1.5187 | lr 3.00e-04 | grad 2.00 | tok/s 20112
step   1600 | loss 0.9540 | lr 3.00e-04 | grad 1.70 | tok/s 21461
step   1610 | loss 0.9701 | lr 3.00e-04 | grad 1.88 | tok/s 20862
step   1620 | loss 1.3172 | lr 3.00e-04 | grad 2.23 | tok/s 19473
step   1630 | loss 1.2693 | lr 3.00e-04 | grad 1.91 | tok/s 20780
step   1640 | loss 1.2465 | lr 3.00e-04 | grad 1.73 | tok/s 20286
step   1650 | loss 1.4260 | lr 3.00e-04 | grad 2.19 | tok/s 19535
step   1660 | loss 1.3314 | lr 3.00e-04 | grad 1.37 | tok/s 20768
step   1670 | loss 1.2647 | lr 3.00e-04 | grad 7.34 | tok/s 20751
step   1680 | loss 1.6095 | lr 3.00e-04 | grad 1.59 | tok/s 19923
step   1690 | loss 1.3695 | lr 3.00e-04 | grad 3.42 | tok/s 20301
step   1700 | loss 1.3815 | lr 3.00e-04 | grad 1.87 | tok/s 20751
step   1710 | loss 1.3209 | lr 3.00e-04 | grad 1.74 | tok/s 20304
step   1720 | loss 1.4080 | lr 3.00e-04 | grad 2.14 | tok/s 21223
step   1730 | loss 1.1203 | lr 3.00e-04 | grad 2.39 | tok/s 21365
step   1740 | loss 1.2304 | lr 3.00e-04 | grad 2.23 | tok/s 20897
step   1750 | loss 1.5065 | lr 3.00e-04 | grad 2.02 | tok/s 20463
step   1760 | loss 1.4480 | lr 3.00e-04 | grad 1.80 | tok/s 20634
step   1770 | loss 1.3568 | lr 3.00e-04 | grad 1.84 | tok/s 20149
step   1780 | loss 1.4269 | lr 3.00e-04 | grad 1.45 | tok/s 21055
step   1790 | loss 1.3083 | lr 3.00e-04 | grad 1.32 | tok/s 20418
step   1800 | loss 1.5243 | lr 3.00e-04 | grad 1.84 | tok/s 20686
step   1810 | loss 1.3337 | lr 3.00e-04 | grad 1.75 | tok/s 19873
step   1820 | loss 1.3647 | lr 3.00e-04 | grad 4.53 | tok/s 20193
step   1830 | loss 1.3086 | lr 3.00e-04 | grad 1.80 | tok/s 20905
step   1840 | loss 1.4241 | lr 3.00e-04 | grad 2.17 | tok/s 20182
step   1850 | loss 1.2272 | lr 3.00e-04 | grad 1.55 | tok/s 20995
step   1860 | loss 1.2456 | lr 3.00e-04 | grad 1.93 | tok/s 20408
step   1870 | loss 1.3289 | lr 3.00e-04 | grad 2.72 | tok/s 20479
step   1880 | loss 1.1443 | lr 3.00e-04 | grad 1.73 | tok/s 20087
step   1890 | loss 1.4138 | lr 3.00e-04 | grad 1.41 | tok/s 19058
step   1900 | loss 1.3303 | lr 3.00e-04 | grad 2.06 | tok/s 20613
step   1910 | loss 1.3728 | lr 3.00e-04 | grad 2.22 | tok/s 19550
step   1920 | loss 1.3281 | lr 3.00e-04 | grad 1.58 | tok/s 21373
step   1930 | loss 1.3808 | lr 3.00e-04 | grad 1.91 | tok/s 20025
step   1940 | loss 1.3669 | lr 3.00e-04 | grad 1.59 | tok/s 20891
step   1950 | loss 1.7768 | lr 3.00e-04 | grad 3.39 | tok/s 21130
step   1960 | loss 1.3766 | lr 3.00e-04 | grad 3.72 | tok/s 21422
step   1970 | loss 1.4130 | lr 3.00e-04 | grad 2.02 | tok/s 20886
step   1980 | loss 1.4381 | lr 3.00e-04 | grad 1.64 | tok/s 20018
step   1990 | loss 1.4556 | lr 3.00e-04 | grad 6.66 | tok/s 20406
step   2000 | loss 1.4061 | lr 3.00e-04 | grad 1.60 | tok/s 20582
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4061.pt
step   2010 | loss 1.0053 | lr 3.00e-04 | grad 1.42 | tok/s 7940
step   2020 | loss 1.2207 | lr 3.00e-04 | grad 1.67 | tok/s 20639
step   2030 | loss 1.0183 | lr 3.00e-04 | grad 0.86 | tok/s 21741
step   2040 | loss 1.1659 | lr 3.00e-04 | grad 1.78 | tok/s 21619
step   2050 | loss 1.1248 | lr 3.00e-04 | grad 1.84 | tok/s 21166
step   2060 | loss 1.4615 | lr 3.00e-04 | grad 1.88 | tok/s 19963
step   2070 | loss 1.5775 | lr 3.00e-04 | grad 1.98 | tok/s 20690
step   2080 | loss 2.0952 | lr 3.00e-04 | grad 3.66 | tok/s 21335
step   2090 | loss 1.5812 | lr 3.00e-04 | grad 4.06 | tok/s 21413
step   2100 | loss 1.2711 | lr 3.00e-04 | grad 2.19 | tok/s 20869
step   2110 | loss 1.4187 | lr 3.00e-04 | grad 23.62 | tok/s 20482
step   2120 | loss 0.8823 | lr 3.00e-04 | grad 1.96 | tok/s 21272
step   2130 | loss 0.9539 | lr 3.00e-04 | grad 2.67 | tok/s 21252
step   2140 | loss 1.4373 | lr 3.00e-04 | grad 1.34 | tok/s 20451
step   2150 | loss 1.2180 | lr 3.00e-04 | grad 1.61 | tok/s 21501
step   2160 | loss 1.1223 | lr 3.00e-04 | grad 1.22 | tok/s 21411
step   2170 | loss 1.1691 | lr 3.00e-04 | grad 1.28 | tok/s 21481
step   2180 | loss 1.1266 | lr 3.00e-04 | grad 1.57 | tok/s 21377
step   2190 | loss 1.1411 | lr 3.00e-04 | grad 1.19 | tok/s 21469
step   2200 | loss 1.1281 | lr 3.00e-04 | grad 1.36 | tok/s 21428
step   2210 | loss 1.0800 | lr 3.00e-04 | grad 1.23 | tok/s 21458
step   2220 | loss 1.0732 | lr 3.00e-04 | grad 1.21 | tok/s 21437
step   2230 | loss 1.2748 | lr 3.00e-04 | grad 1.55 | tok/s 21101
step   2240 | loss 1.2663 | lr 3.00e-04 | grad 1.44 | tok/s 21361
step   2250 | loss 1.3983 | lr 3.00e-04 | grad 2.62 | tok/s 20656
step   2260 | loss 1.4411 | lr 3.00e-04 | grad 1.61 | tok/s 20873
step   2270 | loss 1.8146 | lr 3.00e-04 | grad 3.98 | tok/s 21240
step   2280 | loss 1.3981 | lr 3.00e-04 | grad 1.98 | tok/s 21216
step   2290 | loss 1.2056 | lr 3.00e-04 | grad 2.14 | tok/s 20663
step   2300 | loss 1.5658 | lr 3.00e-04 | grad 3.69 | tok/s 21161
step   2310 | loss 1.2768 | lr 3.00e-04 | grad 1.41 | tok/s 20072
step   2320 | loss 1.4938 | lr 3.00e-04 | grad 3.88 | tok/s 20173
step   2330 | loss 1.7257 | lr 3.00e-04 | grad 1.67 | tok/s 20471
step   2340 | loss 1.3399 | lr 3.00e-04 | grad 5.00 | tok/s 19950
step   2350 | loss 1.2552 | lr 3.00e-04 | grad 3.86 | tok/s 20955
step   2360 | loss 1.2382 | lr 3.00e-04 | grad 1.93 | tok/s 21149
step   2370 | loss 1.3459 | lr 3.00e-04 | grad 2.84 | tok/s 20975
step   2380 | loss 1.3842 | lr 3.00e-04 | grad 1.88 | tok/s 21426
step   2390 | loss 1.1071 | lr 3.00e-04 | grad 1.53 | tok/s 21422
step   2400 | loss 1.0321 | lr 3.00e-04 | grad 1.43 | tok/s 21387
step   2410 | loss 1.0099 | lr 3.00e-04 | grad 1.60 | tok/s 20810
step   2420 | loss 1.3753 | lr 3.00e-04 | grad 3.36 | tok/s 20051
step   2430 | loss 1.3165 | lr 3.00e-04 | grad 1.64 | tok/s 20457
step   2440 | loss 1.1373 | lr 3.00e-04 | grad 3.20 | tok/s 20947
step   2450 | loss 1.3691 | lr 3.00e-04 | grad 1.77 | tok/s 20449
step   2460 | loss 1.2406 | lr 3.00e-04 | grad 1.74 | tok/s 21165
step   2470 | loss 1.0684 | lr 3.00e-04 | grad 1.96 | tok/s 21162
step   2480 | loss 1.1673 | lr 3.00e-04 | grad 1.36 | tok/s 21345
step   2490 | loss 1.2321 | lr 3.00e-04 | grad 1.58 | tok/s 20270
step   2500 | loss 1.4389 | lr 3.00e-04 | grad 1.98 | tok/s 20882
step   2510 | loss 1.0365 | lr 3.00e-04 | grad 2.30 | tok/s 21403
step   2520 | loss 1.2852 | lr 3.00e-04 | grad 4.69 | tok/s 21297
step   2530 | loss 1.2661 | lr 3.00e-04 | grad 1.41 | tok/s 20586
step   2540 | loss 1.2970 | lr 3.00e-04 | grad 2.62 | tok/s 20402
step   2550 | loss 1.1034 | lr 3.00e-04 | grad 1.43 | tok/s 21242
step   2560 | loss 1.3277 | lr 3.00e-04 | grad 6.19 | tok/s 19881
step   2570 | loss 1.3008 | lr 3.00e-04 | grad 1.42 | tok/s 20814
step   2580 | loss 1.2625 | lr 3.00e-04 | grad 2.08 | tok/s 19517
step   2590 | loss 1.2199 | lr 3.00e-04 | grad 1.98 | tok/s 20598
step   2600 | loss 1.4674 | lr 3.00e-04 | grad 3.59 | tok/s 19773
step   2610 | loss 1.2050 | lr 3.00e-04 | grad 2.05 | tok/s 21254
step   2620 | loss 1.4378 | lr 3.00e-04 | grad 1.64 | tok/s 20476
step   2630 | loss 1.3420 | lr 3.00e-04 | grad 1.50 | tok/s 21181
step   2640 | loss 1.3454 | lr 3.00e-04 | grad 1.77 | tok/s 20563
step   2650 | loss 1.3957 | lr 3.00e-04 | grad 2.45 | tok/s 21372
step   2660 | loss 1.2412 | lr 3.00e-04 | grad 1.73 | tok/s 20585
step   2670 | loss 1.3164 | lr 3.00e-04 | grad 2.38 | tok/s 19894
step   2680 | loss 1.4324 | lr 3.00e-04 | grad 8.12 | tok/s 20227
step   2690 | loss 1.1990 | lr 3.00e-04 | grad 1.34 | tok/s 21223
step   2700 | loss 1.3379 | lr 3.00e-04 | grad 1.60 | tok/s 20593
step   2710 | loss 1.4133 | lr 3.00e-04 | grad 2.44 | tok/s 20339
step   2720 | loss 1.2482 | lr 3.00e-04 | grad 1.59 | tok/s 19425
step   2730 | loss 1.0896 | lr 3.00e-04 | grad 1.79 | tok/s 20924
step   2740 | loss 1.5374 | lr 3.00e-04 | grad 5.31 | tok/s 20682
step   2750 | loss 1.4691 | lr 3.00e-04 | grad 1.78 | tok/s 21189
step   2760 | loss 1.2219 | lr 3.00e-04 | grad 1.62 | tok/s 19691
step   2770 | loss 1.3979 | lr 3.00e-04 | grad 2.38 | tok/s 20330
step   2780 | loss 0.9936 | lr 3.00e-04 | grad 1.41 | tok/s 21326
step   2790 | loss 1.5037 | lr 3.00e-04 | grad 4.44 | tok/s 19895
step   2800 | loss 1.2939 | lr 3.00e-04 | grad 1.20 | tok/s 20450
step   2810 | loss 1.1582 | lr 3.00e-04 | grad 1.73 | tok/s 20372
step   2820 | loss 1.3176 | lr 3.00e-04 | grad 1.38 | tok/s 19687
step   2830 | loss 1.0015 | lr 3.00e-04 | grad 2.48 | tok/s 20900
step   2840 | loss 0.6303 | lr 3.00e-04 | grad 1.88 | tok/s 21326
step   2850 | loss 1.6166 | lr 3.00e-04 | grad 1.80 | tok/s 20604
step   2860 | loss 1.4900 | lr 3.00e-04 | grad 1.33 | tok/s 20594
step   2870 | loss 1.2631 | lr 3.00e-04 | grad 1.60 | tok/s 20087
step   2880 | loss 1.3908 | lr 3.00e-04 | grad 2.72 | tok/s 20786
step   2890 | loss 1.1451 | lr 3.00e-04 | grad 1.98 | tok/s 21293
step   2900 | loss 1.3430 | lr 3.00e-04 | grad 1.37 | tok/s 20484
step   2910 | loss 1.2365 | lr 3.00e-04 | grad 1.47 | tok/s 20537
step   2920 | loss 1.4196 | lr 3.00e-04 | grad 1.94 | tok/s 19952
step   2930 | loss 1.4546 | lr 3.00e-04 | grad 1.49 | tok/s 20884
step   2940 | loss 1.2088 | lr 3.00e-04 | grad 1.93 | tok/s 19192
step   2950 | loss 1.2764 | lr 3.00e-04 | grad 2.11 | tok/s 20635
step   2960 | loss 1.2072 | lr 3.00e-04 | grad 2.41 | tok/s 20709
step   2970 | loss 1.2190 | lr 3.00e-04 | grad 1.81 | tok/s 20942
step   2980 | loss 1.6210 | lr 3.00e-04 | grad 1.49 | tok/s 20224
step   2990 | loss 1.8735 | lr 3.00e-04 | grad 2.12 | tok/s 20837
step   3000 | loss 1.2476 | lr 3.00e-04 | grad 3.47 | tok/s 20795
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2476.pt

Training complete! Final step: 3007
