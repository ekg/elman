Loading data from data/fineweb_100mb.txt...

Creating mamba2 model with ~50m parameters...
Created Mamba2 model: dim=672, depth=18, expand=2, params=50,928,750

============================================================
Training: mamba2 (steps=1000)
Parameters: 50.93M
Vocab size: 256
============================================================
[mamba2] step    1 | loss 5.7188 | ppl 304.5 | grad 5.38 | 157 tok/s | 13.1s | 13058ms/step
[mamba2] step   50 | loss 2.2656 | ppl 9.6 | grad 2.53 | 5651 tok/s | 18.1s | 105ms/step
[mamba2] step  100 | loss 2.1562 | ppl 8.6 | grad 2.81 | 8736 tok/s | 23.4s | 107ms/step
[mamba2] step  150 | loss 1.8672 | ppl 6.5 | grad 2.84 | 10678 tok/s | 28.8s | 106ms/step
[mamba2] step  200 | loss 1.5391 | ppl 4.7 | grad 1.83 | 12023 tok/s | 34.1s | 104ms/step
[mamba2] step  250 | loss 1.5547 | ppl 4.7 | grad 1.99 | 12997 tok/s | 39.4s | 107ms/step
[mamba2] step  300 | loss 1.6875 | ppl 5.4 | grad 2.03 | 13741 tok/s | 44.7s | 107ms/step
[mamba2] step  350 | loss 1.6875 | ppl 5.4 | grad 2.06 | 14324 tok/s | 50.0s | 106ms/step
[mamba2] step  400 | loss 1.5078 | ppl 4.5 | grad 1.93 | 14801 tok/s | 55.3s | 106ms/step
[mamba2] step  450 | loss 1.5859 | ppl 4.9 | grad 1.80 | 15194 tok/s | 60.7s | 107ms/step
[mamba2] step  500 | loss 1.4688 | ppl 4.3 | grad 2.08 | 15573 tok/s | 65.8s | 92ms/step
[mamba2] step  550 | loss 1.5156 | ppl 4.6 | grad 2.03 | 16002 tok/s | 70.4s | 92ms/step
[mamba2] step  600 | loss 1.7969 | ppl 6.0 | grad 2.50 | 16377 tok/s | 75.0s | 92ms/step
[mamba2] step  650 | loss 1.4141 | ppl 4.1 | grad 2.45 | 16704 tok/s | 79.7s | 93ms/step
[mamba2] step  700 | loss 1.3828 | ppl 4.0 | grad 2.25 | 16998 tok/s | 84.3s | 93ms/step
[mamba2] step  750 | loss 1.4766 | ppl 4.4 | grad 1.95 | 17262 tok/s | 89.0s | 93ms/step
[mamba2] step  800 | loss 1.8281 | ppl 6.2 | grad 2.52 | 17500 tok/s | 93.6s | 92ms/step
[mamba2] step  850 | loss 1.5312 | ppl 4.6 | grad 2.23 | 17712 tok/s | 98.3s | 93ms/step
[mamba2] step  900 | loss 1.4922 | ppl 4.4 | grad 2.59 | 17909 tok/s | 102.9s | 92ms/step
[mamba2] step  950 | loss 1.4844 | ppl 4.4 | grad 1.94 | 18089 tok/s | 107.6s | 93ms/step
[mamba2] step 1000 | loss 1.7656 | ppl 5.8 | grad 2.42 | 18248 tok/s | 112.2s | 93ms/step

mamba2 Final: loss=1.8441, grad=2.39, steps=1000, tokens=2,048,000, time=112.2s

==========================================================================================
BENCHMARK SUMMARY
==========================================================================================
Model           Params       Loss       Steps    Tokens       tok/s      Time    
------------------------------------------------------------------------------------------
mamba2          50.93M       1.8441     1000     2,048,000    18248      112.2   s

Results saved to: benchmark_results/eseries_50m_20260104_142334
