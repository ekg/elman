{
  "config": {
    "data": "data/fineweb_100mb.txt",
    "params": "50m",
    "batch_size": 4,
    "chunk_size": 512,
    "max_steps": 1000,
    "lr": 0.0003
  },
  "results": [
    {
      "model": "mamba2",
      "num_params": 50928750,
      "losses": [
        5.71875,
        2.265625,
        2.15625,
        1.8671875,
        1.5390625,
        1.5546875,
        1.6875,
        1.6875,
        1.5078125,
        1.5859375,
        1.46875,
        1.515625,
        1.796875,
        1.4140625,
        1.3828125,
        1.4765625,
        1.828125,
        1.53125,
        1.4921875,
        1.484375,
        1.765625
      ],
      "grad_norms": [
        5.375,
        2.53125,
        2.8125,
        2.84375,
        1.828125,
        1.9921875,
        2.03125,
        2.0625,
        1.9296875,
        1.796875,
        2.078125,
        2.03125,
        2.5,
        2.453125,
        2.25,
        1.953125,
        2.515625,
        2.234375,
        2.59375,
        1.9375,
        2.421875
      ],
      "step_times_ms": [
        13057.838201522827,
        105.13639450073242,
        106.60982131958008,
        106.02855682373047,
        104.4917106628418,
        107.05184936523438,
        106.69398307800293,
        105.92818260192871,
        105.66592216491699,
        107.21254348754883,
        92.07749366760254,
        91.96043014526367,
        92.33570098876953,
        93.33086013793945,
        92.73362159729004,
        93.0640697479248,
        92.48733520507812,
        93.1692123413086,
        92.42892265319824,
        93.2469367980957,
        92.86856651306152
      ],
      "final_loss": 1.8441220238095237,
      "final_grad_norm": 2.3891369047619047,
      "avg_step_time_ms": 715.8266816820417,
      "total_time_s": 112.22983741760254,
      "total_steps": 1000,
      "tokens_seen": 2048000
    }
  ]
}