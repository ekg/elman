Using device: cuda
Output directory: benchmark_results/e87_100m_20260119_152323/87b4k1/level87b4k1_100m_20260119_152330
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level 87b4k1, 52,770,176 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.7338 | lr 2.70e-06 | grad 88.00 | tok/s 18367
step     20 | loss 5.6873 | lr 5.70e-06 | grad 31.00 | tok/s 39446
step     30 | loss 5.8314 | lr 8.70e-06 | grad 28.50 | tok/s 41775
step     40 | loss 5.7959 | lr 1.17e-05 | grad 30.38 | tok/s 41763
step     50 | loss 5.7558 | lr 1.47e-05 | grad 26.62 | tok/s 41745
step     60 | loss 5.6315 | lr 1.77e-05 | grad 108.00 | tok/s 40905
step     70 | loss 5.3240 | lr 2.07e-05 | grad 105.00 | tok/s 39500
step     80 | loss 5.0066 | lr 2.37e-05 | grad 17.50 | tok/s 41022
step     90 | loss 4.9174 | lr 2.67e-05 | grad 22.25 | tok/s 39638
step    100 | loss 4.6642 | lr 2.97e-05 | grad 17.38 | tok/s 39982
step    110 | loss 4.4128 | lr 3.27e-05 | grad 65.50 | tok/s 39421
step    120 | loss 4.3651 | lr 3.57e-05 | grad 14.75 | tok/s 38866
step    130 | loss 4.2120 | lr 3.87e-05 | grad 8.56 | tok/s 39765
step    140 | loss 3.8653 | lr 4.17e-05 | grad 22.62 | tok/s 39789
step    150 | loss 3.6262 | lr 4.47e-05 | grad 5.22 | tok/s 37970
step    160 | loss 3.4119 | lr 4.77e-05 | grad 4.94 | tok/s 38235
step    170 | loss 3.4532 | lr 5.07e-05 | grad 18.38 | tok/s 39689
step    180 | loss 3.4500 | lr 5.37e-05 | grad 4.22 | tok/s 39674
step    190 | loss 3.2807 | lr 5.67e-05 | grad 5.47 | tok/s 40307
step    200 | loss 3.2121 | lr 5.97e-05 | grad 29.62 | tok/s 41214
step    210 | loss 3.1955 | lr 6.27e-05 | grad 4.78 | tok/s 39497
step    220 | loss 3.2012 | lr 6.57e-05 | grad 3.72 | tok/s 40801
step    230 | loss 2.9539 | lr 6.87e-05 | grad 9.31 | tok/s 39411
step    240 | loss 3.0658 | lr 7.17e-05 | grad 4.41 | tok/s 40187
step    250 | loss 2.8688 | lr 7.47e-05 | grad 3.17 | tok/s 39625
step    260 | loss 2.8159 | lr 7.77e-05 | grad 2.86 | tok/s 38023
step    270 | loss 2.7051 | lr 8.07e-05 | grad 3.91 | tok/s 39473
step    280 | loss 2.7508 | lr 8.37e-05 | grad 5.59 | tok/s 39365
step    290 | loss 2.5809 | lr 8.67e-05 | grad 2.78 | tok/s 41522
step    300 | loss 2.4841 | lr 8.97e-05 | grad 2.59 | tok/s 41552
step    310 | loss 2.4003 | lr 9.27e-05 | grad 2.78 | tok/s 41494
step    320 | loss 2.4869 | lr 9.57e-05 | grad 16.88 | tok/s 40001
step    330 | loss 2.5726 | lr 9.87e-05 | grad 4.84 | tok/s 39015
step    340 | loss 2.5419 | lr 1.02e-04 | grad 3.72 | tok/s 39836
step    350 | loss 2.5241 | lr 1.05e-04 | grad 3.12 | tok/s 38702
step    360 | loss 2.5287 | lr 1.08e-04 | grad 5.91 | tok/s 39193
step    370 | loss 2.3995 | lr 1.11e-04 | grad 3.02 | tok/s 39939
step    380 | loss 2.8684 | lr 1.14e-04 | grad 3.48 | tok/s 40929
step    390 | loss 2.4622 | lr 1.17e-04 | grad 2.33 | tok/s 39423
step    400 | loss 2.5327 | lr 1.20e-04 | grad 5.53 | tok/s 40444
step    410 | loss 2.3798 | lr 1.23e-04 | grad 3.42 | tok/s 39192
step    420 | loss 2.3892 | lr 1.26e-04 | grad 2.44 | tok/s 38990
step    430 | loss 2.5177 | lr 1.29e-04 | grad 3.91 | tok/s 38864
step    440 | loss 2.6800 | lr 1.32e-04 | grad 2.91 | tok/s 40424
step    450 | loss 2.3460 | lr 1.35e-04 | grad 3.34 | tok/s 39290
step    460 | loss 2.3293 | lr 1.38e-04 | grad 2.41 | tok/s 39456
step    470 | loss 2.3365 | lr 1.41e-04 | grad 2.95 | tok/s 39922
step    480 | loss 2.2403 | lr 1.44e-04 | grad 1.62 | tok/s 38495
step    490 | loss 2.1290 | lr 1.47e-04 | grad 1.87 | tok/s 39218
step    500 | loss 3.0333 | lr 1.50e-04 | grad 2.69 | tok/s 40398
step    510 | loss 2.3237 | lr 1.53e-04 | grad 5.62 | tok/s 39546
step    520 | loss 2.3183 | lr 1.56e-04 | grad 1.74 | tok/s 40773
step    530 | loss 2.6677 | lr 1.59e-04 | grad 3.70 | tok/s 39931
step    540 | loss 2.3097 | lr 1.62e-04 | grad 2.44 | tok/s 39894
step    550 | loss 2.0772 | lr 1.65e-04 | grad 1.45 | tok/s 41040
step    560 | loss 1.8965 | lr 1.68e-04 | grad 1.52 | tok/s 41588
step    570 | loss 2.2133 | lr 1.71e-04 | grad 5.62 | tok/s 40630
step    580 | loss 2.7334 | lr 1.74e-04 | grad 7.38 | tok/s 40077
step    590 | loss 2.8137 | lr 1.77e-04 | grad 4.75 | tok/s 39275
step    600 | loss 2.2785 | lr 1.80e-04 | grad 3.64 | tok/s 39379
step    610 | loss 2.3341 | lr 1.83e-04 | grad 2.59 | tok/s 41279
step    620 | loss 2.1532 | lr 1.86e-04 | grad 2.14 | tok/s 39162
step    630 | loss 2.1125 | lr 1.89e-04 | grad 1.48 | tok/s 40426
step    640 | loss 2.5598 | lr 1.92e-04 | grad 1.94 | tok/s 40420
step    650 | loss 2.1670 | lr 1.95e-04 | grad 1.94 | tok/s 39683
step    660 | loss 2.4465 | lr 1.98e-04 | grad 4.81 | tok/s 39170
step    670 | loss 2.3101 | lr 2.01e-04 | grad 2.56 | tok/s 40555
step    680 | loss 2.2558 | lr 2.04e-04 | grad 2.88 | tok/s 39093
step    690 | loss 2.2638 | lr 2.07e-04 | grad 1.80 | tok/s 39413
step    700 | loss 2.3113 | lr 2.10e-04 | grad 1.73 | tok/s 39588
step    710 | loss 2.2709 | lr 2.13e-04 | grad 1.48 | tok/s 39861
step    720 | loss 2.2987 | lr 2.16e-04 | grad 7.19 | tok/s 39688
step    730 | loss 2.3893 | lr 2.19e-04 | grad 1.81 | tok/s 40079
step    740 | loss 2.2705 | lr 2.22e-04 | grad 2.62 | tok/s 39713
step    750 | loss 2.0518 | lr 2.25e-04 | grad 1.80 | tok/s 39286
step    760 | loss 2.4975 | lr 2.28e-04 | grad 1.38 | tok/s 39743
step    770 | loss 2.0421 | lr 2.31e-04 | grad 1.67 | tok/s 39492
step    780 | loss 2.0925 | lr 2.34e-04 | grad 1.84 | tok/s 39952
step    790 | loss 2.0692 | lr 2.37e-04 | grad 1.25 | tok/s 40267
step    800 | loss 2.0424 | lr 2.40e-04 | grad 1.30 | tok/s 40281
step    810 | loss 2.1005 | lr 2.43e-04 | grad 2.91 | tok/s 39900
step    820 | loss 2.7009 | lr 2.46e-04 | grad 1.84 | tok/s 40947
step    830 | loss 2.2370 | lr 2.49e-04 | grad 1.13 | tok/s 41656
step    840 | loss 1.9346 | lr 2.52e-04 | grad 0.82 | tok/s 41635
step    850 | loss 2.4468 | lr 2.55e-04 | grad 1.94 | tok/s 39624
step    860 | loss 2.1836 | lr 2.58e-04 | grad 1.34 | tok/s 38747
step    870 | loss 2.1050 | lr 2.61e-04 | grad 1.20 | tok/s 39917
step    880 | loss 2.1694 | lr 2.64e-04 | grad 1.66 | tok/s 39730
step    890 | loss 2.0148 | lr 2.67e-04 | grad 1.09 | tok/s 39746
step    900 | loss 2.4885 | lr 2.70e-04 | grad 1.14 | tok/s 38697
step    910 | loss 2.0660 | lr 2.73e-04 | grad 1.13 | tok/s 39437
step    920 | loss 1.9920 | lr 2.76e-04 | grad 0.96 | tok/s 39273
step    930 | loss 2.0887 | lr 2.79e-04 | grad 1.59 | tok/s 39195
step    940 | loss 1.9939 | lr 2.82e-04 | grad 1.50 | tok/s 38793
step    950 | loss 2.0931 | lr 2.85e-04 | grad 1.56 | tok/s 39695
step    960 | loss 1.7913 | lr 2.88e-04 | grad 0.80 | tok/s 41686
step    970 | loss 1.6159 | lr 2.91e-04 | grad 0.71 | tok/s 41728
step    980 | loss 1.8169 | lr 2.94e-04 | grad 2.47 | tok/s 40508
step    990 | loss 2.2092 | lr 2.97e-04 | grad 1.02 | tok/s 39354
step   1000 | loss 2.0359 | lr 3.00e-04 | grad 0.78 | tok/s 38444
  >>> saved checkpoint: checkpoint_step_001000_loss_2.0359.pt
step   1010 | loss 2.3403 | lr 1.06e-06 | grad 4.22 | tok/s 35197
step   1020 | loss 1.9748 | lr 1.27e-06 | grad 0.89 | tok/s 38122
step   1030 | loss 2.2696 | lr 1.62e-06 | grad 0.95 | tok/s 37475
step   1040 | loss 1.9312 | lr 2.12e-06 | grad 1.56 | tok/s 38281
step   1050 | loss 1.9725 | lr 2.77e-06 | grad 0.95 | tok/s 38370
step   1060 | loss 2.3820 | lr 3.56e-06 | grad 2.47 | tok/s 38430
step   1070 | loss 2.4439 | lr 4.50e-06 | grad 1.00 | tok/s 38580
step   1080 | loss 2.6049 | lr 5.58e-06 | grad 1.32 | tok/s 38093
step   1090 | loss 2.3263 | lr 6.81e-06 | grad 1.04 | tok/s 38395
step   1100 | loss 2.0018 | lr 8.17e-06 | grad 0.99 | tok/s 38140
step   1110 | loss 2.0946 | lr 9.68e-06 | grad 1.02 | tok/s 38821
step   1120 | loss 2.4826 | lr 1.13e-05 | grad 0.98 | tok/s 39265
step   1130 | loss 2.0097 | lr 1.31e-05 | grad 0.74 | tok/s 37342
step   1140 | loss 1.9015 | lr 1.50e-05 | grad 0.91 | tok/s 38248
step   1150 | loss 2.2214 | lr 1.71e-05 | grad 1.38 | tok/s 38176
step   1160 | loss 1.8511 | lr 1.93e-05 | grad 0.69 | tok/s 37825
step   1170 | loss 2.1925 | lr 2.16e-05 | grad 0.83 | tok/s 38270
step   1180 | loss 1.9165 | lr 2.40e-05 | grad 0.95 | tok/s 40234
step   1190 | loss 1.8861 | lr 2.66e-05 | grad 0.75 | tok/s 40263
step   1200 | loss 1.8354 | lr 2.93e-05 | grad 0.73 | tok/s 40276
step   1210 | loss 1.8260 | lr 3.21e-05 | grad 0.70 | tok/s 40254
step   1220 | loss 1.8384 | lr 3.50e-05 | grad 0.82 | tok/s 39803
step   1230 | loss 1.7824 | lr 3.80e-05 | grad 0.78 | tok/s 38408
step   1240 | loss 1.9210 | lr 4.12e-05 | grad 0.84 | tok/s 37794
step   1250 | loss 2.0289 | lr 4.45e-05 | grad 3.08 | tok/s 38927
step   1260 | loss 2.0625 | lr 4.78e-05 | grad 2.84 | tok/s 38938
step   1270 | loss 2.1124 | lr 5.13e-05 | grad 1.37 | tok/s 38457
step   1280 | loss 2.0013 | lr 5.48e-05 | grad 0.96 | tok/s 37951
step   1290 | loss 1.9185 | lr 5.85e-05 | grad 1.03 | tok/s 37831
step   1300 | loss 1.9562 | lr 6.22e-05 | grad 0.87 | tok/s 37504
step   1310 | loss 2.0728 | lr 6.61e-05 | grad 0.94 | tok/s 37530
step   1320 | loss 1.9870 | lr 7.00e-05 | grad 1.26 | tok/s 38217
step   1330 | loss 1.9219 | lr 7.40e-05 | grad 0.84 | tok/s 38289
step   1340 | loss 1.8566 | lr 7.81e-05 | grad 1.09 | tok/s 38319
step   1350 | loss 1.9584 | lr 8.22e-05 | grad 2.17 | tok/s 39326
step   1360 | loss 1.8225 | lr 8.64e-05 | grad 0.79 | tok/s 37380
step   1370 | loss 1.9610 | lr 9.07e-05 | grad 0.68 | tok/s 37953
step   1380 | loss 2.0237 | lr 9.50e-05 | grad 1.12 | tok/s 38219
step   1390 | loss 1.9146 | lr 9.94e-05 | grad 1.78 | tok/s 37228
step   1400 | loss 1.9603 | lr 1.04e-04 | grad 9.56 | tok/s 38802
step   1410 | loss 1.9942 | lr 1.08e-04 | grad 1.00 | tok/s 39223
step   1420 | loss 1.9669 | lr 1.13e-04 | grad 1.05 | tok/s 37328
step   1430 | loss 1.7809 | lr 1.17e-04 | grad 1.03 | tok/s 36403
step   1440 | loss 1.7278 | lr 1.22e-04 | grad 0.90 | tok/s 38469
step   1450 | loss 1.8228 | lr 1.27e-04 | grad 2.28 | tok/s 39275
step   1460 | loss 1.8346 | lr 1.31e-04 | grad 0.79 | tok/s 36624
step   1470 | loss 1.9603 | lr 1.36e-04 | grad 2.39 | tok/s 37951
step   1480 | loss 1.8553 | lr 1.41e-04 | grad 2.36 | tok/s 38365
step   1490 | loss 1.9845 | lr 1.45e-04 | grad 2.61 | tok/s 38416

Training complete! Final step: 1492
