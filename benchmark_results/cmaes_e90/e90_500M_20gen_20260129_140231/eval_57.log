Using device: cuda
Output directory: benchmark_results/cmaes_e90/e90_500M_20gen_20260129_140231/eval_57/levelE90_100m_20260129_143425
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E90, 492,796,436 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 2.0 minutes
step     10 | loss 4.5956 | lr 3.00e-04 | grad 13.56 | tok/s 6057
step     20 | loss 3.1475 | lr 3.00e-04 | grad 6.44 | tok/s 15044
step     30 | loss 2.5912 | lr 3.00e-04 | grad 3.77 | tok/s 15248
step     40 | loss 2.3466 | lr 3.00e-04 | grad 3.92 | tok/s 14628
step     50 | loss 2.9381 | lr 3.00e-04 | grad 11.94 | tok/s 14875
step     60 | loss 2.0526 | lr 3.00e-04 | grad 3.03 | tok/s 15382
step     70 | loss 1.8907 | lr 3.00e-04 | grad 4.56 | tok/s 15561
step     80 | loss 5.1718 | lr 3.00e-04 | grad 49.50 | tok/s 15661
step     90 | loss 4.5895 | lr 3.00e-04 | grad 5.94 | tok/s 15821
step    100 | loss 3.7898 | lr 3.00e-04 | grad 6.12 | tok/s 15797
step    110 | loss 3.1915 | lr 3.00e-04 | grad 12.19 | tok/s 15782
step    120 | loss 3.0549 | lr 3.00e-04 | grad 7.44 | tok/s 15784
step    130 | loss 2.8111 | lr 3.00e-04 | grad 8.75 | tok/s 15748
step    140 | loss 2.7155 | lr 3.00e-04 | grad 9.69 | tok/s 15705
step    150 | loss 2.6460 | lr 3.00e-04 | grad 8.31 | tok/s 15675
step    160 | loss 2.3237 | lr 3.00e-04 | grad 6.38 | tok/s 15653
step    170 | loss 2.3502 | lr 3.00e-04 | grad 8.75 | tok/s 15586
step    180 | loss 2.1654 | lr 3.00e-04 | grad 6.97 | tok/s 15632
step    190 | loss 2.2864 | lr 3.00e-04 | grad 5.00 | tok/s 15621
step    200 | loss 2.0164 | lr 3.00e-04 | grad 3.84 | tok/s 15575
step    210 | loss 2.0757 | lr 3.00e-04 | grad 7.03 | tok/s 15575
step    220 | loss 2.1112 | lr 3.00e-04 | grad 3.16 | tok/s 15393
step    230 | loss 2.0417 | lr 3.00e-04 | grad 3.16 | tok/s 15201
step    240 | loss 2.2714 | lr 3.00e-04 | grad 4.31 | tok/s 14473
step    250 | loss 2.0902 | lr 3.00e-04 | grad 2.48 | tok/s 14882
step    260 | loss 1.5586 | lr 3.00e-04 | grad 2.89 | tok/s 15334
step    270 | loss 2.0774 | lr 3.00e-04 | grad 2.78 | tok/s 15165
step    280 | loss 2.2372 | lr 3.00e-04 | grad 5.38 | tok/s 14869
step    290 | loss 1.4094 | lr 3.00e-04 | grad 3.81 | tok/s 15644
step    300 | loss 0.6023 | lr 3.00e-04 | grad 2.38 | tok/s 15615
step    310 | loss 2.3890 | lr 3.00e-04 | grad 3.67 | tok/s 15335
step    320 | loss 1.9175 | lr 3.00e-04 | grad 5.38 | tok/s 15022
step    330 | loss 1.9587 | lr 3.00e-04 | grad 3.12 | tok/s 14496
step    340 | loss 2.2697 | lr 3.00e-04 | grad 2.72 | tok/s 14728
step    350 | loss 1.8701 | lr 3.00e-04 | grad 4.19 | tok/s 15104
step    360 | loss 1.2363 | lr 3.00e-04 | grad 8.81 | tok/s 15446
step    370 | loss 1.8208 | lr 3.00e-04 | grad 2.80 | tok/s 14020
step    380 | loss 1.7614 | lr 3.00e-04 | grad 2.86 | tok/s 14910
step    390 | loss 1.5410 | lr 3.00e-04 | grad 2.20 | tok/s 15581
step    400 | loss 1.5030 | lr 3.00e-04 | grad 2.53 | tok/s 15449
step    410 | loss 1.2859 | lr 3.00e-04 | grad 2.09 | tok/s 15103
step    420 | loss 1.8281 | lr 3.00e-04 | grad 4.78 | tok/s 14403
step    430 | loss 2.1618 | lr 3.00e-04 | grad 3.20 | tok/s 15328

Training complete! Final step: 439
