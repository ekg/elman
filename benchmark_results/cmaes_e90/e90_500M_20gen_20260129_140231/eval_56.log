Using device: cuda
Output directory: benchmark_results/cmaes_e90/e90_500M_20gen_20260129_140231/eval_56/levelE90_100m_20260129_143208
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E90, 497,337,754 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 2.0 minutes
step     10 | loss 4.2646 | lr 3.00e-04 | grad 13.44 | tok/s 5778
step     20 | loss 2.9112 | lr 3.00e-04 | grad 5.81 | tok/s 13548
step     30 | loss 2.5277 | lr 3.00e-04 | grad 3.70 | tok/s 13698
step     40 | loss 2.3747 | lr 3.00e-04 | grad 3.61 | tok/s 13071
step     50 | loss 2.9386 | lr 3.00e-04 | grad 13.06 | tok/s 13282
step     60 | loss 2.0835 | lr 3.00e-04 | grad 3.59 | tok/s 13674
step     70 | loss 1.9056 | lr 3.00e-04 | grad 4.81 | tok/s 13805
step     80 | loss 5.2136 | lr 3.00e-04 | grad 59.00 | tok/s 13889
step     90 | loss 4.6804 | lr 3.00e-04 | grad 8.12 | tok/s 14115
step    100 | loss 3.8137 | lr 3.00e-04 | grad 7.19 | tok/s 14139
step    110 | loss 3.2645 | lr 3.00e-04 | grad 12.38 | tok/s 14081
step    120 | loss 3.0452 | lr 3.00e-04 | grad 11.88 | tok/s 14008
step    130 | loss 2.7894 | lr 3.00e-04 | grad 10.62 | tok/s 13975
step    140 | loss 2.6631 | lr 3.00e-04 | grad 7.62 | tok/s 13955
step    150 | loss 2.6447 | lr 3.00e-04 | grad 7.25 | tok/s 13925
step    160 | loss 2.2766 | lr 3.00e-04 | grad 8.94 | tok/s 13935
step    170 | loss 2.4005 | lr 3.00e-04 | grad 9.31 | tok/s 13931
step    180 | loss 2.1726 | lr 3.00e-04 | grad 7.00 | tok/s 13921
step    190 | loss 2.3374 | lr 3.00e-04 | grad 9.00 | tok/s 13893
step    200 | loss 2.0277 | lr 3.00e-04 | grad 3.69 | tok/s 13896
step    210 | loss 2.0996 | lr 3.00e-04 | grad 4.88 | tok/s 13866
step    220 | loss 2.1506 | lr 3.00e-04 | grad 3.19 | tok/s 13712
step    230 | loss 2.0683 | lr 3.00e-04 | grad 3.17 | tok/s 13530
step    240 | loss 2.2893 | lr 3.00e-04 | grad 4.88 | tok/s 12872
step    250 | loss 2.1096 | lr 3.00e-04 | grad 2.69 | tok/s 13242
step    260 | loss 1.5979 | lr 3.00e-04 | grad 3.02 | tok/s 13664
step    270 | loss 2.1040 | lr 3.00e-04 | grad 2.89 | tok/s 13499
step    280 | loss 2.2718 | lr 3.00e-04 | grad 5.75 | tok/s 13236
step    290 | loss 1.5096 | lr 3.00e-04 | grad 22.62 | tok/s 13846
step    300 | loss 0.6232 | lr 3.00e-04 | grad 8.38 | tok/s 13858
step    310 | loss 2.4296 | lr 3.00e-04 | grad 3.33 | tok/s 13639
step    320 | loss 1.9662 | lr 3.00e-04 | grad 5.38 | tok/s 13343
step    330 | loss 1.9749 | lr 3.00e-04 | grad 3.22 | tok/s 12879
step    340 | loss 2.3115 | lr 3.00e-04 | grad 2.89 | tok/s 13074
step    350 | loss 1.9225 | lr 3.00e-04 | grad 3.67 | tok/s 13405
step    360 | loss 1.2838 | lr 3.00e-04 | grad 11.00 | tok/s 13688
step    370 | loss 1.8499 | lr 3.00e-04 | grad 2.97 | tok/s 12411
step    380 | loss 1.7973 | lr 3.00e-04 | grad 2.70 | tok/s 13233
step    390 | loss 1.5627 | lr 3.00e-04 | grad 2.28 | tok/s 13826

Training complete! Final step: 391
