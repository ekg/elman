Using device: cuda
Output directory: benchmark_results/cmaes_e90/e90_500M_20gen_20260129_140231/eval_65/levelE90_100m_20260129_143858
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E90, 508,730,192 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 2.0 minutes
step     10 | loss 4.4896 | lr 3.00e-04 | grad 18.75 | tok/s 5917
step     20 | loss 3.1391 | lr 3.00e-04 | grad 8.50 | tok/s 14940
step     30 | loss 2.6063 | lr 3.00e-04 | grad 4.06 | tok/s 15114
step     40 | loss 2.3539 | lr 3.00e-04 | grad 4.00 | tok/s 14486
step     50 | loss 2.9025 | lr 3.00e-04 | grad 15.56 | tok/s 14682
step     60 | loss 2.0525 | lr 3.00e-04 | grad 4.22 | tok/s 15156
step     70 | loss 1.8653 | lr 3.00e-04 | grad 4.97 | tok/s 15307
step     80 | loss 5.3460 | lr 3.00e-04 | grad 60.50 | tok/s 15405
step     90 | loss 4.7662 | lr 3.00e-04 | grad 8.06 | tok/s 15668
step    100 | loss 3.8779 | lr 3.00e-04 | grad 6.75 | tok/s 15602
step    110 | loss 3.2720 | lr 3.00e-04 | grad 13.50 | tok/s 15580
step    120 | loss 3.1450 | lr 3.00e-04 | grad 11.56 | tok/s 15550
step    130 | loss 2.8761 | lr 3.00e-04 | grad 11.50 | tok/s 15528
step    140 | loss 2.6998 | lr 3.00e-04 | grad 9.12 | tok/s 15621
step    150 | loss 2.7675 | lr 3.00e-04 | grad 15.12 | tok/s 15530
step    160 | loss 2.3550 | lr 3.00e-04 | grad 7.53 | tok/s 15500
step    170 | loss 2.4129 | lr 3.00e-04 | grad 11.00 | tok/s 15506
step    180 | loss 2.2383 | lr 3.00e-04 | grad 6.81 | tok/s 15572
step    190 | loss 2.3471 | lr 3.00e-04 | grad 9.75 | tok/s 15467
step    200 | loss 2.0517 | lr 3.00e-04 | grad 4.53 | tok/s 15471
step    210 | loss 2.0940 | lr 3.00e-04 | grad 5.81 | tok/s 15449
step    220 | loss 2.1397 | lr 3.00e-04 | grad 3.41 | tok/s 15283
step    230 | loss 2.0705 | lr 3.00e-04 | grad 3.47 | tok/s 15087
step    240 | loss 2.2826 | lr 3.00e-04 | grad 5.19 | tok/s 14358
step    250 | loss 2.1040 | lr 3.00e-04 | grad 2.75 | tok/s 14751
step    260 | loss 1.5553 | lr 3.00e-04 | grad 3.22 | tok/s 15205
step    270 | loss 2.0781 | lr 3.00e-04 | grad 3.12 | tok/s 14957
step    280 | loss 2.2596 | lr 3.00e-04 | grad 5.81 | tok/s 14714
step    290 | loss 1.4455 | lr 3.00e-04 | grad 27.00 | tok/s 15499
step    300 | loss 0.5777 | lr 3.00e-04 | grad 2.95 | tok/s 15504
step    310 | loss 2.4081 | lr 3.00e-04 | grad 3.92 | tok/s 15216
step    320 | loss 1.9185 | lr 3.00e-04 | grad 5.66 | tok/s 14876
step    330 | loss 1.9560 | lr 3.00e-04 | grad 3.36 | tok/s 14384
step    340 | loss 2.2804 | lr 3.00e-04 | grad 2.97 | tok/s 14618
step    350 | loss 1.8885 | lr 3.00e-04 | grad 4.47 | tok/s 14941
step    360 | loss 1.2403 | lr 3.00e-04 | grad 8.94 | tok/s 15276
step    370 | loss 1.8298 | lr 3.00e-04 | grad 3.05 | tok/s 13878
step    380 | loss 1.7684 | lr 3.00e-04 | grad 2.94 | tok/s 14784
step    390 | loss 1.5412 | lr 3.00e-04 | grad 2.31 | tok/s 15390
step    400 | loss 1.4956 | lr 3.00e-04 | grad 2.75 | tok/s 15256
step    410 | loss 1.2817 | lr 3.00e-04 | grad 2.25 | tok/s 14937
step    420 | loss 1.8309 | lr 3.00e-04 | grad 4.88 | tok/s 14248
step    430 | loss 2.1693 | lr 3.00e-04 | grad 3.38 | tok/s 15175

Training complete! Final step: 434
