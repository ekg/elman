Using device: cuda
Output directory: benchmark_results/cmaes_e90/e90_500M_20gen_20260129_140231/eval_31/levelE90_100m_20260129_141831
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E90, 504,930,118 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 2.0 minutes
step     10 | loss 4.5865 | lr 3.00e-04 | grad 19.62 | tok/s 5917
step     20 | loss 3.1329 | lr 3.00e-04 | grad 8.31 | tok/s 15012
step     30 | loss 2.6114 | lr 3.00e-04 | grad 4.19 | tok/s 15165
step     40 | loss 2.3690 | lr 3.00e-04 | grad 4.06 | tok/s 14474
step     50 | loss 3.0172 | lr 3.00e-04 | grad 14.69 | tok/s 14710
step     60 | loss 2.0278 | lr 3.00e-04 | grad 3.98 | tok/s 15134
step     70 | loss 1.8726 | lr 3.00e-04 | grad 5.19 | tok/s 15305
step     80 | loss 5.5039 | lr 3.00e-04 | grad 58.25 | tok/s 15369
step     90 | loss 5.0316 | lr 3.00e-04 | grad 8.62 | tok/s 15632
step    100 | loss 4.1643 | lr 3.00e-04 | grad 7.50 | tok/s 15555
step    110 | loss 3.3674 | lr 3.00e-04 | grad 12.69 | tok/s 15521
step    120 | loss 3.2616 | lr 3.00e-04 | grad 10.25 | tok/s 15487
step    130 | loss 2.8897 | lr 3.00e-04 | grad 12.38 | tok/s 15457
step    140 | loss 2.7003 | lr 3.00e-04 | grad 8.62 | tok/s 15450
step    150 | loss 2.7361 | lr 3.00e-04 | grad 15.00 | tok/s 15416
step    160 | loss 2.3557 | lr 3.00e-04 | grad 9.81 | tok/s 15411
step    170 | loss 2.3951 | lr 3.00e-04 | grad 10.50 | tok/s 15405
step    180 | loss 2.1976 | lr 3.00e-04 | grad 5.28 | tok/s 15338
step    190 | loss 2.3646 | lr 3.00e-04 | grad 12.88 | tok/s 15357
step    200 | loss 2.0740 | lr 3.00e-04 | grad 4.38 | tok/s 15321
step    210 | loss 2.0832 | lr 3.00e-04 | grad 6.03 | tok/s 15325
step    220 | loss 2.1234 | lr 3.00e-04 | grad 3.50 | tok/s 15128
step    230 | loss 2.0707 | lr 3.00e-04 | grad 4.06 | tok/s 14970
step    240 | loss 2.2894 | lr 3.00e-04 | grad 4.91 | tok/s 14201
step    250 | loss 2.0872 | lr 3.00e-04 | grad 2.81 | tok/s 14597
step    260 | loss 1.5379 | lr 3.00e-04 | grad 3.34 | tok/s 15026
step    270 | loss 2.0720 | lr 3.00e-04 | grad 3.08 | tok/s 14817
step    280 | loss 2.2541 | lr 3.00e-04 | grad 5.41 | tok/s 14551
step    290 | loss 1.3922 | lr 3.00e-04 | grad 5.06 | tok/s 15333
step    300 | loss 0.6178 | lr 3.00e-04 | grad 3.22 | tok/s 15325
step    310 | loss 2.4010 | lr 3.00e-04 | grad 3.70 | tok/s 15040
step    320 | loss 1.9206 | lr 3.00e-04 | grad 5.88 | tok/s 14731
step    330 | loss 1.9629 | lr 3.00e-04 | grad 3.36 | tok/s 14227
step    340 | loss 2.2615 | lr 3.00e-04 | grad 2.98 | tok/s 14441
step    350 | loss 1.8740 | lr 3.00e-04 | grad 3.95 | tok/s 14813
step    360 | loss 1.2264 | lr 3.00e-04 | grad 10.25 | tok/s 15127
step    370 | loss 1.8171 | lr 3.00e-04 | grad 3.03 | tok/s 13741
step    380 | loss 1.7554 | lr 3.00e-04 | grad 3.05 | tok/s 14629
step    390 | loss 1.5390 | lr 3.00e-04 | grad 2.47 | tok/s 15222
step    400 | loss 1.4921 | lr 3.00e-04 | grad 2.81 | tok/s 15118
step    410 | loss 1.2807 | lr 3.00e-04 | grad 2.34 | tok/s 14778
step    420 | loss 1.8288 | lr 3.00e-04 | grad 4.81 | tok/s 14129
step    430 | loss 2.1595 | lr 3.00e-04 | grad 3.39 | tok/s 15033

Training complete! Final step: 431
