Using device: cuda
Output directory: benchmark_results/cmaes_e90/e90_500M_20gen_20260129_140231/eval_52/levelE90_100m_20260129_142952
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E90, 508,736,592 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 2.0 minutes
step     10 | loss 4.3745 | lr 3.00e-04 | grad 26.38 | tok/s 5855
step     20 | loss 3.0444 | lr 3.00e-04 | grad 7.91 | tok/s 14024
step     30 | loss 2.6208 | lr 3.00e-04 | grad 4.56 | tok/s 14196
step     40 | loss 2.3948 | lr 3.00e-04 | grad 4.62 | tok/s 13603
step     50 | loss 2.9288 | lr 3.00e-04 | grad 18.25 | tok/s 13781
step     60 | loss 2.0461 | lr 3.00e-04 | grad 3.75 | tok/s 14251
step     70 | loss 1.9372 | lr 3.00e-04 | grad 5.31 | tok/s 14370
step     80 | loss 5.6031 | lr 3.00e-04 | grad 71.00 | tok/s 14424
step     90 | loss 5.1019 | lr 3.00e-04 | grad 9.00 | tok/s 14683
step    100 | loss 4.0445 | lr 3.00e-04 | grad 7.75 | tok/s 14661
step    110 | loss 3.3822 | lr 3.00e-04 | grad 12.88 | tok/s 14661
step    120 | loss 3.1757 | lr 3.00e-04 | grad 11.19 | tok/s 14646
step    130 | loss 2.9297 | lr 3.00e-04 | grad 13.88 | tok/s 14607
step    140 | loss 2.6554 | lr 3.00e-04 | grad 9.56 | tok/s 14621
step    150 | loss 2.6543 | lr 3.00e-04 | grad 8.75 | tok/s 14545
step    160 | loss 2.3604 | lr 3.00e-04 | grad 7.56 | tok/s 14509
step    170 | loss 2.4024 | lr 3.00e-04 | grad 10.88 | tok/s 14512
step    180 | loss 2.2106 | lr 3.00e-04 | grad 6.56 | tok/s 14538
step    190 | loss 2.3198 | lr 3.00e-04 | grad 10.12 | tok/s 14501
step    200 | loss 2.0605 | lr 3.00e-04 | grad 4.25 | tok/s 14507
step    210 | loss 2.0743 | lr 3.00e-04 | grad 6.84 | tok/s 14517
step    220 | loss 2.1473 | lr 3.00e-04 | grad 3.66 | tok/s 14301
step    230 | loss 2.1198 | lr 3.00e-04 | grad 4.06 | tok/s 14140
step    240 | loss 2.2950 | lr 3.00e-04 | grad 5.28 | tok/s 13431
step    250 | loss 2.1109 | lr 3.00e-04 | grad 2.81 | tok/s 13771
step    260 | loss 1.5613 | lr 3.00e-04 | grad 3.19 | tok/s 14227
step    270 | loss 2.0825 | lr 3.00e-04 | grad 3.11 | tok/s 14035
step    280 | loss 2.2693 | lr 3.00e-04 | grad 5.41 | tok/s 13743
step    290 | loss 1.3956 | lr 3.00e-04 | grad 3.78 | tok/s 14486
step    300 | loss 0.5888 | lr 3.00e-04 | grad 2.11 | tok/s 14499
step    310 | loss 2.4267 | lr 3.00e-04 | grad 4.22 | tok/s 14223
step    320 | loss 1.9503 | lr 3.00e-04 | grad 6.00 | tok/s 13925
step    330 | loss 1.9726 | lr 3.00e-04 | grad 3.34 | tok/s 13463
step    340 | loss 2.2888 | lr 3.00e-04 | grad 2.98 | tok/s 13659
step    350 | loss 1.9049 | lr 3.00e-04 | grad 5.03 | tok/s 13992
step    360 | loss 1.2739 | lr 3.00e-04 | grad 11.81 | tok/s 14320
step    370 | loss 1.8314 | lr 3.00e-04 | grad 2.98 | tok/s 12992
step    380 | loss 1.7864 | lr 3.00e-04 | grad 2.91 | tok/s 13829
step    390 | loss 1.5449 | lr 3.00e-04 | grad 2.48 | tok/s 14445
step    400 | loss 1.5008 | lr 3.00e-04 | grad 2.75 | tok/s 14298

Training complete! Final step: 407
