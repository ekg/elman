Using device: cuda
Output directory: benchmark_results/cmaes_e90/e90_500M_20gen_20260129_140231/eval_37/levelE90_100m_20260129_142304
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E90, 490,339,844 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 1, Effective batch: 8

Time-based training: 2.0 minutes
step     10 | loss 4.5088 | lr 3.00e-04 | grad 12.56 | tok/s 5825
step     20 | loss 3.0148 | lr 3.00e-04 | grad 5.56 | tok/s 14125
step     30 | loss 2.5187 | lr 3.00e-04 | grad 3.56 | tok/s 14276
step     40 | loss 2.3551 | lr 3.00e-04 | grad 3.42 | tok/s 13652
step     50 | loss 2.9117 | lr 3.00e-04 | grad 11.62 | tok/s 13813
step     60 | loss 2.0765 | lr 3.00e-04 | grad 3.00 | tok/s 14263
step     70 | loss 1.9036 | lr 3.00e-04 | grad 4.50 | tok/s 14455
step     80 | loss 5.1763 | lr 3.00e-04 | grad 51.75 | tok/s 14559
step     90 | loss 4.6022 | lr 3.00e-04 | grad 7.22 | tok/s 14825
step    100 | loss 3.7215 | lr 3.00e-04 | grad 6.00 | tok/s 14828
step    110 | loss 3.1560 | lr 3.00e-04 | grad 10.88 | tok/s 14781
step    120 | loss 3.0740 | lr 3.00e-04 | grad 8.25 | tok/s 14695
step    130 | loss 2.7874 | lr 3.00e-04 | grad 9.12 | tok/s 14693
step    140 | loss 2.5800 | lr 3.00e-04 | grad 9.38 | tok/s 14681
step    150 | loss 2.5930 | lr 3.00e-04 | grad 9.88 | tok/s 14645
step    160 | loss 2.2860 | lr 3.00e-04 | grad 8.94 | tok/s 14633
step    170 | loss 2.3465 | lr 3.00e-04 | grad 8.94 | tok/s 14634
step    180 | loss 2.1890 | lr 3.00e-04 | grad 4.59 | tok/s 14640
step    190 | loss 2.2692 | lr 3.00e-04 | grad 6.84 | tok/s 14648
step    200 | loss 2.0065 | lr 3.00e-04 | grad 4.66 | tok/s 14608
step    210 | loss 2.0763 | lr 3.00e-04 | grad 5.03 | tok/s 14624
step    220 | loss 2.1218 | lr 3.00e-04 | grad 3.23 | tok/s 14387
step    230 | loss 2.1359 | lr 3.00e-04 | grad 3.20 | tok/s 14235
step    240 | loss 2.2867 | lr 3.00e-04 | grad 4.88 | tok/s 13524
step    250 | loss 2.1147 | lr 3.00e-04 | grad 2.58 | tok/s 13898
step    260 | loss 1.5938 | lr 3.00e-04 | grad 3.00 | tok/s 14325
step    270 | loss 2.1134 | lr 3.00e-04 | grad 2.88 | tok/s 14173
step    280 | loss 2.2778 | lr 3.00e-04 | grad 5.78 | tok/s 13897
step    290 | loss 1.4823 | lr 3.00e-04 | grad 3.56 | tok/s 14618
step    300 | loss 0.5920 | lr 3.00e-04 | grad 2.62 | tok/s 14613
step    310 | loss 2.4037 | lr 3.00e-04 | grad 3.75 | tok/s 14363
step    320 | loss 1.9570 | lr 3.00e-04 | grad 5.31 | tok/s 14050
step    330 | loss 1.9736 | lr 3.00e-04 | grad 3.16 | tok/s 13578
step    340 | loss 2.2936 | lr 3.00e-04 | grad 2.81 | tok/s 13800
step    350 | loss 1.8931 | lr 3.00e-04 | grad 4.47 | tok/s 14145
step    360 | loss 1.2501 | lr 3.00e-04 | grad 9.06 | tok/s 14454
step    370 | loss 1.8375 | lr 3.00e-04 | grad 2.95 | tok/s 13116
step    380 | loss 1.7804 | lr 3.00e-04 | grad 2.84 | tok/s 13970
step    390 | loss 1.5565 | lr 3.00e-04 | grad 2.22 | tok/s 14568
step    400 | loss 1.5213 | lr 3.00e-04 | grad 2.67 | tok/s 14432
step    410 | loss 1.3132 | lr 3.00e-04 | grad 2.25 | tok/s 14100

Training complete! Final step: 410
