Using device: cuda
Output directory: benchmark_results/autopoetic_100m/e74v2/level74v2-delta_100m_20260118_121059
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level 74v2-delta, 100,872,832 parameters

Starting training from step 0...
Batch size: 16, Chunk size: 512
Gradient accumulation: 1, Effective batch: 16

Time-based training: 10.0 minutes
step     10 | loss 8.8339 | lr 9.00e-07 | grad 5.06 | tok/s 30006
step     20 | loss 8.5888 | lr 1.90e-06 | grad 4.91 | tok/s 35432
step     30 | loss 8.2464 | lr 2.90e-06 | grad 6.03 | tok/s 35345
step     40 | loss 8.8012 | lr 3.90e-06 | grad 4.72 | tok/s 36656
step     50 | loss 9.4903 | lr 4.90e-06 | grad 4.56 | tok/s 38088
step     60 | loss 9.4837 | lr 5.90e-06 | grad 3.45 | tok/s 38089
step     70 | loss 9.4781 | lr 6.90e-06 | grad 5.47 | tok/s 38100
step     80 | loss 9.4613 | lr 7.90e-06 | grad 3.73 | tok/s 38098
step     90 | loss 9.4473 | lr 8.90e-06 | grad 3.70 | tok/s 37994
step    100 | loss 9.4146 | lr 9.90e-06 | grad 4.00 | tok/s 38012
step    110 | loss 9.3249 | lr 1.09e-05 | grad 4.75 | tok/s 37821
step    120 | loss 8.5422 | lr 1.19e-05 | grad 17.00 | tok/s 36629
step    130 | loss 7.8872 | lr 1.29e-05 | grad 22.50 | tok/s 35840
step    140 | loss 7.2984 | lr 1.39e-05 | grad 52.50 | tok/s 36031
step    150 | loss 7.3304 | lr 1.49e-05 | grad 43.00 | tok/s 37225
step    160 | loss 6.5695 | lr 1.59e-05 | grad 42.50 | tok/s 37446
step    170 | loss 5.6004 | lr 1.69e-05 | grad 31.62 | tok/s 35389
step    180 | loss 5.3928 | lr 1.79e-05 | grad 21.38 | tok/s 36684
step    190 | loss 4.7931 | lr 1.89e-05 | grad 13.56 | tok/s 35138
step    200 | loss 4.4650 | lr 1.99e-05 | grad 11.69 | tok/s 37618
step    210 | loss 4.1743 | lr 2.09e-05 | grad 9.56 | tok/s 36506
step    220 | loss 3.9861 | lr 2.19e-05 | grad 8.75 | tok/s 35192
step    230 | loss 4.0869 | lr 2.29e-05 | grad 6.47 | tok/s 35256
step    240 | loss 3.6869 | lr 2.39e-05 | grad 9.94 | tok/s 35443
step    250 | loss 3.8638 | lr 2.49e-05 | grad 7.16 | tok/s 35566
step    260 | loss 3.5494 | lr 2.59e-05 | grad 5.66 | tok/s 36773
step    270 | loss 3.5451 | lr 2.69e-05 | grad 6.56 | tok/s 36779
step    280 | loss 3.2094 | lr 2.79e-05 | grad 5.19 | tok/s 35687
step    290 | loss 3.1113 | lr 2.89e-05 | grad 7.34 | tok/s 34224
step    300 | loss 3.1675 | lr 2.99e-05 | grad 6.38 | tok/s 34758
step    310 | loss 3.1482 | lr 3.09e-05 | grad 4.62 | tok/s 35538
step    320 | loss 2.8559 | lr 3.19e-05 | grad 4.91 | tok/s 34003
step    330 | loss 3.0798 | lr 3.29e-05 | grad 3.84 | tok/s 35621
step    340 | loss 3.0888 | lr 3.39e-05 | grad 7.75 | tok/s 36324
step    350 | loss 3.1258 | lr 3.49e-05 | grad 4.97 | tok/s 35653
step    360 | loss 3.1542 | lr 3.59e-05 | grad 5.72 | tok/s 36485
step    370 | loss 2.8711 | lr 3.69e-05 | grad 4.56 | tok/s 35848
step    380 | loss 2.9023 | lr 3.79e-05 | grad 5.59 | tok/s 37467
step    390 | loss 2.8026 | lr 3.89e-05 | grad 5.97 | tok/s 37819
step    400 | loss 2.7257 | lr 3.99e-05 | grad 3.94 | tok/s 37208
step    410 | loss 2.9517 | lr 4.09e-05 | grad 5.69 | tok/s 35932
step    420 | loss 2.8051 | lr 4.19e-05 | grad 4.47 | tok/s 35880
step    430 | loss 3.0210 | lr 4.29e-05 | grad 9.75 | tok/s 37682
step    440 | loss 2.7552 | lr 4.39e-05 | grad 6.44 | tok/s 36500
step    450 | loss 2.7978 | lr 4.49e-05 | grad 4.34 | tok/s 35982
step    460 | loss 2.5608 | lr 4.59e-05 | grad 7.31 | tok/s 35643
step    470 | loss 2.7359 | lr 4.69e-05 | grad 5.25 | tok/s 35679
step    480 | loss 2.8268 | lr 4.79e-05 | grad 5.62 | tok/s 37402
step    490 | loss 2.6693 | lr 4.89e-05 | grad 5.12 | tok/s 36128
step    500 | loss 2.6425 | lr 4.99e-05 | grad 5.66 | tok/s 35900
step    510 | loss 2.7656 | lr 5.09e-05 | grad 13.25 | tok/s 35293
step    520 | loss 2.5228 | lr 5.19e-05 | grad 7.12 | tok/s 33780
step    530 | loss 2.4555 | lr 5.29e-05 | grad 4.44 | tok/s 35891
step    540 | loss 2.6291 | lr 5.39e-05 | grad 5.78 | tok/s 35806
step    550 | loss 2.6252 | lr 5.49e-05 | grad 4.94 | tok/s 34990
step    560 | loss 2.3524 | lr 5.59e-05 | grad 6.91 | tok/s 36571
step    570 | loss 2.5043 | lr 5.69e-05 | grad 6.00 | tok/s 37701
step    580 | loss 2.3947 | lr 5.79e-05 | grad 3.34 | tok/s 37725
step    590 | loss 2.3038 | lr 5.89e-05 | grad 5.00 | tok/s 37717
step    600 | loss 2.3968 | lr 5.99e-05 | grad 5.00 | tok/s 37701
step    610 | loss 2.3321 | lr 6.09e-05 | grad 5.41 | tok/s 37711
step    620 | loss 2.2484 | lr 6.19e-05 | grad 4.25 | tok/s 37711
step    630 | loss 2.3555 | lr 6.29e-05 | grad 10.38 | tok/s 37163
step    640 | loss 2.4299 | lr 6.39e-05 | grad 10.25 | tok/s 35432
step    650 | loss 2.5748 | lr 6.49e-05 | grad 6.81 | tok/s 35250
step    660 | loss 2.4165 | lr 6.59e-05 | grad 7.19 | tok/s 35578
step    670 | loss 2.4923 | lr 6.69e-05 | grad 5.53 | tok/s 36812
step    680 | loss 2.5387 | lr 6.79e-05 | grad 5.53 | tok/s 35511
step    690 | loss 2.5059 | lr 6.89e-05 | grad 4.97 | tok/s 35287
step    700 | loss 2.4945 | lr 6.99e-05 | grad 5.53 | tok/s 34951
step    710 | loss 2.4294 | lr 7.09e-05 | grad 5.41 | tok/s 35975
step    720 | loss 2.5593 | lr 7.19e-05 | grad 11.62 | tok/s 35142
step    730 | loss 2.3711 | lr 7.29e-05 | grad 4.50 | tok/s 36766
step    740 | loss 2.3876 | lr 7.39e-05 | grad 3.48 | tok/s 35714
step    750 | loss 2.9095 | lr 7.49e-05 | grad 6.47 | tok/s 37153
step    760 | loss 2.7766 | lr 7.59e-05 | grad 4.19 | tok/s 37141
step    770 | loss 2.4740 | lr 7.69e-05 | grad 4.72 | tok/s 36314
step    780 | loss 2.4356 | lr 7.79e-05 | grad 3.89 | tok/s 35228
step    790 | loss 2.3990 | lr 7.89e-05 | grad 4.59 | tok/s 36195
step    800 | loss 2.6865 | lr 7.99e-05 | grad 8.25 | tok/s 37236
step    810 | loss 2.5888 | lr 8.09e-05 | grad 55.50 | tok/s 36051
step    820 | loss 2.2256 | lr 8.19e-05 | grad 80.00 | tok/s 35108
step    830 | loss 2.4688 | lr 8.29e-05 | grad 5.44 | tok/s 35718
step    840 | loss 2.3669 | lr 8.39e-05 | grad 2.80 | tok/s 34963
step    850 | loss 2.6016 | lr 8.49e-05 | grad 4.69 | tok/s 35039
step    860 | loss 2.5464 | lr 8.59e-05 | grad 4.09 | tok/s 35427
step    870 | loss 2.4778 | lr 8.69e-05 | grad 6.47 | tok/s 35765
step    880 | loss 2.8683 | lr 8.79e-05 | grad 3.77 | tok/s 37466
step    890 | loss 2.4433 | lr 8.89e-05 | grad 4.25 | tok/s 35637
step    900 | loss 2.2787 | lr 8.99e-05 | grad 2.50 | tok/s 35573
step    910 | loss 2.2823 | lr 9.09e-05 | grad 3.00 | tok/s 36026
step    920 | loss 2.4440 | lr 9.19e-05 | grad 4.16 | tok/s 35495
step    930 | loss 2.3982 | lr 9.29e-05 | grad 3.67 | tok/s 35635
step    940 | loss 2.3478 | lr 9.39e-05 | grad 3.41 | tok/s 36736
step    950 | loss 2.2360 | lr 9.49e-05 | grad 3.23 | tok/s 35138
step    960 | loss 2.3298 | lr 9.59e-05 | grad 2.69 | tok/s 34653
step    970 | loss 2.1890 | lr 9.69e-05 | grad 2.80 | tok/s 35051
step    980 | loss 2.1835 | lr 9.79e-05 | grad 2.69 | tok/s 36022
step    990 | loss 3.2347 | lr 9.89e-05 | grad 5.09 | tok/s 37459
step   1000 | loss 2.8889 | lr 9.99e-05 | grad 5.56 | tok/s 35822
  >>> saved checkpoint: checkpoint_step_001000_loss_2.8889.pt
step   1010 | loss 2.7133 | lr 1.02e-06 | grad 4.97 | tok/s 25594
step   1020 | loss 2.1964 | lr 1.09e-06 | grad 3.47 | tok/s 34724
step   1030 | loss 2.3053 | lr 1.21e-06 | grad 36.50 | tok/s 35549
step   1040 | loss 2.7080 | lr 1.37e-06 | grad 3.30 | tok/s 35519
step   1050 | loss 2.6311 | lr 1.59e-06 | grad 10.75 | tok/s 33992
step   1060 | loss 3.1003 | lr 1.85e-06 | grad 3.30 | tok/s 35678
step   1070 | loss 2.7148 | lr 2.16e-06 | grad 5.53 | tok/s 34406
step   1080 | loss 2.0576 | lr 2.52e-06 | grad 4.00 | tok/s 35073
step   1090 | loss 2.3554 | lr 2.92e-06 | grad 4.75 | tok/s 35230
step   1100 | loss 2.3245 | lr 3.37e-06 | grad 4.06 | tok/s 36198
step   1110 | loss 2.3172 | lr 3.87e-06 | grad 3.86 | tok/s 36113
step   1120 | loss 2.2773 | lr 4.42e-06 | grad 3.44 | tok/s 36215
step   1130 | loss 2.2656 | lr 5.01e-06 | grad 2.73 | tok/s 35235
step   1140 | loss 2.7527 | lr 5.65e-06 | grad 6.09 | tok/s 35587
step   1150 | loss 2.8939 | lr 6.32e-06 | grad 5.91 | tok/s 34937
step   1160 | loss 2.5005 | lr 7.05e-06 | grad 3.23 | tok/s 34878
step   1170 | loss 3.0994 | lr 7.81e-06 | grad 5.31 | tok/s 34124
step   1180 | loss 2.5572 | lr 8.62e-06 | grad 3.23 | tok/s 34354
step   1190 | loss 2.4396 | lr 9.47e-06 | grad 2.23 | tok/s 33217
step   1200 | loss 2.4972 | lr 1.04e-05 | grad 4.66 | tok/s 35411
step   1210 | loss 2.8710 | lr 1.13e-05 | grad 3.20 | tok/s 36226
step   1220 | loss 2.2327 | lr 1.23e-05 | grad 2.75 | tok/s 35774
step   1230 | loss 2.2997 | lr 1.33e-05 | grad 3.53 | tok/s 33702
step   1240 | loss 2.3235 | lr 1.43e-05 | grad 2.45 | tok/s 34585
step   1250 | loss 2.3880 | lr 1.54e-05 | grad 2.78 | tok/s 35327
step   1260 | loss 2.3496 | lr 1.65e-05 | grad 2.30 | tok/s 35079
step   1270 | loss 2.8483 | lr 1.76e-05 | grad 8.12 | tok/s 35405
step   1280 | loss 2.7718 | lr 1.88e-05 | grad 2.89 | tok/s 35061
step   1290 | loss 2.2533 | lr 2.00e-05 | grad 2.66 | tok/s 34869
step   1300 | loss 2.3299 | lr 2.13e-05 | grad 3.12 | tok/s 34301
step   1310 | loss 2.3367 | lr 2.25e-05 | grad 2.88 | tok/s 34093
step   1320 | loss 2.8991 | lr 2.38e-05 | grad 9.19 | tok/s 34175
step   1330 | loss 2.2803 | lr 2.52e-05 | grad 2.23 | tok/s 35084
step   1340 | loss 2.5244 | lr 2.65e-05 | grad 4.22 | tok/s 35561
step   1350 | loss 2.2664 | lr 2.79e-05 | grad 2.31 | tok/s 34271
step   1360 | loss 2.4086 | lr 2.93e-05 | grad 2.83 | tok/s 33861
step   1370 | loss 2.3906 | lr 3.07e-05 | grad 6.34 | tok/s 34699
step   1380 | loss 2.3450 | lr 3.21e-05 | grad 3.25 | tok/s 34058
step   1390 | loss 2.7636 | lr 3.36e-05 | grad 3.47 | tok/s 35622
step   1400 | loss 2.1919 | lr 3.51e-05 | grad 4.12 | tok/s 33397
step   1410 | loss 2.3814 | lr 3.65e-05 | grad 2.75 | tok/s 34995
step   1420 | loss 2.5041 | lr 3.80e-05 | grad 2.52 | tok/s 34472
step   1430 | loss 2.1906 | lr 3.96e-05 | grad 4.84 | tok/s 33271
step   1440 | loss 2.5807 | lr 4.11e-05 | grad 11.38 | tok/s 35906
step   1450 | loss 2.4983 | lr 4.26e-05 | grad 3.34 | tok/s 34272
step   1460 | loss 2.3580 | lr 4.41e-05 | grad 3.55 | tok/s 35543
step   1470 | loss 2.3755 | lr 4.57e-05 | grad 6.06 | tok/s 35496
step   1480 | loss 2.2907 | lr 4.72e-05 | grad 5.53 | tok/s 33765
step   1490 | loss 2.0640 | lr 4.88e-05 | grad 2.14 | tok/s 33019
step   1500 | loss 2.3060 | lr 5.03e-05 | grad 2.69 | tok/s 35391
step   1510 | loss 3.3558 | lr 5.19e-05 | grad 9.44 | tok/s 34483
step   1520 | loss 2.3886 | lr 5.35e-05 | grad 2.47 | tok/s 34785
step   1530 | loss 2.1152 | lr 5.50e-05 | grad 2.58 | tok/s 34075
step   1540 | loss 2.2123 | lr 5.65e-05 | grad 2.95 | tok/s 34745
step   1550 | loss 2.1433 | lr 5.81e-05 | grad 2.83 | tok/s 34673
step   1560 | loss 2.3266 | lr 5.96e-05 | grad 2.27 | tok/s 34874
step   1570 | loss 2.2506 | lr 6.11e-05 | grad 3.88 | tok/s 34357
step   1580 | loss 2.3006 | lr 6.27e-05 | grad 2.92 | tok/s 35810
step   1590 | loss 2.4100 | lr 6.42e-05 | grad 3.31 | tok/s 34989
step   1600 | loss 2.1733 | lr 6.56e-05 | grad 2.64 | tok/s 35200
step   1610 | loss 2.2650 | lr 6.71e-05 | grad 5.09 | tok/s 33619
step   1620 | loss 2.2026 | lr 6.86e-05 | grad 8.31 | tok/s 35902
step   1630 | loss 2.7614 | lr 7.00e-05 | grad 5.59 | tok/s 35088
step   1640 | loss 2.7604 | lr 7.14e-05 | grad 2.66 | tok/s 36176
step   1650 | loss 2.4126 | lr 7.28e-05 | grad 2.53 | tok/s 36205
step   1660 | loss 2.2057 | lr 7.42e-05 | grad 2.80 | tok/s 36223
step   1670 | loss 2.1105 | lr 7.56e-05 | grad 2.50 | tok/s 36236
step   1680 | loss 2.0492 | lr 7.69e-05 | grad 2.75 | tok/s 36203
step   1690 | loss 2.4334 | lr 7.82e-05 | grad 8.75 | tok/s 34623
step   1700 | loss 2.5619 | lr 7.95e-05 | grad 2.95 | tok/s 34279
step   1710 | loss 2.3016 | lr 8.07e-05 | grad 3.27 | tok/s 32996
step   1720 | loss 2.2627 | lr 8.19e-05 | grad 3.08 | tok/s 34557
step   1730 | loss 2.2690 | lr 8.31e-05 | grad 4.06 | tok/s 35668
step   1740 | loss 2.2296 | lr 8.43e-05 | grad 3.80 | tok/s 33934
step   1750 | loss 2.3428 | lr 8.54e-05 | grad 4.31 | tok/s 34835
step   1760 | loss 2.3227 | lr 8.65e-05 | grad 3.11 | tok/s 34307
step   1770 | loss 2.1963 | lr 8.75e-05 | grad 3.06 | tok/s 34862
step   1780 | loss 2.1484 | lr 8.85e-05 | grad 2.70 | tok/s 34294
step   1790 | loss 2.7504 | lr 8.95e-05 | grad 3.88 | tok/s 34274
step   1800 | loss 2.4851 | lr 9.05e-05 | grad 2.50 | tok/s 33088
step   1810 | loss 2.2172 | lr 9.14e-05 | grad 5.22 | tok/s 34065
step   1820 | loss 2.2623 | lr 9.22e-05 | grad 2.25 | tok/s 34556
step   1830 | loss 2.2112 | lr 9.30e-05 | grad 2.92 | tok/s 33860
step   1840 | loss 2.1328 | lr 9.38e-05 | grad 3.00 | tok/s 34583
step   1850 | loss 2.2052 | lr 9.45e-05 | grad 2.41 | tok/s 33686
step   1860 | loss 2.3538 | lr 9.52e-05 | grad 3.86 | tok/s 34385
step   1870 | loss 2.1261 | lr 9.59e-05 | grad 5.16 | tok/s 33278
step   1880 | loss 2.2702 | lr 9.65e-05 | grad 4.47 | tok/s 34099
step   1890 | loss 2.2568 | lr 9.70e-05 | grad 2.91 | tok/s 33782
step   1900 | loss 2.2733 | lr 9.75e-05 | grad 3.11 | tok/s 35184
step   1910 | loss 2.0444 | lr 9.80e-05 | grad 2.14 | tok/s 36164
step   1920 | loss 1.8935 | lr 9.84e-05 | grad 1.84 | tok/s 36099
step   1930 | loss 1.8238 | lr 9.88e-05 | grad 2.00 | tok/s 36127
step   1940 | loss 1.7814 | lr 9.91e-05 | grad 1.93 | tok/s 36144
step   1950 | loss 1.7098 | lr 9.94e-05 | grad 2.16 | tok/s 36194
step   1960 | loss 2.2793 | lr 9.96e-05 | grad 8.12 | tok/s 34149
step   1970 | loss 2.5003 | lr 9.98e-05 | grad 3.94 | tok/s 33767
step   1980 | loss 2.4596 | lr 9.99e-05 | grad 2.53 | tok/s 34610
step   1990 | loss 2.3345 | lr 1.00e-04 | grad 4.41 | tok/s 33776
step   2000 | loss 2.1262 | lr 1.00e-04 | grad 2.19 | tok/s 33001
  >>> saved checkpoint: checkpoint_step_002000_loss_2.1262.pt
step   2010 | loss 2.7956 | lr 1.00e-04 | grad 2.83 | tok/s 27300
step   2020 | loss 2.2737 | lr 9.99e-05 | grad 4.88 | tok/s 35086
step   2030 | loss 2.2339 | lr 9.98e-05 | grad 3.27 | tok/s 36163
step   2040 | loss 2.1163 | lr 9.96e-05 | grad 2.38 | tok/s 32301
step   2050 | loss 2.2152 | lr 9.94e-05 | grad 2.70 | tok/s 34654
step   2060 | loss 2.7221 | lr 9.92e-05 | grad 2.12 | tok/s 32784
step   2070 | loss 2.0690 | lr 9.88e-05 | grad 2.34 | tok/s 34883
step   2080 | loss 2.1216 | lr 9.85e-05 | grad 3.78 | tok/s 33917
step   2090 | loss 2.3798 | lr 9.81e-05 | grad 2.73 | tok/s 34564
step   2100 | loss 1.9986 | lr 9.76e-05 | grad 2.69 | tok/s 34458
step   2110 | loss 2.1973 | lr 9.71e-05 | grad 2.45 | tok/s 34202
step   2120 | loss 2.7605 | lr 9.66e-05 | grad 4.16 | tok/s 35043
step   2130 | loss 2.7794 | lr 9.60e-05 | grad 3.11 | tok/s 35550
step   2140 | loss 2.2155 | lr 9.54e-05 | grad 2.81 | tok/s 33904
step   2150 | loss 3.1393 | lr 9.47e-05 | grad 4.25 | tok/s 34855
step   2160 | loss 2.4450 | lr 9.40e-05 | grad 4.34 | tok/s 33553
step   2170 | loss 2.5195 | lr 9.32e-05 | grad 2.28 | tok/s 34152
step   2180 | loss 2.5706 | lr 9.24e-05 | grad 4.06 | tok/s 34923
step   2190 | loss 2.2451 | lr 9.15e-05 | grad 2.94 | tok/s 33978
step   2200 | loss 2.2244 | lr 9.06e-05 | grad 2.73 | tok/s 34689
step   2210 | loss 2.1599 | lr 8.97e-05 | grad 5.59 | tok/s 36034
step   2220 | loss 2.6241 | lr 8.87e-05 | grad 3.02 | tok/s 33880
step   2230 | loss 2.4855 | lr 8.77e-05 | grad 2.92 | tok/s 36272
step   2240 | loss 2.4465 | lr 8.67e-05 | grad 2.42 | tok/s 34529
step   2250 | loss 2.1628 | lr 8.56e-05 | grad 2.19 | tok/s 33318
step   2260 | loss 2.2382 | lr 8.45e-05 | grad 2.11 | tok/s 33980
step   2270 | loss 2.0652 | lr 8.34e-05 | grad 7.34 | tok/s 34877
step   2280 | loss 2.0652 | lr 8.22e-05 | grad 1.99 | tok/s 33998
step   2290 | loss 2.3165 | lr 8.10e-05 | grad 2.66 | tok/s 35294
step   2300 | loss 2.4330 | lr 7.97e-05 | grad 2.89 | tok/s 33596
step   2310 | loss 2.0192 | lr 7.85e-05 | grad 2.19 | tok/s 34293
step   2320 | loss 1.9823 | lr 7.72e-05 | grad 1.80 | tok/s 33819
step   2330 | loss 2.8537 | lr 7.58e-05 | grad 3.28 | tok/s 34351
step   2340 | loss 2.0279 | lr 7.45e-05 | grad 2.59 | tok/s 34486
step   2350 | loss 1.9529 | lr 7.31e-05 | grad 1.73 | tok/s 36224
step   2360 | loss 1.9249 | lr 7.17e-05 | grad 1.45 | tok/s 36157
step   2370 | loss 1.8676 | lr 7.03e-05 | grad 1.99 | tok/s 36155
step   2380 | loss 1.8294 | lr 6.89e-05 | grad 1.87 | tok/s 36207
step   2390 | loss 1.8041 | lr 6.74e-05 | grad 1.58 | tok/s 36177
step   2400 | loss 1.7661 | lr 6.59e-05 | grad 1.41 | tok/s 36124
step   2410 | loss 1.7416 | lr 6.45e-05 | grad 1.36 | tok/s 36156
step   2420 | loss 1.7594 | lr 6.30e-05 | grad 1.66 | tok/s 36063
step   2430 | loss 1.7362 | lr 6.15e-05 | grad 1.55 | tok/s 36129
step   2440 | loss 1.8611 | lr 5.99e-05 | grad 2.62 | tok/s 35559
step   2450 | loss 2.2510 | lr 5.84e-05 | grad 2.58 | tok/s 35169
step   2460 | loss 1.6680 | lr 5.69e-05 | grad 1.85 | tok/s 34076
step   2470 | loss 2.0603 | lr 5.53e-05 | grad 2.25 | tok/s 33231
step   2480 | loss 2.0313 | lr 5.38e-05 | grad 2.25 | tok/s 34817
step   2490 | loss 2.2739 | lr 5.22e-05 | grad 3.08 | tok/s 35307
step   2500 | loss 2.0405 | lr 5.07e-05 | grad 8.69 | tok/s 34819
step   2510 | loss 2.1565 | lr 4.91e-05 | grad 6.03 | tok/s 35022
step   2520 | loss 2.2466 | lr 4.75e-05 | grad 3.08 | tok/s 35050
step   2530 | loss 2.4180 | lr 4.60e-05 | grad 3.95 | tok/s 34809
step   2540 | loss 2.1336 | lr 4.45e-05 | grad 2.78 | tok/s 34400
step   2550 | loss 1.9742 | lr 4.29e-05 | grad 2.94 | tok/s 33702
step   2560 | loss 2.2233 | lr 4.14e-05 | grad 2.08 | tok/s 34719
step   2570 | loss 2.0256 | lr 3.99e-05 | grad 2.23 | tok/s 33420
step   2580 | loss 2.0025 | lr 3.83e-05 | grad 1.95 | tok/s 34702
step   2590 | loss 2.2097 | lr 3.68e-05 | grad 1.94 | tok/s 33913
step   2600 | loss 1.9238 | lr 3.54e-05 | grad 1.56 | tok/s 33697
step   2610 | loss 2.4678 | lr 3.39e-05 | grad 1.69 | tok/s 33961
step   2620 | loss 1.9125 | lr 3.24e-05 | grad 1.66 | tok/s 33536
step   2630 | loss 2.0454 | lr 3.10e-05 | grad 1.77 | tok/s 33375
step   2640 | loss 2.1771 | lr 2.96e-05 | grad 2.92 | tok/s 35512
step   2650 | loss 2.1860 | lr 2.82e-05 | grad 4.66 | tok/s 34009
step   2660 | loss 1.9702 | lr 2.68e-05 | grad 2.14 | tok/s 34885
step   2670 | loss 2.1346 | lr 2.54e-05 | grad 5.56 | tok/s 34516
step   2680 | loss 1.9371 | lr 2.41e-05 | grad 2.20 | tok/s 34513

Training complete! Final step: 2680
