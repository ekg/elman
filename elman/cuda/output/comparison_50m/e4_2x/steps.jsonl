{"type": "header", "timestamp": "2026-01-04T22:14:52.683775", "config": {"level": "4", "params": "50m", "num_params": 49187840, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 700.6685733795166, "total_time_s": 66.34102439880371, "loss": 3.3645245599746705, "perplexity": 28.919744425953656, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 24696.961353590093, "forward_time_ms": 176.30839347839355, "backward_time_ms": 509.4339847564697, "grad_norm_total": 0.9926423050986487, "grad_norm_embedding": 0.76171875, "grad_norm_layers": 0.6359282529311524, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 200, "step_time_ms": 669.3170070648193, "total_time_s": 130.34799432754517, "loss": 2.7827357840538025, "perplexity": 16.16317948506871, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 25138.983378721703, "forward_time_ms": 177.40583419799805, "backward_time_ms": 478.38902473449707, "grad_norm_total": 1.8504348765099787, "grad_norm_embedding": 1.21875, "grad_norm_layers": 1.3922381355737956, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 300, "step_time_ms": 632.0421695709229, "total_time_s": 193.49795508384705, "loss": 2.568726665973663, "perplexity": 13.049197869927573, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 25401.91442216908, "forward_time_ms": 165.73047637939453, "backward_time_ms": 452.6350498199463, "grad_norm_total": 2.874261528244657, "grad_norm_embedding": 1.8046875, "grad_norm_layers": 2.236967706944689, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 400, "step_time_ms": 637.0670795440674, "total_time_s": 256.6144771575928, "loss": 2.4547865056991576, "perplexity": 11.643947367093906, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 25538.76394018629, "forward_time_ms": 169.48890686035156, "backward_time_ms": 454.56647872924805, "grad_norm_total": 5.536683975846335, "grad_norm_embedding": 3.578125, "grad_norm_layers": 4.224715220059688, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 500, "step_time_ms": 645.4997062683105, "total_time_s": 319.7309925556183, "loss": 2.3871994334459306, "perplexity": 10.882972735202573, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 25621.589943331255, "forward_time_ms": 171.5247631072998, "backward_time_ms": 461.14373207092285, "grad_norm_total": 4.433554534932987, "grad_norm_embedding": 2.75, "grad_norm_layers": 3.4775807282906497, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 600, "step_time_ms": 634.3538761138916, "total_time_s": 382.91385197639465, "loss": 2.2410721909999847, "perplexity": 9.403408133895734, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 25672.65856435577, "forward_time_ms": 168.60532760620117, "backward_time_ms": 452.7156352996826, "grad_norm_total": 4.964487240530063, "grad_norm_embedding": 3.0625, "grad_norm_layers": 3.9072718681732597, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 700, "step_time_ms": 631.493330001831, "total_time_s": 445.9347836971283, "loss": 2.266593223810196, "perplexity": 9.646481368278868, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 25718.59614972682, "forward_time_ms": 166.3835048675537, "backward_time_ms": 451.7018795013428, "grad_norm_total": 5.651165334223025, "grad_norm_embedding": 3.4375, "grad_norm_layers": 4.485396883940297, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 800, "step_time_ms": 633.2192420959473, "total_time_s": 508.9032859802246, "loss": 2.2004760205745697, "perplexity": 9.029310614222004, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 25755.80664202832, "forward_time_ms": 169.18659210205078, "backward_time_ms": 451.3275623321533, "grad_norm_total": 5.669950875613999, "grad_norm_embedding": 3.34375, "grad_norm_layers": 4.579002871729148, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 900, "step_time_ms": 633.9516639709473, "total_time_s": 571.9035305976868, "loss": 2.214123706817627, "perplexity": 9.153384547712188, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 25783.395740155298, "forward_time_ms": 169.59810256958008, "backward_time_ms": 451.5500068664551, "grad_norm_total": 4.192638012133924, "grad_norm_embedding": 2.625, "grad_norm_layers": 3.269159101997375, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1000, "step_time_ms": 636.6739273071289, "total_time_s": 634.9314949512482, "loss": 2.0864264261722565, "perplexity": 8.056074685556494, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 25804.382997495657, "forward_time_ms": 170.11284828186035, "backward_time_ms": 453.37772369384766, "grad_norm_total": 4.5294608648941095, "grad_norm_embedding": 2.8125, "grad_norm_layers": 3.5504160027373963, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1100, "step_time_ms": 629.4796466827393, "total_time_s": 698.3522160053253, "loss": 2.2492168402671813, "perplexity": 9.480308332536454, "lr": 0.0003, "tokens_seen": 18022400, "tokens_per_sec": 25807.05682265394, "forward_time_ms": 168.64919662475586, "backward_time_ms": 447.7193355560303, "grad_norm_total": 5.691664754341932, "grad_norm_embedding": 3.5625, "grad_norm_layers": 4.43879505479375, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1200, "step_time_ms": 640.2323246002197, "total_time_s": 761.6278781890869, "loss": 2.05662344455719, "perplexity": 7.819522134401098, "lr": 0.0003, "tokens_seen": 19660800, "tokens_per_sec": 25814.20019914149, "forward_time_ms": 169.52872276306152, "backward_time_ms": 456.8624496459961, "grad_norm_total": 4.893419921677584, "grad_norm_embedding": 2.75, "grad_norm_layers": 4.047538217921579, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1300, "step_time_ms": 636.7392539978027, "total_time_s": 824.8810038566589, "loss": 2.044392066001892, "perplexity": 7.724461147654212, "lr": 0.0003, "tokens_seen": 21299200, "tokens_per_sec": 25820.956670214506, "forward_time_ms": 168.28036308288574, "backward_time_ms": 455.52968978881836, "grad_norm_total": 5.826019929249813, "grad_norm_embedding": 3.53125, "grad_norm_layers": 4.633833502002662, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1400, "step_time_ms": 633.2614421844482, "total_time_s": 887.9390501976013, "loss": 2.1010738480091096, "perplexity": 8.174943847963702, "lr": 0.0003, "tokens_seen": 22937600, "tokens_per_sec": 25832.42051388357, "forward_time_ms": 168.1969165802002, "backward_time_ms": 451.2491226196289, "grad_norm_total": 12.169165845525303, "grad_norm_embedding": 7.65625, "grad_norm_layers": 9.458569783425919, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1500, "step_time_ms": 632.230281829834, "total_time_s": 950.7280538082123, "loss": 2.0708606421947477, "perplexity": 7.931646490830794, "lr": 0.0003, "tokens_seen": 24576000, "tokens_per_sec": 25849.681151936526, "forward_time_ms": 168.92695426940918, "backward_time_ms": 450.5600929260254, "grad_norm_total": 9.666072225520583, "grad_norm_embedding": 5.90625, "grad_norm_layers": 7.651668059136712, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1600, "step_time_ms": 637.7630233764648, "total_time_s": 1013.632969379425, "loss": 2.104369423389435, "perplexity": 8.201929433736852, "lr": 0.0003, "tokens_seen": 26214400, "tokens_per_sec": 25861.842004515325, "forward_time_ms": 168.2717800140381, "backward_time_ms": 456.2697410583496, "grad_norm_total": 5.477517336973019, "grad_norm_embedding": 3.40625, "grad_norm_layers": 4.289525420141614, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1700, "step_time_ms": 634.2346668243408, "total_time_s": 1076.465299129486, "loss": 2.0699157869815825, "perplexity": 7.924155772674279, "lr": 0.0003, "tokens_seen": 27852800, "tokens_per_sec": 25874.327255131895, "forward_time_ms": 169.8920726776123, "backward_time_ms": 451.4791965484619, "grad_norm_total": 5.946191083188098, "grad_norm_embedding": 3.765625, "grad_norm_layers": 4.601826341832649, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1800, "step_time_ms": 633.197546005249, "total_time_s": 1139.4031729698181, "loss": 2.117329549789429, "perplexity": 8.308919279342708, "lr": 0.0003, "tokens_seen": 29491200, "tokens_per_sec": 25883.03870012572, "forward_time_ms": 168.00522804260254, "backward_time_ms": 452.33607292175293, "grad_norm_total": 5.156054217805714, "grad_norm_embedding": 3.21875, "grad_norm_layers": 4.027926952258888, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 1900, "step_time_ms": 629.5692920684814, "total_time_s": 1203.189334154129, "loss": 2.035316880941391, "perplexity": 7.654677362571334, "lr": 0.0003, "tokens_seen": 31129600, "tokens_per_sec": 25872.582806947114, "forward_time_ms": 165.3919219970703, "backward_time_ms": 451.0469436645508, "grad_norm_total": 3.9078600683531146, "grad_norm_embedding": 2.40625, "grad_norm_layers": 3.0790783239356374, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
{"type": "step", "step": 2000, "step_time_ms": 631.0081481933594, "total_time_s": 1266.0673985481262, "loss": 2.0312830555438994, "perplexity": 7.62386192445013, "lr": 0.0003, "tokens_seen": 32768000, "tokens_per_sec": 25881.73109501899, "forward_time_ms": 168.41483116149902, "backward_time_ms": 449.22924041748047, "grad_norm_total": 5.784603972035512, "grad_norm_embedding": 3.53125, "grad_norm_layers": 4.58163813379654, "grad_norm_head": 0, "memory_allocated_mb": 851.03955078125, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5085.35986328125}
