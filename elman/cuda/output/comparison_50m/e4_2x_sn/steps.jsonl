{"type": "header", "timestamp": "2026-01-04T22:36:56.398393", "config": {"level": "4", "params": "50m", "num_params": 49187840, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 666.2380695343018, "total_time_s": 66.77082777023315, "loss": 3.0902115726470947, "perplexity": 21.981728216240658, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 24537.899394132084, "forward_time_ms": 184.89766120910645, "backward_time_ms": 467.82684326171875, "grad_norm_total": 3.134206747952824, "grad_norm_embedding": 1.8515625, "grad_norm_layers": 2.528554430086595, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 200, "step_time_ms": 657.6070785522461, "total_time_s": 132.6715726852417, "loss": 2.3738252997398375, "perplexity": 10.738391382958786, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 24698.698424211223, "forward_time_ms": 183.76588821411133, "backward_time_ms": 460.41178703308105, "grad_norm_total": 3.935275987680602, "grad_norm_embedding": 2.3125, "grad_norm_layers": 3.18402255109054, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 300, "step_time_ms": 659.1176986694336, "total_time_s": 198.56706047058105, "loss": 2.1877657103538515, "perplexity": 8.915271546465938, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 24753.4295669538, "forward_time_ms": 182.2507381439209, "backward_time_ms": 463.4408950805664, "grad_norm_total": 4.72134491203103, "grad_norm_embedding": 2.796875, "grad_norm_layers": 3.8036801773389635, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 400, "step_time_ms": 665.3988361358643, "total_time_s": 264.50909876823425, "loss": 2.1528233242034913, "perplexity": 8.60913048353558, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 24776.513206690568, "forward_time_ms": 184.04245376586914, "backward_time_ms": 468.13440322875977, "grad_norm_total": 7.994123904285051, "grad_norm_embedding": 4.59375, "grad_norm_layers": 6.542214611988431, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 500, "step_time_ms": 662.304162979126, "total_time_s": 330.41750955581665, "loss": 2.17821258187294, "perplexity": 8.830508333511482, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 24792.917701643266, "forward_time_ms": 183.74276161193848, "backward_time_ms": 464.89763259887695, "grad_norm_total": 7.69335516354256, "grad_norm_embedding": 4.3125, "grad_norm_layers": 6.37100549336494, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 600, "step_time_ms": 661.0431671142578, "total_time_s": 396.33694434165955, "loss": 2.079139494895935, "perplexity": 7.9975839906210915, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 24803.179056424975, "forward_time_ms": 183.47597122192383, "backward_time_ms": 463.96684646606445, "grad_norm_total": 8.731999417667877, "grad_norm_embedding": 4.96875, "grad_norm_layers": 7.1804581700438925, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 700, "step_time_ms": 664.1907691955566, "total_time_s": 462.19329738616943, "loss": 2.12845010638237, "perplexity": 8.401834764827573, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 24813.88759885048, "forward_time_ms": 183.51197242736816, "backward_time_ms": 466.95446968078613, "grad_norm_total": 10.781666148790828, "grad_norm_embedding": 5.15625, "grad_norm_layers": 9.468733942878677, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 800, "step_time_ms": 644.3119049072266, "total_time_s": 527.7561273574829, "loss": 2.0829559659957884, "perplexity": 8.02816485716797, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 24835.736566695225, "forward_time_ms": 176.61333084106445, "backward_time_ms": 454.9376964569092, "grad_norm_total": 8.128446235846479, "grad_norm_embedding": 4.0625, "grad_norm_layers": 7.0404037419529555, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 900, "step_time_ms": 646.0719108581543, "total_time_s": 591.9596500396729, "loss": 2.16651975274086, "perplexity": 8.727856025933153, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 24909.828030598746, "forward_time_ms": 177.01482772827148, "backward_time_ms": 456.44569396972656, "grad_norm_total": 8.415638210384179, "grad_norm_embedding": 3.859375, "grad_norm_layers": 7.478500774540158, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1000, "step_time_ms": 644.2673206329346, "total_time_s": 656.1463446617126, "loss": 2.0305647921562193, "perplexity": 7.61838794967024, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 24970.05951372674, "forward_time_ms": 176.9719123840332, "backward_time_ms": 454.8304080963135, "grad_norm_total": 8.665596180658165, "grad_norm_embedding": 3.921875, "grad_norm_layers": 7.727282797447244, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1100, "step_time_ms": 644.3641185760498, "total_time_s": 721.047687292099, "loss": 2.2195553958415983, "perplexity": 9.203238158176351, "lr": 0.0003, "tokens_seen": 18022400, "tokens_per_sec": 24994.760245872887, "forward_time_ms": 175.5225658416748, "backward_time_ms": 456.0375213623047, "grad_norm_total": 21.711750993145003, "grad_norm_embedding": 9.75, "grad_norm_layers": 19.399392903928742, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1200, "step_time_ms": 651.34596824646, "total_time_s": 785.6612410545349, "loss": 2.037284915447235, "perplexity": 7.669756865375795, "lr": 0.0003, "tokens_seen": 19660800, "tokens_per_sec": 25024.54393852222, "forward_time_ms": 178.04932594299316, "backward_time_ms": 460.08944511413574, "grad_norm_total": 9.011530741618849, "grad_norm_embedding": 2.4375, "grad_norm_layers": 8.67557937690408, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1300, "step_time_ms": 647.3114490509033, "total_time_s": 850.25403881073, "loss": 2.0479104578495027, "perplexity": 7.751686695770974, "lr": 0.0003, "tokens_seen": 21299200, "tokens_per_sec": 25050.410811400623, "forward_time_ms": 176.44524574279785, "backward_time_ms": 457.9343795776367, "grad_norm_total": 12.21265486054114, "grad_norm_embedding": 4.28125, "grad_norm_layers": 11.43763051442435, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1400, "step_time_ms": 648.7317085266113, "total_time_s": 914.9139058589935, "loss": 2.1294929575920105, "perplexity": 8.41060119862383, "lr": 0.0003, "tokens_seen": 22937600, "tokens_per_sec": 25070.787972016304, "forward_time_ms": 178.49373817443848, "backward_time_ms": 456.67004585266113, "grad_norm_total": 19.258354532223827, "grad_norm_embedding": 9.25, "grad_norm_layers": 16.891298797605817, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1500, "step_time_ms": 650.6204605102539, "total_time_s": 979.6243731975555, "loss": 2.1243038535118104, "perplexity": 8.367070753310736, "lr": 0.0003, "tokens_seen": 24576000, "tokens_per_sec": 25087.1800880303, "forward_time_ms": 178.0998706817627, "backward_time_ms": 459.7969055175781, "grad_norm_total": 16.56308922360566, "grad_norm_embedding": 7.125, "grad_norm_layers": 14.952228834314656, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1600, "step_time_ms": 652.2109508514404, "total_time_s": 1044.192780971527, "loss": 2.202912234067917, "perplexity": 9.051334759442854, "lr": 0.0003, "tokens_seen": 26214400, "tokens_per_sec": 25104.955775184877, "forward_time_ms": 177.6735782623291, "backward_time_ms": 461.2691402435303, "grad_norm_total": 42.63966252723137, "grad_norm_embedding": 5.3125, "grad_norm_layers": 42.307410647154015, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1700, "step_time_ms": 652.7163982391357, "total_time_s": 1108.9530563354492, "loss": 2.202098879814148, "perplexity": 9.0439758109357, "lr": 0.0003, "tokens_seen": 27852800, "tokens_per_sec": 25116.315042039187, "forward_time_ms": 178.4679889678955, "backward_time_ms": 461.2603187561035, "grad_norm_total": 37.36648792335613, "grad_norm_embedding": 5.15625, "grad_norm_layers": 37.009008327636046, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1800, "step_time_ms": 646.9452381134033, "total_time_s": 1173.6081008911133, "loss": 2.268107725381851, "perplexity": 9.661102048198789, "lr": 0.0003, "tokens_seen": 29491200, "tokens_per_sec": 25128.672072241865, "forward_time_ms": 177.42681503295898, "backward_time_ms": 456.74633979797363, "grad_norm_total": 14.93747346470246, "grad_norm_embedding": 3.203125, "grad_norm_layers": 14.589980879695181, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1900, "step_time_ms": 651.0906219482422, "total_time_s": 1238.2134714126587, "loss": 2.201656676530838, "perplexity": 9.039977419254047, "lr": 0.0003, "tokens_seen": 31129600, "tokens_per_sec": 25140.74811794546, "forward_time_ms": 177.5658130645752, "backward_time_ms": 460.12210845947266, "grad_norm_total": 74.1226571312667, "grad_norm_embedding": 4.78125, "grad_norm_layers": 73.96828068701853, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 2000, "step_time_ms": 650.099515914917, "total_time_s": 1302.8203225135803, "loss": 2.2224358355998994, "perplexity": 9.229785747282554, "lr": 0.0003, "tokens_seen": 32768000, "tokens_per_sec": 25151.598607986547, "forward_time_ms": 176.6185760498047, "backward_time_ms": 460.4005813598633, "grad_norm_total": 17.34684044055257, "grad_norm_embedding": 4.78125, "grad_norm_layers": 16.674889115473082, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
