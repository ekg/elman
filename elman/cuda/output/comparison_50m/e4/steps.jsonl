{"type": "header", "timestamp": "2026-01-04T21:38:28.003480", "config": {"level": "4", "params": "50m", "num_params": 50610432, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 1019.054651260376, "total_time_s": 102.4524896144867, "loss": 3.412554717063904, "perplexity": 30.34266224376944, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 15991.904780309023, "forward_time_ms": 267.8251266479492, "backward_time_ms": 734.8291873931885, "grad_norm_total": 0.8610550373920919, "grad_norm_embedding": 0.71875, "grad_norm_layers": 0.4733602872245504, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 200, "step_time_ms": 1024.9104499816895, "total_time_s": 204.2114372253418, "loss": 2.812092871665955, "perplexity": 16.644717048040604, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 16046.162980570289, "forward_time_ms": 273.0705738067627, "backward_time_ms": 736.020565032959, "grad_norm_total": 1.5984989599694561, "grad_norm_embedding": 1.140625, "grad_norm_layers": 1.1196841915593292, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 300, "step_time_ms": 1023.8766670227051, "total_time_s": 305.9062650203705, "loss": 2.6278634691238403, "perplexity": 13.844159807070032, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 16067.695365829535, "forward_time_ms": 271.09789848327637, "backward_time_ms": 736.4253997802734, "grad_norm_total": 2.376599430729406, "grad_norm_embedding": 1.6328125, "grad_norm_layers": 1.7267729323651457, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 400, "step_time_ms": 1030.4858684539795, "total_time_s": 407.69113659858704, "loss": 2.538768775463104, "perplexity": 12.66406905551623, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 16074.934386232866, "forward_time_ms": 272.2351551055908, "backward_time_ms": 741.9793605804443, "grad_norm_total": 6.648949516331342, "grad_norm_embedding": 4.46875, "grad_norm_layers": 4.922910220120787, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 500, "step_time_ms": 1030.1971435546875, "total_time_s": 509.99292516708374, "loss": 2.5247398853302, "perplexity": 12.487646621037921, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 16062.98576929705, "forward_time_ms": 272.3970413208008, "backward_time_ms": 742.0496940612793, "grad_norm_total": 5.0453465647249285, "grad_norm_embedding": 3.4375, "grad_norm_layers": 3.6929814285822187, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 600, "step_time_ms": 1028.461217880249, "total_time_s": 612.4673645496368, "loss": 2.364915192127228, "perplexity": 10.64313615749707, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 16050.502693975664, "forward_time_ms": 270.68614959716797, "backward_time_ms": 741.9140338897705, "grad_norm_total": 6.360247157751962, "grad_norm_embedding": 4.21875, "grad_norm_layers": 4.759655144759954, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 700, "step_time_ms": 1025.869369506836, "total_time_s": 714.7868545055389, "loss": 2.3839823257923127, "perplexity": 10.848017298172465, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 16045.074504868793, "forward_time_ms": 270.9367275238037, "backward_time_ms": 738.9287948608398, "grad_norm_total": 6.097994681756963, "grad_norm_embedding": 4.0625, "grad_norm_layers": 4.547648175001102, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 800, "step_time_ms": 1027.658462524414, "total_time_s": 817.1813857555389, "loss": 2.3140699458122254, "perplexity": 10.115510569457742, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 16039.533193361958, "forward_time_ms": 276.5071392059326, "backward_time_ms": 734.7710132598877, "grad_norm_total": 5.127139359384187, "grad_norm_embedding": 3.359375, "grad_norm_layers": 3.873200904857164, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 900, "step_time_ms": 1029.4404029846191, "total_time_s": 919.6439235210419, "loss": 2.318985747098923, "perplexity": 10.165358831022534, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 16034.041765562288, "forward_time_ms": 272.01199531555176, "backward_time_ms": 741.5921688079834, "grad_norm_total": 4.717972492240705, "grad_norm_embedding": 3.125, "grad_norm_layers": 3.5346095992978057, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1000, "step_time_ms": 1032.7320098876953, "total_time_s": 1021.7266356945038, "loss": 2.2038698172569275, "perplexity": 9.06000631665268, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 16035.611047306573, "forward_time_ms": 269.7176933288574, "backward_time_ms": 746.4916706085205, "grad_norm_total": 5.7065950180659515, "grad_norm_embedding": 3.828125, "grad_norm_layers": 4.2320498482172555, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1100, "step_time_ms": 1026.1025428771973, "total_time_s": 1124.6861326694489, "loss": 2.362236363887787, "perplexity": 10.614663177940127, "lr": 0.0003, "tokens_seen": 18022400, "tokens_per_sec": 16024.389046707138, "forward_time_ms": 272.0651626586914, "backward_time_ms": 738.1253242492676, "grad_norm_total": 10.942280443232711, "grad_norm_embedding": 7.375, "grad_norm_layers": 8.083447698565212, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1200, "step_time_ms": 1023.2217311859131, "total_time_s": 1226.8983597755432, "loss": 2.1665281105041503, "perplexity": 8.727928971592682, "lr": 0.0003, "tokens_seen": 19660800, "tokens_per_sec": 16024.806496690242, "forward_time_ms": 270.9348201751709, "backward_time_ms": 736.2933158874512, "grad_norm_total": 5.789211449955347, "grad_norm_embedding": 3.828125, "grad_norm_layers": 4.342788155124451, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1300, "step_time_ms": 1145.8756923675537, "total_time_s": 1329.3127403259277, "loss": 2.154957478046417, "perplexity": 8.62752331202305, "lr": 0.0003, "tokens_seen": 21299200, "tokens_per_sec": 16022.722499276315, "forward_time_ms": 298.00868034362793, "backward_time_ms": 830.3196430206299, "grad_norm_total": 7.361856937668486, "grad_norm_embedding": 4.96875, "grad_norm_layers": 5.4321313550600685, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1400, "step_time_ms": 1078.3107280731201, "total_time_s": 1439.1269164085388, "loss": 2.2195464217662813, "perplexity": 9.203155567994544, "lr": 0.0003, "tokens_seen": 22937600, "tokens_per_sec": 15938.559640850437, "forward_time_ms": 279.99329566955566, "backward_time_ms": 779.9365520477295, "grad_norm_total": 12.546732069771453, "grad_norm_embedding": 8.3125, "grad_norm_layers": 9.397666732277377, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1500, "step_time_ms": 1073.1990337371826, "total_time_s": 1546.22971701622, "loss": 2.1781781446933746, "perplexity": 8.830204240946422, "lr": 0.0003, "tokens_seen": 24576000, "tokens_per_sec": 15894.15232285838, "forward_time_ms": 289.2296314239502, "backward_time_ms": 765.7139301300049, "grad_norm_total": 10.532771824652581, "grad_norm_embedding": 6.9375, "grad_norm_layers": 7.925229286775627, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1600, "step_time_ms": 1177.325963973999, "total_time_s": 1655.9160549640656, "loss": 2.2228398656845094, "perplexity": 9.233515611836967, "lr": 0.0003, "tokens_seen": 26214400, "tokens_per_sec": 15830.759900283256, "forward_time_ms": 284.67345237731934, "backward_time_ms": 875.3488063812256, "grad_norm_total": 6.461374452677214, "grad_norm_embedding": 4.25, "grad_norm_layers": 4.8668368996926175, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1700, "step_time_ms": 985.6555461883545, "total_time_s": 1760.9895405769348, "loss": 2.184799256324768, "perplexity": 8.888863991031366, "lr": 0.0003, "tokens_seen": 27852800, "tokens_per_sec": 15816.566952462901, "forward_time_ms": 266.385555267334, "backward_time_ms": 703.411340713501, "grad_norm_total": 7.248512977606801, "grad_norm_embedding": 4.78125, "grad_norm_layers": 5.447942651112947, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1800, "step_time_ms": 1134.0916156768799, "total_time_s": 1868.479915380478, "loss": 2.230892276763916, "perplexity": 9.308167837075747, "lr": 0.0003, "tokens_seen": 29491200, "tokens_per_sec": 15783.531920961514, "forward_time_ms": 305.80615997314453, "backward_time_ms": 809.0615272521973, "grad_norm_total": 7.199571737824049, "grad_norm_embedding": 4.875, "grad_norm_layers": 5.297907044234455, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 1900, "step_time_ms": 1058.2709312438965, "total_time_s": 1975.2030711174011, "loss": 2.1487005972862243, "perplexity": 8.573710453282056, "lr": 0.0003, "tokens_seen": 31129600, "tokens_per_sec": 15760.207761937889, "forward_time_ms": 294.6193218231201, "backward_time_ms": 745.4679012298584, "grad_norm_total": 6.234508787202437, "grad_norm_embedding": 4.1875, "grad_norm_layers": 4.618791550830008, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
{"type": "step", "step": 2000, "step_time_ms": 1160.271167755127, "total_time_s": 2084.054099559784, "loss": 2.1431623101234436, "perplexity": 8.526358029436999, "lr": 0.0003, "tokens_seen": 32768000, "tokens_per_sec": 15723.205171783751, "forward_time_ms": 294.20995712280273, "backward_time_ms": 848.0770587921143, "grad_norm_total": 8.196846413138148, "grad_norm_embedding": 5.375, "grad_norm_layers": 6.188463319042959, "grad_norm_head": 0, "memory_allocated_mb": 966.2578125, "memory_reserved_mb": 6808.0, "memory_max_allocated_mb": 6305.8671875}
