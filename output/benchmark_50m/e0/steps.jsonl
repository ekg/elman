{"type": "header", "timestamp": "2026-01-04T18:07:02.218035", "config": {"level": "0", "params": "50m", "num_params": 48742912, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 500, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 50, "step_time_ms": 360.66126823425293, "total_time_s": 20.52936029434204, "loss": 3.191271495819092, "perplexity": 24.31932971893472, "lr": 0.0003, "tokens_seen": 819200, "tokens_per_sec": 39905.3719450556, "forward_time_ms": 136.21068000793457, "backward_time_ms": 208.8491916656494, "grad_norm_total": 1.4051517914776448, "grad_norm_embedding": 0.875, "grad_norm_layers": 1.098740534402123, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 100, "step_time_ms": 366.9860363006592, "total_time_s": 38.37388324737549, "loss": 2.5042446422576905, "perplexity": 12.234314190738559, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 42696.52075195632, "forward_time_ms": 141.6299343109131, "backward_time_ms": 209.5022201538086, "grad_norm_total": 1.2899244237997787, "grad_norm_embedding": 0.80078125, "grad_norm_layers": 1.0107002480819627, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 150, "step_time_ms": 357.90205001831055, "total_time_s": 56.06281518936157, "loss": 2.2131410884857177, "perplexity": 9.14439468178346, "lr": 0.0003, "tokens_seen": 2457600, "tokens_per_sec": 43837.046194128234, "forward_time_ms": 132.12895393371582, "backward_time_ms": 211.11226081848145, "grad_norm_total": 2.6333351233368747, "grad_norm_embedding": 1.5, "grad_norm_layers": 2.164170926255616, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 200, "step_time_ms": 357.0561408996582, "total_time_s": 73.60442900657654, "loss": 1.9390802335739137, "perplexity": 6.952353487673012, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 44519.4888468146, "forward_time_ms": 131.48117065429688, "backward_time_ms": 210.90292930603027, "grad_norm_total": 1.9443866222073891, "grad_norm_embedding": 1.0859375, "grad_norm_layers": 1.6127416020999985, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 250, "step_time_ms": 363.49940299987793, "total_time_s": 91.09223246574402, "loss": 1.95526615858078, "perplexity": 7.065799396590893, "lr": 0.0003, "tokens_seen": 4096000, "tokens_per_sec": 44965.79038911048, "forward_time_ms": 139.40978050231934, "backward_time_ms": 208.43505859375, "grad_norm_total": 2.1464688726518144, "grad_norm_embedding": 1.203125, "grad_norm_layers": 1.7774229748754902, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 300, "step_time_ms": 354.5703887939453, "total_time_s": 108.56986856460571, "loss": 1.7702519249916078, "perplexity": 5.872332562382424, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 45272.499559519776, "forward_time_ms": 131.2413215637207, "backward_time_ms": 207.92126655578613, "grad_norm_total": 1.659875658972406, "grad_norm_embedding": 0.91015625, "grad_norm_layers": 1.3879852049434322, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 350, "step_time_ms": 354.11691665649414, "total_time_s": 126.0544080734253, "loss": 1.7851504683494568, "perplexity": 5.960476743208742, "lr": 0.0003, "tokens_seen": 5734400, "tokens_per_sec": 45491.713173842996, "forward_time_ms": 131.38294219970703, "backward_time_ms": 208.12392234802246, "grad_norm_total": 2.0378530941196806, "grad_norm_embedding": 1.15625, "grad_norm_layers": 1.6779780170723553, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 400, "step_time_ms": 356.6477298736572, "total_time_s": 143.54694771766663, "loss": 1.8562796688079835, "perplexity": 6.3998827431052545, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 45654.96406169757, "forward_time_ms": 131.54888153076172, "backward_time_ms": 210.0379467010498, "grad_norm_total": 4.579487702149524, "grad_norm_embedding": 2.71875, "grad_norm_layers": 3.6847903615383486, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 450, "step_time_ms": 356.21094703674316, "total_time_s": 161.0785505771637, "loss": 1.8265602612495422, "perplexity": 6.2124805538293995, "lr": 0.0003, "tokens_seen": 7372800, "tokens_per_sec": 45771.64679415485, "forward_time_ms": 132.1403980255127, "backward_time_ms": 208.65321159362793, "grad_norm_total": 1.873937196244912, "grad_norm_embedding": 1.046875, "grad_norm_layers": 1.5541911278337897, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 500, "step_time_ms": 366.22023582458496, "total_time_s": 178.94956874847412, "loss": 1.8394710636138916, "perplexity": 6.293208673481505, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 45778.4438002884, "forward_time_ms": 142.8229808807373, "backward_time_ms": 207.53145217895508, "grad_norm_total": 2.93042690543746, "grad_norm_embedding": 1.6171875, "grad_norm_layers": 2.4437470848533227, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
