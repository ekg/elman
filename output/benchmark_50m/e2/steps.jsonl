{"type": "header", "timestamp": "2026-01-04T18:07:08.627776", "config": {"level": "2", "params": "50m", "num_params": 49715112, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 500, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 50, "step_time_ms": 762.3956203460693, "total_time_s": 38.75604033470154, "loss": 3.2642930793762206, "perplexity": 26.161610270471552, "lr": 0.0003, "tokens_seen": 819200, "tokens_per_sec": 21137.809043380927, "forward_time_ms": 139.4336223602295, "backward_time_ms": 599.7886657714844, "grad_norm_total": 1.2274252099540284, "grad_norm_embedding": 0.859375, "grad_norm_layers": 0.8754511658510356, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12424.36376953125}
{"type": "step", "step": 100, "step_time_ms": 766.9417858123779, "total_time_s": 76.69310975074768, "loss": 2.55776606798172, "perplexity": 12.906951832826609, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 21363.23852698155, "forward_time_ms": 142.52781867980957, "backward_time_ms": 601.2837886810303, "grad_norm_total": 1.2470139881308153, "grad_norm_embedding": 0.86328125, "grad_norm_layers": 0.8992654029306029, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12425.98876953125}
{"type": "step", "step": 150, "step_time_ms": 771.0192203521729, "total_time_s": 114.7893009185791, "loss": 2.230986840724945, "perplexity": 9.309048095916067, "lr": 0.0003, "tokens_seen": 2457600, "tokens_per_sec": 21409.7650673719, "forward_time_ms": 145.11370658874512, "backward_time_ms": 603.412389755249, "grad_norm_total": 2.465238299871594, "grad_norm_embedding": 1.5625, "grad_norm_layers": 1.9066390816738075, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12429.23876953125}
{"type": "step", "step": 200, "step_time_ms": 769.7131633758545, "total_time_s": 152.97331070899963, "loss": 1.966570816040039, "perplexity": 7.146129032476745, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 21420.807747249462, "forward_time_ms": 144.37627792358398, "backward_time_ms": 603.1625270843506, "grad_norm_total": 1.9093142743057772, "grad_norm_embedding": 1.1796875, "grad_norm_layers": 1.5010911058386733, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12430.86376953125}
{"type": "step", "step": 250, "step_time_ms": 769.5555686950684, "total_time_s": 191.38983488082886, "loss": 1.9803406071662903, "perplexity": 7.245210335500107, "lr": 0.0003, "tokens_seen": 4096000, "tokens_per_sec": 21401.40782173547, "forward_time_ms": 143.4311866760254, "backward_time_ms": 603.6500930786133, "grad_norm_total": 2.1554751749541796, "grad_norm_embedding": 1.3359375, "grad_norm_layers": 1.6913419694364507, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12430.86376953125}
{"type": "step", "step": 300, "step_time_ms": 775.3958702087402, "total_time_s": 229.5730104446411, "loss": 1.7939740443229675, "perplexity": 6.013302174465079, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 21410.23353127298, "forward_time_ms": 147.25637435913086, "backward_time_ms": 604.2022705078125, "grad_norm_total": 1.800889102506291, "grad_norm_embedding": 1.1015625, "grad_norm_layers": 1.4245840043324276, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 350, "step_time_ms": 774.1971015930176, "total_time_s": 267.86303448677063, "loss": 1.8035701680183411, "perplexity": 6.071284322940674, "lr": 0.0003, "tokens_seen": 5734400, "tokens_per_sec": 21408.002035644844, "forward_time_ms": 147.51386642456055, "backward_time_ms": 603.3971309661865, "grad_norm_total": 2.20519782415498, "grad_norm_embedding": 1.359375, "grad_norm_layers": 1.7362849353202476, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 400, "step_time_ms": 767.575740814209, "total_time_s": 305.95088171958923, "loss": 1.8794928765296937, "perplexity": 6.550182268616564, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 21420.46855284586, "forward_time_ms": 140.04850387573242, "backward_time_ms": 605.1559448242188, "grad_norm_total": 4.333335435347277, "grad_norm_embedding": 2.796875, "grad_norm_layers": 3.3094387071366675, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 450, "step_time_ms": 767.2169208526611, "total_time_s": 344.14547777175903, "loss": 1.848861347436905, "perplexity": 6.352582019084534, "lr": 0.0003, "tokens_seen": 7372800, "tokens_per_sec": 21423.536482920616, "forward_time_ms": 140.0768756866455, "backward_time_ms": 605.0081253051758, "grad_norm_total": 1.8414709179720206, "grad_norm_embedding": 1.1015625, "grad_norm_layers": 1.4755929507133703, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 500, "step_time_ms": 782.5043201446533, "total_time_s": 382.3375005722046, "loss": 1.8702278423309326, "perplexity": 6.489774876285534, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 21426.13013228669, "forward_time_ms": 154.37722206115723, "backward_time_ms": 604.7074794769287, "grad_norm_total": 3.0270587286291186, "grad_norm_embedding": 1.828125, "grad_norm_layers": 2.4126326828262856, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12434.11376953125}
