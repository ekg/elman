{"type": "header", "timestamp": "2026-01-05T07:13:11.145687", "config": {"level": "mamba2", "params": "50m", "num_params": 50928750, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 143.40806007385254, "total_time_s": 26.975053071975708, "loss": 2.727606728076935, "perplexity": 15.296235128368801, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 60739.12631740584, "forward_time_ms": 23.506641387939453, "backward_time_ms": 64.40567970275879, "grad_norm_total": 0.9836494561521909, "grad_norm_embedding": 0.6640625, "grad_norm_layers": 0.7252675283867067, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 200, "step_time_ms": 145.18260955810547, "total_time_s": 40.630892276763916, "loss": 1.979571441411972, "perplexity": 7.239639710468849, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 80649.2818171952, "forward_time_ms": 23.43440055847168, "backward_time_ms": 64.56971168518066, "grad_norm_total": 1.3173062643445668, "grad_norm_embedding": 0.67578125, "grad_norm_layers": 1.1306547147383434, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 300, "step_time_ms": 148.9872932434082, "total_time_s": 54.60223054885864, "loss": 1.779751842021942, "perplexity": 5.9283850599843735, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 90019.33588139714, "forward_time_ms": 23.414134979248047, "backward_time_ms": 64.33534622192383, "grad_norm_total": 1.1327477725766482, "grad_norm_embedding": 0.55859375, "grad_norm_layers": 0.9853653776062342, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 400, "step_time_ms": 152.14109420776367, "total_time_s": 68.8561360836029, "loss": 1.7349503207206727, "perplexity": 5.668646182552557, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 95179.02185476635, "forward_time_ms": 23.350954055786133, "backward_time_ms": 64.58759307861328, "grad_norm_total": 3.1289021903265106, "grad_norm_embedding": 1.765625, "grad_norm_layers": 2.5827574267755105, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 500, "step_time_ms": 152.4796485900879, "total_time_s": 83.3186867237091, "loss": 1.7494095134735108, "perplexity": 5.751205663703952, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 98322.02730529939, "forward_time_ms": 23.40984344482422, "backward_time_ms": 65.0334358215332, "grad_norm_total": 1.9606578276901154, "grad_norm_embedding": 0.93359375, "grad_norm_layers": 1.724043689950465, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 600, "step_time_ms": 155.36022186279297, "total_time_s": 98.00087308883667, "loss": 1.6646232736110687, "perplexity": 5.283682372195914, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 100309.95076985043, "forward_time_ms": 23.672103881835938, "backward_time_ms": 64.24117088317871, "grad_norm_total": 1.8760814970879853, "grad_norm_embedding": 0.94921875, "grad_norm_layers": 1.6181242155587925, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 700, "step_time_ms": 154.60610389709473, "total_time_s": 112.83802270889282, "loss": 1.6757175385951997, "perplexity": 5.342627315343683, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 101640.02580717884, "forward_time_ms": 23.47397804260254, "backward_time_ms": 64.37420845031738, "grad_norm_total": 2.6141240381624544, "grad_norm_embedding": 1.25, "grad_norm_layers": 2.2958113046421076, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 800, "step_time_ms": 156.55231475830078, "total_time_s": 127.79172468185425, "loss": 1.6401879847049714, "perplexity": 5.156138696347557, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 102567.33423218495, "forward_time_ms": 23.432493209838867, "backward_time_ms": 64.47482109069824, "grad_norm_total": 1.5395566054941558, "grad_norm_embedding": 0.7265625, "grad_norm_layers": 1.3572677991133846, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 900, "step_time_ms": 156.62336349487305, "total_time_s": 142.86138916015625, "loss": 1.7676859021186828, "perplexity": 5.857283339292863, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 103216.55901405888, "forward_time_ms": 23.792266845703125, "backward_time_ms": 64.38016891479492, "grad_norm_total": 1.4787471141609014, "grad_norm_embedding": 0.68359375, "grad_norm_layers": 1.3112168894801344, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 1000, "step_time_ms": 156.96120262145996, "total_time_s": 157.9910237789154, "loss": 1.5684346222877503, "perplexity": 4.799129859873427, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 103702.48617904476, "forward_time_ms": 23.479700088500977, "backward_time_ms": 64.4083023071289, "grad_norm_total": 1.3383181876782757, "grad_norm_embedding": 0.62890625, "grad_norm_layers": 1.1813001693424292, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
