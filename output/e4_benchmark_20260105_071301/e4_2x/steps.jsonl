{"type": "header", "timestamp": "2026-01-05T07:13:29.270071", "config": {"level": "4", "params": "50m", "num_params": 49187840, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 561.0032081604004, "total_time_s": 56.223084449768066, "loss": 2.9214719903469084, "perplexity": 18.56860015298561, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 29141.43296454637, "forward_time_ms": 154.23297882080078, "backward_time_ms": 393.3238983154297, "grad_norm_total": 1.5072071205196798, "grad_norm_embedding": 0.953125, "grad_norm_layers": 1.1670713378388504, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 200, "step_time_ms": 546.3318824768066, "total_time_s": 111.62935423851013, "loss": 2.159272096157074, "perplexity": 8.664828200657196, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 29354.454361242795, "forward_time_ms": 147.48144149780273, "backward_time_ms": 385.85805892944336, "grad_norm_total": 2.050714763190866, "grad_norm_embedding": 1.15625, "grad_norm_layers": 1.6935314081077322, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 300, "step_time_ms": 564.3222332000732, "total_time_s": 167.25674486160278, "loss": 1.9308552479743957, "perplexity": 6.895405001641475, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 29387.256511750536, "forward_time_ms": 156.54802322387695, "backward_time_ms": 394.1993713378906, "grad_norm_total": 1.7734939663785474, "grad_norm_embedding": 0.97265625, "grad_norm_layers": 1.4828611257027529, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 400, "step_time_ms": 562.6742839813232, "total_time_s": 222.82844495773315, "loss": 1.8763686418533325, "perplexity": 6.529749896419097, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 29411.04699705606, "forward_time_ms": 150.25973320007324, "backward_time_ms": 398.8912105560303, "grad_norm_total": 4.217804173125486, "grad_norm_embedding": 2.46875, "grad_norm_layers": 3.419487742085567, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 500, "step_time_ms": 565.4757022857666, "total_time_s": 278.58429980278015, "loss": 1.8814058339595794, "perplexity": 6.562724480988838, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 29405.899729532728, "forward_time_ms": 164.0174388885498, "backward_time_ms": 388.2720470428467, "grad_norm_total": 3.1804701569518823, "grad_norm_embedding": 1.71875, "grad_norm_layers": 2.6760095400167234, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 600, "step_time_ms": 558.3922863006592, "total_time_s": 334.11772894859314, "loss": 1.7856049311161042, "perplexity": 5.9631861735809775, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 29422.01324397284, "forward_time_ms": 149.96886253356934, "backward_time_ms": 395.61009407043457, "grad_norm_total": 3.6383822222985147, "grad_norm_embedding": 1.984375, "grad_norm_layers": 3.049552597300926, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 700, "step_time_ms": 537.4464988708496, "total_time_s": 389.70010137557983, "loss": 1.7997881615161895, "perplexity": 6.048366051997521, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 29429.852645017807, "forward_time_ms": 145.42770385742188, "backward_time_ms": 379.66084480285645, "grad_norm_total": 4.498776296166512, "grad_norm_embedding": 2.40625, "grad_norm_layers": 3.801130898409335, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 800, "step_time_ms": 540.8952236175537, "total_time_s": 443.1350464820862, "loss": 1.7552596998214722, "perplexity": 5.784949897349155, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 29578.380370046056, "forward_time_ms": 147.57490158081055, "backward_time_ms": 379.7192573547363, "grad_norm_total": 2.7718223725402287, "grad_norm_embedding": 1.484375, "grad_norm_layers": 2.3408249795116807, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 900, "step_time_ms": 532.6626300811768, "total_time_s": 496.81240153312683, "loss": 1.8462464237213134, "perplexity": 6.335992201714219, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 29680.45385134132, "forward_time_ms": 145.22814750671387, "backward_time_ms": 375.22172927856445, "grad_norm_total": 2.772592649760923, "grad_norm_embedding": 1.5, "grad_norm_layers": 2.3317545068854266, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1000, "step_time_ms": 536.9782447814941, "total_time_s": 550.139429807663, "loss": 1.6762003159523011, "perplexity": 5.345207237552866, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 29781.57148790589, "forward_time_ms": 145.37835121154785, "backward_time_ms": 379.1496753692627, "grad_norm_total": 2.497819814627337, "grad_norm_embedding": 1.3046875, "grad_norm_layers": 2.1299528914603743, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
