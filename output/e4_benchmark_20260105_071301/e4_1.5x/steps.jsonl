{"type": "header", "timestamp": "2026-01-05T07:13:30.252396", "config": {"level": "4", "params": "50m", "num_params": 50941696, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 843.8436985015869, "total_time_s": 84.87206840515137, "loss": 2.9181474804878236, "perplexity": 18.506971158569545, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 19304.53000314246, "forward_time_ms": 223.48403930664062, "backward_time_ms": 603.6176681518555, "grad_norm_total": 1.414348567102165, "grad_norm_embedding": 0.91015625, "grad_norm_layers": 1.0820405650684681, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 200, "step_time_ms": 856.3859462738037, "total_time_s": 169.83753061294556, "loss": 2.1161517655849456, "perplexity": 8.299138926162506, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 19293.82267036653, "forward_time_ms": 229.48551177978516, "backward_time_ms": 610.0454330444336, "grad_norm_total": 2.3346685490997627, "grad_norm_embedding": 1.3359375, "grad_norm_layers": 1.914533110451064, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 300, "step_time_ms": 848.2415676116943, "total_time_s": 254.60104990005493, "loss": 1.9006457388401032, "perplexity": 6.690213178239186, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 19305.55854563835, "forward_time_ms": 228.03568840026855, "backward_time_ms": 602.971076965332, "grad_norm_total": 2.059312669749901, "grad_norm_embedding": 1.1796875, "grad_norm_layers": 1.6878301500655004, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 400, "step_time_ms": 844.9556827545166, "total_time_s": 339.35724568367004, "loss": 1.8537983834743499, "perplexity": 6.384022492958186, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 19311.845076411402, "forward_time_ms": 220.98588943481445, "backward_time_ms": 607.6724529266357, "grad_norm_total": 4.860913384368391, "grad_norm_embedding": 2.890625, "grad_norm_layers": 3.90772499096025, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 500, "step_time_ms": 815.037727355957, "total_time_s": 422.9166536331177, "loss": 1.8661576318740845, "perplexity": 6.463413810656761, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 19370.279072588128, "forward_time_ms": 213.85765075683594, "backward_time_ms": 585.6754779815674, "grad_norm_total": 3.709276483915198, "grad_norm_embedding": 2.109375, "grad_norm_layers": 3.051071184696366, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 600, "step_time_ms": 820.561408996582, "total_time_s": 504.8204472064972, "loss": 1.7765515446662903, "perplexity": 5.9094427915664545, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 19473.088906033492, "forward_time_ms": 213.01841735839844, "backward_time_ms": 591.9189453125, "grad_norm_total": 3.7938698112432805, "grad_norm_embedding": 2.125, "grad_norm_layers": 3.1428520245233287, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 700, "step_time_ms": 822.2188949584961, "total_time_s": 586.2630481719971, "loss": 1.791982661485672, "perplexity": 6.001339303001172, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 19562.572694305454, "forward_time_ms": 212.36586570739746, "backward_time_ms": 594.2201614379883, "grad_norm_total": 4.8858189788140365, "grad_norm_embedding": 2.734375, "grad_norm_layers": 4.04896469602973, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 800, "step_time_ms": 822.4141597747803, "total_time_s": 667.459157705307, "loss": 1.746268366575241, "perplexity": 5.733168625196535, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 19637.47727456213, "forward_time_ms": 219.0389633178711, "backward_time_ms": 587.355375289917, "grad_norm_total": 3.028087541842119, "grad_norm_embedding": 1.6875, "grad_norm_layers": 2.5142563568155247, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 900, "step_time_ms": 819.2586898803711, "total_time_s": 748.7166616916656, "loss": 1.8423689138889312, "perplexity": 6.311471899233212, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 19694.517776136814, "forward_time_ms": 213.87290954589844, "backward_time_ms": 589.6286964416504, "grad_norm_total": 2.8491164748306392, "grad_norm_embedding": 1.59375, "grad_norm_layers": 2.3616225560417856, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 1000, "step_time_ms": 820.9707736968994, "total_time_s": 829.8303349018097, "loss": 1.6694257259368896, "perplexity": 5.309118032780468, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 19743.811259761966, "forward_time_ms": 212.8002643585205, "backward_time_ms": 592.5133228302002, "grad_norm_total": 2.6991937280309757, "grad_norm_embedding": 1.5234375, "grad_norm_layers": 2.2281374013022375, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
