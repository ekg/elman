{"type": "header", "timestamp": "2026-01-05T07:13:22.592987", "config": {"level": "4", "params": "50m", "num_params": 53368832, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 260.38265228271484, "total_time_s": 28.72220802307129, "loss": 2.963371760845184, "perplexity": 19.36314972156697, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 57044.695162806274, "forward_time_ms": 69.53668594360352, "backward_time_ms": 178.21168899536133, "grad_norm_total": 1.1669955290463223, "grad_norm_embedding": 0.7578125, "grad_norm_layers": 0.8868697654636936, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 200, "step_time_ms": 260.96200942993164, "total_time_s": 54.5267813205719, "loss": 2.2272803843021394, "perplexity": 9.274608378893141, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 60096.00947215468, "forward_time_ms": 69.99874114990234, "backward_time_ms": 178.67732048034668, "grad_norm_total": 1.5842686442446894, "grad_norm_embedding": 0.8203125, "grad_norm_layers": 1.3552216212150878, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 300, "step_time_ms": 260.6627941131592, "total_time_s": 80.3368673324585, "loss": 1.988494428396225, "perplexity": 7.304527989479042, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 61182.84209215004, "forward_time_ms": 69.2293643951416, "backward_time_ms": 179.1665554046631, "grad_norm_total": 1.371938877326616, "grad_norm_embedding": 0.68359375, "grad_norm_layers": 1.189369158372776, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 400, "step_time_ms": 260.3566646575928, "total_time_s": 106.14040327072144, "loss": 1.9239380645751953, "perplexity": 6.84787280461973, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 61745.0066808233, "forward_time_ms": 69.75126266479492, "backward_time_ms": 178.32374572753906, "grad_norm_total": 3.1070333210336574, "grad_norm_embedding": 1.8515625, "grad_norm_layers": 2.4945527798888083, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 500, "step_time_ms": 260.5569362640381, "total_time_s": 131.94482159614563, "loss": 1.9180201482772827, "perplexity": 6.8074673425369046, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 62086.86059858463, "forward_time_ms": 69.51189041137695, "backward_time_ms": 178.9834499359131, "grad_norm_total": 2.2669091430973403, "grad_norm_embedding": 1.078125, "grad_norm_layers": 1.9940675314360927, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 600, "step_time_ms": 261.8601322174072, "total_time_s": 157.82806658744812, "loss": 1.8143823093175888, "perplexity": 6.137284063207541, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 62285.785677873944, "forward_time_ms": 69.84066963195801, "backward_time_ms": 179.65078353881836, "grad_norm_total": 2.6942571985921204, "grad_norm_embedding": 1.296875, "grad_norm_layers": 2.361519063545324, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 700, "step_time_ms": 261.8086338043213, "total_time_s": 183.7727861404419, "loss": 1.8229273056983948, "perplexity": 6.189951835809082, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 62407.731871405085, "forward_time_ms": 70.24431228637695, "backward_time_ms": 179.30245399475098, "grad_norm_total": 3.02860351300527, "grad_norm_embedding": 1.4140625, "grad_norm_layers": 2.678160243841542, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 800, "step_time_ms": 262.2556686401367, "total_time_s": 209.7272515296936, "loss": 1.7752948939800262, "perplexity": 5.902021350283278, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 62496.66682432296, "forward_time_ms": 69.8082447052002, "backward_time_ms": 180.14836311340332, "grad_norm_total": 2.0576756630406563, "grad_norm_embedding": 0.97265625, "grad_norm_layers": 1.8132357464419975, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 900, "step_time_ms": 260.98155975341797, "total_time_s": 235.66460299491882, "loss": 1.8534127628803254, "perplexity": 6.381561157013601, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 62570.44426119548, "forward_time_ms": 69.74077224731445, "backward_time_ms": 179.396390914917, "grad_norm_total": 1.9363032187894964, "grad_norm_embedding": 0.91015625, "grad_norm_layers": 1.7090095853308465, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 1000, "step_time_ms": 262.01725006103516, "total_time_s": 261.6045410633087, "loss": 1.6886467838287353, "perplexity": 5.412151936023968, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 62629.03037443428, "forward_time_ms": 69.78464126586914, "backward_time_ms": 180.64379692077637, "grad_norm_total": 1.784084135726973, "grad_norm_embedding": 0.828125, "grad_norm_layers": 1.580189368401335, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
