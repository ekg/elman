{"type": "header", "timestamp": "2026-01-05T07:13:30.538172", "config": {"level": "4", "params": "50m", "num_params": 49954816, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 376.6210079193115, "total_time_s": 37.94668698310852, "loss": 2.95239506483078, "perplexity": 19.1517685689207, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 43177.55763255096, "forward_time_ms": 101.31072998046875, "backward_time_ms": 261.7638111114502, "grad_norm_total": 1.0960480247895827, "grad_norm_embedding": 0.68359375, "grad_norm_layers": 0.8561930347400772, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 200, "step_time_ms": 374.7437000274658, "total_time_s": 75.04028606414795, "loss": 2.197446012496948, "perplexity": 9.001993137113733, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 43667.70707168951, "forward_time_ms": 101.26757621765137, "backward_time_ms": 260.6034278869629, "grad_norm_total": 1.6398610693003128, "grad_norm_embedding": 0.85546875, "grad_norm_layers": 1.3988971042356726, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 300, "step_time_ms": 376.5397071838379, "total_time_s": 112.5608184337616, "loss": 1.9600287294387817, "perplexity": 7.099531027768794, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 43667.32691930483, "forward_time_ms": 102.47397422790527, "backward_time_ms": 261.0790729522705, "grad_norm_total": 1.4672149776299361, "grad_norm_embedding": 0.74609375, "grad_norm_layers": 1.263223427917482, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 400, "step_time_ms": 373.74377250671387, "total_time_s": 150.37922549247742, "loss": 1.9005240881443024, "perplexity": 6.68939935865286, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 43580.678489075864, "forward_time_ms": 101.38320922851562, "backward_time_ms": 259.427547454834, "grad_norm_total": 3.7522584164439463, "grad_norm_embedding": 2.171875, "grad_norm_layers": 3.059357355366948, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 500, "step_time_ms": 374.6612071990967, "total_time_s": 188.03571128845215, "loss": 1.8977102047204972, "perplexity": 6.670602626990771, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 43566.35835676457, "forward_time_ms": 101.09257698059082, "backward_time_ms": 260.892391204834, "grad_norm_total": 2.802897118120094, "grad_norm_embedding": 1.3984375, "grad_norm_layers": 2.4290670807521155, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 600, "step_time_ms": 374.218225479126, "total_time_s": 225.74144577980042, "loss": 1.7990328806638718, "perplexity": 6.043799561639083, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 43547.3063028326, "forward_time_ms": 101.43160820007324, "backward_time_ms": 259.7935199737549, "grad_norm_total": 2.9278306730502686, "grad_norm_embedding": 1.4765625, "grad_norm_layers": 2.528166026384028, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 700, "step_time_ms": 370.44405937194824, "total_time_s": 263.5386526584625, "loss": 1.8099077343940735, "perplexity": 6.109883674103935, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 43518.62607416189, "forward_time_ms": 101.52459144592285, "backward_time_ms": 256.2549114227295, "grad_norm_total": 3.8471060818215226, "grad_norm_embedding": 1.8984375, "grad_norm_layers": 3.346016737624824, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 800, "step_time_ms": 372.47776985168457, "total_time_s": 300.43993163108826, "loss": 1.7643734228610992, "perplexity": 5.8379133088491955, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 43626.789360962655, "forward_time_ms": 101.02105140686035, "backward_time_ms": 259.14621353149414, "grad_norm_total": 2.4547597034034094, "grad_norm_embedding": 1.2109375, "grad_norm_layers": 2.135257533774968, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 900, "step_time_ms": 372.3304271697998, "total_time_s": 337.1718213558197, "loss": 1.8483996963500977, "perplexity": 6.349650019523856, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 43733.278865536195, "forward_time_ms": 100.53873062133789, "backward_time_ms": 259.1109275817871, "grad_norm_total": 2.2872998815293335, "grad_norm_embedding": 1.125, "grad_norm_layers": 1.9914598065060947, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 1000, "step_time_ms": 341.4475917816162, "total_time_s": 371.5033440589905, "loss": 1.6805837011337281, "perplexity": 5.368688766444544, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 44101.974362749505, "forward_time_ms": 93.10555458068848, "backward_time_ms": 236.3147735595703, "grad_norm_total": 2.133611323157847, "grad_norm_embedding": 1.0546875, "grad_norm_layers": 1.8546566518642114, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
