{"type": "header", "timestamp": "2026-01-05T07:53:25.612710", "config": {"level": "4", "params": "50m", "num_params": 49187840, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 597.7437496185303, "total_time_s": 61.53895902633667, "loss": 2.9228539633750916, "perplexity": 18.59427919735458, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 26624.119177779572, "forward_time_ms": 163.0403995513916, "backward_time_ms": 420.3047752380371, "grad_norm_total": 1.2939794631715915, "grad_norm_embedding": 0.8359375, "grad_norm_layers": 0.9871561713277264, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 200, "step_time_ms": 611.2394332885742, "total_time_s": 121.8268654346466, "loss": 2.1577527844905853, "perplexity": 8.651673621566959, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 26897.321172564687, "forward_time_ms": 163.87081146240234, "backward_time_ms": 433.38489532470703, "grad_norm_total": 1.9693960562572614, "grad_norm_embedding": 1.09375, "grad_norm_layers": 1.6376036862775538, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 300, "step_time_ms": 600.7623672485352, "total_time_s": 177.99085307121277, "loss": 1.9296924698352813, "perplexity": 6.887391835115509, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 27614.990273477903, "forward_time_ms": 163.82551193237305, "backward_time_ms": 422.98030853271484, "grad_norm_total": 1.8277515093436083, "grad_norm_embedding": 1.0078125, "grad_norm_layers": 1.5246815170577865, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 400, "step_time_ms": 557.9979419708252, "total_time_s": 234.1161403656006, "loss": 1.8789551377296447, "perplexity": 6.54666092832884, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 27993.024989376714, "forward_time_ms": 152.84156799316406, "backward_time_ms": 391.5591239929199, "grad_norm_total": 4.143880458089117, "grad_norm_embedding": 2.453125, "grad_norm_layers": 3.3393875807439577, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 500, "step_time_ms": 569.1673755645752, "total_time_s": 290.36405205726624, "loss": 1.8852628701925278, "perplexity": 6.588086025856215, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 28212.92766718797, "forward_time_ms": 159.5630645751953, "backward_time_ms": 395.1253890991211, "grad_norm_total": 3.095328397589075, "grad_norm_embedding": 1.671875, "grad_norm_layers": 2.604928621510849, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 600, "step_time_ms": 526.7283916473389, "total_time_s": 343.7965018749237, "loss": 1.787010442018509, "perplexity": 5.9715733895420335, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 28593.703354358833, "forward_time_ms": 142.50779151916504, "backward_time_ms": 371.68407440185547, "grad_norm_total": 3.1602406869557425, "grad_norm_embedding": 1.6953125, "grad_norm_layers": 2.6669738810196257, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 700, "step_time_ms": 528.7618637084961, "total_time_s": 396.456506729126, "loss": 1.8026959013938904, "perplexity": 6.065978721282742, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 28928.306304726706, "forward_time_ms": 142.6398754119873, "backward_time_ms": 373.7010955810547, "grad_norm_total": 4.844555777128124, "grad_norm_embedding": 2.546875, "grad_norm_layers": 4.1210220169371246, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 800, "step_time_ms": 531.3999652862549, "total_time_s": 449.14366459846497, "loss": 1.7557586348056793, "perplexity": 5.787836931396081, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 29182.68465769377, "forward_time_ms": 142.7459716796875, "backward_time_ms": 375.95582008361816, "grad_norm_total": 2.7901875799802123, "grad_norm_embedding": 1.4765625, "grad_norm_layers": 2.3674310244910246, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 900, "step_time_ms": 529.5107364654541, "total_time_s": 501.50096559524536, "loss": 1.8427511584758758, "perplexity": 6.313884886348599, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 29402.966243054005, "forward_time_ms": 142.1043872833252, "backward_time_ms": 374.9723434448242, "grad_norm_total": 2.7128407359256332, "grad_norm_embedding": 1.4140625, "grad_norm_layers": 2.315082268672577, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1000, "step_time_ms": 529.3841361999512, "total_time_s": 553.8803102970123, "loss": 1.673442530632019, "perplexity": 5.330486610992855, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 29580.42744805034, "forward_time_ms": 143.20969581604004, "backward_time_ms": 374.1116523742676, "grad_norm_total": 2.347422251738956, "grad_norm_embedding": 1.234375, "grad_norm_layers": 1.9966309015190735, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
