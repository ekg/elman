{"type": "header", "timestamp": "2026-01-05T07:53:06.111192", "config": {"level": "mamba2", "params": "50m", "num_params": 50928750, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 135.850191116333, "total_time_s": 26.70168924331665, "loss": 2.7377450680732727, "perplexity": 15.452102343095184, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 61361.07009592178, "forward_time_ms": 23.32162857055664, "backward_time_ms": 64.33391571044922, "grad_norm_total": 1.0666213487695344, "grad_norm_embedding": 0.71484375, "grad_norm_layers": 0.7912424146338272, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 200, "step_time_ms": 139.78338241577148, "total_time_s": 39.61998009681702, "loss": 1.9804865300655365, "perplexity": 7.24626765473958, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 82707.45982737684, "forward_time_ms": 23.868322372436523, "backward_time_ms": 66.48564338684082, "grad_norm_total": 1.289620432519181, "grad_norm_embedding": 0.671875, "grad_norm_layers": 1.1006741229125576, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 300, "step_time_ms": 141.95704460144043, "total_time_s": 52.75818967819214, "loss": 1.7802991771697998, "perplexity": 5.9316307616600135, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 93166.1322677305, "forward_time_ms": 25.729656219482422, "backward_time_ms": 65.6135082244873, "grad_norm_total": 1.1913036642784125, "grad_norm_embedding": 0.59375, "grad_norm_layers": 1.0327229236266025, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 400, "step_time_ms": 140.07878303527832, "total_time_s": 66.08635759353638, "loss": 1.7346234560012816, "perplexity": 5.666793604896402, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 99168.20409964651, "forward_time_ms": 22.14503288269043, "backward_time_ms": 60.46867370605469, "grad_norm_total": 2.9262582633915986, "grad_norm_embedding": 1.671875, "grad_norm_layers": 2.4012285031174314, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 500, "step_time_ms": 143.0497169494629, "total_time_s": 79.57314419746399, "loss": 1.749608782529831, "perplexity": 5.7523518152217346, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 102950.19843007842, "forward_time_ms": 23.413658142089844, "backward_time_ms": 68.35699081420898, "grad_norm_total": 1.9615522290631136, "grad_norm_embedding": 0.9375, "grad_norm_layers": 1.722940239822877, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 600, "step_time_ms": 144.33026313781738, "total_time_s": 93.22691941261292, "loss": 1.6662048000097274, "perplexity": 5.29204526667574, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 105446.69965965714, "forward_time_ms": 23.446083068847656, "backward_time_ms": 65.42325019836426, "grad_norm_total": 1.9073870825099362, "grad_norm_embedding": 0.953125, "grad_norm_layers": 1.6520672378390382, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 700, "step_time_ms": 143.83721351623535, "total_time_s": 106.98010349273682, "loss": 1.6757543337345124, "perplexity": 5.342823901676735, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 107205.57483218268, "forward_time_ms": 23.21600914001465, "backward_time_ms": 64.4843578338623, "grad_norm_total": 2.7552569133243487, "grad_norm_embedding": 1.28125, "grad_norm_layers": 2.4391462790028395, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 800, "step_time_ms": 145.4930305480957, "total_time_s": 120.82957983016968, "loss": 1.640279928445816, "perplexity": 5.15661279282238, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 108477.27723875681, "forward_time_ms": 23.46348762512207, "backward_time_ms": 64.61739540100098, "grad_norm_total": 1.56611741004677, "grad_norm_embedding": 0.73828125, "grad_norm_layers": 1.3811242567674589, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 900, "step_time_ms": 145.6592082977295, "total_time_s": 134.7481153011322, "loss": 1.7709407961368562, "perplexity": 5.876379236498441, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 109431.33049607459, "forward_time_ms": 23.311853408813477, "backward_time_ms": 64.28408622741699, "grad_norm_total": 1.473924579997502, "grad_norm_embedding": 0.6796875, "grad_norm_layers": 1.3078148212176148, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1000, "step_time_ms": 144.38700675964355, "total_time_s": 148.6758575439453, "loss": 1.5679743838310243, "perplexity": 4.796921623949617, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 110199.94187935119, "forward_time_ms": 23.25129508972168, "backward_time_ms": 64.47267532348633, "grad_norm_total": 1.3322348047521178, "grad_norm_embedding": 0.625, "grad_norm_layers": 1.176490483835612, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
