{"type": "header", "timestamp": "2026-01-04T17:47:11.485876", "config": {"level": "3", "params": "50m", "num_params": 49698912, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 500, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 10, "step_time_ms": 2348.076105117798, "total_time_s": 23.78000783920288, "loss": 3.853950595855713, "perplexity": 47.179081031068286, "lr": 0.0003, "tokens_seen": 163840, "tokens_per_sec": 6890.079745259219, "forward_time_ms": 1324.4869709014893, "backward_time_ms": 965.1901721954346, "grad_norm_total": 2.2860731003930224, "grad_norm_embedding": 1.765625, "grad_norm_layers": 1.4509758500008727, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 20, "step_time_ms": 2372.344732284546, "total_time_s": 47.39626431465149, "loss": 3.3026792287826536, "perplexity": 27.185377281070945, "lr": 0.0003, "tokens_seen": 327680, "tokens_per_sec": 6913.731257849344, "forward_time_ms": 1333.9710235595703, "backward_time_ms": 978.5828590393066, "grad_norm_total": 10.26349041757507, "grad_norm_embedding": 6.9375, "grad_norm_layers": 7.563388906701131, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 30, "step_time_ms": 2404.9935340881348, "total_time_s": 71.33374381065369, "loss": 4.196045708656311, "perplexity": 66.42315454055439, "lr": 0.0003, "tokens_seen": 491520, "tokens_per_sec": 6890.488047599437, "forward_time_ms": 1340.7998085021973, "backward_time_ms": 1002.9752254486084, "grad_norm_total": 2.714958737188608, "grad_norm_embedding": 1.96875, "grad_norm_layers": 1.8685163770420465, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 40, "step_time_ms": 2403.7258625030518, "total_time_s": 95.30884575843811, "loss": 3.4522401809692385, "perplexity": 31.57103798813071, "lr": 0.0003, "tokens_seen": 655360, "tokens_per_sec": 6876.219765797194, "forward_time_ms": 1339.7681713104248, "backward_time_ms": 1001.7111301422119, "grad_norm_total": 2.3175821054355477, "grad_norm_embedding": 1.71875, "grad_norm_layers": 1.5536435782956302, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 50, "step_time_ms": 2423.82550239563, "total_time_s": 119.4230637550354, "loss": 3.025371026992798, "perplexity": 20.601647060504963, "lr": 0.0003, "tokens_seen": 819200, "tokens_per_sec": 6859.679301801032, "forward_time_ms": 1341.186761856079, "backward_time_ms": 1020.637035369873, "grad_norm_total": 2.326651871427294, "grad_norm_embedding": 1.75, "grad_norm_layers": 1.532213884854917, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 60, "step_time_ms": 2423.9542484283447, "total_time_s": 143.61720252037048, "loss": 3.08676495552063, "perplexity": 21.90609602776993, "lr": 0.0003, "tokens_seen": 983040, "tokens_per_sec": 6844.891403614686, "forward_time_ms": 1341.6690826416016, "backward_time_ms": 1020.7476615905762, "grad_norm_total": 1.556434792888638, "grad_norm_embedding": 1.15625, "grad_norm_layers": 1.0413327876845988, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 70, "step_time_ms": 2423.938751220703, "total_time_s": 167.79076266288757, "loss": 2.686086893081665, "perplexity": 14.674141939204915, "lr": 0.0003, "tokens_seen": 1146880, "tokens_per_sec": 6835.209535509333, "forward_time_ms": 1343.2164192199707, "backward_time_ms": 1019.5097923278809, "grad_norm_total": 1.6638406849298777, "grad_norm_embedding": 1.1875, "grad_norm_layers": 1.1651616676493197, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 80, "step_time_ms": 2444.1778659820557, "total_time_s": 192.03350186347961, "loss": 2.9650476217269897, "perplexity": 19.395626872726442, "lr": 0.0003, "tokens_seen": 1310720, "tokens_per_sec": 6825.496907966514, "forward_time_ms": 1364.1443252563477, "backward_time_ms": 1018.4431076049805, "grad_norm_total": 2.6038393942902602, "grad_norm_embedding": 2.046875, "grad_norm_layers": 1.608507609237852, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 90, "step_time_ms": 2428.9355278015137, "total_time_s": 216.28632259368896, "loss": 2.8555761098861696, "perplexity": 17.384449676562454, "lr": 0.0003, "tokens_seen": 1474560, "tokens_per_sec": 6817.648527056588, "forward_time_ms": 1344.7558879852295, "backward_time_ms": 1022.8774547576904, "grad_norm_total": 3.7342415441873396, "grad_norm_embedding": 2.640625, "grad_norm_layers": 2.6398406883127725, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 100, "step_time_ms": 2435.5623722076416, "total_time_s": 240.54934549331665, "loss": 2.5870518684387207, "perplexity": 13.290531553663165, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 6811.094467721324, "forward_time_ms": 1345.3214168548584, "backward_time_ms": 1028.315782546997, "grad_norm_total": 1.4278940694169393, "grad_norm_embedding": 1.0390625, "grad_norm_layers": 0.9788293508084998, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 110, "step_time_ms": 2436.6142749786377, "total_time_s": 264.8220376968384, "loss": 2.5532570600509645, "perplexity": 12.848885294271883, "lr": 0.0003, "tokens_seen": 1802240, "tokens_per_sec": 6805.492442046155, "forward_time_ms": 1345.4134464263916, "backward_time_ms": 1029.4170379638672, "grad_norm_total": 2.3140784705934117, "grad_norm_embedding": 1.640625, "grad_norm_layers": 1.6317087555829008, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 120, "step_time_ms": 2436.164140701294, "total_time_s": 289.09758591651917, "loss": 2.6551369428634644, "perplexity": 14.226934203043367, "lr": 0.0003, "tokens_seen": 1966080, "tokens_per_sec": 6800.7640928421315, "forward_time_ms": 1347.0287322998047, "backward_time_ms": 1028.4216403961182, "grad_norm_total": 1.720977222579246, "grad_norm_embedding": 1.1796875, "grad_norm_layers": 1.2527224610407517, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 130, "step_time_ms": 2435.1675510406494, "total_time_s": 313.32629346847534, "loss": 2.595713496208191, "perplexity": 13.406149186450222, "lr": 0.0003, "tokens_seen": 2129920, "tokens_per_sec": 6797.783634526612, "forward_time_ms": 1344.9592590332031, "backward_time_ms": 1027.4572372436523, "grad_norm_total": 1.2044453898640977, "grad_norm_embedding": 0.8515625, "grad_norm_layers": 0.851363154223673, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 140, "step_time_ms": 2429.532527923584, "total_time_s": 337.58358335494995, "loss": 2.4068573474884034, "perplexity": 11.099025897532922, "lr": 0.0003, "tokens_seen": 2293760, "tokens_per_sec": 6794.654978821912, "forward_time_ms": 1342.4930572509766, "backward_time_ms": 1026.4496803283691, "grad_norm_total": 1.8441793923726109, "grad_norm_embedding": 1.2578125, "grad_norm_layers": 1.348419269226355, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 150, "step_time_ms": 2425.733804702759, "total_time_s": 361.7780556678772, "loss": 2.445402979850769, "perplexity": 11.535197114360138, "lr": 0.0003, "tokens_seen": 2457600, "tokens_per_sec": 6793.127128221283, "forward_time_ms": 1344.7368144989014, "backward_time_ms": 1020.0018882751465, "grad_norm_total": 2.279877833371823, "grad_norm_embedding": 1.5859375, "grad_norm_layers": 1.6375963258484805, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 160, "step_time_ms": 2424.8669147491455, "total_time_s": 385.967636346817, "loss": 2.3443136692047117, "perplexity": 10.426114507914635, "lr": 0.0003, "tokens_seen": 2621440, "tokens_per_sec": 6791.875586499588, "forward_time_ms": 1343.430995941162, "backward_time_ms": 1020.1132297515869, "grad_norm_total": 1.9332696864222367, "grad_norm_embedding": 1.3203125, "grad_norm_layers": 1.4120065023128476, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 170, "step_time_ms": 2425.076723098755, "total_time_s": 410.1801974773407, "loss": 2.4499903202056883, "perplexity": 11.588234546953638, "lr": 0.0003, "tokens_seen": 2785280, "tokens_per_sec": 6790.391070512414, "forward_time_ms": 1344.7577953338623, "backward_time_ms": 1018.9380645751953, "grad_norm_total": 4.549467987375894, "grad_norm_embedding": 3.21875, "grad_norm_layers": 3.2144980837194725, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 180, "step_time_ms": 2405.88641166687, "total_time_s": 434.37198758125305, "loss": 2.475741147994995, "perplexity": 11.890516480622681, "lr": 0.0003, "tokens_seen": 2949120, "tokens_per_sec": 6789.397214688192, "forward_time_ms": 1342.101812362671, "backward_time_ms": 1003.1378269195557, "grad_norm_total": 1.457566031396341, "grad_norm_embedding": 1.0, "grad_norm_layers": 1.0601127377646888, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 190, "step_time_ms": 2424.293041229248, "total_time_s": 458.58554315567017, "loss": 2.179629755020142, "perplexity": 8.84303156449526, "lr": 0.0003, "tokens_seen": 3112960, "tokens_per_sec": 6788.1860487162485, "forward_time_ms": 1343.4433937072754, "backward_time_ms": 1019.6094512939453, "grad_norm_total": 1.60210893957637, "grad_norm_embedding": 1.078125, "grad_norm_layers": 1.184810105576587, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 200, "step_time_ms": 2423.7475395202637, "total_time_s": 482.7971625328064, "loss": 1.9726292371749878, "perplexity": 7.189554704317952, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 6787.1246701663285, "forward_time_ms": 1343.7519073486328, "backward_time_ms": 1018.474817276001, "grad_norm_total": 2.0614073522235428, "grad_norm_embedding": 1.359375, "grad_norm_layers": 1.5494758996191096, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 210, "step_time_ms": 2422.8599071502686, "total_time_s": 506.9712588787079, "loss": 2.3969449520111086, "perplexity": 10.989551436869839, "lr": 0.0003, "tokens_seen": 3440640, "tokens_per_sec": 6786.6651849684995, "forward_time_ms": 1344.0909385681152, "backward_time_ms": 1017.11106300354, "grad_norm_total": 2.3162464706708725, "grad_norm_embedding": 1.5859375, "grad_norm_layers": 1.6879507313889253, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 220, "step_time_ms": 2423.691511154175, "total_time_s": 531.1627376079559, "loss": 2.2945375442504883, "perplexity": 9.919847460873576, "lr": 0.0003, "tokens_seen": 3604480, "tokens_per_sec": 6786.025599236749, "forward_time_ms": 1342.895269393921, "backward_time_ms": 1019.3507671356201, "grad_norm_total": 1.5999766497711418, "grad_norm_embedding": 1.0625, "grad_norm_layers": 1.1960553401229308, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 230, "step_time_ms": 2424.8299598693848, "total_time_s": 555.3561608791351, "loss": 2.2270913124084473, "perplexity": 9.272854976888434, "lr": 0.0003, "tokens_seen": 3768320, "tokens_per_sec": 6785.41875974831, "forward_time_ms": 1344.2060947418213, "backward_time_ms": 1019.6056365966797, "grad_norm_total": 2.43238428418218, "grad_norm_embedding": 1.6015625, "grad_norm_layers": 1.8305908729584859, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 240, "step_time_ms": 2423.1698513031006, "total_time_s": 579.5482683181763, "loss": 2.2500001907348635, "perplexity": 9.487737646000697, "lr": 0.0003, "tokens_seen": 3932160, "tokens_per_sec": 6784.878425652283, "forward_time_ms": 1343.8167572021484, "backward_time_ms": 1017.7576541900635, "grad_norm_total": 2.3256127066163663, "grad_norm_embedding": 1.5625, "grad_norm_layers": 1.722336720277331, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 250, "step_time_ms": 2425.0500202178955, "total_time_s": 603.7420451641083, "loss": 2.213000702857971, "perplexity": 9.143111030300913, "lr": 0.0003, "tokens_seen": 4096000, "tokens_per_sec": 6784.360866525876, "forward_time_ms": 1343.1854248046875, "backward_time_ms": 1020.5228328704834, "grad_norm_total": 1.7723347632763078, "grad_norm_embedding": 1.1953125, "grad_norm_layers": 1.308337085466047, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 260, "step_time_ms": 2423.5999584198, "total_time_s": 627.9324533939362, "loss": 2.360966348648071, "perplexity": 10.601190950717461, "lr": 0.0003, "tokens_seen": 4259840, "tokens_per_sec": 6783.920958135043, "forward_time_ms": 1343.045949935913, "backward_time_ms": 1019.3326473236084, "grad_norm_total": 1.3602744775397706, "grad_norm_embedding": 0.90234375, "grad_norm_layers": 1.0177355677273177, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 270, "step_time_ms": 2423.834800720215, "total_time_s": 652.1261537075043, "loss": 2.1699262142181395, "perplexity": 8.757637827746091, "lr": 0.0003, "tokens_seen": 4423680, "tokens_per_sec": 6783.479161387385, "forward_time_ms": 1343.2989120483398, "backward_time_ms": 1019.2966461181641, "grad_norm_total": 1.4967403732595206, "grad_norm_embedding": 1.0078125, "grad_norm_layers": 1.1064291125438992, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 280, "step_time_ms": 2425.233840942383, "total_time_s": 676.3196523189545, "loss": 2.0825247526168824, "perplexity": 8.024703751364694, "lr": 0.0003, "tokens_seen": 4587520, "tokens_per_sec": 6783.071290138434, "forward_time_ms": 1343.2776927947998, "backward_time_ms": 1020.7164287567139, "grad_norm_total": 2.8660808197799508, "grad_norm_embedding": 1.9609375, "grad_norm_layers": 2.090010817536726, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 290, "step_time_ms": 2424.940824508667, "total_time_s": 700.5127439498901, "loss": 1.9263904094696045, "perplexity": 6.864686758910596, "lr": 0.0003, "tokens_seen": 4751360, "tokens_per_sec": 6782.694853914799, "forward_time_ms": 1343.6543941497803, "backward_time_ms": 1019.9956893920898, "grad_norm_total": 1.4640509791910723, "grad_norm_embedding": 0.97265625, "grad_norm_layers": 1.0940136121359136, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 300, "step_time_ms": 2424.406051635742, "total_time_s": 724.7044620513916, "loss": 1.8587005615234375, "perplexity": 6.415394941726063, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 6782.357200039304, "forward_time_ms": 1343.4488773345947, "backward_time_ms": 1018.9204216003418, "grad_norm_total": 1.8757602240123006, "grad_norm_embedding": 1.2421875, "grad_norm_layers": 1.4053447361839508, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 310, "step_time_ms": 2425.0714778900146, "total_time_s": 748.9175832271576, "loss": 1.8238254070281983, "perplexity": 6.195513536895981, "lr": 0.0003, "tokens_seen": 5079040, "tokens_per_sec": 6781.846366415871, "forward_time_ms": 1342.933177947998, "backward_time_ms": 1020.7998752593994, "grad_norm_total": 1.6674075630832546, "grad_norm_embedding": 1.1015625, "grad_norm_layers": 1.2515070036864928, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 320, "step_time_ms": 2425.006628036499, "total_time_s": 773.11097240448, "loss": 2.0134556531906127, "perplexity": 7.489152596844859, "lr": 0.0003, "tokens_seen": 5242880, "tokens_per_sec": 6781.541391907654, "forward_time_ms": 1342.7259922027588, "backward_time_ms": 1021.3162899017334, "grad_norm_total": 2.3406610250187523, "grad_norm_embedding": 1.65625, "grad_norm_layers": 1.653712433228853, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 330, "step_time_ms": 2423.4461784362793, "total_time_s": 797.3012857437134, "loss": 2.1675132393836973, "perplexity": 8.736531343007789, "lr": 0.0003, "tokens_seen": 5406720, "tokens_per_sec": 6781.280970925256, "forward_time_ms": 1342.9765701293945, "backward_time_ms": 1019.36936378479, "grad_norm_total": 1.8382900211483262, "grad_norm_embedding": 1.203125, "grad_norm_layers": 1.3897892591763616, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 340, "step_time_ms": 2424.262523651123, "total_time_s": 821.4945521354675, "loss": 2.1473047852516176, "perplexity": 8.561751513207994, "lr": 0.0003, "tokens_seen": 5570560, "tokens_per_sec": 6781.014732727491, "forward_time_ms": 1342.6411151885986, "backward_time_ms": 1019.9317932128906, "grad_norm_total": 3.4065554423377646, "grad_norm_embedding": 2.28125, "grad_norm_layers": 2.52969430025128, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 350, "step_time_ms": 2424.6182441711426, "total_time_s": 845.6874186992645, "loss": 2.197133409976959, "perplexity": 8.999179531167213, "lr": 0.0003, "tokens_seen": 5734400, "tokens_per_sec": 6780.760565413407, "forward_time_ms": 1342.3066139221191, "backward_time_ms": 1021.3823318481445, "grad_norm_total": 1.8455358288144559, "grad_norm_embedding": 1.2265625, "grad_norm_layers": 1.3788398329541245, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 360, "step_time_ms": 2423.5548973083496, "total_time_s": 869.8803663253784, "loss": 2.1648168325424195, "perplexity": 8.713005831554211, "lr": 0.0003, "tokens_seen": 5898240, "tokens_per_sec": 6780.523394250368, "forward_time_ms": 1342.2739505767822, "backward_time_ms": 1019.6588039398193, "grad_norm_total": 3.9901130073610465, "grad_norm_embedding": 2.625, "grad_norm_layers": 3.0048933163813554, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 370, "step_time_ms": 2423.9773750305176, "total_time_s": 894.0725111961365, "loss": 1.9871229171752929, "perplexity": 7.294516614303872, "lr": 0.0003, "tokens_seen": 6062080, "tokens_per_sec": 6780.304632715642, "forward_time_ms": 1342.341423034668, "backward_time_ms": 1020.6036567687988, "grad_norm_total": 1.7126230686555541, "grad_norm_embedding": 1.1171875, "grad_norm_layers": 1.2979615398016922, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 380, "step_time_ms": 2425.7006645202637, "total_time_s": 918.2669994831085, "loss": 2.4052401781082153, "perplexity": 11.081091398171704, "lr": 0.0003, "tokens_seen": 6225920, "tokens_per_sec": 6780.080302880781, "forward_time_ms": 1342.681884765625, "backward_time_ms": 1022.4058628082275, "grad_norm_total": 2.072486512703823, "grad_norm_embedding": 1.3671875, "grad_norm_layers": 1.5573330459355321, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 390, "step_time_ms": 2424.490213394165, "total_time_s": 942.4586288928986, "loss": 2.053093123435974, "perplexity": 7.791965380966911, "lr": 0.0003, "tokens_seen": 6389760, "tokens_per_sec": 6779.888209738864, "forward_time_ms": 1342.9327011108398, "backward_time_ms": 1019.9668407440186, "grad_norm_total": 1.6495605352931768, "grad_norm_embedding": 1.109375, "grad_norm_layers": 1.2206732032208119, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 400, "step_time_ms": 2424.5526790618896, "total_time_s": 966.6524305343628, "loss": 2.1546504497528076, "perplexity": 8.624874824863534, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 6779.690579787551, "forward_time_ms": 1342.8478240966797, "backward_time_ms": 1020.103931427002, "grad_norm_total": 4.360316039535534, "grad_norm_embedding": 2.953125, "grad_norm_layers": 3.2075580502277754, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 410, "step_time_ms": 2424.7546195983887, "total_time_s": 990.8441400527954, "loss": 1.9461843609809875, "perplexity": 7.001919746676406, "lr": 0.0003, "tokens_seen": 6717440, "tokens_per_sec": 6779.519297338235, "forward_time_ms": 1342.1356678009033, "backward_time_ms": 1021.1567878723145, "grad_norm_total": 3.4348802739853337, "grad_norm_embedding": 2.328125, "grad_norm_layers": 2.5253738661281524, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 420, "step_time_ms": 2424.171209335327, "total_time_s": 1015.0360562801361, "loss": 2.083136534690857, "perplexity": 8.029614623307276, "lr": 0.0003, "tokens_seen": 6881280, "tokens_per_sec": 6779.34927308024, "forward_time_ms": 1342.6575660705566, "backward_time_ms": 1020.3840732574463, "grad_norm_total": 2.4017409476485114, "grad_norm_embedding": 1.5703125, "grad_norm_layers": 1.8171453532206678, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 430, "step_time_ms": 2424.3555068969727, "total_time_s": 1039.230253458023, "loss": 2.2192712783813477, "perplexity": 9.200623728944851, "lr": 0.0003, "tokens_seen": 7045120, "tokens_per_sec": 6779.175265487915, "forward_time_ms": 1342.8232669830322, "backward_time_ms": 1020.3628540039062, "grad_norm_total": 2.969356001824293, "grad_norm_embedding": 1.9140625, "grad_norm_layers": 2.270053176328999, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 440, "step_time_ms": 2424.5517253875732, "total_time_s": 1063.422383069992, "loss": 2.26023645401001, "perplexity": 9.585355394544907, "lr": 0.0003, "tokens_seen": 7208960, "tokens_per_sec": 6779.022275252387, "forward_time_ms": 1342.3993587493896, "backward_time_ms": 1020.6682682037354, "grad_norm_total": 2.0436254002427408, "grad_norm_embedding": 1.34375, "grad_norm_layers": 1.5395554944143794, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 450, "step_time_ms": 2423.8369464874268, "total_time_s": 1087.615082502365, "loss": 2.0352290391922, "perplexity": 7.654004991853856, "lr": 0.0003, "tokens_seen": 7372800, "tokens_per_sec": 6778.872517171603, "forward_time_ms": 1343.0347442626953, "backward_time_ms": 1019.5376873016357, "grad_norm_total": 1.6114435892928358, "grad_norm_embedding": 1.046875, "grad_norm_layers": 1.22496993686531, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 460, "step_time_ms": 2424.105167388916, "total_time_s": 1111.8072836399078, "loss": 2.044656205177307, "perplexity": 7.7265017499419155, "lr": 0.0003, "tokens_seen": 7536640, "tokens_per_sec": 6778.732382947739, "forward_time_ms": 1342.348575592041, "backward_time_ms": 1020.7083225250244, "grad_norm_total": 1.8794092752969014, "grad_norm_embedding": 1.2421875, "grad_norm_layers": 1.4102531934573506, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
{"type": "step", "step": 470, "step_time_ms": 2423.9416122436523, "total_time_s": 1136.000067949295, "loss": 2.0156115889549255, "perplexity": 7.505316146299205, "lr": 0.0003, "tokens_seen": 7700480, "tokens_per_sec": 6778.59464073814, "forward_time_ms": 1342.3285484313965, "backward_time_ms": 1019.5212364196777, "grad_norm_total": 2.577266751291463, "grad_norm_embedding": 1.734375, "grad_norm_layers": 1.9061623676766823, "grad_norm_head": 0, "memory_allocated_mb": 321.16845703125, "memory_reserved_mb": 6074.0, "memory_max_allocated_mb": 5784.7197265625}
