{"type": "header", "timestamp": "2026-01-04T20:22:23.111301", "config": {"level": "3", "params": "50m", "num_params": 49899744, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 198.47583770751953, "total_time_s": 19.880764961242676, "loss": 3.020487208366394, "perplexity": 20.501277645364084, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 82414.78889480566, "forward_time_ms": 16.449451446533203, "backward_time_ms": 107.4666976928711, "grad_norm_total": 1.8418357455351706, "grad_norm_embedding": 1.3203125, "grad_norm_layers": 1.2836282334675757, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 200, "step_time_ms": 199.41163063049316, "total_time_s": 38.8396782875061, "loss": 2.2648970234394072, "perplexity": 9.63013287208752, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 84368.8967691359, "forward_time_ms": 16.081809997558594, "backward_time_ms": 108.04605484008789, "grad_norm_total": 2.288640502995902, "grad_norm_embedding": 1.546875, "grad_norm_layers": 1.6865473433257072, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 300, "step_time_ms": 198.35758209228516, "total_time_s": 57.832457304000854, "loss": 2.0468125104904176, "perplexity": 7.7431804224096, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 84991.34022840863, "forward_time_ms": 14.349222183227539, "backward_time_ms": 109.80558395385742, "grad_norm_total": 2.5653421716946125, "grad_norm_embedding": 1.7109375, "grad_norm_layers": 1.911350424142295, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 400, "step_time_ms": 200.5026340484619, "total_time_s": 76.87347102165222, "loss": 1.9919655287265778, "perplexity": 7.329926794394929, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 85252.52462551478, "forward_time_ms": 16.16644859313965, "backward_time_ms": 108.37769508361816, "grad_norm_total": 4.791170214967616, "grad_norm_embedding": 3.234375, "grad_norm_layers": 3.534276081377735, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 500, "step_time_ms": 199.91517066955566, "total_time_s": 95.93203449249268, "loss": 2.006961572766304, "perplexity": 7.4406750165941125, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 85394.35657206012, "forward_time_ms": 16.158342361450195, "backward_time_ms": 108.37101936340332, "grad_norm_total": 3.761477783675432, "grad_norm_embedding": 2.4375, "grad_norm_layers": 2.8647910142822357, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 600, "step_time_ms": 198.0452537536621, "total_time_s": 114.9516932964325, "loss": 1.901256068944931, "perplexity": 6.694297663064816, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 85518.12163391555, "forward_time_ms": 13.613700866699219, "backward_time_ms": 110.67986488342285, "grad_norm_total": 3.8887922725881827, "grad_norm_embedding": 2.5625, "grad_norm_layers": 2.925053381636391, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 700, "step_time_ms": 199.47576522827148, "total_time_s": 133.97105050086975, "loss": 1.9268495893478395, "perplexity": 6.867839608747879, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 85607.01706543071, "forward_time_ms": 13.626337051391602, "backward_time_ms": 111.02175712585449, "grad_norm_total": 4.221266486999071, "grad_norm_embedding": 2.75, "grad_norm_layers": 3.2025301718988683, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 800, "step_time_ms": 198.55928421020508, "total_time_s": 152.9900016784668, "loss": 1.8804729652404786, "perplexity": 6.556605175306648, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 85673.91028574832, "forward_time_ms": 13.610124588012695, "backward_time_ms": 111.15741729736328, "grad_norm_total": 3.2361680660231005, "grad_norm_embedding": 2.140625, "grad_norm_layers": 2.426988388049782, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 900, "step_time_ms": 197.81827926635742, "total_time_s": 172.01237678527832, "loss": 1.989276715517044, "perplexity": 7.310244463319278, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 85724.35595875017, "forward_time_ms": 13.569116592407227, "backward_time_ms": 110.54491996765137, "grad_norm_total": 2.866131852791772, "grad_norm_embedding": 1.875, "grad_norm_layers": 2.167704924471614, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1000, "step_time_ms": 197.03984260559082, "total_time_s": 191.03003001213074, "loss": 1.8036273622512817, "perplexity": 6.0716315753208105, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 85766.89438965617, "forward_time_ms": 13.620138168334961, "backward_time_ms": 110.52060127258301, "grad_norm_total": 2.8997116388348885, "grad_norm_embedding": 1.9140625, "grad_norm_layers": 2.1781692629925486, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1100, "step_time_ms": 198.46749305725098, "total_time_s": 210.50010180473328, "loss": 1.9854775595664977, "perplexity": 7.2825243943406734, "lr": 0.0003, "tokens_seen": 18022400, "tokens_per_sec": 85617.2907496637, "forward_time_ms": 13.850688934326172, "backward_time_ms": 110.69869995117188, "grad_norm_total": 4.289221661814005, "grad_norm_embedding": 2.921875, "grad_norm_layers": 3.1399953810030663, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1200, "step_time_ms": 198.7924575805664, "total_time_s": 229.5343735218048, "loss": 1.7927794742584229, "perplexity": 6.006123152474488, "lr": 0.0003, "tokens_seen": 19660800, "tokens_per_sec": 85655.36250870014, "forward_time_ms": 13.985872268676758, "backward_time_ms": 110.81194877624512, "grad_norm_total": 2.0414504845425987, "grad_norm_embedding": 1.3359375, "grad_norm_layers": 1.5435474002299154, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1300, "step_time_ms": 198.6367702484131, "total_time_s": 248.56205368041992, "loss": 1.7905963563919067, "perplexity": 5.993025379904481, "lr": 0.0003, "tokens_seen": 21299200, "tokens_per_sec": 85689.86731683981, "forward_time_ms": 13.629674911499023, "backward_time_ms": 110.95356941223145, "grad_norm_total": 3.114446711270376, "grad_norm_embedding": 2.03125, "grad_norm_layers": 2.36083350488614, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1400, "step_time_ms": 198.61078262329102, "total_time_s": 267.58633732795715, "loss": 1.8359277331829071, "perplexity": 6.270949215277346, "lr": 0.0003, "tokens_seen": 22937600, "tokens_per_sec": 85720.55496131533, "forward_time_ms": 13.628959655761719, "backward_time_ms": 110.95261573791504, "grad_norm_total": 7.308404088444977, "grad_norm_embedding": 4.75, "grad_norm_layers": 5.553960131878801, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1500, "step_time_ms": 198.4117031097412, "total_time_s": 286.61037588119507, "loss": 1.8168215346336365, "perplexity": 6.152272554588537, "lr": 0.0003, "tokens_seen": 24576000, "tokens_per_sec": 85747.25051963808, "forward_time_ms": 13.609647750854492, "backward_time_ms": 111.06419563293457, "grad_norm_total": 5.4617648568855035, "grad_norm_embedding": 3.515625, "grad_norm_layers": 4.1797411103995, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1600, "step_time_ms": 198.24934005737305, "total_time_s": 305.6325385570526, "loss": 1.8493070387840271, "perplexity": 6.355413940956983, "lr": 0.0003, "tokens_seen": 26214400, "tokens_per_sec": 85771.18862022589, "forward_time_ms": 13.694047927856445, "backward_time_ms": 110.72421073913574, "grad_norm_total": 2.7819656023535737, "grad_norm_embedding": 1.8125, "grad_norm_layers": 2.1104115323783152, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1700, "step_time_ms": 197.97229766845703, "total_time_s": 324.65568256378174, "loss": 1.8193748879432678, "perplexity": 6.168001552376248, "lr": 0.0003, "tokens_seen": 27852800, "tokens_per_sec": 85791.96988905115, "forward_time_ms": 13.646364212036133, "backward_time_ms": 110.89634895324707, "grad_norm_total": 2.968368929151073, "grad_norm_embedding": 1.9453125, "grad_norm_layers": 2.242030599073981, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1800, "step_time_ms": 198.46868515014648, "total_time_s": 343.6697964668274, "loss": 1.8713485658168794, "perplexity": 6.497052196578071, "lr": 0.0003, "tokens_seen": 29491200, "tokens_per_sec": 85812.75179542572, "forward_time_ms": 13.625860214233398, "backward_time_ms": 110.78381538391113, "grad_norm_total": 2.3857777778867146, "grad_norm_embedding": 1.546875, "grad_norm_layers": 1.816296158575553, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 1900, "step_time_ms": 198.50730895996094, "total_time_s": 362.6920187473297, "loss": 1.7973972141742707, "perplexity": 6.033922001625406, "lr": 0.0003, "tokens_seen": 31129600, "tokens_per_sec": 85829.43349847708, "forward_time_ms": 14.018774032592773, "backward_time_ms": 110.72039604187012, "grad_norm_total": 2.037949856479337, "grad_norm_embedding": 1.3203125, "grad_norm_layers": 1.5523207174753226, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
{"type": "step", "step": 2000, "step_time_ms": 200.39868354797363, "total_time_s": 381.72619819641113, "loss": 1.793553273677826, "perplexity": 6.010772485676413, "lr": 0.0003, "tokens_seen": 32768000, "tokens_per_sec": 85841.7833708828, "forward_time_ms": 13.596057891845703, "backward_time_ms": 111.21940612792969, "grad_norm_total": 3.5425856633902466, "grad_norm_embedding": 2.265625, "grad_norm_layers": 2.723326462287647, "grad_norm_head": 0, "memory_allocated_mb": 323.09033203125, "memory_reserved_mb": 11396.0, "memory_max_allocated_mb": 10891.2470703125}
