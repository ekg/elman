{"type": "header", "timestamp": "2026-01-04T20:03:52.782942", "config": {"level": "3", "params": "50m", "num_params": 48728472, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 1493.3114051818848, "total_time_s": 148.2901406288147, "loss": 3.282650146484375, "perplexity": 26.646295797458386, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 11048.667134405712, "forward_time_ms": 748.4962940216064, "backward_time_ms": 708.3561420440674, "grad_norm_total": 1.0350116158322789, "grad_norm_embedding": 0.7890625, "grad_norm_layers": 0.6691397331757818, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
{"type": "step", "step": 200, "step_time_ms": 1491.445779800415, "total_time_s": 296.7606120109558, "loss": 2.483126486539841, "perplexity": 11.978657043631639, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 11041.922918342547, "forward_time_ms": 748.3251094818115, "backward_time_ms": 707.427978515625, "grad_norm_total": 2.1289631355985374, "grad_norm_embedding": 1.40625, "grad_norm_layers": 1.5982181966135776, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
{"type": "step", "step": 300, "step_time_ms": 1492.361068725586, "total_time_s": 445.15848898887634, "loss": 2.237530357837677, "perplexity": 9.370161742469394, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 11041.479148375796, "forward_time_ms": 748.1889724731445, "backward_time_ms": 707.7007293701172, "grad_norm_total": 1.942173483972352, "grad_norm_embedding": 1.265625, "grad_norm_layers": 1.4730137726519699, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
{"type": "step", "step": 400, "step_time_ms": 1492.051362991333, "total_time_s": 593.5979692935944, "loss": 2.16412859916687, "perplexity": 8.70701131319, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 11040.481953738563, "forward_time_ms": 747.5378513336182, "backward_time_ms": 707.5581550598145, "grad_norm_total": 4.2952085082108, "grad_norm_embedding": 2.875, "grad_norm_layers": 3.1906575303154385, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
{"type": "step", "step": 500, "step_time_ms": 1491.7371273040771, "total_time_s": 741.9731552600861, "loss": 2.1543999201059343, "perplexity": 8.622714308667314, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 11040.841117474789, "forward_time_ms": 747.2987174987793, "backward_time_ms": 707.7164649963379, "grad_norm_total": 3.0200538895810456, "grad_norm_embedding": 1.9140625, "grad_norm_layers": 2.335994527243866, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
{"type": "step", "step": 600, "step_time_ms": 1491.1587238311768, "total_time_s": 890.3380937576294, "loss": 2.025775680541992, "perplexity": 7.581989866268362, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 11041.206844717322, "forward_time_ms": 747.9987144470215, "backward_time_ms": 707.4184417724609, "grad_norm_total": 3.296735532986411, "grad_norm_embedding": 2.140625, "grad_norm_layers": 2.507153138505819, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
{"type": "step", "step": 700, "step_time_ms": 1489.6926879882812, "total_time_s": 1038.6762351989746, "loss": 2.0424868524074555, "perplexity": 7.7097584096415535, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 11041.753900308448, "forward_time_ms": 747.5135326385498, "backward_time_ms": 706.3658237457275, "grad_norm_total": 3.9658266521923116, "grad_norm_embedding": 2.515625, "grad_norm_layers": 3.065783322631451, "grad_norm_head": 0, "memory_allocated_mb": 312.62548828125, "memory_reserved_mb": 8498.0, "memory_max_allocated_mb": 7986.4541015625}
