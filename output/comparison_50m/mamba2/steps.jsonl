{"type": "header", "timestamp": "2026-01-04T19:48:50.104450", "config": {"level": "mamba2", "params": "50m", "num_params": 50928750, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 145.71523666381836, "total_time_s": 26.94312834739685, "loss": 2.7318133425712587, "perplexity": 15.360716020811086, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 60811.055519916496, "forward_time_ms": 23.768901824951172, "backward_time_ms": 65.10591506958008, "grad_norm_total": 1.0023077632347293, "grad_norm_embedding": 0.6640625, "grad_norm_layers": 0.7503663116656468, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 200, "step_time_ms": 147.72796630859375, "total_time_s": 40.79050421714783, "loss": 1.9712150251865388, "perplexity": 7.179394336014217, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 80333.66164278387, "forward_time_ms": 23.704051971435547, "backward_time_ms": 64.60714340209961, "grad_norm_total": 1.275640564031747, "grad_norm_embedding": 0.6640625, "grad_norm_layers": 1.089057308850381, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 300, "step_time_ms": 150.36773681640625, "total_time_s": 54.909823179244995, "loss": 1.7746625143289565, "perplexity": 5.8982902119534995, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 89515.08472574364, "forward_time_ms": 23.70738983154297, "backward_time_ms": 64.32366371154785, "grad_norm_total": 1.1478860525245709, "grad_norm_embedding": 0.57421875, "grad_norm_layers": 0.99386825782306, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 400, "step_time_ms": 152.0073413848877, "total_time_s": 69.25467991828918, "loss": 1.7336890077590943, "perplexity": 5.6615007529067265, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 94631.29455333229, "forward_time_ms": 23.826122283935547, "backward_time_ms": 64.60094451904297, "grad_norm_total": 3.100747370643983, "grad_norm_embedding": 1.7890625, "grad_norm_layers": 2.5321612387782966, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 500, "step_time_ms": 153.57375144958496, "total_time_s": 83.78268313407898, "loss": 1.7451849865913391, "perplexity": 5.726960788393915, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 97777.51848768261, "forward_time_ms": 24.04642105102539, "backward_time_ms": 64.84174728393555, "grad_norm_total": 1.956618853688266, "grad_norm_embedding": 0.95703125, "grad_norm_layers": 1.70651820078359, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 600, "step_time_ms": 155.24983406066895, "total_time_s": 98.51039338111877, "loss": 1.6626492285728454, "perplexity": 5.273262433323595, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 99791.06653075952, "forward_time_ms": 25.031328201293945, "backward_time_ms": 66.8797492980957, "grad_norm_total": 1.8481273538431968, "grad_norm_embedding": 0.9140625, "grad_norm_layers": 1.606141546218346, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 700, "step_time_ms": 157.32860565185547, "total_time_s": 113.41325855255127, "loss": 1.6751318287849426, "perplexity": 5.339499002343778, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 101124.5257661626, "forward_time_ms": 23.735761642456055, "backward_time_ms": 64.82672691345215, "grad_norm_total": 2.487761745746684, "grad_norm_embedding": 1.1640625, "grad_norm_layers": 2.1985419064213447, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 800, "step_time_ms": 159.29889678955078, "total_time_s": 128.45214462280273, "loss": 1.635273416042328, "perplexity": 5.1308606648792034, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 102040.07476044088, "forward_time_ms": 24.898767471313477, "backward_time_ms": 65.82117080688477, "grad_norm_total": 1.5790661437315483, "grad_norm_embedding": 0.74609375, "grad_norm_layers": 1.3916345695951486, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 900, "step_time_ms": 159.38782691955566, "total_time_s": 143.5691237449646, "loss": 1.7703536105155946, "perplexity": 5.872929723956884, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 102707.71411251505, "forward_time_ms": 23.454666137695312, "backward_time_ms": 64.15772438049316, "grad_norm_total": 1.4707307275955235, "grad_norm_embedding": 0.6875, "grad_norm_layers": 1.3001158409207698, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1000, "step_time_ms": 156.6784381866455, "total_time_s": 158.73680901527405, "loss": 1.5642436957359314, "perplexity": 4.779059145938629, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 103215.27885177691, "forward_time_ms": 23.42963218688965, "backward_time_ms": 64.20707702636719, "grad_norm_total": 1.3332170386375004, "grad_norm_embedding": 0.625, "grad_norm_layers": 1.1776007562867736, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1100, "step_time_ms": 159.99960899353027, "total_time_s": 174.18789148330688, "loss": 1.7456584364175796, "perplexity": 5.729672858948072, "lr": 0.0003, "tokens_seen": 18022400, "tokens_per_sec": 103465.65542352988, "forward_time_ms": 24.423837661743164, "backward_time_ms": 66.44153594970703, "grad_norm_total": 1.2830735712500225, "grad_norm_embedding": 0.65625, "grad_norm_layers": 1.10243912414933, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1200, "step_time_ms": 160.50362586975098, "total_time_s": 189.3783519268036, "loss": 1.5635239100456237, "perplexity": 4.775620485250089, "lr": 0.0003, "tokens_seen": 19660800, "tokens_per_sec": 103817.9178725202, "forward_time_ms": 24.50704574584961, "backward_time_ms": 64.94140625, "grad_norm_total": 1.0880381605985447, "grad_norm_embedding": 0.55859375, "grad_norm_layers": 0.9336201532717556, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1300, "step_time_ms": 159.78455543518066, "total_time_s": 204.54731917381287, "loss": 1.562814673781395, "perplexity": 4.772234642840795, "lr": 0.0003, "tokens_seen": 21299200, "tokens_per_sec": 104128.75032516879, "forward_time_ms": 23.829221725463867, "backward_time_ms": 64.31269645690918, "grad_norm_total": 1.3698918596139498, "grad_norm_embedding": 0.6328125, "grad_norm_layers": 1.2149088048376786, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1400, "step_time_ms": 160.90869903564453, "total_time_s": 219.74263763427734, "loss": 1.5894950568675994, "perplexity": 4.9012734390255055, "lr": 0.0003, "tokens_seen": 22937600, "tokens_per_sec": 104384.19850550283, "forward_time_ms": 24.337291717529297, "backward_time_ms": 64.88156318664551, "grad_norm_total": 4.062353821705791, "grad_norm_embedding": 2.03125, "grad_norm_layers": 3.517819036439428, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1500, "step_time_ms": 158.44988822937012, "total_time_s": 234.90055203437805, "loss": 1.5789287734031676, "perplexity": 4.8497578380466235, "lr": 0.0003, "tokens_seen": 24576000, "tokens_per_sec": 104623.29199538626, "forward_time_ms": 23.491859436035156, "backward_time_ms": 64.8355484008789, "grad_norm_total": 2.9463069032518727, "grad_norm_embedding": 1.5, "grad_norm_layers": 2.535660392476967, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1600, "step_time_ms": 160.01200675964355, "total_time_s": 250.10868430137634, "loss": 1.6092342829704285, "perplexity": 4.998981956337, "lr": 0.0003, "tokens_seen": 26214400, "tokens_per_sec": 104812.26570837297, "forward_time_ms": 23.911237716674805, "backward_time_ms": 64.71562385559082, "grad_norm_total": 1.1438312352803008, "grad_norm_embedding": 0.53515625, "grad_norm_layers": 1.0108700512324351, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1700, "step_time_ms": 158.6761474609375, "total_time_s": 265.2887420654297, "loss": 1.5696473920345306, "perplexity": 4.804953630110725, "lr": 0.0003, "tokens_seen": 27852800, "tokens_per_sec": 104990.74579226773, "forward_time_ms": 24.083852767944336, "backward_time_ms": 66.42460823059082, "grad_norm_total": 1.313166580146051, "grad_norm_embedding": 0.6015625, "grad_norm_layers": 1.1672300377361375, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1800, "step_time_ms": 159.50942039489746, "total_time_s": 280.48127031326294, "loss": 1.6231473755836487, "perplexity": 5.069019343814539, "lr": 0.0003, "tokens_seen": 29491200, "tokens_per_sec": 105145.1962417222, "forward_time_ms": 23.746728897094727, "backward_time_ms": 64.63956832885742, "grad_norm_total": 1.1285086493872225, "grad_norm_embedding": 0.51953125, "grad_norm_layers": 1.0017608670570783, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1900, "step_time_ms": 160.7186794281006, "total_time_s": 295.65255308151245, "loss": 1.5595165491104126, "perplexity": 4.756521144811079, "lr": 0.0003, "tokens_seen": 31129600, "tokens_per_sec": 105291.36719443565, "forward_time_ms": 23.897409439086914, "backward_time_ms": 64.65697288513184, "grad_norm_total": 0.9911390129966895, "grad_norm_embedding": 0.470703125, "grad_norm_layers": 0.8721772031160675, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 2000, "step_time_ms": 160.62235832214355, "total_time_s": 310.87460947036743, "loss": 1.5407167267799378, "perplexity": 4.667934706132727, "lr": 0.0003, "tokens_seen": 32768000, "tokens_per_sec": 105406.04121026429, "forward_time_ms": 23.905038833618164, "backward_time_ms": 64.47505950927734, "grad_norm_total": 1.68740261857101, "grad_norm_embedding": 0.78125, "grad_norm_layers": 1.4955852953354634, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
