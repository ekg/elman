{"type": "header", "timestamp": "2026-01-04T19:48:59.017406", "config": {"level": "2", "params": "50m", "num_params": 49715112, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 2000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 796.9250679016113, "total_time_s": 79.07497048377991, "loss": 2.9102210605144503, "perplexity": 18.360856978913592, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 20719.818030611586, "forward_time_ms": 167.94657707214355, "backward_time_ms": 604.2304039001465, "grad_norm_total": 1.2409563265535892, "grad_norm_embedding": 0.8828125, "grad_norm_layers": 0.8714100906784638, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12430.86376953125}
{"type": "step", "step": 200, "step_time_ms": 795.1743602752686, "total_time_s": 157.75871968269348, "loss": 2.097341779470444, "perplexity": 8.144491258145697, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 20771.054664467065, "forward_time_ms": 166.37659072875977, "backward_time_ms": 604.6147346496582, "grad_norm_total": 1.937488394871996, "grad_norm_embedding": 1.234375, "grad_norm_layers": 1.49320086118652, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 300, "step_time_ms": 789.0279293060303, "total_time_s": 236.5267972946167, "loss": 1.8835306626558304, "perplexity": 6.576683971802827, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 20780.799427313257, "forward_time_ms": 159.15632247924805, "backward_time_ms": 604.5131683349609, "grad_norm_total": 1.839942015541394, "grad_norm_embedding": 1.1328125, "grad_norm_layers": 1.4497544375960625, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 400, "step_time_ms": 794.3501472473145, "total_time_s": 315.31467151641846, "loss": 1.8435333716869353, "perplexity": 6.318825622622484, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 20784.360836200976, "forward_time_ms": 164.3073558807373, "backward_time_ms": 605.140209197998, "grad_norm_total": 4.63628543263237, "grad_norm_embedding": 2.953125, "grad_norm_layers": 3.5737251780296573, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12432.48876953125}
{"type": "step", "step": 500, "step_time_ms": 793.7090396881104, "total_time_s": 394.0553820133209, "loss": 1.8615429186820984, "perplexity": 6.43365572500429, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 20788.992619424265, "forward_time_ms": 164.9625301361084, "backward_time_ms": 604.1333675384521, "grad_norm_total": 3.032942676993576, "grad_norm_embedding": 1.859375, "grad_norm_layers": 2.3960877424044655, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12434.11376953125}
{"type": "step", "step": 600, "step_time_ms": 806.5946102142334, "total_time_s": 473.0353636741638, "loss": 1.7722507476806642, "perplexity": 5.884082052607735, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 20781.567480230606, "forward_time_ms": 174.89218711853027, "backward_time_ms": 606.1382293701172, "grad_norm_total": 3.3834385676001246, "grad_norm_embedding": 2.078125, "grad_norm_layers": 2.669971109563222, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12434.11376953125}
{"type": "step", "step": 700, "step_time_ms": 804.2504787445068, "total_time_s": 552.3279376029968, "loss": 1.791369595527649, "perplexity": 5.997661213742815, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 20764.50709968547, "forward_time_ms": 172.97053337097168, "backward_time_ms": 605.499267578125, "grad_norm_total": 4.805494415163359, "grad_norm_embedding": 3.046875, "grad_norm_layers": 3.716044582858634, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12434.11376953125}
{"type": "step", "step": 800, "step_time_ms": 802.4802207946777, "total_time_s": 631.6318597793579, "loss": 1.7448786079883576, "perplexity": 5.725206438909532, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 20751.357402443675, "forward_time_ms": 169.45815086364746, "backward_time_ms": 606.7383289337158, "grad_norm_total": 2.8142057883009812, "grad_norm_embedding": 1.765625, "grad_norm_layers": 2.1913706477057344, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12435.73876953125}
{"type": "step", "step": 900, "step_time_ms": 799.0639209747314, "total_time_s": 710.9298529624939, "loss": 1.862468008995056, "perplexity": 6.439610191377327, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 20741.316766183038, "forward_time_ms": 165.6792163848877, "backward_time_ms": 605.6320667266846, "grad_norm_total": 2.452714692134337, "grad_norm_embedding": 1.5, "grad_norm_layers": 1.940525265709519, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1000, "step_time_ms": 792.7618026733398, "total_time_s": 789.6211814880371, "loss": 1.673334082365036, "perplexity": 5.329908560302581, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 20749.21144281479, "forward_time_ms": 162.48369216918945, "backward_time_ms": 605.4391860961914, "grad_norm_total": 2.417775962525544, "grad_norm_embedding": 1.4921875, "grad_norm_layers": 1.9023189635162543, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1100, "step_time_ms": 791.2213802337646, "total_time_s": 869.646821975708, "loss": 1.8564932203292848, "perplexity": 6.4012495937425165, "lr": 0.0003, "tokens_seen": 18022400, "tokens_per_sec": 20723.833519352575, "forward_time_ms": 162.6594066619873, "backward_time_ms": 604.1655540466309, "grad_norm_total": 2.243233966108612, "grad_norm_embedding": 1.375, "grad_norm_layers": 1.7723156467464873, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1200, "step_time_ms": 827.8956413269043, "total_time_s": 950.0010783672333, "loss": 1.6676024055480958, "perplexity": 5.299446629337709, "lr": 0.0003, "tokens_seen": 19660800, "tokens_per_sec": 20695.57507790931, "forward_time_ms": 194.749116897583, "backward_time_ms": 605.7872772216797, "grad_norm_total": 1.9995750187832224, "grad_norm_embedding": 1.2109375, "grad_norm_layers": 1.591122869982338, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1300, "step_time_ms": 810.889482498169, "total_time_s": 1031.310928106308, "loss": 1.66707869887352, "perplexity": 5.296672000375636, "lr": 0.0003, "tokens_seen": 21299200, "tokens_per_sec": 20652.564728154848, "forward_time_ms": 182.11627006530762, "backward_time_ms": 603.848934173584, "grad_norm_total": 2.545712283265206, "grad_norm_embedding": 1.5625, "grad_norm_layers": 2.0097128943590805, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1400, "step_time_ms": 857.637882232666, "total_time_s": 1112.7559843063354, "loss": 1.7032757961750031, "perplexity": 5.491908329779947, "lr": 0.0003, "tokens_seen": 22937600, "tokens_per_sec": 20613.344403705738, "forward_time_ms": 229.0780544281006, "backward_time_ms": 603.217363357544, "grad_norm_total": 6.420540588659108, "grad_norm_embedding": 3.984375, "grad_norm_layers": 5.0342795080508305, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1500, "step_time_ms": 856.7581176757812, "total_time_s": 1197.4638216495514, "loss": 1.6887983250617982, "perplexity": 5.412972162349361, "lr": 0.0003, "tokens_seen": 24576000, "tokens_per_sec": 20523.390396945026, "forward_time_ms": 226.26757621765137, "backward_time_ms": 603.5799980163574, "grad_norm_total": 4.061492485108953, "grad_norm_embedding": 2.484375, "grad_norm_layers": 3.2128826455139516, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1600, "step_time_ms": 845.4833030700684, "total_time_s": 1281.4865543842316, "loss": 1.724773336648941, "perplexity": 5.611249021032997, "lr": 0.0003, "tokens_seen": 26214400, "tokens_per_sec": 20456.255386741836, "forward_time_ms": 216.29881858825684, "backward_time_ms": 603.5184860229492, "grad_norm_total": 1.9884813667763912, "grad_norm_embedding": 1.21875, "grad_norm_layers": 1.5711510969640077, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1700, "step_time_ms": 858.5734367370605, "total_time_s": 1365.5941503047943, "loss": 1.6901937592029572, "perplexity": 5.420530881130421, "lr": 0.0003, "tokens_seen": 27852800, "tokens_per_sec": 20396.117289329835, "forward_time_ms": 225.22687911987305, "backward_time_ms": 606.212854385376, "grad_norm_total": 2.448879997197551, "grad_norm_embedding": 1.46875, "grad_norm_layers": 1.959509872862988, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1800, "step_time_ms": 851.292610168457, "total_time_s": 1449.7474989891052, "loss": 1.7446623396873475, "perplexity": 5.72396839212002, "lr": 0.0003, "tokens_seen": 29491200, "tokens_per_sec": 20342.31044848905, "forward_time_ms": 223.16312789916992, "backward_time_ms": 603.8229465484619, "grad_norm_total": 1.953089859198602, "grad_norm_embedding": 1.171875, "grad_norm_layers": 1.5624030983566377, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 1900, "step_time_ms": 844.841718673706, "total_time_s": 1533.5765717029572, "loss": 1.6730010080337525, "perplexity": 5.328133600186292, "lr": 0.0003, "tokens_seen": 31129600, "tokens_per_sec": 20298.703217261856, "forward_time_ms": 217.26536750793457, "backward_time_ms": 602.7367115020752, "grad_norm_total": 1.6708894085672372, "grad_norm_embedding": 1.0, "grad_norm_layers": 1.3385303047841144, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
{"type": "step", "step": 2000, "step_time_ms": 766.5069103240967, "total_time_s": 1615.3031842708588, "loss": 1.667719898223877, "perplexity": 5.3000693120819635, "lr": 0.0003, "tokens_seen": 32768000, "tokens_per_sec": 20285.984240730268, "forward_time_ms": 139.25457000732422, "backward_time_ms": 604.6619415283203, "grad_norm_total": 2.876946201113504, "grad_norm_embedding": 1.7265625, "grad_norm_layers": 2.3011887855755355, "grad_norm_head": 0, "memory_allocated_mb": 4357.14892578125, "memory_reserved_mb": 12832.0, "memory_max_allocated_mb": 12437.36376953125}
