{"type": "header", "timestamp": "2026-01-05T08:53:05.199989", "config": {"level": "mamba2", "params": "50m", "num_params": 50928750, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 145.86520195007324, "total_time_s": 28.464102745056152, "loss": 2.735705519914627, "perplexity": 15.420619152868984, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 57562.07714471026, "forward_time_ms": 31.077861785888672, "backward_time_ms": 84.8245620727539, "grad_norm_total": 1.020985640765259, "grad_norm_embedding": 0.67578125, "grad_norm_layers": 0.7649395518797971, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 200, "step_time_ms": 143.6598300933838, "total_time_s": 43.29268527030945, "loss": 1.9764669692516328, "perplexity": 7.2171993013723785, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 75690.65493390901, "forward_time_ms": 28.012752532958984, "backward_time_ms": 83.04190635681152, "grad_norm_total": 1.328268165464175, "grad_norm_embedding": 0.68359375, "grad_norm_layers": 1.1387508211419899, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 300, "step_time_ms": 216.0344123840332, "total_time_s": 58.19947338104248, "loss": 1.778308601975441, "perplexity": 5.919835148526112, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 84455.33770524399, "forward_time_ms": 40.804147720336914, "backward_time_ms": 132.17782974243164, "grad_norm_total": 1.1425274465864221, "grad_norm_embedding": 0.5703125, "grad_norm_layers": 0.9899286717908437, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 400, "step_time_ms": 151.503324508667, "total_time_s": 72.57560420036316, "loss": 1.734997465610504, "perplexity": 5.668913436552106, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 90301.29948659273, "forward_time_ms": 31.27288818359375, "backward_time_ms": 85.968017578125, "grad_norm_total": 3.0175428129032187, "grad_norm_embedding": 1.7109375, "grad_norm_layers": 2.4852205620250474, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 500, "step_time_ms": 151.13544464111328, "total_time_s": 86.78405213356018, "loss": 1.7462773513793945, "perplexity": 5.7332201368252225, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 94396.10032784048, "forward_time_ms": 30.991315841674805, "backward_time_ms": 84.40780639648438, "grad_norm_total": 1.9422165431292129, "grad_norm_embedding": 0.921875, "grad_norm_layers": 1.7094107071599642, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 600, "step_time_ms": 153.77569198608398, "total_time_s": 101.2206449508667, "loss": 1.6653087240457536, "perplexity": 5.2873053161070604, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 97119.20723629341, "forward_time_ms": 27.766942977905273, "backward_time_ms": 76.83444023132324, "grad_norm_total": 1.8880612659150942, "grad_norm_embedding": 0.9375, "grad_norm_layers": 1.6387580398389883, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 700, "step_time_ms": 176.7420768737793, "total_time_s": 116.57579445838928, "loss": 1.6751301312446594, "perplexity": 5.339489938336822, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 98381.17601017457, "forward_time_ms": 57.41381645202637, "backward_time_ms": 87.51392364501953, "grad_norm_total": 2.5228768635525167, "grad_norm_embedding": 1.1796875, "grad_norm_layers": 2.229991990853018, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 800, "step_time_ms": 157.12738037109375, "total_time_s": 131.39323735237122, "loss": 1.6398776078224182, "perplexity": 5.154538598422521, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 99756.12455581118, "forward_time_ms": 30.73740005493164, "backward_time_ms": 84.71512794494629, "grad_norm_total": 1.670653272909758, "grad_norm_embedding": 0.77734375, "grad_norm_layers": 1.4787427663867316, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 900, "step_time_ms": 156.5690040588379, "total_time_s": 146.28310441970825, "loss": 1.7700215101242065, "perplexity": 5.870979645525791, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 100802.32379876169, "forward_time_ms": 30.80272674560547, "backward_time_ms": 84.42306518554688, "grad_norm_total": 1.4415447261482652, "grad_norm_embedding": 0.671875, "grad_norm_layers": 1.275352381850633, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
{"type": "step", "step": 1000, "step_time_ms": 177.27327346801758, "total_time_s": 161.54369592666626, "loss": 1.5669611024856567, "perplexity": 4.792063454514781, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 101421.91663399442, "forward_time_ms": 37.47677803039551, "backward_time_ms": 113.72733116149902, "grad_norm_total": 1.3073045373027952, "grad_norm_embedding": 0.6015625, "grad_norm_layers": 1.1606338157655347, "grad_norm_head": 0, "memory_allocated_mb": 675.5830078125, "memory_reserved_mb": 4940.0, "memory_max_allocated_mb": 4632.63671875}
