{"type": "header", "timestamp": "2026-01-05T07:43:08.787812", "config": {"level": "4", "params": "50m", "num_params": 49187840, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 614.4683361053467, "total_time_s": 61.019503593444824, "loss": 2.928482836484909, "perplexity": 18.69923916155405, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 26850.79479016376, "forward_time_ms": 167.44542121887207, "backward_time_ms": 432.2516918182373, "grad_norm_total": 1.5221056168356535, "grad_norm_embedding": 0.95703125, "grad_norm_layers": 1.1830973563406169, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 200, "step_time_ms": 599.3161201477051, "total_time_s": 118.78298473358154, "loss": 2.1528658485412597, "perplexity": 8.609496588892293, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 27586.595728432014, "forward_time_ms": 165.17186164855957, "backward_time_ms": 420.0870990753174, "grad_norm_total": 2.253233303242919, "grad_norm_embedding": 1.21875, "grad_norm_layers": 1.8950611178036485, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 300, "step_time_ms": 537.0142459869385, "total_time_s": 174.68794655799866, "loss": 1.9264564359188079, "perplexity": 6.8651400247657834, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 28137.119940103836, "forward_time_ms": 144.95396614074707, "backward_time_ms": 379.2901039123535, "grad_norm_total": 1.9392926013678573, "grad_norm_embedding": 1.0546875, "grad_norm_layers": 1.6273172801460258, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 400, "step_time_ms": 535.2466106414795, "total_time_s": 227.87944173812866, "loss": 1.8741631484031678, "perplexity": 6.5153644451317705, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 28759.138149612623, "forward_time_ms": 144.94752883911133, "backward_time_ms": 377.5303363800049, "grad_norm_total": 4.3651023599431396, "grad_norm_embedding": 2.546875, "grad_norm_layers": 3.544702567523184, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 500, "step_time_ms": 529.6320915222168, "total_time_s": 280.9439220428467, "loss": 1.879077884554863, "perplexity": 6.547464559494151, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 29158.917632797464, "forward_time_ms": 143.23663711547852, "backward_time_ms": 373.70777130126953, "grad_norm_total": 3.1202187898074305, "grad_norm_embedding": 1.671875, "grad_norm_layers": 2.6344551597821213, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 600, "step_time_ms": 530.8735370635986, "total_time_s": 333.6901273727417, "loss": 1.7868419086933136, "perplexity": 5.97056706522402, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 29459.714974572882, "forward_time_ms": 143.79048347473145, "backward_time_ms": 374.5689392089844, "grad_norm_total": 3.419443814071586, "grad_norm_embedding": 1.8515625, "grad_norm_layers": 2.8747149185132463, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 700, "step_time_ms": 529.8974514007568, "total_time_s": 386.3008246421814, "loss": 1.8000590932369231, "perplexity": 6.050004968226787, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 29688.82038897265, "forward_time_ms": 143.4342861175537, "backward_time_ms": 373.95572662353516, "grad_norm_total": 4.24946135783453, "grad_norm_embedding": 2.265625, "grad_norm_layers": 3.5950737900841694, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 800, "step_time_ms": 530.4994583129883, "total_time_s": 438.8929145336151, "loss": 1.754857244491577, "perplexity": 5.782622181861962, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 29864.269343732845, "forward_time_ms": 143.47314834594727, "backward_time_ms": 374.37915802001953, "grad_norm_total": 2.7730053533093857, "grad_norm_embedding": 1.4765625, "grad_norm_layers": 2.347155818546686, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 900, "step_time_ms": 530.1737785339355, "total_time_s": 491.4812083244324, "loss": 1.8440109503269195, "perplexity": 6.321844079487525, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 30002.401172037535, "forward_time_ms": 143.5558795928955, "backward_time_ms": 374.2978572845459, "grad_norm_total": 2.633759247455857, "grad_norm_embedding": 1.40625, "grad_norm_layers": 2.226868220827554, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
{"type": "step", "step": 1000, "step_time_ms": 530.5347442626953, "total_time_s": 544.0860641002655, "loss": 1.6728163874149322, "perplexity": 5.327150007662392, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 30112.914489271727, "forward_time_ms": 144.1655158996582, "backward_time_ms": 374.0987777709961, "grad_norm_total": 2.4940476146284145, "grad_norm_embedding": 1.3203125, "grad_norm_layers": 2.1158629048934996, "grad_norm_head": 0, "memory_allocated_mb": 851.07275390625, "memory_reserved_mb": 5232.0, "memory_max_allocated_mb": 5093.95947265625}
