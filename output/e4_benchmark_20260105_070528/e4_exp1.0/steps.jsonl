{"type": "header", "timestamp": "2026-01-05T07:05:34.898910", "config": {"level": "4", "params": "50m", "num_params": 50941696, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 1157.0091247558594, "total_time_s": 116.2030897140503, "loss": 2.9280963563919067, "perplexity": 18.692013674207267, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 14099.552122223728, "forward_time_ms": 295.66097259521484, "backward_time_ms": 841.0356044769287, "grad_norm_total": 1.426059042759338, "grad_norm_embedding": 0.9296875, "grad_norm_layers": 1.0807689645715968, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
{"type": "step", "step": 200, "step_time_ms": 1118.3667182922363, "total_time_s": 228.74380254745483, "loss": 2.125634523630142, "perplexity": 8.37821197534179, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 14325.243331885897, "forward_time_ms": 296.9233989715576, "backward_time_ms": 801.3660907745361, "grad_norm_total": 2.532678937574731, "grad_norm_embedding": 1.4765625, "grad_norm_layers": 2.057584313536032, "grad_norm_head": 0, "memory_allocated_mb": 921.09619140625, "memory_reserved_mb": 6376.0, "memory_max_allocated_mb": 5888.984375}
