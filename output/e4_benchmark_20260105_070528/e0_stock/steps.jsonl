{"type": "header", "timestamp": "2026-01-05T07:05:40.264480", "config": {"level": "0", "params": "50m", "num_params": 48742912, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 423.0043888092041, "total_time_s": 42.15134310722351, "loss": 2.8607974100112914, "perplexity": 17.475456486014632, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 38870.24159091182, "forward_time_ms": 188.27223777770996, "backward_time_ms": 218.32633018493652, "grad_norm_total": 1.4604542744546476, "grad_norm_embedding": 0.89453125, "grad_norm_layers": 1.1539167305020275, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 200, "step_time_ms": 424.0736961364746, "total_time_s": 83.68812346458435, "loss": 2.0749512875080107, "perplexity": 7.964158495578598, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 39155.21286215233, "forward_time_ms": 190.02985954284668, "backward_time_ms": 218.17922592163086, "grad_norm_total": 1.9971032535732212, "grad_norm_embedding": 1.1328125, "grad_norm_layers": 1.6445936314486531, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 300, "step_time_ms": 422.8367805480957, "total_time_s": 125.24803614616394, "loss": 1.8608068072795867, "perplexity": 6.428921580307996, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 39243.94341816322, "forward_time_ms": 188.33208084106445, "backward_time_ms": 218.25432777404785, "grad_norm_total": 1.766201723610959, "grad_norm_embedding": 0.99609375, "grad_norm_layers": 1.4584073171832839, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 400, "step_time_ms": 397.9334831237793, "total_time_s": 166.42517614364624, "loss": 1.821027261018753, "perplexity": 6.178201817071472, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 39378.818214215105, "forward_time_ms": 172.99556732177734, "backward_time_ms": 209.97309684753418, "grad_norm_total": 4.282879006324518, "grad_norm_embedding": 2.625, "grad_norm_layers": 3.383740597607659, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 500, "step_time_ms": 394.8979377746582, "total_time_s": 206.51049613952637, "loss": 1.8324455165863036, "perplexity": 6.249150387989938, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 39668.8180421956, "forward_time_ms": 172.7137565612793, "backward_time_ms": 207.59820938110352, "grad_norm_total": 3.043420150219866, "grad_norm_embedding": 1.7265625, "grad_norm_layers": 2.5062191511243155, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
{"type": "step", "step": 600, "step_time_ms": 405.78770637512207, "total_time_s": 246.30864119529724, "loss": 1.738664973974228, "perplexity": 5.689742395838224, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 39911.00313005722, "forward_time_ms": 180.4523468017578, "backward_time_ms": 209.74421501159668, "grad_norm_total": 3.1245526430925694, "grad_norm_embedding": 1.734375, "grad_norm_layers": 2.5989306288014498, "grad_norm_head": 0, "memory_allocated_mb": 765.240234375, "memory_reserved_mb": 4114.0, "memory_max_allocated_mb": 3683.2021484375}
