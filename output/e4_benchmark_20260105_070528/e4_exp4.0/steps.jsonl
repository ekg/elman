{"type": "header", "timestamp": "2026-01-05T07:05:38.973203", "config": {"level": "4", "params": "50m", "num_params": 53368832, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 262.68863677978516, "total_time_s": 26.52342987060547, "loss": 2.9763861227035524, "perplexity": 19.616795698960164, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 61773.910437054015, "forward_time_ms": 69.23580169677734, "backward_time_ms": 180.83953857421875, "grad_norm_total": 0.960845977313105, "grad_norm_embedding": 0.63671875, "grad_norm_layers": 0.7189722177631442, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 200, "step_time_ms": 259.74225997924805, "total_time_s": 52.43027663230896, "loss": 2.232605136632919, "perplexity": 9.324125086582569, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 62498.99319285104, "forward_time_ms": 69.1678524017334, "backward_time_ms": 178.6043643951416, "grad_norm_total": 1.6471781808107215, "grad_norm_embedding": 0.828125, "grad_norm_layers": 1.4237173146722741, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 300, "step_time_ms": 260.58411598205566, "total_time_s": 78.19145512580872, "loss": 1.991946486234665, "perplexity": 7.329787215652193, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 62861.56621101909, "forward_time_ms": 69.02384757995605, "backward_time_ms": 179.40235137939453, "grad_norm_total": 1.421895985428821, "grad_norm_embedding": 0.73828125, "grad_norm_layers": 1.2150623327659664, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 400, "step_time_ms": 260.8821392059326, "total_time_s": 103.99373173713684, "loss": 1.926192467212677, "perplexity": 6.86332808179468, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 63019.55420639412, "forward_time_ms": 69.02885437011719, "backward_time_ms": 179.4438362121582, "grad_norm_total": 3.133112367467185, "grad_norm_embedding": 1.8515625, "grad_norm_layers": 2.526953361936975, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 500, "step_time_ms": 263.89193534851074, "total_time_s": 129.95516443252563, "loss": 1.917380912899971, "perplexity": 6.80311715912536, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 63037.414665500175, "forward_time_ms": 69.65065002441406, "backward_time_ms": 182.33346939086914, "grad_norm_total": 2.1712426152159314, "grad_norm_embedding": 1.0234375, "grad_norm_layers": 1.9148426784390207, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 600, "step_time_ms": 262.937068939209, "total_time_s": 155.98839163780212, "loss": 1.8165307986736297, "perplexity": 6.150484127713755, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 63020.32145814556, "forward_time_ms": 69.63157653808594, "backward_time_ms": 181.09869956970215, "grad_norm_total": 2.512749442107923, "grad_norm_embedding": 1.21875, "grad_norm_layers": 2.1973157243315313, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 700, "step_time_ms": 263.1211280822754, "total_time_s": 182.0040340423584, "loss": 1.8259649527072908, "perplexity": 6.208783311696235, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 63014.22324559605, "forward_time_ms": 69.52476501464844, "backward_time_ms": 181.39004707336426, "grad_norm_total": 3.003934850017135, "grad_norm_embedding": 1.4375, "grad_norm_layers": 2.6375859838846987, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 800, "step_time_ms": 261.0762119293213, "total_time_s": 207.94886231422424, "loss": 1.7779093492031097, "perplexity": 5.917472109687612, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 63031.14581141323, "forward_time_ms": 69.01741027832031, "backward_time_ms": 179.734468460083, "grad_norm_total": 2.042355232630759, "grad_norm_embedding": 0.95703125, "grad_norm_layers": 1.8041927639506379, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 900, "step_time_ms": 259.7339153289795, "total_time_s": 233.69933557510376, "loss": 1.857254728078842, "perplexity": 6.406126051409501, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 63096.62666927838, "forward_time_ms": 69.00215148925781, "backward_time_ms": 178.88712882995605, "grad_norm_total": 1.8303482550055197, "grad_norm_embedding": 0.85546875, "grad_norm_layers": 1.618079190238532, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
{"type": "step", "step": 1000, "step_time_ms": 259.340763092041, "total_time_s": 259.43856739997864, "loss": 1.689655261039734, "perplexity": 5.417612720989693, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 63151.90205047765, "forward_time_ms": 69.05984878540039, "backward_time_ms": 178.74622344970703, "grad_norm_total": 1.7761404011065354, "grad_norm_embedding": 0.828125, "grad_norm_layers": 1.5712128321261822, "grad_norm_head": 0, "memory_allocated_mb": 778.80322265625, "memory_reserved_mb": 4174.0, "memory_max_allocated_mb": 4090.5146484375}
