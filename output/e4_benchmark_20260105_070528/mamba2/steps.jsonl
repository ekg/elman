{"type": "header", "timestamp": "2026-01-05T07:05:39.463427", "config": {"level": "mamba2", "params": "50m", "num_params": 50928750, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 142.49014854431152, "total_time_s": 26.554063320159912, "loss": 2.721578209400177, "perplexity": 15.204298887323139, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 61702.26120755765, "forward_time_ms": 23.738622665405273, "backward_time_ms": 65.56081771850586, "grad_norm_total": 1.0141324091102386, "grad_norm_embedding": 0.6875, "grad_norm_layers": 0.7451316578006189, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 200, "step_time_ms": 143.94426345825195, "total_time_s": 40.07463264465332, "loss": 1.9739299809932709, "perplexity": 7.198912557921508, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 81768.61669108529, "forward_time_ms": 23.76866340637207, "backward_time_ms": 65.58799743652344, "grad_norm_total": 1.264128622201152, "grad_norm_embedding": 0.64453125, "grad_norm_layers": 1.087374651123459, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 300, "step_time_ms": 147.71342277526855, "total_time_s": 53.89596199989319, "loss": 1.7737672817707062, "perplexity": 5.8930122333793795, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 91198.99393684865, "forward_time_ms": 23.72908592224121, "backward_time_ms": 65.65642356872559, "grad_norm_total": 1.162004443116532, "grad_norm_embedding": 0.57421875, "grad_norm_layers": 1.0101395836259799, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 400, "step_time_ms": 149.57714080810547, "total_time_s": 68.00060081481934, "loss": 1.7320350074768067, "perplexity": 5.652144368927154, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 96376.42530819602, "forward_time_ms": 23.751020431518555, "backward_time_ms": 65.75226783752441, "grad_norm_total": 3.054063941778148, "grad_norm_embedding": 1.796875, "grad_norm_layers": 2.4691167614905836, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 500, "step_time_ms": 153.2003879547119, "total_time_s": 82.34347653388977, "loss": 1.746208170056343, "perplexity": 5.732823518790249, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 99486.42685138028, "forward_time_ms": 23.76270294189453, "backward_time_ms": 65.57130813598633, "grad_norm_total": 1.9251747926970344, "grad_norm_embedding": 0.91796875, "grad_norm_layers": 1.6921433963328336, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 600, "step_time_ms": 154.14714813232422, "total_time_s": 96.93756055831909, "loss": 1.661474575996399, "perplexity": 5.267071818642577, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 101410.22713547757, "forward_time_ms": 23.730993270874023, "backward_time_ms": 65.62209129333496, "grad_norm_total": 1.8282598794569616, "grad_norm_embedding": 0.9140625, "grad_norm_layers": 1.5832650549680565, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 700, "step_time_ms": 154.31976318359375, "total_time_s": 111.72283411026001, "loss": 1.6745686066150665, "perplexity": 5.336492524866486, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 102654.56104832394, "forward_time_ms": 23.760080337524414, "backward_time_ms": 65.90914726257324, "grad_norm_total": 2.544875578203712, "grad_norm_embedding": 1.1484375, "grad_norm_layers": 2.270921029270202, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 800, "step_time_ms": 157.4423313140869, "total_time_s": 126.62710666656494, "loss": 1.638613486289978, "perplexity": 5.1480267519403, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 103510.66151513439, "forward_time_ms": 23.755788803100586, "backward_time_ms": 65.80424308776855, "grad_norm_total": 1.5732494533281312, "grad_norm_embedding": 0.7421875, "grad_norm_layers": 1.3871301872561042, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 900, "step_time_ms": 157.2549343109131, "total_time_s": 141.65876936912537, "loss": 1.7700266563892364, "perplexity": 5.871009859220776, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 104092.80771590077, "forward_time_ms": 23.72598648071289, "backward_time_ms": 65.52815437316895, "grad_norm_total": 1.511309279496484, "grad_norm_embedding": 0.6953125, "grad_norm_layers": 1.3418251412034963, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
{"type": "step", "step": 1000, "step_time_ms": 158.27012062072754, "total_time_s": 156.77410507202148, "loss": 1.5658633768558503, "perplexity": 4.786805969806898, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 104507.44186477212, "forward_time_ms": 23.753881454467773, "backward_time_ms": 65.54222106933594, "grad_norm_total": 1.3481674446259517, "grad_norm_embedding": 0.625, "grad_norm_layers": 1.1944981398192125, "grad_norm_head": 0, "memory_allocated_mb": 320.51123046875, "memory_reserved_mb": 4848.0, "memory_max_allocated_mb": 4488.603515625}
