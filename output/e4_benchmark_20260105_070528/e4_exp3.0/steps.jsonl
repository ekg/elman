{"type": "header", "timestamp": "2026-01-05T07:05:38.053026", "config": {"level": "4", "params": "50m", "num_params": 49954816, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 376.4946460723877, "total_time_s": 37.87017869949341, "loss": 2.9355708503723146, "perplexity": 18.832250464523508, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 43264.67249466977, "forward_time_ms": 99.03383255004883, "backward_time_ms": 264.13655281066895, "grad_norm_total": 1.2595810987927842, "grad_norm_embedding": 0.8046875, "grad_norm_layers": 0.9684952590358431, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 200, "step_time_ms": 376.2011528015137, "total_time_s": 75.12230920791626, "loss": 2.1958675837516783, "perplexity": 8.987795340434333, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 43619.90147006789, "forward_time_ms": 99.19404983520508, "backward_time_ms": 264.27459716796875, "grad_norm_total": 1.7014170800751864, "grad_norm_embedding": 0.8828125, "grad_norm_layers": 1.4543251756087425, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 300, "step_time_ms": 377.7961730957031, "total_time_s": 112.43297243118286, "loss": 1.9604172384738923, "perplexity": 7.1022897955865405, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 43716.97370083594, "forward_time_ms": 98.33359718322754, "backward_time_ms": 266.2065029144287, "grad_norm_total": 1.5560448901653392, "grad_norm_embedding": 0.80078125, "grad_norm_layers": 1.3340499516750282, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 400, "step_time_ms": 374.55248832702637, "total_time_s": 149.5345687866211, "loss": 1.8974402606487275, "perplexity": 6.668802180377361, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 43826.82229665107, "forward_time_ms": 97.4264144897461, "backward_time_ms": 264.21427726745605, "grad_norm_total": 3.789480943900145, "grad_norm_embedding": 2.171875, "grad_norm_layers": 3.1049062982774664, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 500, "step_time_ms": 374.4924068450928, "total_time_s": 186.58821201324463, "loss": 1.8955438178777695, "perplexity": 6.656167163271676, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 43904.30433538347, "forward_time_ms": 97.41330146789551, "backward_time_ms": 264.4660472869873, "grad_norm_total": 2.741219696884375, "grad_norm_embedding": 1.375, "grad_norm_layers": 2.371376261149821, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 600, "step_time_ms": 376.6961097717285, "total_time_s": 223.78121709823608, "loss": 1.7966458368301392, "perplexity": 6.029389952189984, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 43928.74188747863, "forward_time_ms": 99.18355941772461, "backward_time_ms": 264.65606689453125, "grad_norm_total": 2.94007321594285, "grad_norm_embedding": 1.4765625, "grad_norm_layers": 2.5423213468648522, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
{"type": "step", "step": 700, "step_time_ms": 379.7125816345215, "total_time_s": 261.0518128871918, "loss": 1.808727604150772, "perplexity": 6.102677468563965, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 43933.18629461706, "forward_time_ms": 101.32002830505371, "backward_time_ms": 264.95957374572754, "grad_norm_total": 3.704904692601974, "grad_norm_embedding": 1.8046875, "grad_norm_layers": 3.235590077787279, "grad_norm_head": 0, "memory_allocated_mb": 795.83251953125, "memory_reserved_mb": 4496.0, "memory_max_allocated_mb": 4377.69677734375}
