{"type": "header", "timestamp": "2026-01-05T07:05:33.403680", "config": {"level": "1", "params": "50m", "num_params": 49714944, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 398.94843101501465, "total_time_s": 40.42389965057373, "loss": 2.8094507682323457, "perplexity": 16.600798028821096, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 40531.23807413648, "forward_time_ms": 179.13460731506348, "backward_time_ms": 204.52237129211426, "grad_norm_total": 1.238084026239248, "grad_norm_embedding": 0.71875, "grad_norm_layers": 1.0075629402915671, "grad_norm_head": 0, "memory_allocated_mb": 821.25830078125, "memory_reserved_mb": 5446.0, "memory_max_allocated_mb": 5048.39013671875}
{"type": "step", "step": 200, "step_time_ms": 388.3485794067383, "total_time_s": 79.5956494808197, "loss": 2.0203630340099337, "perplexity": 7.541062098802729, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 41168.43592702106, "forward_time_ms": 177.92654037475586, "backward_time_ms": 195.6961154937744, "grad_norm_total": 1.8700545536569673, "grad_norm_embedding": 0.9609375, "grad_norm_layers": 1.604148219513686, "grad_norm_head": 0, "memory_allocated_mb": 821.25830078125, "memory_reserved_mb": 5446.0, "memory_max_allocated_mb": 5048.39013671875}
{"type": "step", "step": 300, "step_time_ms": 399.18971061706543, "total_time_s": 118.81988501548767, "loss": 1.8136694943904876, "perplexity": 6.132910874337749, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 41367.03036059756, "forward_time_ms": 179.26669120788574, "backward_time_ms": 204.58316802978516, "grad_norm_total": 1.5842719790223472, "grad_norm_embedding": 0.80859375, "grad_norm_layers": 1.362287304217854, "grad_norm_head": 0, "memory_allocated_mb": 821.25830078125, "memory_reserved_mb": 5446.0, "memory_max_allocated_mb": 5048.39013671875}
{"type": "step", "step": 400, "step_time_ms": 398.38266372680664, "total_time_s": 158.04146265983582, "loss": 1.773353751897812, "perplexity": 5.890575800583139, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 41467.76347040876, "forward_time_ms": 178.8313388824463, "backward_time_ms": 204.40340042114258, "grad_norm_total": 4.095788951605754, "grad_norm_embedding": 2.3125, "grad_norm_layers": 3.3801705167145992, "grad_norm_head": 0, "memory_allocated_mb": 821.25830078125, "memory_reserved_mb": 5446.0, "memory_max_allocated_mb": 5048.39013671875}
{"type": "step", "step": 500, "step_time_ms": 397.40610122680664, "total_time_s": 197.20855045318604, "loss": 1.7841627240180968, "perplexity": 5.9545922227727175, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 41539.91143674222, "forward_time_ms": 178.61390113830566, "backward_time_ms": 203.90748977661133, "grad_norm_total": 2.9016899541971313, "grad_norm_embedding": 1.53125, "grad_norm_layers": 2.4647179400873016, "grad_norm_head": 0, "memory_allocated_mb": 821.25830078125, "memory_reserved_mb": 5446.0, "memory_max_allocated_mb": 5048.39013671875}
{"type": "step", "step": 600, "step_time_ms": 397.857666015625, "total_time_s": 236.39094710350037, "loss": 1.6962893056869506, "perplexity": 5.45367288578147, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 41585.45630460888, "forward_time_ms": 178.30801010131836, "backward_time_ms": 204.43153381347656, "grad_norm_total": 2.752906788437781, "grad_norm_embedding": 1.421875, "grad_norm_layers": 2.3572145780669915, "grad_norm_head": 0, "memory_allocated_mb": 821.25830078125, "memory_reserved_mb": 5446.0, "memory_max_allocated_mb": 5048.39013671875}
