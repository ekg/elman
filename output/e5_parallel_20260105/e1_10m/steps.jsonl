{"type": "header", "timestamp": "2026-01-05T09:22:49.197128", "config": {"level": "1", "params": "10m", "num_params": 9576448, "vocab_size": 256, "tokenizer": "byte", "tokenizer_name": "p50k_base", "chunk_size": 512, "batch_size": 32, "grad_accum": 1, "lr": 0.0003, "warmup_steps": 1000, "max_steps": 1000, "weight_decay": 0.1, "grad_clip": 1.0, "world_size": 1, "dtype": "torch.bfloat16", "tbptt": false, "tokens_per_step": 16384, "r_h_mode": "spectral_norm", "r_h_init_gain": 0.1}}
{"type": "step", "step": 100, "step_time_ms": 112.45584487915039, "total_time_s": 10.397249460220337, "loss": 2.982014021873474, "perplexity": 19.7275082946347, "lr": 0.0003, "tokens_seen": 1638400, "tokens_per_sec": 157593.21934875115, "forward_time_ms": 39.41178321838379, "backward_time_ms": 64.34154510498047, "grad_norm_total": 1.1510363112263209, "grad_norm_embedding": 0.76953125, "grad_norm_layers": 0.8553271742597843, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 200, "step_time_ms": 140.0125026702881, "total_time_s": 21.97375774383545, "loss": 2.2132384610176086, "perplexity": 9.14528513799852, "lr": 0.0003, "tokens_seen": 3276800, "tokens_per_sec": 149131.06617881428, "forward_time_ms": 58.419227600097656, "backward_time_ms": 67.78430938720703, "grad_norm_total": 1.453670691822686, "grad_norm_embedding": 0.87109375, "grad_norm_layers": 1.1635032424858267, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 300, "step_time_ms": 138.31043243408203, "total_time_s": 34.347265005111694, "loss": 1.9952441108226777, "perplexity": 7.353997999297488, "lr": 0.0003, "tokens_seen": 4915200, "tokens_per_sec": 143107.9209358813, "forward_time_ms": 58.67314338684082, "backward_time_ms": 66.25986099243164, "grad_norm_total": 1.5599895518730378, "grad_norm_embedding": 0.9375, "grad_norm_layers": 1.2466840799371721, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 400, "step_time_ms": 101.2415885925293, "total_time_s": 44.98730182647705, "loss": 1.940624305009842, "perplexity": 6.963096710122802, "lr": 0.0003, "tokens_seen": 6553600, "tokens_per_sec": 145679.15734014142, "forward_time_ms": 44.10529136657715, "backward_time_ms": 47.31273651123047, "grad_norm_total": 3.8269027198897767, "grad_norm_embedding": 2.40625, "grad_norm_layers": 2.9753376851249462, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 500, "step_time_ms": 79.85377311706543, "total_time_s": 53.28393030166626, "loss": 1.9462079745531082, "perplexity": 7.002085088965481, "lr": 0.0003, "tokens_seen": 8192000, "tokens_per_sec": 153744.23978456383, "forward_time_ms": 33.80131721496582, "backward_time_ms": 38.829803466796875, "grad_norm_total": 2.506508969351941, "grad_norm_embedding": 1.4921875, "grad_norm_layers": 2.0138728770365373, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 600, "step_time_ms": 80.09958267211914, "total_time_s": 61.093366622924805, "loss": 1.8439934307336807, "perplexity": 6.321733324320928, "lr": 0.0003, "tokens_seen": 9830400, "tokens_per_sec": 160909.78583638894, "forward_time_ms": 33.76269340515137, "backward_time_ms": 38.80476951599121, "grad_norm_total": 2.9228033475407287, "grad_norm_embedding": 1.734375, "grad_norm_layers": 2.352533904972971, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 700, "step_time_ms": 79.70094680786133, "total_time_s": 68.89537048339844, "loss": 1.8647926151752472, "perplexity": 6.454597161679244, "lr": 0.0003, "tokens_seen": 11468800, "tokens_per_sec": 166468.28519593956, "forward_time_ms": 33.737897872924805, "backward_time_ms": 38.80667686462402, "grad_norm_total": 2.8803834056445616, "grad_norm_embedding": 1.6875, "grad_norm_layers": 2.3342171836205305, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 800, "step_time_ms": 79.46085929870605, "total_time_s": 76.64661002159119, "loss": 1.8147925412654877, "perplexity": 6.139802289696762, "lr": 0.0003, "tokens_seen": 13107200, "tokens_per_sec": 171009.52616354157, "forward_time_ms": 33.59484672546387, "backward_time_ms": 38.804054260253906, "grad_norm_total": 2.1067503242747905, "grad_norm_embedding": 1.2421875, "grad_norm_layers": 1.7015103973428098, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 900, "step_time_ms": 77.14295387268066, "total_time_s": 84.41894865036011, "loss": 1.9440908873081206, "perplexity": 6.987276744744638, "lr": 0.0003, "tokens_seen": 14745600, "tokens_per_sec": 174672.8501341513, "forward_time_ms": 32.793521881103516, "backward_time_ms": 37.38594055175781, "grad_norm_total": 2.031857489792701, "grad_norm_embedding": 1.1796875, "grad_norm_layers": 1.654245573113079, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
{"type": "step", "step": 1000, "step_time_ms": 79.16426658630371, "total_time_s": 92.18052268028259, "loss": 1.7337377727031709, "perplexity": 5.661776842406022, "lr": 0.0003, "tokens_seen": 16384000, "tokens_per_sec": 177739.52803205705, "forward_time_ms": 33.65015983581543, "backward_time_ms": 38.64693641662598, "grad_norm_total": 1.9555267182322078, "grad_norm_embedding": 1.171875, "grad_norm_layers": 1.565419393375887, "grad_norm_head": 0, "memory_allocated_mb": 177.26220703125, "memory_reserved_mb": 1214.0, "memory_max_allocated_mb": 1104.32470703125}
