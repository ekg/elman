# Job 0: E75h8n32
# GPU: 0
# Command: python train.py --level E75h8n32 --dim 1024 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/E75h8n32
# Started: 2026-01-19T20:18:01.028595
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/E75h8n32/levelE75h8n32_100m_20260119_201806
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h8n32, 89,417,728 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.7249 | lr 2.70e-05 | grad 294.00 | tok/s 22888
step     20 | loss 5.5427 | lr 5.70e-05 | grad 54.50 | tok/s 66254
step     30 | loss 5.3855 | lr 8.70e-05 | grad 28.62 | tok/s 69902
step     40 | loss 4.7901 | lr 1.17e-04 | grad 10.19 | tok/s 69960
step     50 | loss 4.0773 | lr 1.47e-04 | grad 4.97 | tok/s 69501
step     60 | loss 3.7863 | lr 1.77e-04 | grad 11.56 | tok/s 68037
step     70 | loss 3.2206 | lr 2.07e-04 | grad 9.25 | tok/s 65625
step     80 | loss 3.3815 | lr 2.37e-04 | grad 2.72 | tok/s 67917
step     90 | loss 3.0960 | lr 2.67e-04 | grad 3.62 | tok/s 65430
step    100 | loss 2.7452 | lr 2.97e-04 | grad 1.52 | tok/s 65777
step    110 | loss 2.7497 | lr 6.94e-06 | grad 2.36 | tok/s 60497
step    120 | loss 3.0174 | lr 2.69e-05 | grad 2.09 | tok/s 60433
step    130 | loss 2.8095 | lr 5.89e-05 | grad 1.62 | tok/s 61667
step    140 | loss 2.5667 | lr 9.99e-05 | grad 1.13 | tok/s 61701
step    150 | loss 2.4440 | lr 1.46e-04 | grad 4.00 | tok/s 59018
step    160 | loss 2.3210 | lr 1.92e-04 | grad 1.76 | tok/s 59361
step    170 | loss 2.5107 | lr 2.35e-04 | grad 5.97 | tok/s 61204
step    180 | loss 2.5393 | lr 2.69e-04 | grad 1.40 | tok/s 61243
step    190 | loss 2.2679 | lr 2.91e-04 | grad 1.59 | tok/s 62172
step    200 | loss 1.9415 | lr 3.00e-04 | grad 1.44 | tok/s 63418
step    210 | loss 2.4436 | lr 2.94e-04 | grad 2.20 | tok/s 60751
step    220 | loss 2.3870 | lr 2.74e-04 | grad 1.16 | tok/s 62584
step    230 | loss 2.1942 | lr 2.42e-04 | grad 1.59 | tok/s 60371
step    240 | loss 2.2111 | lr 2.01e-04 | grad 1.95 | tok/s 61486
step    250 | loss 2.1548 | lr 1.55e-04 | grad 1.30 | tok/s 60554
step    260 | loss 2.1771 | lr 1.09e-04 | grad 0.74 | tok/s 58152
step    270 | loss 2.0388 | lr 6.65e-05 | grad 1.04 | tok/s 60218
step    280 | loss 1.9567 | lr 3.24e-05 | grad 1.77 | tok/s 60178
step    290 | loss 1.9347 | lr 9.84e-06 | grad 0.82 | tok/s 63310
step    300 | loss 1.9088 | lr 1.07e-06 | grad 0.82 | tok/s 63531
step    310 | loss 1.9118 | lr 6.94e-06 | grad 0.73 | tok/s 63226
step    320 | loss 2.0097 | lr 2.69e-05 | grad 1.95 | tok/s 61306
step    330 | loss 2.0439 | lr 5.89e-05 | grad 0.68 | tok/s 59620
step    340 | loss 2.0567 | lr 9.99e-05 | grad 2.19 | tok/s 60553
step    350 | loss 2.0777 | lr 1.46e-04 | grad 0.98 | tok/s 58866
step    360 | loss 2.0413 | lr 1.92e-04 | grad 2.38 | tok/s 59524
step    370 | loss 1.8830 | lr 2.35e-04 | grad 1.34 | tok/s 60677
step    380 | loss 2.4029 | lr 2.69e-04 | grad 1.22 | tok/s 62249
step    390 | loss 2.0130 | lr 2.91e-04 | grad 1.65 | tok/s 59960
step    400 | loss 2.1358 | lr 3.00e-04 | grad 2.73 | tok/s 61508
step    410 | loss 1.8884 | lr 2.94e-04 | grad 1.76 | tok/s 59647
step    420 | loss 2.0038 | lr 2.74e-04 | grad 1.11 | tok/s 59116
step    430 | loss 2.1329 | lr 2.42e-04 | grad 1.20 | tok/s 59033
step    440 | loss 2.1976 | lr 2.01e-04 | grad 0.91 | tok/s 61394
step    450 | loss 1.9229 | lr 1.55e-04 | grad 0.79 | tok/s 59702
step    460 | loss 1.8974 | lr 1.09e-04 | grad 0.68 | tok/s 59913
step    470 | loss 1.8706 | lr 6.65e-05 | grad 1.02 | tok/s 60661
step    480 | loss 1.7865 | lr 3.24e-05 | grad 0.60 | tok/s 58487
step    490 | loss 1.7412 | lr 9.84e-06 | grad 0.54 | tok/s 59577
step    500 | loss 2.6694 | lr 1.07e-06 | grad 0.97 | tok/s 61422
step    510 | loss 1.8004 | lr 6.94e-06 | grad 0.66 | tok/s 60035
step    520 | loss 1.8622 | lr 2.69e-05 | grad 0.54 | tok/s 61927
step    530 | loss 2.3049 | lr 5.89e-05 | grad 0.58 | tok/s 60657
step    540 | loss 1.7809 | lr 9.99e-05 | grad 1.02 | tok/s 60597
step    550 | loss 1.6649 | lr 1.46e-04 | grad 0.70 | tok/s 62270
step    560 | loss 1.5229 | lr 1.92e-04 | grad 0.70 | tok/s 63151
step    570 | loss 1.8033 | lr 2.35e-04 | grad 1.77 | tok/s 61702
step    580 | loss 2.1535 | lr 2.69e-04 | grad 1.09 | tok/s 60868
step    590 | loss 2.4222 | lr 2.91e-04 | grad 1.55 | tok/s 59622
step    600 | loss 1.9751 | lr 3.00e-04 | grad 1.28 | tok/s 59736
step    610 | loss 1.9495 | lr 2.94e-04 | grad 1.06 | tok/s 62724
step    620 | loss 1.8539 | lr 2.74e-04 | grad 0.82 | tok/s 59458
step    630 | loss 1.7730 | lr 2.42e-04 | grad 0.87 | tok/s 61335
step    640 | loss 2.0648 | lr 2.01e-04 | grad 0.80 | tok/s 61386
step    650 | loss 1.7810 | lr 1.55e-04 | grad 0.97 | tok/s 60233
step    660 | loss 2.1009 | lr 1.09e-04 | grad 4.31 | tok/s 59457
step    670 | loss 1.9142 | lr 6.65e-05 | grad 1.55 | tok/s 61503
step    680 | loss 1.8618 | lr 3.24e-05 | grad 1.00 | tok/s 59362
step    690 | loss 1.8670 | lr 9.84e-06 | grad 1.04 | tok/s 59841
step    700 | loss 1.9691 | lr 1.07e-06 | grad 1.20 | tok/s 60159
step    710 | loss 1.9095 | lr 6.94e-06 | grad 0.99 | tok/s 60456
step    720 | loss 2.0028 | lr 2.68e-05 | grad 1.41 | tok/s 60218
step    730 | loss 1.9573 | lr 5.89e-05 | grad 1.05 | tok/s 60816
step    740 | loss 1.8943 | lr 9.99e-05 | grad 1.64 | tok/s 60293
step    750 | loss 1.6890 | lr 1.46e-04 | grad 1.23 | tok/s 59565
step    760 | loss 2.1505 | lr 1.92e-04 | grad 0.67 | tok/s 60291
step    770 | loss 1.7506 | lr 2.35e-04 | grad 1.10 | tok/s 59953
step    780 | loss 1.8201 | lr 2.69e-04 | grad 1.16 | tok/s 60609
step    790 | loss 1.7292 | lr 2.91e-04 | grad 0.75 | tok/s 61144
step    800 | loss 1.7120 | lr 3.00e-04 | grad 0.96 | tok/s 61153
step    810 | loss 1.8031 | lr 2.94e-04 | grad 1.73 | tok/s 60545
step    820 | loss 2.5220 | lr 2.74e-04 | grad 1.29 | tok/s 62135
step    830 | loss 1.9812 | lr 2.42e-04 | grad 0.69 | tok/s 63148
step    840 | loss 1.6911 | lr 2.01e-04 | grad 0.54 | tok/s 63160
step    850 | loss 2.2037 | lr 1.55e-04 | grad 1.24 | tok/s 59963
step    860 | loss 1.8978 | lr 1.09e-04 | grad 0.97 | tok/s 58319
step    870 | loss 1.7919 | lr 6.65e-05 | grad 0.73 | tok/s 60145
step    880 | loss 1.8719 | lr 3.24e-05 | grad 1.09 | tok/s 59954
step    890 | loss 1.7608 | lr 9.84e-06 | grad 0.77 | tok/s 59928
step    900 | loss 2.2294 | lr 1.07e-06 | grad 0.77 | tok/s 58428
step    910 | loss 1.8065 | lr 6.94e-06 | grad 0.63 | tok/s 59422
step    920 | loss 1.7912 | lr 2.68e-05 | grad 0.67 | tok/s 59467
step    930 | loss 1.9064 | lr 5.89e-05 | grad 1.31 | tok/s 59014
step    940 | loss 1.7912 | lr 9.99e-05 | grad 1.27 | tok/s 58418
step    950 | loss 1.8728 | lr 1.46e-04 | grad 1.15 | tok/s 60182
step    960 | loss 1.6245 | lr 1.92e-04 | grad 0.59 | tok/s 62729
step    970 | loss 1.4261 | lr 2.35e-04 | grad 0.53 | tok/s 62712
step    980 | loss 1.5829 | lr 2.69e-04 | grad 1.52 | tok/s 60928
step    990 | loss 1.9305 | lr 2.91e-04 | grad 0.73 | tok/s 59506
step   1000 | loss 1.7985 | lr 3.00e-04 | grad 0.57 | tok/s 57855
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7985.pt
step   1010 | loss 2.0524 | lr 2.94e-04 | grad 2.27 | tok/s 47726
step   1020 | loss 1.6846 | lr 2.74e-04 | grad 0.79 | tok/s 59823
step   1030 | loss 2.0683 | lr 2.42e-04 | grad 0.73 | tok/s 58791
step   1040 | loss 1.6842 | lr 2.01e-04 | grad 1.10 | tok/s 60045
step   1050 | loss 1.7088 | lr 1.55e-04 | grad 0.71 | tok/s 59872
step   1060 | loss 1.9046 | lr 1.09e-04 | grad 1.13 | tok/s 60148
step   1070 | loss 1.9601 | lr 6.65e-05 | grad 0.73 | tok/s 60407
step   1080 | loss 2.3803 | lr 3.24e-05 | grad 0.91 | tok/s 59770
step   1090 | loss 2.0627 | lr 9.84e-06 | grad 0.75 | tok/s 59914
step   1100 | loss 1.7230 | lr 1.07e-06 | grad 0.68 | tok/s 59936
step   1110 | loss 1.7514 | lr 6.93e-06 | grad 0.67 | tok/s 60901
step   1120 | loss 1.9549 | lr 2.68e-05 | grad 0.76 | tok/s 61293
step   1130 | loss 1.7353 | lr 5.89e-05 | grad 0.55 | tok/s 58562
step   1140 | loss 1.6015 | lr 9.99e-05 | grad 0.59 | tok/s 60049
step   1150 | loss 1.8890 | lr 1.46e-04 | grad 0.95 | tok/s 59650
step   1160 | loss 1.5680 | lr 1.92e-04 | grad 0.53 | tok/s 59311
step   1170 | loss 1.9083 | lr 2.35e-04 | grad 0.74 | tok/s 60044
step   1180 | loss 1.6052 | lr 2.69e-04 | grad 0.60 | tok/s 63062
step   1190 | loss 1.4571 | lr 2.91e-04 | grad 0.61 | tok/s 62737
step   1200 | loss 1.3719 | lr 3.00e-04 | grad 0.56 | tok/s 62733
step   1210 | loss 1.3407 | lr 2.94e-04 | grad 0.62 | tok/s 62731
step   1220 | loss 1.3893 | lr 2.74e-04 | grad 0.73 | tok/s 62266
step   1230 | loss 1.6177 | lr 2.42e-04 | grad 0.75 | tok/s 60165
step   1240 | loss 1.6683 | lr 2.01e-04 | grad 0.70 | tok/s 59119
step   1250 | loss 1.8025 | lr 1.55e-04 | grad 2.64 | tok/s 60818
step   1260 | loss 1.8106 | lr 1.09e-04 | grad 2.03 | tok/s 60667
step   1270 | loss 1.8828 | lr 6.65e-05 | grad 1.12 | tok/s 59889
step   1280 | loss 1.7023 | lr 3.24e-05 | grad 0.68 | tok/s 59575
step   1290 | loss 1.6563 | lr 9.84e-06 | grad 0.81 | tok/s 59048
step   1300 | loss 1.7027 | lr 1.07e-06 | grad 0.69 | tok/s 58834
step   1310 | loss 1.7772 | lr 6.93e-06 | grad 0.68 | tok/s 58618
step   1320 | loss 1.7603 | lr 2.68e-05 | grad 0.95 | tok/s 59690
step   1330 | loss 1.6856 | lr 5.89e-05 | grad 0.52 | tok/s 60019
step   1340 | loss 1.6015 | lr 9.99e-05 | grad 0.80 | tok/s 59822
step   1350 | loss 1.6539 | lr 1.46e-04 | grad 1.39 | tok/s 61638
step   1360 | loss 1.5822 | lr 1.92e-04 | grad 0.69 | tok/s 58531
step   1370 | loss 1.6948 | lr 2.35e-04 | grad 0.71 | tok/s 59278
step   1380 | loss 1.7844 | lr 2.69e-04 | grad 0.79 | tok/s 59853
step   1390 | loss 1.6967 | lr 2.91e-04 | grad 1.30 | tok/s 58272
step   1400 | loss 1.7023 | lr 3.00e-04 | grad 4.75 | tok/s 60966
step   1410 | loss 1.7168 | lr 2.94e-04 | grad 0.99 | tok/s 61497
step   1420 | loss 1.7946 | lr 2.74e-04 | grad 0.79 | tok/s 58472
step   1430 | loss 1.5822 | lr 2.42e-04 | grad 1.16 | tok/s 56863
step   1440 | loss 1.5014 | lr 2.01e-04 | grad 0.60 | tok/s 60247
step   1450 | loss 1.5452 | lr 1.55e-04 | grad 1.55 | tok/s 61348
step   1460 | loss 1.6223 | lr 1.09e-04 | grad 0.52 | tok/s 57221
step   1470 | loss 1.7160 | lr 6.65e-05 | grad 2.14 | tok/s 58212
step   1480 | loss 1.5760 | lr 3.24e-05 | grad 1.40 | tok/s 59174
step   1490 | loss 1.7665 | lr 9.84e-06 | grad 1.85 | tok/s 59043
step   1500 | loss 1.8438 | lr 1.07e-06 | grad 1.78 | tok/s 57537
step   1510 | loss 1.7204 | lr 6.93e-06 | grad 0.87 | tok/s 60575
step   1520 | loss 1.6805 | lr 2.68e-05 | grad 0.97 | tok/s 60230
step   1530 | loss 1.6304 | lr 5.89e-05 | grad 0.50 | tok/s 60196
step   1540 | loss 1.6091 | lr 9.99e-05 | grad 0.47 | tok/s 59156
step   1550 | loss 1.6023 | lr 1.46e-04 | grad 2.38 | tok/s 61449
step   1560 | loss 2.1787 | lr 1.92e-04 | grad 0.96 | tok/s 59895
step   1570 | loss 1.6213 | lr 2.35e-04 | grad 0.97 | tok/s 59068
step   1580 | loss 1.7959 | lr 2.69e-04 | grad 0.92 | tok/s 61028
step   1590 | loss 1.6222 | lr 2.91e-04 | grad 0.68 | tok/s 59530
step   1600 | loss 1.6869 | lr 3.00e-04 | grad 0.80 | tok/s 58054
step   1610 | loss 1.5308 | lr 2.94e-04 | grad 0.66 | tok/s 61850
step   1620 | loss 1.6893 | lr 2.74e-04 | grad 0.55 | tok/s 60911
step   1630 | loss 1.6916 | lr 2.42e-04 | grad 0.66 | tok/s 61427
step   1640 | loss 1.5943 | lr 2.01e-04 | grad 0.52 | tok/s 59237
step   1650 | loss 1.6118 | lr 1.55e-04 | grad 0.95 | tok/s 58073
step   1660 | loss 1.6136 | lr 1.09e-04 | grad 0.56 | tok/s 58707
step   1670 | loss 1.6647 | lr 6.65e-05 | grad 1.68 | tok/s 61127
step   1680 | loss 2.0164 | lr 3.24e-05 | grad 0.45 | tok/s 61106
step   1690 | loss 1.5911 | lr 9.84e-06 | grad 0.80 | tok/s 59674
step   1700 | loss 1.9833 | lr 1.07e-06 | grad 0.46 | tok/s 60796
step   1710 | loss 1.6324 | lr 6.93e-06 | grad 0.77 | tok/s 59078
step   1720 | loss 1.6404 | lr 2.68e-05 | grad 0.66 | tok/s 59568
step   1730 | loss 1.7397 | lr 5.89e-05 | grad 0.72 | tok/s 59641
step   1740 | loss 1.6434 | lr 9.99e-05 | grad 0.55 | tok/s 60196
step   1750 | loss 1.5470 | lr 1.46e-04 | grad 0.47 | tok/s 58395
step   1760 | loss 1.8158 | lr 1.92e-04 | grad 0.61 | tok/s 59151
step   1770 | loss 1.7160 | lr 2.35e-04 | grad 0.52 | tok/s 60316
step   1780 | loss 1.5982 | lr 2.69e-04 | grad 0.87 | tok/s 58103
step   1790 | loss 1.7979 | lr 2.91e-04 | grad 0.65 | tok/s 59044
step   1800 | loss 1.5446 | lr 3.00e-04 | grad 0.58 | tok/s 60103
step   1810 | loss 1.6394 | lr 2.94e-04 | grad 0.80 | tok/s 60069
step   1820 | loss 1.5943 | lr 2.74e-04 | grad 0.68 | tok/s 59466
step   1830 | loss 1.6200 | lr 2.42e-04 | grad 0.63 | tok/s 59277
step   1840 | loss 1.5941 | lr 2.01e-04 | grad 0.77 | tok/s 58469
step   1850 | loss 1.8112 | lr 1.55e-04 | grad 0.83 | tok/s 59026
step   1860 | loss 1.5628 | lr 1.09e-04 | grad 0.46 | tok/s 58996
step   1870 | loss 1.6113 | lr 6.65e-05 | grad 1.09 | tok/s 60264
step   1880 | loss 1.5671 | lr 3.24e-05 | grad 0.50 | tok/s 60275
step   1890 | loss 1.6489 | lr 9.84e-06 | grad 0.50 | tok/s 59261
step   1900 | loss 1.6909 | lr 1.07e-06 | grad 1.23 | tok/s 59834
step   1910 | loss 1.6690 | lr 6.93e-06 | grad 1.07 | tok/s 59122
step   1920 | loss 1.5778 | lr 2.68e-05 | grad 0.80 | tok/s 60923
step   1930 | loss 1.5689 | lr 5.89e-05 | grad 0.76 | tok/s 60458
step   1940 | loss 1.4926 | lr 9.99e-05 | grad 0.59 | tok/s 61933
step   1950 | loss 1.5467 | lr 1.46e-04 | grad 0.74 | tok/s 60402
step   1960 | loss 1.9370 | lr 1.92e-04 | grad 3.69 | tok/s 61618
step   1970 | loss 1.6125 | lr 2.35e-04 | grad 1.21 | tok/s 59513
step   1980 | loss 1.6519 | lr 2.69e-04 | grad 1.62 | tok/s 59399
step   1990 | loss 1.7457 | lr 2.91e-04 | grad 0.92 | tok/s 60837
step   2000 | loss 1.6770 | lr 3.00e-04 | grad 1.08 | tok/s 61365
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6770.pt
step   2010 | loss 1.4174 | lr 2.94e-04 | grad 0.55 | tok/s 48041
step   2020 | loss 1.2612 | lr 2.74e-04 | grad 0.49 | tok/s 63110
step   2030 | loss 1.5840 | lr 2.42e-04 | grad 0.80 | tok/s 62496
step   2040 | loss 1.4100 | lr 2.01e-04 | grad 0.45 | tok/s 63132
step   2050 | loss 1.3621 | lr 1.55e-04 | grad 0.72 | tok/s 62256
step   2060 | loss 1.6928 | lr 1.09e-04 | grad 0.60 | tok/s 59448
step   2070 | loss 1.6195 | lr 6.65e-05 | grad 0.97 | tok/s 62409
step   2080 | loss 1.7500 | lr 3.24e-05 | grad 2.64 | tok/s 59017
step   2090 | loss 1.6743 | lr 9.84e-06 | grad 0.76 | tok/s 61155
step   2100 | loss 1.6324 | lr 1.07e-06 | grad 0.79 | tok/s 59348
step   2110 | loss 1.5023 | lr 6.93e-06 | grad 0.58 | tok/s 61370
step   2120 | loss 1.5089 | lr 2.68e-05 | grad 0.99 | tok/s 60778
step   2130 | loss 1.6093 | lr 5.89e-05 | grad 1.89 | tok/s 59058
step   2140 | loss 1.6717 | lr 9.99e-05 | grad 2.31 | tok/s 59000
step   2150 | loss 1.6689 | lr 1.46e-04 | grad 0.47 | tok/s 59881
step   2160 | loss 1.6237 | lr 1.92e-04 | grad 0.52 | tok/s 59169
step   2170 | loss 1.7327 | lr 2.35e-04 | grad 0.64 | tok/s 59903
step   2180 | loss 1.5845 | lr 2.69e-04 | grad 0.65 | tok/s 61122
step   2190 | loss 1.8756 | lr 2.91e-04 | grad 0.66 | tok/s 60978
step   2200 | loss 1.3530 | lr 3.00e-04 | grad 0.49 | tok/s 63112
step   2210 | loss 1.3201 | lr 2.94e-04 | grad 0.42 | tok/s 63169
step   2220 | loss 1.2744 | lr 2.74e-04 | grad 0.45 | tok/s 63133
step   2230 | loss 1.5336 | lr 2.42e-04 | grad 0.67 | tok/s 60984
step   2240 | loss 1.7740 | lr 2.01e-04 | grad 1.55 | tok/s 62316
step   2250 | loss 1.6750 | lr 1.55e-04 | grad 0.81 | tok/s 61808
step   2260 | loss 1.7265 | lr 1.09e-04 | grad 0.68 | tok/s 60927
step   2270 | loss 1.5483 | lr 6.65e-05 | grad 0.81 | tok/s 59637
step   2280 | loss 1.7027 | lr 3.24e-05 | grad 0.52 | tok/s 59574
step   2290 | loss 1.5276 | lr 9.84e-06 | grad 0.60 | tok/s 60331

Training complete! Final step: 2292
