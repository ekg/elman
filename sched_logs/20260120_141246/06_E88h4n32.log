# Job 6: E88h4n32
# GPU: 6
# Command: python train.py --level E88h4n32 --dim 1024 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/e88_100m/E88h4n32
# Started: 2026-01-20T14:12:46.618147
============================================================

Using device: cuda
Output directory: benchmark_results/e88_100m/E88h4n32/levelE88h4n32_100m_20260120_141252
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88h4n32, 21,379,488 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.7458 | lr 2.70e-05 | grad 384.00 | tok/s 277

Training complete! Final step: 11
