# Job 6: E75h8n24
# GPU: 6
# Command: python train.py --level E75h8n24 --dim 1152 --depth 20 --n_state 24 --expansion 2.0 --data data/pile.txt --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/e75_exp2_20260119/E75h8n24
# Started: 2026-01-19T18:58:55.101600
============================================================

Using device: cuda
Output directory: benchmark_results/e75_exp2_20260119/E75h8n24/levelE75h8n24_100m_20260119_185901
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h8n24, 93,220,224 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.6204 | lr 2.70e-05 | grad 72.50 | tok/s 24170
step     20 | loss 5.2638 | lr 5.70e-05 | grad 45.75 | tok/s 75041
step     30 | loss 5.3030 | lr 8.70e-05 | grad 24.00 | tok/s 79235
step     40 | loss 4.7711 | lr 1.17e-04 | grad 8.81 | tok/s 79149
step     50 | loss 4.0923 | lr 1.47e-04 | grad 4.56 | tok/s 78882
step     60 | loss 3.6978 | lr 1.77e-04 | grad 13.00 | tok/s 76540
step     70 | loss 3.2158 | lr 2.07e-04 | grad 3.44 | tok/s 74416
step     80 | loss 3.3199 | lr 2.37e-04 | grad 4.22 | tok/s 77285
step     90 | loss 3.0641 | lr 2.67e-04 | grad 3.84 | tok/s 74626
step    100 | loss 2.7464 | lr 2.97e-04 | grad 1.89 | tok/s 75268
step    110 | loss 2.7085 | lr 6.94e-06 | grad 2.14 | tok/s 67976
step    120 | loss 2.9950 | lr 2.69e-05 | grad 1.63 | tok/s 67966
step    130 | loss 2.8009 | lr 5.89e-05 | grad 1.38 | tok/s 69676
step    140 | loss 2.5652 | lr 9.99e-05 | grad 1.40 | tok/s 69694
step    150 | loss 2.4435 | lr 1.46e-04 | grad 2.28 | tok/s 66165
step    160 | loss 2.3246 | lr 1.92e-04 | grad 1.80 | tok/s 66299
step    170 | loss 2.5031 | lr 2.35e-04 | grad 5.12 | tok/s 68385
step    180 | loss 2.5497 | lr 2.69e-04 | grad 2.03 | tok/s 68595
step    190 | loss 2.2633 | lr 2.91e-04 | grad 1.53 | tok/s 69938
step    200 | loss 1.9266 | lr 3.00e-04 | grad 1.36 | tok/s 71888
step    210 | loss 2.4437 | lr 2.94e-04 | grad 2.12 | tok/s 68779
step    220 | loss 2.3416 | lr 2.74e-04 | grad 1.00 | tok/s 70790
step    230 | loss 2.1870 | lr 2.42e-04 | grad 1.67 | tok/s 68321
step    240 | loss 2.1976 | lr 2.01e-04 | grad 1.69 | tok/s 69566
step    250 | loss 2.1464 | lr 1.55e-04 | grad 1.24 | tok/s 68432
step    260 | loss 2.1700 | lr 1.09e-04 | grad 0.76 | tok/s 65774
step    270 | loss 2.0391 | lr 6.65e-05 | grad 1.89 | tok/s 68244
step    280 | loss 1.9581 | lr 3.24e-05 | grad 1.63 | tok/s 68321
step    290 | loss 1.9295 | lr 9.84e-06 | grad 0.84 | tok/s 71846
step    300 | loss 1.8990 | lr 1.07e-06 | grad 0.83 | tok/s 71444
step    310 | loss 1.9013 | lr 6.94e-06 | grad 0.73 | tok/s 71595
step    320 | loss 1.9983 | lr 2.69e-05 | grad 1.74 | tok/s 68769
step    330 | loss 2.0469 | lr 5.89e-05 | grad 0.70 | tok/s 67031
step    340 | loss 2.0433 | lr 9.99e-05 | grad 1.77 | tok/s 68459
step    350 | loss 2.0666 | lr 1.46e-04 | grad 0.96 | tok/s 66540
step    360 | loss 2.0226 | lr 1.92e-04 | grad 2.33 | tok/s 67173
step    370 | loss 1.8812 | lr 2.35e-04 | grad 1.25 | tok/s 68356
step    380 | loss 2.3769 | lr 2.69e-04 | grad 1.22 | tok/s 70008
step    390 | loss 2.0118 | lr 2.91e-04 | grad 1.27 | tok/s 67337
step    400 | loss 2.1279 | lr 3.00e-04 | grad 3.19 | tok/s 69132
step    410 | loss 1.8669 | lr 2.94e-04 | grad 1.76 | tok/s 67135
step    420 | loss 1.9891 | lr 2.74e-04 | grad 1.20 | tok/s 66612
step    430 | loss 2.1435 | lr 2.42e-04 | grad 1.33 | tok/s 66239
step    440 | loss 2.2156 | lr 2.01e-04 | grad 1.02 | tok/s 68675
step    450 | loss 1.9180 | lr 1.55e-04 | grad 0.87 | tok/s 66896
step    460 | loss 1.9060 | lr 1.09e-04 | grad 0.64 | tok/s 67411
step    470 | loss 1.8733 | lr 6.65e-05 | grad 0.94 | tok/s 67871
step    480 | loss 1.7789 | lr 3.24e-05 | grad 0.59 | tok/s 65518
step    490 | loss 1.7376 | lr 9.84e-06 | grad 0.52 | tok/s 66741
step    500 | loss 2.6840 | lr 1.07e-06 | grad 0.90 | tok/s 68605
step    510 | loss 1.8113 | lr 6.94e-06 | grad 0.63 | tok/s 67348
step    520 | loss 1.8535 | lr 2.69e-05 | grad 0.53 | tok/s 69402
step    530 | loss 2.3221 | lr 5.89e-05 | grad 0.58 | tok/s 67804
step    540 | loss 1.7832 | lr 9.99e-05 | grad 1.00 | tok/s 67819
step    550 | loss 1.6551 | lr 1.46e-04 | grad 0.68 | tok/s 69481
step    560 | loss 1.5159 | lr 1.92e-04 | grad 0.71 | tok/s 70463
step    570 | loss 1.7982 | lr 2.35e-04 | grad 1.89 | tok/s 68849
step    580 | loss 2.1612 | lr 2.69e-04 | grad 0.96 | tok/s 67991
step    590 | loss 2.4133 | lr 2.91e-04 | grad 2.00 | tok/s 66546
step    600 | loss 1.9540 | lr 3.00e-04 | grad 1.38 | tok/s 66730
step    610 | loss 1.9392 | lr 2.94e-04 | grad 1.23 | tok/s 69835
step    620 | loss 1.8732 | lr 2.74e-04 | grad 0.86 | tok/s 66383
step    630 | loss 1.7689 | lr 2.42e-04 | grad 0.89 | tok/s 68441
step    640 | loss 2.1134 | lr 2.01e-04 | grad 0.78 | tok/s 68430
step    650 | loss 1.7832 | lr 1.55e-04 | grad 1.02 | tok/s 67101
step    660 | loss 2.1098 | lr 1.09e-04 | grad 4.25 | tok/s 66240
step    670 | loss 1.9215 | lr 6.65e-05 | grad 1.63 | tok/s 68532
step    680 | loss 1.8748 | lr 3.24e-05 | grad 1.00 | tok/s 66092
step    690 | loss 1.8749 | lr 9.84e-06 | grad 1.09 | tok/s 66616
step    700 | loss 1.9603 | lr 1.07e-06 | grad 1.16 | tok/s 67099
step    710 | loss 1.8934 | lr 6.94e-06 | grad 1.00 | tok/s 67388
step    720 | loss 2.0040 | lr 2.68e-05 | grad 1.32 | tok/s 67070
step    730 | loss 1.9582 | lr 5.89e-05 | grad 1.05 | tok/s 67743
step    740 | loss 1.8955 | lr 9.99e-05 | grad 1.87 | tok/s 67108
step    750 | loss 1.6987 | lr 1.46e-04 | grad 1.23 | tok/s 66307
step    760 | loss 2.1336 | lr 1.92e-04 | grad 0.65 | tok/s 67138
step    770 | loss 1.7579 | lr 2.35e-04 | grad 1.05 | tok/s 66805
step    780 | loss 1.8140 | lr 2.69e-04 | grad 1.05 | tok/s 67557
step    790 | loss 1.7401 | lr 2.91e-04 | grad 0.71 | tok/s 67976
step    800 | loss 1.7138 | lr 3.00e-04 | grad 0.98 | tok/s 68062
step    810 | loss 1.8201 | lr 2.94e-04 | grad 1.73 | tok/s 67564
step    820 | loss 2.5090 | lr 2.74e-04 | grad 1.44 | tok/s 69147
step    830 | loss 1.9879 | lr 2.42e-04 | grad 0.68 | tok/s 70263
step    840 | loss 1.6778 | lr 2.01e-04 | grad 0.50 | tok/s 70115
step    850 | loss 2.1945 | lr 1.55e-04 | grad 1.23 | tok/s 66760
step    860 | loss 1.9004 | lr 1.09e-04 | grad 0.99 | tok/s 65513
step    870 | loss 1.8262 | lr 6.65e-05 | grad 0.71 | tok/s 67546
step    880 | loss 1.8867 | lr 3.24e-05 | grad 1.06 | tok/s 67187
step    890 | loss 1.7694 | lr 9.84e-06 | grad 0.75 | tok/s 67023
step    900 | loss 2.2901 | lr 1.07e-06 | grad 0.87 | tok/s 65334
step    910 | loss 1.8746 | lr 6.94e-06 | grad 0.61 | tok/s 66621
step    920 | loss 1.8008 | lr 2.68e-05 | grad 0.65 | tok/s 66371
step    930 | loss 1.9259 | lr 5.89e-05 | grad 1.25 | tok/s 66149
step    940 | loss 1.8077 | lr 9.99e-05 | grad 1.35 | tok/s 65516
step    950 | loss 1.9076 | lr 1.46e-04 | grad 1.09 | tok/s 67086
step    960 | loss 1.6201 | lr 1.92e-04 | grad 0.61 | tok/s 70087
step    970 | loss 1.4288 | lr 2.35e-04 | grad 0.46 | tok/s 70161
step    980 | loss 1.6037 | lr 2.69e-04 | grad 1.91 | tok/s 68112
step    990 | loss 1.9679 | lr 2.91e-04 | grad 0.69 | tok/s 66463
step   1000 | loss 1.7984 | lr 3.00e-04 | grad 0.57 | tok/s 64772
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7984.pt
step   1010 | loss 2.0519 | lr 2.94e-04 | grad 2.58 | tok/s 54157
step   1020 | loss 1.6780 | lr 2.74e-04 | grad 0.71 | tok/s 66461
step   1030 | loss 2.0432 | lr 2.42e-04 | grad 0.78 | tok/s 65458
step   1040 | loss 1.6906 | lr 2.01e-04 | grad 1.08 | tok/s 66846
step   1050 | loss 1.7231 | lr 1.55e-04 | grad 0.68 | tok/s 67171
step   1060 | loss 1.9226 | lr 1.09e-04 | grad 1.34 | tok/s 67099
step   1070 | loss 1.9850 | lr 6.65e-05 | grad 0.74 | tok/s 67378
step   1080 | loss 2.3726 | lr 3.24e-05 | grad 0.91 | tok/s 66542
step   1090 | loss 2.0679 | lr 9.84e-06 | grad 0.73 | tok/s 67074
step   1100 | loss 1.7366 | lr 1.07e-06 | grad 0.67 | tok/s 66625
step   1110 | loss 1.7861 | lr 6.93e-06 | grad 0.72 | tok/s 67697
step   1120 | loss 1.9601 | lr 2.68e-05 | grad 0.87 | tok/s 68507
step   1130 | loss 1.7450 | lr 5.89e-05 | grad 0.60 | tok/s 65284
step   1140 | loss 1.6154 | lr 9.99e-05 | grad 0.64 | tok/s 66882
step   1150 | loss 1.8998 | lr 1.46e-04 | grad 1.04 | tok/s 66756
step   1160 | loss 1.5752 | lr 1.92e-04 | grad 0.52 | tok/s 66156
step   1170 | loss 1.9253 | lr 2.35e-04 | grad 0.72 | tok/s 66840
step   1180 | loss 1.6091 | lr 2.69e-04 | grad 0.70 | tok/s 70088
step   1190 | loss 1.4604 | lr 2.91e-04 | grad 0.55 | tok/s 70060
step   1200 | loss 1.3749 | lr 3.00e-04 | grad 0.54 | tok/s 70010
step   1210 | loss 1.3448 | lr 2.94e-04 | grad 0.67 | tok/s 70113
step   1220 | loss 1.3962 | lr 2.74e-04 | grad 0.75 | tok/s 69409
step   1230 | loss 1.6985 | lr 2.42e-04 | grad 0.79 | tok/s 67253
step   1240 | loss 1.6801 | lr 2.01e-04 | grad 0.76 | tok/s 65943
step   1250 | loss 1.7727 | lr 1.55e-04 | grad 2.61 | tok/s 68008
step   1260 | loss 1.8325 | lr 1.09e-04 | grad 2.16 | tok/s 67882
step   1270 | loss 1.9035 | lr 6.65e-05 | grad 1.13 | tok/s 66978
step   1280 | loss 1.7267 | lr 3.24e-05 | grad 0.70 | tok/s 66301
step   1290 | loss 1.6588 | lr 9.84e-06 | grad 0.76 | tok/s 66115
step   1300 | loss 1.7159 | lr 1.07e-06 | grad 0.68 | tok/s 65594
step   1310 | loss 1.7899 | lr 6.93e-06 | grad 0.66 | tok/s 65583
step   1320 | loss 1.7726 | lr 2.68e-05 | grad 0.98 | tok/s 66731
step   1330 | loss 1.7004 | lr 5.89e-05 | grad 0.52 | tok/s 66932
step   1340 | loss 1.6116 | lr 9.99e-05 | grad 0.81 | tok/s 67112
step   1350 | loss 1.6696 | lr 1.46e-04 | grad 1.42 | tok/s 68779
step   1360 | loss 1.5979 | lr 1.92e-04 | grad 0.73 | tok/s 65358
step   1370 | loss 1.6997 | lr 2.35e-04 | grad 0.64 | tok/s 66353
step   1380 | loss 1.7935 | lr 2.69e-04 | grad 0.77 | tok/s 66796
step   1390 | loss 1.7061 | lr 2.91e-04 | grad 1.31 | tok/s 65118
step   1400 | loss 1.7311 | lr 3.00e-04 | grad 5.53 | tok/s 67724
step   1410 | loss 1.7300 | lr 2.94e-04 | grad 1.10 | tok/s 68305
step   1420 | loss 1.8105 | lr 2.74e-04 | grad 0.79 | tok/s 64627
step   1430 | loss 1.5951 | lr 2.42e-04 | grad 0.79 | tok/s 63572
step   1440 | loss 1.5120 | lr 2.01e-04 | grad 0.61 | tok/s 67118
step   1450 | loss 1.5650 | lr 1.55e-04 | grad 1.81 | tok/s 68506
step   1460 | loss 1.6248 | lr 1.09e-04 | grad 0.51 | tok/s 63871
step   1470 | loss 1.7297 | lr 6.65e-05 | grad 1.80 | tok/s 66166
step   1480 | loss 1.5921 | lr 3.24e-05 | grad 1.44 | tok/s 66873
step   1490 | loss 1.7688 | lr 9.84e-06 | grad 1.97 | tok/s 66664
step   1500 | loss 1.8636 | lr 1.07e-06 | grad 1.98 | tok/s 65407
step   1510 | loss 1.7378 | lr 6.93e-06 | grad 0.90 | tok/s 68669
step   1520 | loss 1.7023 | lr 2.68e-05 | grad 0.97 | tok/s 67859
step   1530 | loss 1.6459 | lr 5.89e-05 | grad 0.50 | tok/s 67330
step   1540 | loss 1.6222 | lr 9.99e-05 | grad 0.46 | tok/s 65932
step   1550 | loss 1.6017 | lr 1.46e-04 | grad 2.08 | tok/s 68205
step   1560 | loss 2.2147 | lr 1.92e-04 | grad 0.97 | tok/s 66139
step   1570 | loss 1.6345 | lr 2.35e-04 | grad 0.99 | tok/s 65055
step   1580 | loss 1.7853 | lr 2.69e-04 | grad 0.89 | tok/s 66381
step   1590 | loss 1.5875 | lr 2.91e-04 | grad 0.64 | tok/s 65428
step   1600 | loss 1.7069 | lr 3.00e-04 | grad 0.78 | tok/s 64175
step   1610 | loss 1.5457 | lr 2.94e-04 | grad 0.69 | tok/s 68339
step   1620 | loss 1.6926 | lr 2.74e-04 | grad 0.58 | tok/s 67140
step   1630 | loss 1.7097 | lr 2.42e-04 | grad 0.80 | tok/s 67611
step   1640 | loss 1.6136 | lr 2.01e-04 | grad 0.55 | tok/s 65559
step   1650 | loss 1.6364 | lr 1.55e-04 | grad 1.02 | tok/s 64918
step   1660 | loss 1.6239 | lr 1.09e-04 | grad 0.59 | tok/s 65238
step   1670 | loss 1.6754 | lr 6.65e-05 | grad 1.81 | tok/s 68086
step   1680 | loss 2.0555 | lr 3.24e-05 | grad 0.46 | tok/s 68106
step   1690 | loss 1.5994 | lr 9.84e-06 | grad 0.82 | tok/s 66456
step   1700 | loss 1.9967 | lr 1.07e-06 | grad 0.46 | tok/s 67877
step   1710 | loss 1.6462 | lr 6.93e-06 | grad 0.76 | tok/s 65968
step   1720 | loss 1.6500 | lr 2.68e-05 | grad 0.68 | tok/s 66330
step   1730 | loss 1.7561 | lr 5.89e-05 | grad 0.68 | tok/s 66155
step   1740 | loss 1.6607 | lr 9.99e-05 | grad 0.56 | tok/s 67060
step   1750 | loss 1.5570 | lr 1.46e-04 | grad 0.47 | tok/s 64740
step   1760 | loss 1.8245 | lr 1.92e-04 | grad 0.57 | tok/s 65637
step   1770 | loss 1.7224 | lr 2.35e-04 | grad 0.55 | tok/s 67089
step   1780 | loss 1.6150 | lr 2.69e-04 | grad 0.95 | tok/s 64833
step   1790 | loss 1.8174 | lr 2.91e-04 | grad 0.65 | tok/s 65824
step   1800 | loss 1.5536 | lr 3.00e-04 | grad 0.59 | tok/s 67154
step   1810 | loss 1.6577 | lr 2.94e-04 | grad 0.77 | tok/s 66808
step   1820 | loss 1.6075 | lr 2.74e-04 | grad 0.75 | tok/s 65657
step   1830 | loss 1.6538 | lr 2.42e-04 | grad 0.66 | tok/s 65398
step   1840 | loss 1.6040 | lr 2.01e-04 | grad 0.79 | tok/s 64868
step   1850 | loss 1.8221 | lr 1.55e-04 | grad 0.90 | tok/s 65212
step   1860 | loss 1.5805 | lr 1.09e-04 | grad 0.46 | tok/s 65419
step   1870 | loss 1.6335 | lr 6.65e-05 | grad 1.18 | tok/s 66836
step   1880 | loss 1.5753 | lr 3.24e-05 | grad 0.52 | tok/s 67054
step   1890 | loss 1.6672 | lr 9.84e-06 | grad 0.50 | tok/s 66047
step   1900 | loss 1.7372 | lr 1.07e-06 | grad 1.31 | tok/s 66531
step   1910 | loss 1.6839 | lr 6.93e-06 | grad 1.02 | tok/s 65409
step   1920 | loss 1.5992 | lr 2.68e-05 | grad 0.85 | tok/s 67804
step   1930 | loss 1.5802 | lr 5.89e-05 | grad 0.81 | tok/s 67026
step   1940 | loss 1.4985 | lr 9.99e-05 | grad 0.60 | tok/s 67819
step   1950 | loss 1.5611 | lr 1.46e-04 | grad 0.76 | tok/s 66097
step   1960 | loss 1.9561 | lr 1.92e-04 | grad 4.03 | tok/s 67700
step   1970 | loss 1.6233 | lr 2.35e-04 | grad 1.21 | tok/s 65321
step   1980 | loss 1.6631 | lr 2.69e-04 | grad 1.70 | tok/s 65241
step   1990 | loss 1.7642 | lr 2.91e-04 | grad 0.95 | tok/s 66794
step   2000 | loss 1.6932 | lr 3.00e-04 | grad 1.02 | tok/s 66967
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6932.pt
step   2010 | loss 1.4317 | lr 2.94e-04 | grad 0.57 | tok/s 50741
step   2020 | loss 1.2764 | lr 2.74e-04 | grad 0.54 | tok/s 68968
step   2030 | loss 1.6021 | lr 2.42e-04 | grad 0.76 | tok/s 68380
step   2040 | loss 1.4218 | lr 2.01e-04 | grad 0.45 | tok/s 69103
step   2050 | loss 1.3706 | lr 1.55e-04 | grad 0.75 | tok/s 68306
step   2060 | loss 1.6964 | lr 1.09e-04 | grad 0.62 | tok/s 65206
step   2070 | loss 1.6177 | lr 6.65e-05 | grad 1.01 | tok/s 68326
step   2080 | loss 1.7697 | lr 3.24e-05 | grad 3.00 | tok/s 64808
step   2090 | loss 1.6963 | lr 9.84e-06 | grad 0.78 | tok/s 67465
step   2100 | loss 1.6443 | lr 1.07e-06 | grad 0.82 | tok/s 65579
step   2110 | loss 1.5522 | lr 6.93e-06 | grad 0.60 | tok/s 67841
step   2120 | loss 1.5609 | lr 2.68e-05 | grad 1.04 | tok/s 67087
step   2130 | loss 1.6243 | lr 5.89e-05 | grad 2.38 | tok/s 65333
step   2140 | loss 1.6686 | lr 9.99e-05 | grad 2.31 | tok/s 64795
step   2150 | loss 1.6762 | lr 1.46e-04 | grad 0.50 | tok/s 66078
step   2160 | loss 1.6331 | lr 1.92e-04 | grad 0.52 | tok/s 65470
step   2170 | loss 1.7552 | lr 2.35e-04 | grad 0.67 | tok/s 66151
step   2180 | loss 1.5961 | lr 2.69e-04 | grad 0.69 | tok/s 67437
step   2190 | loss 1.9012 | lr 2.91e-04 | grad 0.68 | tok/s 67213
step   2200 | loss 1.3647 | lr 3.00e-04 | grad 0.46 | tok/s 69260
step   2210 | loss 1.3286 | lr 2.94e-04 | grad 0.44 | tok/s 69080
step   2220 | loss 1.2798 | lr 2.74e-04 | grad 0.46 | tok/s 69185
step   2230 | loss 1.5607 | lr 2.42e-04 | grad 0.74 | tok/s 67299
step   2240 | loss 1.8199 | lr 2.01e-04 | grad 1.28 | tok/s 68676
step   2250 | loss 1.6958 | lr 1.55e-04 | grad 0.80 | tok/s 68432
step   2260 | loss 1.7660 | lr 1.09e-04 | grad 0.75 | tok/s 67737
step   2270 | loss 1.5616 | lr 6.65e-05 | grad 0.81 | tok/s 66023
step   2280 | loss 1.7111 | lr 3.24e-05 | grad 0.55 | tok/s 65781
step   2290 | loss 1.5434 | lr 9.84e-06 | grad 0.61 | tok/s 66973
step   2300 | loss 1.5585 | lr 1.07e-06 | grad 0.52 | tok/s 64800
step   2310 | loss 1.6396 | lr 6.93e-06 | grad 0.88 | tok/s 69060
step   2320 | loss 1.7139 | lr 2.68e-05 | grad 0.91 | tok/s 69767
step   2330 | loss 1.6503 | lr 5.89e-05 | grad 0.52 | tok/s 70007
step   2340 | loss 1.6050 | lr 9.98e-05 | grad 0.82 | tok/s 68395
step   2350 | loss 1.6608 | lr 1.46e-04 | grad 0.65 | tok/s 66173
step   2360 | loss 2.0816 | lr 1.92e-04 | grad 1.16 | tok/s 67689
step   2370 | loss 1.6319 | lr 2.35e-04 | grad 0.57 | tok/s 67302
step   2380 | loss 1.5021 | lr 2.69e-04 | grad 0.68 | tok/s 66552
step   2390 | loss 1.5585 | lr 2.91e-04 | grad 0.88 | tok/s 66425
step   2400 | loss 1.7148 | lr 3.00e-04 | grad 0.76 | tok/s 65610
step   2410 | loss 1.5831 | lr 2.94e-04 | grad 0.75 | tok/s 66071
step   2420 | loss 1.7856 | lr 2.74e-04 | grad 0.64 | tok/s 66659
step   2430 | loss 1.7148 | lr 2.42e-04 | grad 1.03 | tok/s 65861
step   2440 | loss 1.7324 | lr 2.01e-04 | grad 0.68 | tok/s 67420
step   2450 | loss 1.4583 | lr 1.55e-04 | grad 1.15 | tok/s 66731
step   2460 | loss 1.7253 | lr 1.09e-04 | grad 1.58 | tok/s 68062
step   2470 | loss 1.8988 | lr 6.65e-05 | grad 1.03 | tok/s 69772
step   2480 | loss 1.5481 | lr 3.24e-05 | grad 0.59 | tok/s 66920
step   2490 | loss 1.4748 | lr 9.84e-06 | grad 0.79 | tok/s 65767
step   2500 | loss 1.5795 | lr 1.07e-06 | grad 0.64 | tok/s 67607
step   2510 | loss 1.6472 | lr 6.93e-06 | grad 0.72 | tok/s 67564
step   2520 | loss 1.8169 | lr 2.68e-05 | grad 1.02 | tok/s 65782
step   2530 | loss 1.6266 | lr 5.89e-05 | grad 0.98 | tok/s 65248
step   2540 | loss 1.6221 | lr 9.98e-05 | grad 0.79 | tok/s 65830
step   2550 | loss 2.1224 | lr 1.46e-04 | grad 2.52 | tok/s 66638

Training complete! Final step: 2555
