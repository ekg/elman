# Job 2: E75h4n16
# GPU: 2
# Command: python train.py --level E75h4n16 --dim 2048 --depth 20 --n_state 16 --expansion 1.0 --data data/pile.txt --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10.0 --output benchmark_results/e75_100m_20260119_175828/E75h4n16
# Started: 2026-01-19T17:58:36.705543
============================================================

Using device: cuda
Output directory: benchmark_results/e75_100m_20260119_175828/E75h4n16/levelE75h4n16_100m_20260119_175842
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h4n16, 97,561,856 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.8400 | lr 2.70e-05 | grad 1048.00 | tok/s 23866
step     20 | loss 5.5299 | lr 5.70e-05 | grad 143.00 | tok/s 83334
step     30 | loss 5.3324 | lr 8.70e-05 | grad 25.50 | tok/s 87987
step     40 | loss 4.7754 | lr 1.17e-04 | grad 17.75 | tok/s 87988
step     50 | loss 4.1372 | lr 1.47e-04 | grad 7.16 | tok/s 87792
step     60 | loss 3.8098 | lr 1.77e-04 | grad 14.38 | tok/s 85902
step     70 | loss 3.0627 | lr 2.07e-04 | grad 3.94 | tok/s 82998
step     80 | loss 3.4267 | lr 2.37e-04 | grad 5.28 | tok/s 86429
step     90 | loss 3.0737 | lr 2.67e-04 | grad 5.62 | tok/s 83688
step    100 | loss 2.7665 | lr 2.97e-04 | grad 1.98 | tok/s 84391
step    110 | loss 2.7944 | lr 6.94e-06 | grad 3.53 | tok/s 75024
step    120 | loss 3.1658 | lr 2.69e-05 | grad 2.62 | tok/s 76268
step    130 | loss 2.8446 | lr 5.89e-05 | grad 2.06 | tok/s 76928
step    140 | loss 2.5760 | lr 9.99e-05 | grad 1.41 | tok/s 77589
step    150 | loss 2.4636 | lr 1.46e-04 | grad 3.14 | tok/s 74066
step    160 | loss 2.3381 | lr 1.92e-04 | grad 2.03 | tok/s 74507
step    170 | loss 2.5575 | lr 2.35e-04 | grad 6.84 | tok/s 77239
step    180 | loss 2.5998 | lr 2.69e-04 | grad 2.02 | tok/s 77234
step    190 | loss 2.3146 | lr 2.91e-04 | grad 2.06 | tok/s 78247
step    200 | loss 2.0072 | lr 3.00e-04 | grad 1.58 | tok/s 80078
step    210 | loss 2.5173 | lr 2.94e-04 | grad 2.55 | tok/s 76719
step    220 | loss 2.4359 | lr 2.74e-04 | grad 1.46 | tok/s 78854
step    230 | loss 2.2694 | lr 2.42e-04 | grad 2.09 | tok/s 76377
step    240 | loss 2.2750 | lr 2.01e-04 | grad 2.55 | tok/s 77730
step    250 | loss 2.2370 | lr 1.55e-04 | grad 1.66 | tok/s 76441
step    260 | loss 2.2334 | lr 1.09e-04 | grad 1.05 | tok/s 73766
step    270 | loss 2.1087 | lr 6.65e-05 | grad 1.42 | tok/s 76285
step    280 | loss 2.0053 | lr 3.24e-05 | grad 2.19 | tok/s 76132
step    290 | loss 2.0021 | lr 9.84e-06 | grad 1.09 | tok/s 79774
step    300 | loss 1.9739 | lr 1.07e-06 | grad 1.07 | tok/s 79722
step    310 | loss 1.9768 | lr 6.94e-06 | grad 0.96 | tok/s 79762
step    320 | loss 2.0745 | lr 2.69e-05 | grad 2.62 | tok/s 76873
step    330 | loss 2.1039 | lr 5.89e-05 | grad 0.89 | tok/s 75104
step    340 | loss 2.1237 | lr 9.99e-05 | grad 2.41 | tok/s 76454
step    350 | loss 2.1397 | lr 1.46e-04 | grad 1.35 | tok/s 74224
step    360 | loss 2.1054 | lr 1.92e-04 | grad 3.16 | tok/s 74941
step    370 | loss 1.9552 | lr 2.35e-04 | grad 1.55 | tok/s 76594
step    380 | loss 2.5245 | lr 2.69e-04 | grad 1.49 | tok/s 78324
step    390 | loss 2.1178 | lr 2.91e-04 | grad 1.77 | tok/s 75323
step    400 | loss 2.2353 | lr 3.00e-04 | grad 4.16 | tok/s 77198
step    410 | loss 2.0179 | lr 2.94e-04 | grad 2.47 | tok/s 75257
step    420 | loss 2.1016 | lr 2.74e-04 | grad 1.42 | tok/s 74376
step    430 | loss 2.2494 | lr 2.42e-04 | grad 1.98 | tok/s 74023
step    440 | loss 2.3649 | lr 2.01e-04 | grad 1.69 | tok/s 76834
step    450 | loss 2.0393 | lr 1.55e-04 | grad 1.27 | tok/s 74536
step    460 | loss 2.0043 | lr 1.09e-04 | grad 1.00 | tok/s 74719
step    470 | loss 1.9810 | lr 6.65e-05 | grad 1.38 | tok/s 75624
step    480 | loss 1.8788 | lr 3.24e-05 | grad 0.81 | tok/s 73004
step    490 | loss 1.8245 | lr 9.84e-06 | grad 0.69 | tok/s 74301
step    500 | loss 2.8474 | lr 1.07e-06 | grad 1.30 | tok/s 76317
step    510 | loss 1.9092 | lr 6.94e-06 | grad 0.86 | tok/s 74935
step    520 | loss 1.9558 | lr 2.69e-05 | grad 0.71 | tok/s 77045
step    530 | loss 2.4237 | lr 5.89e-05 | grad 0.80 | tok/s 75461
step    540 | loss 1.8846 | lr 9.99e-05 | grad 1.45 | tok/s 75565
step    550 | loss 1.7374 | lr 1.46e-04 | grad 0.98 | tok/s 77311
step    560 | loss 1.5855 | lr 1.92e-04 | grad 0.87 | tok/s 78423
step    570 | loss 1.9444 | lr 2.35e-04 | grad 2.78 | tok/s 76826
step    580 | loss 2.2911 | lr 2.69e-04 | grad 1.62 | tok/s 76042
step    590 | loss 2.5656 | lr 2.91e-04 | grad 2.98 | tok/s 74767
step    600 | loss 2.0953 | lr 3.00e-04 | grad 1.92 | tok/s 74953
step    610 | loss 2.1394 | lr 2.94e-04 | grad 2.48 | tok/s 78482
step    620 | loss 1.9797 | lr 2.74e-04 | grad 1.30 | tok/s 74400
step    630 | loss 1.8775 | lr 2.42e-04 | grad 1.27 | tok/s 76748
step    640 | loss 2.3273 | lr 2.01e-04 | grad 1.29 | tok/s 76787
step    650 | loss 1.8985 | lr 1.55e-04 | grad 1.55 | tok/s 75116
step    660 | loss 2.2324 | lr 1.09e-04 | grad 5.91 | tok/s 74424
step    670 | loss 2.0228 | lr 6.65e-05 | grad 2.02 | tok/s 76475
step    680 | loss 1.9836 | lr 3.24e-05 | grad 1.41 | tok/s 73771
step    690 | loss 1.9785 | lr 9.84e-06 | grad 1.47 | tok/s 74513
step    700 | loss 2.0593 | lr 1.07e-06 | grad 1.41 | tok/s 74854
step    710 | loss 2.0111 | lr 6.94e-06 | grad 1.38 | tok/s 75293
step    720 | loss 2.1140 | lr 2.68e-05 | grad 1.89 | tok/s 74842
step    730 | loss 2.0512 | lr 5.89e-05 | grad 1.36 | tok/s 75403
step    740 | loss 1.9792 | lr 9.99e-05 | grad 2.61 | tok/s 74871
step    750 | loss 1.7829 | lr 1.46e-04 | grad 1.67 | tok/s 74044
step    760 | loss 2.2952 | lr 1.92e-04 | grad 0.93 | tok/s 74951
step    770 | loss 1.8418 | lr 2.35e-04 | grad 1.54 | tok/s 74394
step    780 | loss 1.8953 | lr 2.69e-04 | grad 1.38 | tok/s 75323
step    790 | loss 1.8725 | lr 2.91e-04 | grad 1.17 | tok/s 76073
step    800 | loss 1.8216 | lr 3.00e-04 | grad 1.31 | tok/s 75713
step    810 | loss 1.9665 | lr 2.94e-04 | grad 2.48 | tok/s 75153
step    820 | loss 2.6616 | lr 2.74e-04 | grad 1.94 | tok/s 77051
step    830 | loss 2.0443 | lr 2.42e-04 | grad 0.87 | tok/s 78202
step    840 | loss 1.7418 | lr 2.01e-04 | grad 0.71 | tok/s 78337
step    850 | loss 2.3287 | lr 1.55e-04 | grad 1.62 | tok/s 74570
step    860 | loss 2.0265 | lr 1.09e-04 | grad 1.41 | tok/s 72874
step    870 | loss 1.9476 | lr 6.65e-05 | grad 1.00 | tok/s 75219
step    880 | loss 2.0137 | lr 3.24e-05 | grad 1.50 | tok/s 74743
step    890 | loss 1.8840 | lr 9.84e-06 | grad 0.96 | tok/s 74627
step    900 | loss 2.4118 | lr 1.07e-06 | grad 1.16 | tok/s 72727
step    910 | loss 1.9659 | lr 6.94e-06 | grad 0.84 | tok/s 74121
step    920 | loss 1.9068 | lr 2.68e-05 | grad 0.87 | tok/s 73937
step    930 | loss 2.0369 | lr 5.89e-05 | grad 1.66 | tok/s 73730
step    940 | loss 1.9117 | lr 9.99e-05 | grad 1.72 | tok/s 72605
step    950 | loss 2.0154 | lr 1.46e-04 | grad 1.59 | tok/s 74801
step    960 | loss 1.7182 | lr 1.92e-04 | grad 0.84 | tok/s 78219
step    970 | loss 1.4958 | lr 2.35e-04 | grad 0.68 | tok/s 78345
step    980 | loss 1.7051 | lr 2.69e-04 | grad 2.83 | tok/s 76379
step    990 | loss 2.1061 | lr 2.91e-04 | grad 1.09 | tok/s 74053
step   1000 | loss 1.9196 | lr 3.00e-04 | grad 0.82 | tok/s 72299
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9196.pt
step   1010 | loss 2.2087 | lr 2.94e-04 | grad 3.16 | tok/s 55171
step   1020 | loss 1.8117 | lr 2.74e-04 | grad 1.13 | tok/s 74661
step   1030 | loss 2.1987 | lr 2.42e-04 | grad 1.24 | tok/s 73073
step   1040 | loss 1.8009 | lr 2.01e-04 | grad 1.77 | tok/s 74592
step   1050 | loss 1.8451 | lr 1.55e-04 | grad 0.98 | tok/s 74890
step   1060 | loss 2.0735 | lr 1.09e-04 | grad 2.03 | tok/s 75090
step   1070 | loss 2.1577 | lr 6.65e-05 | grad 1.11 | tok/s 75140
step   1080 | loss 2.4751 | lr 3.24e-05 | grad 1.33 | tok/s 74267
step   1090 | loss 2.1752 | lr 9.84e-06 | grad 1.02 | tok/s 74960
step   1100 | loss 1.8400 | lr 1.07e-06 | grad 0.98 | tok/s 74373
step   1110 | loss 1.8924 | lr 6.93e-06 | grad 0.91 | tok/s 75858
step   1120 | loss 2.0960 | lr 2.68e-05 | grad 1.19 | tok/s 76727
step   1130 | loss 1.8345 | lr 5.89e-05 | grad 0.83 | tok/s 73393
step   1140 | loss 1.6964 | lr 9.99e-05 | grad 0.86 | tok/s 74853
step   1150 | loss 2.0051 | lr 1.46e-04 | grad 1.50 | tok/s 74766
step   1160 | loss 1.6627 | lr 1.92e-04 | grad 0.71 | tok/s 73998
step   1170 | loss 2.0556 | lr 2.35e-04 | grad 1.09 | tok/s 74814
step   1180 | loss 1.6722 | lr 2.69e-04 | grad 0.96 | tok/s 79002
step   1190 | loss 1.5298 | lr 2.91e-04 | grad 0.90 | tok/s 79235
step   1200 | loss 1.4446 | lr 3.00e-04 | grad 0.79 | tok/s 79116
step   1210 | loss 1.4179 | lr 2.94e-04 | grad 1.09 | tok/s 79101
step   1220 | loss 1.4735 | lr 2.74e-04 | grad 1.04 | tok/s 78275
step   1230 | loss 1.7705 | lr 2.42e-04 | grad 1.30 | tok/s 75898
step   1240 | loss 1.7874 | lr 2.01e-04 | grad 1.12 | tok/s 74641
step   1250 | loss 1.9051 | lr 1.55e-04 | grad 3.53 | tok/s 76971
step   1260 | loss 1.9475 | lr 1.09e-04 | grad 2.70 | tok/s 77024
step   1270 | loss 1.9939 | lr 6.65e-05 | grad 1.59 | tok/s 75484
step   1280 | loss 1.8181 | lr 3.24e-05 | grad 0.99 | tok/s 74968
step   1290 | loss 1.7518 | lr 9.84e-06 | grad 1.13 | tok/s 74725
step   1300 | loss 1.8147 | lr 1.07e-06 | grad 0.95 | tok/s 74538
step   1310 | loss 1.9327 | lr 6.93e-06 | grad 0.96 | tok/s 74614
step   1320 | loss 1.8662 | lr 2.68e-05 | grad 1.34 | tok/s 76082
step   1330 | loss 1.8074 | lr 5.89e-05 | grad 0.78 | tok/s 75929
step   1340 | loss 1.7124 | lr 9.99e-05 | grad 1.15 | tok/s 75947
step   1350 | loss 1.7728 | lr 1.46e-04 | grad 2.02 | tok/s 77943
step   1360 | loss 1.6872 | lr 1.92e-04 | grad 1.02 | tok/s 74205
step   1370 | loss 1.8126 | lr 2.35e-04 | grad 1.00 | tok/s 74964
step   1380 | loss 1.9296 | lr 2.69e-04 | grad 1.10 | tok/s 75008
step   1390 | loss 1.8148 | lr 2.91e-04 | grad 1.83 | tok/s 73140
step   1400 | loss 1.9799 | lr 3.00e-04 | grad 22.25 | tok/s 75863
step   1410 | loss 2.0036 | lr 2.94e-04 | grad 1.52 | tok/s 76612
step   1420 | loss 1.9110 | lr 2.74e-04 | grad 1.23 | tok/s 73210
step   1430 | loss 1.6788 | lr 2.42e-04 | grad 1.33 | tok/s 71825
step   1440 | loss 1.5889 | lr 2.01e-04 | grad 0.89 | tok/s 75838
step   1450 | loss 1.6352 | lr 1.55e-04 | grad 2.38 | tok/s 76951
step   1460 | loss 1.7084 | lr 1.09e-04 | grad 0.73 | tok/s 71725
step   1470 | loss 1.8373 | lr 6.65e-05 | grad 3.19 | tok/s 74337
step   1480 | loss 1.6816 | lr 3.24e-05 | grad 2.14 | tok/s 75015
step   1490 | loss 1.8408 | lr 9.84e-06 | grad 2.73 | tok/s 74894
step   1500 | loss 1.9344 | lr 1.07e-06 | grad 3.44 | tok/s 73142
step   1510 | loss 1.8312 | lr 6.93e-06 | grad 1.49 | tok/s 76855
step   1520 | loss 1.7828 | lr 2.68e-05 | grad 1.28 | tok/s 76114
step   1530 | loss 1.7227 | lr 5.89e-05 | grad 0.72 | tok/s 75316
step   1540 | loss 1.7015 | lr 9.99e-05 | grad 0.63 | tok/s 74144
step   1550 | loss 1.6942 | lr 1.46e-04 | grad 2.89 | tok/s 77096
step   1560 | loss 2.3590 | lr 1.92e-04 | grad 1.35 | tok/s 74917
step   1570 | loss 1.7200 | lr 2.35e-04 | grad 1.37 | tok/s 73623
step   1580 | loss 1.8997 | lr 2.69e-04 | grad 1.31 | tok/s 75865
step   1590 | loss 1.6934 | lr 2.91e-04 | grad 0.96 | tok/s 74313
step   1600 | loss 1.7896 | lr 3.00e-04 | grad 1.06 | tok/s 72846
step   1610 | loss 1.5998 | lr 2.94e-04 | grad 0.95 | tok/s 77242
step   1620 | loss 1.7844 | lr 2.74e-04 | grad 0.98 | tok/s 75720
step   1630 | loss 1.8049 | lr 2.42e-04 | grad 1.23 | tok/s 76334
step   1640 | loss 1.7112 | lr 2.01e-04 | grad 0.88 | tok/s 73925
step   1650 | loss 1.7154 | lr 1.55e-04 | grad 1.41 | tok/s 72996
step   1660 | loss 1.7068 | lr 1.09e-04 | grad 0.82 | tok/s 73412
step   1670 | loss 1.7671 | lr 6.65e-05 | grad 2.38 | tok/s 76532
step   1680 | loss 2.1783 | lr 3.24e-05 | grad 0.66 | tok/s 76487
step   1690 | loss 1.6777 | lr 9.84e-06 | grad 1.10 | tok/s 74574
step   1700 | loss 2.1257 | lr 1.07e-06 | grad 0.64 | tok/s 76413
step   1710 | loss 1.7194 | lr 6.93e-06 | grad 1.09 | tok/s 74197
step   1720 | loss 1.7408 | lr 2.68e-05 | grad 1.00 | tok/s 74352
step   1730 | loss 1.9050 | lr 5.89e-05 | grad 0.88 | tok/s 74271
step   1740 | loss 1.7324 | lr 9.99e-05 | grad 0.78 | tok/s 75701
step   1750 | loss 1.6327 | lr 1.46e-04 | grad 0.67 | tok/s 73289
step   1760 | loss 1.9538 | lr 1.92e-04 | grad 0.85 | tok/s 74000
step   1770 | loss 1.8242 | lr 2.35e-04 | grad 0.92 | tok/s 75767
step   1780 | loss 1.6975 | lr 2.69e-04 | grad 1.28 | tok/s 72978
step   1790 | loss 1.9287 | lr 2.91e-04 | grad 1.01 | tok/s 74284
step   1800 | loss 1.6317 | lr 3.00e-04 | grad 1.01 | tok/s 75672
step   1810 | loss 1.7383 | lr 2.94e-04 | grad 1.11 | tok/s 75183
step   1820 | loss 1.7133 | lr 2.74e-04 | grad 1.19 | tok/s 74374
step   1830 | loss 1.7346 | lr 2.42e-04 | grad 0.98 | tok/s 74044
step   1840 | loss 1.6812 | lr 2.01e-04 | grad 1.16 | tok/s 73753
step   1850 | loss 1.9013 | lr 1.55e-04 | grad 1.30 | tok/s 74560
step   1860 | loss 1.6566 | lr 1.09e-04 | grad 0.64 | tok/s 74371
step   1870 | loss 1.7246 | lr 6.65e-05 | grad 1.58 | tok/s 75876
step   1880 | loss 1.6511 | lr 3.24e-05 | grad 0.70 | tok/s 76159
step   1890 | loss 1.7430 | lr 9.84e-06 | grad 0.69 | tok/s 74840
step   1900 | loss 1.8621 | lr 1.07e-06 | grad 2.05 | tok/s 75369
step   1910 | loss 1.7612 | lr 6.93e-06 | grad 1.36 | tok/s 74504
step   1920 | loss 1.6722 | lr 2.68e-05 | grad 1.20 | tok/s 76616
step   1930 | loss 1.6467 | lr 5.89e-05 | grad 1.16 | tok/s 75971
step   1940 | loss 1.5544 | lr 9.99e-05 | grad 0.86 | tok/s 77209
step   1950 | loss 1.6442 | lr 1.46e-04 | grad 1.08 | tok/s 75426
step   1960 | loss 2.0396 | lr 1.92e-04 | grad 5.28 | tok/s 76880
step   1970 | loss 1.7237 | lr 2.35e-04 | grad 1.83 | tok/s 74403
step   1980 | loss 1.7801 | lr 2.69e-04 | grad 2.98 | tok/s 74994
step   1990 | loss 1.8888 | lr 2.91e-04 | grad 1.40 | tok/s 76456
step   2000 | loss 1.8050 | lr 3.00e-04 | grad 1.59 | tok/s 77271
  >>> saved checkpoint: checkpoint_step_002000_loss_1.8050.pt
step   2010 | loss 1.5047 | lr 2.94e-04 | grad 0.80 | tok/s 56442
step   2020 | loss 1.3235 | lr 2.74e-04 | grad 0.80 | tok/s 79456
step   2030 | loss 1.6845 | lr 2.42e-04 | grad 1.27 | tok/s 78705
step   2040 | loss 1.4767 | lr 2.01e-04 | grad 0.69 | tok/s 79257
step   2050 | loss 1.4272 | lr 1.55e-04 | grad 1.00 | tok/s 78375
step   2060 | loss 1.7813 | lr 1.09e-04 | grad 0.91 | tok/s 75060
step   2070 | loss 1.6826 | lr 6.65e-05 | grad 1.48 | tok/s 78454
step   2080 | loss 1.8966 | lr 3.24e-05 | grad 4.44 | tok/s 74232
step   2090 | loss 1.8022 | lr 9.84e-06 | grad 1.19 | tok/s 77204
step   2100 | loss 1.7239 | lr 1.07e-06 | grad 1.13 | tok/s 75008
step   2110 | loss 1.6235 | lr 6.93e-06 | grad 0.92 | tok/s 77499
step   2120 | loss 1.6157 | lr 2.68e-05 | grad 1.42 | tok/s 76911
step   2130 | loss 1.7090 | lr 5.89e-05 | grad 3.09 | tok/s 74616
step   2140 | loss 1.7587 | lr 9.99e-05 | grad 3.03 | tok/s 74577
step   2150 | loss 1.7629 | lr 1.46e-04 | grad 0.73 | tok/s 75391
step   2160 | loss 1.7097 | lr 1.92e-04 | grad 0.74 | tok/s 74613
step   2170 | loss 1.8300 | lr 2.35e-04 | grad 0.91 | tok/s 75656
step   2180 | loss 1.6775 | lr 2.69e-04 | grad 1.01 | tok/s 76669
step   2190 | loss 2.0086 | lr 2.91e-04 | grad 0.96 | tok/s 77107
step   2200 | loss 1.4244 | lr 3.00e-04 | grad 0.70 | tok/s 79448
step   2210 | loss 1.3867 | lr 2.94e-04 | grad 0.63 | tok/s 79555
step   2220 | loss 1.3395 | lr 2.74e-04 | grad 0.68 | tok/s 79154
step   2230 | loss 1.6394 | lr 2.42e-04 | grad 1.05 | tok/s 76181
step   2240 | loss 2.0166 | lr 2.01e-04 | grad 2.56 | tok/s 77716
step   2250 | loss 1.8243 | lr 1.55e-04 | grad 1.05 | tok/s 77044
step   2260 | loss 1.8842 | lr 1.09e-04 | grad 1.01 | tok/s 75991
step   2270 | loss 1.6546 | lr 6.65e-05 | grad 1.21 | tok/s 74410
step   2280 | loss 1.8108 | lr 3.24e-05 | grad 0.82 | tok/s 74552
step   2290 | loss 1.6394 | lr 9.84e-06 | grad 0.87 | tok/s 75572
step   2300 | loss 1.6377 | lr 1.07e-06 | grad 0.75 | tok/s 72836
step   2310 | loss 1.7096 | lr 6.93e-06 | grad 1.18 | tok/s 77902
step   2320 | loss 1.7915 | lr 2.68e-05 | grad 1.19 | tok/s 78651
step   2330 | loss 1.7152 | lr 5.89e-05 | grad 0.75 | tok/s 78858
step   2340 | loss 1.6959 | lr 9.98e-05 | grad 1.19 | tok/s 77174
step   2350 | loss 1.7545 | lr 1.46e-04 | grad 0.99 | tok/s 74761
step   2360 | loss 2.2214 | lr 1.92e-04 | grad 1.62 | tok/s 76058
step   2370 | loss 1.7493 | lr 2.35e-04 | grad 0.93 | tok/s 75812
step   2380 | loss 1.5919 | lr 2.69e-04 | grad 1.23 | tok/s 74929
step   2390 | loss 1.6375 | lr 2.91e-04 | grad 1.20 | tok/s 74834
step   2400 | loss 1.8231 | lr 3.00e-04 | grad 1.16 | tok/s 74151
step   2410 | loss 1.6920 | lr 2.94e-04 | grad 1.18 | tok/s 74686
step   2420 | loss 1.9275 | lr 2.74e-04 | grad 1.00 | tok/s 75391
step   2430 | loss 1.8704 | lr 2.42e-04 | grad 1.67 | tok/s 74005
step   2440 | loss 1.8678 | lr 2.01e-04 | grad 1.04 | tok/s 76240
step   2450 | loss 1.5265 | lr 1.55e-04 | grad 1.75 | tok/s 75618
step   2460 | loss 1.8431 | lr 1.09e-04 | grad 2.50 | tok/s 76627
step   2470 | loss 1.9937 | lr 6.65e-05 | grad 1.62 | tok/s 78393
step   2480 | loss 1.6310 | lr 3.24e-05 | grad 0.83 | tok/s 75343
step   2490 | loss 1.5524 | lr 9.84e-06 | grad 1.20 | tok/s 74399
step   2500 | loss 1.6617 | lr 1.07e-06 | grad 1.09 | tok/s 76273
step   2510 | loss 1.7408 | lr 6.93e-06 | grad 0.97 | tok/s 75815
step   2520 | loss 1.9284 | lr 2.68e-05 | grad 1.63 | tok/s 73980
step   2530 | loss 1.7135 | lr 5.89e-05 | grad 1.49 | tok/s 74436
step   2540 | loss 1.6991 | lr 9.98e-05 | grad 1.13 | tok/s 74732
step   2550 | loss 2.2085 | lr 1.46e-04 | grad 3.38 | tok/s 75525
step   2560 | loss 1.7172 | lr 1.92e-04 | grad 1.31 | tok/s 76706
step   2570 | loss 1.6758 | lr 2.35e-04 | grad 2.14 | tok/s 73778
step   2580 | loss 1.7780 | lr 2.69e-04 | grad 1.17 | tok/s 77087
step   2590 | loss 1.5210 | lr 2.91e-04 | grad 1.35 | tok/s 75392
step   2600 | loss 1.7601 | lr 3.00e-04 | grad 1.02 | tok/s 76910
step   2610 | loss 1.6971 | lr 2.94e-04 | grad 0.75 | tok/s 77654
step   2620 | loss 1.4760 | lr 2.74e-04 | grad 0.82 | tok/s 79574
step   2630 | loss 1.5349 | lr 2.42e-04 | grad 0.61 | tok/s 77045
step   2640 | loss 1.7244 | lr 2.01e-04 | grad 1.30 | tok/s 74892
step   2650 | loss 1.6288 | lr 1.55e-04 | grad 0.86 | tok/s 72739
step   2660 | loss 2.0424 | lr 1.09e-04 | grad 1.20 | tok/s 78013
step   2670 | loss 1.5186 | lr 6.65e-05 | grad 0.68 | tok/s 79277
step   2680 | loss 1.4876 | lr 3.24e-05 | grad 0.70 | tok/s 79392
step   2690 | loss 1.4437 | lr 9.84e-06 | grad 0.65 | tok/s 79492
step   2700 | loss 1.6475 | lr 1.07e-06 | grad 0.83 | tok/s 76346
step   2710 | loss 1.7752 | lr 6.93e-06 | grad 2.44 | tok/s 74437
step   2720 | loss 2.2999 | lr 2.68e-05 | grad 0.86 | tok/s 78513
step   2730 | loss 1.7116 | lr 5.89e-05 | grad 1.17 | tok/s 76021
step   2740 | loss 1.5141 | lr 9.98e-05 | grad 0.96 | tok/s 75491
step   2750 | loss 1.7522 | lr 1.46e-04 | grad 0.95 | tok/s 76424
step   2760 | loss 1.8085 | lr 1.92e-04 | grad 1.95 | tok/s 73703
step   2770 | loss 1.6154 | lr 2.35e-04 | grad 0.98 | tok/s 76881
step   2780 | loss 1.5985 | lr 2.69e-04 | grad 0.77 | tok/s 74012
step   2790 | loss 1.5162 | lr 2.91e-04 | grad 0.97 | tok/s 75872
step   2800 | loss 2.0471 | lr 3.00e-04 | grad 2.47 | tok/s 75637
step   2810 | loss 1.8129 | lr 2.94e-04 | grad 1.05 | tok/s 77006
step   2820 | loss 2.0528 | lr 2.74e-04 | grad 2.41 | tok/s 77538
step   2830 | loss 1.7754 | lr 2.42e-04 | grad 0.98 | tok/s 77101
step   2840 | loss 1.8553 | lr 2.01e-04 | grad 1.05 | tok/s 75960
step   2850 | loss 1.6360 | lr 1.55e-04 | grad 1.09 | tok/s 77771
step   2860 | loss 1.6145 | lr 1.09e-04 | grad 0.81 | tok/s 75637
step   2870 | loss 1.7537 | lr 6.65e-05 | grad 0.94 | tok/s 75022

Training complete! Final step: 2873
