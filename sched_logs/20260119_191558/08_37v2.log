# Job 8: 37v2
# GPU: 4
# Command: python train.py --level 37v2 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/37v2
# Started: 2026-01-19T19:26:07.035793
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/37v2/level37v2_100m_20260119_192612
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level 37v2, 65,738,880 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 8.9966 | lr 2.70e-05 | grad 9.75 | tok/s 17470
step     20 | loss 4.2815 | lr 5.70e-05 | grad 6.53 | tok/s 42512
step     30 | loss 4.6566 | lr 8.70e-05 | grad 3.14 | tok/s 58959
step     40 | loss 3.6892 | lr 1.17e-04 | grad 2.72 | tok/s 58969
step     50 | loss 3.0512 | lr 1.47e-04 | grad 2.59 | tok/s 59026
step     60 | loss 3.1382 | lr 1.77e-04 | grad 2.53 | tok/s 57782
step     70 | loss 2.7827 | lr 2.07e-04 | grad 1.48 | tok/s 55820
step     80 | loss 3.1830 | lr 2.37e-04 | grad 3.25 | tok/s 57314
step     90 | loss 3.0573 | lr 2.67e-04 | grad 3.52 | tok/s 55724
step    100 | loss 2.6686 | lr 2.97e-04 | grad 1.02 | tok/s 56438
step    110 | loss 2.6148 | lr 6.94e-06 | grad 1.85 | tok/s 52922
step    120 | loss 2.9120 | lr 2.69e-05 | grad 0.98 | tok/s 50737
step    130 | loss 2.6529 | lr 5.89e-05 | grad 1.02 | tok/s 52521
step    140 | loss 2.4409 | lr 9.99e-05 | grad 1.03 | tok/s 54143
step    150 | loss 2.3556 | lr 1.46e-04 | grad 1.81 | tok/s 50461
step    160 | loss 2.2613 | lr 1.92e-04 | grad 1.26 | tok/s 52157
step    170 | loss 2.4610 | lr 2.35e-04 | grad 3.52 | tok/s 54107
step    180 | loss 2.4894 | lr 2.69e-04 | grad 1.16 | tok/s 54472
step    190 | loss 2.2241 | lr 2.91e-04 | grad 1.03 | tok/s 55253
step    200 | loss 1.9346 | lr 3.00e-04 | grad 0.90 | tok/s 56572
step    210 | loss 2.4222 | lr 2.94e-04 | grad 1.37 | tok/s 54143
step    220 | loss 2.3053 | lr 2.74e-04 | grad 0.89 | tok/s 55932
step    230 | loss 2.1426 | lr 2.42e-04 | grad 1.02 | tok/s 53927
step    240 | loss 2.1634 | lr 2.01e-04 | grad 1.27 | tok/s 55155
step    250 | loss 2.1250 | lr 1.55e-04 | grad 0.91 | tok/s 54306
step    260 | loss 2.1635 | lr 1.09e-04 | grad 0.63 | tok/s 52211
step    270 | loss 2.0288 | lr 6.65e-05 | grad 0.79 | tok/s 54181
step    280 | loss 1.9143 | lr 3.24e-05 | grad 1.23 | tok/s 54068
step    290 | loss 1.9238 | lr 9.84e-06 | grad 0.60 | tok/s 57026
step    300 | loss 1.8836 | lr 1.07e-06 | grad 0.59 | tok/s 57037
step    310 | loss 1.8858 | lr 6.94e-06 | grad 0.52 | tok/s 57090
step    320 | loss 1.9739 | lr 2.69e-05 | grad 1.25 | tok/s 54897
step    330 | loss 2.0070 | lr 5.89e-05 | grad 0.60 | tok/s 53602
step    340 | loss 2.0202 | lr 9.99e-05 | grad 1.40 | tok/s 54743
step    350 | loss 2.0123 | lr 1.46e-04 | grad 0.78 | tok/s 53131
step    360 | loss 1.9988 | lr 1.92e-04 | grad 1.91 | tok/s 53858
step    370 | loss 1.8575 | lr 2.35e-04 | grad 0.95 | tok/s 54904
step    380 | loss 2.3899 | lr 2.69e-04 | grad 1.12 | tok/s 56304
step    390 | loss 1.9938 | lr 2.91e-04 | grad 1.01 | tok/s 54219
step    400 | loss 2.0823 | lr 3.00e-04 | grad 2.23 | tok/s 55652
step    410 | loss 1.8359 | lr 2.94e-04 | grad 1.72 | tok/s 53927
step    420 | loss 1.9572 | lr 2.74e-04 | grad 0.93 | tok/s 53515
step    430 | loss 2.1039 | lr 2.42e-04 | grad 1.03 | tok/s 53373
step    440 | loss 2.1241 | lr 2.01e-04 | grad 1.15 | tok/s 55466
step    450 | loss 1.9135 | lr 1.55e-04 | grad 0.57 | tok/s 53384
step    460 | loss 1.8772 | lr 1.09e-04 | grad 0.60 | tok/s 53493
step    470 | loss 1.8519 | lr 6.65e-05 | grad 0.94 | tok/s 54018
step    480 | loss 1.7512 | lr 3.24e-05 | grad 0.52 | tok/s 52835
step    490 | loss 1.7166 | lr 9.84e-06 | grad 0.45 | tok/s 53844
step    500 | loss 2.6338 | lr 1.07e-06 | grad 0.77 | tok/s 55566
step    510 | loss 1.7096 | lr 6.94e-06 | grad 0.51 | tok/s 54209
step    520 | loss 1.7883 | lr 2.69e-05 | grad 0.44 | tok/s 55989
step    530 | loss 2.2672 | lr 5.89e-05 | grad 0.61 | tok/s 54829
step    540 | loss 1.7213 | lr 9.99e-05 | grad 0.85 | tok/s 54795
step    550 | loss 1.6357 | lr 1.46e-04 | grad 0.63 | tok/s 56331
step    560 | loss 1.4910 | lr 1.92e-04 | grad 0.62 | tok/s 57115
step    570 | loss 1.7825 | lr 2.35e-04 | grad 1.62 | tok/s 55581
step    580 | loss 2.1350 | lr 2.69e-04 | grad 0.89 | tok/s 55067
step    590 | loss 2.4812 | lr 2.91e-04 | grad 2.45 | tok/s 53903
step    600 | loss 1.9002 | lr 3.00e-04 | grad 1.20 | tok/s 54097
step    610 | loss 1.8720 | lr 2.94e-04 | grad 1.07 | tok/s 56715
step    620 | loss 1.8144 | lr 2.74e-04 | grad 0.72 | tok/s 53867
step    630 | loss 1.6986 | lr 2.42e-04 | grad 0.71 | tok/s 55562
step    640 | loss 2.0337 | lr 2.01e-04 | grad 0.79 | tok/s 55642
step    650 | loss 1.7678 | lr 1.55e-04 | grad 0.85 | tok/s 54582
step    660 | loss 2.0494 | lr 1.09e-04 | grad 4.06 | tok/s 53889
step    670 | loss 1.8800 | lr 6.65e-05 | grad 1.29 | tok/s 55782
step    680 | loss 1.8214 | lr 3.24e-05 | grad 0.83 | tok/s 53876
step    690 | loss 1.8335 | lr 9.84e-06 | grad 1.01 | tok/s 45913
step    700 | loss 1.9291 | lr 1.07e-06 | grad 1.16 | tok/s 45299
step    710 | loss 1.8496 | lr 6.94e-06 | grad 0.89 | tok/s 46022
step    720 | loss 1.9273 | lr 2.68e-05 | grad 1.16 | tok/s 45898
step    730 | loss 1.9038 | lr 5.89e-05 | grad 0.95 | tok/s 46248
step    740 | loss 1.8493 | lr 9.99e-05 | grad 1.54 | tok/s 45936
step    750 | loss 1.6526 | lr 1.46e-04 | grad 1.11 | tok/s 45454
step    760 | loss 2.0416 | lr 1.92e-04 | grad 0.58 | tok/s 45673
step    770 | loss 1.7256 | lr 2.35e-04 | grad 1.01 | tok/s 50689
step    780 | loss 1.7732 | lr 2.69e-04 | grad 0.82 | tok/s 54839
step    790 | loss 1.6996 | lr 2.91e-04 | grad 0.73 | tok/s 55266
step    800 | loss 1.6597 | lr 3.00e-04 | grad 0.78 | tok/s 55286
step    810 | loss 1.7771 | lr 2.94e-04 | grad 1.43 | tok/s 54736
step    820 | loss 2.4200 | lr 2.74e-04 | grad 1.09 | tok/s 56287
step    830 | loss 1.9223 | lr 2.42e-04 | grad 0.68 | tok/s 57145
step    840 | loss 1.6233 | lr 2.01e-04 | grad 0.50 | tok/s 57139
step    850 | loss 2.0026 | lr 1.55e-04 | grad 1.09 | tok/s 54445
step    860 | loss 1.7591 | lr 1.09e-04 | grad 0.88 | tok/s 53360
step    870 | loss 1.6938 | lr 6.65e-05 | grad 0.68 | tok/s 54933
step    880 | loss 1.7556 | lr 3.24e-05 | grad 0.89 | tok/s 54816
step    890 | loss 1.6761 | lr 9.84e-06 | grad 0.66 | tok/s 55117
step    900 | loss 2.1186 | lr 1.07e-06 | grad 0.74 | tok/s 53477
step    910 | loss 1.7230 | lr 6.94e-06 | grad 0.57 | tok/s 54368
step    920 | loss 1.7042 | lr 2.68e-05 | grad 0.57 | tok/s 54247
step    930 | loss 1.7979 | lr 5.89e-05 | grad 1.22 | tok/s 54046
step    940 | loss 1.7069 | lr 9.99e-05 | grad 1.21 | tok/s 53270
step    950 | loss 1.7954 | lr 1.46e-04 | grad 1.02 | tok/s 54612
step    960 | loss 1.5493 | lr 1.92e-04 | grad 0.49 | tok/s 57352
step    970 | loss 1.3794 | lr 2.35e-04 | grad 0.40 | tok/s 57402
step    980 | loss 1.5403 | lr 2.69e-04 | grad 1.73 | tok/s 55780
step    990 | loss 1.8926 | lr 2.91e-04 | grad 0.66 | tok/s 54415
step   1000 | loss 1.7606 | lr 3.00e-04 | grad 0.65 | tok/s 52774
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7606.pt
step   1010 | loss 1.9683 | lr 2.94e-04 | grad 1.12 | tok/s 48527
step   1020 | loss 1.6315 | lr 2.74e-04 | grad 0.70 | tok/s 54261
step   1030 | loss 2.0273 | lr 2.42e-04 | grad 0.69 | tok/s 53182
step   1040 | loss 1.6609 | lr 2.01e-04 | grad 1.16 | tok/s 54468
step   1050 | loss 1.6779 | lr 1.55e-04 | grad 0.74 | tok/s 54572
step   1060 | loss 1.8450 | lr 1.09e-04 | grad 1.16 | tok/s 54750
step   1070 | loss 1.9703 | lr 6.65e-05 | grad 0.75 | tok/s 54861
step   1080 | loss 2.3415 | lr 3.24e-05 | grad 0.88 | tok/s 54324
step   1090 | loss 2.0469 | lr 9.84e-06 | grad 0.73 | tok/s 54625
step   1100 | loss 1.7272 | lr 1.07e-06 | grad 0.68 | tok/s 54252
step   1110 | loss 1.7247 | lr 6.93e-06 | grad 0.67 | tok/s 55183
step   1120 | loss 1.9149 | lr 2.68e-05 | grad 0.71 | tok/s 55878
step   1130 | loss 1.7088 | lr 5.89e-05 | grad 0.62 | tok/s 53122
step   1140 | loss 1.5755 | lr 9.99e-05 | grad 0.61 | tok/s 54224
step   1150 | loss 1.8637 | lr 1.46e-04 | grad 0.95 | tok/s 54152
step   1160 | loss 1.5483 | lr 1.92e-04 | grad 0.56 | tok/s 53682
step   1170 | loss 1.8680 | lr 2.35e-04 | grad 0.64 | tok/s 54324
step   1180 | loss 1.5933 | lr 2.69e-04 | grad 0.61 | tok/s 57099
step   1190 | loss 1.4378 | lr 2.91e-04 | grad 0.54 | tok/s 57126
step   1200 | loss 1.3525 | lr 3.00e-04 | grad 0.45 | tok/s 57188
step   1210 | loss 1.3201 | lr 2.94e-04 | grad 0.58 | tok/s 57119
step   1220 | loss 1.3682 | lr 2.74e-04 | grad 0.86 | tok/s 56690
step   1230 | loss 1.5914 | lr 2.42e-04 | grad 0.73 | tok/s 54620
step   1240 | loss 1.6587 | lr 2.01e-04 | grad 0.73 | tok/s 53742
step   1250 | loss 1.7428 | lr 1.55e-04 | grad 2.62 | tok/s 55384
step   1260 | loss 1.8096 | lr 1.09e-04 | grad 2.03 | tok/s 55332
step   1270 | loss 1.8431 | lr 6.65e-05 | grad 1.00 | tok/s 54690
step   1280 | loss 1.6764 | lr 3.24e-05 | grad 0.66 | tok/s 53855
step   1290 | loss 1.6290 | lr 9.84e-06 | grad 0.77 | tok/s 53594
step   1300 | loss 1.6802 | lr 1.07e-06 | grad 0.64 | tok/s 53538
step   1310 | loss 1.7679 | lr 6.93e-06 | grad 0.65 | tok/s 53524
step   1320 | loss 1.7342 | lr 2.68e-05 | grad 0.95 | tok/s 54371
step   1330 | loss 1.6500 | lr 5.89e-05 | grad 0.52 | tok/s 54525
step   1340 | loss 1.5727 | lr 9.99e-05 | grad 0.81 | tok/s 54633
step   1350 | loss 1.5978 | lr 1.46e-04 | grad 1.31 | tok/s 55922
step   1360 | loss 1.5784 | lr 1.92e-04 | grad 0.64 | tok/s 53192
step   1370 | loss 1.6780 | lr 2.35e-04 | grad 0.77 | tok/s 53982
step   1380 | loss 1.7637 | lr 2.69e-04 | grad 0.77 | tok/s 54456
step   1390 | loss 1.6805 | lr 2.91e-04 | grad 1.26 | tok/s 53144
step   1400 | loss 1.7026 | lr 3.00e-04 | grad 5.31 | tok/s 55293
step   1410 | loss 1.7065 | lr 2.94e-04 | grad 1.46 | tok/s 55803
step   1420 | loss 1.7679 | lr 2.74e-04 | grad 0.83 | tok/s 53058
step   1430 | loss 1.5708 | lr 2.42e-04 | grad 0.75 | tok/s 51901
step   1440 | loss 1.4840 | lr 2.01e-04 | grad 0.57 | tok/s 54753
step   1450 | loss 1.5117 | lr 1.55e-04 | grad 1.66 | tok/s 55776
step   1460 | loss 1.5996 | lr 1.09e-04 | grad 0.52 | tok/s 52162
step   1470 | loss 1.6923 | lr 6.65e-05 | grad 1.67 | tok/s 54034
step   1480 | loss 1.5633 | lr 3.24e-05 | grad 1.53 | tok/s 54612
step   1490 | loss 1.7077 | lr 9.84e-06 | grad 1.99 | tok/s 54618
step   1500 | loss 1.8084 | lr 1.07e-06 | grad 1.56 | tok/s 52979
step   1510 | loss 1.6910 | lr 6.93e-06 | grad 0.86 | tok/s 55828
step   1520 | loss 1.6383 | lr 2.68e-05 | grad 0.94 | tok/s 55348
step   1530 | loss 1.5964 | lr 5.89e-05 | grad 0.50 | tok/s 54272
step   1540 | loss 1.5752 | lr 9.99e-05 | grad 0.48 | tok/s 53824
step   1550 | loss 1.5576 | lr 1.46e-04 | grad 2.19 | tok/s 55976
step   1560 | loss 2.1801 | lr 1.92e-04 | grad 1.67 | tok/s 54514
step   1570 | loss 1.6343 | lr 2.35e-04 | grad 0.91 | tok/s 53500
step   1580 | loss 1.7844 | lr 2.69e-04 | grad 1.16 | tok/s 55258
step   1590 | loss 1.6310 | lr 2.91e-04 | grad 0.79 | tok/s 53925
step   1600 | loss 1.6865 | lr 3.00e-04 | grad 0.89 | tok/s 52923
step   1610 | loss 1.5160 | lr 2.94e-04 | grad 0.67 | tok/s 55924
step   1620 | loss 1.6874 | lr 2.74e-04 | grad 0.58 | tok/s 55237
step   1630 | loss 1.6593 | lr 2.42e-04 | grad 0.77 | tok/s 55415
step   1640 | loss 1.6038 | lr 2.01e-04 | grad 0.58 | tok/s 53463
step   1650 | loss 1.6115 | lr 1.55e-04 | grad 1.16 | tok/s 52720
step   1660 | loss 1.6090 | lr 1.09e-04 | grad 0.63 | tok/s 53306
step   1670 | loss 1.6531 | lr 6.65e-05 | grad 1.76 | tok/s 56499
step   1680 | loss 2.0044 | lr 3.24e-05 | grad 0.61 | tok/s 56713
step   1690 | loss 1.5684 | lr 9.84e-06 | grad 0.75 | tok/s 55392
step   1700 | loss 1.8934 | lr 1.07e-06 | grad 0.48 | tok/s 56508
step   1710 | loss 1.6263 | lr 6.93e-06 | grad 0.77 | tok/s 54935
step   1720 | loss 1.6091 | lr 2.68e-05 | grad 0.67 | tok/s 55181
step   1730 | loss 1.7260 | lr 5.89e-05 | grad 0.68 | tok/s 55179
step   1740 | loss 1.6197 | lr 9.99e-05 | grad 0.52 | tok/s 56034
step   1750 | loss 1.5412 | lr 1.46e-04 | grad 0.54 | tok/s 54014
step   1760 | loss 1.7936 | lr 1.92e-04 | grad 0.60 | tok/s 54688
step   1770 | loss 1.7080 | lr 2.35e-04 | grad 0.62 | tok/s 56068
step   1780 | loss 1.6141 | lr 2.69e-04 | grad 0.90 | tok/s 53909
step   1790 | loss 1.8083 | lr 2.91e-04 | grad 0.82 | tok/s 54943
step   1800 | loss 1.5399 | lr 3.00e-04 | grad 0.57 | tok/s 55941
step   1810 | loss 1.6312 | lr 2.94e-04 | grad 0.75 | tok/s 55635
step   1820 | loss 1.5692 | lr 2.74e-04 | grad 0.66 | tok/s 55080
step   1830 | loss 1.6070 | lr 2.42e-04 | grad 0.61 | tok/s 53587
step   1840 | loss 1.5945 | lr 2.01e-04 | grad 1.85 | tok/s 53090
step   1850 | loss 1.8416 | lr 1.55e-04 | grad 1.02 | tok/s 53754
step   1860 | loss 1.5665 | lr 1.09e-04 | grad 0.47 | tok/s 53637
step   1870 | loss 1.6096 | lr 6.65e-05 | grad 1.05 | tok/s 54966
step   1880 | loss 1.5551 | lr 3.24e-05 | grad 0.54 | tok/s 55020
step   1890 | loss 1.6510 | lr 9.84e-06 | grad 0.49 | tok/s 54073
step   1900 | loss 1.6911 | lr 1.07e-06 | grad 1.22 | tok/s 54707
step   1910 | loss 1.6700 | lr 6.93e-06 | grad 1.00 | tok/s 53909
step   1920 | loss 1.5677 | lr 2.68e-05 | grad 0.79 | tok/s 55635
step   1930 | loss 1.5388 | lr 5.89e-05 | grad 0.74 | tok/s 55186
step   1940 | loss 1.4820 | lr 9.99e-05 | grad 0.64 | tok/s 56069
step   1950 | loss 1.5344 | lr 1.46e-04 | grad 0.70 | tok/s 54810
step   1960 | loss 1.8805 | lr 1.92e-04 | grad 3.33 | tok/s 55752
step   1970 | loss 1.5717 | lr 2.35e-04 | grad 1.15 | tok/s 53893
step   1980 | loss 1.6975 | lr 2.69e-04 | grad 1.82 | tok/s 53788
step   1990 | loss 1.7417 | lr 2.91e-04 | grad 0.85 | tok/s 55022
step   2000 | loss 1.6807 | lr 3.00e-04 | grad 1.14 | tok/s 55565
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6807.pt
step   2010 | loss 1.4238 | lr 2.94e-04 | grad 0.58 | tok/s 48854
step   2020 | loss 1.2578 | lr 2.74e-04 | grad 0.50 | tok/s 57088
step   2030 | loss 1.5651 | lr 2.42e-04 | grad 0.82 | tok/s 56707
step   2040 | loss 1.4087 | lr 2.01e-04 | grad 0.44 | tok/s 57227
step   2050 | loss 1.3527 | lr 1.55e-04 | grad 0.77 | tok/s 56877

Training complete! Final step: 2051
