# Job 33: E75h6n32
# GPU: 1
# Command: python train.py --level E75h6n32 --dim 1152 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/E75h6n32
# Started: 2026-01-19T19:56:37.396529
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/E75h6n32/levelE75h6n32_100m_20260119_195642
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h6n32, 93,220,224 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.6462 | lr 2.70e-05 | grad 114.00 | tok/s 21907
step     20 | loss 5.4604 | lr 5.70e-05 | grad 49.75 | tok/s 63731
step     30 | loss 5.3330 | lr 8.70e-05 | grad 27.25 | tok/s 67027
step     40 | loss 4.7688 | lr 1.17e-04 | grad 11.69 | tok/s 66069
step     50 | loss 4.1390 | lr 1.47e-04 | grad 6.56 | tok/s 65534
step     60 | loss 3.8137 | lr 1.77e-04 | grad 9.38 | tok/s 65039
step     70 | loss 3.1918 | lr 2.07e-04 | grad 3.03 | tok/s 62959
step     80 | loss 3.3220 | lr 2.37e-04 | grad 3.73 | tok/s 65421
step     90 | loss 3.0802 | lr 2.67e-04 | grad 4.94 | tok/s 63606
step    100 | loss 2.7270 | lr 2.97e-04 | grad 1.73 | tok/s 64353
step    110 | loss 2.7131 | lr 6.94e-06 | grad 2.67 | tok/s 58707
step    120 | loss 3.0353 | lr 2.69e-05 | grad 2.17 | tok/s 58899
step    130 | loss 2.7964 | lr 5.89e-05 | grad 1.51 | tok/s 60370
step    140 | loss 2.5494 | lr 9.99e-05 | grad 1.12 | tok/s 60233
step    150 | loss 2.4682 | lr 1.46e-04 | grad 2.59 | tok/s 57348
step    160 | loss 2.3169 | lr 1.92e-04 | grad 1.62 | tok/s 58070
step    170 | loss 2.5104 | lr 2.35e-04 | grad 4.88 | tok/s 60009
step    180 | loss 2.5625 | lr 2.69e-04 | grad 1.47 | tok/s 59967
step    190 | loss 2.3070 | lr 2.91e-04 | grad 1.52 | tok/s 60916
step    200 | loss 1.9312 | lr 3.00e-04 | grad 1.24 | tok/s 62704
step    210 | loss 2.4419 | lr 2.94e-04 | grad 2.09 | tok/s 60177
step    220 | loss 2.4134 | lr 2.74e-04 | grad 1.01 | tok/s 62032
step    230 | loss 2.2086 | lr 2.42e-04 | grad 2.42 | tok/s 59977
step    240 | loss 2.2161 | lr 2.01e-04 | grad 1.64 | tok/s 61367
step    250 | loss 2.1442 | lr 1.55e-04 | grad 1.20 | tok/s 60307
step    260 | loss 2.1668 | lr 1.09e-04 | grad 0.81 | tok/s 57815
step    270 | loss 2.0345 | lr 6.65e-05 | grad 1.02 | tok/s 60158
step    280 | loss 1.9413 | lr 3.24e-05 | grad 1.70 | tok/s 60101
step    290 | loss 1.9328 | lr 9.84e-06 | grad 0.86 | tok/s 63090
step    300 | loss 1.8988 | lr 1.07e-06 | grad 0.85 | tok/s 63177
step    310 | loss 1.9050 | lr 6.94e-06 | grad 0.73 | tok/s 63159
step    320 | loss 2.0053 | lr 2.69e-05 | grad 1.84 | tok/s 60790
step    330 | loss 2.0420 | lr 5.89e-05 | grad 0.69 | tok/s 59255
step    340 | loss 2.0540 | lr 9.99e-05 | grad 1.80 | tok/s 60572
step    350 | loss 2.0768 | lr 1.46e-04 | grad 0.95 | tok/s 58854
step    360 | loss 2.0336 | lr 1.92e-04 | grad 2.31 | tok/s 59485
step    370 | loss 1.8783 | lr 2.35e-04 | grad 1.09 | tok/s 60731
step    380 | loss 2.4186 | lr 2.69e-04 | grad 1.28 | tok/s 62286
step    390 | loss 2.0043 | lr 2.91e-04 | grad 1.38 | tok/s 59922
step    400 | loss 2.1227 | lr 3.00e-04 | grad 3.05 | tok/s 61505
step    410 | loss 1.8810 | lr 2.94e-04 | grad 2.25 | tok/s 59620
step    420 | loss 1.9932 | lr 2.74e-04 | grad 1.10 | tok/s 59010
step    430 | loss 2.1337 | lr 2.42e-04 | grad 1.36 | tok/s 58477
step    440 | loss 2.2072 | lr 2.01e-04 | grad 0.99 | tok/s 60559
step    450 | loss 1.9195 | lr 1.55e-04 | grad 0.77 | tok/s 58838
step    460 | loss 1.8988 | lr 1.09e-04 | grad 0.68 | tok/s 59200
step    470 | loss 1.8777 | lr 6.65e-05 | grad 1.03 | tok/s 59869
step    480 | loss 1.7799 | lr 3.24e-05 | grad 0.60 | tok/s 58221
step    490 | loss 1.7380 | lr 9.84e-06 | grad 0.52 | tok/s 59443
step    500 | loss 2.6774 | lr 1.07e-06 | grad 0.95 | tok/s 61057
step    510 | loss 1.7779 | lr 6.94e-06 | grad 0.62 | tok/s 59786
step    520 | loss 1.8466 | lr 2.69e-05 | grad 0.55 | tok/s 61892
step    530 | loss 2.3020 | lr 5.89e-05 | grad 0.60 | tok/s 60625
step    540 | loss 1.7760 | lr 9.99e-05 | grad 1.05 | tok/s 60604
step    550 | loss 1.6614 | lr 1.46e-04 | grad 0.71 | tok/s 62227
step    560 | loss 1.5232 | lr 1.92e-04 | grad 0.70 | tok/s 63166
step    570 | loss 1.8148 | lr 2.35e-04 | grad 2.38 | tok/s 61716
step    580 | loss 2.1608 | lr 2.69e-04 | grad 1.00 | tok/s 60875
step    590 | loss 2.4447 | lr 2.91e-04 | grad 1.81 | tok/s 59573
step    600 | loss 1.9499 | lr 3.00e-04 | grad 1.39 | tok/s 59875
step    610 | loss 1.9476 | lr 2.94e-04 | grad 1.22 | tok/s 62684
step    620 | loss 1.8502 | lr 2.74e-04 | grad 0.84 | tok/s 59433
step    630 | loss 1.7644 | lr 2.42e-04 | grad 0.87 | tok/s 61246
step    640 | loss 2.1195 | lr 2.01e-04 | grad 0.84 | tok/s 61389
step    650 | loss 1.7783 | lr 1.55e-04 | grad 1.01 | tok/s 60304
step    660 | loss 2.1124 | lr 1.09e-04 | grad 4.31 | tok/s 59467
step    670 | loss 1.9168 | lr 6.65e-05 | grad 1.88 | tok/s 61570
step    680 | loss 1.8745 | lr 3.24e-05 | grad 0.95 | tok/s 59335
step    690 | loss 1.8816 | lr 9.84e-06 | grad 1.09 | tok/s 59819
step    700 | loss 1.9643 | lr 1.07e-06 | grad 1.09 | tok/s 60158
step    710 | loss 1.9026 | lr 6.94e-06 | grad 1.00 | tok/s 60491
step    720 | loss 1.9973 | lr 2.68e-05 | grad 1.44 | tok/s 60179
step    730 | loss 1.9530 | lr 5.89e-05 | grad 1.03 | tok/s 60810
step    740 | loss 1.8970 | lr 9.99e-05 | grad 1.77 | tok/s 60257
step    750 | loss 1.6960 | lr 1.46e-04 | grad 1.23 | tok/s 59620
step    760 | loss 2.0735 | lr 1.92e-04 | grad 0.66 | tok/s 60317
step    770 | loss 1.7459 | lr 2.35e-04 | grad 1.03 | tok/s 59925
step    780 | loss 1.8053 | lr 2.69e-04 | grad 0.96 | tok/s 60645
step    790 | loss 1.7324 | lr 2.91e-04 | grad 0.72 | tok/s 61108
step    800 | loss 1.7114 | lr 3.00e-04 | grad 0.89 | tok/s 61157
step    810 | loss 1.8301 | lr 2.94e-04 | grad 1.95 | tok/s 60563
step    820 | loss 2.5245 | lr 2.74e-04 | grad 1.51 | tok/s 62150
step    830 | loss 2.0135 | lr 2.42e-04 | grad 0.70 | tok/s 63106
step    840 | loss 1.7059 | lr 2.01e-04 | grad 0.51 | tok/s 63142
step    850 | loss 2.1990 | lr 1.55e-04 | grad 1.32 | tok/s 60098
step    860 | loss 1.9052 | lr 1.09e-04 | grad 1.02 | tok/s 58787
step    870 | loss 1.8357 | lr 6.65e-05 | grad 0.73 | tok/s 60620
step    880 | loss 1.8776 | lr 3.24e-05 | grad 1.09 | tok/s 60316
step    890 | loss 1.7733 | lr 9.84e-06 | grad 0.71 | tok/s 60272
step    900 | loss 2.2842 | lr 1.07e-06 | grad 0.91 | tok/s 58681
step    910 | loss 1.8579 | lr 6.94e-06 | grad 0.61 | tok/s 59736
step    920 | loss 1.8069 | lr 2.68e-05 | grad 0.64 | tok/s 59585
step    930 | loss 1.9318 | lr 5.89e-05 | grad 1.26 | tok/s 59413
step    940 | loss 1.8101 | lr 9.99e-05 | grad 1.31 | tok/s 58806
step    950 | loss 1.8933 | lr 1.46e-04 | grad 1.23 | tok/s 60197
step    960 | loss 1.6275 | lr 1.92e-04 | grad 0.62 | tok/s 63140
step    970 | loss 1.4313 | lr 2.35e-04 | grad 0.46 | tok/s 63074
step    980 | loss 1.6049 | lr 2.69e-04 | grad 1.62 | tok/s 61390
step    990 | loss 1.9296 | lr 2.91e-04 | grad 0.76 | tok/s 59660
step   1000 | loss 1.8042 | lr 3.00e-04 | grad 0.58 | tok/s 58286
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8042.pt
step   1010 | loss 2.0562 | lr 2.94e-04 | grad 1.19 | tok/s 50814
step   1020 | loss 1.6817 | lr 2.74e-04 | grad 0.76 | tok/s 59783
step   1030 | loss 2.0803 | lr 2.42e-04 | grad 0.83 | tok/s 58794
step   1040 | loss 1.7006 | lr 2.01e-04 | grad 1.12 | tok/s 60044
step   1050 | loss 1.7209 | lr 1.55e-04 | grad 0.71 | tok/s 60340
step   1060 | loss 1.9626 | lr 1.09e-04 | grad 1.45 | tok/s 60415
step   1070 | loss 2.0254 | lr 6.65e-05 | grad 0.76 | tok/s 60592
step   1080 | loss 2.3816 | lr 3.24e-05 | grad 0.90 | tok/s 59863
step   1090 | loss 2.0665 | lr 9.84e-06 | grad 0.76 | tok/s 60254
step   1100 | loss 1.7448 | lr 1.07e-06 | grad 0.71 | tok/s 59878
step   1110 | loss 1.7739 | lr 6.93e-06 | grad 0.66 | tok/s 61016
step   1120 | loss 2.0110 | lr 2.68e-05 | grad 0.80 | tok/s 61702
step   1130 | loss 1.7463 | lr 5.89e-05 | grad 0.62 | tok/s 58604
step   1140 | loss 1.6176 | lr 9.99e-05 | grad 0.58 | tok/s 60108
step   1150 | loss 1.9169 | lr 1.46e-04 | grad 1.06 | tok/s 60005
step   1160 | loss 1.5796 | lr 1.92e-04 | grad 0.53 | tok/s 59341
step   1170 | loss 1.9088 | lr 2.35e-04 | grad 0.69 | tok/s 60054
step   1180 | loss 1.6160 | lr 2.69e-04 | grad 0.71 | tok/s 63134
step   1190 | loss 1.4705 | lr 2.91e-04 | grad 0.55 | tok/s 63104
step   1200 | loss 1.3780 | lr 3.00e-04 | grad 0.57 | tok/s 63204
step   1210 | loss 1.3515 | lr 2.94e-04 | grad 0.73 | tok/s 63128
step   1220 | loss 1.3984 | lr 2.74e-04 | grad 0.71 | tok/s 62649
step   1230 | loss 1.6231 | lr 2.42e-04 | grad 0.86 | tok/s 60402
step   1240 | loss 1.6879 | lr 2.01e-04 | grad 0.79 | tok/s 59316
step   1250 | loss 1.7918 | lr 1.55e-04 | grad 2.52 | tok/s 61131
step   1260 | loss 1.8278 | lr 1.09e-04 | grad 2.14 | tok/s 61058
step   1270 | loss 1.8991 | lr 6.65e-05 | grad 1.16 | tok/s 60391
step   1280 | loss 1.7245 | lr 3.24e-05 | grad 0.71 | tok/s 59622
step   1290 | loss 1.6565 | lr 9.84e-06 | grad 0.75 | tok/s 59410
step   1300 | loss 1.7119 | lr 1.07e-06 | grad 0.66 | tok/s 58988
step   1310 | loss 1.7918 | lr 6.93e-06 | grad 0.68 | tok/s 58978
step   1320 | loss 1.7713 | lr 2.68e-05 | grad 0.98 | tok/s 60042
step   1330 | loss 1.7053 | lr 5.89e-05 | grad 0.53 | tok/s 60137
step   1340 | loss 1.6097 | lr 9.99e-05 | grad 0.84 | tok/s 60084
step   1350 | loss 1.6668 | lr 1.46e-04 | grad 1.47 | tok/s 61817
step   1360 | loss 1.5953 | lr 1.92e-04 | grad 0.66 | tok/s 58685
step   1370 | loss 1.7148 | lr 2.35e-04 | grad 0.76 | tok/s 59551
step   1380 | loss 1.8044 | lr 2.69e-04 | grad 0.80 | tok/s 59972
step   1390 | loss 1.7049 | lr 2.91e-04 | grad 1.34 | tok/s 58592
step   1400 | loss 1.8312 | lr 3.00e-04 | grad 11.50 | tok/s 60978
step   1410 | loss 1.8133 | lr 2.94e-04 | grad 1.02 | tok/s 61552
step   1420 | loss 1.8111 | lr 2.74e-04 | grad 0.80 | tok/s 58562
step   1430 | loss 1.5981 | lr 2.42e-04 | grad 0.96 | tok/s 57164
step   1440 | loss 1.5124 | lr 2.01e-04 | grad 0.63 | tok/s 60181
step   1450 | loss 1.5557 | lr 1.55e-04 | grad 1.79 | tok/s 60859
step   1460 | loss 1.6214 | lr 1.09e-04 | grad 0.52 | tok/s 56952
step   1470 | loss 1.7289 | lr 6.65e-05 | grad 1.86 | tok/s 59243
step   1480 | loss 1.5996 | lr 3.24e-05 | grad 1.50 | tok/s 59480
step   1490 | loss 1.7593 | lr 9.84e-06 | grad 1.97 | tok/s 59257
step   1500 | loss 1.8585 | lr 1.07e-06 | grad 2.00 | tok/s 57890
step   1510 | loss 1.7415 | lr 6.93e-06 | grad 0.98 | tok/s 60828
step   1520 | loss 1.6960 | lr 2.68e-05 | grad 1.01 | tok/s 60246
step   1530 | loss 1.6434 | lr 5.89e-05 | grad 0.51 | tok/s 59744
step   1540 | loss 1.6251 | lr 9.99e-05 | grad 0.50 | tok/s 58791
step   1550 | loss 1.6046 | lr 1.46e-04 | grad 2.12 | tok/s 61094
step   1560 | loss 2.1904 | lr 1.92e-04 | grad 0.98 | tok/s 59646
step   1570 | loss 1.6421 | lr 2.35e-04 | grad 1.05 | tok/s 58555
step   1580 | loss 1.8081 | lr 2.69e-04 | grad 0.94 | tok/s 60541
step   1590 | loss 1.5810 | lr 2.91e-04 | grad 0.66 | tok/s 58772
step   1600 | loss 1.6947 | lr 3.00e-04 | grad 0.79 | tok/s 57853
step   1610 | loss 1.5292 | lr 2.94e-04 | grad 0.69 | tok/s 61142
step   1620 | loss 1.6925 | lr 2.74e-04 | grad 0.58 | tok/s 60416
step   1630 | loss 1.7059 | lr 2.42e-04 | grad 0.73 | tok/s 60749
step   1640 | loss 1.6250 | lr 2.01e-04 | grad 0.56 | tok/s 58787
step   1650 | loss 1.6315 | lr 1.55e-04 | grad 0.97 | tok/s 57843
step   1660 | loss 1.6230 | lr 1.09e-04 | grad 0.61 | tok/s 58150
step   1670 | loss 1.6878 | lr 6.65e-05 | grad 1.76 | tok/s 60804
step   1680 | loss 2.0348 | lr 3.24e-05 | grad 0.48 | tok/s 60718
step   1690 | loss 1.6059 | lr 9.84e-06 | grad 0.84 | tok/s 58805
step   1700 | loss 2.0618 | lr 1.07e-06 | grad 0.47 | tok/s 60047
step   1710 | loss 1.6487 | lr 6.93e-06 | grad 0.75 | tok/s 58397
step   1720 | loss 1.6565 | lr 2.68e-05 | grad 0.73 | tok/s 58529
step   1730 | loss 1.7636 | lr 5.89e-05 | grad 0.69 | tok/s 59298
step   1740 | loss 1.6652 | lr 9.99e-05 | grad 0.57 | tok/s 60124
step   1750 | loss 1.5622 | lr 1.46e-04 | grad 0.46 | tok/s 57185
step   1760 | loss 1.8618 | lr 1.92e-04 | grad 0.58 | tok/s 58025
step   1770 | loss 1.7450 | lr 2.35e-04 | grad 0.59 | tok/s 59695
step   1780 | loss 1.6246 | lr 2.69e-04 | grad 0.98 | tok/s 57372
step   1790 | loss 1.8365 | lr 2.91e-04 | grad 0.68 | tok/s 58481
step   1800 | loss 1.5534 | lr 3.00e-04 | grad 0.64 | tok/s 59694
step   1810 | loss 1.6514 | lr 2.94e-04 | grad 0.75 | tok/s 59356
step   1820 | loss 1.6050 | lr 2.74e-04 | grad 0.76 | tok/s 58832
step   1830 | loss 1.6325 | lr 2.42e-04 | grad 0.65 | tok/s 58593
step   1840 | loss 1.6123 | lr 2.01e-04 | grad 0.78 | tok/s 58067
step   1850 | loss 1.8295 | lr 1.55e-04 | grad 0.94 | tok/s 58653
step   1860 | loss 1.5802 | lr 1.09e-04 | grad 0.46 | tok/s 58516
step   1870 | loss 1.6399 | lr 6.65e-05 | grad 1.14 | tok/s 59905
step   1880 | loss 1.5769 | lr 3.24e-05 | grad 0.52 | tok/s 59874
step   1890 | loss 1.6668 | lr 9.84e-06 | grad 0.51 | tok/s 58974
step   1900 | loss 1.7506 | lr 1.07e-06 | grad 1.36 | tok/s 59469
step   1910 | loss 1.6925 | lr 6.93e-06 | grad 1.06 | tok/s 58830
step   1920 | loss 1.5933 | lr 2.68e-05 | grad 0.86 | tok/s 60568
step   1930 | loss 1.5826 | lr 5.89e-05 | grad 0.83 | tok/s 60018
step   1940 | loss 1.5017 | lr 9.99e-05 | grad 0.62 | tok/s 61213
step   1950 | loss 1.5599 | lr 1.46e-04 | grad 0.79 | tok/s 59582
step   1960 | loss 1.9616 | lr 1.92e-04 | grad 3.95 | tok/s 60864
step   1970 | loss 1.6188 | lr 2.35e-04 | grad 1.16 | tok/s 58722
step   1980 | loss 1.6807 | lr 2.69e-04 | grad 1.81 | tok/s 58793
step   1990 | loss 1.7883 | lr 2.91e-04 | grad 0.99 | tok/s 60320
step   2000 | loss 1.6962 | lr 3.00e-04 | grad 1.09 | tok/s 60736
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6962.pt
step   2010 | loss 1.4281 | lr 2.94e-04 | grad 0.57 | tok/s 50278
step   2020 | loss 1.2712 | lr 2.74e-04 | grad 0.53 | tok/s 62587
step   2030 | loss 1.5923 | lr 2.42e-04 | grad 0.81 | tok/s 62113
step   2040 | loss 1.4242 | lr 2.01e-04 | grad 0.47 | tok/s 63023
step   2050 | loss 1.3724 | lr 1.55e-04 | grad 0.77 | tok/s 61778
step   2060 | loss 1.6897 | lr 1.09e-04 | grad 0.64 | tok/s 58770
step   2070 | loss 1.6322 | lr 6.65e-05 | grad 1.06 | tok/s 61735
step   2080 | loss 1.7825 | lr 3.24e-05 | grad 3.50 | tok/s 58551
step   2090 | loss 1.7084 | lr 9.84e-06 | grad 0.82 | tok/s 60608
step   2100 | loss 1.6452 | lr 1.07e-06 | grad 0.79 | tok/s 58587
step   2110 | loss 1.5238 | lr 6.93e-06 | grad 0.65 | tok/s 60905
step   2120 | loss 1.5162 | lr 2.68e-05 | grad 0.98 | tok/s 60717
step   2130 | loss 1.6213 | lr 5.89e-05 | grad 2.31 | tok/s 58909
step   2140 | loss 1.6896 | lr 9.99e-05 | grad 2.38 | tok/s 58803
step   2150 | loss 1.6917 | lr 1.46e-04 | grad 0.50 | tok/s 59733
step   2160 | loss 1.6326 | lr 1.92e-04 | grad 0.56 | tok/s 59147
step   2170 | loss 1.7410 | lr 2.35e-04 | grad 0.64 | tok/s 59632
step   2180 | loss 1.6003 | lr 2.69e-04 | grad 0.71 | tok/s 60965
step   2190 | loss 1.9252 | lr 2.91e-04 | grad 0.69 | tok/s 60672
step   2200 | loss 1.3637 | lr 3.00e-04 | grad 0.52 | tok/s 62977
step   2210 | loss 1.3279 | lr 2.94e-04 | grad 0.42 | tok/s 63004
step   2220 | loss 1.2824 | lr 2.74e-04 | grad 0.44 | tok/s 62919
step   2230 | loss 1.5529 | lr 2.42e-04 | grad 0.75 | tok/s 60899
step   2240 | loss 1.7866 | lr 2.01e-04 | grad 1.46 | tok/s 62354
step   2250 | loss 1.7042 | lr 1.55e-04 | grad 0.84 | tok/s 61604
step   2260 | loss 1.7704 | lr 1.09e-04 | grad 0.79 | tok/s 60703
step   2270 | loss 1.5636 | lr 6.65e-05 | grad 0.84 | tok/s 59640
step   2280 | loss 1.7203 | lr 3.24e-05 | grad 0.59 | tok/s 59485

Training complete! Final step: 2282
