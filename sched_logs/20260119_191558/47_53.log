# Job 47: 53
# GPU: 2
# Command: python train.py --level 53 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/53
# Started: 2026-01-19T20:07:12.037386
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/53/level53_100m_20260119_200717
Auto r_h_mode: spectral_norm (level 53 has full W_h)
Model: Level 53, 65,738,880 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.3967 | lr 2.70e-05 | grad 22.25 | tok/s 22310
step     20 | loss 4.6790 | lr 5.70e-05 | grad 15.75 | tok/s 58879
step     30 | loss 5.2450 | lr 8.70e-05 | grad 10.69 | tok/s 61304
step     40 | loss 4.9504 | lr 1.17e-04 | grad 4.56 | tok/s 61520
step     50 | loss 4.3072 | lr 1.47e-04 | grad 9.44 | tok/s 62401
step     60 | loss 3.9101 | lr 1.77e-04 | grad 9.06 | tok/s 61229
step     70 | loss 3.3173 | lr 2.07e-04 | grad 0.98 | tok/s 58661
step     80 | loss 3.5696 | lr 2.37e-04 | grad 2.28 | tok/s 61331
step     90 | loss 3.4542 | lr 2.67e-04 | grad 3.23 | tok/s 59331
step    100 | loss 3.3028 | lr 2.97e-04 | grad 1.28 | tok/s 59800
step    110 | loss 3.2037 | lr 6.94e-06 | grad 1.77 | tok/s 56114
step    120 | loss 3.5791 | lr 2.69e-05 | grad 6.12 | tok/s 56594
step    130 | loss 3.3618 | lr 5.89e-05 | grad 0.94 | tok/s 57841
step    140 | loss 3.1482 | lr 9.99e-05 | grad 0.81 | tok/s 57766
step    150 | loss 2.9216 | lr 1.46e-04 | grad 2.02 | tok/s 55328
step    160 | loss 2.6516 | lr 1.92e-04 | grad 1.42 | tok/s 55216
step    170 | loss 2.7328 | lr 2.35e-04 | grad 3.08 | tok/s 57702
step    180 | loss 2.7191 | lr 2.69e-04 | grad 1.40 | tok/s 57666
step    190 | loss 2.4089 | lr 2.91e-04 | grad 1.11 | tok/s 58529
step    200 | loss 2.0796 | lr 3.00e-04 | grad 0.96 | tok/s 60189
step    210 | loss 2.5597 | lr 2.94e-04 | grad 1.59 | tok/s 57178
step    220 | loss 2.4757 | lr 2.74e-04 | grad 1.02 | tok/s 59293
step    230 | loss 2.2706 | lr 2.42e-04 | grad 1.08 | tok/s 57480
step    240 | loss 2.2905 | lr 2.01e-04 | grad 1.41 | tok/s 58550
step    250 | loss 2.2574 | lr 1.55e-04 | grad 1.08 | tok/s 56901
step    260 | loss 2.2707 | lr 1.09e-04 | grad 0.59 | tok/s 55127
step    270 | loss 2.1493 | lr 6.65e-05 | grad 0.71 | tok/s 57655
step    280 | loss 2.0407 | lr 3.24e-05 | grad 1.41 | tok/s 57016
step    290 | loss 2.0744 | lr 9.84e-06 | grad 0.75 | tok/s 60362
step    300 | loss 2.0445 | lr 1.07e-06 | grad 0.68 | tok/s 60659
step    310 | loss 2.0539 | lr 6.94e-06 | grad 0.63 | tok/s 60089
step    320 | loss 2.1177 | lr 2.69e-05 | grad 1.34 | tok/s 58435
step    330 | loss 2.1591 | lr 5.89e-05 | grad 0.54 | tok/s 56133
step    340 | loss 2.1593 | lr 9.99e-05 | grad 1.24 | tok/s 58135
step    350 | loss 2.1714 | lr 1.46e-04 | grad 0.87 | tok/s 56464
step    360 | loss 2.1312 | lr 1.92e-04 | grad 1.87 | tok/s 56889
step    370 | loss 2.0198 | lr 2.35e-04 | grad 1.00 | tok/s 57831
step    380 | loss 2.5474 | lr 2.69e-04 | grad 1.20 | tok/s 59617
step    390 | loss 2.1437 | lr 2.91e-04 | grad 1.19 | tok/s 57269
step    400 | loss 2.2229 | lr 3.00e-04 | grad 1.93 | tok/s 58375
step    410 | loss 1.9945 | lr 2.94e-04 | grad 2.09 | tok/s 56702
step    420 | loss 2.1341 | lr 2.74e-04 | grad 0.95 | tok/s 56706
step    430 | loss 2.2638 | lr 2.42e-04 | grad 1.05 | tok/s 56173
step    440 | loss 2.3398 | lr 2.01e-04 | grad 1.33 | tok/s 58657
step    450 | loss 2.0785 | lr 1.55e-04 | grad 0.61 | tok/s 57455
step    460 | loss 2.0129 | lr 1.09e-04 | grad 0.61 | tok/s 57655
step    470 | loss 2.0060 | lr 6.65e-05 | grad 0.89 | tok/s 58269
step    480 | loss 1.9119 | lr 3.24e-05 | grad 0.51 | tok/s 55819
step    490 | loss 1.8705 | lr 9.84e-06 | grad 0.48 | tok/s 57360
step    500 | loss 2.8106 | lr 1.07e-06 | grad 0.75 | tok/s 58673
step    510 | loss 1.8731 | lr 6.94e-06 | grad 0.54 | tok/s 57648
step    520 | loss 1.9433 | lr 2.69e-05 | grad 0.44 | tok/s 59169
step    530 | loss 2.3888 | lr 5.89e-05 | grad 0.48 | tok/s 58174
step    540 | loss 1.8780 | lr 9.99e-05 | grad 0.76 | tok/s 58291
step    550 | loss 1.8145 | lr 1.46e-04 | grad 0.63 | tok/s 59788
step    560 | loss 1.6858 | lr 1.92e-04 | grad 0.70 | tok/s 60397
step    570 | loss 1.9551 | lr 2.35e-04 | grad 1.62 | tok/s 59424
step    580 | loss 2.3056 | lr 2.69e-04 | grad 1.08 | tok/s 57749
step    590 | loss 2.6025 | lr 2.91e-04 | grad 1.73 | tok/s 57265
step    600 | loss 2.1439 | lr 3.00e-04 | grad 1.11 | tok/s 57526
step    610 | loss 2.1208 | lr 2.94e-04 | grad 1.16 | tok/s 60372
step    620 | loss 2.0142 | lr 2.74e-04 | grad 0.80 | tok/s 57277
step    630 | loss 1.9198 | lr 2.42e-04 | grad 0.79 | tok/s 58770
step    640 | loss 2.2075 | lr 2.01e-04 | grad 0.89 | tok/s 58555
step    650 | loss 1.9610 | lr 1.55e-04 | grad 0.88 | tok/s 57917
step    660 | loss 2.2686 | lr 1.09e-04 | grad 3.62 | tok/s 56997
step    670 | loss 2.0583 | lr 6.65e-05 | grad 1.29 | tok/s 59364
step    680 | loss 1.9854 | lr 3.24e-05 | grad 0.78 | tok/s 57347
step    690 | loss 2.0223 | lr 9.84e-06 | grad 0.80 | tok/s 57747
step    700 | loss 2.0872 | lr 1.07e-06 | grad 0.86 | tok/s 57845
step    710 | loss 2.0133 | lr 6.94e-06 | grad 0.79 | tok/s 58018
step    720 | loss 2.1545 | lr 2.68e-05 | grad 1.00 | tok/s 58131
step    730 | loss 2.0793 | lr 5.89e-05 | grad 0.86 | tok/s 57813
step    740 | loss 2.0000 | lr 9.99e-05 | grad 1.39 | tok/s 58158
step    750 | loss 1.8204 | lr 1.46e-04 | grad 1.02 | tok/s 57371
step    760 | loss 2.1506 | lr 1.92e-04 | grad 0.65 | tok/s 58178
step    770 | loss 1.9068 | lr 2.35e-04 | grad 1.01 | tok/s 57389
step    780 | loss 1.9556 | lr 2.69e-04 | grad 0.94 | tok/s 58010
step    790 | loss 1.9072 | lr 2.91e-04 | grad 0.83 | tok/s 58868
step    800 | loss 1.9053 | lr 3.00e-04 | grad 0.83 | tok/s 58371
step    810 | loss 2.0088 | lr 2.94e-04 | grad 1.45 | tok/s 58093
step    820 | loss 2.6449 | lr 2.74e-04 | grad 1.45 | tok/s 59936
step    830 | loss 2.2045 | lr 2.42e-04 | grad 0.60 | tok/s 60943
step    840 | loss 1.9746 | lr 2.01e-04 | grad 0.44 | tok/s 60866
step    850 | loss 2.3654 | lr 1.55e-04 | grad 1.01 | tok/s 57967
step    860 | loss 2.1167 | lr 1.09e-04 | grad 0.98 | tok/s 56386
step    870 | loss 2.0239 | lr 6.65e-05 | grad 0.64 | tok/s 58470
step    880 | loss 2.0779 | lr 3.24e-05 | grad 0.86 | tok/s 57832
step    890 | loss 1.9538 | lr 9.84e-06 | grad 0.58 | tok/s 58078
step    900 | loss 2.4477 | lr 1.07e-06 | grad 0.71 | tok/s 56662
step    910 | loss 2.0198 | lr 6.94e-06 | grad 0.51 | tok/s 57594
step    920 | loss 1.9842 | lr 2.68e-05 | grad 0.49 | tok/s 56948
step    930 | loss 2.1192 | lr 5.89e-05 | grad 1.00 | tok/s 56433
step    940 | loss 1.9988 | lr 9.99e-05 | grad 1.06 | tok/s 56783
step    950 | loss 2.0361 | lr 1.46e-04 | grad 1.05 | tok/s 57750
step    960 | loss 1.8424 | lr 1.92e-04 | grad 0.58 | tok/s 61038
step    970 | loss 1.6444 | lr 2.35e-04 | grad 0.43 | tok/s 60753
step    980 | loss 1.7761 | lr 2.69e-04 | grad 1.65 | tok/s 59290
step    990 | loss 2.1154 | lr 2.91e-04 | grad 0.64 | tok/s 57477
step   1000 | loss 1.9767 | lr 3.00e-04 | grad 0.59 | tok/s 56242
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9767.pt
step   1010 | loss 2.2095 | lr 2.94e-04 | grad 0.91 | tok/s 51509
step   1020 | loss 1.8649 | lr 2.74e-04 | grad 0.66 | tok/s 57144
step   1030 | loss 2.2471 | lr 2.42e-04 | grad 0.76 | tok/s 56446
step   1040 | loss 1.8644 | lr 2.01e-04 | grad 1.00 | tok/s 58061
step   1050 | loss 1.8493 | lr 1.55e-04 | grad 0.64 | tok/s 58198
step   1060 | loss 2.1122 | lr 1.09e-04 | grad 1.20 | tok/s 58380
step   1070 | loss 2.1813 | lr 6.65e-05 | grad 0.66 | tok/s 58354
step   1080 | loss 2.4755 | lr 3.24e-05 | grad 0.83 | tok/s 57271
step   1090 | loss 2.2099 | lr 9.84e-06 | grad 0.71 | tok/s 58137
step   1100 | loss 1.8873 | lr 1.07e-06 | grad 0.67 | tok/s 56998
step   1110 | loss 1.9074 | lr 6.93e-06 | grad 0.55 | tok/s 58779
step   1120 | loss 2.1298 | lr 2.68e-05 | grad 0.68 | tok/s 59155
step   1130 | loss 1.8758 | lr 5.89e-05 | grad 0.50 | tok/s 56642
step   1140 | loss 1.7651 | lr 9.99e-05 | grad 0.60 | tok/s 57709
step   1150 | loss 2.0544 | lr 1.46e-04 | grad 0.80 | tok/s 57960
step   1160 | loss 1.7269 | lr 1.92e-04 | grad 0.53 | tok/s 57003
step   1170 | loss 2.0419 | lr 2.35e-04 | grad 0.61 | tok/s 57596
step   1180 | loss 1.7764 | lr 2.69e-04 | grad 0.70 | tok/s 60959
step   1190 | loss 1.6724 | lr 2.91e-04 | grad 0.66 | tok/s 60223
step   1200 | loss 1.5970 | lr 3.00e-04 | grad 0.64 | tok/s 60914
step   1210 | loss 1.5483 | lr 2.94e-04 | grad 0.60 | tok/s 60888
step   1220 | loss 1.5903 | lr 2.74e-04 | grad 0.72 | tok/s 60431
step   1230 | loss 1.7738 | lr 2.42e-04 | grad 0.76 | tok/s 57434
step   1240 | loss 1.8640 | lr 2.01e-04 | grad 0.78 | tok/s 57247
step   1250 | loss 1.9419 | lr 1.55e-04 | grad 2.12 | tok/s 58764
step   1260 | loss 1.9840 | lr 1.09e-04 | grad 1.65 | tok/s 58998
step   1270 | loss 2.0273 | lr 6.65e-05 | grad 0.91 | tok/s 58242
step   1280 | loss 1.8645 | lr 3.24e-05 | grad 0.69 | tok/s 57483
step   1290 | loss 1.8017 | lr 9.84e-06 | grad 0.65 | tok/s 57216
step   1300 | loss 1.8526 | lr 1.07e-06 | grad 0.57 | tok/s 56971
step   1310 | loss 1.9608 | lr 6.93e-06 | grad 0.61 | tok/s 56748
step   1320 | loss 1.9107 | lr 2.68e-05 | grad 0.79 | tok/s 57139
step   1330 | loss 1.8363 | lr 5.89e-05 | grad 0.52 | tok/s 57407
step   1340 | loss 1.7691 | lr 9.99e-05 | grad 0.74 | tok/s 57970
step   1350 | loss 1.8374 | lr 1.46e-04 | grad 1.34 | tok/s 59638
step   1360 | loss 1.7758 | lr 1.92e-04 | grad 0.56 | tok/s 56474
step   1370 | loss 1.8778 | lr 2.35e-04 | grad 0.72 | tok/s 57437
step   1380 | loss 1.9747 | lr 2.69e-04 | grad 0.84 | tok/s 57620
step   1390 | loss 1.8927 | lr 2.91e-04 | grad 1.09 | tok/s 56586
step   1400 | loss 1.9957 | lr 3.00e-04 | grad 8.38 | tok/s 58613
step   1410 | loss 1.9939 | lr 2.94e-04 | grad 0.98 | tok/s 59416
step   1420 | loss 1.9673 | lr 2.74e-04 | grad 0.73 | tok/s 55708
step   1430 | loss 1.7694 | lr 2.42e-04 | grad 0.62 | tok/s 55311
step   1440 | loss 1.6724 | lr 2.01e-04 | grad 0.66 | tok/s 58101
step   1450 | loss 1.7399 | lr 1.55e-04 | grad 1.47 | tok/s 59582
step   1460 | loss 1.7595 | lr 1.09e-04 | grad 0.44 | tok/s 55301
step   1470 | loss 1.8625 | lr 6.65e-05 | grad 1.40 | tok/s 57358
step   1480 | loss 1.7534 | lr 3.24e-05 | grad 1.21 | tok/s 58201
step   1490 | loss 1.8694 | lr 9.84e-06 | grad 1.70 | tok/s 58145
step   1500 | loss 1.9733 | lr 1.07e-06 | grad 1.39 | tok/s 55873
step   1510 | loss 1.8863 | lr 6.93e-06 | grad 0.75 | tok/s 59215
step   1520 | loss 1.8485 | lr 2.68e-05 | grad 0.84 | tok/s 58998
step   1530 | loss 1.7882 | lr 5.89e-05 | grad 0.43 | tok/s 58279
step   1540 | loss 1.7702 | lr 9.99e-05 | grad 0.41 | tok/s 57452
step   1550 | loss 1.7523 | lr 1.46e-04 | grad 1.79 | tok/s 59486
step   1560 | loss 2.3420 | lr 1.92e-04 | grad 1.16 | tok/s 58170
step   1570 | loss 1.8207 | lr 2.35e-04 | grad 0.93 | tok/s 57153
step   1580 | loss 2.0123 | lr 2.69e-04 | grad 0.82 | tok/s 58817
step   1590 | loss 1.7536 | lr 2.91e-04 | grad 0.79 | tok/s 57542
step   1600 | loss 1.8661 | lr 3.00e-04 | grad 0.90 | tok/s 56387
step   1610 | loss 1.7187 | lr 2.94e-04 | grad 0.57 | tok/s 58766
step   1620 | loss 1.8595 | lr 2.74e-04 | grad 0.52 | tok/s 58507
step   1630 | loss 1.8759 | lr 2.42e-04 | grad 0.69 | tok/s 59363
step   1640 | loss 1.7845 | lr 2.01e-04 | grad 0.52 | tok/s 57287
step   1650 | loss 1.7912 | lr 1.55e-04 | grad 0.91 | tok/s 56426
step   1660 | loss 1.7827 | lr 1.09e-04 | grad 0.55 | tok/s 56628
step   1670 | loss 1.8558 | lr 6.65e-05 | grad 1.52 | tok/s 59279
step   1680 | loss 2.2101 | lr 3.24e-05 | grad 0.47 | tok/s 58016
step   1690 | loss 1.7619 | lr 9.84e-06 | grad 0.70 | tok/s 57568
step   1700 | loss 2.1606 | lr 1.07e-06 | grad 0.48 | tok/s 59100
step   1710 | loss 1.7870 | lr 6.93e-06 | grad 0.66 | tok/s 57225
step   1720 | loss 1.8103 | lr 2.68e-05 | grad 0.70 | tok/s 57657
step   1730 | loss 1.9053 | lr 5.89e-05 | grad 0.55 | tok/s 57462
step   1740 | loss 1.8085 | lr 9.99e-05 | grad 0.48 | tok/s 58458
step   1750 | loss 1.7139 | lr 1.46e-04 | grad 0.46 | tok/s 56344
step   1760 | loss 2.0016 | lr 1.92e-04 | grad 0.54 | tok/s 56258
step   1770 | loss 1.9103 | lr 2.35e-04 | grad 0.54 | tok/s 58208
step   1780 | loss 1.8095 | lr 2.69e-04 | grad 0.79 | tok/s 56243
step   1790 | loss 2.0001 | lr 2.91e-04 | grad 0.62 | tok/s 57273
step   1800 | loss 1.7368 | lr 3.00e-04 | grad 0.67 | tok/s 58350
step   1810 | loss 1.8103 | lr 2.94e-04 | grad 0.70 | tok/s 57909
step   1820 | loss 1.7615 | lr 2.74e-04 | grad 0.59 | tok/s 57477
step   1830 | loss 1.8080 | lr 2.42e-04 | grad 0.62 | tok/s 57010
step   1840 | loss 1.7708 | lr 2.01e-04 | grad 0.80 | tok/s 56466
step   1850 | loss 1.9687 | lr 1.55e-04 | grad 0.71 | tok/s 56371
step   1860 | loss 1.7385 | lr 1.09e-04 | grad 0.39 | tok/s 56996
step   1870 | loss 1.7929 | lr 6.65e-05 | grad 0.91 | tok/s 58567
step   1880 | loss 1.7191 | lr 3.24e-05 | grad 0.46 | tok/s 58485
step   1890 | loss 1.8146 | lr 9.84e-06 | grad 0.44 | tok/s 57630
step   1900 | loss 1.8685 | lr 1.07e-06 | grad 0.98 | tok/s 58235
step   1910 | loss 1.8123 | lr 6.93e-06 | grad 0.82 | tok/s 57291
step   1920 | loss 1.7457 | lr 2.68e-05 | grad 0.75 | tok/s 59068
step   1930 | loss 1.7303 | lr 5.89e-05 | grad 0.66 | tok/s 57893
step   1940 | loss 1.6285 | lr 9.99e-05 | grad 0.54 | tok/s 59856
step   1950 | loss 1.6959 | lr 1.46e-04 | grad 0.65 | tok/s 58262
step   1960 | loss 2.1105 | lr 1.92e-04 | grad 2.91 | tok/s 59474
step   1970 | loss 1.8524 | lr 2.35e-04 | grad 1.00 | tok/s 57410
step   1980 | loss 1.8737 | lr 2.69e-04 | grad 1.48 | tok/s 56996
step   1990 | loss 2.0004 | lr 2.91e-04 | grad 0.82 | tok/s 58453
step   2000 | loss 1.9276 | lr 3.00e-04 | grad 1.00 | tok/s 58532
  >>> saved checkpoint: checkpoint_step_002000_loss_1.9276.pt
step   2010 | loss 1.6664 | lr 2.94e-04 | grad 0.54 | tok/s 51994
step   2020 | loss 1.4975 | lr 2.74e-04 | grad 0.64 | tok/s 61021
step   2030 | loss 1.7942 | lr 2.42e-04 | grad 0.80 | tok/s 60044
step   2040 | loss 1.6077 | lr 2.01e-04 | grad 0.45 | tok/s 61020
step   2050 | loss 1.5515 | lr 1.55e-04 | grad 0.68 | tok/s 59697
step   2060 | loss 1.8387 | lr 1.09e-04 | grad 0.57 | tok/s 57230
step   2070 | loss 1.7726 | lr 6.65e-05 | grad 0.86 | tok/s 59550
step   2080 | loss 1.9247 | lr 3.24e-05 | grad 2.20 | tok/s 56713
step   2090 | loss 1.8230 | lr 9.84e-06 | grad 0.71 | tok/s 59048
step   2100 | loss 1.7901 | lr 1.07e-06 | grad 0.63 | tok/s 56407
step   2110 | loss 1.6613 | lr 6.93e-06 | grad 0.53 | tok/s 58250
step   2120 | loss 1.6655 | lr 2.68e-05 | grad 0.80 | tok/s 57731
step   2130 | loss 1.7699 | lr 5.89e-05 | grad 1.54 | tok/s 56091
step   2140 | loss 1.8214 | lr 9.99e-05 | grad 1.81 | tok/s 55740
step   2150 | loss 1.8401 | lr 1.46e-04 | grad 0.44 | tok/s 57095
step   2160 | loss 1.7886 | lr 1.92e-04 | grad 0.48 | tok/s 56297
step   2170 | loss 1.8881 | lr 2.35e-04 | grad 0.57 | tok/s 53533
step   2180 | loss 1.8025 | lr 2.69e-04 | grad 0.67 | tok/s 55588
step   2190 | loss 2.1357 | lr 2.91e-04 | grad 0.65 | tok/s 58237

Training complete! Final step: 2198
