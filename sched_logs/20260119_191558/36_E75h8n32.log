# Job 36: E75h8n32
# GPU: 5
# Command: python train.py --level E75h8n32 --dim 1024 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/E75h8n32
# Started: 2026-01-19T19:56:44.857012
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/E75h8n32/levelE75h8n32_100m_20260119_195650
Auto r_h_mode: none (level 0 has bounded/no W_h)
Traceback (most recent call last):
  File "/home/erikg/elman/train.py", line 555, in <module>
    train(args)
  File "/home/erikg/elman/train.py", line 333, in train
    model = LadderLM(
            ^^^^^^^^^
  File "/home/erikg/elman/elman/models/ladder_lm.py", line 462, in __init__
    LayerClass = get_ladder_level(level)
                 ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/elman/elman/models/ladder_lm.py", line 406, in get_ladder_level
    raise ValueError(f"Invalid level {level}. Available: 0-6, 8-17, 18a/b/e, 19a/b/d/e, 20-26, 28, 30-68, gdn, gdn-vec, fla-gdn, llama, mamba2")
ValueError: Invalid level E75h8n32. Available: 0-6, 8-17, 18a/b/e, 19a/b/d/e, 20-26, 28, 30-68, gdn, gdn-vec, fla-gdn, llama, mamba2
