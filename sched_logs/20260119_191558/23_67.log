# Job 23: 67
# GPU: 2
# Command: python train.py --level 67 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/67
# Started: 2026-01-19T19:36:28.663484
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/67/level67_100m_20260119_193635
Auto r_h_mode: none (level 67 has bounded/no W_h)
Model: Level 67, 98,558,080 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.4972 | lr 2.70e-05 | grad 11.50 | tok/s 24476
step     20 | loss 4.4566 | lr 5.70e-05 | grad 7.91 | tok/s 80470
step     30 | loss 4.7634 | lr 8.70e-05 | grad 4.06 | tok/s 85265
step     40 | loss 3.8805 | lr 1.17e-04 | grad 3.16 | tok/s 85165
step     50 | loss 3.4991 | lr 1.47e-04 | grad 2.69 | tok/s 84326
step     60 | loss 3.6119 | lr 1.77e-04 | grad 1.83 | tok/s 81561
step     70 | loss 3.2460 | lr 2.07e-04 | grad 1.68 | tok/s 76764
step     80 | loss 3.5774 | lr 2.37e-04 | grad 2.45 | tok/s 79937
step     90 | loss 3.4501 | lr 2.67e-04 | grad 3.27 | tok/s 78752
step    100 | loss 3.2952 | lr 2.97e-04 | grad 1.18 | tok/s 78587
step    110 | loss 3.2236 | lr 6.94e-06 | grad 1.83 | tok/s 70494
step    120 | loss 3.5899 | lr 2.69e-05 | grad 1.37 | tok/s 70492
step    130 | loss 3.3878 | lr 5.89e-05 | grad 0.97 | tok/s 73229
step    140 | loss 3.1894 | lr 9.99e-05 | grad 0.84 | tok/s 73213
step    150 | loss 3.0749 | lr 1.46e-04 | grad 1.91 | tok/s 69662
step    160 | loss 3.0395 | lr 1.92e-04 | grad 1.01 | tok/s 70571
step    170 | loss 3.1975 | lr 2.35e-04 | grad 3.38 | tok/s 73382
step    180 | loss 3.2875 | lr 2.69e-04 | grad 2.30 | tok/s 72907
step    190 | loss 3.0201 | lr 2.91e-04 | grad 1.28 | tok/s 74410
step    200 | loss 2.7968 | lr 3.00e-04 | grad 1.88 | tok/s 76152
step    210 | loss 2.8394 | lr 2.94e-04 | grad 2.16 | tok/s 69367
step    220 | loss 2.7566 | lr 2.74e-04 | grad 1.21 | tok/s 70433
step    230 | loss 2.5195 | lr 2.42e-04 | grad 1.20 | tok/s 65957
step    240 | loss 2.5570 | lr 2.01e-04 | grad 1.42 | tok/s 71107
step    250 | loss 2.4644 | lr 1.55e-04 | grad 1.25 | tok/s 69355
step    260 | loss 2.4410 | lr 1.09e-04 | grad 0.71 | tok/s 66617
step    270 | loss 2.3276 | lr 6.65e-05 | grad 1.01 | tok/s 69416
step    280 | loss 2.2197 | lr 3.24e-05 | grad 1.72 | tok/s 69706
step    290 | loss 2.3032 | lr 9.84e-06 | grad 0.82 | tok/s 74201
step    300 | loss 2.2807 | lr 1.07e-06 | grad 0.77 | tok/s 74238
step    310 | loss 2.2833 | lr 6.94e-06 | grad 0.71 | tok/s 74000
step    320 | loss 2.2949 | lr 2.69e-05 | grad 1.34 | tok/s 71689
step    330 | loss 2.3426 | lr 5.89e-05 | grad 0.66 | tok/s 70259
step    340 | loss 2.3509 | lr 9.99e-05 | grad 1.33 | tok/s 71182
step    350 | loss 2.3547 | lr 1.46e-04 | grad 1.34 | tok/s 69129
step    360 | loss 2.3197 | lr 1.92e-04 | grad 2.23 | tok/s 70388
step    370 | loss 2.2172 | lr 2.35e-04 | grad 1.33 | tok/s 71122
step    380 | loss 2.6442 | lr 2.69e-04 | grad 2.00 | tok/s 73327
step    390 | loss 2.2763 | lr 2.91e-04 | grad 1.62 | tok/s 70670
step    400 | loss 2.3467 | lr 3.00e-04 | grad 1.98 | tok/s 73017
step    410 | loss 2.1037 | lr 2.94e-04 | grad 2.31 | tok/s 70245
step    420 | loss 2.2404 | lr 2.74e-04 | grad 1.70 | tok/s 69842
step    430 | loss 2.3102 | lr 2.42e-04 | grad 1.48 | tok/s 69678
step    440 | loss 2.4098 | lr 2.01e-04 | grad 1.19 | tok/s 72231
step    450 | loss 2.1232 | lr 1.55e-04 | grad 0.75 | tok/s 70452
step    460 | loss 2.0921 | lr 1.09e-04 | grad 0.72 | tok/s 70865
step    470 | loss 2.1119 | lr 6.65e-05 | grad 1.40 | tok/s 71446
step    480 | loss 2.0107 | lr 3.24e-05 | grad 0.62 | tok/s 68813
step    490 | loss 1.9680 | lr 9.84e-06 | grad 0.58 | tok/s 70599
step    500 | loss 2.8310 | lr 1.07e-06 | grad 0.89 | tok/s 72314
step    510 | loss 1.9585 | lr 6.94e-06 | grad 0.65 | tok/s 70678
step    520 | loss 2.0553 | lr 2.69e-05 | grad 0.52 | tok/s 72649
step    530 | loss 2.4573 | lr 5.89e-05 | grad 0.82 | tok/s 71587
step    540 | loss 1.9795 | lr 9.99e-05 | grad 1.12 | tok/s 71699
step    550 | loss 1.9402 | lr 1.46e-04 | grad 0.89 | tok/s 73543
step    560 | loss 1.8180 | lr 1.92e-04 | grad 0.93 | tok/s 74530
step    570 | loss 2.0467 | lr 2.35e-04 | grad 2.39 | tok/s 72656
step    580 | loss 2.3703 | lr 2.69e-04 | grad 1.30 | tok/s 72640
step    590 | loss 2.5378 | lr 2.91e-04 | grad 2.17 | tok/s 70183
step    600 | loss 2.1735 | lr 3.00e-04 | grad 1.45 | tok/s 68901
step    610 | loss 2.1366 | lr 2.94e-04 | grad 1.64 | tok/s 73899
step    620 | loss 2.0494 | lr 2.74e-04 | grad 1.04 | tok/s 70361
step    630 | loss 1.9956 | lr 2.42e-04 | grad 1.18 | tok/s 71180
step    640 | loss 2.2678 | lr 2.01e-04 | grad 1.05 | tok/s 71609
step    650 | loss 2.0004 | lr 1.55e-04 | grad 1.35 | tok/s 69743
step    660 | loss 2.2752 | lr 1.09e-04 | grad 4.31 | tok/s 69642
step    670 | loss 2.1050 | lr 6.65e-05 | grad 2.06 | tok/s 77322
step    680 | loss 2.0311 | lr 3.24e-05 | grad 1.01 | tok/s 74450
step    690 | loss 2.0503 | lr 9.84e-06 | grad 1.15 | tok/s 71848
step    700 | loss 2.1378 | lr 1.07e-06 | grad 1.13 | tok/s 70790
step    710 | loss 2.0555 | lr 6.94e-06 | grad 1.02 | tok/s 73160
step    720 | loss 2.1666 | lr 2.68e-05 | grad 1.41 | tok/s 72847
step    730 | loss 2.1129 | lr 5.89e-05 | grad 1.20 | tok/s 74027
step    740 | loss 2.0377 | lr 9.99e-05 | grad 1.76 | tok/s 72090
step    750 | loss 1.8786 | lr 1.46e-04 | grad 1.50 | tok/s 74782
step    760 | loss 2.2649 | lr 1.92e-04 | grad 1.22 | tok/s 76027
step    770 | loss 1.9322 | lr 2.35e-04 | grad 1.22 | tok/s 75377
step    780 | loss 1.9844 | lr 2.69e-04 | grad 1.60 | tok/s 76278
step    790 | loss 1.9647 | lr 2.91e-04 | grad 1.39 | tok/s 76799
step    800 | loss 1.9244 | lr 3.00e-04 | grad 1.20 | tok/s 76715
step    810 | loss 1.9563 | lr 2.94e-04 | grad 1.91 | tok/s 76144
step    820 | loss 2.5608 | lr 2.74e-04 | grad 1.62 | tok/s 77027
step    830 | loss 2.1738 | lr 2.42e-04 | grad 1.09 | tok/s 75424
step    840 | loss 1.8956 | lr 2.01e-04 | grad 0.99 | tok/s 75457
step    850 | loss 2.2436 | lr 1.55e-04 | grad 1.43 | tok/s 70593
step    860 | loss 2.0248 | lr 1.09e-04 | grad 1.18 | tok/s 71064
step    870 | loss 1.9492 | lr 6.65e-05 | grad 0.98 | tok/s 73358
step    880 | loss 1.9990 | lr 3.24e-05 | grad 1.33 | tok/s 73664
step    890 | loss 1.9001 | lr 9.84e-06 | grad 0.82 | tok/s 74031
step    900 | loss 2.2817 | lr 1.07e-06 | grad 0.82 | tok/s 70462
step    910 | loss 1.9396 | lr 6.94e-06 | grad 0.76 | tok/s 71707
step    920 | loss 1.9312 | lr 2.68e-05 | grad 0.74 | tok/s 69687
step    930 | loss 2.0341 | lr 5.89e-05 | grad 1.38 | tok/s 68080
step    940 | loss 1.9450 | lr 9.99e-05 | grad 1.31 | tok/s 69451
step    950 | loss 1.9949 | lr 1.46e-04 | grad 1.80 | tok/s 70893
step    960 | loss 1.8016 | lr 1.92e-04 | grad 0.95 | tok/s 73186
step    970 | loss 1.6138 | lr 2.35e-04 | grad 0.85 | tok/s 74732
step    980 | loss 1.7384 | lr 2.69e-04 | grad 2.08 | tok/s 71855
step    990 | loss 2.0756 | lr 2.91e-04 | grad 1.46 | tok/s 69684
step   1000 | loss 1.9497 | lr 3.00e-04 | grad 1.08 | tok/s 68150
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9497.pt
step   1010 | loss 2.1584 | lr 2.94e-04 | grad 1.59 | tok/s 50755
step   1020 | loss 1.8192 | lr 2.74e-04 | grad 1.12 | tok/s 70126
step   1030 | loss 2.1277 | lr 2.42e-04 | grad 1.14 | tok/s 69480
step   1040 | loss 1.8448 | lr 2.01e-04 | grad 1.70 | tok/s 70432
step   1050 | loss 1.8392 | lr 1.55e-04 | grad 1.00 | tok/s 71314
step   1060 | loss 2.0592 | lr 1.09e-04 | grad 1.43 | tok/s 71550
step   1070 | loss 2.1342 | lr 6.65e-05 | grad 0.90 | tok/s 71675
step   1080 | loss 2.4089 | lr 3.24e-05 | grad 1.02 | tok/s 69844
step   1090 | loss 2.1378 | lr 9.84e-06 | grad 1.00 | tok/s 70823
step   1100 | loss 1.8350 | lr 1.07e-06 | grad 0.94 | tok/s 70577
step   1110 | loss 1.8599 | lr 6.93e-06 | grad 0.84 | tok/s 71673
step   1120 | loss 2.0964 | lr 2.68e-05 | grad 0.90 | tok/s 72505
step   1130 | loss 1.8405 | lr 5.89e-05 | grad 0.76 | tok/s 68900
step   1140 | loss 1.7418 | lr 9.99e-05 | grad 0.79 | tok/s 70834
step   1150 | loss 2.0146 | lr 1.46e-04 | grad 1.23 | tok/s 70362
step   1160 | loss 1.6922 | lr 1.92e-04 | grad 0.83 | tok/s 68936
step   1170 | loss 1.9792 | lr 2.35e-04 | grad 0.97 | tok/s 70424
step   1180 | loss 1.7454 | lr 2.69e-04 | grad 0.81 | tok/s 73993
step   1190 | loss 1.6152 | lr 2.91e-04 | grad 1.14 | tok/s 73758
step   1200 | loss 1.5342 | lr 3.00e-04 | grad 0.84 | tok/s 74182
step   1210 | loss 1.4787 | lr 2.94e-04 | grad 0.89 | tok/s 74283
step   1220 | loss 1.5220 | lr 2.74e-04 | grad 1.20 | tok/s 73398
step   1230 | loss 1.7415 | lr 2.42e-04 | grad 1.25 | tok/s 71039
step   1240 | loss 1.8227 | lr 2.01e-04 | grad 1.13 | tok/s 70216
step   1250 | loss 1.8877 | lr 1.55e-04 | grad 3.19 | tok/s 72065
step   1260 | loss 1.9385 | lr 1.09e-04 | grad 2.14 | tok/s 71631
step   1270 | loss 1.9716 | lr 6.65e-05 | grad 1.33 | tok/s 71186
step   1280 | loss 1.8044 | lr 3.24e-05 | grad 0.97 | tok/s 70407
step   1290 | loss 1.7574 | lr 9.84e-06 | grad 1.12 | tok/s 70380
step   1300 | loss 1.8113 | lr 1.07e-06 | grad 0.86 | tok/s 69551
step   1310 | loss 1.8933 | lr 6.93e-06 | grad 0.87 | tok/s 69981
step   1320 | loss 1.8709 | lr 2.68e-05 | grad 1.29 | tok/s 71281
step   1330 | loss 1.7857 | lr 5.89e-05 | grad 0.88 | tok/s 72202
step   1340 | loss 1.7365 | lr 9.99e-05 | grad 1.05 | tok/s 71936
step   1350 | loss 1.7917 | lr 1.46e-04 | grad 2.00 | tok/s 74282
step   1360 | loss 1.7242 | lr 1.92e-04 | grad 1.14 | tok/s 70021
step   1370 | loss 1.8177 | lr 2.35e-04 | grad 1.21 | tok/s 71996
step   1380 | loss 1.9282 | lr 2.69e-04 | grad 1.90 | tok/s 72565
step   1390 | loss 1.8200 | lr 2.91e-04 | grad 1.66 | tok/s 71310
step   1400 | loss 1.8494 | lr 3.00e-04 | grad 6.34 | tok/s 73797
step   1410 | loss 1.8850 | lr 2.94e-04 | grad 1.60 | tok/s 75481
step   1420 | loss 1.9135 | lr 2.74e-04 | grad 1.46 | tok/s 72812
step   1430 | loss 1.7134 | lr 2.42e-04 | grad 1.05 | tok/s 70937
step   1440 | loss 1.6182 | lr 2.01e-04 | grad 0.93 | tok/s 75163
step   1450 | loss 1.6607 | lr 1.55e-04 | grad 2.08 | tok/s 76778
step   1460 | loss 1.7012 | lr 1.09e-04 | grad 0.82 | tok/s 71259
step   1470 | loss 1.8058 | lr 6.65e-05 | grad 1.86 | tok/s 72599
step   1480 | loss 1.6794 | lr 3.24e-05 | grad 1.59 | tok/s 73100
step   1490 | loss 1.8233 | lr 9.84e-06 | grad 2.59 | tok/s 73366
step   1500 | loss 1.9105 | lr 1.07e-06 | grad 2.44 | tok/s 71267
step   1510 | loss 1.8118 | lr 6.93e-06 | grad 1.09 | tok/s 75986
step   1520 | loss 1.7826 | lr 2.68e-05 | grad 1.28 | tok/s 75214
step   1530 | loss 1.7286 | lr 5.89e-05 | grad 0.62 | tok/s 74388
step   1540 | loss 1.7076 | lr 9.99e-05 | grad 0.77 | tok/s 72671
step   1550 | loss 1.6940 | lr 1.46e-04 | grad 2.33 | tok/s 76305
step   1560 | loss 2.2346 | lr 1.92e-04 | grad 1.53 | tok/s 74162
step   1570 | loss 1.7407 | lr 2.35e-04 | grad 1.30 | tok/s 72178
step   1580 | loss 1.9257 | lr 2.69e-04 | grad 1.28 | tok/s 75174
step   1590 | loss 1.6924 | lr 2.91e-04 | grad 1.21 | tok/s 72869
step   1600 | loss 1.7758 | lr 3.00e-04 | grad 1.34 | tok/s 70278
step   1610 | loss 1.6284 | lr 2.94e-04 | grad 1.32 | tok/s 75616
step   1620 | loss 1.7911 | lr 2.74e-04 | grad 1.09 | tok/s 74204
step   1630 | loss 1.8119 | lr 2.42e-04 | grad 1.55 | tok/s 75781
step   1640 | loss 1.6949 | lr 2.01e-04 | grad 0.80 | tok/s 72754
step   1650 | loss 1.7117 | lr 1.55e-04 | grad 1.48 | tok/s 71492
step   1660 | loss 1.6992 | lr 1.09e-04 | grad 0.89 | tok/s 72035
step   1670 | loss 1.7534 | lr 6.65e-05 | grad 2.09 | tok/s 74943
step   1680 | loss 2.1695 | lr 3.24e-05 | grad 0.70 | tok/s 76451
step   1690 | loss 1.6801 | lr 9.84e-06 | grad 1.02 | tok/s 74646
step   1700 | loss 1.9953 | lr 1.07e-06 | grad 0.62 | tok/s 75226
step   1710 | loss 1.7108 | lr 6.93e-06 | grad 0.95 | tok/s 73968
step   1720 | loss 1.7191 | lr 2.68e-05 | grad 0.87 | tok/s 73360
step   1730 | loss 1.8251 | lr 5.89e-05 | grad 0.84 | tok/s 72651
step   1740 | loss 1.7248 | lr 9.99e-05 | grad 0.70 | tok/s 73430
step   1750 | loss 1.6434 | lr 1.46e-04 | grad 0.88 | tok/s 72723
step   1760 | loss 1.9116 | lr 1.92e-04 | grad 1.05 | tok/s 72811
step   1770 | loss 1.8427 | lr 2.35e-04 | grad 1.13 | tok/s 75712
step   1780 | loss 1.6990 | lr 2.69e-04 | grad 1.16 | tok/s 72556
step   1790 | loss 1.9186 | lr 2.91e-04 | grad 1.12 | tok/s 73437
step   1800 | loss 1.6556 | lr 3.00e-04 | grad 1.04 | tok/s 73644
step   1810 | loss 1.7233 | lr 2.94e-04 | grad 1.13 | tok/s 73523
step   1820 | loss 1.6876 | lr 2.74e-04 | grad 1.24 | tok/s 72525
step   1830 | loss 1.7177 | lr 2.42e-04 | grad 0.97 | tok/s 72462
step   1840 | loss 1.6769 | lr 2.01e-04 | grad 1.20 | tok/s 72378
step   1850 | loss 1.9091 | lr 1.55e-04 | grad 1.09 | tok/s 72329
step   1860 | loss 1.6522 | lr 1.09e-04 | grad 0.55 | tok/s 72249
step   1870 | loss 1.6890 | lr 6.65e-05 | grad 1.30 | tok/s 73655
step   1880 | loss 1.6452 | lr 3.24e-05 | grad 0.68 | tok/s 73757
step   1890 | loss 1.7351 | lr 9.84e-06 | grad 0.63 | tok/s 73109
step   1900 | loss 1.7820 | lr 1.07e-06 | grad 1.51 | tok/s 73860
step   1910 | loss 1.7409 | lr 6.93e-06 | grad 1.09 | tok/s 72979
step   1920 | loss 1.6455 | lr 2.68e-05 | grad 1.03 | tok/s 75418
step   1930 | loss 1.6376 | lr 5.89e-05 | grad 0.95 | tok/s 74487
step   1940 | loss 1.5633 | lr 9.99e-05 | grad 0.87 | tok/s 76028
step   1950 | loss 1.6465 | lr 1.46e-04 | grad 0.94 | tok/s 73936
step   1960 | loss 2.0048 | lr 1.92e-04 | grad 3.73 | tok/s 75586
step   1970 | loss 1.7346 | lr 2.35e-04 | grad 1.55 | tok/s 73116
step   1980 | loss 1.7501 | lr 2.69e-04 | grad 2.45 | tok/s 72944
step   1990 | loss 1.8708 | lr 2.91e-04 | grad 1.15 | tok/s 74628
step   2000 | loss 1.7703 | lr 3.00e-04 | grad 1.37 | tok/s 75240
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7703.pt
step   2010 | loss 1.5191 | lr 2.94e-04 | grad 0.87 | tok/s 56613
step   2020 | loss 1.3627 | lr 2.74e-04 | grad 0.79 | tok/s 77428
step   2030 | loss 1.6766 | lr 2.42e-04 | grad 1.28 | tok/s 76326
step   2040 | loss 1.5127 | lr 2.01e-04 | grad 0.66 | tok/s 77403
step   2050 | loss 1.4512 | lr 1.55e-04 | grad 1.03 | tok/s 76107
step   2060 | loss 1.7437 | lr 1.09e-04 | grad 0.89 | tok/s 72675
step   2070 | loss 1.6823 | lr 6.65e-05 | grad 1.32 | tok/s 76765
step   2080 | loss 1.8254 | lr 3.24e-05 | grad 3.58 | tok/s 71895
step   2090 | loss 1.7607 | lr 9.84e-06 | grad 1.06 | tok/s 74873
step   2100 | loss 1.6922 | lr 1.07e-06 | grad 0.96 | tok/s 72895
step   2110 | loss 1.5710 | lr 6.93e-06 | grad 0.79 | tok/s 74858
step   2120 | loss 1.5751 | lr 2.68e-05 | grad 1.30 | tok/s 73986
step   2130 | loss 1.6760 | lr 5.89e-05 | grad 2.05 | tok/s 72354
step   2140 | loss 1.7309 | lr 9.99e-05 | grad 2.84 | tok/s 72036
step   2150 | loss 1.7357 | lr 1.46e-04 | grad 0.87 | tok/s 73287
step   2160 | loss 1.7012 | lr 1.92e-04 | grad 0.98 | tok/s 72336
step   2170 | loss 1.8168 | lr 2.35e-04 | grad 1.17 | tok/s 73129
step   2180 | loss 1.7047 | lr 2.69e-04 | grad 0.94 | tok/s 74472
step   2190 | loss 1.9865 | lr 2.91e-04 | grad 1.10 | tok/s 73948
step   2200 | loss 1.4668 | lr 3.00e-04 | grad 0.84 | tok/s 76911
step   2210 | loss 1.4166 | lr 2.94e-04 | grad 0.90 | tok/s 76506
step   2220 | loss 1.3680 | lr 2.74e-04 | grad 0.75 | tok/s 76960
step   2230 | loss 1.5933 | lr 2.42e-04 | grad 1.16 | tok/s 74259
step   2240 | loss 1.8434 | lr 2.01e-04 | grad 1.87 | tok/s 75795
step   2250 | loss 1.7478 | lr 1.55e-04 | grad 1.06 | tok/s 75337
step   2260 | loss 1.8101 | lr 1.09e-04 | grad 1.06 | tok/s 74006
step   2270 | loss 1.6173 | lr 6.65e-05 | grad 1.16 | tok/s 72745
step   2280 | loss 1.7595 | lr 3.24e-05 | grad 0.66 | tok/s 72248
step   2290 | loss 1.5870 | lr 9.84e-06 | grad 0.91 | tok/s 73373
step   2300 | loss 1.5928 | lr 1.07e-06 | grad 0.65 | tok/s 71503
step   2310 | loss 1.6829 | lr 6.93e-06 | grad 1.02 | tok/s 75915
step   2320 | loss 1.7541 | lr 2.68e-05 | grad 1.00 | tok/s 77394
step   2330 | loss 1.6832 | lr 5.89e-05 | grad 0.73 | tok/s 77830
step   2340 | loss 1.6732 | lr 9.98e-05 | grad 0.97 | tok/s 75513
step   2350 | loss 1.7021 | lr 1.46e-04 | grad 0.77 | tok/s 73361
step   2360 | loss 2.1536 | lr 1.92e-04 | grad 1.84 | tok/s 74944
step   2370 | loss 1.7196 | lr 2.35e-04 | grad 1.25 | tok/s 73800
step   2380 | loss 1.5731 | lr 2.69e-04 | grad 1.20 | tok/s 74026
step   2390 | loss 1.6343 | lr 2.91e-04 | grad 1.16 | tok/s 73986
step   2400 | loss 1.7700 | lr 3.00e-04 | grad 1.43 | tok/s 72806
step   2410 | loss 1.6760 | lr 2.94e-04 | grad 1.06 | tok/s 73171
step   2420 | loss 1.8858 | lr 2.74e-04 | grad 0.90 | tok/s 74330
step   2430 | loss 1.7942 | lr 2.42e-04 | grad 1.27 | tok/s 73051
step   2440 | loss 1.8165 | lr 2.01e-04 | grad 1.09 | tok/s 75047
step   2450 | loss 1.5177 | lr 1.55e-04 | grad 1.31 | tok/s 74020
step   2460 | loss 1.7685 | lr 1.09e-04 | grad 1.68 | tok/s 75831
step   2470 | loss 1.9249 | lr 6.65e-05 | grad 1.09 | tok/s 77086
step   2480 | loss 1.6174 | lr 3.24e-05 | grad 0.80 | tok/s 73943
step   2490 | loss 1.5323 | lr 9.84e-06 | grad 0.99 | tok/s 73325
step   2500 | loss 1.6475 | lr 1.07e-06 | grad 0.91 | tok/s 75185
step   2510 | loss 1.6909 | lr 6.93e-06 | grad 0.84 | tok/s 74820
step   2520 | loss 1.8731 | lr 2.68e-05 | grad 1.07 | tok/s 73255
step   2530 | loss 1.6715 | lr 5.89e-05 | grad 1.14 | tok/s 71888
step   2540 | loss 1.6514 | lr 9.98e-05 | grad 0.86 | tok/s 73064
step   2550 | loss 2.0824 | lr 1.46e-04 | grad 2.03 | tok/s 73814
step   2560 | loss 1.7790 | lr 1.92e-04 | grad 1.12 | tok/s 75248
step   2570 | loss 1.6683 | lr 2.35e-04 | grad 2.55 | tok/s 72094
step   2580 | loss 1.7629 | lr 2.69e-04 | grad 1.03 | tok/s 75186
step   2590 | loss 1.5251 | lr 2.91e-04 | grad 1.09 | tok/s 72239
step   2600 | loss 1.7321 | lr 3.00e-04 | grad 0.98 | tok/s 75060
step   2610 | loss 1.6934 | lr 2.94e-04 | grad 1.15 | tok/s 76006
step   2620 | loss 1.5203 | lr 2.74e-04 | grad 0.76 | tok/s 77269
step   2630 | loss 1.5455 | lr 2.42e-04 | grad 0.68 | tok/s 74846
step   2640 | loss 1.6660 | lr 2.01e-04 | grad 1.30 | tok/s 73678
step   2650 | loss 1.6039 | lr 1.55e-04 | grad 1.00 | tok/s 70987
step   2660 | loss 2.0104 | lr 1.09e-04 | grad 2.66 | tok/s 75725
step   2670 | loss 1.5811 | lr 6.65e-05 | grad 0.72 | tok/s 78133
step   2680 | loss 1.5165 | lr 3.24e-05 | grad 0.75 | tok/s 77396
step   2690 | loss 1.4637 | lr 9.84e-06 | grad 0.64 | tok/s 77458
step   2700 | loss 1.6313 | lr 1.07e-06 | grad 0.79 | tok/s 75103
step   2710 | loss 1.7311 | lr 6.93e-06 | grad 2.88 | tok/s 73681
step   2720 | loss 2.2037 | lr 2.68e-05 | grad 0.74 | tok/s 76721
step   2730 | loss 1.6747 | lr 5.89e-05 | grad 0.92 | tok/s 73582
step   2740 | loss 1.4954 | lr 9.98e-05 | grad 0.97 | tok/s 73284
step   2750 | loss 1.7095 | lr 1.46e-04 | grad 0.95 | tok/s 73590
step   2760 | loss 1.7721 | lr 1.92e-04 | grad 1.60 | tok/s 71520

Training complete! Final step: 2767
