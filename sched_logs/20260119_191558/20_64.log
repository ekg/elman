# Job 20: 64
# GPU: 7
# Command: python train.py --level 64 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/64
# Started: 2026-01-19T19:36:18.366953
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/64/level64_100m_20260119_193624
Auto r_h_mode: none (level 64 has bounded/no W_h)
Model: Level 64, 98,532,480 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.4872 | lr 2.70e-05 | grad 8.81 | tok/s 23781
step     20 | loss 4.6808 | lr 5.70e-05 | grad 6.50 | tok/s 86797
step     30 | loss 4.9729 | lr 8.70e-05 | grad 3.42 | tok/s 92968
step     40 | loss 4.3269 | lr 1.17e-04 | grad 2.86 | tok/s 90995
step     50 | loss 3.7864 | lr 1.47e-04 | grad 1.71 | tok/s 93445
step     60 | loss 3.7174 | lr 1.77e-04 | grad 3.42 | tok/s 91592
step     70 | loss 3.2846 | lr 2.07e-04 | grad 1.27 | tok/s 88567
step     80 | loss 3.5258 | lr 2.37e-04 | grad 2.42 | tok/s 91995
step     90 | loss 3.5251 | lr 2.67e-04 | grad 2.94 | tok/s 88938
step    100 | loss 3.3049 | lr 2.97e-04 | grad 0.96 | tok/s 89865
step    110 | loss 3.2587 | lr 6.94e-06 | grad 1.86 | tok/s 81247
step    120 | loss 3.6422 | lr 2.69e-05 | grad 1.25 | tok/s 81663
step    130 | loss 3.4192 | lr 5.89e-05 | grad 1.05 | tok/s 83538
step    140 | loss 3.2008 | lr 9.99e-05 | grad 0.62 | tok/s 83711
step    150 | loss 3.1044 | lr 1.46e-04 | grad 1.89 | tok/s 79901
step    160 | loss 3.0724 | lr 1.92e-04 | grad 1.11 | tok/s 80530
step    170 | loss 3.2506 | lr 2.35e-04 | grad 2.72 | tok/s 83184
step    180 | loss 3.3716 | lr 2.69e-04 | grad 1.33 | tok/s 83396
step    190 | loss 3.2152 | lr 2.91e-04 | grad 1.51 | tok/s 84655
step    200 | loss 3.1687 | lr 3.00e-04 | grad 0.91 | tok/s 86653
step    210 | loss 3.2625 | lr 2.94e-04 | grad 2.02 | tok/s 82913
step    220 | loss 3.2930 | lr 2.74e-04 | grad 0.95 | tok/s 85673
step    230 | loss 3.0725 | lr 2.42e-04 | grad 1.41 | tok/s 82615
step    240 | loss 3.2006 | lr 2.01e-04 | grad 1.23 | tok/s 84186
step    250 | loss 3.0494 | lr 1.55e-04 | grad 1.09 | tok/s 83030
step    260 | loss 2.9843 | lr 1.09e-04 | grad 0.78 | tok/s 79653
step    270 | loss 2.9367 | lr 6.65e-05 | grad 0.94 | tok/s 82711
step    280 | loss 2.8456 | lr 3.24e-05 | grad 1.80 | tok/s 82512
step    290 | loss 2.9185 | lr 9.84e-06 | grad 0.63 | tok/s 87045
step    300 | loss 2.9074 | lr 1.07e-06 | grad 0.59 | tok/s 87109
step    310 | loss 2.9070 | lr 6.94e-06 | grad 0.52 | tok/s 86960
step    320 | loss 2.8375 | lr 2.69e-05 | grad 1.27 | tok/s 83672
step    330 | loss 2.9144 | lr 5.89e-05 | grad 0.57 | tok/s 81754
step    340 | loss 2.9302 | lr 9.99e-05 | grad 1.16 | tok/s 83400
step    350 | loss 2.8706 | lr 1.46e-04 | grad 1.16 | tok/s 80971
step    360 | loss 2.8081 | lr 1.92e-04 | grad 3.06 | tok/s 82000
step    370 | loss 2.7062 | lr 2.35e-04 | grad 1.91 | tok/s 83674
step    380 | loss 3.0748 | lr 2.69e-04 | grad 1.41 | tok/s 85877
step    390 | loss 2.6599 | lr 2.91e-04 | grad 2.17 | tok/s 82650
step    400 | loss 2.7544 | lr 3.00e-04 | grad 3.06 | tok/s 84634
step    410 | loss 2.4768 | lr 2.94e-04 | grad 2.03 | tok/s 82070
step    420 | loss 2.6160 | lr 2.74e-04 | grad 1.33 | tok/s 81523
step    430 | loss 2.6652 | lr 2.42e-04 | grad 1.73 | tok/s 81213
step    440 | loss 2.7910 | lr 2.01e-04 | grad 1.71 | tok/s 84328
step    450 | loss 2.5003 | lr 1.55e-04 | grad 1.13 | tok/s 82146
step    460 | loss 2.4603 | lr 1.09e-04 | grad 1.09 | tok/s 82402
step    470 | loss 2.4795 | lr 6.65e-05 | grad 2.47 | tok/s 83394
step    480 | loss 2.3593 | lr 3.24e-05 | grad 0.74 | tok/s 80458
step    490 | loss 2.3161 | lr 9.84e-06 | grad 0.66 | tok/s 81950
step    500 | loss 3.1577 | lr 1.07e-06 | grad 0.80 | tok/s 84462
step    510 | loss 2.2581 | lr 6.94e-06 | grad 0.76 | tok/s 82630
step    520 | loss 2.3802 | lr 2.69e-05 | grad 0.59 | tok/s 85164
step    530 | loss 2.7900 | lr 5.89e-05 | grad 1.16 | tok/s 83498
step    540 | loss 2.2863 | lr 9.99e-05 | grad 1.80 | tok/s 83385
step    550 | loss 2.3348 | lr 1.46e-04 | grad 1.41 | tok/s 85712
step    560 | loss 2.2517 | lr 1.92e-04 | grad 1.89 | tok/s 86922
step    570 | loss 2.4532 | lr 2.35e-04 | grad 2.53 | tok/s 84943
step    580 | loss 2.7251 | lr 2.69e-04 | grad 1.47 | tok/s 83796
step    590 | loss 2.8989 | lr 2.91e-04 | grad 2.28 | tok/s 82069
step    600 | loss 2.5209 | lr 3.00e-04 | grad 2.31 | tok/s 82336
step    610 | loss 2.5179 | lr 2.94e-04 | grad 1.37 | tok/s 86173
step    620 | loss 2.3773 | lr 2.74e-04 | grad 1.92 | tok/s 81832
step    630 | loss 2.3587 | lr 2.42e-04 | grad 1.71 | tok/s 84345
step    640 | loss 2.6913 | lr 2.01e-04 | grad 1.74 | tok/s 84420
step    650 | loss 2.3708 | lr 1.55e-04 | grad 1.77 | tok/s 82850
step    660 | loss 2.6319 | lr 1.09e-04 | grad 3.47 | tok/s 81653
step    670 | loss 2.4455 | lr 6.65e-05 | grad 2.30 | tok/s 84662
step    680 | loss 2.3736 | lr 3.24e-05 | grad 1.08 | tok/s 81595
step    690 | loss 2.3909 | lr 9.84e-06 | grad 1.12 | tok/s 82272
step    700 | loss 2.4814 | lr 1.07e-06 | grad 1.02 | tok/s 82760
step    710 | loss 2.4388 | lr 6.94e-06 | grad 0.89 | tok/s 83217
step    720 | loss 2.4814 | lr 2.68e-05 | grad 1.48 | tok/s 82849
step    730 | loss 2.4582 | lr 5.89e-05 | grad 1.23 | tok/s 83619
step    740 | loss 2.3636 | lr 9.99e-05 | grad 2.20 | tok/s 82893
step    750 | loss 2.2549 | lr 1.46e-04 | grad 1.75 | tok/s 82022
step    760 | loss 2.6478 | lr 1.92e-04 | grad 2.58 | tok/s 82992
step    770 | loss 2.2552 | lr 2.35e-04 | grad 2.05 | tok/s 82567
step    780 | loss 2.3414 | lr 2.69e-04 | grad 1.85 | tok/s 83421
step    790 | loss 2.3725 | lr 2.91e-04 | grad 1.82 | tok/s 84141
step    800 | loss 2.3544 | lr 3.00e-04 | grad 2.03 | tok/s 84117
step    810 | loss 2.2434 | lr 2.94e-04 | grad 1.91 | tok/s 83355
step    820 | loss 2.7951 | lr 2.74e-04 | grad 1.61 | tok/s 85398
step    830 | loss 2.4724 | lr 2.42e-04 | grad 1.25 | tok/s 86899
step    840 | loss 2.2267 | lr 2.01e-04 | grad 1.08 | tok/s 86668
step    850 | loss 2.4474 | lr 1.55e-04 | grad 1.84 | tok/s 82715
step    860 | loss 2.3324 | lr 1.09e-04 | grad 1.51 | tok/s 80945
step    870 | loss 2.2928 | lr 6.65e-05 | grad 1.06 | tok/s 83332
step    880 | loss 2.3316 | lr 3.24e-05 | grad 1.59 | tok/s 82907
step    890 | loss 2.2205 | lr 9.84e-06 | grad 0.89 | tok/s 82955
step    900 | loss 2.5662 | lr 1.07e-06 | grad 0.98 | tok/s 80747
step    910 | loss 2.2692 | lr 6.94e-06 | grad 0.82 | tok/s 82195
step    920 | loss 2.2313 | lr 2.68e-05 | grad 1.03 | tok/s 82060
step    930 | loss 2.3516 | lr 5.89e-05 | grad 1.67 | tok/s 81846
step    940 | loss 2.2388 | lr 9.99e-05 | grad 1.55 | tok/s 81083
step    950 | loss 2.2886 | lr 1.46e-04 | grad 2.41 | tok/s 82861
step    960 | loss 2.1512 | lr 1.92e-04 | grad 1.64 | tok/s 86930
step    970 | loss 2.0046 | lr 2.35e-04 | grad 2.67 | tok/s 86892
step    980 | loss 2.1169 | lr 2.69e-04 | grad 3.03 | tok/s 84550
step    990 | loss 2.4127 | lr 2.91e-04 | grad 3.45 | tok/s 82166
step   1000 | loss 2.2667 | lr 3.00e-04 | grad 2.80 | tok/s 80072
  >>> saved checkpoint: checkpoint_step_001000_loss_2.2667.pt
step   1010 | loss 2.4989 | lr 2.94e-04 | grad 1.99 | tok/s 54877
step   1020 | loss 2.2061 | lr 2.74e-04 | grad 1.59 | tok/s 82470
step   1030 | loss 2.4206 | lr 2.42e-04 | grad 2.56 | tok/s 81074
step   1040 | loss 2.1910 | lr 2.01e-04 | grad 2.41 | tok/s 82861
step   1050 | loss 2.1435 | lr 1.55e-04 | grad 1.59 | tok/s 83141
step   1060 | loss 2.4303 | lr 1.09e-04 | grad 1.81 | tok/s 83300
step   1070 | loss 2.4646 | lr 6.65e-05 | grad 1.33 | tok/s 83548
step   1080 | loss 2.6019 | lr 3.24e-05 | grad 1.36 | tok/s 82494
step   1090 | loss 2.4051 | lr 9.84e-06 | grad 1.07 | tok/s 83041
step   1100 | loss 2.1136 | lr 1.07e-06 | grad 1.03 | tok/s 82600
step   1110 | loss 2.1687 | lr 6.93e-06 | grad 0.87 | tok/s 83992
step   1120 | loss 2.4519 | lr 2.68e-05 | grad 1.06 | tok/s 84952
step   1130 | loss 2.1303 | lr 5.89e-05 | grad 0.95 | tok/s 79520
step   1140 | loss 2.0795 | lr 9.99e-05 | grad 1.29 | tok/s 82862
step   1150 | loss 2.3472 | lr 1.46e-04 | grad 1.57 | tok/s 82597
step   1160 | loss 2.0022 | lr 1.92e-04 | grad 1.82 | tok/s 81856
step   1170 | loss 2.2764 | lr 2.35e-04 | grad 1.60 | tok/s 82795
step   1180 | loss 2.0110 | lr 2.69e-04 | grad 1.83 | tok/s 87054
step   1190 | loss 1.9562 | lr 2.91e-04 | grad 2.27 | tok/s 87115
step   1200 | loss 1.8982 | lr 3.00e-04 | grad 2.80 | tok/s 86950
step   1210 | loss 1.8750 | lr 2.94e-04 | grad 2.02 | tok/s 87012
step   1220 | loss 1.8924 | lr 2.74e-04 | grad 2.81 | tok/s 86263
step   1230 | loss 2.0104 | lr 2.42e-04 | grad 1.72 | tok/s 83113
step   1240 | loss 2.1270 | lr 2.01e-04 | grad 1.56 | tok/s 81771
step   1250 | loss 2.2065 | lr 1.55e-04 | grad 3.02 | tok/s 84327
step   1260 | loss 2.2266 | lr 1.09e-04 | grad 2.19 | tok/s 84248
step   1270 | loss 2.2793 | lr 6.65e-05 | grad 1.55 | tok/s 83149
step   1280 | loss 2.0968 | lr 3.24e-05 | grad 1.20 | tok/s 82209
step   1290 | loss 2.0342 | lr 9.84e-06 | grad 1.22 | tok/s 81902
step   1300 | loss 2.0656 | lr 1.07e-06 | grad 0.87 | tok/s 81376
step   1310 | loss 2.1986 | lr 6.93e-06 | grad 1.16 | tok/s 81293
step   1320 | loss 2.1438 | lr 2.68e-05 | grad 1.72 | tok/s 82739
step   1330 | loss 2.0991 | lr 5.89e-05 | grad 1.02 | tok/s 82855
step   1340 | loss 2.0406 | lr 9.99e-05 | grad 1.26 | tok/s 82945
step   1350 | loss 2.1336 | lr 1.46e-04 | grad 2.12 | tok/s 85189
step   1360 | loss 2.0417 | lr 1.92e-04 | grad 1.55 | tok/s 80876
step   1370 | loss 2.1428 | lr 2.35e-04 | grad 2.23 | tok/s 82080
step   1380 | loss 2.2437 | lr 2.69e-04 | grad 2.69 | tok/s 82765
step   1390 | loss 2.1092 | lr 2.91e-04 | grad 1.57 | tok/s 80705
step   1400 | loss 2.1985 | lr 3.00e-04 | grad 7.34 | tok/s 84116
step   1410 | loss 2.2777 | lr 2.94e-04 | grad 1.75 | tok/s 84853
step   1420 | loss 2.1958 | lr 2.74e-04 | grad 1.55 | tok/s 80739
step   1430 | loss 1.9917 | lr 2.42e-04 | grad 1.24 | tok/s 78844
step   1440 | loss 1.9304 | lr 2.01e-04 | grad 2.06 | tok/s 83218
step   1450 | loss 1.9892 | lr 1.55e-04 | grad 2.55 | tok/s 84950
step   1460 | loss 1.9643 | lr 1.09e-04 | grad 1.91 | tok/s 79294
step   1470 | loss 2.0621 | lr 6.65e-05 | grad 2.16 | tok/s 82118
step   1480 | loss 1.9598 | lr 3.24e-05 | grad 1.99 | tok/s 83083
step   1490 | loss 2.0889 | lr 9.84e-06 | grad 3.42 | tok/s 83028
step   1500 | loss 2.1425 | lr 1.07e-06 | grad 2.06 | tok/s 80727
step   1510 | loss 2.1173 | lr 6.93e-06 | grad 1.40 | tok/s 84935
step   1520 | loss 2.0867 | lr 2.68e-05 | grad 1.50 | tok/s 84234
step   1530 | loss 2.0219 | lr 5.89e-05 | grad 1.02 | tok/s 83437
step   1540 | loss 2.0152 | lr 9.99e-05 | grad 1.14 | tok/s 81934
step   1550 | loss 2.0113 | lr 1.46e-04 | grad 4.03 | tok/s 85253
step   1560 | loss 2.5376 | lr 1.92e-04 | grad 2.11 | tok/s 83031
step   1570 | loss 2.0462 | lr 2.35e-04 | grad 2.44 | tok/s 81475
step   1580 | loss 2.2389 | lr 2.69e-04 | grad 2.03 | tok/s 84219
step   1590 | loss 1.9692 | lr 2.91e-04 | grad 2.14 | tok/s 82134
step   1600 | loss 2.0267 | lr 3.00e-04 | grad 2.81 | tok/s 80533
step   1610 | loss 1.9135 | lr 2.94e-04 | grad 1.43 | tok/s 85207
step   1620 | loss 2.0494 | lr 2.74e-04 | grad 2.05 | tok/s 84042
step   1630 | loss 2.1000 | lr 2.42e-04 | grad 2.27 | tok/s 84688
step   1640 | loss 1.9902 | lr 2.01e-04 | grad 1.69 | tok/s 81771
step   1650 | loss 1.9974 | lr 1.55e-04 | grad 3.52 | tok/s 80561
step   1660 | loss 1.9686 | lr 1.09e-04 | grad 1.52 | tok/s 81024
step   1670 | loss 2.0766 | lr 6.65e-05 | grad 2.67 | tok/s 84559
step   1680 | loss 2.4388 | lr 3.24e-05 | grad 1.14 | tok/s 84573
step   1690 | loss 1.9612 | lr 9.84e-06 | grad 1.30 | tok/s 82601
step   1700 | loss 2.3603 | lr 1.07e-06 | grad 0.88 | tok/s 84366
step   1710 | loss 1.9671 | lr 6.93e-06 | grad 1.03 | tok/s 81864
step   1720 | loss 2.0126 | lr 2.68e-05 | grad 1.28 | tok/s 82114
step   1730 | loss 2.1012 | lr 5.89e-05 | grad 1.46 | tok/s 82111
step   1740 | loss 2.0399 | lr 9.99e-05 | grad 1.34 | tok/s 83417
step   1750 | loss 1.8978 | lr 1.46e-04 | grad 1.24 | tok/s 80402
step   1760 | loss 2.2141 | lr 1.92e-04 | grad 1.88 | tok/s 81616
step   1770 | loss 2.1031 | lr 2.35e-04 | grad 2.14 | tok/s 83589
step   1780 | loss 2.0110 | lr 2.69e-04 | grad 1.98 | tok/s 80375
step   1790 | loss 2.2403 | lr 2.91e-04 | grad 1.78 | tok/s 81904
step   1800 | loss 1.9489 | lr 3.00e-04 | grad 2.62 | tok/s 83399
step   1810 | loss 1.9598 | lr 2.94e-04 | grad 1.82 | tok/s 81246
step   1820 | loss 1.9649 | lr 2.74e-04 | grad 2.77 | tok/s 79403
step   1830 | loss 1.9600 | lr 2.42e-04 | grad 1.86 | tok/s 79806
step   1840 | loss 1.9438 | lr 2.01e-04 | grad 2.53 | tok/s 80383
step   1850 | loss 2.1590 | lr 1.55e-04 | grad 1.99 | tok/s 81823
step   1860 | loss 1.9115 | lr 1.09e-04 | grad 1.25 | tok/s 81658
step   1870 | loss 1.9851 | lr 6.65e-05 | grad 1.60 | tok/s 83460
step   1880 | loss 1.8974 | lr 3.24e-05 | grad 0.95 | tok/s 83639
step   1890 | loss 1.9957 | lr 9.84e-06 | grad 0.68 | tok/s 82219
step   1900 | loss 2.0476 | lr 1.07e-06 | grad 1.80 | tok/s 82929
step   1910 | loss 1.9562 | lr 6.93e-06 | grad 1.52 | tok/s 82051
step   1920 | loss 1.9000 | lr 2.68e-05 | grad 1.34 | tok/s 84605
step   1930 | loss 1.8908 | lr 5.89e-05 | grad 1.11 | tok/s 83733
step   1940 | loss 1.7758 | lr 9.99e-05 | grad 1.50 | tok/s 85540
step   1950 | loss 1.8749 | lr 1.46e-04 | grad 1.23 | tok/s 83257
step   1960 | loss 2.2974 | lr 1.92e-04 | grad 4.03 | tok/s 84948
step   1970 | loss 2.0702 | lr 2.35e-04 | grad 2.48 | tok/s 82068
step   1980 | loss 2.0377 | lr 2.69e-04 | grad 2.52 | tok/s 81912
step   1990 | loss 2.1786 | lr 2.91e-04 | grad 2.95 | tok/s 83881
step   2000 | loss 2.1110 | lr 3.00e-04 | grad 2.42 | tok/s 84661
  >>> saved checkpoint: checkpoint_step_002000_loss_2.1110.pt
step   2010 | loss 1.8619 | lr 2.94e-04 | grad 1.70 | tok/s 57727
step   2020 | loss 1.6800 | lr 2.74e-04 | grad 1.62 | tok/s 87166
step   2030 | loss 1.9482 | lr 2.42e-04 | grad 2.02 | tok/s 86149
step   2040 | loss 1.7753 | lr 2.01e-04 | grad 1.27 | tok/s 87076
step   2050 | loss 1.6857 | lr 1.55e-04 | grad 1.93 | tok/s 85651
step   2060 | loss 1.9389 | lr 1.09e-04 | grad 1.23 | tok/s 81912
step   2070 | loss 1.8739 | lr 6.65e-05 | grad 1.77 | tok/s 86113
step   2080 | loss 2.0572 | lr 3.24e-05 | grad 3.77 | tok/s 81402
step   2090 | loss 1.9862 | lr 9.84e-06 | grad 1.49 | tok/s 84253
step   2100 | loss 1.9239 | lr 1.07e-06 | grad 1.25 | tok/s 81869
step   2110 | loss 1.8163 | lr 6.93e-06 | grad 1.02 | tok/s 84740
step   2120 | loss 1.7925 | lr 2.68e-05 | grad 1.52 | tok/s 83903
step   2130 | loss 1.9073 | lr 5.89e-05 | grad 2.98 | tok/s 81431
step   2140 | loss 1.9513 | lr 9.99e-05 | grad 2.91 | tok/s 81380
step   2150 | loss 1.9837 | lr 1.46e-04 | grad 1.86 | tok/s 82703
step   2160 | loss 1.9255 | lr 1.92e-04 | grad 1.72 | tok/s 81675
step   2170 | loss 2.0606 | lr 2.35e-04 | grad 2.28 | tok/s 82719
step   2180 | loss 1.9811 | lr 2.69e-04 | grad 2.09 | tok/s 84262
step   2190 | loss 2.3040 | lr 2.91e-04 | grad 2.78 | tok/s 84073
step   2200 | loss 1.7819 | lr 3.00e-04 | grad 2.03 | tok/s 87284
step   2210 | loss 1.7268 | lr 2.94e-04 | grad 2.84 | tok/s 87068
step   2220 | loss 1.6663 | lr 2.74e-04 | grad 1.84 | tok/s 87044
step   2230 | loss 1.8360 | lr 2.42e-04 | grad 1.75 | tok/s 83990
step   2240 | loss 2.1573 | lr 2.01e-04 | grad 2.06 | tok/s 85886
step   2250 | loss 2.0814 | lr 1.55e-04 | grad 1.49 | tok/s 85177
step   2260 | loss 2.0719 | lr 1.09e-04 | grad 1.48 | tok/s 84039
step   2270 | loss 1.8775 | lr 6.65e-05 | grad 1.74 | tok/s 82178
step   2280 | loss 1.9825 | lr 3.24e-05 | grad 1.22 | tok/s 82157
step   2290 | loss 1.8121 | lr 9.84e-06 | grad 1.20 | tok/s 83050
step   2300 | loss 1.8017 | lr 1.07e-06 | grad 0.96 | tok/s 80478
step   2310 | loss 1.8795 | lr 6.93e-06 | grad 1.79 | tok/s 85637
step   2320 | loss 1.9433 | lr 2.68e-05 | grad 1.26 | tok/s 86940
step   2330 | loss 1.8791 | lr 5.89e-05 | grad 0.94 | tok/s 86960
step   2340 | loss 1.8828 | lr 9.98e-05 | grad 1.67 | tok/s 85048
step   2350 | loss 1.9211 | lr 1.46e-04 | grad 1.62 | tok/s 82512
step   2360 | loss 2.4271 | lr 1.92e-04 | grad 4.34 | tok/s 84053
step   2370 | loss 2.0188 | lr 2.35e-04 | grad 2.73 | tok/s 83571
step   2380 | loss 1.8402 | lr 2.69e-04 | grad 2.38 | tok/s 82657
step   2390 | loss 1.9012 | lr 2.91e-04 | grad 2.70 | tok/s 82467
step   2400 | loss 2.0148 | lr 3.00e-04 | grad 4.47 | tok/s 81542
step   2410 | loss 1.9374 | lr 2.94e-04 | grad 2.14 | tok/s 82186
step   2420 | loss 2.1522 | lr 2.74e-04 | grad 2.27 | tok/s 82938
step   2430 | loss 2.0116 | lr 2.42e-04 | grad 2.36 | tok/s 81883
step   2440 | loss 2.1044 | lr 2.01e-04 | grad 2.61 | tok/s 83985
step   2450 | loss 1.7261 | lr 1.55e-04 | grad 1.72 | tok/s 82932
step   2460 | loss 2.0250 | lr 1.09e-04 | grad 1.97 | tok/s 84694
step   2470 | loss 2.3170 | lr 6.65e-05 | grad 1.37 | tok/s 86672
step   2480 | loss 1.8221 | lr 3.24e-05 | grad 1.35 | tok/s 82987
step   2490 | loss 1.7424 | lr 9.84e-06 | grad 1.34 | tok/s 81811
step   2500 | loss 1.8676 | lr 1.07e-06 | grad 1.22 | tok/s 83993
step   2510 | loss 1.9251 | lr 6.93e-06 | grad 1.19 | tok/s 83797
step   2520 | loss 2.0397 | lr 2.68e-05 | grad 1.41 | tok/s 81668
step   2530 | loss 1.8785 | lr 5.89e-05 | grad 1.35 | tok/s 81084
step   2540 | loss 1.8727 | lr 9.98e-05 | grad 1.20 | tok/s 81795
step   2550 | loss 2.2591 | lr 1.46e-04 | grad 2.48 | tok/s 82974
step   2560 | loss 2.1733 | lr 1.92e-04 | grad 2.19 | tok/s 84548
step   2570 | loss 1.8895 | lr 2.35e-04 | grad 2.31 | tok/s 81049
step   2580 | loss 2.0254 | lr 2.69e-04 | grad 1.76 | tok/s 84225
step   2590 | loss 1.7392 | lr 2.91e-04 | grad 2.12 | tok/s 82063
step   2600 | loss 1.9427 | lr 3.00e-04 | grad 2.59 | tok/s 84287
step   2610 | loss 1.8929 | lr 2.94e-04 | grad 2.70 | tok/s 85018
step   2620 | loss 1.7375 | lr 2.74e-04 | grad 1.59 | tok/s 87009
step   2630 | loss 1.7532 | lr 2.42e-04 | grad 1.73 | tok/s 84471
step   2640 | loss 1.8753 | lr 2.01e-04 | grad 1.91 | tok/s 82063
step   2650 | loss 1.7921 | lr 1.55e-04 | grad 1.16 | tok/s 79276
step   2660 | loss 2.1879 | lr 1.09e-04 | grad 3.09 | tok/s 85394
step   2670 | loss 1.8028 | lr 6.65e-05 | grad 1.22 | tok/s 86950
step   2680 | loss 1.7077 | lr 3.24e-05 | grad 0.89 | tok/s 86871
step   2690 | loss 1.6538 | lr 9.84e-06 | grad 1.03 | tok/s 86846
step   2700 | loss 1.8195 | lr 1.07e-06 | grad 1.02 | tok/s 83667
step   2710 | loss 1.9317 | lr 6.93e-06 | grad 2.95 | tok/s 81257
step   2720 | loss 2.3935 | lr 2.68e-05 | grad 1.09 | tok/s 85779
step   2730 | loss 1.8615 | lr 5.89e-05 | grad 1.20 | tok/s 82829
step   2740 | loss 1.6984 | lr 9.98e-05 | grad 1.38 | tok/s 82653
step   2750 | loss 1.9394 | lr 1.46e-04 | grad 1.29 | tok/s 83511
step   2760 | loss 1.9585 | lr 1.92e-04 | grad 2.05 | tok/s 80241
step   2770 | loss 1.8150 | lr 2.35e-04 | grad 2.39 | tok/s 83757
step   2780 | loss 1.8069 | lr 2.69e-04 | grad 1.63 | tok/s 80917
step   2790 | loss 1.7249 | lr 2.91e-04 | grad 1.57 | tok/s 82707
step   2800 | loss 2.2455 | lr 3.00e-04 | grad 2.03 | tok/s 82861
step   2810 | loss 2.1179 | lr 2.94e-04 | grad 2.61 | tok/s 84129
step   2820 | loss 2.2041 | lr 2.74e-04 | grad 2.58 | tok/s 84939
step   2830 | loss 2.0367 | lr 2.42e-04 | grad 2.03 | tok/s 84437
step   2840 | loss 2.0093 | lr 2.01e-04 | grad 1.84 | tok/s 83088
step   2850 | loss 1.8179 | lr 1.55e-04 | grad 1.63 | tok/s 84993
step   2860 | loss 1.7832 | lr 1.09e-04 | grad 1.59 | tok/s 82706
step   2870 | loss 1.9096 | lr 6.65e-05 | grad 1.38 | tok/s 82587
step   2880 | loss 2.2912 | lr 3.24e-05 | grad 1.01 | tok/s 83083
step   2890 | loss 1.9903 | lr 9.84e-06 | grad 1.22 | tok/s 84226
step   2900 | loss 1.7338 | lr 1.07e-06 | grad 1.09 | tok/s 80802
step   2910 | loss 1.6693 | lr 6.93e-06 | grad 0.92 | tok/s 80977
step   2920 | loss 2.2580 | lr 2.68e-05 | grad 1.24 | tok/s 84990
step   2930 | loss 1.7330 | lr 5.89e-05 | grad 0.80 | tok/s 83479
step   2940 | loss 1.8117 | lr 9.98e-05 | grad 1.33 | tok/s 81261
step   2950 | loss 1.7842 | lr 1.46e-04 | grad 1.41 | tok/s 81439
step   2960 | loss 2.0536 | lr 1.92e-04 | grad 1.91 | tok/s 82491
step   2970 | loss 1.8283 | lr 2.35e-04 | grad 1.95 | tok/s 81681
step   2980 | loss 1.8533 | lr 2.69e-04 | grad 1.85 | tok/s 82997
step   2990 | loss 1.8403 | lr 2.91e-04 | grad 1.88 | tok/s 83295
step   3000 | loss 1.7346 | lr 3.00e-04 | grad 2.45 | tok/s 84185
  >>> saved checkpoint: checkpoint_step_003000_loss_1.7346.pt
step   3010 | loss 2.0429 | lr 2.94e-04 | grad 2.50 | tok/s 54579
step   3020 | loss 1.8022 | lr 2.74e-04 | grad 1.43 | tok/s 82724
step   3030 | loss 1.9406 | lr 2.42e-04 | grad 3.45 | tok/s 82383
step   3040 | loss 1.7682 | lr 2.01e-04 | grad 1.66 | tok/s 81958
step   3050 | loss 1.8749 | lr 1.55e-04 | grad 1.54 | tok/s 82932
step   3060 | loss 1.7263 | lr 1.09e-04 | grad 1.16 | tok/s 81693
step   3070 | loss 1.7106 | lr 6.65e-05 | grad 1.30 | tok/s 82219
step   3080 | loss 1.7276 | lr 3.24e-05 | grad 1.04 | tok/s 84015
step   3090 | loss 1.6748 | lr 9.84e-06 | grad 0.95 | tok/s 83723
step   3100 | loss 1.6906 | lr 1.07e-06 | grad 1.00 | tok/s 82083
step   3110 | loss 1.6905 | lr 6.93e-06 | grad 0.94 | tok/s 84081
step   3120 | loss 1.6962 | lr 2.68e-05 | grad 1.03 | tok/s 81325
step   3130 | loss 2.3339 | lr 5.89e-05 | grad 3.27 | tok/s 85210
step   3140 | loss 2.4592 | lr 9.98e-05 | grad 1.21 | tok/s 87003

Training complete! Final step: 3145
