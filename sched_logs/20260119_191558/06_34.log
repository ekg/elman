# Job 6: 34
# GPU: 6
# Command: python train.py --level 34 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/elman48_20260119_191441/34
# Started: 2026-01-19T19:15:58.748041
============================================================

Using device: cuda
Output directory: benchmark_results/elman48_20260119_191441/34/level34_100m_20260119_191605
Auto r_h_mode: none (level 34 has bounded/no W_h)
Model: Level 34, 65,764,480 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.4794 | lr 2.70e-05 | grad 11.56 | tok/s 27193
step     20 | loss 4.5975 | lr 5.70e-05 | grad 6.16 | tok/s 107141
step     30 | loss 4.9297 | lr 8.70e-05 | grad 3.12 | tok/s 115920
step     40 | loss 4.2781 | lr 1.17e-04 | grad 2.91 | tok/s 115867
step     50 | loss 3.6911 | lr 1.47e-04 | grad 1.80 | tok/s 116238
step     60 | loss 3.6206 | lr 1.77e-04 | grad 5.31 | tok/s 113312
step     70 | loss 3.1708 | lr 2.07e-04 | grad 2.08 | tok/s 109377
step     80 | loss 3.2381 | lr 2.37e-04 | grad 3.25 | tok/s 113556
step     90 | loss 3.3465 | lr 2.67e-04 | grad 3.31 | tok/s 104429
step    100 | loss 3.0595 | lr 2.97e-04 | grad 1.18 | tok/s 106093
step    110 | loss 2.9609 | lr 6.94e-06 | grad 2.31 | tok/s 98825
step    120 | loss 3.2309 | lr 2.69e-05 | grad 1.59 | tok/s 102102
step    130 | loss 3.0636 | lr 5.89e-05 | grad 1.05 | tok/s 104511
step    140 | loss 2.8333 | lr 9.99e-05 | grad 1.02 | tok/s 104456
step    150 | loss 2.6781 | lr 1.46e-04 | grad 3.55 | tok/s 99549
step    160 | loss 2.5618 | lr 1.92e-04 | grad 2.38 | tok/s 100406
step    170 | loss 2.7420 | lr 2.35e-04 | grad 7.00 | tok/s 104011
step    180 | loss 2.7598 | lr 2.69e-04 | grad 2.62 | tok/s 104223
step    190 | loss 2.6098 | lr 2.91e-04 | grad 3.34 | tok/s 106257
step    200 | loss 2.3892 | lr 3.00e-04 | grad 2.06 | tok/s 108648
step    210 | loss 2.6297 | lr 2.94e-04 | grad 2.38 | tok/s 103943
step    220 | loss 2.6234 | lr 2.74e-04 | grad 2.80 | tok/s 107434
step    230 | loss 2.4585 | lr 2.42e-04 | grad 4.94 | tok/s 103668
step    240 | loss 2.5367 | lr 2.01e-04 | grad 3.47 | tok/s 99161
step    250 | loss 2.4314 | lr 1.55e-04 | grad 1.70 | tok/s 103645
step    260 | loss 2.4032 | lr 1.09e-04 | grad 1.19 | tok/s 100106
step    270 | loss 2.3008 | lr 6.65e-05 | grad 1.77 | tok/s 103572
step    280 | loss 2.1955 | lr 3.24e-05 | grad 2.81 | tok/s 103297
step    290 | loss 2.2423 | lr 9.84e-06 | grad 0.99 | tok/s 108378
step    300 | loss 2.2241 | lr 1.07e-06 | grad 1.08 | tok/s 107635
step    310 | loss 2.2277 | lr 6.94e-06 | grad 0.87 | tok/s 107983
step    320 | loss 2.2477 | lr 2.69e-05 | grad 2.20 | tok/s 104356
step    330 | loss 2.2854 | lr 5.89e-05 | grad 1.11 | tok/s 102078
step    340 | loss 2.3078 | lr 9.99e-05 | grad 2.03 | tok/s 104373
step    350 | loss 2.3268 | lr 1.46e-04 | grad 2.52 | tok/s 101197
step    360 | loss 2.3118 | lr 1.92e-04 | grad 3.31 | tok/s 102005
step    370 | loss 2.2354 | lr 2.35e-04 | grad 3.59 | tok/s 104256
step    380 | loss 2.6891 | lr 2.69e-04 | grad 2.38 | tok/s 106665
step    390 | loss 2.3372 | lr 2.91e-04 | grad 3.28 | tok/s 102769
step    400 | loss 2.4288 | lr 3.00e-04 | grad 4.25 | tok/s 105097
step    410 | loss 2.2122 | lr 2.94e-04 | grad 3.14 | tok/s 102175
step    420 | loss 2.3275 | lr 2.74e-04 | grad 2.03 | tok/s 101473
step    430 | loss 2.4300 | lr 2.42e-04 | grad 3.62 | tok/s 101070
step    440 | loss 2.5063 | lr 2.01e-04 | grad 2.42 | tok/s 104997
step    450 | loss 2.2298 | lr 1.55e-04 | grad 1.37 | tok/s 102068
step    460 | loss 2.1834 | lr 1.09e-04 | grad 1.33 | tok/s 102530
step    470 | loss 2.1854 | lr 6.65e-05 | grad 2.67 | tok/s 103678
step    480 | loss 2.0849 | lr 3.24e-05 | grad 1.16 | tok/s 100063
step    490 | loss 2.0354 | lr 9.84e-06 | grad 0.84 | tok/s 101757
step    500 | loss 2.9021 | lr 1.07e-06 | grad 1.27 | tok/s 104997
step    510 | loss 2.0330 | lr 6.94e-06 | grad 1.07 | tok/s 102503
step    520 | loss 2.1218 | lr 2.69e-05 | grad 0.73 | tok/s 105756
step    530 | loss 2.5322 | lr 5.89e-05 | grad 2.02 | tok/s 103493
step    540 | loss 2.0713 | lr 9.99e-05 | grad 4.09 | tok/s 103441
step    550 | loss 2.0290 | lr 1.46e-04 | grad 2.12 | tok/s 106316
step    560 | loss 1.9030 | lr 1.92e-04 | grad 2.02 | tok/s 107603
step    570 | loss 2.1193 | lr 2.35e-04 | grad 3.34 | tok/s 105143
step    580 | loss 2.5104 | lr 2.69e-04 | grad 2.83 | tok/s 103623
step    590 | loss 2.7247 | lr 2.91e-04 | grad 2.64 | tok/s 101638
step    600 | loss 2.2690 | lr 3.00e-04 | grad 3.42 | tok/s 101887
step    610 | loss 2.2781 | lr 2.94e-04 | grad 2.28 | tok/s 106698
step    620 | loss 2.1710 | lr 2.74e-04 | grad 2.66 | tok/s 100896
step    630 | loss 2.1233 | lr 2.42e-04 | grad 3.41 | tok/s 103817
step    640 | loss 2.3776 | lr 2.01e-04 | grad 2.47 | tok/s 104505
step    650 | loss 2.1306 | lr 1.55e-04 | grad 3.05 | tok/s 102412
step    660 | loss 2.4095 | lr 1.09e-04 | grad 5.47 | tok/s 101146
step    670 | loss 2.2201 | lr 6.65e-05 | grad 3.03 | tok/s 104598
step    680 | loss 2.1442 | lr 3.24e-05 | grad 1.41 | tok/s 100846
step    690 | loss 2.1619 | lr 9.84e-06 | grad 1.46 | tok/s 101728
step    700 | loss 2.2544 | lr 1.07e-06 | grad 1.48 | tok/s 102273
step    710 | loss 2.1745 | lr 6.94e-06 | grad 1.27 | tok/s 102705
step    720 | loss 2.2748 | lr 2.68e-05 | grad 2.02 | tok/s 102370
step    730 | loss 2.2236 | lr 5.89e-05 | grad 1.43 | tok/s 103270
step    740 | loss 2.1338 | lr 9.99e-05 | grad 2.30 | tok/s 102353
step    750 | loss 1.9999 | lr 1.46e-04 | grad 2.97 | tok/s 101045
step    760 | loss 2.3422 | lr 1.92e-04 | grad 1.77 | tok/s 102438
step    770 | loss 2.0731 | lr 2.35e-04 | grad 2.19 | tok/s 101792
step    780 | loss 2.1223 | lr 2.69e-04 | grad 3.42 | tok/s 102877
step    790 | loss 2.1382 | lr 2.91e-04 | grad 3.80 | tok/s 103744
step    800 | loss 2.0679 | lr 3.00e-04 | grad 2.50 | tok/s 103738
step    810 | loss 2.1206 | lr 2.94e-04 | grad 3.05 | tok/s 102680
step    820 | loss 2.6526 | lr 2.74e-04 | grad 2.23 | tok/s 105390
step    830 | loss 2.2149 | lr 2.42e-04 | grad 1.46 | tok/s 106997
step    840 | loss 1.9641 | lr 2.01e-04 | grad 1.38 | tok/s 106987
step    850 | loss 2.3474 | lr 1.55e-04 | grad 1.32 | tok/s 101917
step    860 | loss 2.1700 | lr 1.09e-04 | grad 2.05 | tok/s 99806
step    870 | loss 2.0949 | lr 6.65e-05 | grad 1.41 | tok/s 102708
step    880 | loss 2.1341 | lr 3.24e-05 | grad 1.88 | tok/s 102203
step    890 | loss 2.0172 | lr 9.84e-06 | grad 1.10 | tok/s 101932
step    900 | loss 2.4441 | lr 1.07e-06 | grad 1.29 | tok/s 99225
step    910 | loss 2.0857 | lr 6.94e-06 | grad 0.98 | tok/s 101286
step    920 | loss 2.0520 | lr 2.68e-05 | grad 1.15 | tok/s 100672
step    930 | loss 2.1689 | lr 5.89e-05 | grad 1.92 | tok/s 100646
step    940 | loss 2.0768 | lr 9.99e-05 | grad 1.94 | tok/s 99457
step    950 | loss 2.1171 | lr 1.46e-04 | grad 2.66 | tok/s 101984
step    960 | loss 1.9107 | lr 1.92e-04 | grad 2.00 | tok/s 106655
step    970 | loss 1.7381 | lr 2.35e-04 | grad 4.22 | tok/s 106596
step    980 | loss 1.8733 | lr 2.69e-04 | grad 3.14 | tok/s 103769
step    990 | loss 2.2560 | lr 2.91e-04 | grad 4.12 | tok/s 101032
step   1000 | loss 2.1364 | lr 3.00e-04 | grad 2.25 | tok/s 98365
  >>> saved checkpoint: checkpoint_step_001000_loss_2.1364.pt
step   1010 | loss 2.3213 | lr 2.94e-04 | grad 2.00 | tok/s 80105
step   1020 | loss 2.0133 | lr 2.74e-04 | grad 2.48 | tok/s 100976
step   1030 | loss 2.3026 | lr 2.42e-04 | grad 1.98 | tok/s 99417
step   1040 | loss 1.9968 | lr 2.01e-04 | grad 2.59 | tok/s 101672
step   1050 | loss 1.9608 | lr 1.55e-04 | grad 1.59 | tok/s 101947
step   1060 | loss 2.2300 | lr 1.09e-04 | grad 2.50 | tok/s 101975
step   1070 | loss 2.2776 | lr 6.65e-05 | grad 1.56 | tok/s 102287
step   1080 | loss 2.5124 | lr 3.24e-05 | grad 1.83 | tok/s 101081
step   1090 | loss 2.2580 | lr 9.84e-06 | grad 1.35 | tok/s 101942
step   1100 | loss 1.9662 | lr 1.07e-06 | grad 1.30 | tok/s 101211
step   1110 | loss 1.9869 | lr 6.93e-06 | grad 1.16 | tok/s 102923
step   1120 | loss 2.2612 | lr 2.68e-05 | grad 1.20 | tok/s 104067
step   1130 | loss 1.9659 | lr 5.89e-05 | grad 1.09 | tok/s 99189
step   1140 | loss 1.8683 | lr 9.99e-05 | grad 1.55 | tok/s 101794
step   1150 | loss 2.1631 | lr 1.46e-04 | grad 1.62 | tok/s 101503
step   1160 | loss 1.8265 | lr 1.92e-04 | grad 1.55 | tok/s 100516
step   1170 | loss 2.1244 | lr 2.35e-04 | grad 1.86 | tok/s 101703
step   1180 | loss 1.8584 | lr 2.69e-04 | grad 2.19 | tok/s 106878
step   1190 | loss 1.7617 | lr 2.91e-04 | grad 2.45 | tok/s 106926
step   1200 | loss 1.6939 | lr 3.00e-04 | grad 5.31 | tok/s 106836
step   1210 | loss 1.6529 | lr 2.94e-04 | grad 3.23 | tok/s 106941
step   1220 | loss 1.6981 | lr 2.74e-04 | grad 3.84 | tok/s 106263
step   1230 | loss 1.8449 | lr 2.42e-04 | grad 2.27 | tok/s 102624
step   1240 | loss 1.9460 | lr 2.01e-04 | grad 1.90 | tok/s 100734
step   1250 | loss 2.0103 | lr 1.55e-04 | grad 4.16 | tok/s 103719
step   1260 | loss 2.0653 | lr 1.09e-04 | grad 2.52 | tok/s 103648
step   1270 | loss 2.1008 | lr 6.65e-05 | grad 1.66 | tok/s 102376
step   1280 | loss 1.9176 | lr 3.24e-05 | grad 1.21 | tok/s 101194
step   1290 | loss 1.8584 | lr 9.84e-06 | grad 1.64 | tok/s 100960
step   1300 | loss 1.9050 | lr 1.07e-06 | grad 1.05 | tok/s 100095
step   1310 | loss 2.0159 | lr 6.93e-06 | grad 1.20 | tok/s 99898
step   1320 | loss 1.9725 | lr 2.68e-05 | grad 2.25 | tok/s 101756
step   1330 | loss 1.9002 | lr 5.89e-05 | grad 1.52 | tok/s 101771
step   1340 | loss 1.8387 | lr 9.99e-05 | grad 1.62 | tok/s 101845
step   1350 | loss 1.9357 | lr 1.46e-04 | grad 2.83 | tok/s 104371
step   1360 | loss 1.8584 | lr 1.92e-04 | grad 1.74 | tok/s 99445
step   1370 | loss 1.9500 | lr 2.35e-04 | grad 2.36 | tok/s 100902
step   1380 | loss 2.0596 | lr 2.69e-04 | grad 3.02 | tok/s 101783
step   1390 | loss 1.9716 | lr 2.91e-04 | grad 2.69 | tok/s 99250
step   1400 | loss 2.0406 | lr 3.00e-04 | grad 14.06 | tok/s 103239
step   1410 | loss 2.0744 | lr 2.94e-04 | grad 2.41 | tok/s 104142
step   1420 | loss 2.0620 | lr 2.74e-04 | grad 2.59 | tok/s 99270
step   1430 | loss 1.8623 | lr 2.42e-04 | grad 1.88 | tok/s 96901
step   1440 | loss 1.7367 | lr 2.01e-04 | grad 1.89 | tok/s 102376
step   1450 | loss 1.7805 | lr 1.55e-04 | grad 3.03 | tok/s 104732
step   1460 | loss 1.8157 | lr 1.09e-04 | grad 2.53 | tok/s 97596
step   1470 | loss 1.9215 | lr 6.65e-05 | grad 2.45 | tok/s 101230
step   1480 | loss 1.7981 | lr 3.24e-05 | grad 3.03 | tok/s 102269
step   1490 | loss 1.9219 | lr 9.84e-06 | grad 4.31 | tok/s 102274
step   1500 | loss 2.0125 | lr 1.07e-06 | grad 3.80 | tok/s 99435
step   1510 | loss 1.9413 | lr 6.93e-06 | grad 1.55 | tok/s 104623
step   1520 | loss 1.9059 | lr 2.68e-05 | grad 1.80 | tok/s 103664
step   1530 | loss 1.8346 | lr 5.89e-05 | grad 1.12 | tok/s 102763
step   1540 | loss 1.8279 | lr 9.99e-05 | grad 1.38 | tok/s 100909
step   1550 | loss 1.8140 | lr 1.46e-04 | grad 3.86 | tok/s 104860
step   1560 | loss 2.4487 | lr 1.92e-04 | grad 3.28 | tok/s 102206
step   1570 | loss 1.9526 | lr 2.35e-04 | grad 2.31 | tok/s 100465
step   1580 | loss 2.1185 | lr 2.69e-04 | grad 1.90 | tok/s 103655
step   1590 | loss 1.8896 | lr 2.91e-04 | grad 2.44 | tok/s 101220
step   1600 | loss 1.9468 | lr 3.00e-04 | grad 3.97 | tok/s 99254
step   1610 | loss 1.8099 | lr 2.94e-04 | grad 1.52 | tok/s 105004
step   1620 | loss 1.9262 | lr 2.74e-04 | grad 1.93 | tok/s 103396
step   1630 | loss 1.9409 | lr 2.42e-04 | grad 2.81 | tok/s 104194
step   1640 | loss 1.8485 | lr 2.01e-04 | grad 1.45 | tok/s 100750
step   1650 | loss 1.8383 | lr 1.55e-04 | grad 2.73 | tok/s 99244
step   1660 | loss 1.8330 | lr 1.09e-04 | grad 1.53 | tok/s 99818
step   1670 | loss 1.9032 | lr 6.65e-05 | grad 3.47 | tok/s 104044
step   1680 | loss 2.2915 | lr 3.24e-05 | grad 1.35 | tok/s 103807
step   1690 | loss 1.8052 | lr 9.84e-06 | grad 1.30 | tok/s 101427
step   1700 | loss 2.1867 | lr 1.07e-06 | grad 1.10 | tok/s 103452
step   1710 | loss 1.8233 | lr 6.93e-06 | grad 1.29 | tok/s 100499
step   1720 | loss 1.8487 | lr 2.68e-05 | grad 1.58 | tok/s 100906
step   1730 | loss 1.9673 | lr 5.89e-05 | grad 1.62 | tok/s 101039
step   1740 | loss 1.8557 | lr 9.99e-05 | grad 1.26 | tok/s 102473
step   1750 | loss 1.7589 | lr 1.46e-04 | grad 1.48 | tok/s 98882
step   1760 | loss 2.0742 | lr 1.92e-04 | grad 2.31 | tok/s 100310
step   1770 | loss 1.9734 | lr 2.35e-04 | grad 2.88 | tok/s 102530
step   1780 | loss 1.8681 | lr 2.69e-04 | grad 3.23 | tok/s 98670
step   1790 | loss 2.0803 | lr 2.91e-04 | grad 2.61 | tok/s 100611
step   1800 | loss 1.7871 | lr 3.00e-04 | grad 2.39 | tok/s 102276
step   1810 | loss 1.8412 | lr 2.94e-04 | grad 2.17 | tok/s 101858
step   1820 | loss 1.8594 | lr 2.74e-04 | grad 2.81 | tok/s 100745
step   1830 | loss 1.8597 | lr 2.42e-04 | grad 1.70 | tok/s 100531
step   1840 | loss 1.8430 | lr 2.01e-04 | grad 3.47 | tok/s 99699
step   1850 | loss 2.0656 | lr 1.55e-04 | grad 2.47 | tok/s 100487
step   1860 | loss 1.7706 | lr 1.09e-04 | grad 1.60 | tok/s 100580
step   1870 | loss 1.8316 | lr 6.65e-05 | grad 1.90 | tok/s 102960
step   1880 | loss 1.7624 | lr 3.24e-05 | grad 1.23 | tok/s 103112
step   1890 | loss 1.8747 | lr 9.84e-06 | grad 0.83 | tok/s 101398
step   1900 | loss 1.9181 | lr 1.07e-06 | grad 2.00 | tok/s 102229
step   1910 | loss 1.8481 | lr 6.93e-06 | grad 2.06 | tok/s 100830
step   1920 | loss 1.7627 | lr 2.68e-05 | grad 1.35 | tok/s 103851
step   1930 | loss 1.7490 | lr 5.89e-05 | grad 1.28 | tok/s 102935
step   1940 | loss 1.6596 | lr 9.99e-05 | grad 1.80 | tok/s 104883
step   1950 | loss 1.7497 | lr 1.46e-04 | grad 1.61 | tok/s 102128
step   1960 | loss 2.1700 | lr 1.92e-04 | grad 4.50 | tok/s 104269
step   1970 | loss 1.9271 | lr 2.35e-04 | grad 2.77 | tok/s 100741
step   1980 | loss 1.9176 | lr 2.69e-04 | grad 2.83 | tok/s 100631
step   1990 | loss 2.0720 | lr 2.91e-04 | grad 4.22 | tok/s 102857
step   2000 | loss 2.0055 | lr 3.00e-04 | grad 3.33 | tok/s 103850
  >>> saved checkpoint: checkpoint_step_002000_loss_2.0055.pt
step   2010 | loss 1.6965 | lr 2.94e-04 | grad 2.28 | tok/s 80869
step   2020 | loss 1.5005 | lr 2.74e-04 | grad 1.83 | tok/s 106715
step   2030 | loss 1.8254 | lr 2.42e-04 | grad 3.09 | tok/s 105604
step   2040 | loss 1.6400 | lr 2.01e-04 | grad 1.45 | tok/s 106850
step   2050 | loss 1.5511 | lr 1.55e-04 | grad 1.50 | tok/s 105178
step   2060 | loss 1.8388 | lr 1.09e-04 | grad 1.20 | tok/s 100609
step   2070 | loss 1.7802 | lr 6.65e-05 | grad 1.96 | tok/s 105506
step   2080 | loss 1.9533 | lr 3.24e-05 | grad 3.59 | tok/s 99972
step   2090 | loss 1.8572 | lr 9.84e-06 | grad 1.66 | tok/s 103400
step   2100 | loss 1.8137 | lr 1.07e-06 | grad 1.39 | tok/s 100522
step   2110 | loss 1.6924 | lr 6.93e-06 | grad 1.27 | tok/s 103988
step   2120 | loss 1.6942 | lr 2.68e-05 | grad 1.84 | tok/s 102900
step   2130 | loss 1.7982 | lr 5.89e-05 | grad 3.05 | tok/s 99971
step   2140 | loss 1.8423 | lr 9.99e-05 | grad 3.59 | tok/s 100015
step   2150 | loss 1.8808 | lr 1.46e-04 | grad 1.78 | tok/s 101311
step   2160 | loss 1.8274 | lr 1.92e-04 | grad 2.38 | tok/s 100159
step   2170 | loss 1.9677 | lr 2.35e-04 | grad 2.89 | tok/s 101450
step   2180 | loss 1.8557 | lr 2.69e-04 | grad 2.19 | tok/s 103409
step   2190 | loss 2.1691 | lr 2.91e-04 | grad 2.70 | tok/s 103244
step   2200 | loss 1.6442 | lr 3.00e-04 | grad 1.91 | tok/s 106469
step   2210 | loss 1.5681 | lr 2.94e-04 | grad 1.73 | tok/s 106438
step   2220 | loss 1.5065 | lr 2.74e-04 | grad 2.03 | tok/s 106406
step   2230 | loss 1.7273 | lr 2.42e-04 | grad 2.25 | tok/s 102725
step   2240 | loss 2.0126 | lr 2.01e-04 | grad 3.28 | tok/s 105103
step   2250 | loss 1.9054 | lr 1.55e-04 | grad 1.84 | tok/s 104281
step   2260 | loss 1.9931 | lr 1.09e-04 | grad 1.71 | tok/s 102772
step   2270 | loss 1.7569 | lr 6.65e-05 | grad 1.51 | tok/s 100514
step   2280 | loss 1.8930 | lr 3.24e-05 | grad 1.16 | tok/s 100356
step   2290 | loss 1.7048 | lr 9.84e-06 | grad 1.34 | tok/s 101444
step   2300 | loss 1.7155 | lr 1.07e-06 | grad 0.95 | tok/s 98733
step   2310 | loss 1.7871 | lr 6.93e-06 | grad 1.73 | tok/s 105161
step   2320 | loss 1.8501 | lr 2.68e-05 | grad 1.32 | tok/s 106756
step   2330 | loss 1.7715 | lr 5.89e-05 | grad 1.04 | tok/s 106794
step   2340 | loss 1.7630 | lr 9.98e-05 | grad 1.73 | tok/s 104262
step   2350 | loss 1.8386 | lr 1.46e-04 | grad 1.53 | tok/s 101260
step   2360 | loss 2.3448 | lr 1.92e-04 | grad 4.72 | tok/s 102747
step   2370 | loss 1.9234 | lr 2.35e-04 | grad 1.88 | tok/s 102430
step   2380 | loss 1.7220 | lr 2.69e-04 | grad 2.56 | tok/s 101222
step   2390 | loss 1.8266 | lr 2.91e-04 | grad 4.31 | tok/s 101172
step   2400 | loss 1.9490 | lr 3.00e-04 | grad 4.56 | tok/s 99977
step   2410 | loss 1.8419 | lr 2.94e-04 | grad 2.19 | tok/s 100747
step   2420 | loss 2.0864 | lr 2.74e-04 | grad 1.98 | tok/s 101687
step   2430 | loss 1.9515 | lr 2.42e-04 | grad 2.91 | tok/s 100586
step   2440 | loss 2.0002 | lr 2.01e-04 | grad 1.79 | tok/s 103043
step   2450 | loss 1.6290 | lr 1.55e-04 | grad 1.77 | tok/s 101698
step   2460 | loss 1.9218 | lr 1.09e-04 | grad 2.70 | tok/s 103651
step   2470 | loss 2.0696 | lr 6.65e-05 | grad 1.50 | tok/s 106393
step   2480 | loss 1.7173 | lr 3.24e-05 | grad 1.74 | tok/s 101826
step   2490 | loss 1.6374 | lr 9.84e-06 | grad 1.30 | tok/s 100400
step   2500 | loss 1.7715 | lr 1.07e-06 | grad 1.59 | tok/s 103242
step   2510 | loss 1.8257 | lr 6.93e-06 | grad 1.44 | tok/s 103002
step   2520 | loss 1.9645 | lr 2.68e-05 | grad 1.38 | tok/s 99606
step   2530 | loss 1.7876 | lr 5.89e-05 | grad 1.70 | tok/s 79713
step   2540 | loss 1.7771 | lr 9.98e-05 | grad 1.30 | tok/s 81529
step   2550 | loss 2.2791 | lr 1.46e-04 | grad 3.30 | tok/s 81898
step   2560 | loss 2.0388 | lr 1.92e-04 | grad 2.11 | tok/s 83192
step   2570 | loss 1.8294 | lr 2.35e-04 | grad 3.72 | tok/s 89830
step   2580 | loss 1.9755 | lr 2.69e-04 | grad 1.73 | tok/s 102890
step   2590 | loss 1.6587 | lr 2.91e-04 | grad 2.77 | tok/s 93020
step   2600 | loss 1.9008 | lr 3.00e-04 | grad 2.83 | tok/s 95606
step   2610 | loss 1.8515 | lr 2.94e-04 | grad 2.39 | tok/s 86972
step   2620 | loss 1.6530 | lr 2.74e-04 | grad 1.77 | tok/s 102574
step   2630 | loss 1.6713 | lr 2.42e-04 | grad 1.39 | tok/s 103818
step   2640 | loss 1.8137 | lr 2.01e-04 | grad 2.08 | tok/s 100910
step   2650 | loss 1.7259 | lr 1.55e-04 | grad 1.48 | tok/s 97794
step   2660 | loss 2.1274 | lr 1.09e-04 | grad 3.64 | tok/s 105216
step   2670 | loss 1.7050 | lr 6.65e-05 | grad 1.35 | tok/s 107061
step   2680 | loss 1.6164 | lr 3.24e-05 | grad 0.89 | tok/s 107068
step   2690 | loss 1.5558 | lr 9.84e-06 | grad 0.95 | tok/s 107102
step   2700 | loss 1.7416 | lr 1.07e-06 | grad 0.93 | tok/s 103129
step   2710 | loss 1.8641 | lr 6.93e-06 | grad 4.12 | tok/s 100219
step   2720 | loss 2.3807 | lr 2.68e-05 | grad 1.18 | tok/s 105737
step   2730 | loss 1.7876 | lr 5.89e-05 | grad 1.23 | tok/s 102164
step   2740 | loss 1.6097 | lr 9.98e-05 | grad 1.55 | tok/s 102027
step   2750 | loss 1.8450 | lr 1.46e-04 | grad 1.67 | tok/s 102977
step   2760 | loss 1.9197 | lr 1.92e-04 | grad 2.69 | tok/s 98919
step   2770 | loss 1.7550 | lr 2.35e-04 | grad 2.34 | tok/s 103208
step   2780 | loss 1.7474 | lr 2.69e-04 | grad 1.52 | tok/s 99633
step   2790 | loss 1.6304 | lr 2.91e-04 | grad 2.39 | tok/s 102144
step   2800 | loss 2.1843 | lr 3.00e-04 | grad 3.05 | tok/s 102040
step   2810 | loss 2.0347 | lr 2.94e-04 | grad 3.70 | tok/s 103690
step   2820 | loss 2.2065 | lr 2.74e-04 | grad 2.72 | tok/s 104644
step   2830 | loss 1.9563 | lr 2.42e-04 | grad 2.41 | tok/s 104025
step   2840 | loss 1.9866 | lr 2.01e-04 | grad 2.45 | tok/s 102359
step   2850 | loss 1.7572 | lr 1.55e-04 | grad 1.78 | tok/s 104670
step   2860 | loss 1.7154 | lr 1.09e-04 | grad 1.57 | tok/s 102095
step   2870 | loss 1.8406 | lr 6.65e-05 | grad 1.86 | tok/s 101891
step   2880 | loss 2.2464 | lr 3.24e-05 | grad 1.05 | tok/s 102500
step   2890 | loss 1.9347 | lr 9.84e-06 | grad 1.20 | tok/s 103955
step   2900 | loss 1.6697 | lr 1.07e-06 | grad 1.25 | tok/s 99565
step   2910 | loss 1.6149 | lr 6.93e-06 | grad 1.07 | tok/s 99724
step   2920 | loss 2.2059 | lr 2.68e-05 | grad 1.21 | tok/s 104840
step   2930 | loss 1.6678 | lr 5.89e-05 | grad 0.77 | tok/s 102861
step   2940 | loss 1.7290 | lr 9.98e-05 | grad 1.57 | tok/s 100241
step   2950 | loss 1.7373 | lr 1.46e-04 | grad 1.48 | tok/s 100236
step   2960 | loss 1.9985 | lr 1.92e-04 | grad 2.36 | tok/s 101852
step   2970 | loss 1.7708 | lr 2.35e-04 | grad 2.61 | tok/s 100696
step   2980 | loss 1.8029 | lr 2.69e-04 | grad 2.47 | tok/s 102330
step   2990 | loss 1.7734 | lr 2.91e-04 | grad 1.58 | tok/s 102638
step   3000 | loss 1.6655 | lr 3.00e-04 | grad 2.19 | tok/s 103617
  >>> saved checkpoint: checkpoint_step_003000_loss_1.6655.pt
step   3010 | loss 2.0019 | lr 2.94e-04 | grad 3.55 | tok/s 78778
step   3020 | loss 1.7343 | lr 2.74e-04 | grad 1.64 | tok/s 102020
step   3030 | loss 1.8829 | lr 2.42e-04 | grad 2.56 | tok/s 101334
step   3040 | loss 1.7241 | lr 2.01e-04 | grad 2.34 | tok/s 100793
step   3050 | loss 1.8697 | lr 1.55e-04 | grad 1.91 | tok/s 101969
step   3060 | loss 1.6577 | lr 1.09e-04 | grad 1.06 | tok/s 100498
step   3070 | loss 1.6557 | lr 6.65e-05 | grad 1.20 | tok/s 101201
step   3080 | loss 1.6814 | lr 3.24e-05 | grad 0.98 | tok/s 103285
step   3090 | loss 1.6195 | lr 9.84e-06 | grad 0.89 | tok/s 103197
step   3100 | loss 1.6502 | lr 1.07e-06 | grad 0.95 | tok/s 91734
step   3110 | loss 1.6382 | lr 6.93e-06 | grad 0.99 | tok/s 81311
step   3120 | loss 1.6409 | lr 2.68e-05 | grad 1.00 | tok/s 79249
step   3130 | loss 2.3870 | lr 5.89e-05 | grad 3.52 | tok/s 85894
step   3140 | loss 2.5028 | lr 9.98e-05 | grad 1.70 | tok/s 87787
step   3150 | loss 2.0673 | lr 1.46e-04 | grad 1.27 | tok/s 102913
step   3160 | loss 2.1075 | lr 1.92e-04 | grad 2.55 | tok/s 90246
step   3170 | loss 2.7776 | lr 2.35e-04 | grad 4.88 | tok/s 89173
step   3180 | loss 2.0299 | lr 2.69e-04 | grad 2.75 | tok/s 81762
step   3190 | loss 2.1190 | lr 2.91e-04 | grad 2.28 | tok/s 81676
step   3200 | loss 1.7890 | lr 3.00e-04 | grad 2.30 | tok/s 78703
step   3210 | loss 2.3703 | lr 2.94e-04 | grad 3.77 | tok/s 80788
step   3220 | loss 2.0054 | lr 2.74e-04 | grad 2.05 | tok/s 81556
step   3230 | loss 1.8601 | lr 2.42e-04 | grad 1.96 | tok/s 78258
step   3240 | loss 1.8361 | lr 2.01e-04 | grad 2.06 | tok/s 82655
step   3250 | loss 1.7489 | lr 1.55e-04 | grad 1.29 | tok/s 80533
step   3260 | loss 1.6022 | lr 1.09e-04 | grad 2.05 | tok/s 81156
step   3270 | loss 1.9188 | lr 6.65e-05 | grad 1.88 | tok/s 91602
step   3280 | loss 1.8872 | lr 3.24e-05 | grad 1.71 | tok/s 96616
step   3290 | loss 2.0487 | lr 9.84e-06 | grad 4.31 | tok/s 81767
step   3300 | loss 1.8826 | lr 1.07e-06 | grad 0.77 | tok/s 79815
step   3310 | loss 1.7778 | lr 6.93e-06 | grad 1.10 | tok/s 87819
step   3320 | loss 1.8063 | lr 2.68e-05 | grad 1.04 | tok/s 82102
step   3330 | loss 1.8579 | lr 5.89e-05 | grad 1.34 | tok/s 82651
step   3340 | loss 1.7008 | lr 9.98e-05 | grad 1.61 | tok/s 85082
step   3350 | loss 1.7551 | lr 1.46e-04 | grad 1.05 | tok/s 75674
step   3360 | loss 1.7552 | lr 1.92e-04 | grad 1.23 | tok/s 82510
step   3370 | loss 1.6897 | lr 2.35e-04 | grad 1.83 | tok/s 82666
step   3380 | loss 1.7064 | lr 2.69e-04 | grad 2.92 | tok/s 78266
step   3390 | loss 1.9720 | lr 2.91e-04 | grad 2.80 | tok/s 81925
step   3400 | loss 2.2521 | lr 3.00e-04 | grad 4.06 | tok/s 79149
step   3410 | loss 1.7983 | lr 2.94e-04 | grad 2.28 | tok/s 82103
step   3420 | loss 1.7358 | lr 2.74e-04 | grad 2.62 | tok/s 95697
step   3430 | loss 2.0190 | lr 2.42e-04 | grad 3.17 | tok/s 99110
step   3440 | loss 2.4573 | lr 2.01e-04 | grad 5.53 | tok/s 98447
step   3450 | loss 2.0101 | lr 1.55e-04 | grad 1.96 | tok/s 91495
step   3460 | loss 1.9434 | lr 1.09e-04 | grad 1.73 | tok/s 99859
step   3470 | loss 1.9155 | lr 6.65e-05 | grad 0.95 | tok/s 99928
step   3480 | loss 1.8640 | lr 3.24e-05 | grad 1.36 | tok/s 90229
step   3490 | loss 1.8225 | lr 9.84e-06 | grad 0.81 | tok/s 93442
step   3500 | loss 1.7225 | lr 1.07e-06 | grad 1.00 | tok/s 90318
step   3510 | loss 2.0856 | lr 6.93e-06 | grad 1.05 | tok/s 95418
step   3520 | loss 1.8384 | lr 2.68e-05 | grad 1.27 | tok/s 88579
step   3530 | loss 1.6697 | lr 5.89e-05 | grad 1.13 | tok/s 91209
step   3540 | loss 1.6274 | lr 9.98e-05 | grad 2.20 | tok/s 91774
step   3550 | loss 1.7117 | lr 1.46e-04 | grad 1.15 | tok/s 87813
step   3560 | loss 1.8108 | lr 1.92e-04 | grad 1.62 | tok/s 88637
step   3570 | loss 1.7863 | lr 2.35e-04 | grad 2.14 | tok/s 88565
step   3580 | loss 1.6906 | lr 2.69e-04 | grad 1.60 | tok/s 90467
step   3590 | loss 1.7597 | lr 2.91e-04 | grad 1.41 | tok/s 83535
step   3600 | loss 1.9671 | lr 3.00e-04 | grad 2.33 | tok/s 82550
step   3610 | loss 1.7735 | lr 2.94e-04 | grad 2.09 | tok/s 86536
step   3620 | loss 1.7489 | lr 2.74e-04 | grad 2.30 | tok/s 90047
step   3630 | loss 1.9858 | lr 2.42e-04 | grad 1.92 | tok/s 82408
step   3640 | loss 1.6734 | lr 2.01e-04 | grad 1.11 | tok/s 88312
step   3650 | loss 1.5578 | lr 1.55e-04 | grad 0.91 | tok/s 86642
step   3660 | loss 1.4780 | lr 1.09e-04 | grad 0.77 | tok/s 82665
step   3670 | loss 1.4388 | lr 6.65e-05 | grad 0.56 | tok/s 84067
step   3680 | loss 1.4566 | lr 3.24e-05 | grad 0.59 | tok/s 86222
step   3690 | loss 1.5132 | lr 9.84e-06 | grad 1.45 | tok/s 82961
step   3700 | loss 1.7961 | lr 1.07e-06 | grad 1.97 | tok/s 82784
step   3710 | loss 2.0994 | lr 6.93e-06 | grad 2.28 | tok/s 82958
step   3720 | loss 1.8529 | lr 2.68e-05 | grad 1.01 | tok/s 84897
step   3730 | loss 1.6117 | lr 5.89e-05 | grad 1.12 | tok/s 80857
step   3740 | loss 1.6736 | lr 9.98e-05 | grad 1.39 | tok/s 82608

Training complete! Final step: 3746
