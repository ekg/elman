# Job 7: E32
# GPU: 7
# Command: python train.py --level 32 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/e75pc_100m/E32
# Started: 2026-01-20T12:47:06.125018
============================================================

Using device: cuda
Output directory: benchmark_results/e75pc_100m/E32/level32_100m_20260120_124712
Auto r_h_mode: none (level 32 has bounded/no W_h)
Model: Level 32, 114,890,880 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.2291 | lr 2.70e-05 | grad 11.25 | tok/s 20729
step     20 | loss 3.9781 | lr 5.70e-05 | grad 14.56 | tok/s 52006
step     30 | loss 4.4235 | lr 8.70e-05 | grad 5.50 | tok/s 54891
step     40 | loss 3.3160 | lr 1.17e-04 | grad 3.59 | tok/s 53563
step     50 | loss 2.6910 | lr 1.47e-04 | grad 2.88 | tok/s 54244
step     60 | loss 2.8626 | lr 1.77e-04 | grad 3.91 | tok/s 52932
step     70 | loss 2.5223 | lr 2.07e-04 | grad 2.02 | tok/s 51367
step     80 | loss 2.8800 | lr 2.37e-04 | grad 3.06 | tok/s 53015
step     90 | loss 2.7818 | lr 2.67e-04 | grad 3.56 | tok/s 51478
step    100 | loss 2.4152 | lr 2.97e-04 | grad 0.83 | tok/s 51912
step    110 | loss 2.4535 | lr 6.94e-06 | grad 2.20 | tok/s 48971
step    120 | loss 2.6641 | lr 2.69e-05 | grad 1.14 | tok/s 49141
step    130 | loss 2.5093 | lr 5.89e-05 | grad 0.90 | tok/s 50289
step    140 | loss 2.2849 | lr 9.99e-05 | grad 0.76 | tok/s 50462
step    150 | loss 2.1747 | lr 1.46e-04 | grad 1.61 | tok/s 48118
step    160 | loss 2.0831 | lr 1.92e-04 | grad 1.20 | tok/s 48707
step    170 | loss 2.2814 | lr 2.35e-04 | grad 3.02 | tok/s 49858
step    180 | loss 2.2673 | lr 2.69e-04 | grad 1.21 | tok/s 50435
step    190 | loss 2.0106 | lr 2.91e-04 | grad 1.02 | tok/s 51343
step    200 | loss 1.6715 | lr 3.00e-04 | grad 0.98 | tok/s 52302
step    210 | loss 2.2954 | lr 2.94e-04 | grad 1.34 | tok/s 50309
step    220 | loss 2.1535 | lr 2.74e-04 | grad 0.78 | tok/s 52064
step    230 | loss 2.0017 | lr 2.42e-04 | grad 1.02 | tok/s 49490
step    240 | loss 2.0009 | lr 2.01e-04 | grad 1.24 | tok/s 50821
step    250 | loss 1.9875 | lr 1.55e-04 | grad 0.95 | tok/s 50446
step    260 | loss 2.0427 | lr 1.09e-04 | grad 0.52 | tok/s 48117
step    270 | loss 1.9042 | lr 6.65e-05 | grad 0.76 | tok/s 49993
step    280 | loss 1.7950 | lr 3.24e-05 | grad 1.22 | tok/s 50300
step    290 | loss 1.8060 | lr 9.84e-06 | grad 0.66 | tok/s 52669
step    300 | loss 1.7763 | lr 1.07e-06 | grad 0.62 | tok/s 52539
step    310 | loss 1.7730 | lr 6.94e-06 | grad 0.58 | tok/s 52779
step    320 | loss 1.8581 | lr 2.69e-05 | grad 1.50 | tok/s 50904
step    330 | loss 1.8885 | lr 5.89e-05 | grad 0.54 | tok/s 49597
step    340 | loss 1.8982 | lr 9.99e-05 | grad 1.62 | tok/s 50840
step    350 | loss 1.9012 | lr 1.46e-04 | grad 0.73 | tok/s 49358
step    360 | loss 1.8722 | lr 1.92e-04 | grad 1.70 | tok/s 49764
step    370 | loss 1.7162 | lr 2.35e-04 | grad 0.79 | tok/s 50804
step    380 | loss 2.2046 | lr 2.69e-04 | grad 0.89 | tok/s 52049
step    390 | loss 1.8840 | lr 2.91e-04 | grad 0.90 | tok/s 50202
step    400 | loss 1.9804 | lr 3.00e-04 | grad 1.98 | tok/s 51330
step    410 | loss 1.7168 | lr 2.94e-04 | grad 1.66 | tok/s 49812
step    420 | loss 1.8573 | lr 2.74e-04 | grad 0.86 | tok/s 49098
step    430 | loss 1.9679 | lr 2.42e-04 | grad 0.94 | tok/s 49181
step    440 | loss 1.9963 | lr 2.01e-04 | grad 0.67 | tok/s 51351
step    450 | loss 1.8010 | lr 1.55e-04 | grad 0.58 | tok/s 50186
step    460 | loss 1.7687 | lr 1.09e-04 | grad 0.52 | tok/s 50245
step    470 | loss 1.7554 | lr 6.65e-05 | grad 0.79 | tok/s 50933
step    480 | loss 1.6433 | lr 3.24e-05 | grad 0.49 | tok/s 49119
step    490 | loss 1.6352 | lr 9.84e-06 | grad 0.46 | tok/s 49533
step    500 | loss 2.5271 | lr 1.07e-06 | grad 0.76 | tok/s 51584
step    510 | loss 1.6307 | lr 6.94e-06 | grad 0.54 | tok/s 50461
step    520 | loss 1.7256 | lr 2.69e-05 | grad 0.45 | tok/s 51852
step    530 | loss 2.2173 | lr 5.89e-05 | grad 0.50 | tok/s 50789
step    540 | loss 1.6413 | lr 9.99e-05 | grad 0.76 | tok/s 50836
step    550 | loss 1.5535 | lr 1.46e-04 | grad 0.54 | tok/s 51973
step    560 | loss 1.4199 | lr 1.92e-04 | grad 0.52 | tok/s 52729
step    570 | loss 1.6712 | lr 2.35e-04 | grad 1.53 | tok/s 51583
step    580 | loss 1.9852 | lr 2.69e-04 | grad 0.83 | tok/s 50914
step    590 | loss 2.2685 | lr 2.91e-04 | grad 1.08 | tok/s 49680
step    600 | loss 1.8080 | lr 3.00e-04 | grad 1.13 | tok/s 50350
step    610 | loss 1.7873 | lr 2.94e-04 | grad 1.01 | tok/s 52638
step    620 | loss 1.7358 | lr 2.74e-04 | grad 0.67 | tok/s 49509
step    630 | loss 1.6312 | lr 2.42e-04 | grad 0.64 | tok/s 51342
step    640 | loss 1.8940 | lr 2.01e-04 | grad 0.73 | tok/s 51420
step    650 | loss 1.6608 | lr 1.55e-04 | grad 0.80 | tok/s 50472
step    660 | loss 1.9739 | lr 1.09e-04 | grad 4.16 | tok/s 49414
step    670 | loss 1.7968 | lr 6.65e-05 | grad 1.30 | tok/s 51531
step    680 | loss 1.7573 | lr 3.24e-05 | grad 0.80 | tok/s 49502
step    690 | loss 1.7524 | lr 9.84e-06 | grad 1.06 | tok/s 49986
step    700 | loss 1.8636 | lr 1.07e-06 | grad 1.02 | tok/s 50479
step    710 | loss 1.7866 | lr 6.94e-06 | grad 0.86 | tok/s 50842
step    720 | loss 1.8552 | lr 2.68e-05 | grad 1.16 | tok/s 50441
step    730 | loss 1.8489 | lr 5.89e-05 | grad 0.97 | tok/s 51022
step    740 | loss 1.7921 | lr 9.99e-05 | grad 1.42 | tok/s 50562
step    750 | loss 1.5844 | lr 1.46e-04 | grad 1.02 | tok/s 49623
step    760 | loss 1.8914 | lr 1.92e-04 | grad 0.51 | tok/s 50220
step    770 | loss 1.6296 | lr 2.35e-04 | grad 0.84 | tok/s 50343
step    780 | loss 1.6857 | lr 2.69e-04 | grad 0.70 | tok/s 50783
step    790 | loss 1.6086 | lr 2.91e-04 | grad 0.53 | tok/s 51120
step    800 | loss 1.5983 | lr 3.00e-04 | grad 0.82 | tok/s 51051
step    810 | loss 1.6966 | lr 2.94e-04 | grad 1.36 | tok/s 50384
step    820 | loss 2.4026 | lr 2.74e-04 | grad 1.05 | tok/s 51884
step    830 | loss 1.7973 | lr 2.42e-04 | grad 0.57 | tok/s 52825
step    840 | loss 1.5003 | lr 2.01e-04 | grad 0.50 | tok/s 52911
step    850 | loss 1.9951 | lr 1.55e-04 | grad 1.05 | tok/s 50143
step    860 | loss 1.7379 | lr 1.09e-04 | grad 0.77 | tok/s 49397
step    870 | loss 1.6694 | lr 6.65e-05 | grad 0.70 | tok/s 50674
step    880 | loss 1.7453 | lr 3.24e-05 | grad 0.91 | tok/s 50431
step    890 | loss 1.6474 | lr 9.84e-06 | grad 0.71 | tok/s 50534
step    900 | loss 2.0904 | lr 1.07e-06 | grad 0.82 | tok/s 49152
step    910 | loss 1.6944 | lr 6.94e-06 | grad 0.56 | tok/s 50150
step    920 | loss 1.6786 | lr 2.68e-05 | grad 0.64 | tok/s 49906
step    930 | loss 1.7785 | lr 5.89e-05 | grad 1.21 | tok/s 50042
step    940 | loss 1.6743 | lr 9.99e-05 | grad 1.21 | tok/s 49027
step    950 | loss 1.7581 | lr 1.46e-04 | grad 0.84 | tok/s 50473
step    960 | loss 1.4940 | lr 1.92e-04 | grad 0.46 | tok/s 53019
step    970 | loss 1.3325 | lr 2.35e-04 | grad 0.42 | tok/s 53140
step    980 | loss 1.4833 | lr 2.69e-04 | grad 1.98 | tok/s 51426
step    990 | loss 1.8127 | lr 2.91e-04 | grad 0.61 | tok/s 50061
step   1000 | loss 1.6855 | lr 3.00e-04 | grad 0.54 | tok/s 48670
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6855.pt
step   1010 | loss 1.8605 | lr 2.94e-04 | grad 1.28 | tok/s 39988
step   1020 | loss 1.5450 | lr 2.74e-04 | grad 0.68 | tok/s 50276
step   1030 | loss 1.9767 | lr 2.42e-04 | grad 0.62 | tok/s 49105
step   1040 | loss 1.6066 | lr 2.01e-04 | grad 0.91 | tok/s 50179
step   1050 | loss 1.6223 | lr 1.55e-04 | grad 0.56 | tok/s 50481
step   1060 | loss 1.7744 | lr 1.09e-04 | grad 1.00 | tok/s 51014
step   1070 | loss 1.8939 | lr 6.65e-05 | grad 0.65 | tok/s 50477
step   1080 | loss 2.2944 | lr 3.24e-05 | grad 0.83 | tok/s 50054
step   1090 | loss 1.9896 | lr 9.84e-06 | grad 0.68 | tok/s 50754
step   1100 | loss 1.6694 | lr 1.07e-06 | grad 0.57 | tok/s 50053
step   1110 | loss 1.6373 | lr 6.93e-06 | grad 0.67 | tok/s 51157
step   1120 | loss 1.8541 | lr 2.68e-05 | grad 0.65 | tok/s 51885
step   1130 | loss 1.6690 | lr 5.89e-05 | grad 0.54 | tok/s 49012
step   1140 | loss 1.5321 | lr 9.99e-05 | grad 0.52 | tok/s 50350
step   1150 | loss 1.8138 | lr 1.46e-04 | grad 0.88 | tok/s 50259
step   1160 | loss 1.4900 | lr 1.92e-04 | grad 0.43 | tok/s 49858
step   1170 | loss 1.7916 | lr 2.35e-04 | grad 0.63 | tok/s 50332
step   1180 | loss 1.5297 | lr 2.69e-04 | grad 0.55 | tok/s 53040
step   1190 | loss 1.3781 | lr 2.91e-04 | grad 0.46 | tok/s 52653
step   1200 | loss 1.2976 | lr 3.00e-04 | grad 0.53 | tok/s 52848
step   1210 | loss 1.2769 | lr 2.94e-04 | grad 0.53 | tok/s 52932
step   1220 | loss 1.3214 | lr 2.74e-04 | grad 0.73 | tok/s 52448
step   1230 | loss 1.5426 | lr 2.42e-04 | grad 0.61 | tok/s 50286
step   1240 | loss 1.6014 | lr 2.01e-04 | grad 0.52 | tok/s 49512
step   1250 | loss 1.6799 | lr 1.55e-04 | grad 2.30 | tok/s 51399
step   1260 | loss 1.7248 | lr 1.09e-04 | grad 1.91 | tok/s 50689
step   1270 | loss 1.7978 | lr 6.65e-05 | grad 0.98 | tok/s 50536
step   1280 | loss 1.6309 | lr 3.24e-05 | grad 0.63 | tok/s 49685
step   1290 | loss 1.5850 | lr 9.84e-06 | grad 0.72 | tok/s 49857
step   1300 | loss 1.6321 | lr 1.07e-06 | grad 0.62 | tok/s 49263
step   1310 | loss 1.7010 | lr 6.93e-06 | grad 0.57 | tok/s 49417
step   1320 | loss 1.6843 | lr 2.68e-05 | grad 0.94 | tok/s 50067
step   1330 | loss 1.6071 | lr 5.89e-05 | grad 0.46 | tok/s 50005
step   1340 | loss 1.5447 | lr 9.99e-05 | grad 0.73 | tok/s 50457
step   1350 | loss 1.5428 | lr 1.46e-04 | grad 1.10 | tok/s 51782
step   1360 | loss 1.5101 | lr 1.92e-04 | grad 0.54 | tok/s 48857
step   1370 | loss 1.6146 | lr 2.35e-04 | grad 0.50 | tok/s 49758
step   1380 | loss 1.6911 | lr 2.69e-04 | grad 1.04 | tok/s 50346
step   1390 | loss 1.6226 | lr 2.91e-04 | grad 1.21 | tok/s 48753
step   1400 | loss 1.6292 | lr 3.00e-04 | grad 2.64 | tok/s 51100
step   1410 | loss 1.6334 | lr 2.94e-04 | grad 0.93 | tok/s 51618
step   1420 | loss 1.7043 | lr 2.74e-04 | grad 0.67 | tok/s 49078
step   1430 | loss 1.5153 | lr 2.42e-04 | grad 0.60 | tok/s 46898
step   1440 | loss 1.4420 | lr 2.01e-04 | grad 0.57 | tok/s 50222
step   1450 | loss 1.4676 | lr 1.55e-04 | grad 1.40 | tok/s 50975
step   1460 | loss 1.5497 | lr 1.09e-04 | grad 0.46 | tok/s 47850
step   1470 | loss 1.6459 | lr 6.65e-05 | grad 1.55 | tok/s 49260
step   1480 | loss 1.5199 | lr 3.24e-05 | grad 1.37 | tok/s 49750
step   1490 | loss 1.6678 | lr 9.84e-06 | grad 1.67 | tok/s 49828
step   1500 | loss 1.7708 | lr 1.07e-06 | grad 1.85 | tok/s 48264
step   1510 | loss 1.6548 | lr 6.93e-06 | grad 0.83 | tok/s 51064
step   1520 | loss 1.6099 | lr 2.68e-05 | grad 0.95 | tok/s 50389
step   1530 | loss 1.5761 | lr 5.89e-05 | grad 0.46 | tok/s 50097
step   1540 | loss 1.5495 | lr 9.99e-05 | grad 0.42 | tok/s 49126
step   1550 | loss 1.5169 | lr 1.46e-04 | grad 1.78 | tok/s 51008
step   1560 | loss 2.0666 | lr 1.92e-04 | grad 0.84 | tok/s 49697
step   1570 | loss 1.5636 | lr 2.35e-04 | grad 0.91 | tok/s 48902
step   1580 | loss 1.6997 | lr 2.69e-04 | grad 0.80 | tok/s 50211
step   1590 | loss 1.5331 | lr 2.91e-04 | grad 0.54 | tok/s 49325
step   1600 | loss 1.6441 | lr 3.00e-04 | grad 0.66 | tok/s 48399
step   1610 | loss 1.4611 | lr 2.94e-04 | grad 0.75 | tok/s 51155
step   1620 | loss 1.6327 | lr 2.74e-04 | grad 0.50 | tok/s 50439
step   1630 | loss 1.6195 | lr 2.42e-04 | grad 0.55 | tok/s 50800
step   1640 | loss 1.5623 | lr 2.01e-04 | grad 0.52 | tok/s 48931
step   1650 | loss 1.5707 | lr 1.55e-04 | grad 0.92 | tok/s 48028
step   1660 | loss 1.5582 | lr 1.09e-04 | grad 0.50 | tok/s 48724
step   1670 | loss 1.6079 | lr 6.65e-05 | grad 1.41 | tok/s 50838
step   1680 | loss 1.9722 | lr 3.24e-05 | grad 0.46 | tok/s 50642
step   1690 | loss 1.5333 | lr 9.84e-06 | grad 0.73 | tok/s 49618
step   1700 | loss 1.8672 | lr 1.07e-06 | grad 0.43 | tok/s 50832
step   1710 | loss 1.5861 | lr 6.93e-06 | grad 0.74 | tok/s 48860
step   1720 | loss 1.5746 | lr 2.68e-05 | grad 0.57 | tok/s 49352
step   1730 | loss 1.6844 | lr 5.89e-05 | grad 0.64 | tok/s 49296
step   1740 | loss 1.5972 | lr 9.99e-05 | grad 0.48 | tok/s 50401
step   1750 | loss 1.5021 | lr 1.46e-04 | grad 0.43 | tok/s 48283
step   1760 | loss 1.7362 | lr 1.92e-04 | grad 0.52 | tok/s 49050
step   1770 | loss 1.6507 | lr 2.35e-04 | grad 0.47 | tok/s 50015
step   1780 | loss 1.5529 | lr 2.69e-04 | grad 0.85 | tok/s 48271
step   1790 | loss 1.7316 | lr 2.91e-04 | grad 0.61 | tok/s 49352
step   1800 | loss 1.4904 | lr 3.00e-04 | grad 0.49 | tok/s 49841
step   1810 | loss 1.5820 | lr 2.94e-04 | grad 0.69 | tok/s 49823
step   1820 | loss 1.5241 | lr 2.74e-04 | grad 0.52 | tok/s 49419
step   1830 | loss 1.5607 | lr 2.42e-04 | grad 0.55 | tok/s 48952
step   1840 | loss 1.5294 | lr 2.01e-04 | grad 0.61 | tok/s 48335
step   1850 | loss 1.7546 | lr 1.55e-04 | grad 0.73 | tok/s 49266
step   1860 | loss 1.5253 | lr 1.09e-04 | grad 0.41 | tok/s 48973
step   1870 | loss 1.5663 | lr 6.65e-05 | grad 0.99 | tok/s 50382
step   1880 | loss 1.5155 | lr 3.24e-05 | grad 0.48 | tok/s 50137
step   1890 | loss 1.6082 | lr 9.84e-06 | grad 0.47 | tok/s 49557
step   1900 | loss 1.6674 | lr 1.07e-06 | grad 1.16 | tok/s 49784
step   1910 | loss 1.6432 | lr 6.93e-06 | grad 1.64 | tok/s 49069

Training complete! Final step: 1911
