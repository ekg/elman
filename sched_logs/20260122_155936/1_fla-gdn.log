Using device: cuda
Output directory: benchmark_results/mega_100m_20260122_155533/fla-gdn/levelfla-gdn_100m_20260122_155943
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level fla-gdn, 105,717,568 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 4.7733 | lr 3.00e-04 | grad 9.56 | tok/s 24852
step     20 | loss 3.7019 | lr 3.00e-04 | grad 13.25 | tok/s 82381
step     30 | loss 5.2357 | lr 3.00e-04 | grad 12.75 | tok/s 86751
step     40 | loss 4.4474 | lr 3.00e-04 | grad 7.94 | tok/s 86447
step     50 | loss 3.4044 | lr 3.00e-04 | grad 3.92 | tok/s 86105
step     60 | loss 3.1659 | lr 3.00e-04 | grad 4.53 | tok/s 84189
step     70 | loss 2.7488 | lr 3.00e-04 | grad 2.72 | tok/s 81199
step     80 | loss 2.9044 | lr 3.00e-04 | grad 2.67 | tok/s 84240
step     90 | loss 2.8239 | lr 3.00e-04 | grad 5.25 | tok/s 80932
step    100 | loss 2.5418 | lr 3.00e-04 | grad 2.23 | tok/s 81397
step    110 | loss 2.4193 | lr 3.00e-04 | grad 2.09 | tok/s 80138
step    120 | loss 2.4883 | lr 3.00e-04 | grad 1.59 | tok/s 78914
step    130 | loss 2.4417 | lr 3.00e-04 | grad 1.58 | tok/s 80568
step    140 | loss 2.2017 | lr 3.00e-04 | grad 1.57 | tok/s 80354
step    150 | loss 2.0912 | lr 3.00e-04 | grad 2.41 | tok/s 76536
step    160 | loss 2.0024 | lr 3.00e-04 | grad 1.63 | tok/s 77364
step    170 | loss 2.1775 | lr 3.00e-04 | grad 8.50 | tok/s 79871
step    180 | loss 2.1883 | lr 3.00e-04 | grad 1.10 | tok/s 80157
step    190 | loss 1.8843 | lr 3.00e-04 | grad 1.59 | tok/s 81222
step    200 | loss 1.5718 | lr 3.00e-04 | grad 1.46 | tok/s 82931
step    210 | loss 2.0796 | lr 3.00e-04 | grad 2.03 | tok/s 79498
step    220 | loss 1.9861 | lr 3.00e-04 | grad 1.44 | tok/s 81819
step    230 | loss 1.8682 | lr 3.00e-04 | grad 2.28 | tok/s 79187
step    240 | loss 1.8977 | lr 3.00e-04 | grad 2.27 | tok/s 80737
step    250 | loss 1.8530 | lr 3.00e-04 | grad 1.57 | tok/s 79577
step    260 | loss 1.9162 | lr 3.00e-04 | grad 1.09 | tok/s 76394
step    270 | loss 1.8029 | lr 3.00e-04 | grad 1.37 | tok/s 79296
step    280 | loss 1.6973 | lr 3.00e-04 | grad 2.14 | tok/s 79119
step    290 | loss 1.5870 | lr 3.00e-04 | grad 1.39 | tok/s 83108
step    300 | loss 1.5117 | lr 3.00e-04 | grad 1.25 | tok/s 83136
step    310 | loss 1.4601 | lr 3.00e-04 | grad 1.03 | tok/s 83198
step    320 | loss 1.6449 | lr 3.00e-04 | grad 2.05 | tok/s 80136
step    330 | loss 1.7659 | lr 3.00e-04 | grad 1.26 | tok/s 78197
step    340 | loss 1.7571 | lr 3.00e-04 | grad 2.69 | tok/s 79757
step    350 | loss 1.7953 | lr 3.00e-04 | grad 1.80 | tok/s 77653
step    360 | loss 1.7514 | lr 3.00e-04 | grad 3.73 | tok/s 78577
step    370 | loss 1.5470 | lr 3.00e-04 | grad 1.27 | tok/s 79926
step    380 | loss 2.0192 | lr 3.00e-04 | grad 1.48 | tok/s 81954
step    390 | loss 1.6541 | lr 3.00e-04 | grad 1.14 | tok/s 78888
step    400 | loss 1.7627 | lr 3.00e-04 | grad 3.02 | tok/s 80984
step    410 | loss 1.5155 | lr 3.00e-04 | grad 2.42 | tok/s 78783
step    420 | loss 1.6362 | lr 3.00e-04 | grad 1.48 | tok/s 78036
step    430 | loss 1.7379 | lr 3.00e-04 | grad 1.73 | tok/s 77674
step    440 | loss 1.7903 | lr 3.00e-04 | grad 1.17 | tok/s 80614
step    450 | loss 1.6530 | lr 3.00e-04 | grad 1.13 | tok/s 78381
step    460 | loss 1.6416 | lr 3.00e-04 | grad 1.09 | tok/s 78677
step    470 | loss 1.6085 | lr 3.00e-04 | grad 1.51 | tok/s 79674
step    480 | loss 1.5452 | lr 3.00e-04 | grad 0.96 | tok/s 76896
step    490 | loss 1.5351 | lr 3.00e-04 | grad 1.05 | tok/s 78355
step    500 | loss 2.1588 | lr 3.00e-04 | grad 1.77 | tok/s 80679
step    510 | loss 1.5122 | lr 3.00e-04 | grad 1.04 | tok/s 79084
step    520 | loss 1.5064 | lr 3.00e-04 | grad 1.17 | tok/s 81493
step    530 | loss 2.0059 | lr 3.00e-04 | grad 1.41 | tok/s 79692
step    540 | loss 1.4646 | lr 3.00e-04 | grad 1.77 | tok/s 79744
step    550 | loss 1.4112 | lr 3.00e-04 | grad 1.09 | tok/s 81621
step    560 | loss 1.3201 | lr 3.00e-04 | grad 0.89 | tok/s 82707
step    570 | loss 1.5516 | lr 3.00e-04 | grad 2.59 | tok/s 81024
step    580 | loss 1.7945 | lr 3.00e-04 | grad 1.32 | tok/s 79963
step    590 | loss 1.9805 | lr 3.00e-04 | grad 1.41 | tok/s 78307
step    600 | loss 1.5410 | lr 3.00e-04 | grad 1.73 | tok/s 78719
step    610 | loss 1.5576 | lr 3.00e-04 | grad 1.38 | tok/s 82515
step    620 | loss 1.5073 | lr 3.00e-04 | grad 1.19 | tok/s 78235
step    630 | loss 1.4634 | lr 3.00e-04 | grad 1.16 | tok/s 80766
step    640 | loss 1.6784 | lr 3.00e-04 | grad 1.22 | tok/s 80854
step    650 | loss 1.5031 | lr 3.00e-04 | grad 1.52 | tok/s 79401
step    660 | loss 1.7448 | lr 3.00e-04 | grad 4.94 | tok/s 78366
step    670 | loss 1.6403 | lr 3.00e-04 | grad 1.91 | tok/s 80983
step    680 | loss 1.5849 | lr 3.00e-04 | grad 1.77 | tok/s 78188
step    690 | loss 1.6217 | lr 3.00e-04 | grad 1.94 | tok/s 78942
step    700 | loss 1.7155 | lr 3.00e-04 | grad 2.08 | tok/s 79260
step    710 | loss 1.5778 | lr 3.00e-04 | grad 1.39 | tok/s 79743
step    720 | loss 1.5536 | lr 3.00e-04 | grad 2.34 | tok/s 79496
step    730 | loss 1.6830 | lr 3.00e-04 | grad 1.84 | tok/s 80190
step    740 | loss 1.6405 | lr 3.00e-04 | grad 2.47 | tok/s 79515
step    750 | loss 1.4603 | lr 3.00e-04 | grad 1.92 | tok/s 78435
step    760 | loss 1.7897 | lr 3.00e-04 | grad 1.18 | tok/s 79522
step    770 | loss 1.4931 | lr 3.00e-04 | grad 1.52 | tok/s 79139
step    780 | loss 1.5410 | lr 3.00e-04 | grad 1.06 | tok/s 79946
step    790 | loss 1.4367 | lr 3.00e-04 | grad 1.15 | tok/s 80668
step    800 | loss 1.4354 | lr 3.00e-04 | grad 1.41 | tok/s 80687
step    810 | loss 1.4766 | lr 3.00e-04 | grad 2.52 | tok/s 80181
step    820 | loss 2.2461 | lr 3.00e-04 | grad 1.65 | tok/s 81919
step    830 | loss 2.0312 | lr 3.00e-04 | grad 1.59 | tok/s 83146
step    840 | loss 1.7387 | lr 3.00e-04 | grad 1.38 | tok/s 83120
step    850 | loss 1.6301 | lr 3.00e-04 | grad 1.33 | tok/s 79127
step    860 | loss 1.4819 | lr 3.00e-04 | grad 1.25 | tok/s 77424
step    870 | loss 1.4485 | lr 3.00e-04 | grad 1.34 | tok/s 79719
step    880 | loss 1.5082 | lr 3.00e-04 | grad 1.48 | tok/s 79350
step    890 | loss 1.4402 | lr 3.00e-04 | grad 1.30 | tok/s 79290
step    900 | loss 1.7923 | lr 3.00e-04 | grad 1.38 | tok/s 77362
step    910 | loss 1.4428 | lr 3.00e-04 | grad 1.27 | tok/s 78802
step    920 | loss 1.5077 | lr 3.00e-04 | grad 1.20 | tok/s 78568
step    930 | loss 1.5700 | lr 3.00e-04 | grad 2.03 | tok/s 78289
step    940 | loss 1.4866 | lr 3.00e-04 | grad 2.52 | tok/s 77639
step    950 | loss 1.5425 | lr 3.00e-04 | grad 1.49 | tok/s 79489
step    960 | loss 1.3688 | lr 3.00e-04 | grad 1.29 | tok/s 83091
step    970 | loss 1.2962 | lr 3.00e-04 | grad 0.95 | tok/s 83008
step    980 | loss 1.3842 | lr 3.00e-04 | grad 2.17 | tok/s 80843
step    990 | loss 1.5862 | lr 3.00e-04 | grad 1.17 | tok/s 78585
step   1000 | loss 1.5366 | lr 3.00e-04 | grad 1.07 | tok/s 76976
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5366.pt
step   1010 | loss 1.6521 | lr 3.00e-04 | grad 1.26 | tok/s 54432
step   1020 | loss 1.3708 | lr 3.00e-04 | grad 1.16 | tok/s 79163
step   1030 | loss 1.7271 | lr 3.00e-04 | grad 1.20 | tok/s 77776
step   1040 | loss 1.4530 | lr 3.00e-04 | grad 1.61 | tok/s 79441
step   1050 | loss 1.4603 | lr 3.00e-04 | grad 1.23 | tok/s 79761
step   1060 | loss 1.5688 | lr 3.00e-04 | grad 3.19 | tok/s 79859
step   1070 | loss 1.6834 | lr 3.00e-04 | grad 1.34 | tok/s 80026
step   1080 | loss 2.0143 | lr 3.00e-04 | grad 1.66 | tok/s 79141
step   1090 | loss 1.7823 | lr 3.00e-04 | grad 1.68 | tok/s 79782
step   1100 | loss 1.4938 | lr 3.00e-04 | grad 1.41 | tok/s 79263
step   1110 | loss 1.4389 | lr 3.00e-04 | grad 1.64 | tok/s 80666
step   1120 | loss 1.5239 | lr 3.00e-04 | grad 1.26 | tok/s 81327
step   1130 | loss 1.5511 | lr 3.00e-04 | grad 1.14 | tok/s 77311
step   1140 | loss 1.4231 | lr 3.00e-04 | grad 1.20 | tok/s 79339
step   1150 | loss 1.6914 | lr 3.00e-04 | grad 1.88 | tok/s 79183
step   1160 | loss 1.3993 | lr 3.00e-04 | grad 1.07 | tok/s 78451
step   1170 | loss 1.5862 | lr 3.00e-04 | grad 1.36 | tok/s 79231
step   1180 | loss 1.4730 | lr 3.00e-04 | grad 1.13 | tok/s 83157
step   1190 | loss 1.3781 | lr 3.00e-04 | grad 1.07 | tok/s 83050
step   1200 | loss 1.3132 | lr 3.00e-04 | grad 1.00 | tok/s 83239
step   1210 | loss 1.2987 | lr 3.00e-04 | grad 1.20 | tok/s 83312
step   1220 | loss 1.3134 | lr 3.00e-04 | grad 1.40 | tok/s 82529
step   1230 | loss 1.3461 | lr 3.00e-04 | grad 1.12 | tok/s 79933
step   1240 | loss 1.4522 | lr 3.00e-04 | grad 1.12 | tok/s 78465
step   1250 | loss 1.5359 | lr 3.00e-04 | grad 5.12 | tok/s 80772
step   1260 | loss 1.5685 | lr 3.00e-04 | grad 3.30 | tok/s 80591
step   1270 | loss 1.6230 | lr 3.00e-04 | grad 1.85 | tok/s 79710
step   1280 | loss 1.5023 | lr 3.00e-04 | grad 1.52 | tok/s 78865
step   1290 | loss 1.4546 | lr 3.00e-04 | grad 1.12 | tok/s 78544
step   1300 | loss 1.5110 | lr 3.00e-04 | grad 1.21 | tok/s 78114
step   1310 | loss 1.5782 | lr 3.00e-04 | grad 1.20 | tok/s 77928
step   1320 | loss 1.5604 | lr 3.00e-04 | grad 1.66 | tok/s 79324
step   1330 | loss 1.4404 | lr 3.00e-04 | grad 1.27 | tok/s 79502
step   1340 | loss 1.3604 | lr 3.00e-04 | grad 1.23 | tok/s 79489
step   1350 | loss 1.3825 | lr 3.00e-04 | grad 1.91 | tok/s 81602
step   1360 | loss 1.4046 | lr 3.00e-04 | grad 1.37 | tok/s 77509
step   1370 | loss 1.5044 | lr 3.00e-04 | grad 1.20 | tok/s 78725
step   1380 | loss 1.5469 | lr 3.00e-04 | grad 1.48 | tok/s 79263
step   1390 | loss 1.4839 | lr 3.00e-04 | grad 2.20 | tok/s 77393
step   1400 | loss 1.4459 | lr 3.00e-04 | grad 4.50 | tok/s 80518
step   1410 | loss 1.4611 | lr 3.00e-04 | grad 1.96 | tok/s 81333
step   1420 | loss 1.5029 | lr 3.00e-04 | grad 1.23 | tok/s 77407
step   1430 | loss 1.3950 | lr 3.00e-04 | grad 1.23 | tok/s 75483
step   1440 | loss 1.3122 | lr 3.00e-04 | grad 1.02 | tok/s 79784
step   1450 | loss 1.3125 | lr 3.00e-04 | grad 1.91 | tok/s 81331
step   1460 | loss 1.4420 | lr 3.00e-04 | grad 1.21 | tok/s 75983
step   1470 | loss 1.5162 | lr 3.00e-04 | grad 3.39 | tok/s 78878
step   1480 | loss 1.4015 | lr 3.00e-04 | grad 3.14 | tok/s 79583
step   1490 | loss 1.5258 | lr 3.00e-04 | grad 2.83 | tok/s 79562
step   1500 | loss 1.6078 | lr 3.00e-04 | grad 3.03 | tok/s 77432
step   1510 | loss 1.4979 | lr 3.00e-04 | grad 1.65 | tok/s 81420
step   1520 | loss 1.4723 | lr 3.00e-04 | grad 1.55 | tok/s 80594
step   1530 | loss 1.4533 | lr 3.00e-04 | grad 1.05 | tok/s 79962
step   1540 | loss 1.4209 | lr 3.00e-04 | grad 1.04 | tok/s 78491
step   1550 | loss 1.3804 | lr 3.00e-04 | grad 5.44 | tok/s 81779
step   1560 | loss 1.8954 | lr 3.00e-04 | grad 2.23 | tok/s 79579
step   1570 | loss 1.4408 | lr 3.00e-04 | grad 1.43 | tok/s 78128
step   1580 | loss 1.5507 | lr 3.00e-04 | grad 2.08 | tok/s 80620
step   1590 | loss 1.3653 | lr 3.00e-04 | grad 1.06 | tok/s 78780
step   1600 | loss 1.4818 | lr 3.00e-04 | grad 1.05 | tok/s 77230
step   1610 | loss 1.3097 | lr 3.00e-04 | grad 1.13 | tok/s 81851
step   1620 | loss 1.4740 | lr 3.00e-04 | grad 1.07 | tok/s 73299
step   1630 | loss 1.4304 | lr 3.00e-04 | grad 1.05 | tok/s 81192
step   1640 | loss 1.3880 | lr 3.00e-04 | grad 1.13 | tok/s 78458
step   1650 | loss 1.4310 | lr 3.00e-04 | grad 1.87 | tok/s 77289
step   1660 | loss 1.4405 | lr 3.00e-04 | grad 1.19 | tok/s 77832
step   1670 | loss 1.4389 | lr 3.00e-04 | grad 2.36 | tok/s 81144
step   1680 | loss 1.8236 | lr 3.00e-04 | grad 1.07 | tok/s 81132
step   1690 | loss 1.4030 | lr 3.00e-04 | grad 1.36 | tok/s 79177
step   1700 | loss 1.4986 | lr 3.00e-04 | grad 1.10 | tok/s 80767
step   1710 | loss 1.4844 | lr 3.00e-04 | grad 1.86 | tok/s 78428
step   1720 | loss 1.4058 | lr 3.00e-04 | grad 1.40 | tok/s 78871
step   1730 | loss 1.5791 | lr 3.00e-04 | grad 1.59 | tok/s 78836
step   1740 | loss 1.4534 | lr 3.00e-04 | grad 1.02 | tok/s 79973
step   1750 | loss 1.4235 | lr 3.00e-04 | grad 1.19 | tok/s 77167
step   1760 | loss 1.5670 | lr 3.00e-04 | grad 1.19 | tok/s 78359
step   1770 | loss 1.5205 | lr 3.00e-04 | grad 1.00 | tok/s 80042
step   1780 | loss 1.4436 | lr 3.00e-04 | grad 1.59 | tok/s 77131
step   1790 | loss 1.5806 | lr 3.00e-04 | grad 1.33 | tok/s 78529
step   1800 | loss 1.3674 | lr 3.00e-04 | grad 0.99 | tok/s 80034
step   1810 | loss 1.4580 | lr 3.00e-04 | grad 1.20 | tok/s 79565
step   1820 | loss 1.3424 | lr 3.00e-04 | grad 1.04 | tok/s 78812
step   1830 | loss 1.4046 | lr 3.00e-04 | grad 1.18 | tok/s 78504
step   1840 | loss 1.3979 | lr 3.00e-04 | grad 1.19 | tok/s 77924
step   1850 | loss 1.6188 | lr 3.00e-04 | grad 1.44 | tok/s 78688
step   1860 | loss 1.3960 | lr 3.00e-04 | grad 1.13 | tok/s 78427
step   1870 | loss 1.3727 | lr 3.00e-04 | grad 1.59 | tok/s 80198
step   1880 | loss 1.3940 | lr 3.00e-04 | grad 1.05 | tok/s 80279
step   1890 | loss 1.4959 | lr 3.00e-04 | grad 1.03 | tok/s 78990
step   1900 | loss 1.4358 | lr 3.00e-04 | grad 0.98 | tok/s 79748
step   1910 | loss 1.5221 | lr 3.00e-04 | grad 2.59 | tok/s 78624
step   1920 | loss 1.3431 | lr 3.00e-04 | grad 1.09 | tok/s 81041
step   1930 | loss 1.3666 | lr 3.00e-04 | grad 1.31 | tok/s 80306
step   1940 | loss 1.3779 | lr 3.00e-04 | grad 1.29 | tok/s 81886
step   1950 | loss 1.4249 | lr 3.00e-04 | grad 1.12 | tok/s 79742
step   1960 | loss 1.6013 | lr 3.00e-04 | grad 4.22 | tok/s 81456
step   1970 | loss 1.2939 | lr 3.00e-04 | grad 1.34 | tok/s 78638
step   1980 | loss 1.4320 | lr 3.00e-04 | grad 2.50 | tok/s 78518
step   1990 | loss 1.4869 | lr 3.00e-04 | grad 1.49 | tok/s 80155
step   2000 | loss 1.3782 | lr 3.00e-04 | grad 1.46 | tok/s 80962
  >>> saved checkpoint: checkpoint_step_002000_loss_1.3782.pt
step   2010 | loss 1.2434 | lr 3.00e-04 | grad 1.03 | tok/s 56255
step   2020 | loss 1.1532 | lr 3.00e-04 | grad 0.91 | tok/s 83569
step   2030 | loss 1.3980 | lr 3.00e-04 | grad 1.01 | tok/s 82473
step   2040 | loss 1.2727 | lr 3.00e-04 | grad 1.14 | tok/s 83413
step   2050 | loss 1.2505 | lr 3.00e-04 | grad 1.44 | tok/s 82371
step   2060 | loss 1.4773 | lr 3.00e-04 | grad 1.20 | tok/s 78687
step   2070 | loss 1.4448 | lr 3.00e-04 | grad 1.41 | tok/s 82444
step   2080 | loss 1.4387 | lr 3.00e-04 | grad 2.14 | tok/s 78219
step   2090 | loss 1.4192 | lr 3.00e-04 | grad 1.27 | tok/s 80863
step   2100 | loss 1.4188 | lr 3.00e-04 | grad 1.44 | tok/s 78548
step   2110 | loss 1.1979 | lr 3.00e-04 | grad 1.04 | tok/s 81368
step   2120 | loss 1.2499 | lr 3.00e-04 | grad 1.34 | tok/s 80702
step   2130 | loss 1.4063 | lr 3.00e-04 | grad 4.09 | tok/s 78310
step   2140 | loss 1.4675 | lr 3.00e-04 | grad 2.97 | tok/s 78235
step   2150 | loss 1.4668 | lr 3.00e-04 | grad 1.11 | tok/s 79296
step   2160 | loss 1.4625 | lr 3.00e-04 | grad 1.04 | tok/s 78295
step   2170 | loss 1.5510 | lr 3.00e-04 | grad 1.42 | tok/s 79273
step   2180 | loss 1.4001 | lr 3.00e-04 | grad 1.30 | tok/s 80900
step   2190 | loss 1.6142 | lr 3.00e-04 | grad 1.29 | tok/s 80674
step   2200 | loss 1.1964 | lr 3.00e-04 | grad 0.98 | tok/s 83504
step   2210 | loss 1.2212 | lr 3.00e-04 | grad 1.03 | tok/s 83384
step   2220 | loss 1.1998 | lr 3.00e-04 | grad 1.12 | tok/s 83429
step   2230 | loss 1.3339 | lr 3.00e-04 | grad 1.20 | tok/s 80484
step   2240 | loss 1.4541 | lr 3.00e-04 | grad 2.41 | tok/s 82446
step   2250 | loss 1.4230 | lr 3.00e-04 | grad 1.40 | tok/s 81744
step   2260 | loss 1.4998 | lr 3.00e-04 | grad 1.39 | tok/s 80704
step   2270 | loss 1.3492 | lr 3.00e-04 | grad 1.87 | tok/s 78890
step   2280 | loss 1.5049 | lr 3.00e-04 | grad 1.01 | tok/s 78838
step   2290 | loss 1.3704 | lr 3.00e-04 | grad 1.17 | tok/s 79939
step   2300 | loss 1.3506 | lr 3.00e-04 | grad 1.13 | tok/s 77329
step   2310 | loss 1.4141 | lr 3.00e-04 | grad 1.19 | tok/s 82085
step   2320 | loss 1.3949 | lr 3.00e-04 | grad 1.01 | tok/s 83247
step   2330 | loss 1.3285 | lr 3.00e-04 | grad 0.90 | tok/s 83311
step   2340 | loss 1.3717 | lr 3.00e-04 | grad 1.43 | tok/s 81504
step   2350 | loss 1.4397 | lr 3.00e-04 | grad 1.19 | tok/s 79030
step   2360 | loss 1.7819 | lr 3.00e-04 | grad 2.14 | tok/s 80565
step   2370 | loss 1.4120 | lr 3.00e-04 | grad 1.18 | tok/s 80256
step   2380 | loss 1.3388 | lr 3.00e-04 | grad 1.34 | tok/s 79313
step   2390 | loss 1.3667 | lr 3.00e-04 | grad 1.46 | tok/s 79093
step   2400 | loss 1.4832 | lr 3.00e-04 | grad 1.44 | tok/s 78156
step   2410 | loss 1.3892 | lr 3.00e-04 | grad 1.27 | tok/s 78855
step   2420 | loss 1.4728 | lr 3.00e-04 | grad 1.39 | tok/s 79532
step   2430 | loss 1.4010 | lr 3.00e-04 | grad 1.65 | tok/s 78573
step   2440 | loss 1.4602 | lr 3.00e-04 | grad 1.09 | tok/s 80669
step   2450 | loss 1.3095 | lr 3.00e-04 | grad 2.06 | tok/s 79690
step   2460 | loss 1.4676 | lr 3.00e-04 | grad 2.28 | tok/s 81302
step   2470 | loss 1.2553 | lr 3.00e-04 | grad 1.45 | tok/s 83224
step   2480 | loss 1.3258 | lr 3.00e-04 | grad 1.19 | tok/s 79741
step   2490 | loss 1.3208 | lr 3.00e-04 | grad 1.23 | tok/s 78515
step   2500 | loss 1.3978 | lr 3.00e-04 | grad 1.59 | tok/s 80617
step   2510 | loss 1.4265 | lr 3.00e-04 | grad 1.45 | tok/s 80363
step   2520 | loss 1.5597 | lr 3.00e-04 | grad 1.72 | tok/s 78524
step   2530 | loss 1.4533 | lr 3.00e-04 | grad 2.05 | tok/s 77694
step   2540 | loss 1.4171 | lr 3.00e-04 | grad 1.54 | tok/s 78436
step   2550 | loss 1.7818 | lr 3.00e-04 | grad 1.61 | tok/s 79523
step   2560 | loss 1.4743 | lr 3.00e-04 | grad 1.30 | tok/s 80878
step   2570 | loss 1.4193 | lr 3.00e-04 | grad 2.33 | tok/s 77815
step   2580 | loss 1.4636 | lr 3.00e-04 | grad 1.16 | tok/s 80699
step   2590 | loss 1.3136 | lr 3.00e-04 | grad 1.45 | tok/s 78691
step   2600 | loss 1.4512 | lr 3.00e-04 | grad 1.03 | tok/s 80778
step   2610 | loss 1.3650 | lr 3.00e-04 | grad 1.10 | tok/s 81479
step   2620 | loss 1.3184 | lr 3.00e-04 | grad 1.10 | tok/s 83385
step   2630 | loss 1.3667 | lr 3.00e-04 | grad 1.05 | tok/s 80906
step   2640 | loss 1.4128 | lr 3.00e-04 | grad 1.51 | tok/s 78731
step   2650 | loss 1.3726 | lr 3.00e-04 | grad 1.30 | tok/s 76182
step   2660 | loss 1.6942 | lr 3.00e-04 | grad 1.25 | tok/s 81825
step   2670 | loss 1.3121 | lr 3.00e-04 | grad 0.91 | tok/s 83347
step   2680 | loss 1.2972 | lr 3.00e-04 | grad 1.06 | tok/s 83300
step   2690 | loss 1.2471 | lr 3.00e-04 | grad 1.12 | tok/s 83238
step   2700 | loss 1.4083 | lr 3.00e-04 | grad 1.27 | tok/s 80195
step   2710 | loss 1.4917 | lr 3.00e-04 | grad 2.08 | tok/s 78028
step   2720 | loss 1.7131 | lr 3.00e-04 | grad 1.39 | tok/s 82240
step   2730 | loss 1.4284 | lr 3.00e-04 | grad 1.38 | tok/s 79602
step   2740 | loss 1.2519 | lr 3.00e-04 | grad 1.70 | tok/s 79401
step   2750 | loss 1.4557 | lr 3.00e-04 | grad 1.20 | tok/s 80206
step   2760 | loss 1.5343 | lr 3.00e-04 | grad 2.11 | tok/s 77080
step   2770 | loss 1.3991 | lr 3.00e-04 | grad 1.15 | tok/s 80427
step   2780 | loss 1.3730 | lr 3.00e-04 | grad 1.26 | tok/s 77692
step   2790 | loss 1.2766 | lr 3.00e-04 | grad 1.16 | tok/s 79486
step   2800 | loss 1.6400 | lr 3.00e-04 | grad 2.95 | tok/s 79423
step   2810 | loss 1.4144 | lr 3.00e-04 | grad 1.26 | tok/s 80600
step   2820 | loss 1.5737 | lr 3.00e-04 | grad 2.78 | tok/s 81515
step   2830 | loss 1.3828 | lr 3.00e-04 | grad 0.93 | tok/s 81119
step   2840 | loss 1.4795 | lr 3.00e-04 | grad 0.93 | tok/s 79785
step   2850 | loss 1.3355 | lr 3.00e-04 | grad 1.30 | tok/s 81625
step   2860 | loss 1.2974 | lr 3.00e-04 | grad 1.07 | tok/s 79465
step   2870 | loss 1.3882 | lr 3.00e-04 | grad 1.30 | tok/s 79274
step   2880 | loss 1.7291 | lr 3.00e-04 | grad 1.22 | tok/s 79818
step   2890 | loss 1.5568 | lr 3.00e-04 | grad 1.81 | tok/s 80908
step   2900 | loss 1.3583 | lr 3.00e-04 | grad 1.55 | tok/s 77661
step   2910 | loss 1.3073 | lr 3.00e-04 | grad 0.97 | tok/s 77635
step   2920 | loss 1.5985 | lr 3.00e-04 | grad 2.08 | tok/s 81540
step   2930 | loss 1.3522 | lr 3.00e-04 | grad 1.31 | tok/s 79975
step   2940 | loss 1.4007 | lr 3.00e-04 | grad 1.46 | tok/s 77918
step   2950 | loss 1.3659 | lr 3.00e-04 | grad 1.44 | tok/s 78154
step   2960 | loss 1.5403 | lr 3.00e-04 | grad 1.63 | tok/s 79166
step   2970 | loss 1.3739 | lr 3.00e-04 | grad 1.51 | tok/s 78373
step   2980 | loss 1.4142 | lr 3.00e-04 | grad 1.78 | tok/s 79622
step   2990 | loss 1.3449 | lr 3.00e-04 | grad 0.98 | tok/s 79912
step   3000 | loss 1.2609 | lr 3.00e-04 | grad 1.66 | tok/s 80856
  >>> saved checkpoint: checkpoint_step_003000_loss_1.2609.pt

Training complete! Final step: 3008
