Using device: cuda
Output directory: benchmark_results/mega_100m_20260122_155533/E88_d12h32/levelE88d_h12_100m_20260122_155943
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88d_h12, 99,959,520 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.0433 | lr 3.00e-04 | grad 28.00 | tok/s 22173
step     20 | loss 3.6833 | lr 3.00e-04 | grad 13.19 | tok/s 64073
step     30 | loss 4.0619 | lr 3.00e-04 | grad 9.25 | tok/s 67336
step     40 | loss 3.0224 | lr 3.00e-04 | grad 3.16 | tok/s 66943
step     50 | loss 2.4669 | lr 3.00e-04 | grad 3.50 | tok/s 65854
step     60 | loss 2.8587 | lr 3.00e-04 | grad 4.19 | tok/s 63690
step     70 | loss 2.5462 | lr 3.00e-04 | grad 4.38 | tok/s 61800
step     80 | loss 2.5002 | lr 3.00e-04 | grad 5.19 | tok/s 65306
step     90 | loss 2.5711 | lr 3.00e-04 | grad 7.03 | tok/s 62436
step    100 | loss 2.2286 | lr 3.00e-04 | grad 3.61 | tok/s 63524
step    110 | loss 2.2545 | lr 3.00e-04 | grad 2.98 | tok/s 62080
step    120 | loss 2.2817 | lr 3.00e-04 | grad 2.84 | tok/s 61393
step    130 | loss 2.2839 | lr 3.00e-04 | grad 2.70 | tok/s 62568
step    140 | loss 2.1077 | lr 3.00e-04 | grad 2.22 | tok/s 62701
step    150 | loss 1.9966 | lr 3.00e-04 | grad 3.34 | tok/s 59803
step    160 | loss 1.9446 | lr 3.00e-04 | grad 2.41 | tok/s 59685
step    170 | loss 2.1163 | lr 3.00e-04 | grad 9.19 | tok/s 60817
step    180 | loss 2.0501 | lr 3.00e-04 | grad 1.77 | tok/s 62485
step    190 | loss 1.7923 | lr 3.00e-04 | grad 2.48 | tok/s 63393
step    200 | loss 1.4981 | lr 3.00e-04 | grad 2.30 | tok/s 64559
step    210 | loss 2.0279 | lr 3.00e-04 | grad 3.02 | tok/s 61842
step    220 | loss 1.8912 | lr 3.00e-04 | grad 2.08 | tok/s 63684
step    230 | loss 1.8439 | lr 3.00e-04 | grad 3.48 | tok/s 61214
step    240 | loss 1.8297 | lr 3.00e-04 | grad 3.02 | tok/s 62460
step    250 | loss 1.8125 | lr 3.00e-04 | grad 2.62 | tok/s 62073
step    260 | loss 1.9025 | lr 3.00e-04 | grad 1.93 | tok/s 59752
step    270 | loss 1.7918 | lr 3.00e-04 | grad 1.89 | tok/s 61438
step    280 | loss 1.6869 | lr 3.00e-04 | grad 3.16 | tok/s 61517
step    290 | loss 1.5816 | lr 3.00e-04 | grad 2.22 | tok/s 64989
step    300 | loss 1.5174 | lr 3.00e-04 | grad 2.06 | tok/s 64639
step    310 | loss 1.4742 | lr 3.00e-04 | grad 2.09 | tok/s 64709
step    320 | loss 1.6699 | lr 3.00e-04 | grad 3.73 | tok/s 62427
step    330 | loss 1.7725 | lr 3.00e-04 | grad 2.03 | tok/s 60911
step    340 | loss 1.7760 | lr 3.00e-04 | grad 4.19 | tok/s 62359
step    350 | loss 1.7985 | lr 3.00e-04 | grad 2.02 | tok/s 60386
step    360 | loss 1.7451 | lr 3.00e-04 | grad 5.41 | tok/s 60615
step    370 | loss 1.5630 | lr 3.00e-04 | grad 1.79 | tok/s 62415
step    380 | loss 1.9484 | lr 3.00e-04 | grad 2.08 | tok/s 63625
step    390 | loss 1.6927 | lr 3.00e-04 | grad 1.68 | tok/s 61779
step    400 | loss 1.7540 | lr 3.00e-04 | grad 4.31 | tok/s 63015
step    410 | loss 1.5124 | lr 3.00e-04 | grad 4.00 | tok/s 60394
step    420 | loss 1.6521 | lr 3.00e-04 | grad 2.00 | tok/s 60437
step    430 | loss 1.7804 | lr 3.00e-04 | grad 2.80 | tok/s 60485
step    440 | loss 1.7830 | lr 3.00e-04 | grad 1.70 | tok/s 62892
step    450 | loss 1.6844 | lr 3.00e-04 | grad 2.12 | tok/s 61176
step    460 | loss 1.6715 | lr 3.00e-04 | grad 1.71 | tok/s 61384
step    470 | loss 1.6418 | lr 3.00e-04 | grad 2.23 | tok/s 62078
step    480 | loss 1.5668 | lr 3.00e-04 | grad 1.77 | tok/s 59392
step    490 | loss 1.5657 | lr 3.00e-04 | grad 1.62 | tok/s 61276
step    500 | loss 2.0905 | lr 3.00e-04 | grad 2.66 | tok/s 63035
step    510 | loss 1.5178 | lr 3.00e-04 | grad 1.55 | tok/s 61589
step    520 | loss 1.4978 | lr 3.00e-04 | grad 1.80 | tok/s 63600
step    530 | loss 2.0659 | lr 3.00e-04 | grad 1.81 | tok/s 62160
step    540 | loss 1.5070 | lr 3.00e-04 | grad 2.47 | tok/s 62329
step    550 | loss 1.4460 | lr 3.00e-04 | grad 1.75 | tok/s 63740
step    560 | loss 1.3544 | lr 3.00e-04 | grad 2.11 | tok/s 64533
step    570 | loss 1.5743 | lr 3.00e-04 | grad 3.59 | tok/s 62510
step    580 | loss 1.8053 | lr 3.00e-04 | grad 1.88 | tok/s 61611
step    590 | loss 2.0033 | lr 3.00e-04 | grad 2.16 | tok/s 61145
step    600 | loss 1.5881 | lr 3.00e-04 | grad 3.08 | tok/s 61120
step    610 | loss 1.5432 | lr 3.00e-04 | grad 1.77 | tok/s 64283
step    620 | loss 1.5522 | lr 3.00e-04 | grad 1.84 | tok/s 61036
step    630 | loss 1.4694 | lr 3.00e-04 | grad 1.90 | tok/s 62921
step    640 | loss 1.6924 | lr 3.00e-04 | grad 2.02 | tok/s 62077
step    650 | loss 1.5440 | lr 3.00e-04 | grad 2.38 | tok/s 61665
step    660 | loss 1.7486 | lr 3.00e-04 | grad 6.28 | tok/s 60653
step    670 | loss 1.6898 | lr 3.00e-04 | grad 2.83 | tok/s 63184
step    680 | loss 1.6403 | lr 3.00e-04 | grad 2.47 | tok/s 60696
step    690 | loss 1.6466 | lr 3.00e-04 | grad 2.70 | tok/s 61141
step    700 | loss 1.7326 | lr 3.00e-04 | grad 3.14 | tok/s 61712
step    710 | loss 1.6195 | lr 3.00e-04 | grad 2.17 | tok/s 62190
step    720 | loss 1.5809 | lr 3.00e-04 | grad 7.44 | tok/s 61846
step    730 | loss 1.7499 | lr 3.00e-04 | grad 2.70 | tok/s 62370
step    740 | loss 1.6905 | lr 3.00e-04 | grad 3.95 | tok/s 61507
step    750 | loss 1.4904 | lr 3.00e-04 | grad 2.48 | tok/s 61387
step    760 | loss 1.8071 | lr 3.00e-04 | grad 1.77 | tok/s 62285
step    770 | loss 1.5099 | lr 3.00e-04 | grad 2.47 | tok/s 61689
step    780 | loss 1.5981 | lr 3.00e-04 | grad 1.54 | tok/s 62451
step    790 | loss 1.4804 | lr 3.00e-04 | grad 1.66 | tok/s 63235
step    800 | loss 1.4508 | lr 3.00e-04 | grad 2.06 | tok/s 62985
step    810 | loss 1.5090 | lr 3.00e-04 | grad 4.31 | tok/s 62426
step    820 | loss 2.1946 | lr 3.00e-04 | grad 3.16 | tok/s 63918
step    830 | loss 1.8700 | lr 3.00e-04 | grad 2.69 | tok/s 64783
step    840 | loss 1.6460 | lr 3.00e-04 | grad 2.33 | tok/s 65308
step    850 | loss 1.6756 | lr 3.00e-04 | grad 2.11 | tok/s 62160
step    860 | loss 1.5277 | lr 3.00e-04 | grad 1.73 | tok/s 60420
step    870 | loss 1.4962 | lr 3.00e-04 | grad 2.06 | tok/s 62606
step    880 | loss 1.5689 | lr 3.00e-04 | grad 2.25 | tok/s 61960
step    890 | loss 1.4679 | lr 3.00e-04 | grad 1.86 | tok/s 62360
step    900 | loss 1.8499 | lr 3.00e-04 | grad 1.90 | tok/s 60805
step    910 | loss 1.4673 | lr 3.00e-04 | grad 1.81 | tok/s 61619
step    920 | loss 1.5536 | lr 3.00e-04 | grad 1.92 | tok/s 61259
step    930 | loss 1.6113 | lr 3.00e-04 | grad 2.81 | tok/s 61091
step    940 | loss 1.5454 | lr 3.00e-04 | grad 3.81 | tok/s 61129
step    950 | loss 1.6118 | lr 3.00e-04 | grad 2.55 | tok/s 61889
step    960 | loss 1.4026 | lr 3.00e-04 | grad 1.82 | tok/s 65089
step    970 | loss 1.3264 | lr 3.00e-04 | grad 1.92 | tok/s 64936
step    980 | loss 1.4339 | lr 3.00e-04 | grad 3.23 | tok/s 63169
step    990 | loss 1.6316 | lr 3.00e-04 | grad 1.59 | tok/s 61588
step   1000 | loss 1.5941 | lr 3.00e-04 | grad 1.48 | tok/s 60442
  >>> saved checkpoint: checkpoint_step_001000_loss_1.5941.pt
step   1010 | loss 1.6860 | lr 3.00e-04 | grad 1.59 | tok/s 47230
step   1020 | loss 1.3966 | lr 3.00e-04 | grad 1.79 | tok/s 62010
step   1030 | loss 1.7250 | lr 3.00e-04 | grad 1.88 | tok/s 60967
step   1040 | loss 1.5042 | lr 3.00e-04 | grad 2.38 | tok/s 61979
step   1050 | loss 1.5104 | lr 3.00e-04 | grad 1.80 | tok/s 62033
step   1060 | loss 1.5886 | lr 3.00e-04 | grad 4.28 | tok/s 62421
step   1070 | loss 1.6986 | lr 3.00e-04 | grad 2.09 | tok/s 62752
step   1080 | loss 2.0735 | lr 3.00e-04 | grad 2.53 | tok/s 61823
step   1090 | loss 1.8292 | lr 3.00e-04 | grad 2.58 | tok/s 62095
step   1100 | loss 1.5798 | lr 3.00e-04 | grad 2.19 | tok/s 61995
step   1110 | loss 1.4790 | lr 3.00e-04 | grad 2.22 | tok/s 62374
step   1120 | loss 1.5564 | lr 3.00e-04 | grad 1.82 | tok/s 63855
step   1130 | loss 1.6251 | lr 3.00e-04 | grad 1.90 | tok/s 60204
step   1140 | loss 1.4753 | lr 3.00e-04 | grad 1.97 | tok/s 62170
step   1150 | loss 1.7713 | lr 3.00e-04 | grad 2.92 | tok/s 61587
step   1160 | loss 1.4545 | lr 3.00e-04 | grad 1.55 | tok/s 60709
step   1170 | loss 1.6308 | lr 3.00e-04 | grad 1.95 | tok/s 62390
step   1180 | loss 1.5139 | lr 3.00e-04 | grad 2.17 | tok/s 65257
step   1190 | loss 1.4130 | lr 3.00e-04 | grad 1.70 | tok/s 64724
step   1200 | loss 1.3488 | lr 3.00e-04 | grad 1.77 | tok/s 64833
step   1210 | loss 1.3351 | lr 3.00e-04 | grad 1.94 | tok/s 64746
step   1220 | loss 1.3520 | lr 3.00e-04 | grad 1.99 | tok/s 64812
step   1230 | loss 1.4074 | lr 3.00e-04 | grad 1.70 | tok/s 61773
step   1240 | loss 1.5093 | lr 3.00e-04 | grad 1.90 | tok/s 61071
step   1250 | loss 1.6010 | lr 3.00e-04 | grad 8.56 | tok/s 63030
step   1260 | loss 1.6236 | lr 3.00e-04 | grad 4.66 | tok/s 62385
step   1270 | loss 1.6865 | lr 3.00e-04 | grad 2.72 | tok/s 62402
step   1280 | loss 1.5526 | lr 3.00e-04 | grad 2.19 | tok/s 61928
step   1290 | loss 1.5168 | lr 3.00e-04 | grad 1.77 | tok/s 61088
step   1300 | loss 1.5850 | lr 3.00e-04 | grad 1.89 | tok/s 61011
step   1310 | loss 1.6241 | lr 3.00e-04 | grad 1.77 | tok/s 60934
step   1320 | loss 1.6024 | lr 3.00e-04 | grad 2.42 | tok/s 61921
step   1330 | loss 1.4895 | lr 3.00e-04 | grad 1.92 | tok/s 62066
step   1340 | loss 1.4244 | lr 3.00e-04 | grad 1.70 | tok/s 61934
step   1350 | loss 1.4258 | lr 3.00e-04 | grad 2.62 | tok/s 63729
step   1360 | loss 1.4483 | lr 3.00e-04 | grad 1.80 | tok/s 60699
step   1370 | loss 1.5488 | lr 3.00e-04 | grad 1.68 | tok/s 61555
step   1380 | loss 1.6178 | lr 3.00e-04 | grad 2.22 | tok/s 61796
step   1390 | loss 1.5435 | lr 3.00e-04 | grad 3.38 | tok/s 60135
step   1400 | loss 1.4779 | lr 3.00e-04 | grad 5.84 | tok/s 62940
step   1410 | loss 1.5442 | lr 3.00e-04 | grad 1.88 | tok/s 63276
step   1420 | loss 1.5522 | lr 3.00e-04 | grad 1.73 | tok/s 60500
step   1430 | loss 1.4562 | lr 3.00e-04 | grad 1.91 | tok/s 58656
step   1440 | loss 1.3576 | lr 3.00e-04 | grad 1.44 | tok/s 62180
step   1450 | loss 1.3702 | lr 3.00e-04 | grad 3.45 | tok/s 63055
step   1460 | loss 1.5011 | lr 3.00e-04 | grad 1.91 | tok/s 37845
step   1470 | loss 1.5646 | lr 3.00e-04 | grad 3.67 | tok/s 61494
step   1480 | loss 1.4527 | lr 3.00e-04 | grad 5.28 | tok/s 61128
step   1490 | loss 1.5883 | lr 3.00e-04 | grad 4.38 | tok/s 61427
step   1500 | loss 1.7048 | lr 3.00e-04 | grad 4.69 | tok/s 60327
step   1510 | loss 1.5489 | lr 3.00e-04 | grad 2.28 | tok/s 63257
step   1520 | loss 1.5392 | lr 3.00e-04 | grad 1.95 | tok/s 62925
step   1530 | loss 1.5112 | lr 3.00e-04 | grad 1.70 | tok/s 62173
step   1540 | loss 1.4631 | lr 3.00e-04 | grad 1.66 | tok/s 60801
step   1550 | loss 1.4218 | lr 3.00e-04 | grad 5.03 | tok/s 62808
step   1560 | loss 1.9261 | lr 3.00e-04 | grad 2.27 | tok/s 61781
step   1570 | loss 1.4943 | lr 3.00e-04 | grad 1.96 | tok/s 60782
step   1580 | loss 1.5735 | lr 3.00e-04 | grad 2.16 | tok/s 63040
step   1590 | loss 1.4119 | lr 3.00e-04 | grad 1.62 | tok/s 61110
step   1600 | loss 1.5386 | lr 3.00e-04 | grad 1.56 | tok/s 59697
step   1610 | loss 1.3560 | lr 3.00e-04 | grad 1.66 | tok/s 63913
step   1620 | loss 1.5348 | lr 3.00e-04 | grad 1.94 | tok/s 62954
step   1630 | loss 1.5122 | lr 3.00e-04 | grad 1.53 | tok/s 63697
step   1640 | loss 1.4557 | lr 3.00e-04 | grad 1.73 | tok/s 61040
step   1650 | loss 1.5057 | lr 3.00e-04 | grad 3.16 | tok/s 60460
step   1660 | loss 1.5067 | lr 3.00e-04 | grad 1.89 | tok/s 60075
step   1670 | loss 1.4960 | lr 3.00e-04 | grad 2.98 | tok/s 63386
step   1680 | loss 1.8416 | lr 3.00e-04 | grad 1.66 | tok/s 63693
step   1690 | loss 1.4622 | lr 3.00e-04 | grad 2.08 | tok/s 62268
step   1700 | loss 1.5493 | lr 3.00e-04 | grad 1.65 | tok/s 63239
step   1710 | loss 1.5749 | lr 3.00e-04 | grad 2.70 | tok/s 61345
step   1720 | loss 1.4679 | lr 3.00e-04 | grad 1.98 | tok/s 61867
step   1730 | loss 1.6668 | lr 3.00e-04 | grad 2.22 | tok/s 61948
step   1740 | loss 1.4954 | lr 3.00e-04 | grad 1.40 | tok/s 62626
step   1750 | loss 1.4952 | lr 3.00e-04 | grad 1.78 | tok/s 60423
step   1760 | loss 1.6306 | lr 3.00e-04 | grad 1.84 | tok/s 61237
step   1770 | loss 1.5756 | lr 3.00e-04 | grad 1.58 | tok/s 62656
step   1780 | loss 1.5021 | lr 3.00e-04 | grad 2.41 | tok/s 60501
step   1790 | loss 1.6551 | lr 3.00e-04 | grad 1.90 | tok/s 61546
step   1800 | loss 1.4239 | lr 3.00e-04 | grad 1.44 | tok/s 62424
step   1810 | loss 1.5007 | lr 3.00e-04 | grad 1.85 | tok/s 61987
step   1820 | loss 1.3954 | lr 3.00e-04 | grad 1.37 | tok/s 61601
step   1830 | loss 1.4749 | lr 3.00e-04 | grad 1.84 | tok/s 61322
step   1840 | loss 1.4379 | lr 3.00e-04 | grad 1.77 | tok/s 60759
step   1850 | loss 1.6994 | lr 3.00e-04 | grad 2.22 | tok/s 61348
step   1860 | loss 1.4546 | lr 3.00e-04 | grad 1.64 | tok/s 61285
step   1870 | loss 1.4233 | lr 3.00e-04 | grad 2.33 | tok/s 62747
step   1880 | loss 1.4494 | lr 3.00e-04 | grad 1.53 | tok/s 62733
step   1890 | loss 1.5602 | lr 3.00e-04 | grad 1.74 | tok/s 61979
step   1900 | loss 1.4995 | lr 3.00e-04 | grad 1.78 | tok/s 57992
step   1910 | loss 1.6021 | lr 3.00e-04 | grad 3.11 | tok/s 61303
step   1920 | loss 1.3869 | lr 3.00e-04 | grad 1.62 | tok/s 63202
step   1930 | loss 1.4232 | lr 3.00e-04 | grad 1.83 | tok/s 61778
step   1940 | loss 1.4342 | lr 3.00e-04 | grad 2.09 | tok/s 62985
step   1950 | loss 1.5060 | lr 3.00e-04 | grad 1.66 | tok/s 62051
step   1960 | loss 1.6131 | lr 3.00e-04 | grad 3.64 | tok/s 62771
step   1970 | loss 1.3513 | lr 3.00e-04 | grad 2.08 | tok/s 61181
step   1980 | loss 1.5030 | lr 3.00e-04 | grad 3.70 | tok/s 60990
step   1990 | loss 1.5422 | lr 3.00e-04 | grad 2.41 | tok/s 61876
step   2000 | loss 1.4639 | lr 3.00e-04 | grad 2.03 | tok/s 62514
  >>> saved checkpoint: checkpoint_step_002000_loss_1.4639.pt
step   2010 | loss 1.2835 | lr 3.00e-04 | grad 1.49 | tok/s 47632
step   2020 | loss 1.1879 | lr 3.00e-04 | grad 1.39 | tok/s 65001
step   2030 | loss 1.4703 | lr 3.00e-04 | grad 1.55 | tok/s 64294
step   2040 | loss 1.3103 | lr 3.00e-04 | grad 1.81 | tok/s 64606
step   2050 | loss 1.2941 | lr 3.00e-04 | grad 2.11 | tok/s 64099
step   2060 | loss 1.5592 | lr 3.00e-04 | grad 1.64 | tok/s 60795
step   2070 | loss 1.4890 | lr 3.00e-04 | grad 2.05 | tok/s 63856
step   2080 | loss 1.5244 | lr 3.00e-04 | grad 3.66 | tok/s 60161
step   2090 | loss 1.4774 | lr 3.00e-04 | grad 1.71 | tok/s 62814
step   2100 | loss 1.4889 | lr 3.00e-04 | grad 1.95 | tok/s 60967
step   2110 | loss 1.2313 | lr 3.00e-04 | grad 1.52 | tok/s 63185
step   2120 | loss 1.3176 | lr 3.00e-04 | grad 1.85 | tok/s 62423
step   2130 | loss 1.4707 | lr 3.00e-04 | grad 4.78 | tok/s 60803
step   2140 | loss 1.5328 | lr 3.00e-04 | grad 4.69 | tok/s 60865
step   2150 | loss 1.5214 | lr 3.00e-04 | grad 1.53 | tok/s 61897
step   2160 | loss 1.5194 | lr 3.00e-04 | grad 1.57 | tok/s 60844
step   2170 | loss 1.6036 | lr 3.00e-04 | grad 1.91 | tok/s 61501
step   2180 | loss 1.4440 | lr 3.00e-04 | grad 1.73 | tok/s 62923
step   2190 | loss 1.6340 | lr 3.00e-04 | grad 1.77 | tok/s 62750
step   2200 | loss 1.2417 | lr 3.00e-04 | grad 1.34 | tok/s 64361
step   2210 | loss 1.2601 | lr 3.00e-04 | grad 1.58 | tok/s 64547
step   2220 | loss 1.2384 | lr 3.00e-04 | grad 1.58 | tok/s 64758
step   2230 | loss 1.4131 | lr 3.00e-04 | grad 1.83 | tok/s 62453
step   2240 | loss 1.5151 | lr 3.00e-04 | grad 3.61 | tok/s 63827
step   2250 | loss 1.4733 | lr 3.00e-04 | grad 2.00 | tok/s 63380
step   2260 | loss 1.5629 | lr 3.00e-04 | grad 2.41 | tok/s 62517
step   2270 | loss 1.4109 | lr 3.00e-04 | grad 2.44 | tok/s 61239
step   2280 | loss 1.5822 | lr 3.00e-04 | grad 1.49 | tok/s 61114
step   2290 | loss 1.4353 | lr 3.00e-04 | grad 1.91 | tok/s 61833
step   2300 | loss 1.4403 | lr 3.00e-04 | grad 1.59 | tok/s 59998
step   2310 | loss 1.4642 | lr 3.00e-04 | grad 1.73 | tok/s 63810
step   2320 | loss 1.4263 | lr 3.00e-04 | grad 1.80 | tok/s 64829
step   2330 | loss 1.3607 | lr 3.00e-04 | grad 1.49 | tok/s 64329
step   2340 | loss 1.4226 | lr 3.00e-04 | grad 1.96 | tok/s 63147

Training complete! Final step: 2341
