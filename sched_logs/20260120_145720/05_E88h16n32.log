# Job 5: E88h16n32
# GPU: 5
# Command: python train.py --level E88h16n32 --dim 512 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/e88_100m_v2/E88h16n32
# Started: 2026-01-20T14:57:20.095530
============================================================

Using device: cuda
Output directory: benchmark_results/e88_100m_v2/E88h16n32/levelE88h16n32_100m_20260120_145725
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88h16n32, 42,414,464 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
Traceback (most recent call last):
  File "/home/erikg/elman/train.py", line 555, in <module>
    train(args)
  File "/home/erikg/elman/train.py", line 470, in train
    result = model(
             ^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/elman/elman/models/ladder_lm.py", line 623, in forward
    x, h_final = layer(x, prev_hiddens[i])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/elman/elman/models/e88_fla_hybrid.py", line 591, in forward
    S_final, output_cuda = E88FLAHybridCUDAFunction.apply(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/erikg/elman/elman/models/e88_fla_hybrid.py", line 159, in forward
    results = hasty_pytorch_lib.e88_fla_hybrid_forward(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: E88 FLA Hybrid Forward only supports bfloat16, got Float
