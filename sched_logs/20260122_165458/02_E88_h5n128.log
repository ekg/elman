# Job 2: E88_h5n128
# GPU: 2
# Command: python train.py --level E88_h5n128 --dim 6144 --depth 32 --data data/pile.txt --batch_size 8 --grad_accum 4 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/500m_state_v2/E88_h5n128
# Started: 2026-01-22T16:54:58.401149
============================================================

Using device: cuda
Output directory: benchmark_results/500m_state_v2/E88_h5n128/levelE88_h5n128_100m_20260122_165504
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E88_h5n128, 506,079,552 parameters
Using schedule-free AdamW (lr=0.0003)

Starting training from step 0...
Batch size: 8, Chunk size: 512
Gradient accumulation: 4, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 47.3020 | lr 3.00e-04 | grad 56.75 | tok/s 1835
step     20 | loss 34.7972 | lr 3.00e-04 | grad 20.88 | tok/s 1940
step     30 | loss 20.0250 | lr 3.00e-04 | grad 7.44 | tok/s 2055
step     40 | loss 12.8818 | lr 3.00e-04 | grad 7.69 | tok/s 2054
step     50 | loss 10.3761 | lr 3.00e-04 | grad 6.16 | tok/s 2054
step     60 | loss 12.2186 | lr 3.00e-04 | grad 8.25 | tok/s 2013
step     70 | loss 11.4699 | lr 3.00e-04 | grad 4.78 | tok/s 1945

Training complete! Final step: 74
