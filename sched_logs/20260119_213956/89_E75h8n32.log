# Job 89: E75h8n32
# GPU: 1
# Command: python train.py --level E75h8n32 --dim 1024 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/E75h8n32
# Started: 2026-01-19T23:21:27.084433
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/E75h8n32/levelE75h8n32_100m_20260119_232132
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h8n32, 89,417,728 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.7325 | lr 2.70e-05 | grad 144.00 | tok/s 22591
step     20 | loss 5.4925 | lr 5.70e-05 | grad 46.00 | tok/s 66423
step     30 | loss 5.3418 | lr 8.70e-05 | grad 29.25 | tok/s 70385
step     40 | loss 4.7484 | lr 1.17e-04 | grad 11.38 | tok/s 70120
step     50 | loss 4.0851 | lr 1.47e-04 | grad 6.78 | tok/s 70079
step     60 | loss 3.8580 | lr 1.77e-04 | grad 13.00 | tok/s 68603
step     70 | loss 3.3070 | lr 2.07e-04 | grad 6.75 | tok/s 66239
step     80 | loss 3.4374 | lr 2.37e-04 | grad 5.22 | tok/s 68845
step     90 | loss 3.2077 | lr 2.67e-04 | grad 3.92 | tok/s 66435
step    100 | loss 2.8303 | lr 2.97e-04 | grad 2.53 | tok/s 66968
step    110 | loss 2.7836 | lr 6.94e-06 | grad 2.14 | tok/s 61607
step    120 | loss 3.0322 | lr 2.69e-05 | grad 2.33 | tok/s 61523
step    130 | loss 2.8572 | lr 5.89e-05 | grad 1.15 | tok/s 62551
step    140 | loss 2.6220 | lr 9.99e-05 | grad 1.25 | tok/s 62245
step    150 | loss 2.5012 | lr 1.46e-04 | grad 2.45 | tok/s 59350
step    160 | loss 2.3716 | lr 1.92e-04 | grad 1.54 | tok/s 60229
step    170 | loss 2.5458 | lr 2.35e-04 | grad 3.47 | tok/s 62093
step    180 | loss 2.5933 | lr 2.69e-04 | grad 1.32 | tok/s 62125
step    190 | loss 2.3090 | lr 2.91e-04 | grad 1.52 | tok/s 63150
step    200 | loss 2.0042 | lr 3.00e-04 | grad 1.33 | tok/s 64502
step    210 | loss 2.4698 | lr 2.94e-04 | grad 2.05 | tok/s 61743
step    220 | loss 2.3629 | lr 2.74e-04 | grad 1.03 | tok/s 63667
step    230 | loss 2.2010 | lr 2.42e-04 | grad 1.66 | tok/s 61542
step    240 | loss 2.2167 | lr 2.01e-04 | grad 1.73 | tok/s 62762
step    250 | loss 2.1828 | lr 1.55e-04 | grad 1.19 | tok/s 61747
step    260 | loss 2.1820 | lr 1.09e-04 | grad 0.72 | tok/s 59479
step    270 | loss 2.0472 | lr 6.65e-05 | grad 1.23 | tok/s 61650
step    280 | loss 1.9720 | lr 3.24e-05 | grad 1.55 | tok/s 61591
step    290 | loss 1.9537 | lr 9.84e-06 | grad 0.86 | tok/s 64756
step    300 | loss 1.9249 | lr 1.07e-06 | grad 0.82 | tok/s 64804
step    310 | loss 1.9305 | lr 6.94e-06 | grad 0.75 | tok/s 64718
step    320 | loss 2.0190 | lr 2.69e-05 | grad 2.17 | tok/s 62359
step    330 | loss 2.0591 | lr 5.89e-05 | grad 0.67 | tok/s 60796
step    340 | loss 2.0699 | lr 9.99e-05 | grad 1.73 | tok/s 62011
step    350 | loss 2.0886 | lr 1.46e-04 | grad 0.99 | tok/s 60237
step    360 | loss 2.0482 | lr 1.92e-04 | grad 2.42 | tok/s 60943
step    370 | loss 1.8916 | lr 2.35e-04 | grad 1.13 | tok/s 62122
step    380 | loss 2.4351 | lr 2.69e-04 | grad 1.25 | tok/s 63644
step    390 | loss 2.0343 | lr 2.91e-04 | grad 1.33 | tok/s 61252
step    400 | loss 2.1386 | lr 3.00e-04 | grad 3.23 | tok/s 62809
step    410 | loss 1.8882 | lr 2.94e-04 | grad 1.85 | tok/s 61039
step    420 | loss 2.0025 | lr 2.74e-04 | grad 1.07 | tok/s 60523
step    430 | loss 2.1528 | lr 2.42e-04 | grad 1.20 | tok/s 60258
step    440 | loss 2.2277 | lr 2.01e-04 | grad 1.05 | tok/s 62660
step    450 | loss 1.9373 | lr 1.55e-04 | grad 0.81 | tok/s 60894
step    460 | loss 1.9127 | lr 1.09e-04 | grad 0.63 | tok/s 61175
step    470 | loss 1.8906 | lr 6.65e-05 | grad 0.93 | tok/s 61889
step    480 | loss 1.7940 | lr 3.24e-05 | grad 0.57 | tok/s 59661
step    490 | loss 1.7556 | lr 9.84e-06 | grad 0.50 | tok/s 60850
step    500 | loss 2.7427 | lr 1.07e-06 | grad 0.91 | tok/s 62595
step    510 | loss 1.7982 | lr 6.94e-06 | grad 0.62 | tok/s 61287
step    520 | loss 1.8656 | lr 2.69e-05 | grad 0.51 | tok/s 63134
step    530 | loss 2.3243 | lr 5.89e-05 | grad 0.53 | tok/s 61864
step    540 | loss 1.7935 | lr 9.99e-05 | grad 1.01 | tok/s 61743
step    550 | loss 1.6677 | lr 1.46e-04 | grad 0.67 | tok/s 63496
step    560 | loss 1.5324 | lr 1.92e-04 | grad 0.68 | tok/s 64242
step    570 | loss 1.8354 | lr 2.35e-04 | grad 1.85 | tok/s 62815
step    580 | loss 2.1700 | lr 2.69e-04 | grad 1.02 | tok/s 62071
step    590 | loss 2.4731 | lr 2.91e-04 | grad 1.25 | tok/s 60717
step    600 | loss 1.9524 | lr 3.00e-04 | grad 1.39 | tok/s 60888
step    610 | loss 1.9779 | lr 2.94e-04 | grad 1.03 | tok/s 63824
step    620 | loss 1.8595 | lr 2.74e-04 | grad 0.95 | tok/s 60563
step    630 | loss 1.7789 | lr 2.42e-04 | grad 0.85 | tok/s 62480
step    640 | loss 2.1486 | lr 2.01e-04 | grad 0.84 | tok/s 62555
step    650 | loss 1.7806 | lr 1.55e-04 | grad 1.04 | tok/s 61336
step    660 | loss 2.1052 | lr 1.09e-04 | grad 4.09 | tok/s 60548
step    670 | loss 1.9317 | lr 6.65e-05 | grad 1.51 | tok/s 62626
step    680 | loss 1.8901 | lr 3.24e-05 | grad 1.02 | tok/s 60467
step    690 | loss 1.8860 | lr 9.84e-06 | grad 1.06 | tok/s 61390
step    700 | loss 1.9642 | lr 1.07e-06 | grad 1.14 | tok/s 61681
step    710 | loss 1.9009 | lr 6.94e-06 | grad 0.95 | tok/s 62006
step    720 | loss 2.0229 | lr 2.68e-05 | grad 1.44 | tok/s 61766
step    730 | loss 1.9648 | lr 5.89e-05 | grad 1.02 | tok/s 62333
step    740 | loss 1.8947 | lr 9.99e-05 | grad 1.65 | tok/s 61821
step    750 | loss 1.7017 | lr 1.46e-04 | grad 1.21 | tok/s 61127
step    760 | loss 2.1216 | lr 1.92e-04 | grad 0.64 | tok/s 61881
step    770 | loss 1.7586 | lr 2.35e-04 | grad 1.03 | tok/s 61493
step    780 | loss 1.8064 | lr 2.69e-04 | grad 1.02 | tok/s 62081
step    790 | loss 1.7529 | lr 2.91e-04 | grad 0.76 | tok/s 62676
step    800 | loss 1.7114 | lr 3.00e-04 | grad 0.91 | tok/s 62700
step    810 | loss 1.8392 | lr 2.94e-04 | grad 1.78 | tok/s 62021
step    820 | loss 2.5050 | lr 2.74e-04 | grad 1.41 | tok/s 63306
step    830 | loss 1.9993 | lr 2.42e-04 | grad 11.50 | tok/s 64280
step    840 | loss 1.7058 | lr 2.01e-04 | grad 0.48 | tok/s 64308
step    850 | loss 2.1948 | lr 1.55e-04 | grad 1.12 | tok/s 61232
step    860 | loss 1.9041 | lr 1.09e-04 | grad 0.89 | tok/s 59968
step    870 | loss 1.7953 | lr 6.65e-05 | grad 0.70 | tok/s 61761
step    880 | loss 1.8667 | lr 3.24e-05 | grad 1.02 | tok/s 61408
step    890 | loss 1.7644 | lr 9.84e-06 | grad 0.73 | tok/s 61396
step    900 | loss 2.2390 | lr 1.07e-06 | grad 0.74 | tok/s 59862
step    910 | loss 1.8155 | lr 6.94e-06 | grad 0.60 | tok/s 60886
step    920 | loss 1.7954 | lr 2.68e-05 | grad 0.62 | tok/s 60904
step    930 | loss 1.9130 | lr 5.89e-05 | grad 1.20 | tok/s 60554
step    940 | loss 1.7990 | lr 9.99e-05 | grad 1.27 | tok/s 59995
step    950 | loss 1.8678 | lr 1.46e-04 | grad 1.03 | tok/s 61431
step    960 | loss 1.6110 | lr 1.92e-04 | grad 0.50 | tok/s 64288
step    970 | loss 1.4240 | lr 2.35e-04 | grad 0.43 | tok/s 64271
step    980 | loss 1.5933 | lr 2.69e-04 | grad 1.48 | tok/s 62592
step    990 | loss 1.9318 | lr 2.91e-04 | grad 0.75 | tok/s 60790
step   1000 | loss 1.8031 | lr 3.00e-04 | grad 0.59 | tok/s 59466
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8031.pt
step   1010 | loss 2.0700 | lr 2.94e-04 | grad 2.17 | tok/s 49232
step   1020 | loss 1.6800 | lr 2.74e-04 | grad 0.75 | tok/s 61048
step   1030 | loss 2.0650 | lr 2.42e-04 | grad 0.75 | tok/s 59986
step   1040 | loss 1.6932 | lr 2.01e-04 | grad 1.11 | tok/s 61277
step   1050 | loss 1.7204 | lr 1.55e-04 | grad 0.64 | tok/s 61453
step   1060 | loss 1.9550 | lr 1.09e-04 | grad 1.30 | tok/s 61674
step   1070 | loss 2.0229 | lr 6.65e-05 | grad 0.66 | tok/s 61706
step   1080 | loss 2.3794 | lr 3.24e-05 | grad 0.90 | tok/s 61040
step   1090 | loss 2.0630 | lr 9.84e-06 | grad 0.70 | tok/s 61484
step   1100 | loss 1.7224 | lr 1.07e-06 | grad 0.63 | tok/s 61162
step   1110 | loss 1.7653 | lr 6.93e-06 | grad 0.64 | tok/s 62084
step   1120 | loss 1.9753 | lr 2.68e-05 | grad 0.76 | tok/s 62839
step   1130 | loss 1.7302 | lr 5.89e-05 | grad 0.57 | tok/s 59725
step   1140 | loss 1.6077 | lr 9.99e-05 | grad 0.61 | tok/s 61145
step   1150 | loss 1.9002 | lr 1.46e-04 | grad 0.91 | tok/s 61102
step   1160 | loss 1.5732 | lr 1.92e-04 | grad 0.49 | tok/s 60546
step   1170 | loss 1.9028 | lr 2.35e-04 | grad 0.64 | tok/s 61344
step   1180 | loss 1.6080 | lr 2.69e-04 | grad 0.61 | tok/s 64226
step   1190 | loss 1.4609 | lr 2.91e-04 | grad 0.57 | tok/s 64219
step   1200 | loss 1.3749 | lr 3.00e-04 | grad 0.59 | tok/s 64297
step   1210 | loss 1.3426 | lr 2.94e-04 | grad 0.61 | tok/s 64419
step   1220 | loss 1.3914 | lr 2.74e-04 | grad 0.71 | tok/s 63791
step   1230 | loss 1.6315 | lr 2.42e-04 | grad 0.85 | tok/s 61499
step   1240 | loss 1.6822 | lr 2.01e-04 | grad 0.70 | tok/s 60389
step   1250 | loss 1.7772 | lr 1.55e-04 | grad 2.52 | tok/s 62285
step   1260 | loss 1.8154 | lr 1.09e-04 | grad 2.08 | tok/s 62283
step   1270 | loss 1.8753 | lr 6.65e-05 | grad 1.09 | tok/s 61400
step   1280 | loss 1.7237 | lr 3.24e-05 | grad 0.71 | tok/s 60820
step   1290 | loss 1.6551 | lr 9.84e-06 | grad 0.73 | tok/s 60529
step   1300 | loss 1.7074 | lr 1.07e-06 | grad 0.66 | tok/s 60235
step   1310 | loss 1.7814 | lr 6.93e-06 | grad 0.67 | tok/s 60215
step   1320 | loss 1.7754 | lr 2.68e-05 | grad 0.96 | tok/s 61240
step   1330 | loss 1.6952 | lr 5.89e-05 | grad 0.51 | tok/s 61301
step   1340 | loss 1.6035 | lr 9.99e-05 | grad 0.77 | tok/s 61339
step   1350 | loss 1.6690 | lr 1.46e-04 | grad 1.39 | tok/s 62930
step   1360 | loss 1.5891 | lr 1.92e-04 | grad 0.59 | tok/s 59848
step   1370 | loss 1.6984 | lr 2.35e-04 | grad 0.62 | tok/s 60651
step   1380 | loss 1.8029 | lr 2.69e-04 | grad 0.81 | tok/s 61242
step   1390 | loss 1.6987 | lr 2.91e-04 | grad 1.22 | tok/s 59719
step   1400 | loss 1.7121 | lr 3.00e-04 | grad 4.25 | tok/s 62169
step   1410 | loss 1.7383 | lr 2.94e-04 | grad 0.96 | tok/s 62737
step   1420 | loss 1.8140 | lr 2.74e-04 | grad 0.79 | tok/s 59731
step   1430 | loss 1.5808 | lr 2.42e-04 | grad 0.63 | tok/s 58308
step   1440 | loss 1.5040 | lr 2.01e-04 | grad 0.59 | tok/s 61500
step   1450 | loss 1.5509 | lr 1.55e-04 | grad 1.59 | tok/s 62738
step   1460 | loss 1.6141 | lr 1.09e-04 | grad 0.50 | tok/s 58673
step   1470 | loss 1.7143 | lr 6.65e-05 | grad 1.58 | tok/s 60732
step   1480 | loss 1.5734 | lr 3.24e-05 | grad 1.33 | tok/s 61433
step   1490 | loss 1.7484 | lr 9.84e-06 | grad 1.91 | tok/s 61296
step   1500 | loss 1.8456 | lr 1.07e-06 | grad 1.76 | tok/s 59714
step   1510 | loss 1.7267 | lr 6.93e-06 | grad 0.88 | tok/s 62733
step   1520 | loss 1.6934 | lr 2.68e-05 | grad 0.98 | tok/s 62184
step   1530 | loss 1.6378 | lr 5.89e-05 | grad 0.49 | tok/s 61756
step   1540 | loss 1.6198 | lr 9.99e-05 | grad 0.47 | tok/s 60578
step   1550 | loss 1.5936 | lr 1.46e-04 | grad 1.90 | tok/s 62905
step   1560 | loss 2.1725 | lr 1.92e-04 | grad 0.96 | tok/s 61460
step   1570 | loss 1.6310 | lr 2.35e-04 | grad 1.01 | tok/s 60158
step   1580 | loss 1.8065 | lr 2.69e-04 | grad 0.88 | tok/s 62237
step   1590 | loss 1.5817 | lr 2.91e-04 | grad 0.66 | tok/s 60681
step   1600 | loss 1.6893 | lr 3.00e-04 | grad 0.76 | tok/s 59560
step   1610 | loss 1.5323 | lr 2.94e-04 | grad 0.64 | tok/s 63063
step   1620 | loss 1.6870 | lr 2.74e-04 | grad 0.57 | tok/s 62129
step   1630 | loss 1.7107 | lr 2.42e-04 | grad 0.73 | tok/s 62623
step   1640 | loss 1.6078 | lr 2.01e-04 | grad 0.58 | tok/s 60467
step   1650 | loss 1.6221 | lr 1.55e-04 | grad 1.04 | tok/s 59552
step   1660 | loss 1.6170 | lr 1.09e-04 | grad 0.56 | tok/s 59936
step   1670 | loss 1.6764 | lr 6.65e-05 | grad 1.69 | tok/s 62529
step   1680 | loss 2.0478 | lr 3.24e-05 | grad 0.45 | tok/s 62517
step   1690 | loss 1.5985 | lr 9.84e-06 | grad 0.74 | tok/s 61086
step   1700 | loss 2.0172 | lr 1.07e-06 | grad 0.46 | tok/s 62372
step   1710 | loss 1.6433 | lr 6.93e-06 | grad 0.73 | tok/s 60571
step   1720 | loss 1.6547 | lr 2.68e-05 | grad 0.67 | tok/s 60812
step   1730 | loss 1.7527 | lr 5.89e-05 | grad 0.68 | tok/s 60799
step   1740 | loss 1.6610 | lr 9.99e-05 | grad 0.55 | tok/s 61733
step   1750 | loss 1.5579 | lr 1.46e-04 | grad 0.45 | tok/s 59580
step   1760 | loss 1.8364 | lr 1.92e-04 | grad 0.55 | tok/s 60395
step   1770 | loss 1.7294 | lr 2.35e-04 | grad 0.55 | tok/s 61814
step   1780 | loss 1.6119 | lr 2.69e-04 | grad 0.92 | tok/s 59445
step   1790 | loss 1.8239 | lr 2.91e-04 | grad 0.66 | tok/s 60570
step   1800 | loss 1.5418 | lr 3.00e-04 | grad 0.58 | tok/s 61542
step   1810 | loss 1.6502 | lr 2.94e-04 | grad 0.72 | tok/s 61311
step   1820 | loss 1.6056 | lr 2.74e-04 | grad 0.68 | tok/s 60663
step   1830 | loss 1.6262 | lr 2.42e-04 | grad 0.66 | tok/s 60602
step   1840 | loss 1.5879 | lr 2.01e-04 | grad 0.69 | tok/s 59911
step   1850 | loss 1.8267 | lr 1.55e-04 | grad 0.79 | tok/s 60553
step   1860 | loss 1.5733 | lr 1.09e-04 | grad 0.43 | tok/s 60388
step   1870 | loss 1.6260 | lr 6.65e-05 | grad 1.17 | tok/s 61746
step   1880 | loss 1.5718 | lr 3.24e-05 | grad 0.50 | tok/s 61928
step   1890 | loss 1.6627 | lr 9.84e-06 | grad 0.49 | tok/s 60803
step   1900 | loss 1.7366 | lr 1.07e-06 | grad 1.27 | tok/s 61470
step   1910 | loss 1.6811 | lr 6.93e-06 | grad 0.91 | tok/s 60636
step   1920 | loss 1.5804 | lr 2.68e-05 | grad 0.80 | tok/s 62616
step   1930 | loss 1.5754 | lr 5.89e-05 | grad 0.77 | tok/s 61967
step   1940 | loss 1.4954 | lr 9.99e-05 | grad 0.56 | tok/s 63268
step   1950 | loss 1.5467 | lr 1.46e-04 | grad 0.68 | tok/s 61531
step   1960 | loss 1.9186 | lr 1.92e-04 | grad 3.72 | tok/s 62847
step   1970 | loss 1.6068 | lr 2.35e-04 | grad 1.26 | tok/s 60697
step   1980 | loss 1.6699 | lr 2.69e-04 | grad 1.65 | tok/s 60656
step   1990 | loss 1.7749 | lr 2.91e-04 | grad 0.88 | tok/s 61996
step   2000 | loss 1.6876 | lr 3.00e-04 | grad 1.05 | tok/s 62524
  >>> saved checkpoint: checkpoint_step_002000_loss_1.6876.pt
step   2010 | loss 1.4415 | lr 2.94e-04 | grad 0.61 | tok/s 50067
step   2020 | loss 1.2706 | lr 2.74e-04 | grad 0.51 | tok/s 64404
step   2030 | loss 1.6016 | lr 2.42e-04 | grad 0.73 | tok/s 63691
step   2040 | loss 1.4129 | lr 2.01e-04 | grad 0.46 | tok/s 64288
step   2050 | loss 1.3675 | lr 1.55e-04 | grad 0.72 | tok/s 63424
step   2060 | loss 1.6768 | lr 1.09e-04 | grad 0.62 | tok/s 60705
step   2070 | loss 1.6210 | lr 6.65e-05 | grad 0.98 | tok/s 63649
step   2080 | loss 1.7679 | lr 3.24e-05 | grad 2.88 | tok/s 60201
step   2090 | loss 1.6988 | lr 9.84e-06 | grad 0.79 | tok/s 62372
step   2100 | loss 1.6295 | lr 1.07e-06 | grad 0.78 | tok/s 60458
step   2110 | loss 1.5102 | lr 6.93e-06 | grad 0.61 | tok/s 62629
step   2120 | loss 1.5151 | lr 2.68e-05 | grad 0.96 | tok/s 62102
step   2130 | loss 1.6177 | lr 5.89e-05 | grad 1.94 | tok/s 60147
step   2140 | loss 1.6597 | lr 9.99e-05 | grad 2.03 | tok/s 60221
step   2150 | loss 1.6724 | lr 1.46e-04 | grad 0.46 | tok/s 61036
step   2160 | loss 1.6306 | lr 1.92e-04 | grad 0.52 | tok/s 60307
step   2170 | loss 1.7244 | lr 2.35e-04 | grad 0.59 | tok/s 61102
step   2180 | loss 1.5894 | lr 2.69e-04 | grad 0.66 | tok/s 62280
step   2190 | loss 1.9089 | lr 2.91e-04 | grad 0.68 | tok/s 62169
step   2200 | loss 1.3574 | lr 3.00e-04 | grad 0.46 | tok/s 64400
step   2210 | loss 1.3242 | lr 2.94e-04 | grad 0.41 | tok/s 64415
step   2220 | loss 1.2775 | lr 2.74e-04 | grad 0.45 | tok/s 64431
step   2230 | loss 1.5452 | lr 2.42e-04 | grad 0.72 | tok/s 62130
step   2240 | loss 1.8080 | lr 2.01e-04 | grad 1.65 | tok/s 63514
step   2250 | loss 1.6894 | lr 1.55e-04 | grad 0.76 | tok/s 63030
step   2260 | loss 1.7655 | lr 1.09e-04 | grad 0.73 | tok/s 62046
step   2270 | loss 1.5579 | lr 6.65e-05 | grad 0.80 | tok/s 60823
step   2280 | loss 1.7131 | lr 3.24e-05 | grad 0.52 | tok/s 60776
step   2290 | loss 1.5392 | lr 9.84e-06 | grad 0.60 | tok/s 61600
step   2300 | loss 1.5504 | lr 1.07e-06 | grad 0.48 | tok/s 59647
step   2310 | loss 1.6381 | lr 6.93e-06 | grad 0.84 | tok/s 63297
step   2320 | loss 1.7165 | lr 2.68e-05 | grad 0.88 | tok/s 64413
step   2330 | loss 1.6595 | lr 5.89e-05 | grad 0.55 | tok/s 64395
step   2340 | loss 1.6030 | lr 9.98e-05 | grad 0.80 | tok/s 62940

Training complete! Final step: 2342
