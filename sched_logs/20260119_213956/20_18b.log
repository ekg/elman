# Job 20: 18b
# GPU: 4
# Command: python train.py --level 18b --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/18b
# Started: 2026-01-19T22:00:16.208487
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/18b/level18b_100m_20260119_220021
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level 18b, 114,890,880 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.2893 | lr 2.70e-05 | grad 14.12 | tok/s 20817
step     20 | loss 4.1126 | lr 5.70e-05 | grad 18.62 | tok/s 47912
step     30 | loss 4.5168 | lr 8.70e-05 | grad 7.66 | tok/s 51562
step     40 | loss 3.3641 | lr 1.17e-04 | grad 4.41 | tok/s 51917
step     50 | loss 2.7042 | lr 1.47e-04 | grad 3.86 | tok/s 52101
step     60 | loss 2.8819 | lr 1.77e-04 | grad 4.88 | tok/s 50989
step     70 | loss 2.5377 | lr 2.07e-04 | grad 3.44 | tok/s 48924
step     80 | loss 2.8329 | lr 2.37e-04 | grad 4.31 | tok/s 51018
step     90 | loss 2.7829 | lr 2.67e-04 | grad 4.94 | tok/s 49146
step    100 | loss 2.3880 | lr 2.97e-04 | grad 1.23 | tok/s 49798
step    110 | loss 2.4301 | lr 6.94e-06 | grad 3.05 | tok/s 46792
step    120 | loss 2.6268 | lr 2.69e-05 | grad 1.48 | tok/s 47049
step    130 | loss 2.4809 | lr 5.89e-05 | grad 1.26 | tok/s 47421
step    140 | loss 2.2575 | lr 9.99e-05 | grad 1.03 | tok/s 48268
step    150 | loss 2.1537 | lr 1.46e-04 | grad 2.28 | tok/s 46135
step    160 | loss 2.0617 | lr 1.92e-04 | grad 1.70 | tok/s 46302
step    170 | loss 2.2465 | lr 2.35e-04 | grad 3.91 | tok/s 47867
step    180 | loss 2.2433 | lr 2.69e-04 | grad 1.46 | tok/s 48295
step    190 | loss 1.9686 | lr 2.91e-04 | grad 1.50 | tok/s 48761
step    200 | loss 1.6144 | lr 3.00e-04 | grad 1.32 | tok/s 50156
step    210 | loss 2.2659 | lr 2.94e-04 | grad 1.70 | tok/s 47780
step    220 | loss 2.1269 | lr 2.74e-04 | grad 1.15 | tok/s 49419
step    230 | loss 1.9717 | lr 2.42e-04 | grad 1.49 | tok/s 47895
step    240 | loss 1.9541 | lr 2.01e-04 | grad 1.77 | tok/s 48722
step    250 | loss 1.9497 | lr 1.55e-04 | grad 1.20 | tok/s 48062
step    260 | loss 2.0230 | lr 1.09e-04 | grad 0.79 | tok/s 45995
step    270 | loss 1.8636 | lr 6.65e-05 | grad 0.94 | tok/s 47799
step    280 | loss 1.7557 | lr 3.24e-05 | grad 1.47 | tok/s 47706
step    290 | loss 1.7530 | lr 9.84e-06 | grad 0.86 | tok/s 50265
step    300 | loss 1.7201 | lr 1.07e-06 | grad 0.86 | tok/s 50304
step    310 | loss 1.7162 | lr 6.94e-06 | grad 0.77 | tok/s 50296
step    320 | loss 1.8185 | lr 2.69e-05 | grad 1.57 | tok/s 48481
step    330 | loss 1.8388 | lr 5.89e-05 | grad 0.84 | tok/s 47045
step    340 | loss 1.8532 | lr 9.99e-05 | grad 2.28 | tok/s 47998
step    350 | loss 1.8558 | lr 1.46e-04 | grad 1.02 | tok/s 46944
step    360 | loss 1.8267 | lr 1.92e-04 | grad 2.25 | tok/s 47531
step    370 | loss 1.6682 | lr 2.35e-04 | grad 1.09 | tok/s 48300
step    380 | loss 2.1575 | lr 2.69e-04 | grad 1.26 | tok/s 49465
step    390 | loss 1.8376 | lr 2.91e-04 | grad 1.31 | tok/s 47596
step    400 | loss 1.9350 | lr 3.00e-04 | grad 2.67 | tok/s 48852
step    410 | loss 1.6955 | lr 2.94e-04 | grad 2.30 | tok/s 47505
step    420 | loss 1.8263 | lr 2.74e-04 | grad 1.27 | tok/s 47152
step    430 | loss 1.9893 | lr 2.42e-04 | grad 1.34 | tok/s 47049
step    440 | loss 1.9641 | lr 2.01e-04 | grad 0.95 | tok/s 48802
step    450 | loss 1.7863 | lr 1.55e-04 | grad 0.75 | tok/s 47662
step    460 | loss 1.7525 | lr 1.09e-04 | grad 0.76 | tok/s 47955
step    470 | loss 1.7332 | lr 6.65e-05 | grad 1.07 | tok/s 48952
step    480 | loss 1.6279 | lr 3.24e-05 | grad 0.65 | tok/s 47129
step    490 | loss 1.6111 | lr 9.84e-06 | grad 0.64 | tok/s 48201
step    500 | loss 2.5552 | lr 1.07e-06 | grad 1.01 | tok/s 49362
step    510 | loss 1.6387 | lr 6.94e-06 | grad 0.73 | tok/s 48406
step    520 | loss 1.6992 | lr 2.69e-05 | grad 0.62 | tok/s 49907
step    530 | loss 2.2020 | lr 5.89e-05 | grad 0.68 | tok/s 48951
step    540 | loss 1.6224 | lr 9.99e-05 | grad 0.98 | tok/s 48662
step    550 | loss 1.5252 | lr 1.46e-04 | grad 0.69 | tok/s 50212
step    560 | loss 1.3899 | lr 1.92e-04 | grad 0.74 | tok/s 50772
step    570 | loss 1.6701 | lr 2.35e-04 | grad 2.09 | tok/s 49837
step    580 | loss 1.9828 | lr 2.69e-04 | grad 1.00 | tok/s 49166
step    590 | loss 2.3115 | lr 2.91e-04 | grad 1.20 | tok/s 48038
step    600 | loss 1.7660 | lr 3.00e-04 | grad 1.50 | tok/s 48245
step    610 | loss 1.7434 | lr 2.94e-04 | grad 1.26 | tok/s 50653
step    620 | loss 1.7215 | lr 2.74e-04 | grad 0.88 | tok/s 47870
step    630 | loss 1.6109 | lr 2.42e-04 | grad 0.91 | tok/s 49436
step    640 | loss 1.9078 | lr 2.01e-04 | grad 0.98 | tok/s 49512
step    650 | loss 1.6581 | lr 1.55e-04 | grad 1.20 | tok/s 48452
step    660 | loss 1.9674 | lr 1.09e-04 | grad 5.56 | tok/s 48002
step    670 | loss 1.7885 | lr 6.65e-05 | grad 1.72 | tok/s 49612
step    680 | loss 1.7338 | lr 3.24e-05 | grad 1.06 | tok/s 47907
step    690 | loss 1.7476 | lr 9.84e-06 | grad 1.53 | tok/s 47939
step    700 | loss 1.8506 | lr 1.07e-06 | grad 1.75 | tok/s 48575
step    710 | loss 1.7640 | lr 6.94e-06 | grad 1.26 | tok/s 48625
step    720 | loss 1.8671 | lr 2.68e-05 | grad 1.52 | tok/s 48511
step    730 | loss 1.8223 | lr 5.89e-05 | grad 1.39 | tok/s 49077
step    740 | loss 1.7670 | lr 9.99e-05 | grad 1.83 | tok/s 48672
step    750 | loss 1.5696 | lr 1.46e-04 | grad 1.58 | tok/s 48092
step    760 | loss 2.0063 | lr 1.92e-04 | grad 0.77 | tok/s 48629
step    770 | loss 1.6241 | lr 2.35e-04 | grad 1.16 | tok/s 48234
step    780 | loss 1.6765 | lr 2.69e-04 | grad 0.88 | tok/s 48769
step    790 | loss 1.5879 | lr 2.91e-04 | grad 0.71 | tok/s 49167
step    800 | loss 1.5780 | lr 3.00e-04 | grad 1.30 | tok/s 49193
step    810 | loss 1.6828 | lr 2.94e-04 | grad 1.75 | tok/s 48441
step    820 | loss 2.3717 | lr 2.74e-04 | grad 1.27 | tok/s 49844
step    830 | loss 1.8126 | lr 2.42e-04 | grad 0.79 | tok/s 50441
step    840 | loss 1.4991 | lr 2.01e-04 | grad 0.79 | tok/s 49438
step    850 | loss 1.9684 | lr 1.55e-04 | grad 1.55 | tok/s 47128
step    860 | loss 1.7143 | lr 1.09e-04 | grad 1.04 | tok/s 46023
step    870 | loss 1.6373 | lr 6.65e-05 | grad 1.01 | tok/s 47872
step    880 | loss 1.7011 | lr 3.24e-05 | grad 1.16 | tok/s 47398
step    890 | loss 1.6221 | lr 9.84e-06 | grad 1.01 | tok/s 47404
step    900 | loss 2.0958 | lr 1.07e-06 | grad 1.04 | tok/s 45960
step    910 | loss 1.6698 | lr 6.94e-06 | grad 0.76 | tok/s 47128
step    920 | loss 1.6579 | lr 2.68e-05 | grad 0.92 | tok/s 46736
step    930 | loss 1.7584 | lr 5.89e-05 | grad 1.77 | tok/s 46978
step    940 | loss 1.6542 | lr 9.99e-05 | grad 1.62 | tok/s 45968
step    950 | loss 1.7287 | lr 1.46e-04 | grad 1.09 | tok/s 47434
step    960 | loss 1.4708 | lr 1.92e-04 | grad 0.64 | tok/s 49774
step    970 | loss 1.3071 | lr 2.35e-04 | grad 0.57 | tok/s 49606
step    980 | loss 1.4765 | lr 2.69e-04 | grad 1.93 | tok/s 48772
step    990 | loss 1.8268 | lr 2.91e-04 | grad 0.92 | tok/s 47168
step   1000 | loss 1.6905 | lr 3.00e-04 | grad 0.74 | tok/s 45970
  >>> saved checkpoint: checkpoint_step_001000_loss_1.6905.pt
step   1010 | loss 1.8786 | lr 2.94e-04 | grad 1.39 | tok/s 40457
step   1020 | loss 1.5419 | lr 2.74e-04 | grad 0.97 | tok/s 47338
step   1030 | loss 1.9614 | lr 2.42e-04 | grad 0.89 | tok/s 46440
step   1040 | loss 1.5951 | lr 2.01e-04 | grad 1.39 | tok/s 46891
step   1050 | loss 1.7113 | lr 1.55e-04 | grad 0.86 | tok/s 46717
step   1060 | loss 1.7686 | lr 1.09e-04 | grad 1.34 | tok/s 47068
step   1070 | loss 1.8827 | lr 6.65e-05 | grad 0.92 | tok/s 47264
step   1080 | loss 2.2928 | lr 3.24e-05 | grad 1.09 | tok/s 46707
step   1090 | loss 1.9738 | lr 9.84e-06 | grad 0.97 | tok/s 47014
step   1100 | loss 1.6537 | lr 1.07e-06 | grad 0.75 | tok/s 46792
step   1110 | loss 1.6478 | lr 6.93e-06 | grad 0.99 | tok/s 47155
step   1120 | loss 1.8406 | lr 2.68e-05 | grad 0.80 | tok/s 48085
step   1130 | loss 1.6477 | lr 5.89e-05 | grad 0.79 | tok/s 45691
step   1140 | loss 1.5171 | lr 9.99e-05 | grad 0.70 | tok/s 46900
step   1150 | loss 1.7966 | lr 1.46e-04 | grad 1.26 | tok/s 46812
step   1160 | loss 1.4836 | lr 1.92e-04 | grad 0.61 | tok/s 46112
step   1170 | loss 1.7732 | lr 2.35e-04 | grad 0.93 | tok/s 46670
step   1180 | loss 1.5181 | lr 2.69e-04 | grad 0.77 | tok/s 49092
step   1190 | loss 1.3693 | lr 2.91e-04 | grad 0.73 | tok/s 49150
step   1200 | loss 1.2903 | lr 3.00e-04 | grad 0.64 | tok/s 50115
step   1210 | loss 1.2651 | lr 2.94e-04 | grad 0.65 | tok/s 50648
step   1220 | loss 1.3152 | lr 2.74e-04 | grad 1.15 | tok/s 50569
step   1230 | loss 1.5319 | lr 2.42e-04 | grad 0.84 | tok/s 48482
step   1240 | loss 1.6025 | lr 2.01e-04 | grad 0.75 | tok/s 47302
step   1250 | loss 1.7027 | lr 1.55e-04 | grad 3.69 | tok/s 48971
step   1260 | loss 1.7432 | lr 1.09e-04 | grad 2.84 | tok/s 48755
step   1270 | loss 1.7940 | lr 6.65e-05 | grad 1.37 | tok/s 48259
step   1280 | loss 1.6264 | lr 3.24e-05 | grad 0.79 | tok/s 47698
step   1290 | loss 1.5789 | lr 9.84e-06 | grad 0.92 | tok/s 47607
step   1300 | loss 1.6252 | lr 1.07e-06 | grad 0.85 | tok/s 47138
step   1310 | loss 1.7039 | lr 6.93e-06 | grad 0.75 | tok/s 47161
step   1320 | loss 1.6720 | lr 2.68e-05 | grad 1.32 | tok/s 47932
step   1330 | loss 1.6033 | lr 5.89e-05 | grad 0.63 | tok/s 48165
step   1340 | loss 1.5376 | lr 9.99e-05 | grad 0.98 | tok/s 48375
step   1350 | loss 1.5437 | lr 1.46e-04 | grad 1.45 | tok/s 49640
step   1360 | loss 1.5058 | lr 1.92e-04 | grad 0.71 | tok/s 47177
step   1370 | loss 1.6134 | lr 2.35e-04 | grad 0.79 | tok/s 47923
step   1380 | loss 1.6927 | lr 2.69e-04 | grad 0.92 | tok/s 48020
step   1390 | loss 1.6238 | lr 2.91e-04 | grad 1.66 | tok/s 46959
step   1400 | loss 1.6524 | lr 3.00e-04 | grad 7.28 | tok/s 49100
step   1410 | loss 1.6281 | lr 2.94e-04 | grad 1.10 | tok/s 49309
step   1420 | loss 1.6938 | lr 2.74e-04 | grad 0.85 | tok/s 46925
step   1430 | loss 1.5120 | lr 2.42e-04 | grad 0.88 | tok/s 45860
step   1440 | loss 1.4292 | lr 2.01e-04 | grad 0.68 | tok/s 48456
step   1450 | loss 1.4537 | lr 1.55e-04 | grad 2.02 | tok/s 49351
step   1460 | loss 1.5450 | lr 1.09e-04 | grad 0.64 | tok/s 46323
step   1470 | loss 1.6432 | lr 6.65e-05 | grad 2.09 | tok/s 47969
step   1480 | loss 1.5291 | lr 3.24e-05 | grad 1.75 | tok/s 48479
step   1490 | loss 1.6575 | lr 9.84e-06 | grad 2.00 | tok/s 48403
step   1500 | loss 1.7599 | lr 1.07e-06 | grad 3.27 | tok/s 46767
step   1510 | loss 1.6407 | lr 6.93e-06 | grad 1.12 | tok/s 49625
step   1520 | loss 1.5946 | lr 2.68e-05 | grad 1.23 | tok/s 49144
step   1530 | loss 1.5621 | lr 5.89e-05 | grad 0.61 | tok/s 48745
step   1540 | loss 1.5319 | lr 9.99e-05 | grad 0.57 | tok/s 47716
step   1550 | loss 1.5063 | lr 1.46e-04 | grad 2.95 | tok/s 49781
step   1560 | loss 2.0592 | lr 1.92e-04 | grad 1.21 | tok/s 48457
step   1570 | loss 1.5546 | lr 2.35e-04 | grad 1.15 | tok/s 47089
step   1580 | loss 1.6866 | lr 2.69e-04 | grad 1.10 | tok/s 48812
step   1590 | loss 1.5357 | lr 2.91e-04 | grad 0.73 | tok/s 47573
step   1600 | loss 1.6456 | lr 3.00e-04 | grad 0.74 | tok/s 46602
step   1610 | loss 1.4529 | lr 2.94e-04 | grad 0.71 | tok/s 49585
step   1620 | loss 1.6290 | lr 2.74e-04 | grad 0.67 | tok/s 48063
step   1630 | loss 1.6130 | lr 2.42e-04 | grad 0.73 | tok/s 49221
step   1640 | loss 1.5596 | lr 2.01e-04 | grad 0.72 | tok/s 47386
step   1650 | loss 1.5699 | lr 1.55e-04 | grad 1.28 | tok/s 46994
step   1660 | loss 1.5608 | lr 1.09e-04 | grad 0.71 | tok/s 47335
step   1670 | loss 1.6010 | lr 6.65e-05 | grad 1.71 | tok/s 48941
step   1680 | loss 2.1082 | lr 3.24e-05 | grad 0.57 | tok/s 48655
step   1690 | loss 1.5276 | lr 9.84e-06 | grad 0.94 | tok/s 47700
step   1700 | loss 1.8516 | lr 1.07e-06 | grad 0.59 | tok/s 48979
step   1710 | loss 1.5779 | lr 6.93e-06 | grad 1.11 | tok/s 47630
step   1720 | loss 1.5606 | lr 2.68e-05 | grad 0.83 | tok/s 47847
step   1730 | loss 1.6800 | lr 5.89e-05 | grad 1.00 | tok/s 47944
step   1740 | loss 1.5829 | lr 9.99e-05 | grad 0.61 | tok/s 48721
step   1750 | loss 1.4957 | lr 1.46e-04 | grad 0.68 | tok/s 46916
step   1760 | loss 1.7309 | lr 1.92e-04 | grad 0.80 | tok/s 47769
step   1770 | loss 1.6444 | lr 2.35e-04 | grad 0.66 | tok/s 48665
step   1780 | loss 1.5854 | lr 2.69e-04 | grad 1.22 | tok/s 46919
step   1790 | loss 1.7609 | lr 2.91e-04 | grad 0.86 | tok/s 47865
step   1800 | loss 1.4856 | lr 3.00e-04 | grad 0.66 | tok/s 48656
step   1810 | loss 1.5785 | lr 2.94e-04 | grad 0.88 | tok/s 48080
step   1820 | loss 1.5209 | lr 2.74e-04 | grad 0.72 | tok/s 47714

Training complete! Final step: 1829
