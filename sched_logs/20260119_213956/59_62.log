# Job 59: 62
# GPU: 0
# Command: python train.py --level 62 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/62
# Started: 2026-01-19T22:51:00.360112
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/62/level62_100m_20260119_225105
Auto r_h_mode: none (level 62 has bounded/no W_h)
Model: Level 62, 98,532,480 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.5191 | lr 2.70e-05 | grad 12.00 | tok/s 24576
step     20 | loss 4.4535 | lr 5.70e-05 | grad 7.59 | tok/s 78355
step     30 | loss 4.7981 | lr 8.70e-05 | grad 4.22 | tok/s 74384
step     40 | loss 3.8914 | lr 1.17e-04 | grad 3.11 | tok/s 74335
step     50 | loss 3.4902 | lr 1.47e-04 | grad 2.48 | tok/s 85409
step     60 | loss 3.6111 | lr 1.77e-04 | grad 1.62 | tok/s 83713
step     70 | loss 3.2392 | lr 2.07e-04 | grad 1.41 | tok/s 80952
step     80 | loss 3.5575 | lr 2.37e-04 | grad 2.56 | tok/s 83983
step     90 | loss 3.4635 | lr 2.67e-04 | grad 2.92 | tok/s 80786
step    100 | loss 3.2897 | lr 2.97e-04 | grad 1.18 | tok/s 81720
step    110 | loss 3.2093 | lr 6.94e-06 | grad 1.66 | tok/s 72867
step    120 | loss 3.5405 | lr 2.69e-05 | grad 1.18 | tok/s 74598
step    130 | loss 3.3690 | lr 5.89e-05 | grad 0.96 | tok/s 75782
step    140 | loss 3.1829 | lr 9.99e-05 | grad 0.77 | tok/s 76673
step    150 | loss 3.0597 | lr 1.46e-04 | grad 1.61 | tok/s 72242
step    160 | loss 3.0320 | lr 1.92e-04 | grad 1.09 | tok/s 73317
step    170 | loss 3.1939 | lr 2.35e-04 | grad 3.17 | tok/s 75859
step    180 | loss 3.2709 | lr 2.69e-04 | grad 1.18 | tok/s 75866
step    190 | loss 3.0118 | lr 2.91e-04 | grad 1.35 | tok/s 76838
step    200 | loss 2.8216 | lr 3.00e-04 | grad 1.66 | tok/s 78511
step    210 | loss 2.8486 | lr 2.94e-04 | grad 1.71 | tok/s 75036
step    220 | loss 2.7647 | lr 2.74e-04 | grad 0.90 | tok/s 77547
step    230 | loss 2.5150 | lr 2.42e-04 | grad 1.50 | tok/s 74955
step    240 | loss 2.5560 | lr 2.01e-04 | grad 1.49 | tok/s 76288
step    250 | loss 2.4649 | lr 1.55e-04 | grad 1.24 | tok/s 75001
step    260 | loss 2.4461 | lr 1.09e-04 | grad 0.70 | tok/s 71871
step    270 | loss 2.3304 | lr 6.65e-05 | grad 1.03 | tok/s 74495
step    280 | loss 2.2220 | lr 3.24e-05 | grad 1.75 | tok/s 74285
step    290 | loss 2.3075 | lr 9.84e-06 | grad 0.84 | tok/s 78240
step    300 | loss 2.2867 | lr 1.07e-06 | grad 0.81 | tok/s 78428
step    310 | loss 2.2898 | lr 6.94e-06 | grad 0.70 | tok/s 78324
step    320 | loss 2.2949 | lr 2.69e-05 | grad 1.47 | tok/s 75428
step    330 | loss 2.3500 | lr 5.89e-05 | grad 0.68 | tok/s 73471
step    340 | loss 2.3554 | lr 9.99e-05 | grad 1.37 | tok/s 75100
step    350 | loss 2.3650 | lr 1.46e-04 | grad 1.29 | tok/s 72835
step    360 | loss 2.3232 | lr 1.92e-04 | grad 2.23 | tok/s 73657
step    370 | loss 2.2225 | lr 2.35e-04 | grad 1.38 | tok/s 75133
step    380 | loss 2.6352 | lr 2.69e-04 | grad 2.22 | tok/s 76958
step    390 | loss 2.2740 | lr 2.91e-04 | grad 1.81 | tok/s 74233
step    400 | loss 2.3547 | lr 3.00e-04 | grad 2.27 | tok/s 76115
step    410 | loss 2.1007 | lr 2.94e-04 | grad 2.75 | tok/s 73787
step    420 | loss 2.2368 | lr 2.74e-04 | grad 1.51 | tok/s 73304
step    430 | loss 2.3129 | lr 2.42e-04 | grad 1.66 | tok/s 72833
step    440 | loss 2.4049 | lr 2.01e-04 | grad 1.21 | tok/s 75697
step    450 | loss 2.1259 | lr 1.55e-04 | grad 0.84 | tok/s 73760
step    460 | loss 2.0984 | lr 1.09e-04 | grad 0.68 | tok/s 74019
step    470 | loss 2.1163 | lr 6.65e-05 | grad 1.59 | tok/s 74933
step    480 | loss 2.0165 | lr 3.24e-05 | grad 0.64 | tok/s 72197
step    490 | loss 1.9718 | lr 9.84e-06 | grad 0.57 | tok/s 73616
step    500 | loss 2.8205 | lr 1.07e-06 | grad 0.92 | tok/s 75742
step    510 | loss 1.9634 | lr 6.94e-06 | grad 0.66 | tok/s 74037
step    520 | loss 2.0570 | lr 2.69e-05 | grad 0.53 | tok/s 76441
step    530 | loss 2.4548 | lr 5.89e-05 | grad 0.84 | tok/s 74675
step    540 | loss 1.9768 | lr 9.99e-05 | grad 1.05 | tok/s 74774
step    550 | loss 1.9447 | lr 1.46e-04 | grad 0.95 | tok/s 76761
step    560 | loss 1.8182 | lr 1.92e-04 | grad 1.19 | tok/s 77809
step    570 | loss 2.0512 | lr 2.35e-04 | grad 2.02 | tok/s 76029
step    580 | loss 2.3709 | lr 2.69e-04 | grad 1.28 | tok/s 75088
step    590 | loss 2.5527 | lr 2.91e-04 | grad 2.28 | tok/s 73499
step    600 | loss 2.1766 | lr 3.00e-04 | grad 1.46 | tok/s 73748
step    610 | loss 2.1320 | lr 2.94e-04 | grad 1.67 | tok/s 77218
step    620 | loss 2.0560 | lr 2.74e-04 | grad 1.03 | tok/s 73188
step    630 | loss 1.9847 | lr 2.42e-04 | grad 1.09 | tok/s 75532
step    640 | loss 2.2678 | lr 2.01e-04 | grad 1.15 | tok/s 75671
step    650 | loss 2.0187 | lr 1.55e-04 | grad 1.50 | tok/s 74227
step    660 | loss 2.2798 | lr 1.09e-04 | grad 4.44 | tok/s 73196
step    670 | loss 2.1097 | lr 6.65e-05 | grad 2.27 | tok/s 75639
step    680 | loss 2.0323 | lr 3.24e-05 | grad 1.00 | tok/s 72919
step    690 | loss 2.0568 | lr 9.84e-06 | grad 1.15 | tok/s 73535
step    700 | loss 2.1406 | lr 1.07e-06 | grad 1.17 | tok/s 73855
step    710 | loss 2.0649 | lr 6.94e-06 | grad 1.05 | tok/s 74293
step    720 | loss 2.1599 | lr 2.68e-05 | grad 1.38 | tok/s 73938
step    730 | loss 2.1158 | lr 5.89e-05 | grad 1.25 | tok/s 74685
step    740 | loss 2.0412 | lr 9.99e-05 | grad 1.73 | tok/s 74038
step    750 | loss 1.8832 | lr 1.46e-04 | grad 1.47 | tok/s 73165
step    760 | loss 2.2603 | lr 1.92e-04 | grad 1.29 | tok/s 74025
step    770 | loss 1.9478 | lr 2.35e-04 | grad 1.35 | tok/s 73485
step    780 | loss 1.9946 | lr 2.69e-04 | grad 1.66 | tok/s 74293
step    790 | loss 1.9635 | lr 2.91e-04 | grad 1.40 | tok/s 74977
step    800 | loss 1.9282 | lr 3.00e-04 | grad 1.27 | tok/s 75042
step    810 | loss 1.9705 | lr 2.94e-04 | grad 2.03 | tok/s 74329
step    820 | loss 2.5589 | lr 2.74e-04 | grad 1.57 | tok/s 76365
step    830 | loss 2.1641 | lr 2.42e-04 | grad 1.03 | tok/s 77574
step    840 | loss 1.8794 | lr 2.01e-04 | grad 0.95 | tok/s 77558
step    850 | loss 2.2433 | lr 1.55e-04 | grad 1.48 | tok/s 73819
step    860 | loss 2.0302 | lr 1.09e-04 | grad 1.12 | tok/s 72378
step    870 | loss 1.9524 | lr 6.65e-05 | grad 0.98 | tok/s 74512
step    880 | loss 2.0106 | lr 3.24e-05 | grad 1.36 | tok/s 74253
step    890 | loss 1.9108 | lr 9.84e-06 | grad 0.85 | tok/s 74143
step    900 | loss 2.3031 | lr 1.07e-06 | grad 0.93 | tok/s 72199
step    910 | loss 1.9488 | lr 6.94e-06 | grad 0.80 | tok/s 73490
step    920 | loss 1.9363 | lr 2.68e-05 | grad 0.73 | tok/s 73246
step    930 | loss 2.0465 | lr 5.89e-05 | grad 1.45 | tok/s 73045
step    940 | loss 1.9462 | lr 9.99e-05 | grad 1.31 | tok/s 72271
step    950 | loss 1.9993 | lr 1.46e-04 | grad 1.80 | tok/s 73998
step    960 | loss 1.8061 | lr 1.92e-04 | grad 0.98 | tok/s 77536
step    970 | loss 1.6162 | lr 2.35e-04 | grad 1.03 | tok/s 77605
step    980 | loss 1.7437 | lr 2.69e-04 | grad 2.20 | tok/s 75441
step    990 | loss 2.0959 | lr 2.91e-04 | grad 1.51 | tok/s 73346
step   1000 | loss 1.9464 | lr 3.00e-04 | grad 1.09 | tok/s 71476
  >>> saved checkpoint: checkpoint_step_001000_loss_1.9464.pt
step   1010 | loss 2.1598 | lr 2.94e-04 | grad 1.60 | tok/s 54950
step   1020 | loss 1.8218 | lr 2.74e-04 | grad 1.38 | tok/s 73368
step   1030 | loss 2.1263 | lr 2.42e-04 | grad 1.27 | tok/s 72156
step   1040 | loss 1.8349 | lr 2.01e-04 | grad 1.98 | tok/s 73766
step   1050 | loss 1.8370 | lr 1.55e-04 | grad 1.00 | tok/s 73909
step   1060 | loss 2.0622 | lr 1.09e-04 | grad 1.36 | tok/s 74093
step   1070 | loss 2.1386 | lr 6.65e-05 | grad 0.87 | tok/s 74279
step   1080 | loss 2.4168 | lr 3.24e-05 | grad 1.09 | tok/s 73367
step   1090 | loss 2.1361 | lr 9.84e-06 | grad 1.04 | tok/s 73955
step   1100 | loss 1.8393 | lr 1.07e-06 | grad 0.89 | tok/s 73593
step   1110 | loss 1.8671 | lr 6.93e-06 | grad 0.82 | tok/s 74923
step   1120 | loss 2.0860 | lr 2.68e-05 | grad 0.89 | tok/s 75845
step   1130 | loss 1.8435 | lr 5.89e-05 | grad 0.80 | tok/s 72094
step   1140 | loss 1.7398 | lr 9.99e-05 | grad 0.85 | tok/s 73973
step   1150 | loss 2.0194 | lr 1.46e-04 | grad 1.17 | tok/s 73807
step   1160 | loss 1.6895 | lr 1.92e-04 | grad 0.75 | tok/s 73096
step   1170 | loss 1.9826 | lr 2.35e-04 | grad 1.06 | tok/s 74015
step   1180 | loss 1.7441 | lr 2.69e-04 | grad 0.90 | tok/s 77785
step   1190 | loss 1.6121 | lr 2.91e-04 | grad 0.83 | tok/s 77720
step   1200 | loss 1.5273 | lr 3.00e-04 | grad 1.02 | tok/s 77708
step   1210 | loss 1.4727 | lr 2.94e-04 | grad 0.84 | tok/s 77809
step   1220 | loss 1.5161 | lr 2.74e-04 | grad 1.17 | tok/s 76910
step   1230 | loss 1.7352 | lr 2.42e-04 | grad 1.16 | tok/s 74260
step   1240 | loss 1.8146 | lr 2.01e-04 | grad 1.07 | tok/s 72940
step   1250 | loss 1.8905 | lr 1.55e-04 | grad 2.98 | tok/s 75080
step   1260 | loss 1.9489 | lr 1.09e-04 | grad 2.12 | tok/s 75025
step   1270 | loss 1.9665 | lr 6.65e-05 | grad 1.34 | tok/s 74115
step   1280 | loss 1.8107 | lr 3.24e-05 | grad 0.96 | tok/s 73193
step   1290 | loss 1.7511 | lr 9.84e-06 | grad 1.09 | tok/s 72928
step   1300 | loss 1.8062 | lr 1.07e-06 | grad 0.86 | tok/s 72405
step   1310 | loss 1.8969 | lr 6.93e-06 | grad 0.86 | tok/s 72433
step   1320 | loss 1.8721 | lr 2.68e-05 | grad 1.30 | tok/s 73644
step   1330 | loss 1.7848 | lr 5.89e-05 | grad 0.81 | tok/s 73808
step   1340 | loss 1.7310 | lr 9.99e-05 | grad 1.05 | tok/s 73826
step   1350 | loss 1.7919 | lr 1.46e-04 | grad 1.99 | tok/s 75760
step   1360 | loss 1.7205 | lr 1.92e-04 | grad 1.09 | tok/s 71937
step   1370 | loss 1.8220 | lr 2.35e-04 | grad 1.27 | tok/s 73016
step   1380 | loss 1.9344 | lr 2.69e-04 | grad 1.85 | tok/s 73592
step   1390 | loss 1.8241 | lr 2.91e-04 | grad 1.62 | tok/s 71867
step   1400 | loss 1.8344 | lr 3.00e-04 | grad 6.66 | tok/s 74789
step   1410 | loss 1.8792 | lr 2.94e-04 | grad 1.50 | tok/s 75516
step   1420 | loss 1.9122 | lr 2.74e-04 | grad 1.28 | tok/s 71932
step   1430 | loss 1.7142 | lr 2.42e-04 | grad 1.09 | tok/s 70439
step   1440 | loss 1.6156 | lr 2.01e-04 | grad 0.95 | tok/s 74196
step   1450 | loss 1.6619 | lr 1.55e-04 | grad 2.28 | tok/s 75741
step   1460 | loss 1.7038 | lr 1.09e-04 | grad 0.95 | tok/s 70637
step   1470 | loss 1.8017 | lr 6.65e-05 | grad 1.89 | tok/s 73171
step   1480 | loss 1.6819 | lr 3.24e-05 | grad 1.74 | tok/s 73936
step   1490 | loss 1.8223 | lr 9.84e-06 | grad 2.75 | tok/s 73836
step   1500 | loss 1.9121 | lr 1.07e-06 | grad 2.55 | tok/s 71883
step   1510 | loss 1.8081 | lr 6.93e-06 | grad 1.13 | tok/s 75618
step   1520 | loss 1.7873 | lr 2.68e-05 | grad 1.28 | tok/s 74958
step   1530 | loss 1.7263 | lr 5.89e-05 | grad 0.64 | tok/s 74458
step   1540 | loss 1.7089 | lr 9.99e-05 | grad 0.76 | tok/s 73048
step   1550 | loss 1.6919 | lr 1.46e-04 | grad 2.27 | tok/s 76002
step   1560 | loss 2.2173 | lr 1.92e-04 | grad 1.45 | tok/s 74029
step   1570 | loss 1.7282 | lr 2.35e-04 | grad 1.34 | tok/s 72552
step   1580 | loss 1.9135 | lr 2.69e-04 | grad 1.24 | tok/s 75068
step   1590 | loss 1.6896 | lr 2.91e-04 | grad 1.09 | tok/s 73222
step   1600 | loss 1.7769 | lr 3.00e-04 | grad 1.34 | tok/s 71769
step   1610 | loss 1.6120 | lr 2.94e-04 | grad 1.35 | tok/s 75950
step   1620 | loss 1.7997 | lr 2.74e-04 | grad 1.16 | tok/s 74857
step   1630 | loss 1.8281 | lr 2.42e-04 | grad 1.63 | tok/s 75448
step   1640 | loss 1.6956 | lr 2.01e-04 | grad 0.86 | tok/s 72913
step   1650 | loss 1.7124 | lr 1.55e-04 | grad 1.45 | tok/s 71789
step   1660 | loss 1.6938 | lr 1.09e-04 | grad 0.84 | tok/s 72248
step   1670 | loss 1.7469 | lr 6.65e-05 | grad 1.87 | tok/s 75331
step   1680 | loss 2.1665 | lr 3.24e-05 | grad 0.71 | tok/s 75379
step   1690 | loss 1.6736 | lr 9.84e-06 | grad 0.93 | tok/s 73596
step   1700 | loss 2.0055 | lr 1.07e-06 | grad 0.65 | tok/s 75112
step   1710 | loss 1.7136 | lr 6.93e-06 | grad 0.96 | tok/s 72892
step   1720 | loss 1.7175 | lr 2.68e-05 | grad 0.89 | tok/s 73142
step   1730 | loss 1.8299 | lr 5.89e-05 | grad 0.80 | tok/s 73225
step   1740 | loss 1.7233 | lr 9.99e-05 | grad 0.66 | tok/s 74412
step   1750 | loss 1.6399 | lr 1.46e-04 | grad 0.77 | tok/s 71825
step   1760 | loss 1.9015 | lr 1.92e-04 | grad 1.08 | tok/s 72900
step   1770 | loss 1.8453 | lr 2.35e-04 | grad 1.20 | tok/s 74567
step   1780 | loss 1.7113 | lr 2.69e-04 | grad 1.16 | tok/s 71810
step   1790 | loss 1.9128 | lr 2.91e-04 | grad 1.26 | tok/s 73124
step   1800 | loss 1.6532 | lr 3.00e-04 | grad 1.09 | tok/s 74423
step   1810 | loss 1.7279 | lr 2.94e-04 | grad 1.09 | tok/s 74016
step   1820 | loss 1.6869 | lr 2.74e-04 | grad 1.16 | tok/s 73201
step   1830 | loss 1.7128 | lr 2.42e-04 | grad 1.03 | tok/s 72906
step   1840 | loss 1.6751 | lr 2.01e-04 | grad 1.16 | tok/s 72249
step   1850 | loss 1.8978 | lr 1.55e-04 | grad 1.11 | tok/s 73052
step   1860 | loss 1.6447 | lr 1.09e-04 | grad 0.61 | tok/s 72783
step   1870 | loss 1.6844 | lr 6.65e-05 | grad 1.27 | tok/s 74674
step   1880 | loss 1.6407 | lr 3.24e-05 | grad 0.68 | tok/s 75185
step   1890 | loss 1.7302 | lr 9.84e-06 | grad 0.66 | tok/s 73647
step   1900 | loss 1.7878 | lr 1.07e-06 | grad 1.44 | tok/s 74617
step   1910 | loss 1.7430 | lr 6.93e-06 | grad 1.06 | tok/s 73525
step   1920 | loss 1.6402 | lr 2.68e-05 | grad 1.04 | tok/s 76004
step   1930 | loss 1.6260 | lr 5.89e-05 | grad 0.90 | tok/s 75115
step   1940 | loss 1.5629 | lr 9.99e-05 | grad 0.91 | tok/s 76618
step   1950 | loss 1.6326 | lr 1.46e-04 | grad 0.90 | tok/s 74508
step   1960 | loss 2.0142 | lr 1.92e-04 | grad 3.64 | tok/s 76112
step   1970 | loss 1.7232 | lr 2.35e-04 | grad 1.60 | tok/s 73474
step   1980 | loss 1.7589 | lr 2.69e-04 | grad 2.31 | tok/s 73453
step   1990 | loss 1.8675 | lr 2.91e-04 | grad 1.17 | tok/s 75257
step   2000 | loss 1.7752 | lr 3.00e-04 | grad 1.54 | tok/s 75736
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7752.pt
step   2010 | loss 1.5351 | lr 2.94e-04 | grad 0.79 | tok/s 56504
step   2020 | loss 1.3641 | lr 2.74e-04 | grad 0.86 | tok/s 77821
step   2030 | loss 1.6658 | lr 2.42e-04 | grad 1.26 | tok/s 76997
step   2040 | loss 1.5088 | lr 2.01e-04 | grad 0.70 | tok/s 78035
step   2050 | loss 1.4476 | lr 1.55e-04 | grad 1.16 | tok/s 76863
step   2060 | loss 1.7379 | lr 1.09e-04 | grad 0.84 | tok/s 73396
step   2070 | loss 1.6833 | lr 6.65e-05 | grad 1.33 | tok/s 76983
step   2080 | loss 1.8147 | lr 3.24e-05 | grad 3.36 | tok/s 72621
step   2090 | loss 1.7542 | lr 9.84e-06 | grad 1.11 | tok/s 75192
step   2100 | loss 1.6857 | lr 1.07e-06 | grad 0.98 | tok/s 73051
step   2110 | loss 1.5568 | lr 6.93e-06 | grad 0.82 | tok/s 75550
step   2120 | loss 1.5652 | lr 2.68e-05 | grad 1.23 | tok/s 74823
step   2130 | loss 1.6722 | lr 5.89e-05 | grad 2.03 | tok/s 72624
step   2140 | loss 1.7243 | lr 9.99e-05 | grad 2.75 | tok/s 72571
step   2150 | loss 1.7299 | lr 1.46e-04 | grad 0.82 | tok/s 73629
step   2160 | loss 1.6975 | lr 1.92e-04 | grad 0.93 | tok/s 72672
step   2170 | loss 1.8004 | lr 2.35e-04 | grad 1.11 | tok/s 73560
step   2180 | loss 1.6943 | lr 2.69e-04 | grad 1.11 | tok/s 75333
step   2190 | loss 1.9976 | lr 2.91e-04 | grad 1.21 | tok/s 75056
step   2200 | loss 1.4644 | lr 3.00e-04 | grad 0.96 | tok/s 77737
step   2210 | loss 1.4179 | lr 2.94e-04 | grad 0.86 | tok/s 77746
step   2220 | loss 1.3713 | lr 2.74e-04 | grad 0.82 | tok/s 77634
step   2230 | loss 1.5914 | lr 2.42e-04 | grad 1.11 | tok/s 74930
step   2240 | loss 1.8390 | lr 2.01e-04 | grad 2.53 | tok/s 76617
step   2250 | loss 1.7537 | lr 1.55e-04 | grad 1.04 | tok/s 75950
step   2260 | loss 1.8174 | lr 1.09e-04 | grad 1.05 | tok/s 74907
step   2270 | loss 1.6137 | lr 6.65e-05 | grad 1.22 | tok/s 73306
step   2280 | loss 1.7590 | lr 3.24e-05 | grad 0.66 | tok/s 73234
step   2290 | loss 1.5893 | lr 9.84e-06 | grad 0.95 | tok/s 74179
step   2300 | loss 1.5944 | lr 1.07e-06 | grad 0.64 | tok/s 71896
step   2310 | loss 1.6889 | lr 6.93e-06 | grad 1.09 | tok/s 76505
step   2320 | loss 1.7634 | lr 2.68e-05 | grad 1.02 | tok/s 77625
step   2330 | loss 1.6860 | lr 5.89e-05 | grad 0.73 | tok/s 77734
step   2340 | loss 1.6640 | lr 9.98e-05 | grad 0.99 | tok/s 76021
step   2350 | loss 1.7077 | lr 1.46e-04 | grad 0.83 | tok/s 73728
step   2360 | loss 2.1377 | lr 1.92e-04 | grad 1.80 | tok/s 75123
step   2370 | loss 1.7196 | lr 2.35e-04 | grad 1.34 | tok/s 74662
step   2380 | loss 1.5737 | lr 2.69e-04 | grad 1.19 | tok/s 73772
step   2390 | loss 1.6290 | lr 2.91e-04 | grad 1.07 | tok/s 73662
step   2400 | loss 1.7684 | lr 3.00e-04 | grad 1.49 | tok/s 72819
step   2410 | loss 1.6728 | lr 2.94e-04 | grad 1.13 | tok/s 73338
step   2420 | loss 1.8776 | lr 2.74e-04 | grad 1.00 | tok/s 74015
step   2430 | loss 1.7999 | lr 2.42e-04 | grad 1.33 | tok/s 73106
step   2440 | loss 1.8018 | lr 2.01e-04 | grad 1.02 | tok/s 75181
step   2450 | loss 1.5202 | lr 1.55e-04 | grad 1.27 | tok/s 74066
step   2460 | loss 1.7623 | lr 1.09e-04 | grad 1.57 | tok/s 75668
step   2470 | loss 1.8962 | lr 6.65e-05 | grad 0.99 | tok/s 77503
step   2480 | loss 1.6136 | lr 3.24e-05 | grad 0.75 | tok/s 74157
step   2490 | loss 1.5321 | lr 9.84e-06 | grad 0.96 | tok/s 73212
step   2500 | loss 1.6522 | lr 1.07e-06 | grad 0.86 | tok/s 75113
step   2510 | loss 1.6922 | lr 6.93e-06 | grad 0.86 | tok/s 75008
step   2520 | loss 1.8424 | lr 2.68e-05 | grad 1.05 | tok/s 73149
step   2530 | loss 1.6667 | lr 5.89e-05 | grad 1.17 | tok/s 72464
step   2540 | loss 1.6559 | lr 9.98e-05 | grad 0.84 | tok/s 73144
step   2550 | loss 2.0754 | lr 1.46e-04 | grad 1.89 | tok/s 74215
step   2560 | loss 1.8039 | lr 1.92e-04 | grad 1.21 | tok/s 75586
step   2570 | loss 1.6707 | lr 2.35e-04 | grad 2.27 | tok/s 72375
step   2580 | loss 1.7746 | lr 2.69e-04 | grad 1.02 | tok/s 75237
step   2590 | loss 1.5269 | lr 2.91e-04 | grad 1.05 | tok/s 73379
step   2600 | loss 1.7249 | lr 3.00e-04 | grad 0.97 | tok/s 75195
step   2610 | loss 1.6706 | lr 2.94e-04 | grad 1.02 | tok/s 75934
step   2620 | loss 1.5145 | lr 2.74e-04 | grad 0.80 | tok/s 77673
step   2630 | loss 1.5387 | lr 2.42e-04 | grad 0.67 | tok/s 75355
step   2640 | loss 1.6713 | lr 2.01e-04 | grad 1.25 | tok/s 73261
step   2650 | loss 1.6034 | lr 1.55e-04 | grad 0.94 | tok/s 70884
step   2660 | loss 2.0168 | lr 1.09e-04 | grad 3.02 | tok/s 76255
step   2670 | loss 1.5904 | lr 6.65e-05 | grad 0.77 | tok/s 77696
step   2680 | loss 1.5150 | lr 3.24e-05 | grad 0.73 | tok/s 77626
step   2690 | loss 1.4638 | lr 9.84e-06 | grad 0.65 | tok/s 77639
step   2700 | loss 1.6297 | lr 1.07e-06 | grad 0.80 | tok/s 74734
step   2710 | loss 1.7289 | lr 6.93e-06 | grad 2.61 | tok/s 72608
step   2720 | loss 2.1996 | lr 2.68e-05 | grad 0.73 | tok/s 76621
step   2730 | loss 1.6710 | lr 5.89e-05 | grad 0.89 | tok/s 74147
step   2740 | loss 1.4926 | lr 9.98e-05 | grad 0.96 | tok/s 73818
step   2750 | loss 1.7149 | lr 1.46e-04 | grad 0.91 | tok/s 74587
step   2760 | loss 1.7640 | lr 1.92e-04 | grad 1.58 | tok/s 71590
step   2770 | loss 1.5995 | lr 2.35e-04 | grad 0.98 | tok/s 74673
step   2780 | loss 1.5970 | lr 2.69e-04 | grad 0.95 | tok/s 72014
step   2790 | loss 1.5028 | lr 2.91e-04 | grad 0.94 | tok/s 73983
step   2800 | loss 1.9959 | lr 3.00e-04 | grad 2.09 | tok/s 73944
step   2810 | loss 1.7789 | lr 2.94e-04 | grad 1.16 | tok/s 75053
step   2820 | loss 1.9720 | lr 2.74e-04 | grad 1.84 | tok/s 75773

Training complete! Final step: 2822
