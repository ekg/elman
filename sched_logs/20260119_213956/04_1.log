# Job 4: 1
# GPU: 4
# Command: python train.py --level 1 --dim 640 --expansion 2.0 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/1
# Started: 2026-01-19T21:39:56.177182
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/1/level1_100m_20260119_214002
Auto r_h_mode: spectral_norm (level 1 has full W_h)
Model: Level 1, 114,890,880 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.1463 | lr 2.70e-05 | grad 7.25 | tok/s 19508
step     20 | loss 3.7077 | lr 5.70e-05 | grad 9.06 | tok/s 49935
step     30 | loss 4.1852 | lr 8.70e-05 | grad 3.59 | tok/s 55065
step     40 | loss 2.9283 | lr 1.17e-04 | grad 2.41 | tok/s 54963
step     50 | loss 2.3792 | lr 1.47e-04 | grad 2.19 | tok/s 55219
step     60 | loss 2.6659 | lr 1.77e-04 | grad 3.08 | tok/s 54143
step     70 | loss 2.3814 | lr 2.07e-04 | grad 2.22 | tok/s 52390
step     80 | loss 2.7331 | lr 2.37e-04 | grad 2.83 | tok/s 54407
step     90 | loss 2.6608 | lr 2.67e-04 | grad 3.95 | tok/s 52537
step    100 | loss 2.2529 | lr 2.97e-04 | grad 0.91 | tok/s 52963
step    110 | loss 2.3337 | lr 6.94e-06 | grad 2.33 | tok/s 49772
step    120 | loss 2.5135 | lr 2.69e-05 | grad 1.31 | tok/s 49613
step    130 | loss 2.3687 | lr 5.89e-05 | grad 1.04 | tok/s 50777
step    140 | loss 2.1367 | lr 9.99e-05 | grad 0.98 | tok/s 50878
step    150 | loss 2.0162 | lr 1.46e-04 | grad 1.85 | tok/s 48466
step    160 | loss 1.9376 | lr 1.92e-04 | grad 1.38 | tok/s 48896
step    170 | loss 2.1274 | lr 2.35e-04 | grad 2.91 | tok/s 50590
step    180 | loss 2.1155 | lr 2.69e-04 | grad 1.29 | tok/s 50766
step    190 | loss 1.8492 | lr 2.91e-04 | grad 1.20 | tok/s 51616
step    200 | loss 1.4836 | lr 3.00e-04 | grad 1.12 | tok/s 52735
step    210 | loss 2.2077 | lr 2.94e-04 | grad 1.45 | tok/s 50502
step    220 | loss 2.0349 | lr 2.74e-04 | grad 0.96 | tok/s 52080
step    230 | loss 1.9114 | lr 2.42e-04 | grad 1.31 | tok/s 50452
step    240 | loss 1.8867 | lr 2.01e-04 | grad 1.40 | tok/s 52326
step    250 | loss 1.9004 | lr 1.55e-04 | grad 1.14 | tok/s 51189
step    260 | loss 1.9756 | lr 1.09e-04 | grad 0.70 | tok/s 49219
step    270 | loss 1.8233 | lr 6.65e-05 | grad 0.89 | tok/s 50858
step    280 | loss 1.7067 | lr 3.24e-05 | grad 1.35 | tok/s 50941
step    290 | loss 1.7020 | lr 9.84e-06 | grad 0.74 | tok/s 53864
step    300 | loss 1.6715 | lr 1.07e-06 | grad 0.71 | tok/s 53406
step    310 | loss 1.6631 | lr 6.94e-06 | grad 0.65 | tok/s 53559
step    320 | loss 1.7725 | lr 2.69e-05 | grad 1.45 | tok/s 51506
step    330 | loss 1.7938 | lr 5.89e-05 | grad 0.67 | tok/s 50279
step    340 | loss 1.8046 | lr 9.99e-05 | grad 2.02 | tok/s 51185
step    350 | loss 1.8122 | lr 1.46e-04 | grad 0.80 | tok/s 49925
step    360 | loss 1.7785 | lr 1.92e-04 | grad 1.91 | tok/s 50511
step    370 | loss 1.6267 | lr 2.35e-04 | grad 0.92 | tok/s 51369
step    380 | loss 2.1079 | lr 2.69e-04 | grad 0.98 | tok/s 52486
step    390 | loss 1.8200 | lr 2.91e-04 | grad 1.12 | tok/s 50676
step    400 | loss 1.9174 | lr 3.00e-04 | grad 2.53 | tok/s 52190
step    410 | loss 1.6942 | lr 2.94e-04 | grad 2.03 | tok/s 50449
step    420 | loss 1.8245 | lr 2.74e-04 | grad 1.05 | tok/s 49891
step    430 | loss 1.9656 | lr 2.42e-04 | grad 1.16 | tok/s 49685
step    440 | loss 2.0008 | lr 2.01e-04 | grad 0.93 | tok/s 51828
step    450 | loss 1.7862 | lr 1.55e-04 | grad 0.66 | tok/s 50197
step    460 | loss 1.7446 | lr 1.09e-04 | grad 0.61 | tok/s 50109
step    470 | loss 1.7267 | lr 6.65e-05 | grad 0.90 | tok/s 50643
step    480 | loss 1.6215 | lr 3.24e-05 | grad 0.53 | tok/s 48787
step    490 | loss 1.6086 | lr 9.84e-06 | grad 0.52 | tok/s 50518
step    500 | loss 2.5496 | lr 1.07e-06 | grad 0.85 | tok/s 51341
step    510 | loss 1.6172 | lr 6.94e-06 | grad 0.59 | tok/s 50742
step    520 | loss 1.6939 | lr 2.69e-05 | grad 0.47 | tok/s 52458
step    530 | loss 2.2093 | lr 5.89e-05 | grad 0.57 | tok/s 51324
step    540 | loss 1.6173 | lr 9.99e-05 | grad 0.87 | tok/s 51131
step    550 | loss 1.5238 | lr 1.46e-04 | grad 0.59 | tok/s 52300
step    560 | loss 1.3923 | lr 1.92e-04 | grad 0.57 | tok/s 53632
step    570 | loss 1.6696 | lr 2.35e-04 | grad 1.75 | tok/s 52304
step    580 | loss 1.9790 | lr 2.69e-04 | grad 0.93 | tok/s 51994
step    590 | loss 2.2537 | lr 2.91e-04 | grad 1.12 | tok/s 50660
step    600 | loss 1.7997 | lr 3.00e-04 | grad 1.26 | tok/s 51062
step    610 | loss 1.7647 | lr 2.94e-04 | grad 1.03 | tok/s 52798
step    620 | loss 1.7383 | lr 2.74e-04 | grad 0.73 | tok/s 50390
step    630 | loss 1.6399 | lr 2.42e-04 | grad 0.72 | tok/s 51712
step    640 | loss 1.9392 | lr 2.01e-04 | grad 0.83 | tok/s 52220
step    650 | loss 1.6688 | lr 1.55e-04 | grad 0.86 | tok/s 51199
step    660 | loss 1.9761 | lr 1.09e-04 | grad 4.59 | tok/s 50269
step    670 | loss 1.8022 | lr 6.65e-05 | grad 1.41 | tok/s 52202
step    680 | loss 1.7631 | lr 3.24e-05 | grad 0.88 | tok/s 50045
step    690 | loss 1.7576 | lr 9.84e-06 | grad 1.10 | tok/s 50944
step    700 | loss 1.8665 | lr 1.07e-06 | grad 1.18 | tok/s 50836
step    710 | loss 1.7937 | lr 6.94e-06 | grad 0.88 | tok/s 51290
step    720 | loss 1.8583 | lr 2.68e-05 | grad 1.16 | tok/s 51012
step    730 | loss 1.8449 | lr 5.89e-05 | grad 1.07 | tok/s 51450
step    740 | loss 1.7844 | lr 9.99e-05 | grad 1.44 | tok/s 50955
step    750 | loss 1.5919 | lr 1.46e-04 | grad 1.27 | tok/s 50559
step    760 | loss 1.9293 | lr 1.92e-04 | grad 0.54 | tok/s 51298
step    770 | loss 1.6381 | lr 2.35e-04 | grad 0.89 | tok/s 50779
step    780 | loss 1.6920 | lr 2.69e-04 | grad 0.71 | tok/s 51689
step    790 | loss 1.6126 | lr 2.91e-04 | grad 0.54 | tok/s 51839
step    800 | loss 1.6034 | lr 3.00e-04 | grad 0.86 | tok/s 51848
step    810 | loss 1.7301 | lr 2.94e-04 | grad 1.46 | tok/s 51307
step    820 | loss 2.3917 | lr 2.74e-04 | grad 1.03 | tok/s 52758
step    830 | loss 1.8188 | lr 2.42e-04 | grad 0.62 | tok/s 53654
step    840 | loss 1.5330 | lr 2.01e-04 | grad 0.53 | tok/s 53562
step    850 | loss 2.0377 | lr 1.55e-04 | grad 1.07 | tok/s 51317
step    860 | loss 1.7413 | lr 1.09e-04 | grad 0.78 | tok/s 49648
step    870 | loss 1.6674 | lr 6.65e-05 | grad 0.75 | tok/s 51331
step    880 | loss 1.7469 | lr 3.24e-05 | grad 0.96 | tok/s 51274
step    890 | loss 1.6444 | lr 9.84e-06 | grad 0.81 | tok/s 51410
step    900 | loss 2.1197 | lr 1.07e-06 | grad 0.79 | tok/s 49799
step    910 | loss 1.7017 | lr 6.94e-06 | grad 0.59 | tok/s 50998
step    920 | loss 1.6782 | lr 2.68e-05 | grad 0.68 | tok/s 50151
step    930 | loss 1.7772 | lr 5.89e-05 | grad 1.27 | tok/s 50684
step    940 | loss 1.6900 | lr 9.99e-05 | grad 1.42 | tok/s 49809
step    950 | loss 1.7651 | lr 1.46e-04 | grad 0.95 | tok/s 51129
step    960 | loss 1.4995 | lr 1.92e-04 | grad 0.49 | tok/s 53491
step    970 | loss 1.3392 | lr 2.35e-04 | grad 0.40 | tok/s 53617
step    980 | loss 1.5102 | lr 2.69e-04 | grad 1.34 | tok/s 52314
step    990 | loss 1.8133 | lr 2.91e-04 | grad 0.62 | tok/s 50599
step   1000 | loss 1.7067 | lr 3.00e-04 | grad 0.52 | tok/s 49721
  >>> saved checkpoint: checkpoint_step_001000_loss_1.7067.pt
step   1010 | loss 1.9012 | lr 2.94e-04 | grad 1.45 | tok/s 42010
step   1020 | loss 1.5763 | lr 2.74e-04 | grad 0.71 | tok/s 50636
step   1030 | loss 2.0124 | lr 2.42e-04 | grad 0.73 | tok/s 49942
step   1040 | loss 1.6207 | lr 2.01e-04 | grad 1.09 | tok/s 51194
step   1050 | loss 1.6542 | lr 1.55e-04 | grad 0.66 | tok/s 51365
step   1060 | loss 1.8165 | lr 1.09e-04 | grad 1.16 | tok/s 51287
step   1070 | loss 1.9178 | lr 6.65e-05 | grad 0.70 | tok/s 51516
step   1080 | loss 2.3111 | lr 3.24e-05 | grad 0.87 | tok/s 50719
step   1090 | loss 2.0022 | lr 9.84e-06 | grad 0.73 | tok/s 51250
step   1100 | loss 1.6992 | lr 1.07e-06 | grad 0.61 | tok/s 50668
step   1110 | loss 1.6579 | lr 6.93e-06 | grad 0.68 | tok/s 51480
step   1120 | loss 1.8805 | lr 2.68e-05 | grad 0.68 | tok/s 52653
step   1130 | loss 1.6804 | lr 5.89e-05 | grad 0.60 | tok/s 49906
step   1140 | loss 1.5476 | lr 9.99e-05 | grad 0.53 | tok/s 51218
step   1150 | loss 1.8217 | lr 1.46e-04 | grad 0.88 | tok/s 51488
step   1160 | loss 1.5146 | lr 1.92e-04 | grad 0.46 | tok/s 50580
step   1170 | loss 1.8400 | lr 2.35e-04 | grad 0.66 | tok/s 50884
step   1180 | loss 1.5460 | lr 2.69e-04 | grad 0.57 | tok/s 54335
step   1190 | loss 1.3966 | lr 2.91e-04 | grad 0.46 | tok/s 54076
step   1200 | loss 1.3212 | lr 3.00e-04 | grad 0.53 | tok/s 53779
step   1210 | loss 1.2998 | lr 2.94e-04 | grad 0.52 | tok/s 53946
step   1220 | loss 1.3483 | lr 2.74e-04 | grad 0.77 | tok/s 53605
step   1230 | loss 1.5623 | lr 2.42e-04 | grad 0.63 | tok/s 51335
step   1240 | loss 1.6264 | lr 2.01e-04 | grad 0.57 | tok/s 50682
step   1250 | loss 1.7101 | lr 1.55e-04 | grad 2.34 | tok/s 51999
step   1260 | loss 1.7608 | lr 1.09e-04 | grad 1.90 | tok/s 51397
step   1270 | loss 1.8239 | lr 6.65e-05 | grad 1.05 | tok/s 50202
step   1280 | loss 1.6514 | lr 3.24e-05 | grad 0.59 | tok/s 50141
step   1290 | loss 1.6025 | lr 9.84e-06 | grad 0.68 | tok/s 49599
step   1300 | loss 1.6474 | lr 1.07e-06 | grad 0.60 | tok/s 49290
step   1310 | loss 1.7268 | lr 6.93e-06 | grad 0.55 | tok/s 49437
step   1320 | loss 1.7063 | lr 2.68e-05 | grad 0.93 | tok/s 50238
step   1330 | loss 1.6350 | lr 5.89e-05 | grad 0.47 | tok/s 50358
step   1340 | loss 1.5414 | lr 9.99e-05 | grad 0.72 | tok/s 50350
step   1350 | loss 1.5708 | lr 1.46e-04 | grad 1.19 | tok/s 51663
step   1360 | loss 1.5340 | lr 1.92e-04 | grad 0.57 | tok/s 49196
step   1370 | loss 1.6404 | lr 2.35e-04 | grad 0.50 | tok/s 49802
step   1380 | loss 1.7195 | lr 2.69e-04 | grad 0.69 | tok/s 50293
step   1390 | loss 1.6476 | lr 2.91e-04 | grad 1.13 | tok/s 49007
step   1400 | loss 1.6512 | lr 3.00e-04 | grad 2.56 | tok/s 51046
step   1410 | loss 1.6652 | lr 2.94e-04 | grad 1.02 | tok/s 51481
step   1420 | loss 1.7301 | lr 2.74e-04 | grad 0.68 | tok/s 48939
step   1430 | loss 1.5426 | lr 2.42e-04 | grad 0.61 | tok/s 47807
step   1440 | loss 1.4662 | lr 2.01e-04 | grad 0.53 | tok/s 50502
step   1450 | loss 1.5048 | lr 1.55e-04 | grad 1.52 | tok/s 50357
step   1460 | loss 1.5692 | lr 1.09e-04 | grad 0.46 | tok/s 39195
step   1470 | loss 1.6719 | lr 6.65e-05 | grad 1.43 | tok/s 49173
step   1480 | loss 1.5604 | lr 3.24e-05 | grad 1.41 | tok/s 50145
step   1490 | loss 1.6909 | lr 9.84e-06 | grad 1.73 | tok/s 50122
step   1500 | loss 1.7937 | lr 1.07e-06 | grad 2.42 | tok/s 48731
step   1510 | loss 1.6887 | lr 6.93e-06 | grad 0.80 | tok/s 51238
step   1520 | loss 1.6405 | lr 2.68e-05 | grad 0.95 | tok/s 50862
step   1530 | loss 1.5927 | lr 5.89e-05 | grad 0.46 | tok/s 50502
step   1540 | loss 1.5690 | lr 9.99e-05 | grad 0.40 | tok/s 49502
step   1550 | loss 1.5387 | lr 1.46e-04 | grad 3.09 | tok/s 51482
step   1560 | loss 2.1121 | lr 1.92e-04 | grad 1.08 | tok/s 50136
step   1570 | loss 1.5885 | lr 2.35e-04 | grad 0.96 | tok/s 49112
step   1580 | loss 1.7388 | lr 2.69e-04 | grad 0.76 | tok/s 50752
step   1590 | loss 1.5407 | lr 2.91e-04 | grad 0.55 | tok/s 49101
step   1600 | loss 1.6812 | lr 3.00e-04 | grad 0.64 | tok/s 48531
step   1610 | loss 1.4932 | lr 2.94e-04 | grad 0.55 | tok/s 51332
step   1620 | loss 1.6578 | lr 2.74e-04 | grad 0.49 | tok/s 51341
step   1630 | loss 1.6459 | lr 2.42e-04 | grad 0.56 | tok/s 51948
step   1640 | loss 1.5800 | lr 2.01e-04 | grad 0.54 | tok/s 50142
step   1650 | loss 1.5938 | lr 1.55e-04 | grad 0.89 | tok/s 49207
step   1660 | loss 1.5809 | lr 1.09e-04 | grad 0.53 | tok/s 49718
step   1670 | loss 1.6338 | lr 6.65e-05 | grad 1.42 | tok/s 51875
step   1680 | loss 1.9881 | lr 3.24e-05 | grad 0.47 | tok/s 52220
step   1690 | loss 1.5555 | lr 9.84e-06 | grad 0.71 | tok/s 50700
step   1700 | loss 1.9082 | lr 1.07e-06 | grad 0.46 | tok/s 52358
step   1710 | loss 1.6146 | lr 6.93e-06 | grad 0.75 | tok/s 50399
step   1720 | loss 1.6110 | lr 2.68e-05 | grad 0.64 | tok/s 50674
step   1730 | loss 1.7095 | lr 5.89e-05 | grad 0.68 | tok/s 50882
step   1740 | loss 1.6153 | lr 9.99e-05 | grad 0.48 | tok/s 51388
step   1750 | loss 1.5248 | lr 1.46e-04 | grad 0.45 | tok/s 49966
step   1760 | loss 1.7776 | lr 1.92e-04 | grad 0.52 | tok/s 50331
step   1770 | loss 1.6707 | lr 2.35e-04 | grad 0.52 | tok/s 51854
step   1780 | loss 1.5886 | lr 2.69e-04 | grad 0.83 | tok/s 49609
step   1790 | loss 1.7640 | lr 2.91e-04 | grad 0.62 | tok/s 50592
step   1800 | loss 1.5187 | lr 3.00e-04 | grad 0.52 | tok/s 51398
step   1810 | loss 1.6057 | lr 2.94e-04 | grad 0.70 | tok/s 51165
step   1820 | loss 1.5459 | lr 2.74e-04 | grad 0.65 | tok/s 50813
step   1830 | loss 1.5970 | lr 2.42e-04 | grad 0.61 | tok/s 50488
step   1840 | loss 1.5665 | lr 2.01e-04 | grad 0.62 | tok/s 50130
step   1850 | loss 1.7746 | lr 1.55e-04 | grad 0.71 | tok/s 50327
step   1860 | loss 1.5468 | lr 1.09e-04 | grad 0.41 | tok/s 50827
step   1870 | loss 1.5983 | lr 6.65e-05 | grad 0.97 | tok/s 51353
step   1880 | loss 1.5373 | lr 3.24e-05 | grad 0.47 | tok/s 52079
step   1890 | loss 1.6294 | lr 9.84e-06 | grad 0.47 | tok/s 51020
step   1900 | loss 1.7015 | lr 1.07e-06 | grad 1.18 | tok/s 50882
step   1910 | loss 1.6604 | lr 6.93e-06 | grad 1.52 | tok/s 51916
step   1920 | loss 1.5638 | lr 2.68e-05 | grad 0.75 | tok/s 53950
step   1930 | loss 1.5448 | lr 5.89e-05 | grad 0.69 | tok/s 53148

Training complete! Final step: 1934
