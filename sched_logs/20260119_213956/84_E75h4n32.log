# Job 84: E75h4n32
# GPU: 3
# Command: python train.py --level E75h4n32 --dim 1280 --expansion 2.0 --n_state 32 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/E75h4n32
# Started: 2026-01-19T23:11:35.738420
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/E75h4n32/levelE75h4n32_100m_20260119_231140
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h4n32, 95,384,320 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.5783 | lr 2.70e-05 | grad 324.00 | tok/s 22862
step     20 | loss 5.3360 | lr 5.70e-05 | grad 49.75 | tok/s 66129
step     30 | loss 5.2674 | lr 8.70e-05 | grad 18.12 | tok/s 69878
step     40 | loss 4.7216 | lr 1.17e-04 | grad 8.50 | tok/s 69864
step     50 | loss 4.0159 | lr 1.47e-04 | grad 8.50 | tok/s 69672
step     60 | loss 3.8820 | lr 1.77e-04 | grad 14.19 | tok/s 68174
step     70 | loss 3.3375 | lr 2.07e-04 | grad 13.56 | tok/s 65659
step     80 | loss 3.3360 | lr 2.37e-04 | grad 3.42 | tok/s 68177
step     90 | loss 3.2302 | lr 2.67e-04 | grad 5.09 | tok/s 65781
step    100 | loss 2.8626 | lr 2.97e-04 | grad 1.62 | tok/s 66280
step    110 | loss 2.7907 | lr 6.94e-06 | grad 2.81 | tok/s 61155
step    120 | loss 3.0734 | lr 2.69e-05 | grad 1.96 | tok/s 61161
step    130 | loss 2.8798 | lr 5.89e-05 | grad 1.60 | tok/s 62432
step    140 | loss 2.6287 | lr 9.99e-05 | grad 1.13 | tok/s 62617
step    150 | loss 2.5114 | lr 1.46e-04 | grad 2.53 | tok/s 59694
step    160 | loss 2.3787 | lr 1.92e-04 | grad 1.72 | tok/s 60156
step    170 | loss 2.5641 | lr 2.35e-04 | grad 4.31 | tok/s 62216
step    180 | loss 2.5930 | lr 2.69e-04 | grad 1.63 | tok/s 62345
step    190 | loss 2.3164 | lr 2.91e-04 | grad 1.64 | tok/s 63287
step    200 | loss 1.9850 | lr 3.00e-04 | grad 1.46 | tok/s 64730
step    210 | loss 2.5080 | lr 2.94e-04 | grad 2.28 | tok/s 61975
step    220 | loss 2.4224 | lr 2.74e-04 | grad 1.33 | tok/s 63963
step    230 | loss 2.2304 | lr 2.42e-04 | grad 1.52 | tok/s 61744
step    240 | loss 2.2509 | lr 2.01e-04 | grad 2.11 | tok/s 62994
step    250 | loss 2.1929 | lr 1.55e-04 | grad 1.16 | tok/s 62089
step    260 | loss 2.2152 | lr 1.09e-04 | grad 0.79 | tok/s 59541
step    270 | loss 2.0805 | lr 6.65e-05 | grad 1.15 | tok/s 61774
step    280 | loss 2.0033 | lr 3.24e-05 | grad 1.71 | tok/s 61752
step    290 | loss 1.9766 | lr 9.84e-06 | grad 0.87 | tok/s 65055
step    300 | loss 1.9372 | lr 1.07e-06 | grad 0.86 | tok/s 64931
step    310 | loss 1.9497 | lr 6.94e-06 | grad 0.75 | tok/s 64961
step    320 | loss 2.0418 | lr 2.69e-05 | grad 2.14 | tok/s 62621
step    330 | loss 2.0898 | lr 5.89e-05 | grad 0.72 | tok/s 61053
step    340 | loss 2.0906 | lr 9.99e-05 | grad 1.89 | tok/s 62389
step    350 | loss 2.1161 | lr 1.46e-04 | grad 1.07 | tok/s 60615
step    360 | loss 2.0723 | lr 1.92e-04 | grad 2.66 | tok/s 61357
step    370 | loss 1.9247 | lr 2.35e-04 | grad 1.35 | tok/s 62476
step    380 | loss 2.4596 | lr 2.69e-04 | grad 1.26 | tok/s 64022
step    390 | loss 2.0691 | lr 2.91e-04 | grad 1.37 | tok/s 61672
step    400 | loss 2.1706 | lr 3.00e-04 | grad 2.91 | tok/s 63238
step    410 | loss 1.9200 | lr 2.94e-04 | grad 2.19 | tok/s 61372
step    420 | loss 2.0279 | lr 2.74e-04 | grad 1.21 | tok/s 60942
step    430 | loss 2.1872 | lr 2.42e-04 | grad 1.48 | tok/s 60719
step    440 | loss 2.2508 | lr 2.01e-04 | grad 1.01 | tok/s 63098
step    450 | loss 1.9526 | lr 1.55e-04 | grad 0.78 | tok/s 61414
step    460 | loss 1.9430 | lr 1.09e-04 | grad 0.68 | tok/s 61624
step    470 | loss 1.9210 | lr 6.65e-05 | grad 1.05 | tok/s 62363
step    480 | loss 1.8198 | lr 3.24e-05 | grad 0.62 | tok/s 60163
step    490 | loss 1.7709 | lr 9.84e-06 | grad 0.53 | tok/s 61260
step    500 | loss 2.7187 | lr 1.07e-06 | grad 1.05 | tok/s 63148
step    510 | loss 1.8261 | lr 6.94e-06 | grad 0.65 | tok/s 61753
step    520 | loss 1.8737 | lr 2.69e-05 | grad 0.55 | tok/s 63740
step    530 | loss 2.3488 | lr 5.89e-05 | grad 0.60 | tok/s 62332
step    540 | loss 1.8217 | lr 9.99e-05 | grad 1.10 | tok/s 62422
step    550 | loss 1.6909 | lr 1.46e-04 | grad 0.73 | tok/s 64046
step    560 | loss 1.5444 | lr 1.92e-04 | grad 0.74 | tok/s 64905
step    570 | loss 1.8382 | lr 2.35e-04 | grad 1.91 | tok/s 63344
step    580 | loss 2.1816 | lr 2.69e-04 | grad 1.05 | tok/s 62593
step    590 | loss 2.4648 | lr 2.91e-04 | grad 1.41 | tok/s 61293
step    600 | loss 1.9681 | lr 3.00e-04 | grad 1.43 | tok/s 61452
step    610 | loss 1.9836 | lr 2.94e-04 | grad 1.27 | tok/s 64375
step    620 | loss 1.8790 | lr 2.74e-04 | grad 0.86 | tok/s 61125
step    630 | loss 1.7991 | lr 2.42e-04 | grad 0.97 | tok/s 63061
step    640 | loss 2.1488 | lr 2.01e-04 | grad 0.88 | tok/s 63084
step    650 | loss 1.8166 | lr 1.55e-04 | grad 1.02 | tok/s 61888
step    660 | loss 2.1342 | lr 1.09e-04 | grad 4.50 | tok/s 61146
step    670 | loss 1.9464 | lr 6.65e-05 | grad 1.78 | tok/s 63140
step    680 | loss 1.9027 | lr 3.24e-05 | grad 1.03 | tok/s 61043
step    690 | loss 1.8936 | lr 9.84e-06 | grad 1.05 | tok/s 61515
step    700 | loss 1.9844 | lr 1.07e-06 | grad 1.10 | tok/s 61824
step    710 | loss 1.9181 | lr 6.94e-06 | grad 1.06 | tok/s 62052
step    720 | loss 2.0200 | lr 2.68e-05 | grad 1.37 | tok/s 61863
step    730 | loss 1.9790 | lr 5.89e-05 | grad 1.09 | tok/s 62504
step    740 | loss 1.9147 | lr 9.99e-05 | grad 1.75 | tok/s 61962
step    750 | loss 1.7069 | lr 1.46e-04 | grad 1.20 | tok/s 61232
step    760 | loss 2.1287 | lr 1.92e-04 | grad 0.69 | tok/s 62027
step    770 | loss 1.7592 | lr 2.35e-04 | grad 1.11 | tok/s 61558
step    780 | loss 1.8221 | lr 2.69e-04 | grad 1.30 | tok/s 62276
step    790 | loss 1.7674 | lr 2.91e-04 | grad 0.74 | tok/s 62767
step    800 | loss 1.7281 | lr 3.00e-04 | grad 0.95 | tok/s 62846
step    810 | loss 1.8526 | lr 2.94e-04 | grad 1.93 | tok/s 62208
step    820 | loss 2.5631 | lr 2.74e-04 | grad 1.68 | tok/s 63868
step    830 | loss 2.0282 | lr 2.42e-04 | grad 0.72 | tok/s 64813
step    840 | loss 1.7084 | lr 2.01e-04 | grad 0.56 | tok/s 64797
step    850 | loss 2.2528 | lr 1.55e-04 | grad 1.43 | tok/s 61686
step    860 | loss 1.9402 | lr 1.09e-04 | grad 1.02 | tok/s 60414
step    870 | loss 1.8310 | lr 6.65e-05 | grad 0.76 | tok/s 62262
step    880 | loss 1.9000 | lr 3.24e-05 | grad 1.15 | tok/s 61903
step    890 | loss 1.7933 | lr 9.84e-06 | grad 0.75 | tok/s 61865
step    900 | loss 2.2891 | lr 1.07e-06 | grad 0.97 | tok/s 60301
step    910 | loss 1.8474 | lr 6.94e-06 | grad 0.65 | tok/s 61384
step    920 | loss 1.8285 | lr 2.68e-05 | grad 0.68 | tok/s 61266
step    930 | loss 1.9518 | lr 5.89e-05 | grad 1.35 | tok/s 61024
step    940 | loss 1.8288 | lr 9.99e-05 | grad 1.40 | tok/s 60420
step    950 | loss 1.9002 | lr 1.46e-04 | grad 1.22 | tok/s 61874
step    960 | loss 1.6384 | lr 1.92e-04 | grad 0.69 | tok/s 64818
step    970 | loss 1.4491 | lr 2.35e-04 | grad 0.52 | tok/s 64863
step    980 | loss 1.6208 | lr 2.69e-04 | grad 2.27 | tok/s 63034
step    990 | loss 1.9748 | lr 2.91e-04 | grad 0.78 | tok/s 61285
step   1000 | loss 1.8207 | lr 3.00e-04 | grad 0.59 | tok/s 59815
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8207.pt
step   1010 | loss 2.0664 | lr 2.94e-04 | grad 1.78 | tok/s 48704
step   1020 | loss 1.6991 | lr 2.74e-04 | grad 0.79 | tok/s 61588
step   1030 | loss 2.0981 | lr 2.42e-04 | grad 0.80 | tok/s 60451
step   1040 | loss 1.7152 | lr 2.01e-04 | grad 1.14 | tok/s 61804
step   1050 | loss 1.7311 | lr 1.55e-04 | grad 0.70 | tok/s 61997
step   1060 | loss 1.9367 | lr 1.09e-04 | grad 1.23 | tok/s 62169
step   1070 | loss 2.0230 | lr 6.65e-05 | grad 0.80 | tok/s 62374
step   1080 | loss 2.3827 | lr 3.24e-05 | grad 0.91 | tok/s 61580
step   1090 | loss 2.0868 | lr 9.84e-06 | grad 0.79 | tok/s 61956
step   1100 | loss 1.7565 | lr 1.07e-06 | grad 0.74 | tok/s 61705
step   1110 | loss 1.7789 | lr 6.93e-06 | grad 0.70 | tok/s 62671
step   1120 | loss 1.9970 | lr 2.68e-05 | grad 0.81 | tok/s 63423
step   1130 | loss 1.7614 | lr 5.89e-05 | grad 0.62 | tok/s 60312
step   1140 | loss 1.6287 | lr 9.99e-05 | grad 0.64 | tok/s 61775
step   1150 | loss 1.9210 | lr 1.46e-04 | grad 1.05 | tok/s 61712
step   1160 | loss 1.5937 | lr 1.92e-04 | grad 0.57 | tok/s 61091
step   1170 | loss 1.9299 | lr 2.35e-04 | grad 0.75 | tok/s 61769
step   1180 | loss 1.6343 | lr 2.69e-04 | grad 0.77 | tok/s 64741
step   1190 | loss 1.4852 | lr 2.91e-04 | grad 0.58 | tok/s 64826
step   1200 | loss 1.3949 | lr 3.00e-04 | grad 0.66 | tok/s 64877
step   1210 | loss 1.3654 | lr 2.94e-04 | grad 0.70 | tok/s 64845
step   1220 | loss 1.4114 | lr 2.74e-04 | grad 0.73 | tok/s 64315
step   1230 | loss 1.6439 | lr 2.42e-04 | grad 0.83 | tok/s 62153
step   1240 | loss 1.7010 | lr 2.01e-04 | grad 0.86 | tok/s 61010
step   1250 | loss 1.8079 | lr 1.55e-04 | grad 2.72 | tok/s 62808
step   1260 | loss 1.8384 | lr 1.09e-04 | grad 2.27 | tok/s 62776
step   1270 | loss 1.8966 | lr 6.65e-05 | grad 1.16 | tok/s 61987
step   1280 | loss 1.7342 | lr 3.24e-05 | grad 0.74 | tok/s 61355
step   1290 | loss 1.6739 | lr 9.84e-06 | grad 0.78 | tok/s 61076
step   1300 | loss 1.7268 | lr 1.07e-06 | grad 0.73 | tok/s 60601
step   1310 | loss 1.8153 | lr 6.93e-06 | grad 0.74 | tok/s 60725
step   1320 | loss 1.7776 | lr 2.68e-05 | grad 1.03 | tok/s 61769
step   1330 | loss 1.7141 | lr 5.89e-05 | grad 0.57 | tok/s 61870
step   1340 | loss 1.6324 | lr 9.99e-05 | grad 0.83 | tok/s 61890
step   1350 | loss 1.6695 | lr 1.46e-04 | grad 1.49 | tok/s 63478
step   1360 | loss 1.6064 | lr 1.92e-04 | grad 0.66 | tok/s 60362
step   1370 | loss 1.7131 | lr 2.35e-04 | grad 0.70 | tok/s 61263
step   1380 | loss 1.8212 | lr 2.69e-04 | grad 0.84 | tok/s 61756
step   1390 | loss 1.7239 | lr 2.91e-04 | grad 1.38 | tok/s 60319
step   1400 | loss 1.7687 | lr 3.00e-04 | grad 6.44 | tok/s 62714
step   1410 | loss 1.7629 | lr 2.94e-04 | grad 1.12 | tok/s 63347
step   1420 | loss 1.8356 | lr 2.74e-04 | grad 0.91 | tok/s 60283
step   1430 | loss 1.6031 | lr 2.42e-04 | grad 0.85 | tok/s 58952
step   1440 | loss 1.5241 | lr 2.01e-04 | grad 0.65 | tok/s 62087
step   1450 | loss 1.5741 | lr 1.55e-04 | grad 1.86 | tok/s 63425
step   1460 | loss 1.6342 | lr 1.09e-04 | grad 0.52 | tok/s 59195
step   1470 | loss 1.7348 | lr 6.65e-05 | grad 1.70 | tok/s 61286
step   1480 | loss 1.5959 | lr 3.24e-05 | grad 1.57 | tok/s 61989
step   1490 | loss 1.7694 | lr 9.84e-06 | grad 2.12 | tok/s 61844
step   1500 | loss 1.8837 | lr 1.07e-06 | grad 1.98 | tok/s 60260
step   1510 | loss 1.7334 | lr 6.93e-06 | grad 0.96 | tok/s 63367
step   1520 | loss 1.7024 | lr 2.68e-05 | grad 1.05 | tok/s 62831
step   1530 | loss 1.6507 | lr 5.89e-05 | grad 0.53 | tok/s 62333
step   1540 | loss 1.6404 | lr 9.99e-05 | grad 0.50 | tok/s 61179
step   1550 | loss 1.6302 | lr 1.46e-04 | grad 2.31 | tok/s 63515
step   1560 | loss 2.2027 | lr 1.92e-04 | grad 1.05 | tok/s 61955
step   1570 | loss 1.6534 | lr 2.35e-04 | grad 1.08 | tok/s 60807
step   1580 | loss 1.8190 | lr 2.69e-04 | grad 0.96 | tok/s 62819
step   1590 | loss 1.5938 | lr 2.91e-04 | grad 0.70 | tok/s 61228
step   1600 | loss 1.7098 | lr 3.00e-04 | grad 0.85 | tok/s 60088
step   1610 | loss 1.5646 | lr 2.94e-04 | grad 0.70 | tok/s 63671
step   1620 | loss 1.7059 | lr 2.74e-04 | grad 0.66 | tok/s 62729
step   1630 | loss 1.7063 | lr 2.42e-04 | grad 0.82 | tok/s 63123
step   1640 | loss 1.6196 | lr 2.01e-04 | grad 0.62 | tok/s 61092
step   1650 | loss 1.6408 | lr 1.55e-04 | grad 1.03 | tok/s 60214
step   1660 | loss 1.6237 | lr 1.09e-04 | grad 0.62 | tok/s 60562
step   1670 | loss 1.6733 | lr 6.65e-05 | grad 1.66 | tok/s 63090
step   1680 | loss 2.0970 | lr 3.24e-05 | grad 0.49 | tok/s 63061
step   1690 | loss 1.6026 | lr 9.84e-06 | grad 0.84 | tok/s 61726
step   1700 | loss 1.9885 | lr 1.07e-06 | grad 0.51 | tok/s 62942
step   1710 | loss 1.6516 | lr 6.93e-06 | grad 0.85 | tok/s 61129
step   1720 | loss 1.6681 | lr 2.68e-05 | grad 0.77 | tok/s 61390
step   1730 | loss 1.7672 | lr 5.89e-05 | grad 0.69 | tok/s 61406
step   1740 | loss 1.6689 | lr 9.99e-05 | grad 0.59 | tok/s 62366
step   1750 | loss 1.5731 | lr 1.46e-04 | grad 0.50 | tok/s 60136
step   1760 | loss 1.8385 | lr 1.92e-04 | grad 0.62 | tok/s 60966
step   1770 | loss 1.7378 | lr 2.35e-04 | grad 0.57 | tok/s 62309
step   1780 | loss 1.6266 | lr 2.69e-04 | grad 1.00 | tok/s 60005
step   1790 | loss 1.8320 | lr 2.91e-04 | grad 0.75 | tok/s 61132
step   1800 | loss 1.5636 | lr 3.00e-04 | grad 0.68 | tok/s 62288
step   1810 | loss 1.6583 | lr 2.94e-04 | grad 0.84 | tok/s 61921
step   1820 | loss 1.6298 | lr 2.74e-04 | grad 0.79 | tok/s 61255
step   1830 | loss 1.6448 | lr 2.42e-04 | grad 0.72 | tok/s 61096
step   1840 | loss 1.6151 | lr 2.01e-04 | grad 0.80 | tok/s 60585
step   1850 | loss 1.8160 | lr 1.55e-04 | grad 0.90 | tok/s 61155
step   1860 | loss 1.5928 | lr 1.09e-04 | grad 0.48 | tok/s 61050
step   1870 | loss 1.6442 | lr 6.65e-05 | grad 1.23 | tok/s 62482
step   1880 | loss 1.5883 | lr 3.24e-05 | grad 0.55 | tok/s 62557
step   1890 | loss 1.6795 | lr 9.84e-06 | grad 0.54 | tok/s 61513
step   1900 | loss 1.7317 | lr 1.07e-06 | grad 1.34 | tok/s 62028
step   1910 | loss 1.6959 | lr 6.93e-06 | grad 1.12 | tok/s 61376
step   1920 | loss 1.6034 | lr 2.68e-05 | grad 0.93 | tok/s 63216
step   1930 | loss 1.5925 | lr 5.89e-05 | grad 0.88 | tok/s 62638
step   1940 | loss 1.5065 | lr 9.99e-05 | grad 0.62 | tok/s 63823
step   1950 | loss 1.5710 | lr 1.46e-04 | grad 0.77 | tok/s 62161
step   1960 | loss 1.9440 | lr 1.92e-04 | grad 3.92 | tok/s 63418
step   1970 | loss 1.6311 | lr 2.35e-04 | grad 1.30 | tok/s 61289
step   1980 | loss 1.6803 | lr 2.69e-04 | grad 1.87 | tok/s 61244
step   1990 | loss 1.7774 | lr 2.91e-04 | grad 0.96 | tok/s 62634
step   2000 | loss 1.7057 | lr 3.00e-04 | grad 1.13 | tok/s 63218
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7057.pt
step   2010 | loss 1.4459 | lr 2.94e-04 | grad 0.64 | tok/s 50778
step   2020 | loss 1.2840 | lr 2.74e-04 | grad 0.59 | tok/s 65037
step   2030 | loss 1.6069 | lr 2.42e-04 | grad 0.84 | tok/s 64303
step   2040 | loss 1.4260 | lr 2.01e-04 | grad 0.52 | tok/s 65008
step   2050 | loss 1.3815 | lr 1.55e-04 | grad 0.77 | tok/s 64061
step   2060 | loss 1.7085 | lr 1.09e-04 | grad 0.67 | tok/s 61184
step   2070 | loss 1.6384 | lr 6.65e-05 | grad 1.04 | tok/s 64270
step   2080 | loss 1.8022 | lr 3.24e-05 | grad 4.16 | tok/s 60777
step   2090 | loss 1.7179 | lr 9.84e-06 | grad 0.88 | tok/s 62960
step   2100 | loss 1.6502 | lr 1.07e-06 | grad 0.86 | tok/s 61085
step   2110 | loss 1.5281 | lr 6.93e-06 | grad 0.68 | tok/s 63237
step   2120 | loss 1.5319 | lr 2.68e-05 | grad 1.05 | tok/s 62685
step   2130 | loss 1.6282 | lr 5.89e-05 | grad 2.27 | tok/s 60818
step   2140 | loss 1.6887 | lr 9.99e-05 | grad 2.61 | tok/s 60832
step   2150 | loss 1.6932 | lr 1.46e-04 | grad 0.64 | tok/s 61677
step   2160 | loss 1.6396 | lr 1.92e-04 | grad 0.57 | tok/s 60920
step   2170 | loss 1.7410 | lr 2.35e-04 | grad 0.67 | tok/s 61688
step   2180 | loss 1.5965 | lr 2.69e-04 | grad 0.71 | tok/s 63025
step   2190 | loss 1.9156 | lr 2.91e-04 | grad 0.73 | tok/s 62801
step   2200 | loss 1.3741 | lr 3.00e-04 | grad 0.48 | tok/s 64898
step   2210 | loss 1.3372 | lr 2.94e-04 | grad 0.46 | tok/s 64956
step   2220 | loss 1.2919 | lr 2.74e-04 | grad 0.48 | tok/s 64993
step   2230 | loss 1.5672 | lr 2.42e-04 | grad 0.78 | tok/s 62746
step   2240 | loss 1.8352 | lr 2.01e-04 | grad 1.64 | tok/s 64158
step   2250 | loss 1.6987 | lr 1.55e-04 | grad 0.90 | tok/s 63595
step   2260 | loss 1.7587 | lr 1.09e-04 | grad 0.75 | tok/s 62708
step   2270 | loss 1.5735 | lr 6.65e-05 | grad 0.88 | tok/s 61377
step   2280 | loss 1.7296 | lr 3.24e-05 | grad 0.57 | tok/s 61380
step   2290 | loss 1.5508 | lr 9.84e-06 | grad 0.64 | tok/s 62182
step   2300 | loss 1.5584 | lr 1.07e-06 | grad 0.55 | tok/s 60090
step   2310 | loss 1.6525 | lr 6.93e-06 | grad 0.93 | tok/s 63915
step   2320 | loss 1.7272 | lr 2.68e-05 | grad 0.95 | tok/s 65044
step   2330 | loss 1.6587 | lr 5.89e-05 | grad 0.57 | tok/s 64944
step   2340 | loss 1.6178 | lr 9.98e-05 | grad 0.88 | tok/s 63559
step   2350 | loss 1.6755 | lr 1.46e-04 | grad 0.67 | tok/s 61670

Training complete! Final step: 2359
