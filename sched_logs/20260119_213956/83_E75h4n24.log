# Job 83: E75h4n24
# GPU: 0
# Command: python train.py --level E75h4n24 --dim 1408 --expansion 2.0 --n_state 24 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/E75h4n24
# Started: 2026-01-19T23:11:35.477580
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/E75h4n24/levelE75h4n24_100m_20260119_231140
Auto r_h_mode: none (level 0 has bounded/no W_h)
Model: Level E75h4n24, 104,020,736 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.6503 | lr 2.70e-05 | grad 1672.00 | tok/s 23738
step     20 | loss 5.4162 | lr 5.70e-05 | grad 81.50 | tok/s 70536
step     30 | loss 5.2547 | lr 8.70e-05 | grad 26.12 | tok/s 74569
step     40 | loss 4.7215 | lr 1.17e-04 | grad 10.25 | tok/s 74680
step     50 | loss 4.0900 | lr 1.47e-04 | grad 8.81 | tok/s 74702
step     60 | loss 3.8097 | lr 1.77e-04 | grad 11.75 | tok/s 73185
step     70 | loss 3.0564 | lr 2.07e-04 | grad 3.22 | tok/s 70688
step     80 | loss 3.3410 | lr 2.37e-04 | grad 5.28 | tok/s 73036
step     90 | loss 3.1011 | lr 2.67e-04 | grad 4.66 | tok/s 70843
step    100 | loss 2.7460 | lr 2.97e-04 | grad 1.66 | tok/s 71374
step    110 | loss 2.7225 | lr 6.94e-06 | grad 2.59 | tok/s 64627
step    120 | loss 3.1158 | lr 2.69e-05 | grad 1.95 | tok/s 65226
step    130 | loss 2.8177 | lr 5.89e-05 | grad 1.50 | tok/s 66634
step    140 | loss 2.5538 | lr 9.99e-05 | grad 1.13 | tok/s 66771
step    150 | loss 2.4627 | lr 1.46e-04 | grad 2.34 | tok/s 63676
step    160 | loss 2.3136 | lr 1.92e-04 | grad 1.66 | tok/s 64282
step    170 | loss 2.5223 | lr 2.35e-04 | grad 5.44 | tok/s 66367
step    180 | loss 2.5424 | lr 2.69e-04 | grad 1.45 | tok/s 66587
step    190 | loss 2.2756 | lr 2.91e-04 | grad 1.59 | tok/s 67570
step    200 | loss 1.9441 | lr 3.00e-04 | grad 1.26 | tok/s 68988
step    210 | loss 2.4680 | lr 2.94e-04 | grad 2.20 | tok/s 66049
step    220 | loss 2.4173 | lr 2.74e-04 | grad 1.45 | tok/s 68131
step    230 | loss 2.2741 | lr 2.42e-04 | grad 1.57 | tok/s 65962
step    240 | loss 2.2462 | lr 2.01e-04 | grad 1.82 | tok/s 67227
step    250 | loss 2.1937 | lr 1.55e-04 | grad 1.27 | tok/s 66216
step    260 | loss 2.2243 | lr 1.09e-04 | grad 0.82 | tok/s 63662
step    270 | loss 2.0783 | lr 6.65e-05 | grad 1.02 | tok/s 65983
step    280 | loss 1.9927 | lr 3.24e-05 | grad 1.72 | tok/s 65898
step    290 | loss 1.9781 | lr 9.84e-06 | grad 0.89 | tok/s 69145
step    300 | loss 1.9434 | lr 1.07e-06 | grad 0.86 | tok/s 69299
step    310 | loss 1.9561 | lr 6.94e-06 | grad 0.78 | tok/s 69227
step    320 | loss 2.0463 | lr 2.69e-05 | grad 2.41 | tok/s 66817
step    330 | loss 2.0785 | lr 5.89e-05 | grad 0.71 | tok/s 65141
step    340 | loss 2.0849 | lr 9.99e-05 | grad 1.98 | tok/s 66452
step    350 | loss 2.1128 | lr 1.46e-04 | grad 0.99 | tok/s 64632
step    360 | loss 2.0747 | lr 1.92e-04 | grad 2.47 | tok/s 65366
step    370 | loss 1.9212 | lr 2.35e-04 | grad 1.38 | tok/s 66698
step    380 | loss 2.4746 | lr 2.69e-04 | grad 1.36 | tok/s 68043
step    390 | loss 2.0657 | lr 2.91e-04 | grad 1.48 | tok/s 65854
step    400 | loss 2.1699 | lr 3.00e-04 | grad 3.14 | tok/s 67447
step    410 | loss 1.9299 | lr 2.94e-04 | grad 1.89 | tok/s 65592
step    420 | loss 2.0373 | lr 2.74e-04 | grad 1.20 | tok/s 65067
step    430 | loss 2.2000 | lr 2.42e-04 | grad 1.37 | tok/s 64631
step    440 | loss 2.3107 | lr 2.01e-04 | grad 1.09 | tok/s 67301
step    450 | loss 1.9698 | lr 1.55e-04 | grad 0.95 | tok/s 65548
step    460 | loss 1.9555 | lr 1.09e-04 | grad 0.64 | tok/s 65834
step    470 | loss 1.9329 | lr 6.65e-05 | grad 1.04 | tok/s 66513
step    480 | loss 1.8263 | lr 3.24e-05 | grad 0.63 | tok/s 64354
step    490 | loss 1.7831 | lr 9.84e-06 | grad 0.58 | tok/s 65462
step    500 | loss 2.7501 | lr 1.07e-06 | grad 0.99 | tok/s 67296
step    510 | loss 1.8371 | lr 6.94e-06 | grad 0.68 | tok/s 66010
step    520 | loss 1.9070 | lr 2.69e-05 | grad 0.58 | tok/s 67970
step    530 | loss 2.3733 | lr 5.89e-05 | grad 0.59 | tok/s 66658
step    540 | loss 1.8391 | lr 9.99e-05 | grad 1.15 | tok/s 66703
step    550 | loss 1.6966 | lr 1.46e-04 | grad 0.74 | tok/s 68267
step    560 | loss 1.5497 | lr 1.92e-04 | grad 0.75 | tok/s 69334
step    570 | loss 1.8770 | lr 2.35e-04 | grad 2.16 | tok/s 67558
step    580 | loss 2.2345 | lr 2.69e-04 | grad 1.22 | tok/s 66778
step    590 | loss 2.4860 | lr 2.91e-04 | grad 1.61 | tok/s 65503
step    600 | loss 2.0673 | lr 3.00e-04 | grad 1.45 | tok/s 65741
step    610 | loss 2.0068 | lr 2.94e-04 | grad 1.27 | tok/s 68649
step    620 | loss 1.9207 | lr 2.74e-04 | grad 1.09 | tok/s 65292
step    630 | loss 1.8217 | lr 2.42e-04 | grad 1.02 | tok/s 67177
step    640 | loss 2.2358 | lr 2.01e-04 | grad 0.91 | tok/s 67359
step    650 | loss 1.8352 | lr 1.55e-04 | grad 1.09 | tok/s 66003
step    660 | loss 2.1682 | lr 1.09e-04 | grad 4.56 | tok/s 65277
step    670 | loss 1.9761 | lr 6.65e-05 | grad 1.66 | tok/s 67420
step    680 | loss 1.9323 | lr 3.24e-05 | grad 1.14 | tok/s 65136
step    690 | loss 1.9272 | lr 9.84e-06 | grad 1.20 | tok/s 65597
step    700 | loss 2.0072 | lr 1.07e-06 | grad 1.17 | tok/s 65919
step    710 | loss 1.9694 | lr 6.94e-06 | grad 1.12 | tok/s 66386
step    720 | loss 2.0446 | lr 2.68e-05 | grad 1.67 | tok/s 66046
step    730 | loss 2.0109 | lr 5.89e-05 | grad 1.12 | tok/s 66727
step    740 | loss 1.9426 | lr 9.99e-05 | grad 2.14 | tok/s 66069
step    750 | loss 1.7373 | lr 1.46e-04 | grad 1.35 | tok/s 65412
step    760 | loss 2.2010 | lr 1.92e-04 | grad 0.71 | tok/s 66208
step    770 | loss 1.7931 | lr 2.35e-04 | grad 1.17 | tok/s 65823
step    780 | loss 1.8438 | lr 2.69e-04 | grad 1.13 | tok/s 66584
step    790 | loss 1.7903 | lr 2.91e-04 | grad 0.79 | tok/s 66969
step    800 | loss 1.7912 | lr 3.00e-04 | grad 1.02 | tok/s 67098
step    810 | loss 1.9182 | lr 2.94e-04 | grad 2.41 | tok/s 66461
step    820 | loss 2.5876 | lr 2.74e-04 | grad 1.56 | tok/s 68050
step    830 | loss 2.0185 | lr 2.42e-04 | grad 0.79 | tok/s 69121
step    840 | loss 1.7094 | lr 2.01e-04 | grad 0.56 | tok/s 69091
step    850 | loss 2.3233 | lr 1.55e-04 | grad 1.31 | tok/s 65836
step    860 | loss 1.9715 | lr 1.09e-04 | grad 1.09 | tok/s 64575
step    870 | loss 1.8641 | lr 6.65e-05 | grad 0.80 | tok/s 66415
step    880 | loss 1.9271 | lr 3.24e-05 | grad 1.17 | tok/s 66179
step    890 | loss 1.8214 | lr 9.84e-06 | grad 0.80 | tok/s 65987
step    900 | loss 2.3361 | lr 1.07e-06 | grad 0.93 | tok/s 64506
step    910 | loss 1.8833 | lr 6.94e-06 | grad 0.68 | tok/s 65470
step    920 | loss 1.8464 | lr 2.68e-05 | grad 0.69 | tok/s 65389
step    930 | loss 1.9801 | lr 5.89e-05 | grad 1.34 | tok/s 65070
step    940 | loss 1.8446 | lr 9.99e-05 | grad 1.52 | tok/s 64684
step    950 | loss 1.9203 | lr 1.46e-04 | grad 1.17 | tok/s 65991
step    960 | loss 1.6442 | lr 1.92e-04 | grad 0.62 | tok/s 69228
step    970 | loss 1.4603 | lr 2.35e-04 | grad 0.53 | tok/s 69111
step    980 | loss 1.6404 | lr 2.69e-04 | grad 1.85 | tok/s 67149
step    990 | loss 2.0106 | lr 2.91e-04 | grad 0.77 | tok/s 65624
step   1000 | loss 1.8537 | lr 3.00e-04 | grad 0.62 | tok/s 63941
  >>> saved checkpoint: checkpoint_step_001000_loss_1.8537.pt
step   1010 | loss 2.1256 | lr 2.94e-04 | grad 2.50 | tok/s 50082
step   1020 | loss 1.7509 | lr 2.74e-04 | grad 0.81 | tok/s 65713
step   1030 | loss 2.1107 | lr 2.42e-04 | grad 0.78 | tok/s 64640
step   1040 | loss 1.7342 | lr 2.01e-04 | grad 1.23 | tok/s 65961
step   1050 | loss 1.7464 | lr 1.55e-04 | grad 0.72 | tok/s 66270
step   1060 | loss 2.0039 | lr 1.09e-04 | grad 1.62 | tok/s 66484
step   1070 | loss 2.0553 | lr 6.65e-05 | grad 0.80 | tok/s 66514
step   1080 | loss 2.4033 | lr 3.24e-05 | grad 1.09 | tok/s 65693
step   1090 | loss 2.1051 | lr 9.84e-06 | grad 0.82 | tok/s 66315
step   1100 | loss 1.7813 | lr 1.07e-06 | grad 0.75 | tok/s 65885
step   1110 | loss 1.8379 | lr 6.93e-06 | grad 0.71 | tok/s 66940
step   1120 | loss 2.0088 | lr 2.68e-05 | grad 0.96 | tok/s 67701
step   1130 | loss 1.7893 | lr 5.89e-05 | grad 0.62 | tok/s 64254
step   1140 | loss 1.6456 | lr 9.99e-05 | grad 0.70 | tok/s 65923
step   1150 | loss 1.9377 | lr 1.46e-04 | grad 1.07 | tok/s 65858
step   1160 | loss 1.6203 | lr 1.92e-04 | grad 0.58 | tok/s 65242
step   1170 | loss 2.0744 | lr 2.35e-04 | grad 0.79 | tok/s 66028
step   1180 | loss 1.6479 | lr 2.69e-04 | grad 0.74 | tok/s 69118
step   1190 | loss 1.5006 | lr 2.91e-04 | grad 0.62 | tok/s 69124
step   1200 | loss 1.4096 | lr 3.00e-04 | grad 0.61 | tok/s 69202
step   1210 | loss 1.3811 | lr 2.94e-04 | grad 0.77 | tok/s 69159
step   1220 | loss 1.4342 | lr 2.74e-04 | grad 0.82 | tok/s 68594
step   1230 | loss 1.6720 | lr 2.42e-04 | grad 0.91 | tok/s 66379
step   1240 | loss 1.7392 | lr 2.01e-04 | grad 0.89 | tok/s 65126
step   1250 | loss 1.8359 | lr 1.55e-04 | grad 3.03 | tok/s 67104
step   1260 | loss 1.8729 | lr 1.09e-04 | grad 2.19 | tok/s 67155
step   1270 | loss 1.9424 | lr 6.65e-05 | grad 1.25 | tok/s 66139
step   1280 | loss 1.7671 | lr 3.24e-05 | grad 0.80 | tok/s 65535
step   1290 | loss 1.7053 | lr 9.84e-06 | grad 0.78 | tok/s 65209
step   1300 | loss 1.7535 | lr 1.07e-06 | grad 0.77 | tok/s 64875
step   1310 | loss 1.8314 | lr 6.93e-06 | grad 0.75 | tok/s 64858
step   1320 | loss 1.8204 | lr 2.68e-05 | grad 1.07 | tok/s 66036
step   1330 | loss 1.7472 | lr 5.89e-05 | grad 0.62 | tok/s 65933
step   1340 | loss 1.6591 | lr 9.99e-05 | grad 0.93 | tok/s 66052
step   1350 | loss 1.7028 | lr 1.46e-04 | grad 1.58 | tok/s 67707
step   1360 | loss 1.6357 | lr 1.92e-04 | grad 0.69 | tok/s 64496
step   1370 | loss 1.7534 | lr 2.35e-04 | grad 0.83 | tok/s 65485
step   1380 | loss 1.8535 | lr 2.69e-04 | grad 0.89 | tok/s 65996
step   1390 | loss 1.7498 | lr 2.91e-04 | grad 1.42 | tok/s 64417
step   1400 | loss 1.7636 | lr 3.00e-04 | grad 3.94 | tok/s 66998
step   1410 | loss 1.7792 | lr 2.94e-04 | grad 1.13 | tok/s 67600
step   1420 | loss 1.8546 | lr 2.74e-04 | grad 0.91 | tok/s 64440
step   1430 | loss 1.6337 | lr 2.42e-04 | grad 1.13 | tok/s 62946
step   1440 | loss 1.5513 | lr 2.01e-04 | grad 0.67 | tok/s 66281
step   1450 | loss 1.5912 | lr 1.55e-04 | grad 1.94 | tok/s 67735
step   1460 | loss 1.6623 | lr 1.09e-04 | grad 0.56 | tok/s 63279
step   1470 | loss 1.7682 | lr 6.65e-05 | grad 2.30 | tok/s 65440
step   1480 | loss 1.6214 | lr 3.24e-05 | grad 1.70 | tok/s 66326
step   1490 | loss 1.8090 | lr 9.84e-06 | grad 2.09 | tok/s 66209
step   1500 | loss 1.9000 | lr 1.07e-06 | grad 1.84 | tok/s 64457
step   1510 | loss 1.7768 | lr 6.93e-06 | grad 1.09 | tok/s 67518
step   1520 | loss 1.7409 | lr 2.68e-05 | grad 1.05 | tok/s 67151
step   1530 | loss 1.6782 | lr 5.89e-05 | grad 0.55 | tok/s 66541
step   1540 | loss 1.6657 | lr 9.99e-05 | grad 0.51 | tok/s 65289
step   1550 | loss 1.6512 | lr 1.46e-04 | grad 2.23 | tok/s 67888
step   1560 | loss 2.2566 | lr 1.92e-04 | grad 1.15 | tok/s 66190
step   1570 | loss 1.6758 | lr 2.35e-04 | grad 1.09 | tok/s 64946
step   1580 | loss 1.8480 | lr 2.69e-04 | grad 0.99 | tok/s 67077
step   1590 | loss 1.6343 | lr 2.91e-04 | grad 0.75 | tok/s 65531
step   1600 | loss 1.7345 | lr 3.00e-04 | grad 0.84 | tok/s 64160
step   1610 | loss 1.5754 | lr 2.94e-04 | grad 0.68 | tok/s 68086
step   1620 | loss 1.7285 | lr 2.74e-04 | grad 0.64 | tok/s 66975
step   1630 | loss 1.7423 | lr 2.42e-04 | grad 0.85 | tok/s 67473
step   1640 | loss 1.6559 | lr 2.01e-04 | grad 0.60 | tok/s 65115
step   1650 | loss 1.6722 | lr 1.55e-04 | grad 1.09 | tok/s 64368
step   1660 | loss 1.6593 | lr 1.09e-04 | grad 0.68 | tok/s 64636
step   1670 | loss 1.7166 | lr 6.65e-05 | grad 1.81 | tok/s 67451
step   1680 | loss 2.0773 | lr 3.24e-05 | grad 0.52 | tok/s 67408
step   1690 | loss 1.6390 | lr 9.84e-06 | grad 0.88 | tok/s 65799
step   1700 | loss 2.0757 | lr 1.07e-06 | grad 0.52 | tok/s 67379
step   1710 | loss 1.6806 | lr 6.93e-06 | grad 0.83 | tok/s 65537
step   1720 | loss 1.7060 | lr 2.68e-05 | grad 0.78 | tok/s 65905
step   1730 | loss 1.7975 | lr 5.89e-05 | grad 0.71 | tok/s 65741
step   1740 | loss 1.6969 | lr 9.99e-05 | grad 0.62 | tok/s 66768
step   1750 | loss 1.5992 | lr 1.46e-04 | grad 0.52 | tok/s 64478
step   1760 | loss 1.9004 | lr 1.92e-04 | grad 0.64 | tok/s 65400
step   1770 | loss 1.7804 | lr 2.35e-04 | grad 0.62 | tok/s 66812
step   1780 | loss 1.6548 | lr 2.69e-04 | grad 1.04 | tok/s 64403
step   1790 | loss 1.8857 | lr 2.91e-04 | grad 0.79 | tok/s 65476
step   1800 | loss 1.5853 | lr 3.00e-04 | grad 0.67 | tok/s 66703
step   1810 | loss 1.6823 | lr 2.94e-04 | grad 0.91 | tok/s 66396
step   1820 | loss 1.6454 | lr 2.74e-04 | grad 0.77 | tok/s 65638
step   1830 | loss 1.6803 | lr 2.42e-04 | grad 0.70 | tok/s 65452
step   1840 | loss 1.6373 | lr 2.01e-04 | grad 0.84 | tok/s 64990
step   1850 | loss 1.8474 | lr 1.55e-04 | grad 0.93 | tok/s 65478
step   1860 | loss 1.6169 | lr 1.09e-04 | grad 0.51 | tok/s 65325
step   1870 | loss 1.6772 | lr 6.65e-05 | grad 1.41 | tok/s 66887
step   1880 | loss 1.6076 | lr 3.24e-05 | grad 0.55 | tok/s 66953
step   1890 | loss 1.7049 | lr 9.84e-06 | grad 0.55 | tok/s 65886
step   1900 | loss 1.7897 | lr 1.07e-06 | grad 1.50 | tok/s 66410
step   1910 | loss 1.7158 | lr 6.93e-06 | grad 1.06 | tok/s 65715
step   1920 | loss 1.6346 | lr 2.68e-05 | grad 0.93 | tok/s 67691
step   1930 | loss 1.6205 | lr 5.89e-05 | grad 0.90 | tok/s 67056
step   1940 | loss 1.5245 | lr 9.99e-05 | grad 0.66 | tok/s 68340
step   1950 | loss 1.5914 | lr 1.46e-04 | grad 0.79 | tok/s 66558
step   1960 | loss 1.9999 | lr 1.92e-04 | grad 4.31 | tok/s 67938
step   1970 | loss 1.6927 | lr 2.35e-04 | grad 1.53 | tok/s 65707
step   1980 | loss 1.7120 | lr 2.69e-04 | grad 1.95 | tok/s 65645
step   1990 | loss 1.8143 | lr 2.91e-04 | grad 1.02 | tok/s 67104
step   2000 | loss 1.7481 | lr 3.00e-04 | grad 1.27 | tok/s 67660
  >>> saved checkpoint: checkpoint_step_002000_loss_1.7481.pt
step   2010 | loss 1.4690 | lr 2.94e-04 | grad 0.67 | tok/s 52821
step   2020 | loss 1.3035 | lr 2.74e-04 | grad 0.63 | tok/s 69696
step   2030 | loss 1.6371 | lr 2.42e-04 | grad 0.91 | tok/s 68911
step   2040 | loss 1.4481 | lr 2.01e-04 | grad 0.54 | tok/s 69630
step   2050 | loss 1.3980 | lr 1.55e-04 | grad 0.79 | tok/s 68545
step   2060 | loss 1.7234 | lr 1.09e-04 | grad 0.68 | tok/s 65581
step   2070 | loss 1.6505 | lr 6.65e-05 | grad 1.15 | tok/s 68781
step   2080 | loss 1.8140 | lr 3.24e-05 | grad 3.25 | tok/s 65138
step   2090 | loss 1.7361 | lr 9.84e-06 | grad 0.91 | tok/s 67392
step   2100 | loss 1.6773 | lr 1.07e-06 | grad 0.89 | tok/s 65626
step   2110 | loss 1.5627 | lr 6.93e-06 | grad 0.70 | tok/s 67823
step   2120 | loss 1.5665 | lr 2.68e-05 | grad 1.06 | tok/s 67302
step   2130 | loss 1.6574 | lr 5.89e-05 | grad 2.50 | tok/s 65257
step   2140 | loss 1.7055 | lr 9.99e-05 | grad 2.59 | tok/s 65201
step   2150 | loss 1.7100 | lr 1.46e-04 | grad 0.55 | tok/s 66168
step   2160 | loss 1.6617 | lr 1.92e-04 | grad 0.60 | tok/s 65343
step   2170 | loss 1.7832 | lr 2.35e-04 | grad 0.68 | tok/s 66096
step   2180 | loss 1.6328 | lr 2.69e-04 | grad 0.76 | tok/s 67426
step   2190 | loss 1.9591 | lr 2.91e-04 | grad 0.71 | tok/s 67325
step   2200 | loss 1.3943 | lr 3.00e-04 | grad 0.50 | tok/s 69497
step   2210 | loss 1.3616 | lr 2.94e-04 | grad 0.49 | tok/s 69506
step   2220 | loss 1.3149 | lr 2.74e-04 | grad 0.50 | tok/s 69587
step   2230 | loss 1.6021 | lr 2.42e-04 | grad 0.80 | tok/s 67223
step   2240 | loss 1.8706 | lr 2.01e-04 | grad 1.95 | tok/s 68665
step   2250 | loss 1.7500 | lr 1.55e-04 | grad 0.88 | tok/s 68185
step   2260 | loss 1.8043 | lr 1.09e-04 | grad 0.82 | tok/s 67188
step   2270 | loss 1.6014 | lr 6.65e-05 | grad 0.86 | tok/s 65778
step   2280 | loss 1.7620 | lr 3.24e-05 | grad 0.62 | tok/s 65819
step   2290 | loss 1.5900 | lr 9.84e-06 | grad 0.65 | tok/s 66660
step   2300 | loss 1.5986 | lr 1.07e-06 | grad 0.57 | tok/s 64417
step   2310 | loss 1.6786 | lr 6.93e-06 | grad 0.95 | tok/s 68595
step   2320 | loss 1.7583 | lr 2.68e-05 | grad 0.99 | tok/s 69513
step   2330 | loss 1.6877 | lr 5.89e-05 | grad 0.61 | tok/s 69646
step   2340 | loss 1.6591 | lr 9.98e-05 | grad 0.93 | tok/s 67959
step   2350 | loss 1.6999 | lr 1.46e-04 | grad 0.73 | tok/s 65975
step   2360 | loss 2.1304 | lr 1.92e-04 | grad 1.30 | tok/s 67223
step   2370 | loss 1.6954 | lr 2.35e-04 | grad 0.60 | tok/s 66854
step   2380 | loss 1.5398 | lr 2.69e-04 | grad 0.82 | tok/s 66132
step   2390 | loss 1.5907 | lr 2.91e-04 | grad 0.96 | tok/s 65957
step   2400 | loss 1.7561 | lr 3.00e-04 | grad 0.88 | tok/s 65349
step   2410 | loss 1.6548 | lr 2.94e-04 | grad 0.88 | tok/s 65771
step   2420 | loss 1.8429 | lr 2.74e-04 | grad 0.67 | tok/s 66357
step   2430 | loss 1.7573 | lr 2.42e-04 | grad 1.07 | tok/s 65537
step   2440 | loss 1.7733 | lr 2.01e-04 | grad 0.77 | tok/s 67320
step   2450 | loss 1.4938 | lr 1.55e-04 | grad 1.31 | tok/s 66452
step   2460 | loss 1.7861 | lr 1.09e-04 | grad 1.85 | tok/s 67737
step   2470 | loss 1.9899 | lr 6.65e-05 | grad 1.22 | tok/s 68910
step   2480 | loss 1.5814 | lr 3.24e-05 | grad 0.64 | tok/s 66438
step   2490 | loss 1.5069 | lr 9.84e-06 | grad 0.91 | tok/s 65643
step   2500 | loss 1.6073 | lr 1.07e-06 | grad 0.76 | tok/s 67299
step   2510 | loss 1.6863 | lr 6.93e-06 | grad 0.75 | tok/s 67138
step   2520 | loss 1.8625 | lr 2.68e-05 | grad 1.17 | tok/s 65500

Training complete! Final step: 2521
