# Job 77: 75
# GPU: 5
# Command: python train.py --level 75 --dim 1408 --expansion 2.0 --n_state 96 --data data/pile.txt --depth 20 --batch_size 32 --chunk_size 512 --lr 3e-4 --warmup_steps 100 --seed 42 --bf16 --train_minutes 10 --output benchmark_results/all_models_20260119_213946/75
# Started: 2026-01-19T23:01:29.609769
============================================================

Using device: cuda
Output directory: benchmark_results/all_models_20260119_213946/75/level75_100m_20260119_230134
Auto r_h_mode: none (level 75 has bounded/no W_h)
Model: Level 75, 104,020,736 parameters

Starting training from step 0...
Batch size: 32, Chunk size: 512
Gradient accumulation: 1, Effective batch: 32

Time-based training: 10.0 minutes
step     10 | loss 5.7109 | lr 2.70e-05 | grad 280.00 | tok/s 14566
step     20 | loss 5.4227 | lr 5.70e-05 | grad 79.00 | tok/s 24471
step     30 | loss 5.1772 | lr 8.70e-05 | grad 18.88 | tok/s 25915
step     40 | loss 4.5531 | lr 1.17e-04 | grad 9.56 | tok/s 25909
step     50 | loss 3.9295 | lr 1.47e-04 | grad 7.06 | tok/s 25912
step     60 | loss 3.8267 | lr 1.77e-04 | grad 8.75 | tok/s 25381
step     70 | loss 3.3872 | lr 2.07e-04 | grad 1.91 | tok/s 24518
step     80 | loss 3.5423 | lr 2.37e-04 | grad 4.09 | tok/s 25462
step     90 | loss 3.3184 | lr 2.67e-04 | grad 4.72 | tok/s 24494
step    100 | loss 2.9734 | lr 2.97e-04 | grad 2.02 | tok/s 24717
step    110 | loss 2.9674 | lr 6.94e-06 | grad 3.44 | tok/s 23736
step    120 | loss 3.2684 | lr 2.69e-05 | grad 2.52 | tok/s 23546
step    130 | loss 3.0259 | lr 5.89e-05 | grad 1.63 | tok/s 24096
step    140 | loss 2.7949 | lr 9.99e-05 | grad 1.64 | tok/s 24145
step    150 | loss 2.6325 | lr 1.46e-04 | grad 2.66 | tok/s 23040
step    160 | loss 2.4707 | lr 1.92e-04 | grad 1.63 | tok/s 23234
step    170 | loss 2.6379 | lr 2.35e-04 | grad 5.28 | tok/s 24055
step    180 | loss 2.6733 | lr 2.69e-04 | grad 1.86 | tok/s 24129
step    190 | loss 2.4344 | lr 2.91e-04 | grad 1.57 | tok/s 24511
step    200 | loss 2.1164 | lr 3.00e-04 | grad 1.32 | tok/s 25066
step    210 | loss 2.5608 | lr 2.94e-04 | grad 2.14 | tok/s 24015
step    220 | loss 2.4956 | lr 2.74e-04 | grad 1.15 | tok/s 24805
step    230 | loss 2.2782 | lr 2.42e-04 | grad 1.61 | tok/s 23961
step    240 | loss 2.3236 | lr 2.01e-04 | grad 1.75 | tok/s 24437
step    250 | loss 2.2369 | lr 1.55e-04 | grad 1.41 | tok/s 24089
step    260 | loss 2.2440 | lr 1.09e-04 | grad 0.87 | tok/s 23127
step    270 | loss 2.1144 | lr 6.65e-05 | grad 1.30 | tok/s 23997
step    280 | loss 2.0528 | lr 3.24e-05 | grad 1.64 | tok/s 23966
step    290 | loss 2.0170 | lr 9.84e-06 | grad 0.88 | tok/s 25256
step    300 | loss 1.9878 | lr 1.07e-06 | grad 0.84 | tok/s 25274
step    310 | loss 2.0005 | lr 6.94e-06 | grad 0.77 | tok/s 25266
step    320 | loss 2.0865 | lr 2.69e-05 | grad 2.03 | tok/s 24321
step    330 | loss 2.1198 | lr 5.89e-05 | grad 0.75 | tok/s 23736
step    340 | loss 2.1353 | lr 9.99e-05 | grad 1.77 | tok/s 24244
step    350 | loss 2.1552 | lr 1.46e-04 | grad 1.02 | tok/s 23544
step    360 | loss 2.1150 | lr 1.92e-04 | grad 2.55 | tok/s 23839
step    370 | loss 1.9776 | lr 2.35e-04 | grad 1.16 | tok/s 24288
step    380 | loss 2.5306 | lr 2.69e-04 | grad 1.30 | tok/s 24916
step    390 | loss 2.0846 | lr 2.91e-04 | grad 1.55 | tok/s 23996
step    400 | loss 2.1992 | lr 3.00e-04 | grad 3.62 | tok/s 24617
step    410 | loss 1.9324 | lr 2.94e-04 | grad 2.08 | tok/s 23856
step    420 | loss 2.0403 | lr 2.74e-04 | grad 1.09 | tok/s 23704
step    430 | loss 2.2148 | lr 2.42e-04 | grad 1.45 | tok/s 23614
step    440 | loss 2.2934 | lr 2.01e-04 | grad 1.12 | tok/s 24550
step    450 | loss 1.9805 | lr 1.55e-04 | grad 0.77 | tok/s 23893
step    460 | loss 1.9713 | lr 1.09e-04 | grad 0.74 | tok/s 23984
step    470 | loss 1.9484 | lr 6.65e-05 | grad 0.99 | tok/s 24266
step    480 | loss 1.8425 | lr 3.24e-05 | grad 0.61 | tok/s 23407
step    490 | loss 1.7996 | lr 9.84e-06 | grad 0.56 | tok/s 23826
step    500 | loss 2.7496 | lr 1.07e-06 | grad 1.05 | tok/s 24569
step    510 | loss 1.8335 | lr 6.94e-06 | grad 0.64 | tok/s 24019
step    520 | loss 1.8916 | lr 2.69e-05 | grad 0.55 | tok/s 24794
step    530 | loss 2.3678 | lr 5.89e-05 | grad 0.63 | tok/s 24272
step    540 | loss 1.8355 | lr 9.99e-05 | grad 1.02 | tok/s 24226
step    550 | loss 1.7178 | lr 1.46e-04 | grad 0.72 | tok/s 24929
step    560 | loss 1.5764 | lr 1.92e-04 | grad 0.68 | tok/s 25259
step    570 | loss 1.8922 | lr 2.35e-04 | grad 2.25 | tok/s 24682
step    580 | loss 2.2427 | lr 2.69e-04 | grad 1.15 | tok/s 24347
step    590 | loss 2.4925 | lr 2.91e-04 | grad 1.35 | tok/s 23855
step    600 | loss 2.0047 | lr 3.00e-04 | grad 1.40 | tok/s 23921
step    610 | loss 2.0332 | lr 2.94e-04 | grad 1.19 | tok/s 25068
step    620 | loss 1.9060 | lr 2.74e-04 | grad 0.84 | tok/s 23786
step    630 | loss 1.8138 | lr 2.42e-04 | grad 0.91 | tok/s 24543
step    640 | loss 2.2463 | lr 2.01e-04 | grad 1.01 | tok/s 24565
step    650 | loss 1.8313 | lr 1.55e-04 | grad 1.08 | tok/s 24092
step    660 | loss 2.1371 | lr 1.09e-04 | grad 4.38 | tok/s 23786
step    670 | loss 1.9643 | lr 6.65e-05 | grad 1.65 | tok/s 24618
step    680 | loss 1.9314 | lr 3.24e-05 | grad 0.97 | tok/s 23742
step    690 | loss 1.9233 | lr 9.84e-06 | grad 1.05 | tok/s 23934
step    700 | loss 2.0144 | lr 1.07e-06 | grad 1.10 | tok/s 24063
step    710 | loss 1.9354 | lr 6.94e-06 | grad 1.06 | tok/s 24201
step    720 | loss 2.0397 | lr 2.68e-05 | grad 1.35 | tok/s 24092
step    730 | loss 2.0018 | lr 5.89e-05 | grad 1.11 | tok/s 24329
step    740 | loss 1.9411 | lr 9.99e-05 | grad 1.95 | tok/s 24108
step    750 | loss 1.7297 | lr 1.46e-04 | grad 1.25 | tok/s 23827
step    760 | loss 2.1252 | lr 1.92e-04 | grad 0.72 | tok/s 24138
step    770 | loss 1.8073 | lr 2.35e-04 | grad 1.06 | tok/s 23980
step    780 | loss 1.8572 | lr 2.69e-04 | grad 1.84 | tok/s 24256
step    790 | loss 1.7920 | lr 2.91e-04 | grad 0.77 | tok/s 24457
step    800 | loss 1.7712 | lr 3.00e-04 | grad 0.95 | tok/s 24472
step    810 | loss 1.8894 | lr 2.94e-04 | grad 1.84 | tok/s 24226
step    820 | loss 2.5830 | lr 2.74e-04 | grad 1.41 | tok/s 24854
step    830 | loss 2.0353 | lr 2.42e-04 | grad 0.78 | tok/s 25252
step    840 | loss 1.7331 | lr 2.01e-04 | grad 0.52 | tok/s 25256
step    850 | loss 2.2425 | lr 1.55e-04 | grad 1.32 | tok/s 24026
step    860 | loss 1.9412 | lr 1.09e-04 | grad 1.02 | tok/s 23535
step    870 | loss 1.8521 | lr 6.65e-05 | grad 0.71 | tok/s 24233
step    880 | loss 1.9305 | lr 3.24e-05 | grad 1.12 | tok/s 24119
step    890 | loss 1.8197 | lr 9.84e-06 | grad 0.75 | tok/s 24110
step    900 | loss 2.2905 | lr 1.07e-06 | grad 0.83 | tok/s 23457
step    910 | loss 1.8637 | lr 6.94e-06 | grad 0.62 | tok/s 23916
step    920 | loss 1.8350 | lr 2.68e-05 | grad 0.65 | tok/s 23818

Training complete! Final step: 920
